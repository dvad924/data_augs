WARNING: Logging before InitGoogleLogging() is written to STDERR
I0823 10:42:08.446811 28265 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.00074
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 10000
snapshot_prefix: "models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074"
solver_mode: GPU
net: "nets/person_vs_background_vs_random_alex_net/trainval.prototxt"
I0823 10:42:08.446955 28265 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random_alex_net/trainval.prototxt
I0823 10:42:08.447243 28265 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0823 10:42:08.447263 28265 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0823 10:42:08.447403 28265 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0823 10:42:08.447481 28265 layer_factory.hpp:77] Creating layer mnist
I0823 10:42:08.447999 28265 net.cpp:100] Creating Layer mnist
I0823 10:42:08.448014 28265 net.cpp:408] mnist -> data
I0823 10:42:08.448025 28265 net.cpp:408] mnist -> label
I0823 10:42:08.448181 28265 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0823 10:42:08.449594 28278 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0823 10:42:08.485199 28265 data_layer.cpp:41] output data size: 128,3,128,128
I0823 10:42:08.562510 28265 net.cpp:150] Setting up mnist
I0823 10:42:08.562556 28265 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0823 10:42:08.562561 28265 net.cpp:157] Top shape: 128 (128)
I0823 10:42:08.562564 28265 net.cpp:165] Memory required for data: 25166336
I0823 10:42:08.562572 28265 layer_factory.hpp:77] Creating layer conv1
I0823 10:42:08.562602 28265 net.cpp:100] Creating Layer conv1
I0823 10:42:08.562608 28265 net.cpp:434] conv1 <- data
I0823 10:42:08.562618 28265 net.cpp:408] conv1 -> conv1
I0823 10:42:08.909482 28265 net.cpp:150] Setting up conv1
I0823 10:42:08.909523 28265 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0823 10:42:08.909526 28265 net.cpp:165] Memory required for data: 69403136
I0823 10:42:08.909546 28265 layer_factory.hpp:77] Creating layer relu1
I0823 10:42:08.909564 28265 net.cpp:100] Creating Layer relu1
I0823 10:42:08.909569 28265 net.cpp:434] relu1 <- conv1
I0823 10:42:08.909574 28265 net.cpp:395] relu1 -> conv1 (in-place)
I0823 10:42:08.909765 28265 net.cpp:150] Setting up relu1
I0823 10:42:08.909776 28265 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0823 10:42:08.909780 28265 net.cpp:165] Memory required for data: 113639936
I0823 10:42:08.909782 28265 layer_factory.hpp:77] Creating layer norm1
I0823 10:42:08.909792 28265 net.cpp:100] Creating Layer norm1
I0823 10:42:08.909795 28265 net.cpp:434] norm1 <- conv1
I0823 10:42:08.909801 28265 net.cpp:408] norm1 -> norm1
I0823 10:42:08.910375 28265 net.cpp:150] Setting up norm1
I0823 10:42:08.910390 28265 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0823 10:42:08.910394 28265 net.cpp:165] Memory required for data: 157876736
I0823 10:42:08.910398 28265 layer_factory.hpp:77] Creating layer pool1
I0823 10:42:08.910408 28265 net.cpp:100] Creating Layer pool1
I0823 10:42:08.910410 28265 net.cpp:434] pool1 <- norm1
I0823 10:42:08.910415 28265 net.cpp:408] pool1 -> pool1
I0823 10:42:08.910475 28265 net.cpp:150] Setting up pool1
I0823 10:42:08.910483 28265 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0823 10:42:08.910486 28265 net.cpp:165] Memory required for data: 168935936
I0823 10:42:08.910488 28265 layer_factory.hpp:77] Creating layer conv2
I0823 10:42:08.910504 28265 net.cpp:100] Creating Layer conv2
I0823 10:42:08.910508 28265 net.cpp:434] conv2 <- pool1
I0823 10:42:08.910514 28265 net.cpp:408] conv2 -> conv2
I0823 10:42:08.917242 28265 net.cpp:150] Setting up conv2
I0823 10:42:08.917258 28265 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0823 10:42:08.917261 28265 net.cpp:165] Memory required for data: 198427136
I0823 10:42:08.917270 28265 layer_factory.hpp:77] Creating layer relu2
I0823 10:42:08.917278 28265 net.cpp:100] Creating Layer relu2
I0823 10:42:08.917280 28265 net.cpp:434] relu2 <- conv2
I0823 10:42:08.917285 28265 net.cpp:395] relu2 -> conv2 (in-place)
I0823 10:42:08.917820 28265 net.cpp:150] Setting up relu2
I0823 10:42:08.917835 28265 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0823 10:42:08.917839 28265 net.cpp:165] Memory required for data: 227918336
I0823 10:42:08.917841 28265 layer_factory.hpp:77] Creating layer norm2
I0823 10:42:08.917848 28265 net.cpp:100] Creating Layer norm2
I0823 10:42:08.917851 28265 net.cpp:434] norm2 <- conv2
I0823 10:42:08.917857 28265 net.cpp:408] norm2 -> norm2
I0823 10:42:08.918081 28265 net.cpp:150] Setting up norm2
I0823 10:42:08.918092 28265 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0823 10:42:08.918095 28265 net.cpp:165] Memory required for data: 257409536
I0823 10:42:08.918097 28265 layer_factory.hpp:77] Creating layer pool2
I0823 10:42:08.918107 28265 net.cpp:100] Creating Layer pool2
I0823 10:42:08.918109 28265 net.cpp:434] pool2 <- norm2
I0823 10:42:08.918114 28265 net.cpp:408] pool2 -> pool2
I0823 10:42:08.918169 28265 net.cpp:150] Setting up pool2
I0823 10:42:08.918176 28265 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0823 10:42:08.918179 28265 net.cpp:165] Memory required for data: 263832064
I0823 10:42:08.918182 28265 layer_factory.hpp:77] Creating layer conv3
I0823 10:42:08.918192 28265 net.cpp:100] Creating Layer conv3
I0823 10:42:08.918195 28265 net.cpp:434] conv3 <- pool2
I0823 10:42:08.918200 28265 net.cpp:408] conv3 -> conv3
I0823 10:42:08.932272 28265 net.cpp:150] Setting up conv3
I0823 10:42:08.932288 28265 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0823 10:42:08.932292 28265 net.cpp:165] Memory required for data: 273465856
I0823 10:42:08.932301 28265 layer_factory.hpp:77] Creating layer relu3
I0823 10:42:08.932310 28265 net.cpp:100] Creating Layer relu3
I0823 10:42:08.932315 28265 net.cpp:434] relu3 <- conv3
I0823 10:42:08.932320 28265 net.cpp:395] relu3 -> conv3 (in-place)
I0823 10:42:08.932525 28265 net.cpp:150] Setting up relu3
I0823 10:42:08.932538 28265 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0823 10:42:08.932540 28265 net.cpp:165] Memory required for data: 283099648
I0823 10:42:08.932543 28265 layer_factory.hpp:77] Creating layer conv4
I0823 10:42:08.932557 28265 net.cpp:100] Creating Layer conv4
I0823 10:42:08.932562 28265 net.cpp:434] conv4 <- conv3
I0823 10:42:08.932569 28265 net.cpp:408] conv4 -> conv4
I0823 10:42:08.944635 28265 net.cpp:150] Setting up conv4
I0823 10:42:08.944651 28265 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0823 10:42:08.944654 28265 net.cpp:165] Memory required for data: 292733440
I0823 10:42:08.944661 28265 layer_factory.hpp:77] Creating layer relu4
I0823 10:42:08.944669 28265 net.cpp:100] Creating Layer relu4
I0823 10:42:08.944671 28265 net.cpp:434] relu4 <- conv4
I0823 10:42:08.944679 28265 net.cpp:395] relu4 -> conv4 (in-place)
I0823 10:42:08.944882 28265 net.cpp:150] Setting up relu4
I0823 10:42:08.944895 28265 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0823 10:42:08.944897 28265 net.cpp:165] Memory required for data: 302367232
I0823 10:42:08.944900 28265 layer_factory.hpp:77] Creating layer conv5
I0823 10:42:08.944913 28265 net.cpp:100] Creating Layer conv5
I0823 10:42:08.944916 28265 net.cpp:434] conv5 <- conv4
I0823 10:42:08.944924 28265 net.cpp:408] conv5 -> conv5
I0823 10:42:08.954157 28265 net.cpp:150] Setting up conv5
I0823 10:42:08.954175 28265 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0823 10:42:08.954179 28265 net.cpp:165] Memory required for data: 308789760
I0823 10:42:08.954190 28265 layer_factory.hpp:77] Creating layer relu5
I0823 10:42:08.954197 28265 net.cpp:100] Creating Layer relu5
I0823 10:42:08.954200 28265 net.cpp:434] relu5 <- conv5
I0823 10:42:08.954207 28265 net.cpp:395] relu5 -> conv5 (in-place)
I0823 10:42:08.954417 28265 net.cpp:150] Setting up relu5
I0823 10:42:08.954429 28265 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0823 10:42:08.954432 28265 net.cpp:165] Memory required for data: 315212288
I0823 10:42:08.954435 28265 layer_factory.hpp:77] Creating layer pool5
I0823 10:42:08.954443 28265 net.cpp:100] Creating Layer pool5
I0823 10:42:08.954447 28265 net.cpp:434] pool5 <- conv5
I0823 10:42:08.954452 28265 net.cpp:408] pool5 -> pool5
I0823 10:42:08.954524 28265 net.cpp:150] Setting up pool5
I0823 10:42:08.954532 28265 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0823 10:42:08.954535 28265 net.cpp:165] Memory required for data: 316391936
I0823 10:42:08.954538 28265 layer_factory.hpp:77] Creating layer fc6
I0823 10:42:08.954552 28265 net.cpp:100] Creating Layer fc6
I0823 10:42:08.954556 28265 net.cpp:434] fc6 <- pool5
I0823 10:42:08.954565 28265 net.cpp:408] fc6 -> fc6
I0823 10:42:09.088577 28265 net.cpp:150] Setting up fc6
I0823 10:42:09.088616 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.088620 28265 net.cpp:165] Memory required for data: 318489088
I0823 10:42:09.088634 28265 layer_factory.hpp:77] Creating layer relu6
I0823 10:42:09.088647 28265 net.cpp:100] Creating Layer relu6
I0823 10:42:09.088652 28265 net.cpp:434] relu6 <- fc6
I0823 10:42:09.088662 28265 net.cpp:395] relu6 -> fc6 (in-place)
I0823 10:42:09.089330 28265 net.cpp:150] Setting up relu6
I0823 10:42:09.089345 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.089349 28265 net.cpp:165] Memory required for data: 320586240
I0823 10:42:09.089351 28265 layer_factory.hpp:77] Creating layer drop6
I0823 10:42:09.089362 28265 net.cpp:100] Creating Layer drop6
I0823 10:42:09.089365 28265 net.cpp:434] drop6 <- fc6
I0823 10:42:09.089370 28265 net.cpp:395] drop6 -> fc6 (in-place)
I0823 10:42:09.089409 28265 net.cpp:150] Setting up drop6
I0823 10:42:09.089417 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.089421 28265 net.cpp:165] Memory required for data: 322683392
I0823 10:42:09.089423 28265 layer_factory.hpp:77] Creating layer fc7
I0823 10:42:09.089437 28265 net.cpp:100] Creating Layer fc7
I0823 10:42:09.089440 28265 net.cpp:434] fc7 <- fc6
I0823 10:42:09.089445 28265 net.cpp:408] fc7 -> fc7
I0823 10:42:09.324352 28265 net.cpp:150] Setting up fc7
I0823 10:42:09.324400 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.324404 28265 net.cpp:165] Memory required for data: 324780544
I0823 10:42:09.324419 28265 layer_factory.hpp:77] Creating layer relu7
I0823 10:42:09.324431 28265 net.cpp:100] Creating Layer relu7
I0823 10:42:09.324435 28265 net.cpp:434] relu7 <- fc7
I0823 10:42:09.324445 28265 net.cpp:395] relu7 -> fc7 (in-place)
I0823 10:42:09.324741 28265 net.cpp:150] Setting up relu7
I0823 10:42:09.324753 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.324755 28265 net.cpp:165] Memory required for data: 326877696
I0823 10:42:09.324759 28265 layer_factory.hpp:77] Creating layer drop7
I0823 10:42:09.324766 28265 net.cpp:100] Creating Layer drop7
I0823 10:42:09.324769 28265 net.cpp:434] drop7 <- fc7
I0823 10:42:09.324776 28265 net.cpp:395] drop7 -> fc7 (in-place)
I0823 10:42:09.324815 28265 net.cpp:150] Setting up drop7
I0823 10:42:09.324822 28265 net.cpp:157] Top shape: 128 4096 (524288)
I0823 10:42:09.324826 28265 net.cpp:165] Memory required for data: 328974848
I0823 10:42:09.324828 28265 layer_factory.hpp:77] Creating layer fc8
I0823 10:42:09.324837 28265 net.cpp:100] Creating Layer fc8
I0823 10:42:09.324839 28265 net.cpp:434] fc8 <- fc7
I0823 10:42:09.324846 28265 net.cpp:408] fc8 -> fc8
I0823 10:42:09.326828 28265 net.cpp:150] Setting up fc8
I0823 10:42:09.326843 28265 net.cpp:157] Top shape: 128 3 (384)
I0823 10:42:09.326846 28265 net.cpp:165] Memory required for data: 328976384
I0823 10:42:09.326853 28265 layer_factory.hpp:77] Creating layer loss
I0823 10:42:09.326866 28265 net.cpp:100] Creating Layer loss
I0823 10:42:09.326870 28265 net.cpp:434] loss <- fc8
I0823 10:42:09.326874 28265 net.cpp:434] loss <- label
I0823 10:42:09.326879 28265 net.cpp:408] loss -> loss
I0823 10:42:09.326889 28265 layer_factory.hpp:77] Creating layer loss
I0823 10:42:09.327252 28265 net.cpp:150] Setting up loss
I0823 10:42:09.327265 28265 net.cpp:157] Top shape: (1)
I0823 10:42:09.327266 28265 net.cpp:160]     with loss weight 1
I0823 10:42:09.327287 28265 net.cpp:165] Memory required for data: 328976388
I0823 10:42:09.327291 28265 net.cpp:226] loss needs backward computation.
I0823 10:42:09.327296 28265 net.cpp:226] fc8 needs backward computation.
I0823 10:42:09.327298 28265 net.cpp:226] drop7 needs backward computation.
I0823 10:42:09.327301 28265 net.cpp:226] relu7 needs backward computation.
I0823 10:42:09.327303 28265 net.cpp:226] fc7 needs backward computation.
I0823 10:42:09.327306 28265 net.cpp:226] drop6 needs backward computation.
I0823 10:42:09.327309 28265 net.cpp:226] relu6 needs backward computation.
I0823 10:42:09.327312 28265 net.cpp:226] fc6 needs backward computation.
I0823 10:42:09.327316 28265 net.cpp:226] pool5 needs backward computation.
I0823 10:42:09.327318 28265 net.cpp:226] relu5 needs backward computation.
I0823 10:42:09.327322 28265 net.cpp:226] conv5 needs backward computation.
I0823 10:42:09.327324 28265 net.cpp:226] relu4 needs backward computation.
I0823 10:42:09.327327 28265 net.cpp:226] conv4 needs backward computation.
I0823 10:42:09.327330 28265 net.cpp:226] relu3 needs backward computation.
I0823 10:42:09.327332 28265 net.cpp:226] conv3 needs backward computation.
I0823 10:42:09.327335 28265 net.cpp:226] pool2 needs backward computation.
I0823 10:42:09.327339 28265 net.cpp:226] norm2 needs backward computation.
I0823 10:42:09.327342 28265 net.cpp:226] relu2 needs backward computation.
I0823 10:42:09.327345 28265 net.cpp:226] conv2 needs backward computation.
I0823 10:42:09.327348 28265 net.cpp:226] pool1 needs backward computation.
I0823 10:42:09.327352 28265 net.cpp:226] norm1 needs backward computation.
I0823 10:42:09.327354 28265 net.cpp:226] relu1 needs backward computation.
I0823 10:42:09.327356 28265 net.cpp:226] conv1 needs backward computation.
I0823 10:42:09.327360 28265 net.cpp:228] mnist does not need backward computation.
I0823 10:42:09.327363 28265 net.cpp:270] This network produces output loss
I0823 10:42:09.327385 28265 net.cpp:283] Network initialization done.
I0823 10:42:09.327782 28265 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random_alex_net/trainval.prototxt
I0823 10:42:09.327826 28265 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0823 10:42:09.328004 28265 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0823 10:42:09.328121 28265 layer_factory.hpp:77] Creating layer mnist
I0823 10:42:09.328269 28265 net.cpp:100] Creating Layer mnist
I0823 10:42:09.328279 28265 net.cpp:408] mnist -> data
I0823 10:42:09.328289 28265 net.cpp:408] mnist -> label
I0823 10:42:09.328296 28265 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0823 10:42:09.329916 28280 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0823 10:42:09.330341 28265 data_layer.cpp:41] output data size: 100,3,128,128
I0823 10:42:09.391005 28265 net.cpp:150] Setting up mnist
I0823 10:42:09.391046 28265 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0823 10:42:09.391053 28265 net.cpp:157] Top shape: 100 (100)
I0823 10:42:09.391057 28265 net.cpp:165] Memory required for data: 19661200
I0823 10:42:09.391065 28265 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0823 10:42:09.391084 28265 net.cpp:100] Creating Layer label_mnist_1_split
I0823 10:42:09.391090 28265 net.cpp:434] label_mnist_1_split <- label
I0823 10:42:09.391101 28265 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I0823 10:42:09.391116 28265 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I0823 10:42:09.391441 28265 net.cpp:150] Setting up label_mnist_1_split
I0823 10:42:09.391474 28265 net.cpp:157] Top shape: 100 (100)
I0823 10:42:09.391481 28265 net.cpp:157] Top shape: 100 (100)
I0823 10:42:09.391485 28265 net.cpp:165] Memory required for data: 19662000
I0823 10:42:09.391491 28265 layer_factory.hpp:77] Creating layer conv1
I0823 10:42:09.391515 28265 net.cpp:100] Creating Layer conv1
I0823 10:42:09.391522 28265 net.cpp:434] conv1 <- data
I0823 10:42:09.391536 28265 net.cpp:408] conv1 -> conv1
I0823 10:42:09.396708 28265 net.cpp:150] Setting up conv1
I0823 10:42:09.396740 28265 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0823 10:42:09.396747 28265 net.cpp:165] Memory required for data: 54222000
I0823 10:42:09.396766 28265 layer_factory.hpp:77] Creating layer relu1
I0823 10:42:09.396780 28265 net.cpp:100] Creating Layer relu1
I0823 10:42:09.396785 28265 net.cpp:434] relu1 <- conv1
I0823 10:42:09.396795 28265 net.cpp:395] relu1 -> conv1 (in-place)
I0823 10:42:09.397164 28265 net.cpp:150] Setting up relu1
I0823 10:42:09.397183 28265 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0823 10:42:09.397189 28265 net.cpp:165] Memory required for data: 88782000
I0823 10:42:09.397194 28265 layer_factory.hpp:77] Creating layer norm1
I0823 10:42:09.397209 28265 net.cpp:100] Creating Layer norm1
I0823 10:42:09.397215 28265 net.cpp:434] norm1 <- conv1
I0823 10:42:09.397225 28265 net.cpp:408] norm1 -> norm1
I0823 10:42:09.398363 28265 net.cpp:150] Setting up norm1
I0823 10:42:09.398391 28265 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0823 10:42:09.398396 28265 net.cpp:165] Memory required for data: 123342000
I0823 10:42:09.398402 28265 layer_factory.hpp:77] Creating layer pool1
I0823 10:42:09.398416 28265 net.cpp:100] Creating Layer pool1
I0823 10:42:09.398422 28265 net.cpp:434] pool1 <- norm1
I0823 10:42:09.398432 28265 net.cpp:408] pool1 -> pool1
I0823 10:42:09.398550 28265 net.cpp:150] Setting up pool1
I0823 10:42:09.398564 28265 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0823 10:42:09.398569 28265 net.cpp:165] Memory required for data: 131982000
I0823 10:42:09.398574 28265 layer_factory.hpp:77] Creating layer conv2
I0823 10:42:09.398592 28265 net.cpp:100] Creating Layer conv2
I0823 10:42:09.398598 28265 net.cpp:434] conv2 <- pool1
I0823 10:42:09.398610 28265 net.cpp:408] conv2 -> conv2
I0823 10:42:09.411509 28265 net.cpp:150] Setting up conv2
I0823 10:42:09.411545 28265 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0823 10:42:09.411552 28265 net.cpp:165] Memory required for data: 155022000
I0823 10:42:09.411569 28265 layer_factory.hpp:77] Creating layer relu2
I0823 10:42:09.411581 28265 net.cpp:100] Creating Layer relu2
I0823 10:42:09.411587 28265 net.cpp:434] relu2 <- conv2
I0823 10:42:09.411597 28265 net.cpp:395] relu2 -> conv2 (in-place)
I0823 10:42:09.412608 28265 net.cpp:150] Setting up relu2
I0823 10:42:09.412634 28265 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0823 10:42:09.412641 28265 net.cpp:165] Memory required for data: 178062000
I0823 10:42:09.412645 28265 layer_factory.hpp:77] Creating layer norm2
I0823 10:42:09.412664 28265 net.cpp:100] Creating Layer norm2
I0823 10:42:09.412672 28265 net.cpp:434] norm2 <- conv2
I0823 10:42:09.412683 28265 net.cpp:408] norm2 -> norm2
I0823 10:42:09.413153 28265 net.cpp:150] Setting up norm2
I0823 10:42:09.413172 28265 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0823 10:42:09.413177 28265 net.cpp:165] Memory required for data: 201102000
I0823 10:42:09.413183 28265 layer_factory.hpp:77] Creating layer pool2
I0823 10:42:09.413197 28265 net.cpp:100] Creating Layer pool2
I0823 10:42:09.413203 28265 net.cpp:434] pool2 <- norm2
I0823 10:42:09.413213 28265 net.cpp:408] pool2 -> pool2
I0823 10:42:09.413327 28265 net.cpp:150] Setting up pool2
I0823 10:42:09.413342 28265 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0823 10:42:09.413347 28265 net.cpp:165] Memory required for data: 206119600
I0823 10:42:09.413352 28265 layer_factory.hpp:77] Creating layer conv3
I0823 10:42:09.413374 28265 net.cpp:100] Creating Layer conv3
I0823 10:42:09.413381 28265 net.cpp:434] conv3 <- pool2
I0823 10:42:09.413391 28265 net.cpp:408] conv3 -> conv3
I0823 10:42:09.436880 28265 net.cpp:150] Setting up conv3
I0823 10:42:09.436919 28265 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0823 10:42:09.436925 28265 net.cpp:165] Memory required for data: 213646000
I0823 10:42:09.436950 28265 layer_factory.hpp:77] Creating layer relu3
I0823 10:42:09.436967 28265 net.cpp:100] Creating Layer relu3
I0823 10:42:09.436974 28265 net.cpp:434] relu3 <- conv3
I0823 10:42:09.436983 28265 net.cpp:395] relu3 -> conv3 (in-place)
I0823 10:42:09.437327 28265 net.cpp:150] Setting up relu3
I0823 10:42:09.437345 28265 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0823 10:42:09.437348 28265 net.cpp:165] Memory required for data: 221172400
I0823 10:42:09.437353 28265 layer_factory.hpp:77] Creating layer conv4
I0823 10:42:09.437372 28265 net.cpp:100] Creating Layer conv4
I0823 10:42:09.437378 28265 net.cpp:434] conv4 <- conv3
I0823 10:42:09.437391 28265 net.cpp:408] conv4 -> conv4
I0823 10:42:09.455512 28265 net.cpp:150] Setting up conv4
I0823 10:42:09.455551 28265 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0823 10:42:09.455556 28265 net.cpp:165] Memory required for data: 228698800
I0823 10:42:09.455571 28265 layer_factory.hpp:77] Creating layer relu4
I0823 10:42:09.455586 28265 net.cpp:100] Creating Layer relu4
I0823 10:42:09.455591 28265 net.cpp:434] relu4 <- conv4
I0823 10:42:09.455601 28265 net.cpp:395] relu4 -> conv4 (in-place)
I0823 10:42:09.456450 28265 net.cpp:150] Setting up relu4
I0823 10:42:09.456471 28265 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0823 10:42:09.456475 28265 net.cpp:165] Memory required for data: 236225200
I0823 10:42:09.456480 28265 layer_factory.hpp:77] Creating layer conv5
I0823 10:42:09.456498 28265 net.cpp:100] Creating Layer conv5
I0823 10:42:09.456504 28265 net.cpp:434] conv5 <- conv4
I0823 10:42:09.456516 28265 net.cpp:408] conv5 -> conv5
I0823 10:42:09.469435 28265 net.cpp:150] Setting up conv5
I0823 10:42:09.469461 28265 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0823 10:42:09.469466 28265 net.cpp:165] Memory required for data: 241242800
I0823 10:42:09.469483 28265 layer_factory.hpp:77] Creating layer relu5
I0823 10:42:09.469496 28265 net.cpp:100] Creating Layer relu5
I0823 10:42:09.469501 28265 net.cpp:434] relu5 <- conv5
I0823 10:42:09.469508 28265 net.cpp:395] relu5 -> conv5 (in-place)
I0823 10:42:09.469789 28265 net.cpp:150] Setting up relu5
I0823 10:42:09.469805 28265 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0823 10:42:09.469808 28265 net.cpp:165] Memory required for data: 246260400
I0823 10:42:09.469812 28265 layer_factory.hpp:77] Creating layer pool5
I0823 10:42:09.469828 28265 net.cpp:100] Creating Layer pool5
I0823 10:42:09.469832 28265 net.cpp:434] pool5 <- conv5
I0823 10:42:09.469840 28265 net.cpp:408] pool5 -> pool5
I0823 10:42:09.469949 28265 net.cpp:150] Setting up pool5
I0823 10:42:09.469960 28265 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0823 10:42:09.469964 28265 net.cpp:165] Memory required for data: 247182000
I0823 10:42:09.469967 28265 layer_factory.hpp:77] Creating layer fc6
I0823 10:42:09.469982 28265 net.cpp:100] Creating Layer fc6
I0823 10:42:09.469990 28265 net.cpp:434] fc6 <- pool5
I0823 10:42:09.469998 28265 net.cpp:408] fc6 -> fc6
I0823 10:42:09.610654 28265 net.cpp:150] Setting up fc6
I0823 10:42:09.610699 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.610702 28265 net.cpp:165] Memory required for data: 248820400
I0823 10:42:09.610715 28265 layer_factory.hpp:77] Creating layer relu6
I0823 10:42:09.610728 28265 net.cpp:100] Creating Layer relu6
I0823 10:42:09.610733 28265 net.cpp:434] relu6 <- fc6
I0823 10:42:09.610743 28265 net.cpp:395] relu6 -> fc6 (in-place)
I0823 10:42:09.611044 28265 net.cpp:150] Setting up relu6
I0823 10:42:09.611055 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.611058 28265 net.cpp:165] Memory required for data: 250458800
I0823 10:42:09.611062 28265 layer_factory.hpp:77] Creating layer drop6
I0823 10:42:09.611073 28265 net.cpp:100] Creating Layer drop6
I0823 10:42:09.611076 28265 net.cpp:434] drop6 <- fc6
I0823 10:42:09.611081 28265 net.cpp:395] drop6 -> fc6 (in-place)
I0823 10:42:09.611137 28265 net.cpp:150] Setting up drop6
I0823 10:42:09.611146 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.611150 28265 net.cpp:165] Memory required for data: 252097200
I0823 10:42:09.611151 28265 layer_factory.hpp:77] Creating layer fc7
I0823 10:42:09.611163 28265 net.cpp:100] Creating Layer fc7
I0823 10:42:09.611167 28265 net.cpp:434] fc7 <- fc6
I0823 10:42:09.611176 28265 net.cpp:408] fc7 -> fc7
I0823 10:42:09.846145 28265 net.cpp:150] Setting up fc7
I0823 10:42:09.846197 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.846201 28265 net.cpp:165] Memory required for data: 253735600
I0823 10:42:09.846215 28265 layer_factory.hpp:77] Creating layer relu7
I0823 10:42:09.846230 28265 net.cpp:100] Creating Layer relu7
I0823 10:42:09.846235 28265 net.cpp:434] relu7 <- fc7
I0823 10:42:09.846243 28265 net.cpp:395] relu7 -> fc7 (in-place)
I0823 10:42:09.847105 28265 net.cpp:150] Setting up relu7
I0823 10:42:09.847123 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.847126 28265 net.cpp:165] Memory required for data: 255374000
I0823 10:42:09.847129 28265 layer_factory.hpp:77] Creating layer drop7
I0823 10:42:09.847138 28265 net.cpp:100] Creating Layer drop7
I0823 10:42:09.847141 28265 net.cpp:434] drop7 <- fc7
I0823 10:42:09.847148 28265 net.cpp:395] drop7 -> fc7 (in-place)
I0823 10:42:09.847208 28265 net.cpp:150] Setting up drop7
I0823 10:42:09.847215 28265 net.cpp:157] Top shape: 100 4096 (409600)
I0823 10:42:09.847218 28265 net.cpp:165] Memory required for data: 257012400
I0823 10:42:09.847221 28265 layer_factory.hpp:77] Creating layer fc8
I0823 10:42:09.847232 28265 net.cpp:100] Creating Layer fc8
I0823 10:42:09.847236 28265 net.cpp:434] fc8 <- fc7
I0823 10:42:09.847242 28265 net.cpp:408] fc8 -> fc8
I0823 10:42:09.847609 28265 net.cpp:150] Setting up fc8
I0823 10:42:09.847620 28265 net.cpp:157] Top shape: 100 3 (300)
I0823 10:42:09.847621 28265 net.cpp:165] Memory required for data: 257013600
I0823 10:42:09.847627 28265 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0823 10:42:09.847635 28265 net.cpp:100] Creating Layer fc8_fc8_0_split
I0823 10:42:09.847638 28265 net.cpp:434] fc8_fc8_0_split <- fc8
I0823 10:42:09.847643 28265 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0823 10:42:09.847651 28265 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0823 10:42:09.847718 28265 net.cpp:150] Setting up fc8_fc8_0_split
I0823 10:42:09.847726 28265 net.cpp:157] Top shape: 100 3 (300)
I0823 10:42:09.847729 28265 net.cpp:157] Top shape: 100 3 (300)
I0823 10:42:09.847733 28265 net.cpp:165] Memory required for data: 257016000
I0823 10:42:09.847734 28265 layer_factory.hpp:77] Creating layer accuracy
I0823 10:42:09.847744 28265 net.cpp:100] Creating Layer accuracy
I0823 10:42:09.847748 28265 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0823 10:42:09.847751 28265 net.cpp:434] accuracy <- label_mnist_1_split_0
I0823 10:42:09.847759 28265 net.cpp:408] accuracy -> accuracy
I0823 10:42:09.847766 28265 net.cpp:150] Setting up accuracy
I0823 10:42:09.847770 28265 net.cpp:157] Top shape: (1)
I0823 10:42:09.847772 28265 net.cpp:165] Memory required for data: 257016004
I0823 10:42:09.847775 28265 layer_factory.hpp:77] Creating layer loss
I0823 10:42:09.847780 28265 net.cpp:100] Creating Layer loss
I0823 10:42:09.847784 28265 net.cpp:434] loss <- fc8_fc8_0_split_1
I0823 10:42:09.847787 28265 net.cpp:434] loss <- label_mnist_1_split_1
I0823 10:42:09.847792 28265 net.cpp:408] loss -> loss
I0823 10:42:09.847800 28265 layer_factory.hpp:77] Creating layer loss
I0823 10:42:09.848186 28265 net.cpp:150] Setting up loss
I0823 10:42:09.848197 28265 net.cpp:157] Top shape: (1)
I0823 10:42:09.848199 28265 net.cpp:160]     with loss weight 1
I0823 10:42:09.848214 28265 net.cpp:165] Memory required for data: 257016008
I0823 10:42:09.848218 28265 net.cpp:226] loss needs backward computation.
I0823 10:42:09.848222 28265 net.cpp:228] accuracy does not need backward computation.
I0823 10:42:09.848227 28265 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0823 10:42:09.848229 28265 net.cpp:226] fc8 needs backward computation.
I0823 10:42:09.848232 28265 net.cpp:226] drop7 needs backward computation.
I0823 10:42:09.848234 28265 net.cpp:226] relu7 needs backward computation.
I0823 10:42:09.848237 28265 net.cpp:226] fc7 needs backward computation.
I0823 10:42:09.848239 28265 net.cpp:226] drop6 needs backward computation.
I0823 10:42:09.848242 28265 net.cpp:226] relu6 needs backward computation.
I0823 10:42:09.848245 28265 net.cpp:226] fc6 needs backward computation.
I0823 10:42:09.848248 28265 net.cpp:226] pool5 needs backward computation.
I0823 10:42:09.848251 28265 net.cpp:226] relu5 needs backward computation.
I0823 10:42:09.848254 28265 net.cpp:226] conv5 needs backward computation.
I0823 10:42:09.848258 28265 net.cpp:226] relu4 needs backward computation.
I0823 10:42:09.848259 28265 net.cpp:226] conv4 needs backward computation.
I0823 10:42:09.848263 28265 net.cpp:226] relu3 needs backward computation.
I0823 10:42:09.848265 28265 net.cpp:226] conv3 needs backward computation.
I0823 10:42:09.848268 28265 net.cpp:226] pool2 needs backward computation.
I0823 10:42:09.848271 28265 net.cpp:226] norm2 needs backward computation.
I0823 10:42:09.848279 28265 net.cpp:226] relu2 needs backward computation.
I0823 10:42:09.848283 28265 net.cpp:226] conv2 needs backward computation.
I0823 10:42:09.848285 28265 net.cpp:226] pool1 needs backward computation.
I0823 10:42:09.848289 28265 net.cpp:226] norm1 needs backward computation.
I0823 10:42:09.848291 28265 net.cpp:226] relu1 needs backward computation.
I0823 10:42:09.848294 28265 net.cpp:226] conv1 needs backward computation.
I0823 10:42:09.848297 28265 net.cpp:228] label_mnist_1_split does not need backward computation.
I0823 10:42:09.848301 28265 net.cpp:228] mnist does not need backward computation.
I0823 10:42:09.848304 28265 net.cpp:270] This network produces output accuracy
I0823 10:42:09.848306 28265 net.cpp:270] This network produces output loss
I0823 10:42:09.848327 28265 net.cpp:283] Network initialization done.
I0823 10:42:09.848428 28265 solver.cpp:60] Solver scaffolding done.
I0823 10:42:09.852711 28265 solver.cpp:337] Iteration 0, Testing net (#0)
I0823 10:42:09.972494 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:42:13.091637 28265 solver.cpp:404]     Test net output #0: accuracy = 0.269667
I0823 10:42:13.091684 28265 solver.cpp:404]     Test net output #1: loss = 1.12684 (* 1 = 1.12684 loss)
I0823 10:42:13.131728 28265 solver.cpp:228] Iteration 0, loss = 1.10494
I0823 10:42:13.131788 28265 solver.cpp:244]     Train net output #0: loss = 1.10494 (* 1 = 1.10494 loss)
I0823 10:42:13.131810 28265 sgd_solver.cpp:106] Iteration 0, lr = 0.00074
I0823 10:42:17.584383 28265 solver.cpp:228] Iteration 100, loss = 1.0923
I0823 10:42:17.584424 28265 solver.cpp:244]     Train net output #0: loss = 1.0923 (* 1 = 1.0923 loss)
I0823 10:42:17.584429 28265 sgd_solver.cpp:106] Iteration 100, lr = 0.000737237
I0823 10:42:22.060982 28265 solver.cpp:228] Iteration 200, loss = 1.09675
I0823 10:42:22.061049 28265 solver.cpp:244]     Train net output #0: loss = 1.09675 (* 1 = 1.09675 loss)
I0823 10:42:22.061056 28265 sgd_solver.cpp:106] Iteration 200, lr = 0.000734498
I0823 10:42:26.533632 28265 solver.cpp:228] Iteration 300, loss = 1.10006
I0823 10:42:26.533673 28265 solver.cpp:244]     Train net output #0: loss = 1.10006 (* 1 = 1.10006 loss)
I0823 10:42:26.533679 28265 sgd_solver.cpp:106] Iteration 300, lr = 0.000731783
I0823 10:42:31.012971 28265 solver.cpp:228] Iteration 400, loss = 1.09819
I0823 10:42:31.013028 28265 solver.cpp:244]     Train net output #0: loss = 1.09819 (* 1 = 1.09819 loss)
I0823 10:42:31.013036 28265 sgd_solver.cpp:106] Iteration 400, lr = 0.000729091
I0823 10:42:35.450911 28265 solver.cpp:337] Iteration 500, Testing net (#0)
I0823 10:42:38.571487 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:42:38.571538 28265 solver.cpp:404]     Test net output #1: loss = 1.09784 (* 1 = 1.09784 loss)
I0823 10:42:38.586735 28265 solver.cpp:228] Iteration 500, loss = 1.10313
I0823 10:42:38.586771 28265 solver.cpp:244]     Train net output #0: loss = 1.10313 (* 1 = 1.10313 loss)
I0823 10:42:38.586781 28265 sgd_solver.cpp:106] Iteration 500, lr = 0.000726422
I0823 10:42:43.075784 28265 solver.cpp:228] Iteration 600, loss = 1.11057
I0823 10:42:43.075824 28265 solver.cpp:244]     Train net output #0: loss = 1.11057 (* 1 = 1.11057 loss)
I0823 10:42:43.075830 28265 sgd_solver.cpp:106] Iteration 600, lr = 0.000723775
I0823 10:42:47.570648 28265 solver.cpp:228] Iteration 700, loss = 1.10149
I0823 10:42:47.570696 28265 solver.cpp:244]     Train net output #0: loss = 1.10149 (* 1 = 1.10149 loss)
I0823 10:42:47.570701 28265 sgd_solver.cpp:106] Iteration 700, lr = 0.000721151
I0823 10:42:52.068976 28265 solver.cpp:228] Iteration 800, loss = 1.09403
I0823 10:42:52.069077 28265 solver.cpp:244]     Train net output #0: loss = 1.09403 (* 1 = 1.09403 loss)
I0823 10:42:52.069083 28265 sgd_solver.cpp:106] Iteration 800, lr = 0.00071855
I0823 10:42:56.568516 28265 solver.cpp:228] Iteration 900, loss = 1.11005
I0823 10:42:56.568562 28265 solver.cpp:244]     Train net output #0: loss = 1.11005 (* 1 = 1.11005 loss)
I0823 10:42:56.568567 28265 sgd_solver.cpp:106] Iteration 900, lr = 0.000715969
I0823 10:43:01.027380 28265 solver.cpp:337] Iteration 1000, Testing net (#0)
I0823 10:43:04.143023 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578167
I0823 10:43:04.143054 28265 solver.cpp:404]     Test net output #1: loss = 1.09626 (* 1 = 1.09626 loss)
I0823 10:43:04.158663 28265 solver.cpp:228] Iteration 1000, loss = 1.10727
I0823 10:43:04.158716 28265 solver.cpp:244]     Train net output #0: loss = 1.10727 (* 1 = 1.10727 loss)
I0823 10:43:04.158730 28265 sgd_solver.cpp:106] Iteration 1000, lr = 0.000713411
I0823 10:43:08.658968 28265 solver.cpp:228] Iteration 1100, loss = 1.09258
I0823 10:43:08.659013 28265 solver.cpp:244]     Train net output #0: loss = 1.09258 (* 1 = 1.09258 loss)
I0823 10:43:08.659018 28265 sgd_solver.cpp:106] Iteration 1100, lr = 0.000710874
I0823 10:43:13.170833 28265 solver.cpp:228] Iteration 1200, loss = 1.09518
I0823 10:43:13.170879 28265 solver.cpp:244]     Train net output #0: loss = 1.09518 (* 1 = 1.09518 loss)
I0823 10:43:13.170886 28265 sgd_solver.cpp:106] Iteration 1200, lr = 0.000708357
I0823 10:43:17.677186 28265 solver.cpp:228] Iteration 1300, loss = 1.09938
I0823 10:43:17.677233 28265 solver.cpp:244]     Train net output #0: loss = 1.09938 (* 1 = 1.09938 loss)
I0823 10:43:17.677238 28265 sgd_solver.cpp:106] Iteration 1300, lr = 0.000705861
I0823 10:43:22.184622 28265 solver.cpp:228] Iteration 1400, loss = 1.09105
I0823 10:43:22.184669 28265 solver.cpp:244]     Train net output #0: loss = 1.09105 (* 1 = 1.09105 loss)
I0823 10:43:22.184674 28265 sgd_solver.cpp:106] Iteration 1400, lr = 0.000703386
I0823 10:43:26.650118 28265 solver.cpp:337] Iteration 1500, Testing net (#0)
I0823 10:43:29.788367 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0823 10:43:29.788399 28265 solver.cpp:404]     Test net output #1: loss = 1.10014 (* 1 = 1.10014 loss)
I0823 10:43:29.804296 28265 solver.cpp:228] Iteration 1500, loss = 1.09808
I0823 10:43:29.804359 28265 solver.cpp:244]     Train net output #0: loss = 1.09808 (* 1 = 1.09808 loss)
I0823 10:43:29.804373 28265 sgd_solver.cpp:106] Iteration 1500, lr = 0.000700931
I0823 10:43:34.326928 28265 solver.cpp:228] Iteration 1600, loss = 1.10715
I0823 10:43:34.326985 28265 solver.cpp:244]     Train net output #0: loss = 1.10715 (* 1 = 1.10715 loss)
I0823 10:43:34.326992 28265 sgd_solver.cpp:106] Iteration 1600, lr = 0.000698496
I0823 10:43:38.852840 28265 solver.cpp:228] Iteration 1700, loss = 1.10621
I0823 10:43:38.852885 28265 solver.cpp:244]     Train net output #0: loss = 1.10621 (* 1 = 1.10621 loss)
I0823 10:43:38.852891 28265 sgd_solver.cpp:106] Iteration 1700, lr = 0.00069608
I0823 10:43:43.371408 28265 solver.cpp:228] Iteration 1800, loss = 1.10712
I0823 10:43:43.371479 28265 solver.cpp:244]     Train net output #0: loss = 1.10712 (* 1 = 1.10712 loss)
I0823 10:43:43.371485 28265 sgd_solver.cpp:106] Iteration 1800, lr = 0.000693684
I0823 10:43:47.895407 28265 solver.cpp:228] Iteration 1900, loss = 1.09074
I0823 10:43:47.895455 28265 solver.cpp:244]     Train net output #0: loss = 1.09074 (* 1 = 1.09074 loss)
I0823 10:43:47.895460 28265 sgd_solver.cpp:106] Iteration 1900, lr = 0.000691307
I0823 10:43:52.362423 28265 solver.cpp:337] Iteration 2000, Testing net (#0)
I0823 10:43:55.546362 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0823 10:43:55.546385 28265 solver.cpp:404]     Test net output #1: loss = 1.10064 (* 1 = 1.10064 loss)
I0823 10:43:55.562114 28265 solver.cpp:228] Iteration 2000, loss = 1.10769
I0823 10:43:55.562172 28265 solver.cpp:244]     Train net output #0: loss = 1.10769 (* 1 = 1.10769 loss)
I0823 10:43:55.562193 28265 sgd_solver.cpp:106] Iteration 2000, lr = 0.000688949
I0823 10:44:00.087625 28265 solver.cpp:228] Iteration 2100, loss = 1.10031
I0823 10:44:00.087700 28265 solver.cpp:244]     Train net output #0: loss = 1.10031 (* 1 = 1.10031 loss)
I0823 10:44:00.087713 28265 sgd_solver.cpp:106] Iteration 2100, lr = 0.00068661
I0823 10:44:04.608933 28265 solver.cpp:228] Iteration 2200, loss = 1.09611
I0823 10:44:04.608983 28265 solver.cpp:244]     Train net output #0: loss = 1.09611 (* 1 = 1.09611 loss)
I0823 10:44:04.608988 28265 sgd_solver.cpp:106] Iteration 2200, lr = 0.000684289
I0823 10:44:09.136893 28265 solver.cpp:228] Iteration 2300, loss = 1.09041
I0823 10:44:09.136951 28265 solver.cpp:244]     Train net output #0: loss = 1.09041 (* 1 = 1.09041 loss)
I0823 10:44:09.136958 28265 sgd_solver.cpp:106] Iteration 2300, lr = 0.000681986
I0823 10:44:13.654497 28265 solver.cpp:228] Iteration 2400, loss = 1.10292
I0823 10:44:13.654518 28265 solver.cpp:244]     Train net output #0: loss = 1.10292 (* 1 = 1.10292 loss)
I0823 10:44:13.654523 28265 sgd_solver.cpp:106] Iteration 2400, lr = 0.000679701
I0823 10:44:18.139130 28265 solver.cpp:337] Iteration 2500, Testing net (#0)
I0823 10:44:21.290997 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152667
I0823 10:44:21.291028 28265 solver.cpp:404]     Test net output #1: loss = 1.10262 (* 1 = 1.10262 loss)
I0823 10:44:21.306849 28265 solver.cpp:228] Iteration 2500, loss = 1.10426
I0823 10:44:21.306902 28265 solver.cpp:244]     Train net output #0: loss = 1.10426 (* 1 = 1.10426 loss)
I0823 10:44:21.306916 28265 sgd_solver.cpp:106] Iteration 2500, lr = 0.000677434
I0823 10:44:25.847678 28265 solver.cpp:228] Iteration 2600, loss = 1.11109
I0823 10:44:25.847735 28265 solver.cpp:244]     Train net output #0: loss = 1.11109 (* 1 = 1.11109 loss)
I0823 10:44:25.847743 28265 sgd_solver.cpp:106] Iteration 2600, lr = 0.000675185
I0823 10:44:30.367818 28265 solver.cpp:228] Iteration 2700, loss = 1.10016
I0823 10:44:30.367840 28265 solver.cpp:244]     Train net output #0: loss = 1.10016 (* 1 = 1.10016 loss)
I0823 10:44:30.367843 28265 sgd_solver.cpp:106] Iteration 2700, lr = 0.000672953
I0823 10:44:34.890422 28265 solver.cpp:228] Iteration 2800, loss = 1.09932
I0823 10:44:34.890444 28265 solver.cpp:244]     Train net output #0: loss = 1.09932 (* 1 = 1.09932 loss)
I0823 10:44:34.890449 28265 sgd_solver.cpp:106] Iteration 2800, lr = 0.000670738
I0823 10:44:39.415808 28265 solver.cpp:228] Iteration 2900, loss = 1.10412
I0823 10:44:39.415870 28265 solver.cpp:244]     Train net output #0: loss = 1.10412 (* 1 = 1.10412 loss)
I0823 10:44:39.415880 28265 sgd_solver.cpp:106] Iteration 2900, lr = 0.00066854
I0823 10:44:43.898545 28265 solver.cpp:337] Iteration 3000, Testing net (#0)
I0823 10:44:47.028071 28265 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0823 10:44:47.028105 28265 solver.cpp:404]     Test net output #1: loss = 1.10321 (* 1 = 1.10321 loss)
I0823 10:44:47.043884 28265 solver.cpp:228] Iteration 3000, loss = 1.09077
I0823 10:44:47.043943 28265 solver.cpp:244]     Train net output #0: loss = 1.09077 (* 1 = 1.09077 loss)
I0823 10:44:47.043957 28265 sgd_solver.cpp:106] Iteration 3000, lr = 0.000666359
I0823 10:44:51.569921 28265 solver.cpp:228] Iteration 3100, loss = 1.10536
I0823 10:44:51.569964 28265 solver.cpp:244]     Train net output #0: loss = 1.10536 (* 1 = 1.10536 loss)
I0823 10:44:51.569969 28265 sgd_solver.cpp:106] Iteration 3100, lr = 0.000664194
I0823 10:44:56.098181 28265 solver.cpp:228] Iteration 3200, loss = 1.10048
I0823 10:44:56.098228 28265 solver.cpp:244]     Train net output #0: loss = 1.10048 (* 1 = 1.10048 loss)
I0823 10:44:56.098233 28265 sgd_solver.cpp:106] Iteration 3200, lr = 0.000662046
I0823 10:45:00.627271 28265 solver.cpp:228] Iteration 3300, loss = 1.09566
I0823 10:45:00.627315 28265 solver.cpp:244]     Train net output #0: loss = 1.09566 (* 1 = 1.09566 loss)
I0823 10:45:00.627320 28265 sgd_solver.cpp:106] Iteration 3300, lr = 0.000659914
I0823 10:45:05.164340 28265 solver.cpp:228] Iteration 3400, loss = 1.09764
I0823 10:45:05.164397 28265 solver.cpp:244]     Train net output #0: loss = 1.09764 (* 1 = 1.09764 loss)
I0823 10:45:05.164404 28265 sgd_solver.cpp:106] Iteration 3400, lr = 0.000657798
I0823 10:45:09.642527 28265 solver.cpp:337] Iteration 3500, Testing net (#0)
I0823 10:45:12.815913 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0823 10:45:12.815945 28265 solver.cpp:404]     Test net output #1: loss = 1.10312 (* 1 = 1.10312 loss)
I0823 10:45:12.832881 28265 solver.cpp:228] Iteration 3500, loss = 1.09602
I0823 10:45:12.832934 28265 solver.cpp:244]     Train net output #0: loss = 1.09602 (* 1 = 1.09602 loss)
I0823 10:45:12.832947 28265 sgd_solver.cpp:106] Iteration 3500, lr = 0.000655697
I0823 10:45:17.357847 28265 solver.cpp:228] Iteration 3600, loss = 1.10919
I0823 10:45:17.357893 28265 solver.cpp:244]     Train net output #0: loss = 1.10919 (* 1 = 1.10919 loss)
I0823 10:45:17.357898 28265 sgd_solver.cpp:106] Iteration 3600, lr = 0.000653612
I0823 10:45:21.886839 28265 solver.cpp:228] Iteration 3700, loss = 1.10578
I0823 10:45:21.886885 28265 solver.cpp:244]     Train net output #0: loss = 1.10578 (* 1 = 1.10578 loss)
I0823 10:45:21.886891 28265 sgd_solver.cpp:106] Iteration 3700, lr = 0.000651543
I0823 10:45:26.415339 28265 solver.cpp:228] Iteration 3800, loss = 1.09639
I0823 10:45:26.415383 28265 solver.cpp:244]     Train net output #0: loss = 1.09639 (* 1 = 1.09639 loss)
I0823 10:45:26.415390 28265 sgd_solver.cpp:106] Iteration 3800, lr = 0.000649489
I0823 10:45:30.952215 28265 solver.cpp:228] Iteration 3900, loss = 1.10408
I0823 10:45:30.952263 28265 solver.cpp:244]     Train net output #0: loss = 1.10408 (* 1 = 1.10408 loss)
I0823 10:45:30.952268 28265 sgd_solver.cpp:106] Iteration 3900, lr = 0.000647449
I0823 10:45:35.436131 28265 solver.cpp:337] Iteration 4000, Testing net (#0)
I0823 10:45:38.602075 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0823 10:45:38.602116 28265 solver.cpp:404]     Test net output #1: loss = 1.10611 (* 1 = 1.10611 loss)
I0823 10:45:38.617854 28265 solver.cpp:228] Iteration 4000, loss = 1.08907
I0823 10:45:38.617892 28265 solver.cpp:244]     Train net output #0: loss = 1.08907 (* 1 = 1.08907 loss)
I0823 10:45:38.617902 28265 sgd_solver.cpp:106] Iteration 4000, lr = 0.000645425
I0823 10:45:43.150951 28265 solver.cpp:228] Iteration 4100, loss = 1.09754
I0823 10:45:43.151012 28265 solver.cpp:244]     Train net output #0: loss = 1.09754 (* 1 = 1.09754 loss)
I0823 10:45:43.151020 28265 sgd_solver.cpp:106] Iteration 4100, lr = 0.000643415
I0823 10:45:47.687690 28265 solver.cpp:228] Iteration 4200, loss = 1.09849
I0823 10:45:47.687738 28265 solver.cpp:244]     Train net output #0: loss = 1.09849 (* 1 = 1.09849 loss)
I0823 10:45:47.687744 28265 sgd_solver.cpp:106] Iteration 4200, lr = 0.00064142
I0823 10:45:52.213109 28265 solver.cpp:228] Iteration 4300, loss = 1.10286
I0823 10:45:52.213127 28265 solver.cpp:244]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0823 10:45:52.213131 28265 sgd_solver.cpp:106] Iteration 4300, lr = 0.00063944
I0823 10:45:56.745555 28265 solver.cpp:228] Iteration 4400, loss = 1.10447
I0823 10:45:56.745601 28265 solver.cpp:244]     Train net output #0: loss = 1.10447 (* 1 = 1.10447 loss)
I0823 10:45:56.745606 28265 sgd_solver.cpp:106] Iteration 4400, lr = 0.000637473
I0823 10:46:01.234761 28265 solver.cpp:337] Iteration 4500, Testing net (#0)
I0823 10:46:04.355605 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:46:04.355636 28265 solver.cpp:404]     Test net output #1: loss = 1.11021 (* 1 = 1.11021 loss)
I0823 10:46:04.371362 28265 solver.cpp:228] Iteration 4500, loss = 1.10469
I0823 10:46:04.371381 28265 solver.cpp:244]     Train net output #0: loss = 1.10469 (* 1 = 1.10469 loss)
I0823 10:46:04.371387 28265 sgd_solver.cpp:106] Iteration 4500, lr = 0.000635521
I0823 10:46:08.896504 28265 solver.cpp:228] Iteration 4600, loss = 1.10305
I0823 10:46:08.896567 28265 solver.cpp:244]     Train net output #0: loss = 1.10305 (* 1 = 1.10305 loss)
I0823 10:46:08.896579 28265 sgd_solver.cpp:106] Iteration 4600, lr = 0.000633582
I0823 10:46:13.427114 28265 solver.cpp:228] Iteration 4700, loss = 1.10151
I0823 10:46:13.427157 28265 solver.cpp:244]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0823 10:46:13.427165 28265 sgd_solver.cpp:106] Iteration 4700, lr = 0.000631657
I0823 10:46:17.947409 28265 solver.cpp:228] Iteration 4800, loss = 1.09606
I0823 10:46:17.947453 28265 solver.cpp:244]     Train net output #0: loss = 1.09606 (* 1 = 1.09606 loss)
I0823 10:46:17.947458 28265 sgd_solver.cpp:106] Iteration 4800, lr = 0.000629746
I0823 10:46:22.471267 28265 solver.cpp:228] Iteration 4900, loss = 1.09768
I0823 10:46:22.471288 28265 solver.cpp:244]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0823 10:46:22.471293 28265 sgd_solver.cpp:106] Iteration 4900, lr = 0.000627848
I0823 10:46:26.951766 28265 solver.cpp:337] Iteration 5000, Testing net (#0)
I0823 10:46:27.202672 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:46:30.076701 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0823 10:46:30.076724 28265 solver.cpp:404]     Test net output #1: loss = 1.11189 (* 1 = 1.11189 loss)
I0823 10:46:30.092545 28265 solver.cpp:228] Iteration 5000, loss = 1.10394
I0823 10:46:30.092600 28265 solver.cpp:244]     Train net output #0: loss = 1.10394 (* 1 = 1.10394 loss)
I0823 10:46:30.092613 28265 sgd_solver.cpp:106] Iteration 5000, lr = 0.000625964
I0823 10:46:34.621872 28265 solver.cpp:228] Iteration 5100, loss = 1.09519
I0823 10:46:34.621919 28265 solver.cpp:244]     Train net output #0: loss = 1.09519 (* 1 = 1.09519 loss)
I0823 10:46:34.621925 28265 sgd_solver.cpp:106] Iteration 5100, lr = 0.000624092
I0823 10:46:39.165619 28265 solver.cpp:228] Iteration 5200, loss = 1.10577
I0823 10:46:39.165665 28265 solver.cpp:244]     Train net output #0: loss = 1.10577 (* 1 = 1.10577 loss)
I0823 10:46:39.165670 28265 sgd_solver.cpp:106] Iteration 5200, lr = 0.000622234
I0823 10:46:43.689617 28265 solver.cpp:228] Iteration 5300, loss = 1.09814
I0823 10:46:43.689638 28265 solver.cpp:244]     Train net output #0: loss = 1.09814 (* 1 = 1.09814 loss)
I0823 10:46:43.689643 28265 sgd_solver.cpp:106] Iteration 5300, lr = 0.000620389
I0823 10:46:48.209334 28265 solver.cpp:228] Iteration 5400, loss = 1.09754
I0823 10:46:48.209357 28265 solver.cpp:244]     Train net output #0: loss = 1.09754 (* 1 = 1.09754 loss)
I0823 10:46:48.209360 28265 sgd_solver.cpp:106] Iteration 5400, lr = 0.000618556
I0823 10:46:52.693620 28265 solver.cpp:337] Iteration 5500, Testing net (#0)
I0823 10:46:55.858297 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0823 10:46:55.858331 28265 solver.cpp:404]     Test net output #1: loss = 1.11244 (* 1 = 1.11244 loss)
I0823 10:46:55.873565 28265 solver.cpp:228] Iteration 5500, loss = 1.10294
I0823 10:46:55.873597 28265 solver.cpp:244]     Train net output #0: loss = 1.10294 (* 1 = 1.10294 loss)
I0823 10:46:55.873603 28265 sgd_solver.cpp:106] Iteration 5500, lr = 0.000616736
I0823 10:47:00.399077 28265 solver.cpp:228] Iteration 5600, loss = 1.09426
I0823 10:47:00.399154 28265 solver.cpp:244]     Train net output #0: loss = 1.09426 (* 1 = 1.09426 loss)
I0823 10:47:00.399170 28265 sgd_solver.cpp:106] Iteration 5600, lr = 0.000614928
I0823 10:47:04.936717 28265 solver.cpp:228] Iteration 5700, loss = 1.10012
I0823 10:47:04.936763 28265 solver.cpp:244]     Train net output #0: loss = 1.10012 (* 1 = 1.10012 loss)
I0823 10:47:04.936769 28265 sgd_solver.cpp:106] Iteration 5700, lr = 0.000613133
I0823 10:47:09.477844 28265 solver.cpp:228] Iteration 5800, loss = 1.09213
I0823 10:47:09.477891 28265 solver.cpp:244]     Train net output #0: loss = 1.09213 (* 1 = 1.09213 loss)
I0823 10:47:09.477896 28265 sgd_solver.cpp:106] Iteration 5800, lr = 0.000611349
I0823 10:47:14.010493 28265 solver.cpp:228] Iteration 5900, loss = 1.10446
I0823 10:47:14.010540 28265 solver.cpp:244]     Train net output #0: loss = 1.10446 (* 1 = 1.10446 loss)
I0823 10:47:14.010546 28265 sgd_solver.cpp:106] Iteration 5900, lr = 0.000609578
I0823 10:47:18.507279 28265 solver.cpp:337] Iteration 6000, Testing net (#0)
I0823 10:47:21.633190 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0823 10:47:21.633316 28265 solver.cpp:404]     Test net output #1: loss = 1.11151 (* 1 = 1.11151 loss)
I0823 10:47:21.648650 28265 solver.cpp:228] Iteration 6000, loss = 1.10368
I0823 10:47:21.648710 28265 solver.cpp:244]     Train net output #0: loss = 1.10368 (* 1 = 1.10368 loss)
I0823 10:47:21.648722 28265 sgd_solver.cpp:106] Iteration 6000, lr = 0.000607819
I0823 10:47:26.181257 28265 solver.cpp:228] Iteration 6100, loss = 1.09415
I0823 10:47:26.181310 28265 solver.cpp:244]     Train net output #0: loss = 1.09415 (* 1 = 1.09415 loss)
I0823 10:47:26.181315 28265 sgd_solver.cpp:106] Iteration 6100, lr = 0.000606071
I0823 10:47:30.715678 28265 solver.cpp:228] Iteration 6200, loss = 1.10297
I0823 10:47:30.715737 28265 solver.cpp:244]     Train net output #0: loss = 1.10297 (* 1 = 1.10297 loss)
I0823 10:47:30.715744 28265 sgd_solver.cpp:106] Iteration 6200, lr = 0.000604336
I0823 10:47:35.252406 28265 solver.cpp:228] Iteration 6300, loss = 1.10134
I0823 10:47:35.252465 28265 solver.cpp:244]     Train net output #0: loss = 1.10134 (* 1 = 1.10134 loss)
I0823 10:47:35.252471 28265 sgd_solver.cpp:106] Iteration 6300, lr = 0.000602611
I0823 10:47:39.784600 28265 solver.cpp:228] Iteration 6400, loss = 1.09355
I0823 10:47:39.784646 28265 solver.cpp:244]     Train net output #0: loss = 1.09355 (* 1 = 1.09355 loss)
I0823 10:47:39.784652 28265 sgd_solver.cpp:106] Iteration 6400, lr = 0.000600899
I0823 10:47:44.271607 28265 solver.cpp:337] Iteration 6500, Testing net (#0)
I0823 10:47:47.724411 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:47:47.724462 28265 solver.cpp:404]     Test net output #1: loss = 1.10661 (* 1 = 1.10661 loss)
I0823 10:47:47.739189 28265 solver.cpp:228] Iteration 6500, loss = 1.10255
I0823 10:47:47.739244 28265 solver.cpp:244]     Train net output #0: loss = 1.10255 (* 1 = 1.10255 loss)
I0823 10:47:47.739253 28265 sgd_solver.cpp:106] Iteration 6500, lr = 0.000599197
I0823 10:47:52.265074 28265 solver.cpp:228] Iteration 6600, loss = 1.10468
I0823 10:47:52.265132 28265 solver.cpp:244]     Train net output #0: loss = 1.10468 (* 1 = 1.10468 loss)
I0823 10:47:52.265139 28265 sgd_solver.cpp:106] Iteration 6600, lr = 0.000597507
I0823 10:47:56.803138 28265 solver.cpp:228] Iteration 6700, loss = 1.10494
I0823 10:47:56.803197 28265 solver.cpp:244]     Train net output #0: loss = 1.10494 (* 1 = 1.10494 loss)
I0823 10:47:56.803205 28265 sgd_solver.cpp:106] Iteration 6700, lr = 0.000595828
I0823 10:48:01.332372 28265 solver.cpp:228] Iteration 6800, loss = 1.11008
I0823 10:48:01.332418 28265 solver.cpp:244]     Train net output #0: loss = 1.11008 (* 1 = 1.11008 loss)
I0823 10:48:01.332424 28265 sgd_solver.cpp:106] Iteration 6800, lr = 0.00059416
I0823 10:48:05.859268 28265 solver.cpp:228] Iteration 6900, loss = 1.10247
I0823 10:48:05.859326 28265 solver.cpp:244]     Train net output #0: loss = 1.10247 (* 1 = 1.10247 loss)
I0823 10:48:05.859333 28265 sgd_solver.cpp:106] Iteration 6900, lr = 0.000592502
I0823 10:48:10.363531 28265 solver.cpp:337] Iteration 7000, Testing net (#0)
I0823 10:48:13.812383 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0823 10:48:13.812435 28265 solver.cpp:404]     Test net output #1: loss = 1.10223 (* 1 = 1.10223 loss)
I0823 10:48:13.827255 28265 solver.cpp:228] Iteration 7000, loss = 1.10251
I0823 10:48:13.827299 28265 solver.cpp:244]     Train net output #0: loss = 1.10251 (* 1 = 1.10251 loss)
I0823 10:48:13.827312 28265 sgd_solver.cpp:106] Iteration 7000, lr = 0.000590856
I0823 10:48:18.349150 28265 solver.cpp:228] Iteration 7100, loss = 1.10725
I0823 10:48:18.349202 28265 solver.cpp:244]     Train net output #0: loss = 1.10725 (* 1 = 1.10725 loss)
I0823 10:48:18.349207 28265 sgd_solver.cpp:106] Iteration 7100, lr = 0.00058922
I0823 10:48:22.877765 28265 solver.cpp:228] Iteration 7200, loss = 1.09947
I0823 10:48:22.877810 28265 solver.cpp:244]     Train net output #0: loss = 1.09947 (* 1 = 1.09947 loss)
I0823 10:48:22.877815 28265 sgd_solver.cpp:106] Iteration 7200, lr = 0.000587594
I0823 10:48:27.408289 28265 solver.cpp:228] Iteration 7300, loss = 1.10054
I0823 10:48:27.408344 28265 solver.cpp:244]     Train net output #0: loss = 1.10054 (* 1 = 1.10054 loss)
I0823 10:48:27.408349 28265 sgd_solver.cpp:106] Iteration 7300, lr = 0.000585979
I0823 10:48:31.936540 28265 solver.cpp:228] Iteration 7400, loss = 1.10282
I0823 10:48:31.936585 28265 solver.cpp:244]     Train net output #0: loss = 1.10282 (* 1 = 1.10282 loss)
I0823 10:48:31.936590 28265 sgd_solver.cpp:106] Iteration 7400, lr = 0.000584375
I0823 10:48:36.415928 28265 solver.cpp:337] Iteration 7500, Testing net (#0)
I0823 10:48:40.120791 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578583
I0823 10:48:40.120852 28265 solver.cpp:404]     Test net output #1: loss = 1.09513 (* 1 = 1.09513 loss)
I0823 10:48:40.137006 28265 solver.cpp:228] Iteration 7500, loss = 1.09826
I0823 10:48:40.137038 28265 solver.cpp:244]     Train net output #0: loss = 1.09826 (* 1 = 1.09826 loss)
I0823 10:48:40.137053 28265 sgd_solver.cpp:106] Iteration 7500, lr = 0.00058278
I0823 10:48:44.666232 28265 solver.cpp:228] Iteration 7600, loss = 1.10539
I0823 10:48:44.666275 28265 solver.cpp:244]     Train net output #0: loss = 1.10539 (* 1 = 1.10539 loss)
I0823 10:48:44.666280 28265 sgd_solver.cpp:106] Iteration 7600, lr = 0.000581196
I0823 10:48:49.197492 28265 solver.cpp:228] Iteration 7700, loss = 1.09653
I0823 10:48:49.197536 28265 solver.cpp:244]     Train net output #0: loss = 1.09653 (* 1 = 1.09653 loss)
I0823 10:48:49.197541 28265 sgd_solver.cpp:106] Iteration 7700, lr = 0.000579621
I0823 10:48:53.726542 28265 solver.cpp:228] Iteration 7800, loss = 1.10778
I0823 10:48:53.726586 28265 solver.cpp:244]     Train net output #0: loss = 1.10778 (* 1 = 1.10778 loss)
I0823 10:48:53.726593 28265 sgd_solver.cpp:106] Iteration 7800, lr = 0.000578057
I0823 10:48:58.255878 28265 solver.cpp:228] Iteration 7900, loss = 1.10371
I0823 10:48:58.255959 28265 solver.cpp:244]     Train net output #0: loss = 1.10371 (* 1 = 1.10371 loss)
I0823 10:48:58.255972 28265 sgd_solver.cpp:106] Iteration 7900, lr = 0.000576502
I0823 10:49:02.740401 28265 solver.cpp:337] Iteration 8000, Testing net (#0)
I0823 10:49:06.113991 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0823 10:49:06.114059 28265 solver.cpp:404]     Test net output #1: loss = 1.0952 (* 1 = 1.0952 loss)
I0823 10:49:06.129436 28265 solver.cpp:228] Iteration 8000, loss = 1.09968
I0823 10:49:06.129463 28265 solver.cpp:244]     Train net output #0: loss = 1.09968 (* 1 = 1.09968 loss)
I0823 10:49:06.129475 28265 sgd_solver.cpp:106] Iteration 8000, lr = 0.000574957
I0823 10:49:10.659479 28265 solver.cpp:228] Iteration 8100, loss = 1.09515
I0823 10:49:10.659523 28265 solver.cpp:244]     Train net output #0: loss = 1.09515 (* 1 = 1.09515 loss)
I0823 10:49:10.659528 28265 sgd_solver.cpp:106] Iteration 8100, lr = 0.000573422
I0823 10:49:15.183977 28265 solver.cpp:228] Iteration 8200, loss = 1.09588
I0823 10:49:15.184032 28265 solver.cpp:244]     Train net output #0: loss = 1.09588 (* 1 = 1.09588 loss)
I0823 10:49:15.184039 28265 sgd_solver.cpp:106] Iteration 8200, lr = 0.000571896
I0823 10:49:19.721257 28265 solver.cpp:228] Iteration 8300, loss = 1.09948
I0823 10:49:19.721298 28265 solver.cpp:244]     Train net output #0: loss = 1.09948 (* 1 = 1.09948 loss)
I0823 10:49:19.721303 28265 sgd_solver.cpp:106] Iteration 8300, lr = 0.00057038
I0823 10:49:24.247654 28265 solver.cpp:228] Iteration 8400, loss = 1.09607
I0823 10:49:24.247699 28265 solver.cpp:244]     Train net output #0: loss = 1.09607 (* 1 = 1.09607 loss)
I0823 10:49:24.247705 28265 sgd_solver.cpp:106] Iteration 8400, lr = 0.000568873
I0823 10:49:28.731292 28265 solver.cpp:337] Iteration 8500, Testing net (#0)
I0823 10:49:29.681978 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:49:32.506431 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578083
I0823 10:49:32.506489 28265 solver.cpp:404]     Test net output #1: loss = 1.09595 (* 1 = 1.09595 loss)
I0823 10:49:32.521953 28265 solver.cpp:228] Iteration 8500, loss = 1.0976
I0823 10:49:32.521998 28265 solver.cpp:244]     Train net output #0: loss = 1.0976 (* 1 = 1.0976 loss)
I0823 10:49:32.522011 28265 sgd_solver.cpp:106] Iteration 8500, lr = 0.000567376
I0823 10:49:37.053916 28265 solver.cpp:228] Iteration 8600, loss = 1.10602
I0823 10:49:37.053962 28265 solver.cpp:244]     Train net output #0: loss = 1.10602 (* 1 = 1.10602 loss)
I0823 10:49:37.053968 28265 sgd_solver.cpp:106] Iteration 8600, lr = 0.000565887
I0823 10:49:41.585886 28265 solver.cpp:228] Iteration 8700, loss = 1.09626
I0823 10:49:41.585932 28265 solver.cpp:244]     Train net output #0: loss = 1.09626 (* 1 = 1.09626 loss)
I0823 10:49:41.585937 28265 sgd_solver.cpp:106] Iteration 8700, lr = 0.000564408
I0823 10:49:46.119735 28265 solver.cpp:228] Iteration 8800, loss = 1.09833
I0823 10:49:46.119781 28265 solver.cpp:244]     Train net output #0: loss = 1.09833 (* 1 = 1.09833 loss)
I0823 10:49:46.119786 28265 sgd_solver.cpp:106] Iteration 8800, lr = 0.000562937
I0823 10:49:50.645016 28265 solver.cpp:228] Iteration 8900, loss = 1.09825
I0823 10:49:50.645059 28265 solver.cpp:244]     Train net output #0: loss = 1.09825 (* 1 = 1.09825 loss)
I0823 10:49:50.645064 28265 sgd_solver.cpp:106] Iteration 8900, lr = 0.000561476
I0823 10:49:55.131525 28265 solver.cpp:337] Iteration 9000, Testing net (#0)
I0823 10:49:58.502889 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0823 10:49:58.502936 28265 solver.cpp:404]     Test net output #1: loss = 1.09742 (* 1 = 1.09742 loss)
I0823 10:49:58.518204 28265 solver.cpp:228] Iteration 9000, loss = 1.10577
I0823 10:49:58.518245 28265 solver.cpp:244]     Train net output #0: loss = 1.10577 (* 1 = 1.10577 loss)
I0823 10:49:58.518256 28265 sgd_solver.cpp:106] Iteration 9000, lr = 0.000560023
I0823 10:50:03.050612 28265 solver.cpp:228] Iteration 9100, loss = 1.09756
I0823 10:50:03.050652 28265 solver.cpp:244]     Train net output #0: loss = 1.09756 (* 1 = 1.09756 loss)
I0823 10:50:03.050657 28265 sgd_solver.cpp:106] Iteration 9100, lr = 0.000558579
I0823 10:50:07.570343 28265 solver.cpp:228] Iteration 9200, loss = 1.10272
I0823 10:50:07.570400 28265 solver.cpp:244]     Train net output #0: loss = 1.10272 (* 1 = 1.10272 loss)
I0823 10:50:07.570410 28265 sgd_solver.cpp:106] Iteration 9200, lr = 0.000557143
I0823 10:50:12.099880 28265 solver.cpp:228] Iteration 9300, loss = 1.0946
I0823 10:50:12.099925 28265 solver.cpp:244]     Train net output #0: loss = 1.0946 (* 1 = 1.0946 loss)
I0823 10:50:12.099930 28265 sgd_solver.cpp:106] Iteration 9300, lr = 0.000555717
I0823 10:50:16.623590 28265 solver.cpp:228] Iteration 9400, loss = 1.0943
I0823 10:50:16.623637 28265 solver.cpp:244]     Train net output #0: loss = 1.0943 (* 1 = 1.0943 loss)
I0823 10:50:16.623643 28265 sgd_solver.cpp:106] Iteration 9400, lr = 0.000554299
I0823 10:50:21.100414 28265 solver.cpp:337] Iteration 9500, Testing net (#0)
I0823 10:50:24.634765 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0823 10:50:24.634832 28265 solver.cpp:404]     Test net output #1: loss = 1.10049 (* 1 = 1.10049 loss)
I0823 10:50:24.650249 28265 solver.cpp:228] Iteration 9500, loss = 1.09664
I0823 10:50:24.650284 28265 solver.cpp:244]     Train net output #0: loss = 1.09664 (* 1 = 1.09664 loss)
I0823 10:50:24.650297 28265 sgd_solver.cpp:106] Iteration 9500, lr = 0.000552889
I0823 10:50:29.191507 28265 solver.cpp:228] Iteration 9600, loss = 1.10301
I0823 10:50:29.191555 28265 solver.cpp:244]     Train net output #0: loss = 1.10301 (* 1 = 1.10301 loss)
I0823 10:50:29.191560 28265 sgd_solver.cpp:106] Iteration 9600, lr = 0.000551487
I0823 10:50:33.723248 28265 solver.cpp:228] Iteration 9700, loss = 1.09556
I0823 10:50:33.723292 28265 solver.cpp:244]     Train net output #0: loss = 1.09556 (* 1 = 1.09556 loss)
I0823 10:50:33.723297 28265 sgd_solver.cpp:106] Iteration 9700, lr = 0.000550094
I0823 10:50:38.247740 28265 solver.cpp:228] Iteration 9800, loss = 1.10067
I0823 10:50:38.247761 28265 solver.cpp:244]     Train net output #0: loss = 1.10067 (* 1 = 1.10067 loss)
I0823 10:50:38.247766 28265 sgd_solver.cpp:106] Iteration 9800, lr = 0.000548709
I0823 10:50:42.771646 28265 solver.cpp:228] Iteration 9900, loss = 1.09791
I0823 10:50:42.771667 28265 solver.cpp:244]     Train net output #0: loss = 1.09791 (* 1 = 1.09791 loss)
I0823 10:50:42.771672 28265 sgd_solver.cpp:106] Iteration 9900, lr = 0.000547332
I0823 10:50:47.248458 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_10000.caffemodel
I0823 10:50:47.785370 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_10000.solverstate
I0823 10:50:47.942111 28265 solver.cpp:337] Iteration 10000, Testing net (#0)
I0823 10:50:51.577093 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:50:51.577162 28265 solver.cpp:404]     Test net output #1: loss = 1.10263 (* 1 = 1.10263 loss)
I0823 10:50:51.592715 28265 solver.cpp:228] Iteration 10000, loss = 1.09862
I0823 10:50:51.592751 28265 solver.cpp:244]     Train net output #0: loss = 1.09862 (* 1 = 1.09862 loss)
I0823 10:50:51.592764 28265 sgd_solver.cpp:106] Iteration 10000, lr = 0.000545963
I0823 10:50:56.121670 28265 solver.cpp:228] Iteration 10100, loss = 1.09807
I0823 10:50:56.121726 28265 solver.cpp:244]     Train net output #0: loss = 1.09807 (* 1 = 1.09807 loss)
I0823 10:50:56.121736 28265 sgd_solver.cpp:106] Iteration 10100, lr = 0.000544602
I0823 10:51:00.642493 28265 solver.cpp:228] Iteration 10200, loss = 1.10158
I0823 10:51:00.642529 28265 solver.cpp:244]     Train net output #0: loss = 1.10158 (* 1 = 1.10158 loss)
I0823 10:51:00.642534 28265 sgd_solver.cpp:106] Iteration 10200, lr = 0.000543249
I0823 10:51:05.164789 28265 solver.cpp:228] Iteration 10300, loss = 1.094
I0823 10:51:05.164809 28265 solver.cpp:244]     Train net output #0: loss = 1.094 (* 1 = 1.094 loss)
I0823 10:51:05.164813 28265 sgd_solver.cpp:106] Iteration 10300, lr = 0.000541904
I0823 10:51:09.687400 28265 solver.cpp:228] Iteration 10400, loss = 1.10642
I0823 10:51:09.687511 28265 solver.cpp:244]     Train net output #0: loss = 1.10642 (* 1 = 1.10642 loss)
I0823 10:51:09.687530 28265 sgd_solver.cpp:106] Iteration 10400, lr = 0.000540566
I0823 10:51:14.165280 28265 solver.cpp:337] Iteration 10500, Testing net (#0)
I0823 10:51:17.482507 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0823 10:51:17.482556 28265 solver.cpp:404]     Test net output #1: loss = 1.10392 (* 1 = 1.10392 loss)
I0823 10:51:17.498456 28265 solver.cpp:228] Iteration 10500, loss = 1.09892
I0823 10:51:17.498522 28265 solver.cpp:244]     Train net output #0: loss = 1.09892 (* 1 = 1.09892 loss)
I0823 10:51:17.498554 28265 sgd_solver.cpp:106] Iteration 10500, lr = 0.000539237
I0823 10:51:22.026726 28265 solver.cpp:228] Iteration 10600, loss = 1.09552
I0823 10:51:22.026787 28265 solver.cpp:244]     Train net output #0: loss = 1.09552 (* 1 = 1.09552 loss)
I0823 10:51:22.026801 28265 sgd_solver.cpp:106] Iteration 10600, lr = 0.000537914
I0823 10:51:26.552363 28265 solver.cpp:228] Iteration 10700, loss = 1.10171
I0823 10:51:26.552425 28265 solver.cpp:244]     Train net output #0: loss = 1.10171 (* 1 = 1.10171 loss)
I0823 10:51:26.552438 28265 sgd_solver.cpp:106] Iteration 10700, lr = 0.0005366
I0823 10:51:31.083673 28265 solver.cpp:228] Iteration 10800, loss = 1.10267
I0823 10:51:31.083727 28265 solver.cpp:244]     Train net output #0: loss = 1.10267 (* 1 = 1.10267 loss)
I0823 10:51:31.083734 28265 sgd_solver.cpp:106] Iteration 10800, lr = 0.000535293
I0823 10:51:35.612104 28265 solver.cpp:228] Iteration 10900, loss = 1.10415
I0823 10:51:35.612387 28265 solver.cpp:244]     Train net output #0: loss = 1.10415 (* 1 = 1.10415 loss)
I0823 10:51:35.612447 28265 sgd_solver.cpp:106] Iteration 10900, lr = 0.000533993
I0823 10:51:40.104333 28265 solver.cpp:337] Iteration 11000, Testing net (#0)
I0823 10:51:43.583158 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:51:43.583209 28265 solver.cpp:404]     Test net output #1: loss = 1.10483 (* 1 = 1.10483 loss)
I0823 10:51:43.600446 28265 solver.cpp:228] Iteration 11000, loss = 1.10302
I0823 10:51:43.600509 28265 solver.cpp:244]     Train net output #0: loss = 1.10302 (* 1 = 1.10302 loss)
I0823 10:51:43.600530 28265 sgd_solver.cpp:106] Iteration 11000, lr = 0.0005327
I0823 10:51:48.132761 28265 solver.cpp:228] Iteration 11100, loss = 1.09719
I0823 10:51:48.132820 28265 solver.cpp:244]     Train net output #0: loss = 1.09719 (* 1 = 1.09719 loss)
I0823 10:51:48.132827 28265 sgd_solver.cpp:106] Iteration 11100, lr = 0.000531415
I0823 10:51:51.709208 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:51:52.664836 28265 solver.cpp:228] Iteration 11200, loss = 1.10248
I0823 10:51:52.664897 28265 solver.cpp:244]     Train net output #0: loss = 1.10248 (* 1 = 1.10248 loss)
I0823 10:51:52.664906 28265 sgd_solver.cpp:106] Iteration 11200, lr = 0.000530137
I0823 10:51:57.199482 28265 solver.cpp:228] Iteration 11300, loss = 1.10122
I0823 10:51:57.199542 28265 solver.cpp:244]     Train net output #0: loss = 1.10122 (* 1 = 1.10122 loss)
I0823 10:51:57.199548 28265 sgd_solver.cpp:106] Iteration 11300, lr = 0.000528866
I0823 10:52:01.724421 28265 solver.cpp:228] Iteration 11400, loss = 1.09178
I0823 10:52:01.724483 28265 solver.cpp:244]     Train net output #0: loss = 1.09178 (* 1 = 1.09178 loss)
I0823 10:52:01.724493 28265 sgd_solver.cpp:106] Iteration 11400, lr = 0.000527603
I0823 10:52:06.209556 28265 solver.cpp:337] Iteration 11500, Testing net (#0)
I0823 10:52:09.831624 28265 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0823 10:52:09.831681 28265 solver.cpp:404]     Test net output #1: loss = 1.10223 (* 1 = 1.10223 loss)
I0823 10:52:09.847004 28265 solver.cpp:228] Iteration 11500, loss = 1.09895
I0823 10:52:09.847041 28265 solver.cpp:244]     Train net output #0: loss = 1.09895 (* 1 = 1.09895 loss)
I0823 10:52:09.847054 28265 sgd_solver.cpp:106] Iteration 11500, lr = 0.000526346
I0823 10:52:14.374164 28265 solver.cpp:228] Iteration 11600, loss = 1.09929
I0823 10:52:14.374208 28265 solver.cpp:244]     Train net output #0: loss = 1.09929 (* 1 = 1.09929 loss)
I0823 10:52:14.374214 28265 sgd_solver.cpp:106] Iteration 11600, lr = 0.000525096
I0823 10:52:18.908023 28265 solver.cpp:228] Iteration 11700, loss = 1.09962
I0823 10:52:18.908066 28265 solver.cpp:244]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0823 10:52:18.908071 28265 sgd_solver.cpp:106] Iteration 11700, lr = 0.000523853
I0823 10:52:23.432356 28265 solver.cpp:228] Iteration 11800, loss = 1.09559
I0823 10:52:23.432379 28265 solver.cpp:244]     Train net output #0: loss = 1.09559 (* 1 = 1.09559 loss)
I0823 10:52:23.432384 28265 sgd_solver.cpp:106] Iteration 11800, lr = 0.000522617
I0823 10:52:27.961498 28265 solver.cpp:228] Iteration 11900, loss = 1.10664
I0823 10:52:27.961544 28265 solver.cpp:244]     Train net output #0: loss = 1.10664 (* 1 = 1.10664 loss)
I0823 10:52:27.961549 28265 sgd_solver.cpp:106] Iteration 11900, lr = 0.000521388
I0823 10:52:32.444751 28265 solver.cpp:337] Iteration 12000, Testing net (#0)
I0823 10:52:35.782902 28265 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0823 10:52:35.782950 28265 solver.cpp:404]     Test net output #1: loss = 1.09609 (* 1 = 1.09609 loss)
I0823 10:52:35.798744 28265 solver.cpp:228] Iteration 12000, loss = 1.10034
I0823 10:52:35.798800 28265 solver.cpp:244]     Train net output #0: loss = 1.10034 (* 1 = 1.10034 loss)
I0823 10:52:35.798815 28265 sgd_solver.cpp:106] Iteration 12000, lr = 0.000520166
I0823 10:52:40.330638 28265 solver.cpp:228] Iteration 12100, loss = 1.09947
I0823 10:52:40.330682 28265 solver.cpp:244]     Train net output #0: loss = 1.09947 (* 1 = 1.09947 loss)
I0823 10:52:40.330687 28265 sgd_solver.cpp:106] Iteration 12100, lr = 0.00051895
I0823 10:52:44.857126 28265 solver.cpp:228] Iteration 12200, loss = 1.09226
I0823 10:52:44.857169 28265 solver.cpp:244]     Train net output #0: loss = 1.09226 (* 1 = 1.09226 loss)
I0823 10:52:44.857174 28265 sgd_solver.cpp:106] Iteration 12200, lr = 0.000517741
I0823 10:52:49.379833 28265 solver.cpp:228] Iteration 12300, loss = 1.09712
I0823 10:52:49.379878 28265 solver.cpp:244]     Train net output #0: loss = 1.09712 (* 1 = 1.09712 loss)
I0823 10:52:49.379883 28265 sgd_solver.cpp:106] Iteration 12300, lr = 0.000516538
I0823 10:52:53.904147 28265 solver.cpp:228] Iteration 12400, loss = 1.09798
I0823 10:52:53.904168 28265 solver.cpp:244]     Train net output #0: loss = 1.09798 (* 1 = 1.09798 loss)
I0823 10:52:53.904172 28265 sgd_solver.cpp:106] Iteration 12400, lr = 0.000515342
I0823 10:52:58.387851 28265 solver.cpp:337] Iteration 12500, Testing net (#0)
I0823 10:53:01.757931 28265 solver.cpp:404]     Test net output #0: accuracy = 0.269375
I0823 10:53:01.758024 28265 solver.cpp:404]     Test net output #1: loss = 1.09357 (* 1 = 1.09357 loss)
I0823 10:53:01.774034 28265 solver.cpp:228] Iteration 12500, loss = 1.09877
I0823 10:53:01.774092 28265 solver.cpp:244]     Train net output #0: loss = 1.09877 (* 1 = 1.09877 loss)
I0823 10:53:01.774108 28265 sgd_solver.cpp:106] Iteration 12500, lr = 0.000514152
I0823 10:53:06.302520 28265 solver.cpp:228] Iteration 12600, loss = 1.0974
I0823 10:53:06.302567 28265 solver.cpp:244]     Train net output #0: loss = 1.0974 (* 1 = 1.0974 loss)
I0823 10:53:06.302572 28265 sgd_solver.cpp:106] Iteration 12600, lr = 0.000512969
I0823 10:53:10.823884 28265 solver.cpp:228] Iteration 12700, loss = 1.0941
I0823 10:53:10.823905 28265 solver.cpp:244]     Train net output #0: loss = 1.0941 (* 1 = 1.0941 loss)
I0823 10:53:10.823909 28265 sgd_solver.cpp:106] Iteration 12700, lr = 0.000511792
I0823 10:53:15.345427 28265 solver.cpp:228] Iteration 12800, loss = 1.0963
I0823 10:53:15.345473 28265 solver.cpp:244]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0823 10:53:15.345477 28265 sgd_solver.cpp:106] Iteration 12800, lr = 0.000510621
I0823 10:53:19.876571 28265 solver.cpp:228] Iteration 12900, loss = 1.10339
I0823 10:53:19.876616 28265 solver.cpp:244]     Train net output #0: loss = 1.10339 (* 1 = 1.10339 loss)
I0823 10:53:19.876622 28265 sgd_solver.cpp:106] Iteration 12900, lr = 0.000509457
I0823 10:53:24.371834 28265 solver.cpp:337] Iteration 13000, Testing net (#0)
I0823 10:53:27.992007 28265 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0823 10:53:27.992070 28265 solver.cpp:404]     Test net output #1: loss = 1.09104 (* 1 = 1.09104 loss)
I0823 10:53:28.007738 28265 solver.cpp:228] Iteration 13000, loss = 1.10142
I0823 10:53:28.007797 28265 solver.cpp:244]     Train net output #0: loss = 1.10142 (* 1 = 1.10142 loss)
I0823 10:53:28.007812 28265 sgd_solver.cpp:106] Iteration 13000, lr = 0.000508298
I0823 10:53:32.540838 28265 solver.cpp:228] Iteration 13100, loss = 1.10466
I0823 10:53:32.540886 28265 solver.cpp:244]     Train net output #0: loss = 1.10466 (* 1 = 1.10466 loss)
I0823 10:53:32.540891 28265 sgd_solver.cpp:106] Iteration 13100, lr = 0.000507146
I0823 10:53:37.081365 28265 solver.cpp:228] Iteration 13200, loss = 1.09402
I0823 10:53:37.081413 28265 solver.cpp:244]     Train net output #0: loss = 1.09402 (* 1 = 1.09402 loss)
I0823 10:53:37.081418 28265 sgd_solver.cpp:106] Iteration 13200, lr = 0.000506
I0823 10:53:41.620278 28265 solver.cpp:228] Iteration 13300, loss = 1.09495
I0823 10:53:41.620335 28265 solver.cpp:244]     Train net output #0: loss = 1.09495 (* 1 = 1.09495 loss)
I0823 10:53:41.620342 28265 sgd_solver.cpp:106] Iteration 13300, lr = 0.00050486
I0823 10:53:46.146697 28265 solver.cpp:228] Iteration 13400, loss = 1.09516
I0823 10:53:46.146741 28265 solver.cpp:244]     Train net output #0: loss = 1.09516 (* 1 = 1.09516 loss)
I0823 10:53:46.146746 28265 sgd_solver.cpp:106] Iteration 13400, lr = 0.000503726
I0823 10:53:50.626107 28265 solver.cpp:337] Iteration 13500, Testing net (#0)
I0823 10:53:54.008947 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0823 10:53:54.009011 28265 solver.cpp:404]     Test net output #1: loss = 1.08854 (* 1 = 1.08854 loss)
I0823 10:53:54.024933 28265 solver.cpp:228] Iteration 13500, loss = 1.1016
I0823 10:53:54.025005 28265 solver.cpp:244]     Train net output #0: loss = 1.1016 (* 1 = 1.1016 loss)
I0823 10:53:54.025020 28265 sgd_solver.cpp:106] Iteration 13500, lr = 0.000502598
I0823 10:53:58.552970 28265 solver.cpp:228] Iteration 13600, loss = 1.096
I0823 10:53:58.553015 28265 solver.cpp:244]     Train net output #0: loss = 1.096 (* 1 = 1.096 loss)
I0823 10:53:58.553020 28265 sgd_solver.cpp:106] Iteration 13600, lr = 0.000501476
I0823 10:54:03.084728 28265 solver.cpp:228] Iteration 13700, loss = 1.09432
I0823 10:54:03.084770 28265 solver.cpp:244]     Train net output #0: loss = 1.09432 (* 1 = 1.09432 loss)
I0823 10:54:03.084775 28265 sgd_solver.cpp:106] Iteration 13700, lr = 0.000500359
I0823 10:54:07.615569 28265 solver.cpp:228] Iteration 13800, loss = 1.09382
I0823 10:54:07.615592 28265 solver.cpp:244]     Train net output #0: loss = 1.09382 (* 1 = 1.09382 loss)
I0823 10:54:07.615597 28265 sgd_solver.cpp:106] Iteration 13800, lr = 0.000499248
I0823 10:54:12.140483 28265 solver.cpp:228] Iteration 13900, loss = 1.09899
I0823 10:54:12.140530 28265 solver.cpp:244]     Train net output #0: loss = 1.09899 (* 1 = 1.09899 loss)
I0823 10:54:12.140535 28265 sgd_solver.cpp:106] Iteration 13900, lr = 0.000498143
I0823 10:54:16.622711 28265 solver.cpp:337] Iteration 14000, Testing net (#0)
I0823 10:54:18.334080 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:54:20.220196 28265 solver.cpp:404]     Test net output #0: accuracy = 0.575083
I0823 10:54:20.220269 28265 solver.cpp:404]     Test net output #1: loss = 1.09142 (* 1 = 1.09142 loss)
I0823 10:54:20.236210 28265 solver.cpp:228] Iteration 14000, loss = 1.09422
I0823 10:54:20.236273 28265 solver.cpp:244]     Train net output #0: loss = 1.09422 (* 1 = 1.09422 loss)
I0823 10:54:20.236292 28265 sgd_solver.cpp:106] Iteration 14000, lr = 0.000497044
I0823 10:54:24.765841 28265 solver.cpp:228] Iteration 14100, loss = 1.10697
I0823 10:54:24.765966 28265 solver.cpp:244]     Train net output #0: loss = 1.10697 (* 1 = 1.10697 loss)
I0823 10:54:24.765986 28265 sgd_solver.cpp:106] Iteration 14100, lr = 0.000495951
I0823 10:54:29.290933 28265 solver.cpp:228] Iteration 14200, loss = 1.10624
I0823 10:54:29.290988 28265 solver.cpp:244]     Train net output #0: loss = 1.10624 (* 1 = 1.10624 loss)
I0823 10:54:29.290995 28265 sgd_solver.cpp:106] Iteration 14200, lr = 0.000494863
I0823 10:54:33.822067 28265 solver.cpp:228] Iteration 14300, loss = 1.10295
I0823 10:54:33.822176 28265 solver.cpp:244]     Train net output #0: loss = 1.10295 (* 1 = 1.10295 loss)
I0823 10:54:33.822192 28265 sgd_solver.cpp:106] Iteration 14300, lr = 0.00049378
I0823 10:54:38.358870 28265 solver.cpp:228] Iteration 14400, loss = 1.09589
I0823 10:54:38.358913 28265 solver.cpp:244]     Train net output #0: loss = 1.09589 (* 1 = 1.09589 loss)
I0823 10:54:38.358919 28265 sgd_solver.cpp:106] Iteration 14400, lr = 0.000492703
I0823 10:54:42.835499 28265 solver.cpp:337] Iteration 14500, Testing net (#0)
I0823 10:54:46.250694 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578209
I0823 10:54:46.250743 28265 solver.cpp:404]     Test net output #1: loss = 1.09123 (* 1 = 1.09123 loss)
I0823 10:54:46.266599 28265 solver.cpp:228] Iteration 14500, loss = 1.09824
I0823 10:54:46.266669 28265 solver.cpp:244]     Train net output #0: loss = 1.09824 (* 1 = 1.09824 loss)
I0823 10:54:46.266687 28265 sgd_solver.cpp:106] Iteration 14500, lr = 0.000491632
I0823 10:54:50.796707 28265 solver.cpp:228] Iteration 14600, loss = 1.10062
I0823 10:54:50.796762 28265 solver.cpp:244]     Train net output #0: loss = 1.10062 (* 1 = 1.10062 loss)
I0823 10:54:50.796772 28265 sgd_solver.cpp:106] Iteration 14600, lr = 0.000490566
I0823 10:54:55.321987 28265 solver.cpp:228] Iteration 14700, loss = 1.10488
I0823 10:54:55.322010 28265 solver.cpp:244]     Train net output #0: loss = 1.10488 (* 1 = 1.10488 loss)
I0823 10:54:55.322013 28265 sgd_solver.cpp:106] Iteration 14700, lr = 0.000489505
I0823 10:54:59.852254 28265 solver.cpp:228] Iteration 14800, loss = 1.09486
I0823 10:54:59.852311 28265 solver.cpp:244]     Train net output #0: loss = 1.09486 (* 1 = 1.09486 loss)
I0823 10:54:59.852318 28265 sgd_solver.cpp:106] Iteration 14800, lr = 0.00048845
I0823 10:55:04.376647 28265 solver.cpp:228] Iteration 14900, loss = 1.10218
I0823 10:55:04.376713 28265 solver.cpp:244]     Train net output #0: loss = 1.10218 (* 1 = 1.10218 loss)
I0823 10:55:04.376718 28265 sgd_solver.cpp:106] Iteration 14900, lr = 0.0004874
I0823 10:55:08.859196 28265 solver.cpp:337] Iteration 15000, Testing net (#0)
I0823 10:55:12.286388 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578541
I0823 10:55:12.286466 28265 solver.cpp:404]     Test net output #1: loss = 1.09094 (* 1 = 1.09094 loss)
I0823 10:55:12.301652 28265 solver.cpp:228] Iteration 15000, loss = 1.09772
I0823 10:55:12.301683 28265 solver.cpp:244]     Train net output #0: loss = 1.09772 (* 1 = 1.09772 loss)
I0823 10:55:12.301692 28265 sgd_solver.cpp:106] Iteration 15000, lr = 0.000486355
I0823 10:55:16.828807 28265 solver.cpp:228] Iteration 15100, loss = 1.09647
I0823 10:55:16.828866 28265 solver.cpp:244]     Train net output #0: loss = 1.09647 (* 1 = 1.09647 loss)
I0823 10:55:16.828876 28265 sgd_solver.cpp:106] Iteration 15100, lr = 0.000485315
I0823 10:55:21.351238 28265 solver.cpp:228] Iteration 15200, loss = 1.09814
I0823 10:55:21.351313 28265 solver.cpp:244]     Train net output #0: loss = 1.09814 (* 1 = 1.09814 loss)
I0823 10:55:21.351326 28265 sgd_solver.cpp:106] Iteration 15200, lr = 0.000484281
I0823 10:55:25.879020 28265 solver.cpp:228] Iteration 15300, loss = 1.0997
I0823 10:55:25.879065 28265 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0823 10:55:25.879070 28265 sgd_solver.cpp:106] Iteration 15300, lr = 0.000483251
I0823 10:55:30.405875 28265 solver.cpp:228] Iteration 15400, loss = 1.09579
I0823 10:55:30.405897 28265 solver.cpp:244]     Train net output #0: loss = 1.09579 (* 1 = 1.09579 loss)
I0823 10:55:30.405901 28265 sgd_solver.cpp:106] Iteration 15400, lr = 0.000482227
I0823 10:55:34.892933 28265 solver.cpp:337] Iteration 15500, Testing net (#0)
I0823 10:55:38.045343 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0823 10:55:38.045436 28265 solver.cpp:404]     Test net output #1: loss = 1.08964 (* 1 = 1.08964 loss)
I0823 10:55:38.060863 28265 solver.cpp:228] Iteration 15500, loss = 1.09919
I0823 10:55:38.060904 28265 solver.cpp:244]     Train net output #0: loss = 1.09919 (* 1 = 1.09919 loss)
I0823 10:55:38.060912 28265 sgd_solver.cpp:106] Iteration 15500, lr = 0.000481208
I0823 10:55:42.587234 28265 solver.cpp:228] Iteration 15600, loss = 1.09713
I0823 10:55:42.587280 28265 solver.cpp:244]     Train net output #0: loss = 1.09713 (* 1 = 1.09713 loss)
I0823 10:55:42.587285 28265 sgd_solver.cpp:106] Iteration 15600, lr = 0.000480194
I0823 10:55:47.109221 28265 solver.cpp:228] Iteration 15700, loss = 1.09776
I0823 10:55:47.109277 28265 solver.cpp:244]     Train net output #0: loss = 1.09776 (* 1 = 1.09776 loss)
I0823 10:55:47.109285 28265 sgd_solver.cpp:106] Iteration 15700, lr = 0.000479185
I0823 10:55:51.644546 28265 solver.cpp:228] Iteration 15800, loss = 1.1007
I0823 10:55:51.644605 28265 solver.cpp:244]     Train net output #0: loss = 1.1007 (* 1 = 1.1007 loss)
I0823 10:55:51.644613 28265 sgd_solver.cpp:106] Iteration 15800, lr = 0.000478181
I0823 10:55:56.167881 28265 solver.cpp:228] Iteration 15900, loss = 1.09522
I0823 10:55:56.167953 28265 solver.cpp:244]     Train net output #0: loss = 1.09522 (* 1 = 1.09522 loss)
I0823 10:55:56.167959 28265 sgd_solver.cpp:106] Iteration 15900, lr = 0.000477181
I0823 10:56:00.647279 28265 solver.cpp:337] Iteration 16000, Testing net (#0)
I0823 10:56:03.776013 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0823 10:56:03.776129 28265 solver.cpp:404]     Test net output #1: loss = 1.09107 (* 1 = 1.09107 loss)
I0823 10:56:03.792088 28265 solver.cpp:228] Iteration 16000, loss = 1.09372
I0823 10:56:03.792158 28265 solver.cpp:244]     Train net output #0: loss = 1.09372 (* 1 = 1.09372 loss)
I0823 10:56:03.792174 28265 sgd_solver.cpp:106] Iteration 16000, lr = 0.000476187
I0823 10:56:08.321913 28265 solver.cpp:228] Iteration 16100, loss = 1.09979
I0823 10:56:08.321955 28265 solver.cpp:244]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0823 10:56:08.321960 28265 sgd_solver.cpp:106] Iteration 16100, lr = 0.000475197
I0823 10:56:12.852957 28265 solver.cpp:228] Iteration 16200, loss = 1.09382
I0823 10:56:12.852999 28265 solver.cpp:244]     Train net output #0: loss = 1.09382 (* 1 = 1.09382 loss)
I0823 10:56:12.853004 28265 sgd_solver.cpp:106] Iteration 16200, lr = 0.000474212
I0823 10:56:17.383131 28265 solver.cpp:228] Iteration 16300, loss = 1.09698
I0823 10:56:17.383180 28265 solver.cpp:244]     Train net output #0: loss = 1.09698 (* 1 = 1.09698 loss)
I0823 10:56:17.383186 28265 sgd_solver.cpp:106] Iteration 16300, lr = 0.000473232
I0823 10:56:21.908645 28265 solver.cpp:228] Iteration 16400, loss = 1.09797
I0823 10:56:21.908689 28265 solver.cpp:244]     Train net output #0: loss = 1.09797 (* 1 = 1.09797 loss)
I0823 10:56:21.908694 28265 sgd_solver.cpp:106] Iteration 16400, lr = 0.000472257
I0823 10:56:26.398170 28265 solver.cpp:337] Iteration 16500, Testing net (#0)
I0823 10:56:29.620156 28265 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0823 10:56:29.620203 28265 solver.cpp:404]     Test net output #1: loss = 1.09078 (* 1 = 1.09078 loss)
I0823 10:56:29.635406 28265 solver.cpp:228] Iteration 16500, loss = 1.0973
I0823 10:56:29.635424 28265 solver.cpp:244]     Train net output #0: loss = 1.0973 (* 1 = 1.0973 loss)
I0823 10:56:29.635434 28265 sgd_solver.cpp:106] Iteration 16500, lr = 0.000471286
I0823 10:56:34.158763 28265 solver.cpp:228] Iteration 16600, loss = 1.1
I0823 10:56:34.158784 28265 solver.cpp:244]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0823 10:56:34.158789 28265 sgd_solver.cpp:106] Iteration 16600, lr = 0.00047032
I0823 10:56:38.690973 28265 solver.cpp:228] Iteration 16700, loss = 1.09223
I0823 10:56:38.691016 28265 solver.cpp:244]     Train net output #0: loss = 1.09223 (* 1 = 1.09223 loss)
I0823 10:56:38.691022 28265 sgd_solver.cpp:106] Iteration 16700, lr = 0.000469358
I0823 10:56:43.231748 28265 solver.cpp:228] Iteration 16800, loss = 1.09293
I0823 10:56:43.231792 28265 solver.cpp:244]     Train net output #0: loss = 1.09293 (* 1 = 1.09293 loss)
I0823 10:56:43.231798 28265 sgd_solver.cpp:106] Iteration 16800, lr = 0.000468402
I0823 10:56:47.766290 28265 solver.cpp:228] Iteration 16900, loss = 1.09254
I0823 10:56:47.766337 28265 solver.cpp:244]     Train net output #0: loss = 1.09254 (* 1 = 1.09254 loss)
I0823 10:56:47.766342 28265 sgd_solver.cpp:106] Iteration 16900, lr = 0.000467449
I0823 10:56:52.250036 28265 solver.cpp:337] Iteration 17000, Testing net (#0)
I0823 10:56:55.814911 28265 solver.cpp:404]     Test net output #0: accuracy = 0.556042
I0823 10:56:55.814982 28265 solver.cpp:404]     Test net output #1: loss = 1.08932 (* 1 = 1.08932 loss)
I0823 10:56:55.830912 28265 solver.cpp:228] Iteration 17000, loss = 1.09302
I0823 10:56:55.830987 28265 solver.cpp:244]     Train net output #0: loss = 1.09302 (* 1 = 1.09302 loss)
I0823 10:56:55.831008 28265 sgd_solver.cpp:106] Iteration 17000, lr = 0.000466501
I0823 10:57:00.355826 28265 solver.cpp:228] Iteration 17100, loss = 1.09921
I0823 10:57:00.355883 28265 solver.cpp:244]     Train net output #0: loss = 1.09921 (* 1 = 1.09921 loss)
I0823 10:57:00.355890 28265 sgd_solver.cpp:106] Iteration 17100, lr = 0.000465558
I0823 10:57:04.895368 28265 solver.cpp:228] Iteration 17200, loss = 1.09198
I0823 10:57:04.895424 28265 solver.cpp:244]     Train net output #0: loss = 1.09198 (* 1 = 1.09198 loss)
I0823 10:57:04.895431 28265 sgd_solver.cpp:106] Iteration 17200, lr = 0.000464619
I0823 10:57:09.423212 28265 solver.cpp:228] Iteration 17300, loss = 1.0913
I0823 10:57:09.423256 28265 solver.cpp:244]     Train net output #0: loss = 1.0913 (* 1 = 1.0913 loss)
I0823 10:57:09.423261 28265 sgd_solver.cpp:106] Iteration 17300, lr = 0.000463684
I0823 10:57:13.949149 28265 solver.cpp:228] Iteration 17400, loss = 1.09725
I0823 10:57:13.949215 28265 solver.cpp:244]     Train net output #0: loss = 1.09725 (* 1 = 1.09725 loss)
I0823 10:57:13.949223 28265 sgd_solver.cpp:106] Iteration 17400, lr = 0.000462754
I0823 10:57:18.423873 28265 solver.cpp:337] Iteration 17500, Testing net (#0)
I0823 10:57:21.986232 28265 solver.cpp:404]     Test net output #0: accuracy = 0.541792
I0823 10:57:21.986279 28265 solver.cpp:404]     Test net output #1: loss = 1.08258 (* 1 = 1.08258 loss)
I0823 10:57:22.001572 28265 solver.cpp:228] Iteration 17500, loss = 1.091
I0823 10:57:22.001607 28265 solver.cpp:244]     Train net output #0: loss = 1.091 (* 1 = 1.091 loss)
I0823 10:57:22.001618 28265 sgd_solver.cpp:106] Iteration 17500, lr = 0.000461829
I0823 10:57:26.537283 28265 solver.cpp:228] Iteration 17600, loss = 1.0885
I0823 10:57:26.537331 28265 solver.cpp:244]     Train net output #0: loss = 1.0885 (* 1 = 1.0885 loss)
I0823 10:57:26.537339 28265 sgd_solver.cpp:106] Iteration 17600, lr = 0.000460907
I0823 10:57:31.074116 28265 solver.cpp:228] Iteration 17700, loss = 1.0801
I0823 10:57:31.074158 28265 solver.cpp:244]     Train net output #0: loss = 1.0801 (* 1 = 1.0801 loss)
I0823 10:57:31.074164 28265 sgd_solver.cpp:106] Iteration 17700, lr = 0.00045999
I0823 10:57:35.601814 28265 solver.cpp:228] Iteration 17800, loss = 1.07663
I0823 10:57:35.601858 28265 solver.cpp:244]     Train net output #0: loss = 1.07663 (* 1 = 1.07663 loss)
I0823 10:57:35.601864 28265 sgd_solver.cpp:106] Iteration 17800, lr = 0.000459077
I0823 10:57:40.139366 28265 solver.cpp:228] Iteration 17900, loss = 1.05987
I0823 10:57:40.139408 28265 solver.cpp:244]     Train net output #0: loss = 1.05987 (* 1 = 1.05987 loss)
I0823 10:57:40.139415 28265 sgd_solver.cpp:106] Iteration 17900, lr = 0.000458168
I0823 10:57:44.619199 28265 solver.cpp:337] Iteration 18000, Testing net (#0)
I0823 10:57:46.458175 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 10:57:48.159036 28265 solver.cpp:404]     Test net output #0: accuracy = 0.528667
I0823 10:57:48.159088 28265 solver.cpp:404]     Test net output #1: loss = 1.0492 (* 1 = 1.0492 loss)
I0823 10:57:48.175037 28265 solver.cpp:228] Iteration 18000, loss = 1.06202
I0823 10:57:48.175083 28265 solver.cpp:244]     Train net output #0: loss = 1.06202 (* 1 = 1.06202 loss)
I0823 10:57:48.175102 28265 sgd_solver.cpp:106] Iteration 18000, lr = 0.000457263
I0823 10:57:52.702553 28265 solver.cpp:228] Iteration 18100, loss = 1.05259
I0823 10:57:52.702595 28265 solver.cpp:244]     Train net output #0: loss = 1.05259 (* 1 = 1.05259 loss)
I0823 10:57:52.702600 28265 sgd_solver.cpp:106] Iteration 18100, lr = 0.000456363
I0823 10:57:57.234299 28265 solver.cpp:228] Iteration 18200, loss = 1.03239
I0823 10:57:57.234343 28265 solver.cpp:244]     Train net output #0: loss = 1.03239 (* 1 = 1.03239 loss)
I0823 10:57:57.234347 28265 sgd_solver.cpp:106] Iteration 18200, lr = 0.000455467
I0823 10:58:01.762086 28265 solver.cpp:228] Iteration 18300, loss = 1.02294
I0823 10:58:01.762127 28265 solver.cpp:244]     Train net output #0: loss = 1.02294 (* 1 = 1.02294 loss)
I0823 10:58:01.762132 28265 sgd_solver.cpp:106] Iteration 18300, lr = 0.000454575
I0823 10:58:06.289122 28265 solver.cpp:228] Iteration 18400, loss = 0.992855
I0823 10:58:06.289170 28265 solver.cpp:244]     Train net output #0: loss = 0.992855 (* 1 = 0.992855 loss)
I0823 10:58:06.289175 28265 sgd_solver.cpp:106] Iteration 18400, lr = 0.000453686
I0823 10:58:10.782171 28265 solver.cpp:337] Iteration 18500, Testing net (#0)
I0823 10:58:14.447312 28265 solver.cpp:404]     Test net output #0: accuracy = 0.489917
I0823 10:58:14.447372 28265 solver.cpp:404]     Test net output #1: loss = 0.990259 (* 1 = 0.990259 loss)
I0823 10:58:14.463028 28265 solver.cpp:228] Iteration 18500, loss = 1.02158
I0823 10:58:14.463074 28265 solver.cpp:244]     Train net output #0: loss = 1.02158 (* 1 = 1.02158 loss)
I0823 10:58:14.463088 28265 sgd_solver.cpp:106] Iteration 18500, lr = 0.000452802
I0823 10:58:18.995370 28265 solver.cpp:228] Iteration 18600, loss = 0.99745
I0823 10:58:18.995414 28265 solver.cpp:244]     Train net output #0: loss = 0.99745 (* 1 = 0.99745 loss)
I0823 10:58:18.995419 28265 sgd_solver.cpp:106] Iteration 18600, lr = 0.000451922
I0823 10:58:23.517664 28265 solver.cpp:228] Iteration 18700, loss = 1.0343
I0823 10:58:23.517724 28265 solver.cpp:244]     Train net output #0: loss = 1.0343 (* 1 = 1.0343 loss)
I0823 10:58:23.517731 28265 sgd_solver.cpp:106] Iteration 18700, lr = 0.000451046
I0823 10:58:28.043105 28265 solver.cpp:228] Iteration 18800, loss = 1.05039
I0823 10:58:28.043164 28265 solver.cpp:244]     Train net output #0: loss = 1.05039 (* 1 = 1.05039 loss)
I0823 10:58:28.043174 28265 sgd_solver.cpp:106] Iteration 18800, lr = 0.000450174
I0823 10:58:32.566105 28265 solver.cpp:228] Iteration 18900, loss = 1.00519
I0823 10:58:32.566124 28265 solver.cpp:244]     Train net output #0: loss = 1.00519 (* 1 = 1.00519 loss)
I0823 10:58:32.566128 28265 sgd_solver.cpp:106] Iteration 18900, lr = 0.000449306
I0823 10:58:37.041772 28265 solver.cpp:337] Iteration 19000, Testing net (#0)
I0823 10:58:40.465868 28265 solver.cpp:404]     Test net output #0: accuracy = 0.493667
I0823 10:58:40.465936 28265 solver.cpp:404]     Test net output #1: loss = 0.961382 (* 1 = 0.961382 loss)
I0823 10:58:40.480588 28265 solver.cpp:228] Iteration 19000, loss = 0.998566
I0823 10:58:40.480645 28265 solver.cpp:244]     Train net output #0: loss = 0.998566 (* 1 = 0.998566 loss)
I0823 10:58:40.480659 28265 sgd_solver.cpp:106] Iteration 19000, lr = 0.000448441
I0823 10:58:45.004916 28265 solver.cpp:228] Iteration 19100, loss = 1.00769
I0823 10:58:45.004986 28265 solver.cpp:244]     Train net output #0: loss = 1.00769 (* 1 = 1.00769 loss)
I0823 10:58:45.004997 28265 sgd_solver.cpp:106] Iteration 19100, lr = 0.000447581
I0823 10:58:49.525961 28265 solver.cpp:228] Iteration 19200, loss = 0.918335
I0823 10:58:49.525988 28265 solver.cpp:244]     Train net output #0: loss = 0.918335 (* 1 = 0.918335 loss)
I0823 10:58:49.525993 28265 sgd_solver.cpp:106] Iteration 19200, lr = 0.000446724
I0823 10:58:54.047174 28265 solver.cpp:228] Iteration 19300, loss = 0.917437
I0823 10:58:54.047229 28265 solver.cpp:244]     Train net output #0: loss = 0.917437 (* 1 = 0.917437 loss)
I0823 10:58:54.047240 28265 sgd_solver.cpp:106] Iteration 19300, lr = 0.000445872
I0823 10:58:58.576303 28265 solver.cpp:228] Iteration 19400, loss = 0.906105
I0823 10:58:58.576354 28265 solver.cpp:244]     Train net output #0: loss = 0.906105 (* 1 = 0.906105 loss)
I0823 10:58:58.576359 28265 sgd_solver.cpp:106] Iteration 19400, lr = 0.000445023
I0823 10:59:03.065578 28265 solver.cpp:337] Iteration 19500, Testing net (#0)
I0823 10:59:06.239531 28265 solver.cpp:404]     Test net output #0: accuracy = 0.560708
I0823 10:59:06.239615 28265 solver.cpp:404]     Test net output #1: loss = 0.859985 (* 1 = 0.859985 loss)
I0823 10:59:06.255548 28265 solver.cpp:228] Iteration 19500, loss = 0.867557
I0823 10:59:06.255610 28265 solver.cpp:244]     Train net output #0: loss = 0.867557 (* 1 = 0.867557 loss)
I0823 10:59:06.255628 28265 sgd_solver.cpp:106] Iteration 19500, lr = 0.000444177
I0823 10:59:10.785682 28265 solver.cpp:228] Iteration 19600, loss = 0.843689
I0823 10:59:10.785727 28265 solver.cpp:244]     Train net output #0: loss = 0.843689 (* 1 = 0.843689 loss)
I0823 10:59:10.785732 28265 sgd_solver.cpp:106] Iteration 19600, lr = 0.000443336
I0823 10:59:15.314057 28265 solver.cpp:228] Iteration 19700, loss = 0.859448
I0823 10:59:15.314116 28265 solver.cpp:244]     Train net output #0: loss = 0.859448 (* 1 = 0.859448 loss)
I0823 10:59:15.314123 28265 sgd_solver.cpp:106] Iteration 19700, lr = 0.000442498
I0823 10:59:19.845522 28265 solver.cpp:228] Iteration 19800, loss = 0.859026
I0823 10:59:19.845569 28265 solver.cpp:244]     Train net output #0: loss = 0.859026 (* 1 = 0.859026 loss)
I0823 10:59:19.845576 28265 sgd_solver.cpp:106] Iteration 19800, lr = 0.000441664
I0823 10:59:24.374744 28265 solver.cpp:228] Iteration 19900, loss = 0.833534
I0823 10:59:24.374809 28265 solver.cpp:244]     Train net output #0: loss = 0.833534 (* 1 = 0.833534 loss)
I0823 10:59:24.374817 28265 sgd_solver.cpp:106] Iteration 19900, lr = 0.000440833
I0823 10:59:28.855643 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_20000.caffemodel
I0823 10:59:29.469887 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_20000.solverstate
I0823 10:59:29.657819 28265 solver.cpp:337] Iteration 20000, Testing net (#0)
I0823 10:59:32.767393 28265 solver.cpp:404]     Test net output #0: accuracy = 0.596
I0823 10:59:32.767462 28265 solver.cpp:404]     Test net output #1: loss = 0.810827 (* 1 = 0.810827 loss)
I0823 10:59:32.783215 28265 solver.cpp:228] Iteration 20000, loss = 0.892981
I0823 10:59:32.783278 28265 solver.cpp:244]     Train net output #0: loss = 0.892981 (* 1 = 0.892981 loss)
I0823 10:59:32.783293 28265 sgd_solver.cpp:106] Iteration 20000, lr = 0.000440007
I0823 10:59:37.308432 28265 solver.cpp:228] Iteration 20100, loss = 0.806027
I0823 10:59:37.308475 28265 solver.cpp:244]     Train net output #0: loss = 0.806027 (* 1 = 0.806027 loss)
I0823 10:59:37.308480 28265 sgd_solver.cpp:106] Iteration 20100, lr = 0.000439183
I0823 10:59:41.834913 28265 solver.cpp:228] Iteration 20200, loss = 0.96236
I0823 10:59:41.834954 28265 solver.cpp:244]     Train net output #0: loss = 0.96236 (* 1 = 0.96236 loss)
I0823 10:59:41.834959 28265 sgd_solver.cpp:106] Iteration 20200, lr = 0.000438364
I0823 10:59:46.365093 28265 solver.cpp:228] Iteration 20300, loss = 0.851696
I0823 10:59:46.365141 28265 solver.cpp:244]     Train net output #0: loss = 0.851696 (* 1 = 0.851696 loss)
I0823 10:59:46.365146 28265 sgd_solver.cpp:106] Iteration 20300, lr = 0.000437548
I0823 10:59:50.905313 28265 solver.cpp:228] Iteration 20400, loss = 0.933235
I0823 10:59:50.905357 28265 solver.cpp:244]     Train net output #0: loss = 0.933235 (* 1 = 0.933235 loss)
I0823 10:59:50.905362 28265 sgd_solver.cpp:106] Iteration 20400, lr = 0.000436735
I0823 10:59:55.387742 28265 solver.cpp:337] Iteration 20500, Testing net (#0)
I0823 10:59:58.674432 28265 solver.cpp:404]     Test net output #0: accuracy = 0.605833
I0823 10:59:58.674492 28265 solver.cpp:404]     Test net output #1: loss = 0.795349 (* 1 = 0.795349 loss)
I0823 10:59:58.690311 28265 solver.cpp:228] Iteration 20500, loss = 0.803391
I0823 10:59:58.690368 28265 solver.cpp:244]     Train net output #0: loss = 0.803391 (* 1 = 0.803391 loss)
I0823 10:59:58.690383 28265 sgd_solver.cpp:106] Iteration 20500, lr = 0.000435926
I0823 11:00:03.223232 28265 solver.cpp:228] Iteration 20600, loss = 0.852674
I0823 11:00:03.223275 28265 solver.cpp:244]     Train net output #0: loss = 0.852674 (* 1 = 0.852674 loss)
I0823 11:00:03.223281 28265 sgd_solver.cpp:106] Iteration 20600, lr = 0.000435121
I0823 11:00:07.754118 28265 solver.cpp:228] Iteration 20700, loss = 0.819932
I0823 11:00:07.754163 28265 solver.cpp:244]     Train net output #0: loss = 0.819932 (* 1 = 0.819932 loss)
I0823 11:00:07.754168 28265 sgd_solver.cpp:106] Iteration 20700, lr = 0.000434319
I0823 11:00:12.293705 28265 solver.cpp:228] Iteration 20800, loss = 0.755375
I0823 11:00:12.293761 28265 solver.cpp:244]     Train net output #0: loss = 0.755375 (* 1 = 0.755375 loss)
I0823 11:00:12.293767 28265 sgd_solver.cpp:106] Iteration 20800, lr = 0.00043352
I0823 11:00:16.828423 28265 solver.cpp:228] Iteration 20900, loss = 0.868252
I0823 11:00:16.828470 28265 solver.cpp:244]     Train net output #0: loss = 0.868252 (* 1 = 0.868252 loss)
I0823 11:00:16.828475 28265 sgd_solver.cpp:106] Iteration 20900, lr = 0.000432725
I0823 11:00:21.320818 28265 solver.cpp:337] Iteration 21000, Testing net (#0)
I0823 11:00:24.716941 28265 solver.cpp:404]     Test net output #0: accuracy = 0.621
I0823 11:00:24.717008 28265 solver.cpp:404]     Test net output #1: loss = 0.770796 (* 1 = 0.770796 loss)
I0823 11:00:24.731736 28265 solver.cpp:228] Iteration 21000, loss = 0.80104
I0823 11:00:24.731775 28265 solver.cpp:244]     Train net output #0: loss = 0.80104 (* 1 = 0.80104 loss)
I0823 11:00:24.731786 28265 sgd_solver.cpp:106] Iteration 21000, lr = 0.000431933
I0823 11:00:29.265101 28265 solver.cpp:228] Iteration 21100, loss = 0.759957
I0823 11:00:29.265148 28265 solver.cpp:244]     Train net output #0: loss = 0.759957 (* 1 = 0.759957 loss)
I0823 11:00:29.265154 28265 sgd_solver.cpp:106] Iteration 21100, lr = 0.000431145
I0823 11:00:33.796581 28265 solver.cpp:228] Iteration 21200, loss = 0.817709
I0823 11:00:33.796629 28265 solver.cpp:244]     Train net output #0: loss = 0.817709 (* 1 = 0.817709 loss)
I0823 11:00:33.796634 28265 sgd_solver.cpp:106] Iteration 21200, lr = 0.000430359
I0823 11:00:38.327863 28265 solver.cpp:228] Iteration 21300, loss = 0.834314
I0823 11:00:38.327908 28265 solver.cpp:244]     Train net output #0: loss = 0.834314 (* 1 = 0.834314 loss)
I0823 11:00:38.327914 28265 sgd_solver.cpp:106] Iteration 21300, lr = 0.000429578
I0823 11:00:42.856937 28265 solver.cpp:228] Iteration 21400, loss = 0.80473
I0823 11:00:42.857007 28265 solver.cpp:244]     Train net output #0: loss = 0.80473 (* 1 = 0.80473 loss)
I0823 11:00:42.857013 28265 sgd_solver.cpp:106] Iteration 21400, lr = 0.000428799
I0823 11:00:47.345618 28265 solver.cpp:337] Iteration 21500, Testing net (#0)
I0823 11:00:47.756898 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:00:50.880532 28265 solver.cpp:404]     Test net output #0: accuracy = 0.633125
I0823 11:00:50.880587 28265 solver.cpp:404]     Test net output #1: loss = 0.75785 (* 1 = 0.75785 loss)
I0823 11:00:50.895792 28265 solver.cpp:228] Iteration 21500, loss = 0.726979
I0823 11:00:50.895836 28265 solver.cpp:244]     Train net output #0: loss = 0.726979 (* 1 = 0.726979 loss)
I0823 11:00:50.895850 28265 sgd_solver.cpp:106] Iteration 21500, lr = 0.000428024
I0823 11:00:55.432039 28265 solver.cpp:228] Iteration 21600, loss = 0.792497
I0823 11:00:55.432085 28265 solver.cpp:244]     Train net output #0: loss = 0.792497 (* 1 = 0.792497 loss)
I0823 11:00:55.432090 28265 sgd_solver.cpp:106] Iteration 21600, lr = 0.000427252
I0823 11:00:59.960868 28265 solver.cpp:228] Iteration 21700, loss = 0.817958
I0823 11:00:59.960914 28265 solver.cpp:244]     Train net output #0: loss = 0.817958 (* 1 = 0.817958 loss)
I0823 11:00:59.960919 28265 sgd_solver.cpp:106] Iteration 21700, lr = 0.000426483
I0823 11:01:04.490501 28265 solver.cpp:228] Iteration 21800, loss = 0.843668
I0823 11:01:04.490546 28265 solver.cpp:244]     Train net output #0: loss = 0.843668 (* 1 = 0.843668 loss)
I0823 11:01:04.490552 28265 sgd_solver.cpp:106] Iteration 21800, lr = 0.000425718
I0823 11:01:09.020191 28265 solver.cpp:228] Iteration 21900, loss = 0.768606
I0823 11:01:09.020249 28265 solver.cpp:244]     Train net output #0: loss = 0.768606 (* 1 = 0.768606 loss)
I0823 11:01:09.020256 28265 sgd_solver.cpp:106] Iteration 21900, lr = 0.000424956
I0823 11:01:13.502686 28265 solver.cpp:337] Iteration 22000, Testing net (#0)
I0823 11:01:16.822562 28265 solver.cpp:404]     Test net output #0: accuracy = 0.643792
I0823 11:01:16.822607 28265 solver.cpp:404]     Test net output #1: loss = 0.755022 (* 1 = 0.755022 loss)
I0823 11:01:16.837844 28265 solver.cpp:228] Iteration 22000, loss = 0.723617
I0823 11:01:16.837885 28265 solver.cpp:244]     Train net output #0: loss = 0.723617 (* 1 = 0.723617 loss)
I0823 11:01:16.837895 28265 sgd_solver.cpp:106] Iteration 22000, lr = 0.000424197
I0823 11:01:21.365618 28265 solver.cpp:228] Iteration 22100, loss = 0.798919
I0823 11:01:21.365661 28265 solver.cpp:244]     Train net output #0: loss = 0.798919 (* 1 = 0.798919 loss)
I0823 11:01:21.365667 28265 sgd_solver.cpp:106] Iteration 22100, lr = 0.000423441
I0823 11:01:25.896800 28265 solver.cpp:228] Iteration 22200, loss = 0.717126
I0823 11:01:25.896845 28265 solver.cpp:244]     Train net output #0: loss = 0.717126 (* 1 = 0.717126 loss)
I0823 11:01:25.896850 28265 sgd_solver.cpp:106] Iteration 22200, lr = 0.000422688
I0823 11:01:30.421592 28265 solver.cpp:228] Iteration 22300, loss = 0.764451
I0823 11:01:30.421614 28265 solver.cpp:244]     Train net output #0: loss = 0.764451 (* 1 = 0.764451 loss)
I0823 11:01:30.421619 28265 sgd_solver.cpp:106] Iteration 22300, lr = 0.000421938
I0823 11:01:34.956991 28265 solver.cpp:228] Iteration 22400, loss = 0.742786
I0823 11:01:34.957036 28265 solver.cpp:244]     Train net output #0: loss = 0.742786 (* 1 = 0.742786 loss)
I0823 11:01:34.957041 28265 sgd_solver.cpp:106] Iteration 22400, lr = 0.000421192
I0823 11:01:39.450839 28265 solver.cpp:337] Iteration 22500, Testing net (#0)
I0823 11:01:42.811703 28265 solver.cpp:404]     Test net output #0: accuracy = 0.708125
I0823 11:01:42.811785 28265 solver.cpp:404]     Test net output #1: loss = 0.643294 (* 1 = 0.643294 loss)
I0823 11:01:42.828533 28265 solver.cpp:228] Iteration 22500, loss = 0.921601
I0823 11:01:42.828573 28265 solver.cpp:244]     Train net output #0: loss = 0.921601 (* 1 = 0.921601 loss)
I0823 11:01:42.828588 28265 sgd_solver.cpp:106] Iteration 22500, lr = 0.000420448
I0823 11:01:47.354370 28265 solver.cpp:228] Iteration 22600, loss = 0.668154
I0823 11:01:47.354425 28265 solver.cpp:244]     Train net output #0: loss = 0.668154 (* 1 = 0.668154 loss)
I0823 11:01:47.354434 28265 sgd_solver.cpp:106] Iteration 22600, lr = 0.000419708
I0823 11:01:51.880396 28265 solver.cpp:228] Iteration 22700, loss = 0.685979
I0823 11:01:51.880440 28265 solver.cpp:244]     Train net output #0: loss = 0.685979 (* 1 = 0.685979 loss)
I0823 11:01:51.880445 28265 sgd_solver.cpp:106] Iteration 22700, lr = 0.00041897
I0823 11:01:56.414921 28265 solver.cpp:228] Iteration 22800, loss = 0.746102
I0823 11:01:56.414968 28265 solver.cpp:244]     Train net output #0: loss = 0.746102 (* 1 = 0.746102 loss)
I0823 11:01:56.414973 28265 sgd_solver.cpp:106] Iteration 22800, lr = 0.000418236
I0823 11:02:00.945471 28265 solver.cpp:228] Iteration 22900, loss = 0.736857
I0823 11:02:00.945516 28265 solver.cpp:244]     Train net output #0: loss = 0.736857 (* 1 = 0.736857 loss)
I0823 11:02:00.945521 28265 sgd_solver.cpp:106] Iteration 22900, lr = 0.000417505
I0823 11:02:05.445626 28265 solver.cpp:337] Iteration 23000, Testing net (#0)
I0823 11:02:08.998592 28265 solver.cpp:404]     Test net output #0: accuracy = 0.66
I0823 11:02:08.998646 28265 solver.cpp:404]     Test net output #1: loss = 0.742968 (* 1 = 0.742968 loss)
I0823 11:02:09.014454 28265 solver.cpp:228] Iteration 23000, loss = 0.746719
I0823 11:02:09.014502 28265 solver.cpp:244]     Train net output #0: loss = 0.746719 (* 1 = 0.746719 loss)
I0823 11:02:09.014513 28265 sgd_solver.cpp:106] Iteration 23000, lr = 0.000416776
I0823 11:02:13.539158 28265 solver.cpp:228] Iteration 23100, loss = 0.750647
I0823 11:02:13.539211 28265 solver.cpp:244]     Train net output #0: loss = 0.750647 (* 1 = 0.750647 loss)
I0823 11:02:13.539222 28265 sgd_solver.cpp:106] Iteration 23100, lr = 0.000416051
I0823 11:02:18.072983 28265 solver.cpp:228] Iteration 23200, loss = 0.680993
I0823 11:02:18.073036 28265 solver.cpp:244]     Train net output #0: loss = 0.680993 (* 1 = 0.680993 loss)
I0823 11:02:18.073043 28265 sgd_solver.cpp:106] Iteration 23200, lr = 0.000415328
I0823 11:02:22.598628 28265 solver.cpp:228] Iteration 23300, loss = 0.756571
I0823 11:02:22.598675 28265 solver.cpp:244]     Train net output #0: loss = 0.756571 (* 1 = 0.756571 loss)
I0823 11:02:22.598681 28265 sgd_solver.cpp:106] Iteration 23300, lr = 0.000414609
I0823 11:02:27.120914 28265 solver.cpp:228] Iteration 23400, loss = 0.765544
I0823 11:02:27.120964 28265 solver.cpp:244]     Train net output #0: loss = 0.765544 (* 1 = 0.765544 loss)
I0823 11:02:27.120970 28265 sgd_solver.cpp:106] Iteration 23400, lr = 0.000413892
I0823 11:02:31.611547 28265 solver.cpp:337] Iteration 23500, Testing net (#0)
I0823 11:02:34.960810 28265 solver.cpp:404]     Test net output #0: accuracy = 0.7145
I0823 11:02:34.960858 28265 solver.cpp:404]     Test net output #1: loss = 0.644949 (* 1 = 0.644949 loss)
I0823 11:02:34.976109 28265 solver.cpp:228] Iteration 23500, loss = 0.736779
I0823 11:02:34.976168 28265 solver.cpp:244]     Train net output #0: loss = 0.736779 (* 1 = 0.736779 loss)
I0823 11:02:34.976179 28265 sgd_solver.cpp:106] Iteration 23500, lr = 0.000413178
I0823 11:02:39.512825 28265 solver.cpp:228] Iteration 23600, loss = 0.653199
I0823 11:02:39.512888 28265 solver.cpp:244]     Train net output #0: loss = 0.653199 (* 1 = 0.653199 loss)
I0823 11:02:39.512897 28265 sgd_solver.cpp:106] Iteration 23600, lr = 0.000412467
I0823 11:02:44.040812 28265 solver.cpp:228] Iteration 23700, loss = 0.692225
I0823 11:02:44.040875 28265 solver.cpp:244]     Train net output #0: loss = 0.692225 (* 1 = 0.692225 loss)
I0823 11:02:44.040881 28265 sgd_solver.cpp:106] Iteration 23700, lr = 0.000411759
I0823 11:02:48.569234 28265 solver.cpp:228] Iteration 23800, loss = 0.605194
I0823 11:02:48.569288 28265 solver.cpp:244]     Train net output #0: loss = 0.605194 (* 1 = 0.605194 loss)
I0823 11:02:48.569295 28265 sgd_solver.cpp:106] Iteration 23800, lr = 0.000411054
I0823 11:02:53.101811 28265 solver.cpp:228] Iteration 23900, loss = 0.620947
I0823 11:02:53.101832 28265 solver.cpp:244]     Train net output #0: loss = 0.620947 (* 1 = 0.620947 loss)
I0823 11:02:53.101837 28265 sgd_solver.cpp:106] Iteration 23900, lr = 0.000410351
I0823 11:02:57.589783 28265 solver.cpp:337] Iteration 24000, Testing net (#0)
I0823 11:03:01.142987 28265 solver.cpp:404]     Test net output #0: accuracy = 0.7025
I0823 11:03:01.143049 28265 solver.cpp:404]     Test net output #1: loss = 0.663841 (* 1 = 0.663841 loss)
I0823 11:03:01.158495 28265 solver.cpp:228] Iteration 24000, loss = 0.628651
I0823 11:03:01.158524 28265 solver.cpp:244]     Train net output #0: loss = 0.628651 (* 1 = 0.628651 loss)
I0823 11:03:01.158538 28265 sgd_solver.cpp:106] Iteration 24000, lr = 0.000409652
I0823 11:03:05.688125 28265 solver.cpp:228] Iteration 24100, loss = 0.590358
I0823 11:03:05.689054 28265 solver.cpp:244]     Train net output #0: loss = 0.590358 (* 1 = 0.590358 loss)
I0823 11:03:05.689064 28265 sgd_solver.cpp:106] Iteration 24100, lr = 0.000408955
I0823 11:03:10.221637 28265 solver.cpp:228] Iteration 24200, loss = 0.691457
I0823 11:03:10.221684 28265 solver.cpp:244]     Train net output #0: loss = 0.691457 (* 1 = 0.691457 loss)
I0823 11:03:10.221693 28265 sgd_solver.cpp:106] Iteration 24200, lr = 0.000408261
I0823 11:03:14.748718 28265 solver.cpp:228] Iteration 24300, loss = 0.615532
I0823 11:03:14.748766 28265 solver.cpp:244]     Train net output #0: loss = 0.615532 (* 1 = 0.615532 loss)
I0823 11:03:14.748774 28265 sgd_solver.cpp:106] Iteration 24300, lr = 0.000407569
I0823 11:03:15.657095 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:03:19.282793 28265 solver.cpp:228] Iteration 24400, loss = 0.631707
I0823 11:03:19.282826 28265 solver.cpp:244]     Train net output #0: loss = 0.631707 (* 1 = 0.631707 loss)
I0823 11:03:19.282832 28265 sgd_solver.cpp:106] Iteration 24400, lr = 0.000406881
I0823 11:03:23.765794 28265 solver.cpp:337] Iteration 24500, Testing net (#0)
I0823 11:03:27.265310 28265 solver.cpp:404]     Test net output #0: accuracy = 0.747667
I0823 11:03:27.265416 28265 solver.cpp:404]     Test net output #1: loss = 0.576083 (* 1 = 0.576083 loss)
I0823 11:03:27.282294 28265 solver.cpp:228] Iteration 24500, loss = 0.700992
I0823 11:03:27.282356 28265 solver.cpp:244]     Train net output #0: loss = 0.700992 (* 1 = 0.700992 loss)
I0823 11:03:27.282371 28265 sgd_solver.cpp:106] Iteration 24500, lr = 0.000406195
I0823 11:03:31.811053 28265 solver.cpp:228] Iteration 24600, loss = 0.709996
I0823 11:03:31.811096 28265 solver.cpp:244]     Train net output #0: loss = 0.709996 (* 1 = 0.709996 loss)
I0823 11:03:31.811101 28265 sgd_solver.cpp:106] Iteration 24600, lr = 0.000405511
I0823 11:03:36.340946 28265 solver.cpp:228] Iteration 24700, loss = 0.70966
I0823 11:03:36.340992 28265 solver.cpp:244]     Train net output #0: loss = 0.70966 (* 1 = 0.70966 loss)
I0823 11:03:36.340998 28265 sgd_solver.cpp:106] Iteration 24700, lr = 0.000404831
I0823 11:03:40.864074 28265 solver.cpp:228] Iteration 24800, loss = 0.689251
I0823 11:03:40.864095 28265 solver.cpp:244]     Train net output #0: loss = 0.689251 (* 1 = 0.689251 loss)
I0823 11:03:40.864099 28265 sgd_solver.cpp:106] Iteration 24800, lr = 0.000404153
I0823 11:03:45.392309 28265 solver.cpp:228] Iteration 24900, loss = 0.642403
I0823 11:03:45.392354 28265 solver.cpp:244]     Train net output #0: loss = 0.642403 (* 1 = 0.642403 loss)
I0823 11:03:45.392359 28265 sgd_solver.cpp:106] Iteration 24900, lr = 0.000403478
I0823 11:03:49.882558 28265 solver.cpp:337] Iteration 25000, Testing net (#0)
I0823 11:03:53.452117 28265 solver.cpp:404]     Test net output #0: accuracy = 0.740583
I0823 11:03:53.452183 28265 solver.cpp:404]     Test net output #1: loss = 0.593324 (* 1 = 0.593324 loss)
I0823 11:03:53.466847 28265 solver.cpp:228] Iteration 25000, loss = 0.575231
I0823 11:03:53.466892 28265 solver.cpp:244]     Train net output #0: loss = 0.575231 (* 1 = 0.575231 loss)
I0823 11:03:53.466914 28265 sgd_solver.cpp:106] Iteration 25000, lr = 0.000402805
I0823 11:03:57.993043 28265 solver.cpp:228] Iteration 25100, loss = 0.59963
I0823 11:03:57.993098 28265 solver.cpp:244]     Train net output #0: loss = 0.59963 (* 1 = 0.59963 loss)
I0823 11:03:57.993106 28265 sgd_solver.cpp:106] Iteration 25100, lr = 0.000402135
I0823 11:04:02.523301 28265 solver.cpp:228] Iteration 25200, loss = 0.696935
I0823 11:04:02.523362 28265 solver.cpp:244]     Train net output #0: loss = 0.696935 (* 1 = 0.696935 loss)
I0823 11:04:02.523370 28265 sgd_solver.cpp:106] Iteration 25200, lr = 0.000401467
I0823 11:04:07.049917 28265 solver.cpp:228] Iteration 25300, loss = 0.743364
I0823 11:04:07.049965 28265 solver.cpp:244]     Train net output #0: loss = 0.743364 (* 1 = 0.743364 loss)
I0823 11:04:07.049970 28265 sgd_solver.cpp:106] Iteration 25300, lr = 0.000400803
I0823 11:04:11.578054 28265 solver.cpp:228] Iteration 25400, loss = 0.617355
I0823 11:04:11.578096 28265 solver.cpp:244]     Train net output #0: loss = 0.617355 (* 1 = 0.617355 loss)
I0823 11:04:11.578102 28265 sgd_solver.cpp:106] Iteration 25400, lr = 0.00040014
I0823 11:04:16.065258 28265 solver.cpp:337] Iteration 25500, Testing net (#0)
I0823 11:04:19.424284 28265 solver.cpp:404]     Test net output #0: accuracy = 0.740959
I0823 11:04:19.424342 28265 solver.cpp:404]     Test net output #1: loss = 0.597813 (* 1 = 0.597813 loss)
I0823 11:04:19.439996 28265 solver.cpp:228] Iteration 25500, loss = 0.581745
I0823 11:04:19.440044 28265 solver.cpp:244]     Train net output #0: loss = 0.581745 (* 1 = 0.581745 loss)
I0823 11:04:19.440057 28265 sgd_solver.cpp:106] Iteration 25500, lr = 0.000399481
I0823 11:04:23.977852 28265 solver.cpp:228] Iteration 25600, loss = 0.75201
I0823 11:04:23.977916 28265 solver.cpp:244]     Train net output #0: loss = 0.75201 (* 1 = 0.75201 loss)
I0823 11:04:23.977922 28265 sgd_solver.cpp:106] Iteration 25600, lr = 0.000398823
I0823 11:04:28.509665 28265 solver.cpp:228] Iteration 25700, loss = 0.596708
I0823 11:04:28.509722 28265 solver.cpp:244]     Train net output #0: loss = 0.596708 (* 1 = 0.596708 loss)
I0823 11:04:28.509733 28265 sgd_solver.cpp:106] Iteration 25700, lr = 0.000398169
I0823 11:04:33.047518 28265 solver.cpp:228] Iteration 25800, loss = 0.557405
I0823 11:04:33.047560 28265 solver.cpp:244]     Train net output #0: loss = 0.557405 (* 1 = 0.557405 loss)
I0823 11:04:33.047565 28265 sgd_solver.cpp:106] Iteration 25800, lr = 0.000397516
I0823 11:04:37.580876 28265 solver.cpp:228] Iteration 25900, loss = 0.560835
I0823 11:04:37.580896 28265 solver.cpp:244]     Train net output #0: loss = 0.560835 (* 1 = 0.560835 loss)
I0823 11:04:37.580901 28265 sgd_solver.cpp:106] Iteration 25900, lr = 0.000396867
I0823 11:04:42.067651 28265 solver.cpp:337] Iteration 26000, Testing net (#0)
I0823 11:04:45.465540 28265 solver.cpp:404]     Test net output #0: accuracy = 0.760834
I0823 11:04:45.465595 28265 solver.cpp:404]     Test net output #1: loss = 0.545771 (* 1 = 0.545771 loss)
I0823 11:04:45.480412 28265 solver.cpp:228] Iteration 26000, loss = 0.650288
I0823 11:04:45.480458 28265 solver.cpp:244]     Train net output #0: loss = 0.650288 (* 1 = 0.650288 loss)
I0823 11:04:45.480469 28265 sgd_solver.cpp:106] Iteration 26000, lr = 0.000396219
I0823 11:04:50.003589 28265 solver.cpp:228] Iteration 26100, loss = 0.566249
I0823 11:04:50.003633 28265 solver.cpp:244]     Train net output #0: loss = 0.566249 (* 1 = 0.566249 loss)
I0823 11:04:50.003639 28265 sgd_solver.cpp:106] Iteration 26100, lr = 0.000395575
I0823 11:04:54.530386 28265 solver.cpp:228] Iteration 26200, loss = 0.589889
I0823 11:04:54.530441 28265 solver.cpp:244]     Train net output #0: loss = 0.589889 (* 1 = 0.589889 loss)
I0823 11:04:54.530450 28265 sgd_solver.cpp:106] Iteration 26200, lr = 0.000394932
I0823 11:04:59.059272 28265 solver.cpp:228] Iteration 26300, loss = 0.578887
I0823 11:04:59.059329 28265 solver.cpp:244]     Train net output #0: loss = 0.578887 (* 1 = 0.578887 loss)
I0823 11:04:59.059336 28265 sgd_solver.cpp:106] Iteration 26300, lr = 0.000394292
I0823 11:05:03.581727 28265 solver.cpp:228] Iteration 26400, loss = 0.533593
I0823 11:05:03.581768 28265 solver.cpp:244]     Train net output #0: loss = 0.533593 (* 1 = 0.533593 loss)
I0823 11:05:03.581773 28265 sgd_solver.cpp:106] Iteration 26400, lr = 0.000393655
I0823 11:05:08.062358 28265 solver.cpp:337] Iteration 26500, Testing net (#0)
I0823 11:05:11.596257 28265 solver.cpp:404]     Test net output #0: accuracy = 0.720042
I0823 11:05:11.596310 28265 solver.cpp:404]     Test net output #1: loss = 0.639426 (* 1 = 0.639426 loss)
I0823 11:05:11.612363 28265 solver.cpp:228] Iteration 26500, loss = 0.494642
I0823 11:05:11.612443 28265 solver.cpp:244]     Train net output #0: loss = 0.494642 (* 1 = 0.494642 loss)
I0823 11:05:11.612462 28265 sgd_solver.cpp:106] Iteration 26500, lr = 0.00039302
I0823 11:05:16.137313 28265 solver.cpp:228] Iteration 26600, loss = 0.536232
I0823 11:05:16.137354 28265 solver.cpp:244]     Train net output #0: loss = 0.536232 (* 1 = 0.536232 loss)
I0823 11:05:16.137359 28265 sgd_solver.cpp:106] Iteration 26600, lr = 0.000392387
I0823 11:05:20.664737 28265 solver.cpp:228] Iteration 26700, loss = 0.511474
I0823 11:05:20.664782 28265 solver.cpp:244]     Train net output #0: loss = 0.511474 (* 1 = 0.511474 loss)
I0823 11:05:20.664786 28265 sgd_solver.cpp:106] Iteration 26700, lr = 0.000391757
I0823 11:05:25.186625 28265 solver.cpp:228] Iteration 26800, loss = 0.70243
I0823 11:05:25.186645 28265 solver.cpp:244]     Train net output #0: loss = 0.70243 (* 1 = 0.70243 loss)
I0823 11:05:25.186650 28265 sgd_solver.cpp:106] Iteration 26800, lr = 0.000391129
I0823 11:05:29.704550 28265 solver.cpp:228] Iteration 26900, loss = 0.546732
I0823 11:05:29.704594 28265 solver.cpp:244]     Train net output #0: loss = 0.546732 (* 1 = 0.546732 loss)
I0823 11:05:29.704599 28265 sgd_solver.cpp:106] Iteration 26900, lr = 0.000390503
I0823 11:05:34.186863 28265 solver.cpp:337] Iteration 27000, Testing net (#0)
I0823 11:05:37.364595 28265 solver.cpp:404]     Test net output #0: accuracy = 0.766708
I0823 11:05:37.364663 28265 solver.cpp:404]     Test net output #1: loss = 0.533656 (* 1 = 0.533656 loss)
I0823 11:05:37.380497 28265 solver.cpp:228] Iteration 27000, loss = 0.578823
I0823 11:05:37.380559 28265 solver.cpp:244]     Train net output #0: loss = 0.578823 (* 1 = 0.578823 loss)
I0823 11:05:37.380574 28265 sgd_solver.cpp:106] Iteration 27000, lr = 0.00038988
I0823 11:05:41.909199 28265 solver.cpp:228] Iteration 27100, loss = 0.510797
I0823 11:05:41.909241 28265 solver.cpp:244]     Train net output #0: loss = 0.510797 (* 1 = 0.510797 loss)
I0823 11:05:41.909246 28265 sgd_solver.cpp:106] Iteration 27100, lr = 0.000389259
I0823 11:05:46.435832 28265 solver.cpp:228] Iteration 27200, loss = 0.674375
I0823 11:05:46.435879 28265 solver.cpp:244]     Train net output #0: loss = 0.674375 (* 1 = 0.674375 loss)
I0823 11:05:46.435888 28265 sgd_solver.cpp:106] Iteration 27200, lr = 0.00038864
I0823 11:05:50.968211 28265 solver.cpp:228] Iteration 27300, loss = 0.523665
I0823 11:05:50.968269 28265 solver.cpp:244]     Train net output #0: loss = 0.523665 (* 1 = 0.523665 loss)
I0823 11:05:50.968277 28265 sgd_solver.cpp:106] Iteration 27300, lr = 0.000388024
I0823 11:05:55.498390 28265 solver.cpp:228] Iteration 27400, loss = 0.561772
I0823 11:05:55.498448 28265 solver.cpp:244]     Train net output #0: loss = 0.561772 (* 1 = 0.561772 loss)
I0823 11:05:55.498456 28265 sgd_solver.cpp:106] Iteration 27400, lr = 0.00038741
I0823 11:05:59.989627 28265 solver.cpp:337] Iteration 27500, Testing net (#0)
I0823 11:06:00.678133 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:06:03.445574 28265 solver.cpp:404]     Test net output #0: accuracy = 0.749458
I0823 11:06:03.445627 28265 solver.cpp:404]     Test net output #1: loss = 0.577249 (* 1 = 0.577249 loss)
I0823 11:06:03.461328 28265 solver.cpp:228] Iteration 27500, loss = 0.562447
I0823 11:06:03.461387 28265 solver.cpp:244]     Train net output #0: loss = 0.562447 (* 1 = 0.562447 loss)
I0823 11:06:03.461401 28265 sgd_solver.cpp:106] Iteration 27500, lr = 0.000386798
I0823 11:06:07.998008 28265 solver.cpp:228] Iteration 27600, loss = 0.582871
I0823 11:06:07.998054 28265 solver.cpp:244]     Train net output #0: loss = 0.582871 (* 1 = 0.582871 loss)
I0823 11:06:07.998060 28265 sgd_solver.cpp:106] Iteration 27600, lr = 0.000386188
I0823 11:06:12.527645 28265 solver.cpp:228] Iteration 27700, loss = 0.644718
I0823 11:06:12.527706 28265 solver.cpp:244]     Train net output #0: loss = 0.644718 (* 1 = 0.644718 loss)
I0823 11:06:12.527714 28265 sgd_solver.cpp:106] Iteration 27700, lr = 0.000385581
I0823 11:06:17.050820 28265 solver.cpp:228] Iteration 27800, loss = 0.523741
I0823 11:06:17.050842 28265 solver.cpp:244]     Train net output #0: loss = 0.523741 (* 1 = 0.523741 loss)
I0823 11:06:17.050846 28265 sgd_solver.cpp:106] Iteration 27800, lr = 0.000384976
I0823 11:06:21.574508 28265 solver.cpp:228] Iteration 27900, loss = 0.680261
I0823 11:06:21.574568 28265 solver.cpp:244]     Train net output #0: loss = 0.680261 (* 1 = 0.680261 loss)
I0823 11:06:21.574573 28265 sgd_solver.cpp:106] Iteration 27900, lr = 0.000384373
I0823 11:06:26.058786 28265 solver.cpp:337] Iteration 28000, Testing net (#0)
I0823 11:06:29.295832 28265 solver.cpp:404]     Test net output #0: accuracy = 0.772333
I0823 11:06:29.295886 28265 solver.cpp:404]     Test net output #1: loss = 0.528201 (* 1 = 0.528201 loss)
I0823 11:06:29.311146 28265 solver.cpp:228] Iteration 28000, loss = 0.49736
I0823 11:06:29.311175 28265 solver.cpp:244]     Train net output #0: loss = 0.49736 (* 1 = 0.49736 loss)
I0823 11:06:29.311185 28265 sgd_solver.cpp:106] Iteration 28000, lr = 0.000383772
I0823 11:06:33.844027 28265 solver.cpp:228] Iteration 28100, loss = 0.529503
I0823 11:06:33.844094 28265 solver.cpp:244]     Train net output #0: loss = 0.529503 (* 1 = 0.529503 loss)
I0823 11:06:33.844105 28265 sgd_solver.cpp:106] Iteration 28100, lr = 0.000383173
I0823 11:06:38.371323 28265 solver.cpp:228] Iteration 28200, loss = 0.523101
I0823 11:06:38.371377 28265 solver.cpp:244]     Train net output #0: loss = 0.523101 (* 1 = 0.523101 loss)
I0823 11:06:38.371384 28265 sgd_solver.cpp:106] Iteration 28200, lr = 0.000382577
I0823 11:06:42.899735 28265 solver.cpp:228] Iteration 28300, loss = 0.452126
I0823 11:06:42.899778 28265 solver.cpp:244]     Train net output #0: loss = 0.452126 (* 1 = 0.452126 loss)
I0823 11:06:42.899783 28265 sgd_solver.cpp:106] Iteration 28300, lr = 0.000381983
I0823 11:06:47.430953 28265 solver.cpp:228] Iteration 28400, loss = 0.441629
I0823 11:06:47.431002 28265 solver.cpp:244]     Train net output #0: loss = 0.441629 (* 1 = 0.441629 loss)
I0823 11:06:47.431008 28265 sgd_solver.cpp:106] Iteration 28400, lr = 0.000381391
I0823 11:06:51.914717 28265 solver.cpp:337] Iteration 28500, Testing net (#0)
I0823 11:06:55.262130 28265 solver.cpp:404]     Test net output #0: accuracy = 0.718792
I0823 11:06:55.262202 28265 solver.cpp:404]     Test net output #1: loss = 0.658272 (* 1 = 0.658272 loss)
I0823 11:06:55.277732 28265 solver.cpp:228] Iteration 28500, loss = 0.512694
I0823 11:06:55.277778 28265 solver.cpp:244]     Train net output #0: loss = 0.512694 (* 1 = 0.512694 loss)
I0823 11:06:55.277799 28265 sgd_solver.cpp:106] Iteration 28500, lr = 0.000380801
I0823 11:06:59.812474 28265 solver.cpp:228] Iteration 28600, loss = 0.486072
I0823 11:06:59.812541 28265 solver.cpp:244]     Train net output #0: loss = 0.486072 (* 1 = 0.486072 loss)
I0823 11:06:59.812548 28265 sgd_solver.cpp:106] Iteration 28600, lr = 0.000380213
I0823 11:07:04.344096 28265 solver.cpp:228] Iteration 28700, loss = 0.47758
I0823 11:07:04.344135 28265 solver.cpp:244]     Train net output #0: loss = 0.47758 (* 1 = 0.47758 loss)
I0823 11:07:04.344146 28265 sgd_solver.cpp:106] Iteration 28700, lr = 0.000379627
I0823 11:07:08.871717 28265 solver.cpp:228] Iteration 28800, loss = 0.488789
I0823 11:07:08.871773 28265 solver.cpp:244]     Train net output #0: loss = 0.488789 (* 1 = 0.488789 loss)
I0823 11:07:08.871778 28265 sgd_solver.cpp:106] Iteration 28800, lr = 0.000379044
I0823 11:07:13.404311 28265 solver.cpp:228] Iteration 28900, loss = 0.615053
I0823 11:07:13.404388 28265 solver.cpp:244]     Train net output #0: loss = 0.615053 (* 1 = 0.615053 loss)
I0823 11:07:13.404394 28265 sgd_solver.cpp:106] Iteration 28900, lr = 0.000378462
I0823 11:07:17.887132 28265 solver.cpp:337] Iteration 29000, Testing net (#0)
I0823 11:07:21.285392 28265 solver.cpp:404]     Test net output #0: accuracy = 0.782375
I0823 11:07:21.285447 28265 solver.cpp:404]     Test net output #1: loss = 0.498158 (* 1 = 0.498158 loss)
I0823 11:07:21.300779 28265 solver.cpp:228] Iteration 29000, loss = 0.670723
I0823 11:07:21.300801 28265 solver.cpp:244]     Train net output #0: loss = 0.670723 (* 1 = 0.670723 loss)
I0823 11:07:21.300812 28265 sgd_solver.cpp:106] Iteration 29000, lr = 0.000377883
I0823 11:07:25.837123 28265 solver.cpp:228] Iteration 29100, loss = 0.708285
I0823 11:07:25.837179 28265 solver.cpp:244]     Train net output #0: loss = 0.708285 (* 1 = 0.708285 loss)
I0823 11:07:25.837187 28265 sgd_solver.cpp:106] Iteration 29100, lr = 0.000377305
I0823 11:07:30.371697 28265 solver.cpp:228] Iteration 29200, loss = 0.551176
I0823 11:07:30.371742 28265 solver.cpp:244]     Train net output #0: loss = 0.551176 (* 1 = 0.551176 loss)
I0823 11:07:30.371747 28265 sgd_solver.cpp:106] Iteration 29200, lr = 0.00037673
I0823 11:07:34.903252 28265 solver.cpp:228] Iteration 29300, loss = 0.463425
I0823 11:07:34.903295 28265 solver.cpp:244]     Train net output #0: loss = 0.463425 (* 1 = 0.463425 loss)
I0823 11:07:34.903301 28265 sgd_solver.cpp:106] Iteration 29300, lr = 0.000376157
I0823 11:07:39.434037 28265 solver.cpp:228] Iteration 29400, loss = 0.584316
I0823 11:07:39.434093 28265 solver.cpp:244]     Train net output #0: loss = 0.584316 (* 1 = 0.584316 loss)
I0823 11:07:39.434098 28265 sgd_solver.cpp:106] Iteration 29400, lr = 0.000375586
I0823 11:07:43.915331 28265 solver.cpp:337] Iteration 29500, Testing net (#0)
I0823 11:07:47.520407 28265 solver.cpp:404]     Test net output #0: accuracy = 0.753208
I0823 11:07:47.520483 28265 solver.cpp:404]     Test net output #1: loss = 0.575386 (* 1 = 0.575386 loss)
I0823 11:07:47.536272 28265 solver.cpp:228] Iteration 29500, loss = 0.534177
I0823 11:07:47.536319 28265 solver.cpp:244]     Train net output #0: loss = 0.534177 (* 1 = 0.534177 loss)
I0823 11:07:47.536337 28265 sgd_solver.cpp:106] Iteration 29500, lr = 0.000375016
I0823 11:07:52.069147 28265 solver.cpp:228] Iteration 29600, loss = 0.68195
I0823 11:07:52.069198 28265 solver.cpp:244]     Train net output #0: loss = 0.68195 (* 1 = 0.68195 loss)
I0823 11:07:52.069203 28265 sgd_solver.cpp:106] Iteration 29600, lr = 0.000374449
I0823 11:07:56.593423 28265 solver.cpp:228] Iteration 29700, loss = 0.499189
I0823 11:07:56.593466 28265 solver.cpp:244]     Train net output #0: loss = 0.499189 (* 1 = 0.499189 loss)
I0823 11:07:56.593472 28265 sgd_solver.cpp:106] Iteration 29700, lr = 0.000373884
I0823 11:08:01.118185 28265 solver.cpp:228] Iteration 29800, loss = 0.477269
I0823 11:08:01.118238 28265 solver.cpp:244]     Train net output #0: loss = 0.477269 (* 1 = 0.477269 loss)
I0823 11:08:01.118245 28265 sgd_solver.cpp:106] Iteration 29800, lr = 0.000373321
I0823 11:08:05.642120 28265 solver.cpp:228] Iteration 29900, loss = 0.528841
I0823 11:08:05.642168 28265 solver.cpp:244]     Train net output #0: loss = 0.528841 (* 1 = 0.528841 loss)
I0823 11:08:05.642174 28265 sgd_solver.cpp:106] Iteration 29900, lr = 0.00037276
I0823 11:08:10.118218 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_30000.caffemodel
I0823 11:08:10.593044 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_30000.solverstate
I0823 11:08:10.748894 28265 solver.cpp:337] Iteration 30000, Testing net (#0)
I0823 11:08:14.012644 28265 solver.cpp:404]     Test net output #0: accuracy = 0.769208
I0823 11:08:14.012696 28265 solver.cpp:404]     Test net output #1: loss = 0.534167 (* 1 = 0.534167 loss)
I0823 11:08:14.028664 28265 solver.cpp:228] Iteration 30000, loss = 0.51735
I0823 11:08:14.028733 28265 solver.cpp:244]     Train net output #0: loss = 0.51735 (* 1 = 0.51735 loss)
I0823 11:08:14.028751 28265 sgd_solver.cpp:106] Iteration 30000, lr = 0.0003722
I0823 11:08:18.561108 28265 solver.cpp:228] Iteration 30100, loss = 0.465013
I0823 11:08:18.561159 28265 solver.cpp:244]     Train net output #0: loss = 0.465013 (* 1 = 0.465013 loss)
I0823 11:08:18.561167 28265 sgd_solver.cpp:106] Iteration 30100, lr = 0.000371643
I0823 11:08:23.086210 28265 solver.cpp:228] Iteration 30200, loss = 0.537257
I0823 11:08:23.086278 28265 solver.cpp:244]     Train net output #0: loss = 0.537257 (* 1 = 0.537257 loss)
I0823 11:08:23.086300 28265 sgd_solver.cpp:106] Iteration 30200, lr = 0.000371088
I0823 11:08:27.616024 28265 solver.cpp:228] Iteration 30300, loss = 0.658018
I0823 11:08:27.616071 28265 solver.cpp:244]     Train net output #0: loss = 0.658018 (* 1 = 0.658018 loss)
I0823 11:08:27.616076 28265 sgd_solver.cpp:106] Iteration 30300, lr = 0.000370534
I0823 11:08:32.142524 28265 solver.cpp:228] Iteration 30400, loss = 0.48517
I0823 11:08:32.142588 28265 solver.cpp:244]     Train net output #0: loss = 0.48517 (* 1 = 0.48517 loss)
I0823 11:08:32.142593 28265 sgd_solver.cpp:106] Iteration 30400, lr = 0.000369983
I0823 11:08:36.627029 28265 solver.cpp:337] Iteration 30500, Testing net (#0)
I0823 11:08:40.104921 28265 solver.cpp:404]     Test net output #0: accuracy = 0.763833
I0823 11:08:40.104996 28265 solver.cpp:404]     Test net output #1: loss = 0.550916 (* 1 = 0.550916 loss)
I0823 11:08:40.120441 28265 solver.cpp:228] Iteration 30500, loss = 0.504349
I0823 11:08:40.120512 28265 solver.cpp:244]     Train net output #0: loss = 0.504349 (* 1 = 0.504349 loss)
I0823 11:08:40.120532 28265 sgd_solver.cpp:106] Iteration 30500, lr = 0.000369433
I0823 11:08:44.646592 28265 solver.cpp:228] Iteration 30600, loss = 0.483643
I0823 11:08:44.646637 28265 solver.cpp:244]     Train net output #0: loss = 0.483643 (* 1 = 0.483643 loss)
I0823 11:08:44.646643 28265 sgd_solver.cpp:106] Iteration 30600, lr = 0.000368885
I0823 11:08:49.173763 28265 solver.cpp:228] Iteration 30700, loss = 0.52435
I0823 11:08:49.173805 28265 solver.cpp:244]     Train net output #0: loss = 0.52435 (* 1 = 0.52435 loss)
I0823 11:08:49.173810 28265 sgd_solver.cpp:106] Iteration 30700, lr = 0.000368339
I0823 11:08:53.705721 28265 solver.cpp:228] Iteration 30800, loss = 0.408537
I0823 11:08:53.705766 28265 solver.cpp:244]     Train net output #0: loss = 0.408537 (* 1 = 0.408537 loss)
I0823 11:08:53.705772 28265 sgd_solver.cpp:106] Iteration 30800, lr = 0.000367796
I0823 11:08:58.228950 28265 solver.cpp:228] Iteration 30900, loss = 0.524681
I0823 11:08:58.228971 28265 solver.cpp:244]     Train net output #0: loss = 0.524681 (* 1 = 0.524681 loss)
I0823 11:08:58.228976 28265 sgd_solver.cpp:106] Iteration 30900, lr = 0.000367253
I0823 11:09:02.715939 28265 solver.cpp:337] Iteration 31000, Testing net (#0)
I0823 11:09:05.737962 28265 solver.cpp:404]     Test net output #0: accuracy = 0.766083
I0823 11:09:05.738026 28265 solver.cpp:404]     Test net output #1: loss = 0.545078 (* 1 = 0.545078 loss)
I0823 11:09:05.752830 28265 solver.cpp:228] Iteration 31000, loss = 0.522704
I0823 11:09:05.752871 28265 solver.cpp:244]     Train net output #0: loss = 0.522704 (* 1 = 0.522704 loss)
I0823 11:09:05.752879 28265 sgd_solver.cpp:106] Iteration 31000, lr = 0.000366713
I0823 11:09:10.290298 28265 solver.cpp:228] Iteration 31100, loss = 0.532983
I0823 11:09:10.290343 28265 solver.cpp:244]     Train net output #0: loss = 0.532983 (* 1 = 0.532983 loss)
I0823 11:09:10.290349 28265 sgd_solver.cpp:106] Iteration 31100, lr = 0.000366175
I0823 11:09:14.814718 28265 solver.cpp:228] Iteration 31200, loss = 0.518043
I0823 11:09:14.814759 28265 solver.cpp:244]     Train net output #0: loss = 0.518043 (* 1 = 0.518043 loss)
I0823 11:09:14.814764 28265 sgd_solver.cpp:106] Iteration 31200, lr = 0.000365638
I0823 11:09:19.344276 28265 solver.cpp:228] Iteration 31300, loss = 0.434993
I0823 11:09:19.344321 28265 solver.cpp:244]     Train net output #0: loss = 0.434993 (* 1 = 0.434993 loss)
I0823 11:09:19.344327 28265 sgd_solver.cpp:106] Iteration 31300, lr = 0.000365104
I0823 11:09:23.880290 28265 solver.cpp:228] Iteration 31400, loss = 0.417977
I0823 11:09:23.880336 28265 solver.cpp:244]     Train net output #0: loss = 0.417977 (* 1 = 0.417977 loss)
I0823 11:09:23.880342 28265 sgd_solver.cpp:106] Iteration 31400, lr = 0.000364571
I0823 11:09:28.367849 28265 solver.cpp:337] Iteration 31500, Testing net (#0)
I0823 11:09:29.722020 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:09:31.805325 28265 solver.cpp:404]     Test net output #0: accuracy = 0.793958
I0823 11:09:31.805393 28265 solver.cpp:404]     Test net output #1: loss = 0.477631 (* 1 = 0.477631 loss)
I0823 11:09:31.821266 28265 solver.cpp:228] Iteration 31500, loss = 0.476373
I0823 11:09:31.821331 28265 solver.cpp:244]     Train net output #0: loss = 0.476373 (* 1 = 0.476373 loss)
I0823 11:09:31.821357 28265 sgd_solver.cpp:106] Iteration 31500, lr = 0.00036404
I0823 11:09:36.347489 28265 solver.cpp:228] Iteration 31600, loss = 0.424901
I0823 11:09:36.347537 28265 solver.cpp:244]     Train net output #0: loss = 0.424901 (* 1 = 0.424901 loss)
I0823 11:09:36.347543 28265 sgd_solver.cpp:106] Iteration 31600, lr = 0.00036351
I0823 11:09:40.876489 28265 solver.cpp:228] Iteration 31700, loss = 0.44639
I0823 11:09:40.876548 28265 solver.cpp:244]     Train net output #0: loss = 0.44639 (* 1 = 0.44639 loss)
I0823 11:09:40.876552 28265 sgd_solver.cpp:106] Iteration 31700, lr = 0.000362983
I0823 11:09:45.400892 28265 solver.cpp:228] Iteration 31800, loss = 0.542737
I0823 11:09:45.400914 28265 solver.cpp:244]     Train net output #0: loss = 0.542737 (* 1 = 0.542737 loss)
I0823 11:09:45.400918 28265 sgd_solver.cpp:106] Iteration 31800, lr = 0.000362457
I0823 11:09:49.935071 28265 solver.cpp:228] Iteration 31900, loss = 0.427175
I0823 11:09:49.935117 28265 solver.cpp:244]     Train net output #0: loss = 0.427175 (* 1 = 0.427175 loss)
I0823 11:09:49.935122 28265 sgd_solver.cpp:106] Iteration 31900, lr = 0.000361933
I0823 11:09:54.415211 28265 solver.cpp:337] Iteration 32000, Testing net (#0)
I0823 11:09:57.861965 28265 solver.cpp:404]     Test net output #0: accuracy = 0.6805
I0823 11:09:57.862015 28265 solver.cpp:404]     Test net output #1: loss = 0.764105 (* 1 = 0.764105 loss)
I0823 11:09:57.877184 28265 solver.cpp:228] Iteration 32000, loss = 0.564452
I0823 11:09:57.877202 28265 solver.cpp:244]     Train net output #0: loss = 0.564452 (* 1 = 0.564452 loss)
I0823 11:09:57.877212 28265 sgd_solver.cpp:106] Iteration 32000, lr = 0.000361411
I0823 11:10:02.403779 28265 solver.cpp:228] Iteration 32100, loss = 0.443548
I0823 11:10:02.403836 28265 solver.cpp:244]     Train net output #0: loss = 0.443548 (* 1 = 0.443548 loss)
I0823 11:10:02.403844 28265 sgd_solver.cpp:106] Iteration 32100, lr = 0.000360891
I0823 11:10:06.938797 28265 solver.cpp:228] Iteration 32200, loss = 0.541705
I0823 11:10:06.938855 28265 solver.cpp:244]     Train net output #0: loss = 0.541705 (* 1 = 0.541705 loss)
I0823 11:10:06.938865 28265 sgd_solver.cpp:106] Iteration 32200, lr = 0.000360372
I0823 11:10:11.475340 28265 solver.cpp:228] Iteration 32300, loss = 0.465669
I0823 11:10:11.475394 28265 solver.cpp:244]     Train net output #0: loss = 0.465669 (* 1 = 0.465669 loss)
I0823 11:10:11.475401 28265 sgd_solver.cpp:106] Iteration 32300, lr = 0.000359855
I0823 11:10:15.999290 28265 solver.cpp:228] Iteration 32400, loss = 0.448968
I0823 11:10:15.999311 28265 solver.cpp:244]     Train net output #0: loss = 0.448968 (* 1 = 0.448968 loss)
I0823 11:10:15.999315 28265 sgd_solver.cpp:106] Iteration 32400, lr = 0.00035934
I0823 11:10:20.477850 28265 solver.cpp:337] Iteration 32500, Testing net (#0)
I0823 11:10:23.580828 28265 solver.cpp:404]     Test net output #0: accuracy = 0.805667
I0823 11:10:23.580894 28265 solver.cpp:404]     Test net output #1: loss = 0.45409 (* 1 = 0.45409 loss)
I0823 11:10:23.596143 28265 solver.cpp:228] Iteration 32500, loss = 0.45636
I0823 11:10:23.596194 28265 solver.cpp:244]     Train net output #0: loss = 0.45636 (* 1 = 0.45636 loss)
I0823 11:10:23.596204 28265 sgd_solver.cpp:106] Iteration 32500, lr = 0.000358827
I0823 11:10:28.120700 28265 solver.cpp:228] Iteration 32600, loss = 0.380859
I0823 11:10:28.120751 28265 solver.cpp:244]     Train net output #0: loss = 0.380859 (* 1 = 0.380859 loss)
I0823 11:10:28.120759 28265 sgd_solver.cpp:106] Iteration 32600, lr = 0.000358315
I0823 11:10:32.652073 28265 solver.cpp:228] Iteration 32700, loss = 0.475742
I0823 11:10:32.652132 28265 solver.cpp:244]     Train net output #0: loss = 0.475742 (* 1 = 0.475742 loss)
I0823 11:10:32.652148 28265 sgd_solver.cpp:106] Iteration 32700, lr = 0.000357805
I0823 11:10:37.179431 28265 solver.cpp:228] Iteration 32800, loss = 0.526465
I0823 11:10:37.179499 28265 solver.cpp:244]     Train net output #0: loss = 0.526465 (* 1 = 0.526465 loss)
I0823 11:10:37.179509 28265 sgd_solver.cpp:106] Iteration 32800, lr = 0.000357297
I0823 11:10:41.708348 28265 solver.cpp:228] Iteration 32900, loss = 0.474633
I0823 11:10:41.708394 28265 solver.cpp:244]     Train net output #0: loss = 0.474633 (* 1 = 0.474633 loss)
I0823 11:10:41.708398 28265 sgd_solver.cpp:106] Iteration 32900, lr = 0.00035679
I0823 11:10:46.189841 28265 solver.cpp:337] Iteration 33000, Testing net (#0)
I0823 11:10:49.340847 28265 solver.cpp:404]     Test net output #0: accuracy = 0.785417
I0823 11:10:49.340896 28265 solver.cpp:404]     Test net output #1: loss = 0.500601 (* 1 = 0.500601 loss)
I0823 11:10:49.357846 28265 solver.cpp:228] Iteration 33000, loss = 0.452056
I0823 11:10:49.357914 28265 solver.cpp:244]     Train net output #0: loss = 0.452056 (* 1 = 0.452056 loss)
I0823 11:10:49.357939 28265 sgd_solver.cpp:106] Iteration 33000, lr = 0.000356285
I0823 11:10:53.877540 28265 solver.cpp:228] Iteration 33100, loss = 0.414631
I0823 11:10:53.877609 28265 solver.cpp:244]     Train net output #0: loss = 0.414631 (* 1 = 0.414631 loss)
I0823 11:10:53.877617 28265 sgd_solver.cpp:106] Iteration 33100, lr = 0.000355781
I0823 11:10:58.401291 28265 solver.cpp:228] Iteration 33200, loss = 0.527886
I0823 11:10:58.401345 28265 solver.cpp:244]     Train net output #0: loss = 0.527886 (* 1 = 0.527886 loss)
I0823 11:10:58.401350 28265 sgd_solver.cpp:106] Iteration 33200, lr = 0.00035528
I0823 11:11:02.925055 28265 solver.cpp:228] Iteration 33300, loss = 0.463707
I0823 11:11:02.925097 28265 solver.cpp:244]     Train net output #0: loss = 0.463707 (* 1 = 0.463707 loss)
I0823 11:11:02.925102 28265 sgd_solver.cpp:106] Iteration 33300, lr = 0.00035478
I0823 11:11:07.462168 28265 solver.cpp:228] Iteration 33400, loss = 0.520577
I0823 11:11:07.462219 28265 solver.cpp:244]     Train net output #0: loss = 0.520577 (* 1 = 0.520577 loss)
I0823 11:11:07.462225 28265 sgd_solver.cpp:106] Iteration 33400, lr = 0.000354281
I0823 11:11:11.944126 28265 solver.cpp:337] Iteration 33500, Testing net (#0)
I0823 11:11:15.482637 28265 solver.cpp:404]     Test net output #0: accuracy = 0.803166
I0823 11:11:15.482687 28265 solver.cpp:404]     Test net output #1: loss = 0.468679 (* 1 = 0.468679 loss)
I0823 11:11:15.497799 28265 solver.cpp:228] Iteration 33500, loss = 0.466165
I0823 11:11:15.497836 28265 solver.cpp:244]     Train net output #0: loss = 0.466165 (* 1 = 0.466165 loss)
I0823 11:11:15.497848 28265 sgd_solver.cpp:106] Iteration 33500, lr = 0.000353785
I0823 11:11:20.026613 28265 solver.cpp:228] Iteration 33600, loss = 0.357453
I0823 11:11:20.026669 28265 solver.cpp:244]     Train net output #0: loss = 0.357453 (* 1 = 0.357453 loss)
I0823 11:11:20.026674 28265 sgd_solver.cpp:106] Iteration 33600, lr = 0.000353289
I0823 11:11:24.555084 28265 solver.cpp:228] Iteration 33700, loss = 0.447769
I0823 11:11:24.555145 28265 solver.cpp:244]     Train net output #0: loss = 0.447769 (* 1 = 0.447769 loss)
I0823 11:11:24.555153 28265 sgd_solver.cpp:106] Iteration 33700, lr = 0.000352796
I0823 11:11:29.085566 28265 solver.cpp:228] Iteration 33800, loss = 0.466518
I0823 11:11:29.085609 28265 solver.cpp:244]     Train net output #0: loss = 0.466518 (* 1 = 0.466518 loss)
I0823 11:11:29.085615 28265 sgd_solver.cpp:106] Iteration 33800, lr = 0.000352304
I0823 11:11:33.617148 28265 solver.cpp:228] Iteration 33900, loss = 0.513946
I0823 11:11:33.617193 28265 solver.cpp:244]     Train net output #0: loss = 0.513946 (* 1 = 0.513946 loss)
I0823 11:11:33.617199 28265 sgd_solver.cpp:106] Iteration 33900, lr = 0.000351814
I0823 11:11:38.101320 28265 solver.cpp:337] Iteration 34000, Testing net (#0)
I0823 11:11:41.264377 28265 solver.cpp:404]     Test net output #0: accuracy = 0.799917
I0823 11:11:41.264457 28265 solver.cpp:404]     Test net output #1: loss = 0.47588 (* 1 = 0.47588 loss)
I0823 11:11:41.279762 28265 solver.cpp:228] Iteration 34000, loss = 0.449902
I0823 11:11:41.279819 28265 solver.cpp:244]     Train net output #0: loss = 0.449902 (* 1 = 0.449902 loss)
I0823 11:11:41.279834 28265 sgd_solver.cpp:106] Iteration 34000, lr = 0.000351325
I0823 11:11:45.809633 28265 solver.cpp:228] Iteration 34100, loss = 0.368383
I0823 11:11:45.809679 28265 solver.cpp:244]     Train net output #0: loss = 0.368383 (* 1 = 0.368383 loss)
I0823 11:11:45.809684 28265 sgd_solver.cpp:106] Iteration 34100, lr = 0.000350838
I0823 11:11:50.342767 28265 solver.cpp:228] Iteration 34200, loss = 0.339167
I0823 11:11:50.342818 28265 solver.cpp:244]     Train net output #0: loss = 0.339167 (* 1 = 0.339167 loss)
I0823 11:11:50.342823 28265 sgd_solver.cpp:106] Iteration 34200, lr = 0.000350352
I0823 11:11:54.873670 28265 solver.cpp:228] Iteration 34300, loss = 0.598762
I0823 11:11:54.873718 28265 solver.cpp:244]     Train net output #0: loss = 0.598762 (* 1 = 0.598762 loss)
I0823 11:11:54.873723 28265 sgd_solver.cpp:106] Iteration 34300, lr = 0.000349868
I0823 11:11:59.406813 28265 solver.cpp:228] Iteration 34400, loss = 0.379742
I0823 11:11:59.406836 28265 solver.cpp:244]     Train net output #0: loss = 0.379742 (* 1 = 0.379742 loss)
I0823 11:11:59.406841 28265 sgd_solver.cpp:106] Iteration 34400, lr = 0.000349386
I0823 11:12:03.899986 28265 solver.cpp:337] Iteration 34500, Testing net (#0)
I0823 11:12:07.508764 28265 solver.cpp:404]     Test net output #0: accuracy = 0.794833
I0823 11:12:07.508821 28265 solver.cpp:404]     Test net output #1: loss = 0.485769 (* 1 = 0.485769 loss)
I0823 11:12:07.523509 28265 solver.cpp:228] Iteration 34500, loss = 0.421337
I0823 11:12:07.523551 28265 solver.cpp:244]     Train net output #0: loss = 0.421337 (* 1 = 0.421337 loss)
I0823 11:12:07.523563 28265 sgd_solver.cpp:106] Iteration 34500, lr = 0.000348905
I0823 11:12:12.046710 28265 solver.cpp:228] Iteration 34600, loss = 0.544428
I0823 11:12:12.046752 28265 solver.cpp:244]     Train net output #0: loss = 0.544428 (* 1 = 0.544428 loss)
I0823 11:12:12.046757 28265 sgd_solver.cpp:106] Iteration 34600, lr = 0.000348425
I0823 11:12:16.571676 28265 solver.cpp:228] Iteration 34700, loss = 0.546656
I0823 11:12:16.571748 28265 solver.cpp:244]     Train net output #0: loss = 0.546656 (* 1 = 0.546656 loss)
I0823 11:12:16.571758 28265 sgd_solver.cpp:106] Iteration 34700, lr = 0.000347947
I0823 11:12:21.093650 28265 solver.cpp:228] Iteration 34800, loss = 0.4516
I0823 11:12:21.093693 28265 solver.cpp:244]     Train net output #0: loss = 0.4516 (* 1 = 0.4516 loss)
I0823 11:12:21.093698 28265 sgd_solver.cpp:106] Iteration 34800, lr = 0.000347471
I0823 11:12:25.617629 28265 solver.cpp:228] Iteration 34900, loss = 0.396985
I0823 11:12:25.617650 28265 solver.cpp:244]     Train net output #0: loss = 0.396985 (* 1 = 0.396985 loss)
I0823 11:12:25.617655 28265 sgd_solver.cpp:106] Iteration 34900, lr = 0.000346996
I0823 11:12:30.109377 28265 solver.cpp:337] Iteration 35000, Testing net (#0)
I0823 11:12:30.848731 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:12:33.692499 28265 solver.cpp:404]     Test net output #0: accuracy = 0.785583
I0823 11:12:33.692548 28265 solver.cpp:404]     Test net output #1: loss = 0.516585 (* 1 = 0.516585 loss)
I0823 11:12:33.708955 28265 solver.cpp:228] Iteration 35000, loss = 0.412406
I0823 11:12:33.708973 28265 solver.cpp:244]     Train net output #0: loss = 0.412406 (* 1 = 0.412406 loss)
I0823 11:12:33.708983 28265 sgd_solver.cpp:106] Iteration 35000, lr = 0.000346523
I0823 11:12:38.234241 28265 solver.cpp:228] Iteration 35100, loss = 0.313393
I0823 11:12:38.234298 28265 solver.cpp:244]     Train net output #0: loss = 0.313393 (* 1 = 0.313393 loss)
I0823 11:12:38.234309 28265 sgd_solver.cpp:106] Iteration 35100, lr = 0.000346051
I0823 11:12:42.778251 28265 solver.cpp:228] Iteration 35200, loss = 0.456697
I0823 11:12:42.778309 28265 solver.cpp:244]     Train net output #0: loss = 0.456697 (* 1 = 0.456697 loss)
I0823 11:12:42.778317 28265 sgd_solver.cpp:106] Iteration 35200, lr = 0.000345581
I0823 11:12:47.309218 28265 solver.cpp:228] Iteration 35300, loss = 0.3868
I0823 11:12:47.309265 28265 solver.cpp:244]     Train net output #0: loss = 0.3868 (* 1 = 0.3868 loss)
I0823 11:12:47.309270 28265 sgd_solver.cpp:106] Iteration 35300, lr = 0.000345112
I0823 11:12:51.837366 28265 solver.cpp:228] Iteration 35400, loss = 0.352443
I0823 11:12:51.837409 28265 solver.cpp:244]     Train net output #0: loss = 0.352443 (* 1 = 0.352443 loss)
I0823 11:12:51.837414 28265 sgd_solver.cpp:106] Iteration 35400, lr = 0.000344645
I0823 11:12:56.326494 28265 solver.cpp:337] Iteration 35500, Testing net (#0)
I0823 11:12:59.775579 28265 solver.cpp:404]     Test net output #0: accuracy = 0.828209
I0823 11:12:59.775653 28265 solver.cpp:404]     Test net output #1: loss = 0.412811 (* 1 = 0.412811 loss)
I0823 11:12:59.790977 28265 solver.cpp:228] Iteration 35500, loss = 0.479551
I0823 11:12:59.791029 28265 solver.cpp:244]     Train net output #0: loss = 0.479551 (* 1 = 0.479551 loss)
I0823 11:12:59.791038 28265 sgd_solver.cpp:106] Iteration 35500, lr = 0.000344179
I0823 11:13:04.326331 28265 solver.cpp:228] Iteration 35600, loss = 0.367701
I0823 11:13:04.326376 28265 solver.cpp:244]     Train net output #0: loss = 0.367701 (* 1 = 0.367701 loss)
I0823 11:13:04.326381 28265 sgd_solver.cpp:106] Iteration 35600, lr = 0.000343715
I0823 11:13:08.862300 28265 solver.cpp:228] Iteration 35700, loss = 0.415086
I0823 11:13:08.862359 28265 solver.cpp:244]     Train net output #0: loss = 0.415086 (* 1 = 0.415086 loss)
I0823 11:13:08.862370 28265 sgd_solver.cpp:106] Iteration 35700, lr = 0.000343252
I0823 11:13:13.389540 28265 solver.cpp:228] Iteration 35800, loss = 0.419568
I0823 11:13:13.389588 28265 solver.cpp:244]     Train net output #0: loss = 0.419568 (* 1 = 0.419568 loss)
I0823 11:13:13.389595 28265 sgd_solver.cpp:106] Iteration 35800, lr = 0.00034279
I0823 11:13:17.918609 28265 solver.cpp:228] Iteration 35900, loss = 0.366306
I0823 11:13:17.918675 28265 solver.cpp:244]     Train net output #0: loss = 0.366306 (* 1 = 0.366306 loss)
I0823 11:13:17.918681 28265 sgd_solver.cpp:106] Iteration 35900, lr = 0.00034233
I0823 11:13:22.400245 28265 solver.cpp:337] Iteration 36000, Testing net (#0)
I0823 11:13:26.130336 28265 solver.cpp:404]     Test net output #0: accuracy = 0.821833
I0823 11:13:26.130393 28265 solver.cpp:404]     Test net output #1: loss = 0.430754 (* 1 = 0.430754 loss)
I0823 11:13:26.145685 28265 solver.cpp:228] Iteration 36000, loss = 0.435882
I0823 11:13:26.145717 28265 solver.cpp:244]     Train net output #0: loss = 0.435882 (* 1 = 0.435882 loss)
I0823 11:13:26.145730 28265 sgd_solver.cpp:106] Iteration 36000, lr = 0.000341872
I0823 11:13:30.678994 28265 solver.cpp:228] Iteration 36100, loss = 0.513406
I0823 11:13:30.679052 28265 solver.cpp:244]     Train net output #0: loss = 0.513406 (* 1 = 0.513406 loss)
I0823 11:13:30.679059 28265 sgd_solver.cpp:106] Iteration 36100, lr = 0.000341415
I0823 11:13:35.211447 28265 solver.cpp:228] Iteration 36200, loss = 0.385107
I0823 11:13:35.211511 28265 solver.cpp:244]     Train net output #0: loss = 0.385107 (* 1 = 0.385107 loss)
I0823 11:13:35.211518 28265 sgd_solver.cpp:106] Iteration 36200, lr = 0.000340959
I0823 11:13:39.746029 28265 solver.cpp:228] Iteration 36300, loss = 0.406508
I0823 11:13:39.746076 28265 solver.cpp:244]     Train net output #0: loss = 0.406508 (* 1 = 0.406508 loss)
I0823 11:13:39.746081 28265 sgd_solver.cpp:106] Iteration 36300, lr = 0.000340505
I0823 11:13:44.272131 28265 solver.cpp:228] Iteration 36400, loss = 0.309904
I0823 11:13:44.272161 28265 solver.cpp:244]     Train net output #0: loss = 0.309904 (* 1 = 0.309904 loss)
I0823 11:13:44.272166 28265 sgd_solver.cpp:106] Iteration 36400, lr = 0.000340052
I0823 11:13:48.757539 28265 solver.cpp:337] Iteration 36500, Testing net (#0)
I0823 11:13:52.419883 28265 solver.cpp:404]     Test net output #0: accuracy = 0.795167
I0823 11:13:52.419931 28265 solver.cpp:404]     Test net output #1: loss = 0.500769 (* 1 = 0.500769 loss)
I0823 11:13:52.435010 28265 solver.cpp:228] Iteration 36500, loss = 0.375382
I0823 11:13:52.435050 28265 solver.cpp:244]     Train net output #0: loss = 0.375382 (* 1 = 0.375382 loss)
I0823 11:13:52.435060 28265 sgd_solver.cpp:106] Iteration 36500, lr = 0.0003396
I0823 11:13:56.959102 28265 solver.cpp:228] Iteration 36600, loss = 0.418236
I0823 11:13:56.959146 28265 solver.cpp:244]     Train net output #0: loss = 0.418236 (* 1 = 0.418236 loss)
I0823 11:13:56.959151 28265 sgd_solver.cpp:106] Iteration 36600, lr = 0.00033915
I0823 11:14:01.483641 28265 solver.cpp:228] Iteration 36700, loss = 0.431399
I0823 11:14:01.483700 28265 solver.cpp:244]     Train net output #0: loss = 0.431399 (* 1 = 0.431399 loss)
I0823 11:14:01.483707 28265 sgd_solver.cpp:106] Iteration 36700, lr = 0.000338701
I0823 11:14:06.016211 28265 solver.cpp:228] Iteration 36800, loss = 0.287242
I0823 11:14:06.016285 28265 solver.cpp:244]     Train net output #0: loss = 0.287242 (* 1 = 0.287242 loss)
I0823 11:14:06.016297 28265 sgd_solver.cpp:106] Iteration 36800, lr = 0.000338254
I0823 11:14:10.544283 28265 solver.cpp:228] Iteration 36900, loss = 0.449228
I0823 11:14:10.544337 28265 solver.cpp:244]     Train net output #0: loss = 0.449228 (* 1 = 0.449228 loss)
I0823 11:14:10.544345 28265 sgd_solver.cpp:106] Iteration 36900, lr = 0.000337808
I0823 11:14:15.037173 28265 solver.cpp:337] Iteration 37000, Testing net (#0)
I0823 11:14:18.426865 28265 solver.cpp:404]     Test net output #0: accuracy = 0.828042
I0823 11:14:18.426941 28265 solver.cpp:404]     Test net output #1: loss = 0.420365 (* 1 = 0.420365 loss)
I0823 11:14:18.442749 28265 solver.cpp:228] Iteration 37000, loss = 0.367847
I0823 11:14:18.442808 28265 solver.cpp:244]     Train net output #0: loss = 0.367847 (* 1 = 0.367847 loss)
I0823 11:14:18.442824 28265 sgd_solver.cpp:106] Iteration 37000, lr = 0.000337363
I0823 11:14:22.970150 28265 solver.cpp:228] Iteration 37100, loss = 0.373031
I0823 11:14:22.970216 28265 solver.cpp:244]     Train net output #0: loss = 0.373031 (* 1 = 0.373031 loss)
I0823 11:14:22.970227 28265 sgd_solver.cpp:106] Iteration 37100, lr = 0.00033692
I0823 11:14:27.497270 28265 solver.cpp:228] Iteration 37200, loss = 0.52294
I0823 11:14:27.497313 28265 solver.cpp:244]     Train net output #0: loss = 0.52294 (* 1 = 0.52294 loss)
I0823 11:14:27.497319 28265 sgd_solver.cpp:106] Iteration 37200, lr = 0.000336478
I0823 11:14:32.025007 28265 solver.cpp:228] Iteration 37300, loss = 0.378552
I0823 11:14:32.025050 28265 solver.cpp:244]     Train net output #0: loss = 0.378552 (* 1 = 0.378552 loss)
I0823 11:14:32.025056 28265 sgd_solver.cpp:106] Iteration 37300, lr = 0.000336038
I0823 11:14:36.553794 28265 solver.cpp:228] Iteration 37400, loss = 0.353201
I0823 11:14:36.553838 28265 solver.cpp:244]     Train net output #0: loss = 0.353201 (* 1 = 0.353201 loss)
I0823 11:14:36.553844 28265 sgd_solver.cpp:106] Iteration 37400, lr = 0.000335599
I0823 11:14:41.036226 28265 solver.cpp:337] Iteration 37500, Testing net (#0)
I0823 11:14:41.735424 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:14:44.370923 28265 solver.cpp:404]     Test net output #0: accuracy = 0.798375
I0823 11:14:44.370978 28265 solver.cpp:404]     Test net output #1: loss = 0.49814 (* 1 = 0.49814 loss)
I0823 11:14:44.386683 28265 solver.cpp:228] Iteration 37500, loss = 0.320803
I0823 11:14:44.386741 28265 solver.cpp:244]     Train net output #0: loss = 0.320803 (* 1 = 0.320803 loss)
I0823 11:14:44.386761 28265 sgd_solver.cpp:106] Iteration 37500, lr = 0.000335161
I0823 11:14:48.910835 28265 solver.cpp:228] Iteration 37600, loss = 0.413965
I0823 11:14:48.910892 28265 solver.cpp:244]     Train net output #0: loss = 0.413965 (* 1 = 0.413965 loss)
I0823 11:14:48.910897 28265 sgd_solver.cpp:106] Iteration 37600, lr = 0.000334724
I0823 11:14:53.435443 28265 solver.cpp:228] Iteration 37700, loss = 0.370171
I0823 11:14:53.435498 28265 solver.cpp:244]     Train net output #0: loss = 0.370171 (* 1 = 0.370171 loss)
I0823 11:14:53.435505 28265 sgd_solver.cpp:106] Iteration 37700, lr = 0.000334289
I0823 11:14:57.983458 28265 solver.cpp:228] Iteration 37800, loss = 0.41398
I0823 11:14:57.983511 28265 solver.cpp:244]     Train net output #0: loss = 0.41398 (* 1 = 0.41398 loss)
I0823 11:14:57.983520 28265 sgd_solver.cpp:106] Iteration 37800, lr = 0.000333855
I0823 11:15:02.513309 28265 solver.cpp:228] Iteration 37900, loss = 0.2767
I0823 11:15:02.513358 28265 solver.cpp:244]     Train net output #0: loss = 0.2767 (* 1 = 0.2767 loss)
I0823 11:15:02.513363 28265 sgd_solver.cpp:106] Iteration 37900, lr = 0.000333423
I0823 11:15:06.995959 28265 solver.cpp:337] Iteration 38000, Testing net (#0)
I0823 11:15:10.511999 28265 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0823 11:15:10.512106 28265 solver.cpp:404]     Test net output #1: loss = 0.578589 (* 1 = 0.578589 loss)
I0823 11:15:10.528280 28265 solver.cpp:228] Iteration 38000, loss = 0.329974
I0823 11:15:10.528309 28265 solver.cpp:244]     Train net output #0: loss = 0.329974 (* 1 = 0.329974 loss)
I0823 11:15:10.528317 28265 sgd_solver.cpp:106] Iteration 38000, lr = 0.000332992
I0823 11:15:15.057487 28265 solver.cpp:228] Iteration 38100, loss = 0.343943
I0823 11:15:15.057530 28265 solver.cpp:244]     Train net output #0: loss = 0.343943 (* 1 = 0.343943 loss)
I0823 11:15:15.057536 28265 sgd_solver.cpp:106] Iteration 38100, lr = 0.000332562
I0823 11:15:19.583895 28265 solver.cpp:228] Iteration 38200, loss = 0.375622
I0823 11:15:19.583938 28265 solver.cpp:244]     Train net output #0: loss = 0.375622 (* 1 = 0.375622 loss)
I0823 11:15:19.583943 28265 sgd_solver.cpp:106] Iteration 38200, lr = 0.000332133
I0823 11:15:24.111187 28265 solver.cpp:228] Iteration 38300, loss = 0.381189
I0823 11:15:24.111207 28265 solver.cpp:244]     Train net output #0: loss = 0.381189 (* 1 = 0.381189 loss)
I0823 11:15:24.111212 28265 sgd_solver.cpp:106] Iteration 38300, lr = 0.000331706
I0823 11:15:28.634785 28265 solver.cpp:228] Iteration 38400, loss = 0.236349
I0823 11:15:28.634806 28265 solver.cpp:244]     Train net output #0: loss = 0.236349 (* 1 = 0.236349 loss)
I0823 11:15:28.634811 28265 sgd_solver.cpp:106] Iteration 38400, lr = 0.00033128
I0823 11:15:33.112468 28265 solver.cpp:337] Iteration 38500, Testing net (#0)
I0823 11:15:36.594321 28265 solver.cpp:404]     Test net output #0: accuracy = 0.835083
I0823 11:15:36.594370 28265 solver.cpp:404]     Test net output #1: loss = 0.405854 (* 1 = 0.405854 loss)
I0823 11:15:36.609035 28265 solver.cpp:228] Iteration 38500, loss = 0.238232
I0823 11:15:36.609081 28265 solver.cpp:244]     Train net output #0: loss = 0.238232 (* 1 = 0.238232 loss)
I0823 11:15:36.609091 28265 sgd_solver.cpp:106] Iteration 38500, lr = 0.000330855
I0823 11:15:41.141732 28265 solver.cpp:228] Iteration 38600, loss = 0.51899
I0823 11:15:41.141774 28265 solver.cpp:244]     Train net output #0: loss = 0.51899 (* 1 = 0.51899 loss)
I0823 11:15:41.141780 28265 sgd_solver.cpp:106] Iteration 38600, lr = 0.000330431
I0823 11:15:45.671166 28265 solver.cpp:228] Iteration 38700, loss = 0.312689
I0823 11:15:45.671216 28265 solver.cpp:244]     Train net output #0: loss = 0.312689 (* 1 = 0.312689 loss)
I0823 11:15:45.671221 28265 sgd_solver.cpp:106] Iteration 38700, lr = 0.000330009
I0823 11:15:50.196199 28265 solver.cpp:228] Iteration 38800, loss = 0.364505
I0823 11:15:50.196260 28265 solver.cpp:244]     Train net output #0: loss = 0.364505 (* 1 = 0.364505 loss)
I0823 11:15:50.196269 28265 sgd_solver.cpp:106] Iteration 38800, lr = 0.000329588
I0823 11:15:54.721990 28265 solver.cpp:228] Iteration 38900, loss = 0.448795
I0823 11:15:54.722033 28265 solver.cpp:244]     Train net output #0: loss = 0.448795 (* 1 = 0.448795 loss)
I0823 11:15:54.722039 28265 sgd_solver.cpp:106] Iteration 38900, lr = 0.000329168
I0823 11:15:59.200029 28265 solver.cpp:337] Iteration 39000, Testing net (#0)
I0823 11:16:02.772017 28265 solver.cpp:404]     Test net output #0: accuracy = 0.804792
I0823 11:16:02.772089 28265 solver.cpp:404]     Test net output #1: loss = 0.501997 (* 1 = 0.501997 loss)
I0823 11:16:02.787513 28265 solver.cpp:228] Iteration 39000, loss = 0.305702
I0823 11:16:02.787544 28265 solver.cpp:244]     Train net output #0: loss = 0.305702 (* 1 = 0.305702 loss)
I0823 11:16:02.787556 28265 sgd_solver.cpp:106] Iteration 39000, lr = 0.00032875
I0823 11:16:07.313812 28265 solver.cpp:228] Iteration 39100, loss = 0.393283
I0823 11:16:07.313859 28265 solver.cpp:244]     Train net output #0: loss = 0.393283 (* 1 = 0.393283 loss)
I0823 11:16:07.313864 28265 sgd_solver.cpp:106] Iteration 39100, lr = 0.000328332
I0823 11:16:11.843968 28265 solver.cpp:228] Iteration 39200, loss = 0.291065
I0823 11:16:11.844015 28265 solver.cpp:244]     Train net output #0: loss = 0.291065 (* 1 = 0.291065 loss)
I0823 11:16:11.844020 28265 sgd_solver.cpp:106] Iteration 39200, lr = 0.000327916
I0823 11:16:16.371253 28265 solver.cpp:228] Iteration 39300, loss = 0.329182
I0823 11:16:16.371299 28265 solver.cpp:244]     Train net output #0: loss = 0.329182 (* 1 = 0.329182 loss)
I0823 11:16:16.371304 28265 sgd_solver.cpp:106] Iteration 39300, lr = 0.000327501
I0823 11:16:20.902180 28265 solver.cpp:228] Iteration 39400, loss = 0.300354
I0823 11:16:20.902228 28265 solver.cpp:244]     Train net output #0: loss = 0.300354 (* 1 = 0.300354 loss)
I0823 11:16:20.902233 28265 sgd_solver.cpp:106] Iteration 39400, lr = 0.000327088
I0823 11:16:25.399852 28265 solver.cpp:337] Iteration 39500, Testing net (#0)
I0823 11:16:28.735641 28265 solver.cpp:404]     Test net output #0: accuracy = 0.831917
I0823 11:16:28.735707 28265 solver.cpp:404]     Test net output #1: loss = 0.43049 (* 1 = 0.43049 loss)
I0823 11:16:28.752698 28265 solver.cpp:228] Iteration 39500, loss = 0.381667
I0823 11:16:28.752754 28265 solver.cpp:244]     Train net output #0: loss = 0.381667 (* 1 = 0.381667 loss)
I0823 11:16:28.752768 28265 sgd_solver.cpp:106] Iteration 39500, lr = 0.000326675
I0823 11:16:33.284724 28265 solver.cpp:228] Iteration 39600, loss = 0.366368
I0823 11:16:33.284770 28265 solver.cpp:244]     Train net output #0: loss = 0.366368 (* 1 = 0.366368 loss)
I0823 11:16:33.284775 28265 sgd_solver.cpp:106] Iteration 39600, lr = 0.000326264
I0823 11:16:37.812674 28265 solver.cpp:228] Iteration 39700, loss = 0.199401
I0823 11:16:37.812721 28265 solver.cpp:244]     Train net output #0: loss = 0.199401 (* 1 = 0.199401 loss)
I0823 11:16:37.812726 28265 sgd_solver.cpp:106] Iteration 39700, lr = 0.000325854
I0823 11:16:42.343601 28265 solver.cpp:228] Iteration 39800, loss = 0.386785
I0823 11:16:42.343650 28265 solver.cpp:244]     Train net output #0: loss = 0.386785 (* 1 = 0.386785 loss)
I0823 11:16:42.343657 28265 sgd_solver.cpp:106] Iteration 39800, lr = 0.000325446
I0823 11:16:46.865665 28265 solver.cpp:228] Iteration 39900, loss = 0.305716
I0823 11:16:46.865741 28265 solver.cpp:244]     Train net output #0: loss = 0.305716 (* 1 = 0.305716 loss)
I0823 11:16:46.865746 28265 sgd_solver.cpp:106] Iteration 39900, lr = 0.000325038
I0823 11:16:51.345247 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_40000.caffemodel
I0823 11:16:51.822495 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_40000.solverstate
I0823 11:16:51.978082 28265 solver.cpp:337] Iteration 40000, Testing net (#0)
I0823 11:16:55.258031 28265 solver.cpp:404]     Test net output #0: accuracy = 0.834209
I0823 11:16:55.258097 28265 solver.cpp:404]     Test net output #1: loss = 0.421344 (* 1 = 0.421344 loss)
I0823 11:16:55.273815 28265 solver.cpp:228] Iteration 40000, loss = 0.31837
I0823 11:16:55.273851 28265 solver.cpp:244]     Train net output #0: loss = 0.31837 (* 1 = 0.31837 loss)
I0823 11:16:55.273865 28265 sgd_solver.cpp:106] Iteration 40000, lr = 0.000324632
I0823 11:16:59.804126 28265 solver.cpp:228] Iteration 40100, loss = 0.318665
I0823 11:16:59.804174 28265 solver.cpp:244]     Train net output #0: loss = 0.318665 (* 1 = 0.318665 loss)
I0823 11:16:59.804180 28265 sgd_solver.cpp:106] Iteration 40100, lr = 0.000324226
I0823 11:17:04.337985 28265 solver.cpp:228] Iteration 40200, loss = 0.354417
I0823 11:17:04.338042 28265 solver.cpp:244]     Train net output #0: loss = 0.354417 (* 1 = 0.354417 loss)
I0823 11:17:04.338048 28265 sgd_solver.cpp:106] Iteration 40200, lr = 0.000323822
I0823 11:17:08.870851 28265 solver.cpp:228] Iteration 40300, loss = 0.331926
I0823 11:17:08.870905 28265 solver.cpp:244]     Train net output #0: loss = 0.331926 (* 1 = 0.331926 loss)
I0823 11:17:08.870913 28265 sgd_solver.cpp:106] Iteration 40300, lr = 0.00032342
I0823 11:17:13.397019 28265 solver.cpp:228] Iteration 40400, loss = 0.388993
I0823 11:17:13.397069 28265 solver.cpp:244]     Train net output #0: loss = 0.388993 (* 1 = 0.388993 loss)
I0823 11:17:13.397074 28265 sgd_solver.cpp:106] Iteration 40400, lr = 0.000323018
I0823 11:17:17.874830 28265 solver.cpp:337] Iteration 40500, Testing net (#0)
I0823 11:17:20.957469 28265 solver.cpp:404]     Test net output #0: accuracy = 0.74275
I0823 11:17:20.957511 28265 solver.cpp:404]     Test net output #1: loss = 0.703065 (* 1 = 0.703065 loss)
I0823 11:17:20.972741 28265 solver.cpp:228] Iteration 40500, loss = 0.447311
I0823 11:17:20.972781 28265 solver.cpp:244]     Train net output #0: loss = 0.447311 (* 1 = 0.447311 loss)
I0823 11:17:20.972790 28265 sgd_solver.cpp:106] Iteration 40500, lr = 0.000322617
I0823 11:17:25.498409 28265 solver.cpp:228] Iteration 40600, loss = 0.443184
I0823 11:17:25.498456 28265 solver.cpp:244]     Train net output #0: loss = 0.443184 (* 1 = 0.443184 loss)
I0823 11:17:25.498461 28265 sgd_solver.cpp:106] Iteration 40600, lr = 0.000322218
I0823 11:17:30.026075 28265 solver.cpp:228] Iteration 40700, loss = 0.242217
I0823 11:17:30.026135 28265 solver.cpp:244]     Train net output #0: loss = 0.242217 (* 1 = 0.242217 loss)
I0823 11:17:30.026146 28265 sgd_solver.cpp:106] Iteration 40700, lr = 0.00032182
I0823 11:17:34.559118 28265 solver.cpp:228] Iteration 40800, loss = 0.381059
I0823 11:17:34.559162 28265 solver.cpp:244]     Train net output #0: loss = 0.381059 (* 1 = 0.381059 loss)
I0823 11:17:34.559168 28265 sgd_solver.cpp:106] Iteration 40800, lr = 0.000321423
I0823 11:17:39.097779 28265 solver.cpp:228] Iteration 40900, loss = 0.285054
I0823 11:17:39.097823 28265 solver.cpp:244]     Train net output #0: loss = 0.285054 (* 1 = 0.285054 loss)
I0823 11:17:39.097828 28265 sgd_solver.cpp:106] Iteration 40900, lr = 0.000321027
I0823 11:17:43.575502 28265 solver.cpp:337] Iteration 41000, Testing net (#0)
I0823 11:17:44.523717 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:17:46.892236 28265 solver.cpp:404]     Test net output #0: accuracy = 0.815875
I0823 11:17:46.892271 28265 solver.cpp:404]     Test net output #1: loss = 0.474698 (* 1 = 0.474698 loss)
I0823 11:17:46.907490 28265 solver.cpp:228] Iteration 41000, loss = 0.3727
I0823 11:17:46.907526 28265 solver.cpp:244]     Train net output #0: loss = 0.3727 (* 1 = 0.3727 loss)
I0823 11:17:46.907537 28265 sgd_solver.cpp:106] Iteration 41000, lr = 0.000320632
I0823 11:17:51.434700 28265 solver.cpp:228] Iteration 41100, loss = 0.250518
I0823 11:17:51.434742 28265 solver.cpp:244]     Train net output #0: loss = 0.250518 (* 1 = 0.250518 loss)
I0823 11:17:51.434747 28265 sgd_solver.cpp:106] Iteration 41100, lr = 0.000320238
I0823 11:17:55.961076 28265 solver.cpp:228] Iteration 41200, loss = 0.314295
I0823 11:17:55.961160 28265 solver.cpp:244]     Train net output #0: loss = 0.314295 (* 1 = 0.314295 loss)
I0823 11:17:55.961175 28265 sgd_solver.cpp:106] Iteration 41200, lr = 0.000319846
I0823 11:18:00.487967 28265 solver.cpp:228] Iteration 41300, loss = 0.353563
I0823 11:18:00.488028 28265 solver.cpp:244]     Train net output #0: loss = 0.353563 (* 1 = 0.353563 loss)
I0823 11:18:00.488037 28265 sgd_solver.cpp:106] Iteration 41300, lr = 0.000319454
I0823 11:18:05.016278 28265 solver.cpp:228] Iteration 41400, loss = 0.32397
I0823 11:18:05.016356 28265 solver.cpp:244]     Train net output #0: loss = 0.32397 (* 1 = 0.32397 loss)
I0823 11:18:05.016369 28265 sgd_solver.cpp:106] Iteration 41400, lr = 0.000319064
I0823 11:18:09.497469 28265 solver.cpp:337] Iteration 41500, Testing net (#0)
I0823 11:18:12.865134 28265 solver.cpp:404]     Test net output #0: accuracy = 0.809292
I0823 11:18:12.865193 28265 solver.cpp:404]     Test net output #1: loss = 0.484913 (* 1 = 0.484913 loss)
I0823 11:18:12.881454 28265 solver.cpp:228] Iteration 41500, loss = 0.454112
I0823 11:18:12.881486 28265 solver.cpp:244]     Train net output #0: loss = 0.454112 (* 1 = 0.454112 loss)
I0823 11:18:12.881500 28265 sgd_solver.cpp:106] Iteration 41500, lr = 0.000318675
I0823 11:18:17.402021 28265 solver.cpp:228] Iteration 41600, loss = 0.239567
I0823 11:18:17.402070 28265 solver.cpp:244]     Train net output #0: loss = 0.239567 (* 1 = 0.239567 loss)
I0823 11:18:17.402076 28265 sgd_solver.cpp:106] Iteration 41600, lr = 0.000318287
I0823 11:18:21.925542 28265 solver.cpp:228] Iteration 41700, loss = 0.28177
I0823 11:18:21.925612 28265 solver.cpp:244]     Train net output #0: loss = 0.28177 (* 1 = 0.28177 loss)
I0823 11:18:21.925619 28265 sgd_solver.cpp:106] Iteration 41700, lr = 0.0003179
I0823 11:18:26.445504 28265 solver.cpp:228] Iteration 41800, loss = 0.331974
I0823 11:18:26.445570 28265 solver.cpp:244]     Train net output #0: loss = 0.331974 (* 1 = 0.331974 loss)
I0823 11:18:26.445575 28265 sgd_solver.cpp:106] Iteration 41800, lr = 0.000317514
I0823 11:18:30.970685 28265 solver.cpp:228] Iteration 41900, loss = 0.459131
I0823 11:18:30.970731 28265 solver.cpp:244]     Train net output #0: loss = 0.459131 (* 1 = 0.459131 loss)
I0823 11:18:30.970736 28265 sgd_solver.cpp:106] Iteration 41900, lr = 0.000317129
I0823 11:18:35.446408 28265 solver.cpp:337] Iteration 42000, Testing net (#0)
I0823 11:18:39.052436 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844125
I0823 11:18:39.052490 28265 solver.cpp:404]     Test net output #1: loss = 0.393784 (* 1 = 0.393784 loss)
I0823 11:18:39.067600 28265 solver.cpp:228] Iteration 42000, loss = 0.325001
I0823 11:18:39.067646 28265 solver.cpp:244]     Train net output #0: loss = 0.325001 (* 1 = 0.325001 loss)
I0823 11:18:39.067657 28265 sgd_solver.cpp:106] Iteration 42000, lr = 0.000316745
I0823 11:18:43.606148 28265 solver.cpp:228] Iteration 42100, loss = 0.32301
I0823 11:18:43.606209 28265 solver.cpp:244]     Train net output #0: loss = 0.32301 (* 1 = 0.32301 loss)
I0823 11:18:43.606215 28265 sgd_solver.cpp:106] Iteration 42100, lr = 0.000316363
I0823 11:18:48.141664 28265 solver.cpp:228] Iteration 42200, loss = 0.384245
I0823 11:18:48.141711 28265 solver.cpp:244]     Train net output #0: loss = 0.384245 (* 1 = 0.384245 loss)
I0823 11:18:48.141717 28265 sgd_solver.cpp:106] Iteration 42200, lr = 0.000315981
I0823 11:18:52.659101 28265 solver.cpp:228] Iteration 42300, loss = 0.232653
I0823 11:18:52.659121 28265 solver.cpp:244]     Train net output #0: loss = 0.232653 (* 1 = 0.232653 loss)
I0823 11:18:52.659124 28265 sgd_solver.cpp:106] Iteration 42300, lr = 0.000315601
I0823 11:18:57.180075 28265 solver.cpp:228] Iteration 42400, loss = 0.334957
I0823 11:18:57.180096 28265 solver.cpp:244]     Train net output #0: loss = 0.334957 (* 1 = 0.334957 loss)
I0823 11:18:57.180101 28265 sgd_solver.cpp:106] Iteration 42400, lr = 0.000315221
I0823 11:19:01.659127 28265 solver.cpp:337] Iteration 42500, Testing net (#0)
I0823 11:19:05.074887 28265 solver.cpp:404]     Test net output #0: accuracy = 0.791416
I0823 11:19:05.074935 28265 solver.cpp:404]     Test net output #1: loss = 0.555355 (* 1 = 0.555355 loss)
I0823 11:19:05.089646 28265 solver.cpp:228] Iteration 42500, loss = 0.270534
I0823 11:19:05.089689 28265 solver.cpp:244]     Train net output #0: loss = 0.270534 (* 1 = 0.270534 loss)
I0823 11:19:05.089700 28265 sgd_solver.cpp:106] Iteration 42500, lr = 0.000314843
I0823 11:19:09.611251 28265 solver.cpp:228] Iteration 42600, loss = 0.312214
I0823 11:19:09.611309 28265 solver.cpp:244]     Train net output #0: loss = 0.312214 (* 1 = 0.312214 loss)
I0823 11:19:09.611317 28265 sgd_solver.cpp:106] Iteration 42600, lr = 0.000314466
I0823 11:19:14.135938 28265 solver.cpp:228] Iteration 42700, loss = 0.288745
I0823 11:19:14.135996 28265 solver.cpp:244]     Train net output #0: loss = 0.288745 (* 1 = 0.288745 loss)
I0823 11:19:14.136003 28265 sgd_solver.cpp:106] Iteration 42700, lr = 0.00031409
I0823 11:19:18.663103 28265 solver.cpp:228] Iteration 42800, loss = 0.334661
I0823 11:19:18.663144 28265 solver.cpp:244]     Train net output #0: loss = 0.334661 (* 1 = 0.334661 loss)
I0823 11:19:18.663151 28265 sgd_solver.cpp:106] Iteration 42800, lr = 0.000313714
I0823 11:19:23.197263 28265 solver.cpp:228] Iteration 42900, loss = 0.215668
I0823 11:19:23.197309 28265 solver.cpp:244]     Train net output #0: loss = 0.215668 (* 1 = 0.215668 loss)
I0823 11:19:23.197314 28265 sgd_solver.cpp:106] Iteration 42900, lr = 0.00031334
I0823 11:19:27.674579 28265 solver.cpp:337] Iteration 43000, Testing net (#0)
I0823 11:19:31.298295 28265 solver.cpp:404]     Test net output #0: accuracy = 0.837625
I0823 11:19:31.298357 28265 solver.cpp:404]     Test net output #1: loss = 0.419012 (* 1 = 0.419012 loss)
I0823 11:19:31.314704 28265 solver.cpp:228] Iteration 43000, loss = 0.288053
I0823 11:19:31.314738 28265 solver.cpp:244]     Train net output #0: loss = 0.288053 (* 1 = 0.288053 loss)
I0823 11:19:31.314749 28265 sgd_solver.cpp:106] Iteration 43000, lr = 0.000312967
I0823 11:19:35.836664 28265 solver.cpp:228] Iteration 43100, loss = 0.296766
I0823 11:19:35.836707 28265 solver.cpp:244]     Train net output #0: loss = 0.296766 (* 1 = 0.296766 loss)
I0823 11:19:35.836714 28265 sgd_solver.cpp:106] Iteration 43100, lr = 0.000312595
I0823 11:19:40.360759 28265 solver.cpp:228] Iteration 43200, loss = 0.263787
I0823 11:19:40.360801 28265 solver.cpp:244]     Train net output #0: loss = 0.263787 (* 1 = 0.263787 loss)
I0823 11:19:40.360807 28265 sgd_solver.cpp:106] Iteration 43200, lr = 0.000312224
I0823 11:19:44.888463 28265 solver.cpp:228] Iteration 43300, loss = 0.215711
I0823 11:19:44.888542 28265 solver.cpp:244]     Train net output #0: loss = 0.215711 (* 1 = 0.215711 loss)
I0823 11:19:44.888551 28265 sgd_solver.cpp:106] Iteration 43300, lr = 0.000311854
I0823 11:19:49.423090 28265 solver.cpp:228] Iteration 43400, loss = 0.338513
I0823 11:19:49.423141 28265 solver.cpp:244]     Train net output #0: loss = 0.338513 (* 1 = 0.338513 loss)
I0823 11:19:49.423146 28265 sgd_solver.cpp:106] Iteration 43400, lr = 0.000311485
I0823 11:19:53.906262 28265 solver.cpp:337] Iteration 43500, Testing net (#0)
I0823 11:19:57.427984 28265 solver.cpp:404]     Test net output #0: accuracy = 0.803542
I0823 11:19:57.428030 28265 solver.cpp:404]     Test net output #1: loss = 0.527248 (* 1 = 0.527248 loss)
I0823 11:19:57.442818 28265 solver.cpp:228] Iteration 43500, loss = 0.26609
I0823 11:19:57.442870 28265 solver.cpp:244]     Train net output #0: loss = 0.26609 (* 1 = 0.26609 loss)
I0823 11:19:57.442883 28265 sgd_solver.cpp:106] Iteration 43500, lr = 0.000311117
I0823 11:20:01.966892 28265 solver.cpp:228] Iteration 43600, loss = 0.300926
I0823 11:20:01.966936 28265 solver.cpp:244]     Train net output #0: loss = 0.300926 (* 1 = 0.300926 loss)
I0823 11:20:01.966941 28265 sgd_solver.cpp:106] Iteration 43600, lr = 0.00031075
I0823 11:20:06.488564 28265 solver.cpp:228] Iteration 43700, loss = 0.262234
I0823 11:20:06.488610 28265 solver.cpp:244]     Train net output #0: loss = 0.262234 (* 1 = 0.262234 loss)
I0823 11:20:06.488615 28265 sgd_solver.cpp:106] Iteration 43700, lr = 0.000310384
I0823 11:20:11.008900 28265 solver.cpp:228] Iteration 43800, loss = 0.331445
I0823 11:20:11.008944 28265 solver.cpp:244]     Train net output #0: loss = 0.331445 (* 1 = 0.331445 loss)
I0823 11:20:11.008949 28265 sgd_solver.cpp:106] Iteration 43800, lr = 0.000310019
I0823 11:20:15.535840 28265 solver.cpp:228] Iteration 43900, loss = 0.270418
I0823 11:20:15.535886 28265 solver.cpp:244]     Train net output #0: loss = 0.270418 (* 1 = 0.270418 loss)
I0823 11:20:15.535892 28265 sgd_solver.cpp:106] Iteration 43900, lr = 0.000309655
I0823 11:20:20.019589 28265 solver.cpp:337] Iteration 44000, Testing net (#0)
I0823 11:20:20.284231 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:20:23.550539 28265 solver.cpp:404]     Test net output #0: accuracy = 0.838917
I0823 11:20:23.550590 28265 solver.cpp:404]     Test net output #1: loss = 0.420513 (* 1 = 0.420513 loss)
I0823 11:20:23.566193 28265 solver.cpp:228] Iteration 44000, loss = 0.202023
I0823 11:20:23.566244 28265 solver.cpp:244]     Train net output #0: loss = 0.202023 (* 1 = 0.202023 loss)
I0823 11:20:23.566260 28265 sgd_solver.cpp:106] Iteration 44000, lr = 0.000309292
I0823 11:20:28.091195 28265 solver.cpp:228] Iteration 44100, loss = 0.351093
I0823 11:20:28.091240 28265 solver.cpp:244]     Train net output #0: loss = 0.351093 (* 1 = 0.351093 loss)
I0823 11:20:28.091245 28265 sgd_solver.cpp:106] Iteration 44100, lr = 0.00030893
I0823 11:20:32.608522 28265 solver.cpp:228] Iteration 44200, loss = 0.194706
I0823 11:20:32.608595 28265 solver.cpp:244]     Train net output #0: loss = 0.194706 (* 1 = 0.194706 loss)
I0823 11:20:32.608602 28265 sgd_solver.cpp:106] Iteration 44200, lr = 0.000308569
I0823 11:20:37.125516 28265 solver.cpp:228] Iteration 44300, loss = 0.301009
I0823 11:20:37.125586 28265 solver.cpp:244]     Train net output #0: loss = 0.301009 (* 1 = 0.301009 loss)
I0823 11:20:37.125591 28265 sgd_solver.cpp:106] Iteration 44300, lr = 0.000308209
I0823 11:20:41.654367 28265 solver.cpp:228] Iteration 44400, loss = 0.29536
I0823 11:20:41.654417 28265 solver.cpp:244]     Train net output #0: loss = 0.29536 (* 1 = 0.29536 loss)
I0823 11:20:41.654422 28265 sgd_solver.cpp:106] Iteration 44400, lr = 0.00030785
I0823 11:20:46.132941 28265 solver.cpp:337] Iteration 44500, Testing net (#0)
I0823 11:20:49.703300 28265 solver.cpp:404]     Test net output #0: accuracy = 0.8365
I0823 11:20:49.703369 28265 solver.cpp:404]     Test net output #1: loss = 0.430403 (* 1 = 0.430403 loss)
I0823 11:20:49.718750 28265 solver.cpp:228] Iteration 44500, loss = 0.201847
I0823 11:20:49.718801 28265 solver.cpp:244]     Train net output #0: loss = 0.201847 (* 1 = 0.201847 loss)
I0823 11:20:49.718816 28265 sgd_solver.cpp:106] Iteration 44500, lr = 0.000307492
I0823 11:20:54.239637 28265 solver.cpp:228] Iteration 44600, loss = 0.284566
I0823 11:20:54.239686 28265 solver.cpp:244]     Train net output #0: loss = 0.284566 (* 1 = 0.284566 loss)
I0823 11:20:54.239693 28265 sgd_solver.cpp:106] Iteration 44600, lr = 0.000307135
I0823 11:20:58.763145 28265 solver.cpp:228] Iteration 44700, loss = 0.22962
I0823 11:20:58.763164 28265 solver.cpp:244]     Train net output #0: loss = 0.22962 (* 1 = 0.22962 loss)
I0823 11:20:58.763169 28265 sgd_solver.cpp:106] Iteration 44700, lr = 0.000306779
I0823 11:21:03.280992 28265 solver.cpp:228] Iteration 44800, loss = 0.217635
I0823 11:21:03.281011 28265 solver.cpp:244]     Train net output #0: loss = 0.217635 (* 1 = 0.217635 loss)
I0823 11:21:03.281016 28265 sgd_solver.cpp:106] Iteration 44800, lr = 0.000306424
I0823 11:21:07.804040 28265 solver.cpp:228] Iteration 44900, loss = 0.280774
I0823 11:21:07.804085 28265 solver.cpp:244]     Train net output #0: loss = 0.280774 (* 1 = 0.280774 loss)
I0823 11:21:07.804091 28265 sgd_solver.cpp:106] Iteration 44900, lr = 0.00030607
I0823 11:21:12.283188 28265 solver.cpp:337] Iteration 45000, Testing net (#0)
I0823 11:21:15.893587 28265 solver.cpp:404]     Test net output #0: accuracy = 0.834334
I0823 11:21:15.893651 28265 solver.cpp:404]     Test net output #1: loss = 0.446541 (* 1 = 0.446541 loss)
I0823 11:21:15.909039 28265 solver.cpp:228] Iteration 45000, loss = 0.193754
I0823 11:21:15.909102 28265 solver.cpp:244]     Train net output #0: loss = 0.193754 (* 1 = 0.193754 loss)
I0823 11:21:15.909117 28265 sgd_solver.cpp:106] Iteration 45000, lr = 0.000305717
I0823 11:21:20.432886 28265 solver.cpp:228] Iteration 45100, loss = 0.237696
I0823 11:21:20.432934 28265 solver.cpp:244]     Train net output #0: loss = 0.237696 (* 1 = 0.237696 loss)
I0823 11:21:20.432940 28265 sgd_solver.cpp:106] Iteration 45100, lr = 0.000305364
I0823 11:21:24.954141 28265 solver.cpp:228] Iteration 45200, loss = 0.329262
I0823 11:21:24.954162 28265 solver.cpp:244]     Train net output #0: loss = 0.329262 (* 1 = 0.329262 loss)
I0823 11:21:24.954166 28265 sgd_solver.cpp:106] Iteration 45200, lr = 0.000305013
I0823 11:21:29.481870 28265 solver.cpp:228] Iteration 45300, loss = 0.199302
I0823 11:21:29.481925 28265 solver.cpp:244]     Train net output #0: loss = 0.199302 (* 1 = 0.199302 loss)
I0823 11:21:29.481933 28265 sgd_solver.cpp:106] Iteration 45300, lr = 0.000304663
I0823 11:21:34.009018 28265 solver.cpp:228] Iteration 45400, loss = 0.225159
I0823 11:21:34.009095 28265 solver.cpp:244]     Train net output #0: loss = 0.225159 (* 1 = 0.225159 loss)
I0823 11:21:34.009110 28265 sgd_solver.cpp:106] Iteration 45400, lr = 0.000304313
I0823 11:21:38.484459 28265 solver.cpp:337] Iteration 45500, Testing net (#0)
I0823 11:21:41.884960 28265 solver.cpp:404]     Test net output #0: accuracy = 0.783083
I0823 11:21:41.885022 28265 solver.cpp:404]     Test net output #1: loss = 0.633628 (* 1 = 0.633628 loss)
I0823 11:21:41.900902 28265 solver.cpp:228] Iteration 45500, loss = 0.236503
I0823 11:21:41.900959 28265 solver.cpp:244]     Train net output #0: loss = 0.236503 (* 1 = 0.236503 loss)
I0823 11:21:41.900974 28265 sgd_solver.cpp:106] Iteration 45500, lr = 0.000303965
I0823 11:21:46.425038 28265 solver.cpp:228] Iteration 45600, loss = 0.279949
I0823 11:21:46.425099 28265 solver.cpp:244]     Train net output #0: loss = 0.279949 (* 1 = 0.279949 loss)
I0823 11:21:46.425108 28265 sgd_solver.cpp:106] Iteration 45600, lr = 0.000303617
I0823 11:21:50.948051 28265 solver.cpp:228] Iteration 45700, loss = 0.281879
I0823 11:21:50.948113 28265 solver.cpp:244]     Train net output #0: loss = 0.281879 (* 1 = 0.281879 loss)
I0823 11:21:50.948122 28265 sgd_solver.cpp:106] Iteration 45700, lr = 0.000303271
I0823 11:21:55.473023 28265 solver.cpp:228] Iteration 45800, loss = 0.366486
I0823 11:21:55.473068 28265 solver.cpp:244]     Train net output #0: loss = 0.366486 (* 1 = 0.366486 loss)
I0823 11:21:55.473074 28265 sgd_solver.cpp:106] Iteration 45800, lr = 0.000302925
I0823 11:21:59.997390 28265 solver.cpp:228] Iteration 45900, loss = 0.102093
I0823 11:21:59.997447 28265 solver.cpp:244]     Train net output #0: loss = 0.102093 (* 1 = 0.102093 loss)
I0823 11:21:59.997452 28265 sgd_solver.cpp:106] Iteration 45900, lr = 0.00030258
I0823 11:22:04.478657 28265 solver.cpp:337] Iteration 46000, Testing net (#0)
I0823 11:22:07.863283 28265 solver.cpp:404]     Test net output #0: accuracy = 0.814417
I0823 11:22:07.863332 28265 solver.cpp:404]     Test net output #1: loss = 0.533123 (* 1 = 0.533123 loss)
I0823 11:22:07.879459 28265 solver.cpp:228] Iteration 46000, loss = 0.212636
I0823 11:22:07.879499 28265 solver.cpp:244]     Train net output #0: loss = 0.212636 (* 1 = 0.212636 loss)
I0823 11:22:07.879509 28265 sgd_solver.cpp:106] Iteration 46000, lr = 0.000302236
I0823 11:22:12.399793 28265 solver.cpp:228] Iteration 46100, loss = 0.2483
I0823 11:22:12.399842 28265 solver.cpp:244]     Train net output #0: loss = 0.2483 (* 1 = 0.2483 loss)
I0823 11:22:12.399847 28265 sgd_solver.cpp:106] Iteration 46100, lr = 0.000301893
I0823 11:22:16.923501 28265 solver.cpp:228] Iteration 46200, loss = 0.196266
I0823 11:22:16.923573 28265 solver.cpp:244]     Train net output #0: loss = 0.196266 (* 1 = 0.196266 loss)
I0823 11:22:16.923583 28265 sgd_solver.cpp:106] Iteration 46200, lr = 0.000301551
I0823 11:22:21.450332 28265 solver.cpp:228] Iteration 46300, loss = 0.174152
I0823 11:22:21.450378 28265 solver.cpp:244]     Train net output #0: loss = 0.174152 (* 1 = 0.174152 loss)
I0823 11:22:21.450383 28265 sgd_solver.cpp:106] Iteration 46300, lr = 0.00030121
I0823 11:22:25.973366 28265 solver.cpp:228] Iteration 46400, loss = 0.163384
I0823 11:22:25.973414 28265 solver.cpp:244]     Train net output #0: loss = 0.163384 (* 1 = 0.163384 loss)
I0823 11:22:25.973420 28265 sgd_solver.cpp:106] Iteration 46400, lr = 0.000300869
I0823 11:22:30.447643 28265 solver.cpp:337] Iteration 46500, Testing net (#0)
I0823 11:22:31.120796 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:22:34.044453 28265 solver.cpp:404]     Test net output #0: accuracy = 0.833667
I0823 11:22:34.044512 28265 solver.cpp:404]     Test net output #1: loss = 0.479147 (* 1 = 0.479147 loss)
I0823 11:22:34.059888 28265 solver.cpp:228] Iteration 46500, loss = 0.204813
I0823 11:22:34.059921 28265 solver.cpp:244]     Train net output #0: loss = 0.204813 (* 1 = 0.204813 loss)
I0823 11:22:34.059933 28265 sgd_solver.cpp:106] Iteration 46500, lr = 0.00030053
I0823 11:22:38.584072 28265 solver.cpp:228] Iteration 46600, loss = 0.126546
I0823 11:22:38.584113 28265 solver.cpp:244]     Train net output #0: loss = 0.126546 (* 1 = 0.126546 loss)
I0823 11:22:38.584118 28265 sgd_solver.cpp:106] Iteration 46600, lr = 0.000300192
I0823 11:22:43.110139 28265 solver.cpp:228] Iteration 46700, loss = 0.217045
I0823 11:22:43.110199 28265 solver.cpp:244]     Train net output #0: loss = 0.217045 (* 1 = 0.217045 loss)
I0823 11:22:43.110211 28265 sgd_solver.cpp:106] Iteration 46700, lr = 0.000299854
I0823 11:22:47.640931 28265 solver.cpp:228] Iteration 46800, loss = 0.130992
I0823 11:22:47.641008 28265 solver.cpp:244]     Train net output #0: loss = 0.130992 (* 1 = 0.130992 loss)
I0823 11:22:47.641021 28265 sgd_solver.cpp:106] Iteration 46800, lr = 0.000299517
I0823 11:22:52.168294 28265 solver.cpp:228] Iteration 46900, loss = 0.299993
I0823 11:22:52.168349 28265 solver.cpp:244]     Train net output #0: loss = 0.299993 (* 1 = 0.299993 loss)
I0823 11:22:52.168355 28265 sgd_solver.cpp:106] Iteration 46900, lr = 0.000299181
I0823 11:22:56.650679 28265 solver.cpp:337] Iteration 47000, Testing net (#0)
I0823 11:23:00.206511 28265 solver.cpp:404]     Test net output #0: accuracy = 0.842209
I0823 11:23:00.206586 28265 solver.cpp:404]     Test net output #1: loss = 0.46084 (* 1 = 0.46084 loss)
I0823 11:23:00.221988 28265 solver.cpp:228] Iteration 47000, loss = 0.186318
I0823 11:23:00.222031 28265 solver.cpp:244]     Train net output #0: loss = 0.186318 (* 1 = 0.186318 loss)
I0823 11:23:00.222043 28265 sgd_solver.cpp:106] Iteration 47000, lr = 0.000298846
I0823 11:23:04.740597 28265 solver.cpp:228] Iteration 47100, loss = 0.241003
I0823 11:23:04.740639 28265 solver.cpp:244]     Train net output #0: loss = 0.241003 (* 1 = 0.241003 loss)
I0823 11:23:04.740645 28265 sgd_solver.cpp:106] Iteration 47100, lr = 0.000298512
I0823 11:23:09.261714 28265 solver.cpp:228] Iteration 47200, loss = 0.12761
I0823 11:23:09.261771 28265 solver.cpp:244]     Train net output #0: loss = 0.12761 (* 1 = 0.12761 loss)
I0823 11:23:09.261778 28265 sgd_solver.cpp:106] Iteration 47200, lr = 0.000298179
I0823 11:23:13.784605 28265 solver.cpp:228] Iteration 47300, loss = 0.194834
I0823 11:23:13.784648 28265 solver.cpp:244]     Train net output #0: loss = 0.194834 (* 1 = 0.194834 loss)
I0823 11:23:13.784653 28265 sgd_solver.cpp:106] Iteration 47300, lr = 0.000297847
I0823 11:23:18.303988 28265 solver.cpp:228] Iteration 47400, loss = 0.327387
I0823 11:23:18.304008 28265 solver.cpp:244]     Train net output #0: loss = 0.327387 (* 1 = 0.327387 loss)
I0823 11:23:18.304013 28265 sgd_solver.cpp:106] Iteration 47400, lr = 0.000297515
I0823 11:23:22.783782 28265 solver.cpp:337] Iteration 47500, Testing net (#0)
I0823 11:23:26.179250 28265 solver.cpp:404]     Test net output #0: accuracy = 0.775542
I0823 11:23:26.179296 28265 solver.cpp:404]     Test net output #1: loss = 0.716784 (* 1 = 0.716784 loss)
I0823 11:23:26.194561 28265 solver.cpp:228] Iteration 47500, loss = 0.298304
I0823 11:23:26.194579 28265 solver.cpp:244]     Train net output #0: loss = 0.298304 (* 1 = 0.298304 loss)
I0823 11:23:26.194589 28265 sgd_solver.cpp:106] Iteration 47500, lr = 0.000297185
I0823 11:23:30.722582 28265 solver.cpp:228] Iteration 47600, loss = 0.188685
I0823 11:23:30.722627 28265 solver.cpp:244]     Train net output #0: loss = 0.188685 (* 1 = 0.188685 loss)
I0823 11:23:30.722633 28265 sgd_solver.cpp:106] Iteration 47600, lr = 0.000296855
I0823 11:23:35.245261 28265 solver.cpp:228] Iteration 47700, loss = 0.200809
I0823 11:23:35.245307 28265 solver.cpp:244]     Train net output #0: loss = 0.200809 (* 1 = 0.200809 loss)
I0823 11:23:35.245312 28265 sgd_solver.cpp:106] Iteration 47700, lr = 0.000296526
I0823 11:23:39.782327 28265 solver.cpp:228] Iteration 47800, loss = 0.209065
I0823 11:23:39.782373 28265 solver.cpp:244]     Train net output #0: loss = 0.209065 (* 1 = 0.209065 loss)
I0823 11:23:39.782379 28265 sgd_solver.cpp:106] Iteration 47800, lr = 0.000296198
I0823 11:23:44.300508 28265 solver.cpp:228] Iteration 47900, loss = 0.1951
I0823 11:23:44.300529 28265 solver.cpp:244]     Train net output #0: loss = 0.1951 (* 1 = 0.1951 loss)
I0823 11:23:44.300534 28265 sgd_solver.cpp:106] Iteration 47900, lr = 0.000295871
I0823 11:23:48.784181 28265 solver.cpp:337] Iteration 48000, Testing net (#0)
I0823 11:23:52.225769 28265 solver.cpp:404]     Test net output #0: accuracy = 0.822042
I0823 11:23:52.225841 28265 solver.cpp:404]     Test net output #1: loss = 0.540162 (* 1 = 0.540162 loss)
I0823 11:23:52.241621 28265 solver.cpp:228] Iteration 48000, loss = 0.166802
I0823 11:23:52.241680 28265 solver.cpp:244]     Train net output #0: loss = 0.166802 (* 1 = 0.166802 loss)
I0823 11:23:52.241698 28265 sgd_solver.cpp:106] Iteration 48000, lr = 0.000295544
I0823 11:23:56.766412 28265 solver.cpp:228] Iteration 48100, loss = 0.163107
I0823 11:23:56.766475 28265 solver.cpp:244]     Train net output #0: loss = 0.163107 (* 1 = 0.163107 loss)
I0823 11:23:56.766481 28265 sgd_solver.cpp:106] Iteration 48100, lr = 0.000295219
I0823 11:24:01.283875 28265 solver.cpp:228] Iteration 48200, loss = 0.184007
I0823 11:24:01.283921 28265 solver.cpp:244]     Train net output #0: loss = 0.184007 (* 1 = 0.184007 loss)
I0823 11:24:01.283926 28265 sgd_solver.cpp:106] Iteration 48200, lr = 0.000294894
I0823 11:24:05.809371 28265 solver.cpp:228] Iteration 48300, loss = 0.137866
I0823 11:24:05.809413 28265 solver.cpp:244]     Train net output #0: loss = 0.137866 (* 1 = 0.137866 loss)
I0823 11:24:05.809419 28265 sgd_solver.cpp:106] Iteration 48300, lr = 0.00029457
I0823 11:24:10.329181 28265 solver.cpp:228] Iteration 48400, loss = 0.341464
I0823 11:24:10.329223 28265 solver.cpp:244]     Train net output #0: loss = 0.341464 (* 1 = 0.341464 loss)
I0823 11:24:10.329229 28265 sgd_solver.cpp:106] Iteration 48400, lr = 0.000294247
I0823 11:24:14.803190 28265 solver.cpp:337] Iteration 48500, Testing net (#0)
I0823 11:24:18.487288 28265 solver.cpp:404]     Test net output #0: accuracy = 0.827375
I0823 11:24:18.487349 28265 solver.cpp:404]     Test net output #1: loss = 0.525517 (* 1 = 0.525517 loss)
I0823 11:24:18.502495 28265 solver.cpp:228] Iteration 48500, loss = 0.100071
I0823 11:24:18.502555 28265 solver.cpp:244]     Train net output #0: loss = 0.100071 (* 1 = 0.100071 loss)
I0823 11:24:18.502576 28265 sgd_solver.cpp:106] Iteration 48500, lr = 0.000293925
I0823 11:24:23.024077 28265 solver.cpp:228] Iteration 48600, loss = 0.213643
I0823 11:24:23.024122 28265 solver.cpp:244]     Train net output #0: loss = 0.213643 (* 1 = 0.213643 loss)
I0823 11:24:23.024128 28265 sgd_solver.cpp:106] Iteration 48600, lr = 0.000293603
I0823 11:24:27.548735 28265 solver.cpp:228] Iteration 48700, loss = 0.207883
I0823 11:24:27.548780 28265 solver.cpp:244]     Train net output #0: loss = 0.207883 (* 1 = 0.207883 loss)
I0823 11:24:27.548787 28265 sgd_solver.cpp:106] Iteration 48700, lr = 0.000293283
I0823 11:24:32.065804 28265 solver.cpp:228] Iteration 48800, loss = 0.221901
I0823 11:24:32.065876 28265 solver.cpp:244]     Train net output #0: loss = 0.221901 (* 1 = 0.221901 loss)
I0823 11:24:32.065881 28265 sgd_solver.cpp:106] Iteration 48800, lr = 0.000292963
I0823 11:24:36.585819 28265 solver.cpp:228] Iteration 48900, loss = 0.240904
I0823 11:24:36.585877 28265 solver.cpp:244]     Train net output #0: loss = 0.240904 (* 1 = 0.240904 loss)
I0823 11:24:36.585883 28265 sgd_solver.cpp:106] Iteration 48900, lr = 0.000292644
I0823 11:24:41.058327 28265 solver.cpp:337] Iteration 49000, Testing net (#0)
I0823 11:24:41.891510 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:24:44.565083 28265 solver.cpp:404]     Test net output #0: accuracy = 0.78425
I0823 11:24:44.565145 28265 solver.cpp:404]     Test net output #1: loss = 0.712627 (* 1 = 0.712627 loss)
I0823 11:24:44.581464 28265 solver.cpp:228] Iteration 49000, loss = 0.308545
I0823 11:24:44.581504 28265 solver.cpp:244]     Train net output #0: loss = 0.308545 (* 1 = 0.308545 loss)
I0823 11:24:44.581514 28265 sgd_solver.cpp:106] Iteration 49000, lr = 0.000292326
I0823 11:24:49.098675 28265 solver.cpp:228] Iteration 49100, loss = 0.270639
I0823 11:24:49.098716 28265 solver.cpp:244]     Train net output #0: loss = 0.270639 (* 1 = 0.270639 loss)
I0823 11:24:49.098721 28265 sgd_solver.cpp:106] Iteration 49100, lr = 0.000292009
I0823 11:24:53.619566 28265 solver.cpp:228] Iteration 49200, loss = 0.318786
I0823 11:24:53.619623 28265 solver.cpp:244]     Train net output #0: loss = 0.318786 (* 1 = 0.318786 loss)
I0823 11:24:53.619633 28265 sgd_solver.cpp:106] Iteration 49200, lr = 0.000291692
I0823 11:24:58.142122 28265 solver.cpp:228] Iteration 49300, loss = 0.275769
I0823 11:24:58.142179 28265 solver.cpp:244]     Train net output #0: loss = 0.275769 (* 1 = 0.275769 loss)
I0823 11:24:58.142186 28265 sgd_solver.cpp:106] Iteration 49300, lr = 0.000291376
I0823 11:25:02.660617 28265 solver.cpp:228] Iteration 49400, loss = 0.252403
I0823 11:25:02.660678 28265 solver.cpp:244]     Train net output #0: loss = 0.252403 (* 1 = 0.252403 loss)
I0823 11:25:02.660686 28265 sgd_solver.cpp:106] Iteration 49400, lr = 0.000291061
I0823 11:25:07.132912 28265 solver.cpp:337] Iteration 49500, Testing net (#0)
I0823 11:25:10.382395 28265 solver.cpp:404]     Test net output #0: accuracy = 0.824083
I0823 11:25:10.382444 28265 solver.cpp:404]     Test net output #1: loss = 0.48244 (* 1 = 0.48244 loss)
I0823 11:25:10.397718 28265 solver.cpp:228] Iteration 49500, loss = 0.231005
I0823 11:25:10.397737 28265 solver.cpp:244]     Train net output #0: loss = 0.231005 (* 1 = 0.231005 loss)
I0823 11:25:10.397744 28265 sgd_solver.cpp:106] Iteration 49500, lr = 0.000290747
I0823 11:25:14.921581 28265 solver.cpp:228] Iteration 49600, loss = 0.296338
I0823 11:25:14.921656 28265 solver.cpp:244]     Train net output #0: loss = 0.296338 (* 1 = 0.296338 loss)
I0823 11:25:14.921674 28265 sgd_solver.cpp:106] Iteration 49600, lr = 0.000290434
I0823 11:25:19.442853 28265 solver.cpp:228] Iteration 49700, loss = 0.205191
I0823 11:25:19.442911 28265 solver.cpp:244]     Train net output #0: loss = 0.205191 (* 1 = 0.205191 loss)
I0823 11:25:19.442919 28265 sgd_solver.cpp:106] Iteration 49700, lr = 0.000290121
I0823 11:25:23.960418 28265 solver.cpp:228] Iteration 49800, loss = 0.132526
I0823 11:25:23.960464 28265 solver.cpp:244]     Train net output #0: loss = 0.132526 (* 1 = 0.132526 loss)
I0823 11:25:23.960469 28265 sgd_solver.cpp:106] Iteration 49800, lr = 0.00028981
I0823 11:25:28.475105 28265 solver.cpp:228] Iteration 49900, loss = 0.264353
I0823 11:25:28.475126 28265 solver.cpp:244]     Train net output #0: loss = 0.264353 (* 1 = 0.264353 loss)
I0823 11:25:28.475131 28265 sgd_solver.cpp:106] Iteration 49900, lr = 0.000289499
I0823 11:25:32.947494 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_50000.caffemodel
I0823 11:25:33.426231 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_50000.solverstate
I0823 11:25:33.582087 28265 solver.cpp:337] Iteration 50000, Testing net (#0)
I0823 11:25:36.852658 28265 solver.cpp:404]     Test net output #0: accuracy = 0.801167
I0823 11:25:36.852730 28265 solver.cpp:404]     Test net output #1: loss = 0.558084 (* 1 = 0.558084 loss)
I0823 11:25:36.867919 28265 solver.cpp:228] Iteration 50000, loss = 0.204891
I0823 11:25:36.867949 28265 solver.cpp:244]     Train net output #0: loss = 0.204891 (* 1 = 0.204891 loss)
I0823 11:25:36.867960 28265 sgd_solver.cpp:106] Iteration 50000, lr = 0.000289188
I0823 11:25:41.389168 28265 solver.cpp:228] Iteration 50100, loss = 0.215174
I0823 11:25:41.389221 28265 solver.cpp:244]     Train net output #0: loss = 0.215174 (* 1 = 0.215174 loss)
I0823 11:25:41.389231 28265 sgd_solver.cpp:106] Iteration 50100, lr = 0.000288879
I0823 11:25:45.910583 28265 solver.cpp:228] Iteration 50200, loss = 0.221243
I0823 11:25:45.910655 28265 solver.cpp:244]     Train net output #0: loss = 0.221243 (* 1 = 0.221243 loss)
I0823 11:25:45.910666 28265 sgd_solver.cpp:106] Iteration 50200, lr = 0.00028857
I0823 11:25:50.429049 28265 solver.cpp:228] Iteration 50300, loss = 0.208248
I0823 11:25:50.429091 28265 solver.cpp:244]     Train net output #0: loss = 0.208248 (* 1 = 0.208248 loss)
I0823 11:25:50.429096 28265 sgd_solver.cpp:106] Iteration 50300, lr = 0.000288262
I0823 11:25:54.947834 28265 solver.cpp:228] Iteration 50400, loss = 0.181379
I0823 11:25:54.947880 28265 solver.cpp:244]     Train net output #0: loss = 0.181379 (* 1 = 0.181379 loss)
I0823 11:25:54.947885 28265 sgd_solver.cpp:106] Iteration 50400, lr = 0.000287955
I0823 11:25:59.427297 28265 solver.cpp:337] Iteration 50500, Testing net (#0)
I0823 11:26:02.869858 28265 solver.cpp:404]     Test net output #0: accuracy = 0.835458
I0823 11:26:02.869925 28265 solver.cpp:404]     Test net output #1: loss = 0.489015 (* 1 = 0.489015 loss)
I0823 11:26:02.885817 28265 solver.cpp:228] Iteration 50500, loss = 0.204804
I0823 11:26:02.885879 28265 solver.cpp:244]     Train net output #0: loss = 0.204804 (* 1 = 0.204804 loss)
I0823 11:26:02.885900 28265 sgd_solver.cpp:106] Iteration 50500, lr = 0.000287649
I0823 11:26:07.406954 28265 solver.cpp:228] Iteration 50600, loss = 0.230389
I0823 11:26:07.407009 28265 solver.cpp:244]     Train net output #0: loss = 0.230389 (* 1 = 0.230389 loss)
I0823 11:26:07.407021 28265 sgd_solver.cpp:106] Iteration 50600, lr = 0.000287343
I0823 11:26:11.922844 28265 solver.cpp:228] Iteration 50700, loss = 0.203029
I0823 11:26:11.922888 28265 solver.cpp:244]     Train net output #0: loss = 0.203029 (* 1 = 0.203029 loss)
I0823 11:26:11.922894 28265 sgd_solver.cpp:106] Iteration 50700, lr = 0.000287038
I0823 11:26:16.437520 28265 solver.cpp:228] Iteration 50800, loss = 0.0923025
I0823 11:26:16.437553 28265 solver.cpp:244]     Train net output #0: loss = 0.0923025 (* 1 = 0.0923025 loss)
I0823 11:26:16.437558 28265 sgd_solver.cpp:106] Iteration 50800, lr = 0.000286734
I0823 11:26:20.955833 28265 solver.cpp:228] Iteration 50900, loss = 0.168986
I0823 11:26:20.955876 28265 solver.cpp:244]     Train net output #0: loss = 0.168986 (* 1 = 0.168986 loss)
I0823 11:26:20.955881 28265 sgd_solver.cpp:106] Iteration 50900, lr = 0.000286431
I0823 11:26:25.430980 28265 solver.cpp:337] Iteration 51000, Testing net (#0)
I0823 11:26:28.796149 28265 solver.cpp:404]     Test net output #0: accuracy = 0.765667
I0823 11:26:28.796196 28265 solver.cpp:404]     Test net output #1: loss = 0.77928 (* 1 = 0.77928 loss)
I0823 11:26:28.811664 28265 solver.cpp:228] Iteration 51000, loss = 0.250058
I0823 11:26:28.811684 28265 solver.cpp:244]     Train net output #0: loss = 0.250058 (* 1 = 0.250058 loss)
I0823 11:26:28.811691 28265 sgd_solver.cpp:106] Iteration 51000, lr = 0.000286128
I0823 11:26:33.331318 28265 solver.cpp:228] Iteration 51100, loss = 0.172708
I0823 11:26:33.331364 28265 solver.cpp:244]     Train net output #0: loss = 0.172708 (* 1 = 0.172708 loss)
I0823 11:26:33.331370 28265 sgd_solver.cpp:106] Iteration 51100, lr = 0.000285826
I0823 11:26:37.846576 28265 solver.cpp:228] Iteration 51200, loss = 0.168183
I0823 11:26:37.846596 28265 solver.cpp:244]     Train net output #0: loss = 0.168183 (* 1 = 0.168183 loss)
I0823 11:26:37.846601 28265 sgd_solver.cpp:106] Iteration 51200, lr = 0.000285525
I0823 11:26:42.355608 28265 solver.cpp:228] Iteration 51300, loss = 0.182268
I0823 11:26:42.355629 28265 solver.cpp:244]     Train net output #0: loss = 0.182268 (* 1 = 0.182268 loss)
I0823 11:26:42.355633 28265 sgd_solver.cpp:106] Iteration 51300, lr = 0.000285225
I0823 11:26:46.868324 28265 solver.cpp:228] Iteration 51400, loss = 0.327121
I0823 11:26:46.868374 28265 solver.cpp:244]     Train net output #0: loss = 0.327121 (* 1 = 0.327121 loss)
I0823 11:26:46.868381 28265 sgd_solver.cpp:106] Iteration 51400, lr = 0.000284925
I0823 11:26:51.330288 28265 solver.cpp:337] Iteration 51500, Testing net (#0)
I0823 11:26:55.038511 28265 solver.cpp:404]     Test net output #0: accuracy = 0.829834
I0823 11:26:55.038573 28265 solver.cpp:404]     Test net output #1: loss = 0.535586 (* 1 = 0.535586 loss)
I0823 11:26:55.053634 28265 solver.cpp:228] Iteration 51500, loss = 0.187687
I0823 11:26:55.053674 28265 solver.cpp:244]     Train net output #0: loss = 0.187687 (* 1 = 0.187687 loss)
I0823 11:26:55.053686 28265 sgd_solver.cpp:106] Iteration 51500, lr = 0.000284626
I0823 11:26:59.568027 28265 solver.cpp:228] Iteration 51600, loss = 0.156892
I0823 11:26:59.568069 28265 solver.cpp:244]     Train net output #0: loss = 0.156892 (* 1 = 0.156892 loss)
I0823 11:26:59.568074 28265 sgd_solver.cpp:106] Iteration 51600, lr = 0.000284328
I0823 11:27:04.089994 28265 solver.cpp:228] Iteration 51700, loss = 0.15757
I0823 11:27:04.090037 28265 solver.cpp:244]     Train net output #0: loss = 0.15757 (* 1 = 0.15757 loss)
I0823 11:27:04.090044 28265 sgd_solver.cpp:106] Iteration 51700, lr = 0.00028403
I0823 11:27:08.604396 28265 solver.cpp:228] Iteration 51800, loss = 0.240027
I0823 11:27:08.604454 28265 solver.cpp:244]     Train net output #0: loss = 0.240027 (* 1 = 0.240027 loss)
I0823 11:27:08.604460 28265 sgd_solver.cpp:106] Iteration 51800, lr = 0.000283734
I0823 11:27:13.123756 28265 solver.cpp:228] Iteration 51900, loss = 0.140281
I0823 11:27:13.123801 28265 solver.cpp:244]     Train net output #0: loss = 0.140281 (* 1 = 0.140281 loss)
I0823 11:27:13.123807 28265 sgd_solver.cpp:106] Iteration 51900, lr = 0.000283438
I0823 11:27:17.603595 28265 solver.cpp:337] Iteration 52000, Testing net (#0)
I0823 11:27:19.248235 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:27:21.030252 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845209
I0823 11:27:21.030323 28265 solver.cpp:404]     Test net output #1: loss = 0.458893 (* 1 = 0.458893 loss)
I0823 11:27:21.045786 28265 solver.cpp:228] Iteration 52000, loss = 0.142948
I0823 11:27:21.045837 28265 solver.cpp:244]     Train net output #0: loss = 0.142948 (* 1 = 0.142948 loss)
I0823 11:27:21.045852 28265 sgd_solver.cpp:106] Iteration 52000, lr = 0.000283142
I0823 11:27:25.572163 28265 solver.cpp:228] Iteration 52100, loss = 0.228231
I0823 11:27:25.572235 28265 solver.cpp:244]     Train net output #0: loss = 0.228231 (* 1 = 0.228231 loss)
I0823 11:27:25.572252 28265 sgd_solver.cpp:106] Iteration 52100, lr = 0.000282848
I0823 11:27:30.081588 28265 solver.cpp:228] Iteration 52200, loss = 0.165544
I0823 11:27:30.081606 28265 solver.cpp:244]     Train net output #0: loss = 0.165544 (* 1 = 0.165544 loss)
I0823 11:27:30.081612 28265 sgd_solver.cpp:106] Iteration 52200, lr = 0.000282554
I0823 11:27:34.607576 28265 solver.cpp:228] Iteration 52300, loss = 0.122297
I0823 11:27:34.607622 28265 solver.cpp:244]     Train net output #0: loss = 0.122297 (* 1 = 0.122297 loss)
I0823 11:27:34.607628 28265 sgd_solver.cpp:106] Iteration 52300, lr = 0.000282261
I0823 11:27:39.133322 28265 solver.cpp:228] Iteration 52400, loss = 0.246117
I0823 11:27:39.133365 28265 solver.cpp:244]     Train net output #0: loss = 0.246117 (* 1 = 0.246117 loss)
I0823 11:27:39.133371 28265 sgd_solver.cpp:106] Iteration 52400, lr = 0.000281968
I0823 11:27:43.608042 28265 solver.cpp:337] Iteration 52500, Testing net (#0)
I0823 11:27:47.157667 28265 solver.cpp:404]     Test net output #0: accuracy = 0.823709
I0823 11:27:47.157742 28265 solver.cpp:404]     Test net output #1: loss = 0.550194 (* 1 = 0.550194 loss)
I0823 11:27:47.172906 28265 solver.cpp:228] Iteration 52500, loss = 0.176736
I0823 11:27:47.172945 28265 solver.cpp:244]     Train net output #0: loss = 0.176736 (* 1 = 0.176736 loss)
I0823 11:27:47.172955 28265 sgd_solver.cpp:106] Iteration 52500, lr = 0.000281677
I0823 11:27:51.683336 28265 solver.cpp:228] Iteration 52600, loss = 0.320661
I0823 11:27:51.683408 28265 solver.cpp:244]     Train net output #0: loss = 0.320661 (* 1 = 0.320661 loss)
I0823 11:27:51.683420 28265 sgd_solver.cpp:106] Iteration 52600, lr = 0.000281386
I0823 11:27:56.204493 28265 solver.cpp:228] Iteration 52700, loss = 0.209647
I0823 11:27:56.204541 28265 solver.cpp:244]     Train net output #0: loss = 0.209647 (* 1 = 0.209647 loss)
I0823 11:27:56.204546 28265 sgd_solver.cpp:106] Iteration 52700, lr = 0.000281095
I0823 11:28:00.721479 28265 solver.cpp:228] Iteration 52800, loss = 0.141823
I0823 11:28:00.721525 28265 solver.cpp:244]     Train net output #0: loss = 0.141823 (* 1 = 0.141823 loss)
I0823 11:28:00.721530 28265 sgd_solver.cpp:106] Iteration 52800, lr = 0.000280806
I0823 11:28:05.232177 28265 solver.cpp:228] Iteration 52900, loss = 0.335373
I0823 11:28:05.232234 28265 solver.cpp:244]     Train net output #0: loss = 0.335373 (* 1 = 0.335373 loss)
I0823 11:28:05.232239 28265 sgd_solver.cpp:106] Iteration 52900, lr = 0.000280517
I0823 11:28:09.698499 28265 solver.cpp:337] Iteration 53000, Testing net (#0)
I0823 11:28:13.123785 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845042
I0823 11:28:13.123833 28265 solver.cpp:404]     Test net output #1: loss = 0.479089 (* 1 = 0.479089 loss)
I0823 11:28:13.139106 28265 solver.cpp:228] Iteration 53000, loss = 0.168327
I0823 11:28:13.139127 28265 solver.cpp:244]     Train net output #0: loss = 0.168327 (* 1 = 0.168327 loss)
I0823 11:28:13.139135 28265 sgd_solver.cpp:106] Iteration 53000, lr = 0.000280228
I0823 11:28:17.669371 28265 solver.cpp:228] Iteration 53100, loss = 0.253758
I0823 11:28:17.669428 28265 solver.cpp:244]     Train net output #0: loss = 0.253758 (* 1 = 0.253758 loss)
I0823 11:28:17.669440 28265 sgd_solver.cpp:106] Iteration 53100, lr = 0.000279941
I0823 11:28:22.185322 28265 solver.cpp:228] Iteration 53200, loss = 0.0931963
I0823 11:28:22.185379 28265 solver.cpp:244]     Train net output #0: loss = 0.0931963 (* 1 = 0.0931963 loss)
I0823 11:28:22.185391 28265 sgd_solver.cpp:106] Iteration 53200, lr = 0.000279654
I0823 11:28:26.706027 28265 solver.cpp:228] Iteration 53300, loss = 0.190621
I0823 11:28:26.706100 28265 solver.cpp:244]     Train net output #0: loss = 0.190621 (* 1 = 0.190621 loss)
I0823 11:28:26.706112 28265 sgd_solver.cpp:106] Iteration 53300, lr = 0.000279368
I0823 11:28:31.220338 28265 solver.cpp:228] Iteration 53400, loss = 0.424251
I0823 11:28:31.220383 28265 solver.cpp:244]     Train net output #0: loss = 0.424251 (* 1 = 0.424251 loss)
I0823 11:28:31.220388 28265 sgd_solver.cpp:106] Iteration 53400, lr = 0.000279082
I0823 11:28:35.692029 28265 solver.cpp:337] Iteration 53500, Testing net (#0)
I0823 11:28:39.397166 28265 solver.cpp:404]     Test net output #0: accuracy = 0.780958
I0823 11:28:39.397215 28265 solver.cpp:404]     Test net output #1: loss = 0.732956 (* 1 = 0.732956 loss)
I0823 11:28:39.414836 28265 solver.cpp:228] Iteration 53500, loss = 0.15408
I0823 11:28:39.414891 28265 solver.cpp:244]     Train net output #0: loss = 0.15408 (* 1 = 0.15408 loss)
I0823 11:28:39.414902 28265 sgd_solver.cpp:106] Iteration 53500, lr = 0.000278797
I0823 11:28:43.927765 28265 solver.cpp:228] Iteration 53600, loss = 0.191726
I0823 11:28:43.927788 28265 solver.cpp:244]     Train net output #0: loss = 0.191726 (* 1 = 0.191726 loss)
I0823 11:28:43.927794 28265 sgd_solver.cpp:106] Iteration 53600, lr = 0.000278513
I0823 11:28:48.444188 28265 solver.cpp:228] Iteration 53700, loss = 0.199076
I0823 11:28:48.444248 28265 solver.cpp:244]     Train net output #0: loss = 0.199076 (* 1 = 0.199076 loss)
I0823 11:28:48.444257 28265 sgd_solver.cpp:106] Iteration 53700, lr = 0.00027823
I0823 11:28:52.954006 28265 solver.cpp:228] Iteration 53800, loss = 0.265056
I0823 11:28:52.954026 28265 solver.cpp:244]     Train net output #0: loss = 0.265056 (* 1 = 0.265056 loss)
I0823 11:28:52.954031 28265 sgd_solver.cpp:106] Iteration 53800, lr = 0.000277947
I0823 11:28:57.470548 28265 solver.cpp:228] Iteration 53900, loss = 0.487296
I0823 11:28:57.470605 28265 solver.cpp:244]     Train net output #0: loss = 0.487296 (* 1 = 0.487296 loss)
I0823 11:28:57.470613 28265 sgd_solver.cpp:106] Iteration 53900, lr = 0.000277665
I0823 11:29:01.941136 28265 solver.cpp:337] Iteration 54000, Testing net (#0)
I0823 11:29:05.373137 28265 solver.cpp:404]     Test net output #0: accuracy = 0.833167
I0823 11:29:05.373201 28265 solver.cpp:404]     Test net output #1: loss = 0.497329 (* 1 = 0.497329 loss)
I0823 11:29:05.389495 28265 solver.cpp:228] Iteration 54000, loss = 0.21962
I0823 11:29:05.389535 28265 solver.cpp:244]     Train net output #0: loss = 0.21962 (* 1 = 0.21962 loss)
I0823 11:29:05.389549 28265 sgd_solver.cpp:106] Iteration 54000, lr = 0.000277383
I0823 11:29:09.911344 28265 solver.cpp:228] Iteration 54100, loss = 0.526574
I0823 11:29:09.911391 28265 solver.cpp:244]     Train net output #0: loss = 0.526574 (* 1 = 0.526574 loss)
I0823 11:29:09.911396 28265 sgd_solver.cpp:106] Iteration 54100, lr = 0.000277103
I0823 11:29:14.420171 28265 solver.cpp:228] Iteration 54200, loss = 0.146393
I0823 11:29:14.420202 28265 solver.cpp:244]     Train net output #0: loss = 0.146393 (* 1 = 0.146393 loss)
I0823 11:29:14.420207 28265 sgd_solver.cpp:106] Iteration 54200, lr = 0.000276822
I0823 11:29:18.930929 28265 solver.cpp:228] Iteration 54300, loss = 0.127511
I0823 11:29:18.930974 28265 solver.cpp:244]     Train net output #0: loss = 0.127511 (* 1 = 0.127511 loss)
I0823 11:29:18.930979 28265 sgd_solver.cpp:106] Iteration 54300, lr = 0.000276543
I0823 11:29:23.454797 28265 solver.cpp:228] Iteration 54400, loss = 0.157192
I0823 11:29:23.454843 28265 solver.cpp:244]     Train net output #0: loss = 0.157192 (* 1 = 0.157192 loss)
I0823 11:29:23.454848 28265 sgd_solver.cpp:106] Iteration 54400, lr = 0.000276264
I0823 11:29:27.917268 28265 solver.cpp:337] Iteration 54500, Testing net (#0)
I0823 11:29:30.002847 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:29:31.400593 28265 solver.cpp:404]     Test net output #0: accuracy = 0.842084
I0823 11:29:31.400662 28265 solver.cpp:404]     Test net output #1: loss = 0.49364 (* 1 = 0.49364 loss)
I0823 11:29:31.416559 28265 solver.cpp:228] Iteration 54500, loss = 0.202645
I0823 11:29:31.416615 28265 solver.cpp:244]     Train net output #0: loss = 0.202645 (* 1 = 0.202645 loss)
I0823 11:29:31.416641 28265 sgd_solver.cpp:106] Iteration 54500, lr = 0.000275986
I0823 11:29:35.929126 28265 solver.cpp:228] Iteration 54600, loss = 0.183998
I0823 11:29:35.929183 28265 solver.cpp:244]     Train net output #0: loss = 0.183998 (* 1 = 0.183998 loss)
I0823 11:29:35.929193 28265 sgd_solver.cpp:106] Iteration 54600, lr = 0.000275708
I0823 11:29:40.439151 28265 solver.cpp:228] Iteration 54700, loss = 0.119489
I0823 11:29:40.439204 28265 solver.cpp:244]     Train net output #0: loss = 0.119489 (* 1 = 0.119489 loss)
I0823 11:29:40.439214 28265 sgd_solver.cpp:106] Iteration 54700, lr = 0.000275432
I0823 11:29:44.949694 28265 solver.cpp:228] Iteration 54800, loss = 0.0865373
I0823 11:29:44.949740 28265 solver.cpp:244]     Train net output #0: loss = 0.0865373 (* 1 = 0.0865373 loss)
I0823 11:29:44.949746 28265 sgd_solver.cpp:106] Iteration 54800, lr = 0.000275155
I0823 11:29:49.470780 28265 solver.cpp:228] Iteration 54900, loss = 0.282843
I0823 11:29:49.470824 28265 solver.cpp:244]     Train net output #0: loss = 0.282843 (* 1 = 0.282843 loss)
I0823 11:29:49.470829 28265 sgd_solver.cpp:106] Iteration 54900, lr = 0.00027488
I0823 11:29:53.951719 28265 solver.cpp:337] Iteration 55000, Testing net (#0)
I0823 11:29:57.560623 28265 solver.cpp:404]     Test net output #0: accuracy = 0.776167
I0823 11:29:57.560678 28265 solver.cpp:404]     Test net output #1: loss = 0.787891 (* 1 = 0.787891 loss)
I0823 11:29:57.575990 28265 solver.cpp:228] Iteration 55000, loss = 0.105559
I0823 11:29:57.576020 28265 solver.cpp:244]     Train net output #0: loss = 0.105559 (* 1 = 0.105559 loss)
I0823 11:29:57.576032 28265 sgd_solver.cpp:106] Iteration 55000, lr = 0.000274605
I0823 11:30:02.089172 28265 solver.cpp:228] Iteration 55100, loss = 0.178123
I0823 11:30:02.089226 28265 solver.cpp:244]     Train net output #0: loss = 0.178123 (* 1 = 0.178123 loss)
I0823 11:30:02.089231 28265 sgd_solver.cpp:106] Iteration 55100, lr = 0.000274331
I0823 11:30:06.596993 28265 solver.cpp:228] Iteration 55200, loss = 0.0720916
I0823 11:30:06.597033 28265 solver.cpp:244]     Train net output #0: loss = 0.0720916 (* 1 = 0.0720916 loss)
I0823 11:30:06.597038 28265 sgd_solver.cpp:106] Iteration 55200, lr = 0.000274057
I0823 11:30:11.103130 28265 solver.cpp:228] Iteration 55300, loss = 0.140904
I0823 11:30:11.103166 28265 solver.cpp:244]     Train net output #0: loss = 0.140904 (* 1 = 0.140904 loss)
I0823 11:30:11.103173 28265 sgd_solver.cpp:106] Iteration 55300, lr = 0.000273784
I0823 11:30:15.616991 28265 solver.cpp:228] Iteration 55400, loss = 0.0915949
I0823 11:30:15.617035 28265 solver.cpp:244]     Train net output #0: loss = 0.0915949 (* 1 = 0.0915949 loss)
I0823 11:30:15.617041 28265 sgd_solver.cpp:106] Iteration 55400, lr = 0.000273512
I0823 11:30:20.088414 28265 solver.cpp:337] Iteration 55500, Testing net (#0)
I0823 11:30:23.453855 28265 solver.cpp:404]     Test net output #0: accuracy = 0.849042
I0823 11:30:23.453904 28265 solver.cpp:404]     Test net output #1: loss = 0.505741 (* 1 = 0.505741 loss)
I0823 11:30:23.469157 28265 solver.cpp:228] Iteration 55500, loss = 0.0718675
I0823 11:30:23.469197 28265 solver.cpp:244]     Train net output #0: loss = 0.0718675 (* 1 = 0.0718675 loss)
I0823 11:30:23.469207 28265 sgd_solver.cpp:106] Iteration 55500, lr = 0.00027324
I0823 11:30:27.978752 28265 solver.cpp:228] Iteration 55600, loss = 0.103608
I0823 11:30:27.978809 28265 solver.cpp:244]     Train net output #0: loss = 0.103608 (* 1 = 0.103608 loss)
I0823 11:30:27.978818 28265 sgd_solver.cpp:106] Iteration 55600, lr = 0.000272969
I0823 11:30:32.487527 28265 solver.cpp:228] Iteration 55700, loss = 0.196188
I0823 11:30:32.487563 28265 solver.cpp:244]     Train net output #0: loss = 0.196188 (* 1 = 0.196188 loss)
I0823 11:30:32.487568 28265 sgd_solver.cpp:106] Iteration 55700, lr = 0.000272698
I0823 11:30:37.011656 28265 solver.cpp:228] Iteration 55800, loss = 0.0520565
I0823 11:30:37.011713 28265 solver.cpp:244]     Train net output #0: loss = 0.0520565 (* 1 = 0.0520565 loss)
I0823 11:30:37.011719 28265 sgd_solver.cpp:106] Iteration 55800, lr = 0.000272428
I0823 11:30:41.541682 28265 solver.cpp:228] Iteration 55900, loss = 0.104165
I0823 11:30:41.541741 28265 solver.cpp:244]     Train net output #0: loss = 0.104165 (* 1 = 0.104165 loss)
I0823 11:30:41.541749 28265 sgd_solver.cpp:106] Iteration 55900, lr = 0.000272159
I0823 11:30:46.015113 28265 solver.cpp:337] Iteration 56000, Testing net (#0)
I0823 11:30:49.411437 28265 solver.cpp:404]     Test net output #0: accuracy = 0.8325
I0823 11:30:49.411545 28265 solver.cpp:404]     Test net output #1: loss = 0.593652 (* 1 = 0.593652 loss)
I0823 11:30:49.426445 28265 solver.cpp:228] Iteration 56000, loss = 0.095668
I0823 11:30:49.426501 28265 solver.cpp:244]     Train net output #0: loss = 0.095668 (* 1 = 0.095668 loss)
I0823 11:30:49.426512 28265 sgd_solver.cpp:106] Iteration 56000, lr = 0.00027189
I0823 11:30:53.944782 28265 solver.cpp:228] Iteration 56100, loss = 0.171021
I0823 11:30:53.944828 28265 solver.cpp:244]     Train net output #0: loss = 0.171021 (* 1 = 0.171021 loss)
I0823 11:30:53.944833 28265 sgd_solver.cpp:106] Iteration 56100, lr = 0.000271622
I0823 11:30:58.479918 28265 solver.cpp:228] Iteration 56200, loss = 0.125417
I0823 11:30:58.479964 28265 solver.cpp:244]     Train net output #0: loss = 0.125417 (* 1 = 0.125417 loss)
I0823 11:30:58.479970 28265 sgd_solver.cpp:106] Iteration 56200, lr = 0.000271355
I0823 11:31:02.997238 28265 solver.cpp:228] Iteration 56300, loss = 0.0823035
I0823 11:31:02.997287 28265 solver.cpp:244]     Train net output #0: loss = 0.0823035 (* 1 = 0.0823035 loss)
I0823 11:31:02.997292 28265 sgd_solver.cpp:106] Iteration 56300, lr = 0.000271088
I0823 11:31:07.508939 28265 solver.cpp:228] Iteration 56400, loss = 0.136079
I0823 11:31:07.508988 28265 solver.cpp:244]     Train net output #0: loss = 0.136079 (* 1 = 0.136079 loss)
I0823 11:31:07.508993 28265 sgd_solver.cpp:106] Iteration 56400, lr = 0.000270822
I0823 11:31:11.987675 28265 solver.cpp:337] Iteration 56500, Testing net (#0)
I0823 11:31:15.405403 28265 solver.cpp:404]     Test net output #0: accuracy = 0.804625
I0823 11:31:15.405514 28265 solver.cpp:404]     Test net output #1: loss = 0.735935 (* 1 = 0.735935 loss)
I0823 11:31:15.420081 28265 solver.cpp:228] Iteration 56500, loss = 0.140853
I0823 11:31:15.420114 28265 solver.cpp:244]     Train net output #0: loss = 0.140853 (* 1 = 0.140853 loss)
I0823 11:31:15.420121 28265 sgd_solver.cpp:106] Iteration 56500, lr = 0.000270557
I0823 11:31:19.932158 28265 solver.cpp:228] Iteration 56600, loss = 0.0880347
I0823 11:31:19.932207 28265 solver.cpp:244]     Train net output #0: loss = 0.0880347 (* 1 = 0.0880347 loss)
I0823 11:31:19.932214 28265 sgd_solver.cpp:106] Iteration 56600, lr = 0.000270292
I0823 11:31:24.453841 28265 solver.cpp:228] Iteration 56700, loss = 0.073388
I0823 11:31:24.453891 28265 solver.cpp:244]     Train net output #0: loss = 0.073388 (* 1 = 0.073388 loss)
I0823 11:31:24.453896 28265 sgd_solver.cpp:106] Iteration 56700, lr = 0.000270027
I0823 11:31:28.961115 28265 solver.cpp:228] Iteration 56800, loss = 0.164635
I0823 11:31:28.961161 28265 solver.cpp:244]     Train net output #0: loss = 0.164635 (* 1 = 0.164635 loss)
I0823 11:31:28.961168 28265 sgd_solver.cpp:106] Iteration 56800, lr = 0.000269764
I0823 11:31:33.470011 28265 solver.cpp:228] Iteration 56900, loss = 0.163995
I0823 11:31:33.470057 28265 solver.cpp:244]     Train net output #0: loss = 0.163995 (* 1 = 0.163995 loss)
I0823 11:31:33.470062 28265 sgd_solver.cpp:106] Iteration 56900, lr = 0.0002695
I0823 11:31:37.943346 28265 solver.cpp:337] Iteration 57000, Testing net (#0)
I0823 11:31:41.391027 28265 solver.cpp:404]     Test net output #0: accuracy = 0.832667
I0823 11:31:41.391106 28265 solver.cpp:404]     Test net output #1: loss = 0.600741 (* 1 = 0.600741 loss)
I0823 11:31:41.406545 28265 solver.cpp:228] Iteration 57000, loss = 0.0866007
I0823 11:31:41.406584 28265 solver.cpp:244]     Train net output #0: loss = 0.0866007 (* 1 = 0.0866007 loss)
I0823 11:31:41.406604 28265 sgd_solver.cpp:106] Iteration 57000, lr = 0.000269238
I0823 11:31:45.918455 28265 solver.cpp:228] Iteration 57100, loss = 0.10026
I0823 11:31:45.918501 28265 solver.cpp:244]     Train net output #0: loss = 0.10026 (* 1 = 0.10026 loss)
I0823 11:31:45.918507 28265 sgd_solver.cpp:106] Iteration 57100, lr = 0.000268976
I0823 11:31:50.443331 28265 solver.cpp:228] Iteration 57200, loss = 0.0866271
I0823 11:31:50.443387 28265 solver.cpp:244]     Train net output #0: loss = 0.0866271 (* 1 = 0.0866271 loss)
I0823 11:31:50.443394 28265 sgd_solver.cpp:106] Iteration 57200, lr = 0.000268715
I0823 11:31:54.956856 28265 solver.cpp:228] Iteration 57300, loss = 0.0961805
I0823 11:31:54.956877 28265 solver.cpp:244]     Train net output #0: loss = 0.0961805 (* 1 = 0.0961805 loss)
I0823 11:31:54.956882 28265 sgd_solver.cpp:106] Iteration 57300, lr = 0.000268454
I0823 11:31:59.478014 28265 solver.cpp:228] Iteration 57400, loss = 0.128159
I0823 11:31:59.478073 28265 solver.cpp:244]     Train net output #0: loss = 0.128159 (* 1 = 0.128159 loss)
I0823 11:31:59.478080 28265 sgd_solver.cpp:106] Iteration 57400, lr = 0.000268194
I0823 11:32:03.947918 28265 solver.cpp:337] Iteration 57500, Testing net (#0)
I0823 11:32:05.364502 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:32:07.376516 28265 solver.cpp:404]     Test net output #0: accuracy = 0.816709
I0823 11:32:07.376621 28265 solver.cpp:404]     Test net output #1: loss = 0.67101 (* 1 = 0.67101 loss)
I0823 11:32:07.391898 28265 solver.cpp:228] Iteration 57500, loss = 0.190019
I0823 11:32:07.391916 28265 solver.cpp:244]     Train net output #0: loss = 0.190019 (* 1 = 0.190019 loss)
I0823 11:32:07.391924 28265 sgd_solver.cpp:106] Iteration 57500, lr = 0.000267934
I0823 11:32:11.901748 28265 solver.cpp:228] Iteration 57600, loss = 0.0730854
I0823 11:32:11.901808 28265 solver.cpp:244]     Train net output #0: loss = 0.0730854 (* 1 = 0.0730854 loss)
I0823 11:32:11.901814 28265 sgd_solver.cpp:106] Iteration 57600, lr = 0.000267675
I0823 11:32:16.423172 28265 solver.cpp:228] Iteration 57700, loss = 0.248961
I0823 11:32:16.423220 28265 solver.cpp:244]     Train net output #0: loss = 0.248961 (* 1 = 0.248961 loss)
I0823 11:32:16.423226 28265 sgd_solver.cpp:106] Iteration 57700, lr = 0.000267417
I0823 11:32:20.944041 28265 solver.cpp:228] Iteration 57800, loss = 0.0382457
I0823 11:32:20.944087 28265 solver.cpp:244]     Train net output #0: loss = 0.0382457 (* 1 = 0.0382457 loss)
I0823 11:32:20.944092 28265 sgd_solver.cpp:106] Iteration 57800, lr = 0.000267159
I0823 11:32:25.457067 28265 solver.cpp:228] Iteration 57900, loss = 0.0686801
I0823 11:32:25.457126 28265 solver.cpp:244]     Train net output #0: loss = 0.0686801 (* 1 = 0.0686801 loss)
I0823 11:32:25.457132 28265 sgd_solver.cpp:106] Iteration 57900, lr = 0.000266902
I0823 11:32:29.923086 28265 solver.cpp:337] Iteration 58000, Testing net (#0)
I0823 11:32:33.432588 28265 solver.cpp:404]     Test net output #0: accuracy = 0.810417
I0823 11:32:33.432642 28265 solver.cpp:404]     Test net output #1: loss = 0.688506 (* 1 = 0.688506 loss)
I0823 11:32:33.448333 28265 solver.cpp:228] Iteration 58000, loss = 0.229155
I0823 11:32:33.448390 28265 solver.cpp:244]     Train net output #0: loss = 0.229155 (* 1 = 0.229155 loss)
I0823 11:32:33.448403 28265 sgd_solver.cpp:106] Iteration 58000, lr = 0.000266645
I0823 11:32:37.965451 28265 solver.cpp:228] Iteration 58100, loss = 0.144269
I0823 11:32:37.965500 28265 solver.cpp:244]     Train net output #0: loss = 0.144269 (* 1 = 0.144269 loss)
I0823 11:32:37.965505 28265 sgd_solver.cpp:106] Iteration 58100, lr = 0.000266389
I0823 11:32:42.478556 28265 solver.cpp:228] Iteration 58200, loss = 0.204489
I0823 11:32:42.478620 28265 solver.cpp:244]     Train net output #0: loss = 0.204489 (* 1 = 0.204489 loss)
I0823 11:32:42.478631 28265 sgd_solver.cpp:106] Iteration 58200, lr = 0.000266133
I0823 11:32:47.001945 28265 solver.cpp:228] Iteration 58300, loss = 0.124435
I0823 11:32:47.001994 28265 solver.cpp:244]     Train net output #0: loss = 0.124435 (* 1 = 0.124435 loss)
I0823 11:32:47.001999 28265 sgd_solver.cpp:106] Iteration 58300, lr = 0.000265878
I0823 11:32:51.514526 28265 solver.cpp:228] Iteration 58400, loss = 0.258897
I0823 11:32:51.514588 28265 solver.cpp:244]     Train net output #0: loss = 0.258897 (* 1 = 0.258897 loss)
I0823 11:32:51.514597 28265 sgd_solver.cpp:106] Iteration 58400, lr = 0.000265624
I0823 11:32:55.979408 28265 solver.cpp:337] Iteration 58500, Testing net (#0)
I0823 11:32:59.569681 28265 solver.cpp:404]     Test net output #0: accuracy = 0.827209
I0823 11:32:59.569735 28265 solver.cpp:404]     Test net output #1: loss = 0.620666 (* 1 = 0.620666 loss)
I0823 11:32:59.585158 28265 solver.cpp:228] Iteration 58500, loss = 0.0706485
I0823 11:32:59.585213 28265 solver.cpp:244]     Train net output #0: loss = 0.0706485 (* 1 = 0.0706485 loss)
I0823 11:32:59.585227 28265 sgd_solver.cpp:106] Iteration 58500, lr = 0.00026537
I0823 11:33:04.092667 28265 solver.cpp:228] Iteration 58600, loss = 0.112225
I0823 11:33:04.092689 28265 solver.cpp:244]     Train net output #0: loss = 0.112225 (* 1 = 0.112225 loss)
I0823 11:33:04.092694 28265 sgd_solver.cpp:106] Iteration 58600, lr = 0.000265117
I0823 11:33:08.607014 28265 solver.cpp:228] Iteration 58700, loss = 0.337254
I0823 11:33:08.607072 28265 solver.cpp:244]     Train net output #0: loss = 0.337254 (* 1 = 0.337254 loss)
I0823 11:33:08.607079 28265 sgd_solver.cpp:106] Iteration 58700, lr = 0.000264864
I0823 11:33:13.116955 28265 solver.cpp:228] Iteration 58800, loss = 0.113136
I0823 11:33:13.116976 28265 solver.cpp:244]     Train net output #0: loss = 0.113136 (* 1 = 0.113136 loss)
I0823 11:33:13.116981 28265 sgd_solver.cpp:106] Iteration 58800, lr = 0.000264612
I0823 11:33:17.631798 28265 solver.cpp:228] Iteration 58900, loss = 0.222799
I0823 11:33:17.631842 28265 solver.cpp:244]     Train net output #0: loss = 0.222799 (* 1 = 0.222799 loss)
I0823 11:33:17.631847 28265 sgd_solver.cpp:106] Iteration 58900, lr = 0.00026436
I0823 11:33:22.099153 28265 solver.cpp:337] Iteration 59000, Testing net (#0)
I0823 11:33:25.682080 28265 solver.cpp:404]     Test net output #0: accuracy = 0.829334
I0823 11:33:25.682134 28265 solver.cpp:404]     Test net output #1: loss = 0.605795 (* 1 = 0.605795 loss)
I0823 11:33:25.697569 28265 solver.cpp:228] Iteration 59000, loss = 0.113205
I0823 11:33:25.697593 28265 solver.cpp:244]     Train net output #0: loss = 0.113205 (* 1 = 0.113205 loss)
I0823 11:33:25.697605 28265 sgd_solver.cpp:106] Iteration 59000, lr = 0.000264109
I0823 11:33:30.204735 28265 solver.cpp:228] Iteration 59100, loss = 0.222846
I0823 11:33:30.204780 28265 solver.cpp:244]     Train net output #0: loss = 0.222846 (* 1 = 0.222846 loss)
I0823 11:33:30.204785 28265 sgd_solver.cpp:106] Iteration 59100, lr = 0.000263859
I0823 11:33:34.715190 28265 solver.cpp:228] Iteration 59200, loss = 0.0927784
I0823 11:33:34.715237 28265 solver.cpp:244]     Train net output #0: loss = 0.0927784 (* 1 = 0.0927784 loss)
I0823 11:33:34.715242 28265 sgd_solver.cpp:106] Iteration 59200, lr = 0.000263609
I0823 11:33:39.226085 28265 solver.cpp:228] Iteration 59300, loss = 0.0847368
I0823 11:33:39.226128 28265 solver.cpp:244]     Train net output #0: loss = 0.0847368 (* 1 = 0.0847368 loss)
I0823 11:33:39.226133 28265 sgd_solver.cpp:106] Iteration 59300, lr = 0.00026336
I0823 11:33:43.735605 28265 solver.cpp:228] Iteration 59400, loss = 0.317194
I0823 11:33:43.735649 28265 solver.cpp:244]     Train net output #0: loss = 0.317194 (* 1 = 0.317194 loss)
I0823 11:33:43.735656 28265 sgd_solver.cpp:106] Iteration 59400, lr = 0.000263111
I0823 11:33:48.197665 28265 solver.cpp:337] Iteration 59500, Testing net (#0)
I0823 11:33:51.772385 28265 solver.cpp:404]     Test net output #0: accuracy = 0.794417
I0823 11:33:51.772454 28265 solver.cpp:404]     Test net output #1: loss = 0.744545 (* 1 = 0.744545 loss)
I0823 11:33:51.787719 28265 solver.cpp:228] Iteration 59500, loss = 0.190018
I0823 11:33:51.787753 28265 solver.cpp:244]     Train net output #0: loss = 0.190018 (* 1 = 0.190018 loss)
I0823 11:33:51.787765 28265 sgd_solver.cpp:106] Iteration 59500, lr = 0.000262863
I0823 11:33:56.302772 28265 solver.cpp:228] Iteration 59600, loss = 0.121176
I0823 11:33:56.302814 28265 solver.cpp:244]     Train net output #0: loss = 0.121176 (* 1 = 0.121176 loss)
I0823 11:33:56.302819 28265 sgd_solver.cpp:106] Iteration 59600, lr = 0.000262615
I0823 11:34:00.808116 28265 solver.cpp:228] Iteration 59700, loss = 0.154889
I0823 11:34:00.808177 28265 solver.cpp:244]     Train net output #0: loss = 0.154889 (* 1 = 0.154889 loss)
I0823 11:34:00.808183 28265 sgd_solver.cpp:106] Iteration 59700, lr = 0.000262368
I0823 11:34:05.318105 28265 solver.cpp:228] Iteration 59800, loss = 0.190774
I0823 11:34:05.318174 28265 solver.cpp:244]     Train net output #0: loss = 0.190774 (* 1 = 0.190774 loss)
I0823 11:34:05.318184 28265 sgd_solver.cpp:106] Iteration 59800, lr = 0.000262121
I0823 11:34:09.842762 28265 solver.cpp:228] Iteration 59900, loss = 0.0556615
I0823 11:34:09.842821 28265 solver.cpp:244]     Train net output #0: loss = 0.0556615 (* 1 = 0.0556615 loss)
I0823 11:34:09.842828 28265 sgd_solver.cpp:106] Iteration 59900, lr = 0.000261875
I0823 11:34:14.307245 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_60000.caffemodel
I0823 11:34:14.780506 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_60000.solverstate
I0823 11:34:14.935966 28265 solver.cpp:337] Iteration 60000, Testing net (#0)
I0823 11:34:18.139560 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84225
I0823 11:34:18.139628 28265 solver.cpp:404]     Test net output #1: loss = 0.553097 (* 1 = 0.553097 loss)
I0823 11:34:18.154881 28265 solver.cpp:228] Iteration 60000, loss = 0.0963808
I0823 11:34:18.154920 28265 solver.cpp:244]     Train net output #0: loss = 0.0963808 (* 1 = 0.0963808 loss)
I0823 11:34:18.154932 28265 sgd_solver.cpp:106] Iteration 60000, lr = 0.000261629
I0823 11:34:22.660768 28265 solver.cpp:228] Iteration 60100, loss = 0.0954124
I0823 11:34:22.660794 28265 solver.cpp:244]     Train net output #0: loss = 0.0954124 (* 1 = 0.0954124 loss)
I0823 11:34:22.660799 28265 sgd_solver.cpp:106] Iteration 60100, lr = 0.000261384
I0823 11:34:27.168326 28265 solver.cpp:228] Iteration 60200, loss = 0.0705891
I0823 11:34:27.168375 28265 solver.cpp:244]     Train net output #0: loss = 0.0705891 (* 1 = 0.0705891 loss)
I0823 11:34:27.168380 28265 sgd_solver.cpp:106] Iteration 60200, lr = 0.00026114
I0823 11:34:31.675894 28265 solver.cpp:228] Iteration 60300, loss = 0.155163
I0823 11:34:31.675940 28265 solver.cpp:244]     Train net output #0: loss = 0.155163 (* 1 = 0.155163 loss)
I0823 11:34:31.675946 28265 sgd_solver.cpp:106] Iteration 60300, lr = 0.000260896
I0823 11:34:36.182669 28265 solver.cpp:228] Iteration 60400, loss = 0.136166
I0823 11:34:36.182690 28265 solver.cpp:244]     Train net output #0: loss = 0.136166 (* 1 = 0.136166 loss)
I0823 11:34:36.182694 28265 sgd_solver.cpp:106] Iteration 60400, lr = 0.000260653
I0823 11:34:40.652933 28265 solver.cpp:337] Iteration 60500, Testing net (#0)
I0823 11:34:41.353229 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:34:43.916124 28265 solver.cpp:404]     Test net output #0: accuracy = 0.826542
I0823 11:34:43.916196 28265 solver.cpp:404]     Test net output #1: loss = 0.662303 (* 1 = 0.662303 loss)
I0823 11:34:43.932123 28265 solver.cpp:228] Iteration 60500, loss = 0.0756103
I0823 11:34:43.932204 28265 solver.cpp:244]     Train net output #0: loss = 0.0756103 (* 1 = 0.0756103 loss)
I0823 11:34:43.932227 28265 sgd_solver.cpp:106] Iteration 60500, lr = 0.00026041
I0823 11:34:48.441938 28265 solver.cpp:228] Iteration 60600, loss = 0.0573574
I0823 11:34:48.441982 28265 solver.cpp:244]     Train net output #0: loss = 0.0573574 (* 1 = 0.0573574 loss)
I0823 11:34:48.441988 28265 sgd_solver.cpp:106] Iteration 60600, lr = 0.000260167
I0823 11:34:52.962878 28265 solver.cpp:228] Iteration 60700, loss = 0.0707039
I0823 11:34:52.962955 28265 solver.cpp:244]     Train net output #0: loss = 0.0707039 (* 1 = 0.0707039 loss)
I0823 11:34:52.962967 28265 sgd_solver.cpp:106] Iteration 60700, lr = 0.000259926
I0823 11:34:57.476990 28265 solver.cpp:228] Iteration 60800, loss = 0.310878
I0823 11:34:57.477032 28265 solver.cpp:244]     Train net output #0: loss = 0.310878 (* 1 = 0.310878 loss)
I0823 11:34:57.477037 28265 sgd_solver.cpp:106] Iteration 60800, lr = 0.000259684
I0823 11:35:01.989759 28265 solver.cpp:228] Iteration 60900, loss = 0.0928787
I0823 11:35:01.989825 28265 solver.cpp:244]     Train net output #0: loss = 0.0928787 (* 1 = 0.0928787 loss)
I0823 11:35:01.989831 28265 sgd_solver.cpp:106] Iteration 60900, lr = 0.000259444
I0823 11:35:06.456686 28265 solver.cpp:337] Iteration 61000, Testing net (#0)
I0823 11:35:09.986224 28265 solver.cpp:404]     Test net output #0: accuracy = 0.797708
I0823 11:35:09.986294 28265 solver.cpp:404]     Test net output #1: loss = 0.818561 (* 1 = 0.818561 loss)
I0823 11:35:10.001476 28265 solver.cpp:228] Iteration 61000, loss = 0.112458
I0823 11:35:10.001518 28265 solver.cpp:244]     Train net output #0: loss = 0.112458 (* 1 = 0.112458 loss)
I0823 11:35:10.001528 28265 sgd_solver.cpp:106] Iteration 61000, lr = 0.000259203
I0823 11:35:14.505837 28265 solver.cpp:228] Iteration 61100, loss = 0.140781
I0823 11:35:14.505882 28265 solver.cpp:244]     Train net output #0: loss = 0.140781 (* 1 = 0.140781 loss)
I0823 11:35:14.505887 28265 sgd_solver.cpp:106] Iteration 61100, lr = 0.000258964
I0823 11:35:19.024235 28265 solver.cpp:228] Iteration 61200, loss = 0.13238
I0823 11:35:19.024281 28265 solver.cpp:244]     Train net output #0: loss = 0.13238 (* 1 = 0.13238 loss)
I0823 11:35:19.024286 28265 sgd_solver.cpp:106] Iteration 61200, lr = 0.000258724
I0823 11:35:23.533084 28265 solver.cpp:228] Iteration 61300, loss = 0.0954428
I0823 11:35:23.533129 28265 solver.cpp:244]     Train net output #0: loss = 0.0954428 (* 1 = 0.0954428 loss)
I0823 11:35:23.533135 28265 sgd_solver.cpp:106] Iteration 61300, lr = 0.000258486
I0823 11:35:28.044332 28265 solver.cpp:228] Iteration 61400, loss = 0.0582958
I0823 11:35:28.044353 28265 solver.cpp:244]     Train net output #0: loss = 0.0582958 (* 1 = 0.0582958 loss)
I0823 11:35:28.044356 28265 sgd_solver.cpp:106] Iteration 61400, lr = 0.000258247
I0823 11:35:32.514361 28265 solver.cpp:337] Iteration 61500, Testing net (#0)
I0823 11:35:35.978957 28265 solver.cpp:404]     Test net output #0: accuracy = 0.808209
I0823 11:35:35.979006 28265 solver.cpp:404]     Test net output #1: loss = 0.739312 (* 1 = 0.739312 loss)
I0823 11:35:35.994192 28265 solver.cpp:228] Iteration 61500, loss = 0.0995397
I0823 11:35:35.994240 28265 solver.cpp:244]     Train net output #0: loss = 0.0995397 (* 1 = 0.0995397 loss)
I0823 11:35:35.994251 28265 sgd_solver.cpp:106] Iteration 61500, lr = 0.00025801
I0823 11:35:40.507742 28265 solver.cpp:228] Iteration 61600, loss = 0.0815164
I0823 11:35:40.507787 28265 solver.cpp:244]     Train net output #0: loss = 0.0815164 (* 1 = 0.0815164 loss)
I0823 11:35:40.507792 28265 sgd_solver.cpp:106] Iteration 61600, lr = 0.000257773
I0823 11:35:45.023746 28265 solver.cpp:228] Iteration 61700, loss = 0.0920653
I0823 11:35:45.023797 28265 solver.cpp:244]     Train net output #0: loss = 0.0920653 (* 1 = 0.0920653 loss)
I0823 11:35:45.023802 28265 sgd_solver.cpp:106] Iteration 61700, lr = 0.000257536
I0823 11:35:49.533401 28265 solver.cpp:228] Iteration 61800, loss = 0.155932
I0823 11:35:49.533449 28265 solver.cpp:244]     Train net output #0: loss = 0.155932 (* 1 = 0.155932 loss)
I0823 11:35:49.533454 28265 sgd_solver.cpp:106] Iteration 61800, lr = 0.0002573
I0823 11:35:54.042418 28265 solver.cpp:228] Iteration 61900, loss = 0.0684611
I0823 11:35:54.042474 28265 solver.cpp:244]     Train net output #0: loss = 0.0684611 (* 1 = 0.0684611 loss)
I0823 11:35:54.042481 28265 sgd_solver.cpp:106] Iteration 61900, lr = 0.000257064
I0823 11:35:58.512150 28265 solver.cpp:337] Iteration 62000, Testing net (#0)
I0823 11:36:02.192514 28265 solver.cpp:404]     Test net output #0: accuracy = 0.771
I0823 11:36:02.192586 28265 solver.cpp:404]     Test net output #1: loss = 0.94857 (* 1 = 0.94857 loss)
I0823 11:36:02.207862 28265 solver.cpp:228] Iteration 62000, loss = 0.156597
I0823 11:36:02.207931 28265 solver.cpp:244]     Train net output #0: loss = 0.156597 (* 1 = 0.156597 loss)
I0823 11:36:02.207952 28265 sgd_solver.cpp:106] Iteration 62000, lr = 0.000256829
I0823 11:36:06.720713 28265 solver.cpp:228] Iteration 62100, loss = 0.0580925
I0823 11:36:06.720782 28265 solver.cpp:244]     Train net output #0: loss = 0.0580925 (* 1 = 0.0580925 loss)
I0823 11:36:06.720790 28265 sgd_solver.cpp:106] Iteration 62100, lr = 0.000256594
I0823 11:36:11.228886 28265 solver.cpp:228] Iteration 62200, loss = 0.201735
I0823 11:36:11.228945 28265 solver.cpp:244]     Train net output #0: loss = 0.201735 (* 1 = 0.201735 loss)
I0823 11:36:11.228952 28265 sgd_solver.cpp:106] Iteration 62200, lr = 0.00025636
I0823 11:36:15.752452 28265 solver.cpp:228] Iteration 62300, loss = 0.0663657
I0823 11:36:15.752499 28265 solver.cpp:244]     Train net output #0: loss = 0.0663657 (* 1 = 0.0663657 loss)
I0823 11:36:15.752504 28265 sgd_solver.cpp:106] Iteration 62300, lr = 0.000256126
I0823 11:36:20.259459 28265 solver.cpp:228] Iteration 62400, loss = 0.0351918
I0823 11:36:20.259480 28265 solver.cpp:244]     Train net output #0: loss = 0.0351918 (* 1 = 0.0351918 loss)
I0823 11:36:20.259485 28265 sgd_solver.cpp:106] Iteration 62400, lr = 0.000255893
I0823 11:36:24.729846 28265 solver.cpp:337] Iteration 62500, Testing net (#0)
I0823 11:36:28.478621 28265 solver.cpp:404]     Test net output #0: accuracy = 0.848208
I0823 11:36:28.478687 28265 solver.cpp:404]     Test net output #1: loss = 0.574149 (* 1 = 0.574149 loss)
I0823 11:36:28.494966 28265 solver.cpp:228] Iteration 62500, loss = 0.0242116
I0823 11:36:28.495003 28265 solver.cpp:244]     Train net output #0: loss = 0.0242116 (* 1 = 0.0242116 loss)
I0823 11:36:28.495018 28265 sgd_solver.cpp:106] Iteration 62500, lr = 0.000255661
I0823 11:36:33.006793 28265 solver.cpp:228] Iteration 62600, loss = 0.0977194
I0823 11:36:33.006847 28265 solver.cpp:244]     Train net output #0: loss = 0.0977194 (* 1 = 0.0977194 loss)
I0823 11:36:33.006858 28265 sgd_solver.cpp:106] Iteration 62600, lr = 0.000255428
I0823 11:36:37.525612 28265 solver.cpp:228] Iteration 62700, loss = 0.057541
I0823 11:36:37.525670 28265 solver.cpp:244]     Train net output #0: loss = 0.057541 (* 1 = 0.057541 loss)
I0823 11:36:37.525676 28265 sgd_solver.cpp:106] Iteration 62700, lr = 0.000255197
I0823 11:36:42.036167 28265 solver.cpp:228] Iteration 62800, loss = 0.0782247
I0823 11:36:42.036211 28265 solver.cpp:244]     Train net output #0: loss = 0.0782247 (* 1 = 0.0782247 loss)
I0823 11:36:42.036216 28265 sgd_solver.cpp:106] Iteration 62800, lr = 0.000254966
I0823 11:36:46.541376 28265 solver.cpp:228] Iteration 62900, loss = 0.0564296
I0823 11:36:46.541421 28265 solver.cpp:244]     Train net output #0: loss = 0.0564296 (* 1 = 0.0564296 loss)
I0823 11:36:46.541427 28265 sgd_solver.cpp:106] Iteration 62900, lr = 0.000254735
I0823 11:36:51.002250 28265 solver.cpp:337] Iteration 63000, Testing net (#0)
I0823 11:36:52.034092 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:36:54.360023 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841583
I0823 11:36:54.360093 28265 solver.cpp:404]     Test net output #1: loss = 0.624053 (* 1 = 0.624053 loss)
I0823 11:36:54.375488 28265 solver.cpp:228] Iteration 63000, loss = 0.0663897
I0823 11:36:54.375520 28265 solver.cpp:244]     Train net output #0: loss = 0.0663897 (* 1 = 0.0663897 loss)
I0823 11:36:54.375532 28265 sgd_solver.cpp:106] Iteration 63000, lr = 0.000254505
I0823 11:36:58.881933 28265 solver.cpp:228] Iteration 63100, loss = 0.0287267
I0823 11:36:58.881979 28265 solver.cpp:244]     Train net output #0: loss = 0.0287267 (* 1 = 0.0287267 loss)
I0823 11:36:58.881984 28265 sgd_solver.cpp:106] Iteration 63100, lr = 0.000254275
I0823 11:37:03.398288 28265 solver.cpp:228] Iteration 63200, loss = 0.0510513
I0823 11:37:03.398356 28265 solver.cpp:244]     Train net output #0: loss = 0.0510513 (* 1 = 0.0510513 loss)
I0823 11:37:03.398375 28265 sgd_solver.cpp:106] Iteration 63200, lr = 0.000254046
I0823 11:37:07.907829 28265 solver.cpp:228] Iteration 63300, loss = 0.154045
I0823 11:37:07.907873 28265 solver.cpp:244]     Train net output #0: loss = 0.154045 (* 1 = 0.154045 loss)
I0823 11:37:07.907878 28265 sgd_solver.cpp:106] Iteration 63300, lr = 0.000253817
I0823 11:37:12.425307 28265 solver.cpp:228] Iteration 63400, loss = 0.137147
I0823 11:37:12.425354 28265 solver.cpp:244]     Train net output #0: loss = 0.137147 (* 1 = 0.137147 loss)
I0823 11:37:12.425359 28265 sgd_solver.cpp:106] Iteration 63400, lr = 0.000253589
I0823 11:37:16.889616 28265 solver.cpp:337] Iteration 63500, Testing net (#0)
I0823 11:37:20.589419 28265 solver.cpp:404]     Test net output #0: accuracy = 0.814917
I0823 11:37:20.589493 28265 solver.cpp:404]     Test net output #1: loss = 0.765545 (* 1 = 0.765545 loss)
I0823 11:37:20.604658 28265 solver.cpp:228] Iteration 63500, loss = 0.115413
I0823 11:37:20.604696 28265 solver.cpp:244]     Train net output #0: loss = 0.115413 (* 1 = 0.115413 loss)
I0823 11:37:20.604719 28265 sgd_solver.cpp:106] Iteration 63500, lr = 0.000253361
I0823 11:37:25.114118 28265 solver.cpp:228] Iteration 63600, loss = 0.105726
I0823 11:37:25.114172 28265 solver.cpp:244]     Train net output #0: loss = 0.105726 (* 1 = 0.105726 loss)
I0823 11:37:25.114182 28265 sgd_solver.cpp:106] Iteration 63600, lr = 0.000253133
I0823 11:37:29.620126 28265 solver.cpp:228] Iteration 63700, loss = 0.109261
I0823 11:37:29.620175 28265 solver.cpp:244]     Train net output #0: loss = 0.109261 (* 1 = 0.109261 loss)
I0823 11:37:29.620182 28265 sgd_solver.cpp:106] Iteration 63700, lr = 0.000252907
I0823 11:37:34.136443 28265 solver.cpp:228] Iteration 63800, loss = 0.104868
I0823 11:37:34.136488 28265 solver.cpp:244]     Train net output #0: loss = 0.104868 (* 1 = 0.104868 loss)
I0823 11:37:34.136493 28265 sgd_solver.cpp:106] Iteration 63800, lr = 0.00025268
I0823 11:37:38.658669 28265 solver.cpp:228] Iteration 63900, loss = 0.137865
I0823 11:37:38.658689 28265 solver.cpp:244]     Train net output #0: loss = 0.137865 (* 1 = 0.137865 loss)
I0823 11:37:38.658694 28265 sgd_solver.cpp:106] Iteration 63900, lr = 0.000252454
I0823 11:37:43.124130 28265 solver.cpp:337] Iteration 64000, Testing net (#0)
I0823 11:37:46.736403 28265 solver.cpp:404]     Test net output #0: accuracy = 0.847209
I0823 11:37:46.736449 28265 solver.cpp:404]     Test net output #1: loss = 0.602031 (* 1 = 0.602031 loss)
I0823 11:37:46.752729 28265 solver.cpp:228] Iteration 64000, loss = 0.124953
I0823 11:37:46.752774 28265 solver.cpp:244]     Train net output #0: loss = 0.124953 (* 1 = 0.124953 loss)
I0823 11:37:46.752784 28265 sgd_solver.cpp:106] Iteration 64000, lr = 0.000252229
I0823 11:37:51.269397 28265 solver.cpp:228] Iteration 64100, loss = 0.0547859
I0823 11:37:51.269553 28265 solver.cpp:244]     Train net output #0: loss = 0.0547859 (* 1 = 0.0547859 loss)
I0823 11:37:51.269583 28265 sgd_solver.cpp:106] Iteration 64100, lr = 0.000252004
I0823 11:37:55.783031 28265 solver.cpp:228] Iteration 64200, loss = 0.125361
I0823 11:37:55.783077 28265 solver.cpp:244]     Train net output #0: loss = 0.125361 (* 1 = 0.125361 loss)
I0823 11:37:55.783082 28265 sgd_solver.cpp:106] Iteration 64200, lr = 0.000251779
I0823 11:38:00.298637 28265 solver.cpp:228] Iteration 64300, loss = 0.0772352
I0823 11:38:00.298717 28265 solver.cpp:244]     Train net output #0: loss = 0.0772352 (* 1 = 0.0772352 loss)
I0823 11:38:00.298732 28265 sgd_solver.cpp:106] Iteration 64300, lr = 0.000251555
I0823 11:38:04.813691 28265 solver.cpp:228] Iteration 64400, loss = 0.154695
I0823 11:38:04.813735 28265 solver.cpp:244]     Train net output #0: loss = 0.154695 (* 1 = 0.154695 loss)
I0823 11:38:04.813740 28265 sgd_solver.cpp:106] Iteration 64400, lr = 0.000251332
I0823 11:38:09.280349 28265 solver.cpp:337] Iteration 64500, Testing net (#0)
I0823 11:38:12.636924 28265 solver.cpp:404]     Test net output #0: accuracy = 0.797542
I0823 11:38:12.636976 28265 solver.cpp:404]     Test net output #1: loss = 0.869745 (* 1 = 0.869745 loss)
I0823 11:38:12.652120 28265 solver.cpp:228] Iteration 64500, loss = 0.0965454
I0823 11:38:12.652252 28265 solver.cpp:244]     Train net output #0: loss = 0.0965454 (* 1 = 0.0965454 loss)
I0823 11:38:12.652264 28265 sgd_solver.cpp:106] Iteration 64500, lr = 0.000251109
I0823 11:38:17.154201 28265 solver.cpp:228] Iteration 64600, loss = 0.0477325
I0823 11:38:17.154248 28265 solver.cpp:244]     Train net output #0: loss = 0.0477325 (* 1 = 0.0477325 loss)
I0823 11:38:17.154253 28265 sgd_solver.cpp:106] Iteration 64600, lr = 0.000250886
I0823 11:38:21.658331 28265 solver.cpp:228] Iteration 64700, loss = 0.0657825
I0823 11:38:21.658351 28265 solver.cpp:244]     Train net output #0: loss = 0.0657825 (* 1 = 0.0657825 loss)
I0823 11:38:21.658356 28265 sgd_solver.cpp:106] Iteration 64700, lr = 0.000250664
I0823 11:38:26.165818 28265 solver.cpp:228] Iteration 64800, loss = 0.0221656
I0823 11:38:26.165838 28265 solver.cpp:244]     Train net output #0: loss = 0.0221656 (* 1 = 0.0221656 loss)
I0823 11:38:26.165843 28265 sgd_solver.cpp:106] Iteration 64800, lr = 0.000250442
I0823 11:38:30.673214 28265 solver.cpp:228] Iteration 64900, loss = 0.0452391
I0823 11:38:30.673259 28265 solver.cpp:244]     Train net output #0: loss = 0.0452391 (* 1 = 0.0452391 loss)
I0823 11:38:30.673264 28265 sgd_solver.cpp:106] Iteration 64900, lr = 0.000250221
I0823 11:38:35.134418 28265 solver.cpp:337] Iteration 65000, Testing net (#0)
I0823 11:38:38.671197 28265 solver.cpp:404]     Test net output #0: accuracy = 0.767292
I0823 11:38:38.671308 28265 solver.cpp:404]     Test net output #1: loss = 1.0612 (* 1 = 1.0612 loss)
I0823 11:38:38.687988 28265 solver.cpp:228] Iteration 65000, loss = 0.240773
I0823 11:38:38.688050 28265 solver.cpp:244]     Train net output #0: loss = 0.240773 (* 1 = 0.240773 loss)
I0823 11:38:38.688066 28265 sgd_solver.cpp:106] Iteration 65000, lr = 0.00025
I0823 11:38:43.197851 28265 solver.cpp:228] Iteration 65100, loss = 0.201612
I0823 11:38:43.197897 28265 solver.cpp:244]     Train net output #0: loss = 0.201612 (* 1 = 0.201612 loss)
I0823 11:38:43.197903 28265 sgd_solver.cpp:106] Iteration 65100, lr = 0.00024978
I0823 11:38:47.719395 28265 solver.cpp:228] Iteration 65200, loss = 0.0897279
I0823 11:38:47.719445 28265 solver.cpp:244]     Train net output #0: loss = 0.0897279 (* 1 = 0.0897279 loss)
I0823 11:38:47.719450 28265 sgd_solver.cpp:106] Iteration 65200, lr = 0.00024956
I0823 11:38:52.229243 28265 solver.cpp:228] Iteration 65300, loss = 0.0118909
I0823 11:38:52.229291 28265 solver.cpp:244]     Train net output #0: loss = 0.0118909 (* 1 = 0.0118909 loss)
I0823 11:38:52.229297 28265 sgd_solver.cpp:106] Iteration 65300, lr = 0.00024934
I0823 11:38:56.750700 28265 solver.cpp:228] Iteration 65400, loss = 0.0174785
I0823 11:38:56.750753 28265 solver.cpp:244]     Train net output #0: loss = 0.0174785 (* 1 = 0.0174785 loss)
I0823 11:38:56.750759 28265 sgd_solver.cpp:106] Iteration 65400, lr = 0.000249121
I0823 11:39:01.215972 28265 solver.cpp:337] Iteration 65500, Testing net (#0)
I0823 11:39:04.474505 28265 solver.cpp:404]     Test net output #0: accuracy = 0.8415
I0823 11:39:04.474572 28265 solver.cpp:404]     Test net output #1: loss = 0.658261 (* 1 = 0.658261 loss)
I0823 11:39:04.491009 28265 solver.cpp:228] Iteration 65500, loss = 0.139705
I0823 11:39:04.491050 28265 solver.cpp:244]     Train net output #0: loss = 0.139705 (* 1 = 0.139705 loss)
I0823 11:39:04.491062 28265 sgd_solver.cpp:106] Iteration 65500, lr = 0.000248903
I0823 11:39:08.995949 28265 solver.cpp:228] Iteration 65600, loss = 0.048173
I0823 11:39:08.995973 28265 solver.cpp:244]     Train net output #0: loss = 0.048173 (* 1 = 0.048173 loss)
I0823 11:39:08.995977 28265 sgd_solver.cpp:106] Iteration 65600, lr = 0.000248685
I0823 11:39:13.502349 28265 solver.cpp:228] Iteration 65700, loss = 0.116936
I0823 11:39:13.502372 28265 solver.cpp:244]     Train net output #0: loss = 0.116936 (* 1 = 0.116936 loss)
I0823 11:39:13.502377 28265 sgd_solver.cpp:106] Iteration 65700, lr = 0.000248467
I0823 11:39:18.007776 28265 solver.cpp:228] Iteration 65800, loss = 0.122174
I0823 11:39:18.007820 28265 solver.cpp:244]     Train net output #0: loss = 0.122174 (* 1 = 0.122174 loss)
I0823 11:39:18.007827 28265 sgd_solver.cpp:106] Iteration 65800, lr = 0.00024825
I0823 11:39:22.517606 28265 solver.cpp:228] Iteration 65900, loss = 0.0259932
I0823 11:39:22.517663 28265 solver.cpp:244]     Train net output #0: loss = 0.0259932 (* 1 = 0.0259932 loss)
I0823 11:39:22.517670 28265 sgd_solver.cpp:106] Iteration 65900, lr = 0.000248033
I0823 11:39:26.987722 28265 solver.cpp:337] Iteration 66000, Testing net (#0)
I0823 11:39:27.761535 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:39:30.540854 28265 solver.cpp:404]     Test net output #0: accuracy = 0.840292
I0823 11:39:30.540932 28265 solver.cpp:404]     Test net output #1: loss = 0.67704 (* 1 = 0.67704 loss)
I0823 11:39:30.556890 28265 solver.cpp:228] Iteration 66000, loss = 0.0312432
I0823 11:39:30.556947 28265 solver.cpp:244]     Train net output #0: loss = 0.0312432 (* 1 = 0.0312432 loss)
I0823 11:39:30.556965 28265 sgd_solver.cpp:106] Iteration 66000, lr = 0.000247817
I0823 11:39:35.063014 28265 solver.cpp:228] Iteration 66100, loss = 0.0588734
I0823 11:39:35.063058 28265 solver.cpp:244]     Train net output #0: loss = 0.0588734 (* 1 = 0.0588734 loss)
I0823 11:39:35.063063 28265 sgd_solver.cpp:106] Iteration 66100, lr = 0.000247601
I0823 11:39:39.574271 28265 solver.cpp:228] Iteration 66200, loss = 0.0296297
I0823 11:39:39.574337 28265 solver.cpp:244]     Train net output #0: loss = 0.0296297 (* 1 = 0.0296297 loss)
I0823 11:39:39.574343 28265 sgd_solver.cpp:106] Iteration 66200, lr = 0.000247385
I0823 11:39:44.078903 28265 solver.cpp:228] Iteration 66300, loss = 0.039367
I0823 11:39:44.078959 28265 solver.cpp:244]     Train net output #0: loss = 0.039367 (* 1 = 0.039367 loss)
I0823 11:39:44.078965 28265 sgd_solver.cpp:106] Iteration 66300, lr = 0.00024717
I0823 11:39:48.590286 28265 solver.cpp:228] Iteration 66400, loss = 0.109111
I0823 11:39:48.590342 28265 solver.cpp:244]     Train net output #0: loss = 0.109111 (* 1 = 0.109111 loss)
I0823 11:39:48.590348 28265 sgd_solver.cpp:106] Iteration 66400, lr = 0.000246956
I0823 11:39:53.051304 28265 solver.cpp:337] Iteration 66500, Testing net (#0)
I0823 11:39:56.818437 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843542
I0823 11:39:56.818508 28265 solver.cpp:404]     Test net output #1: loss = 0.674652 (* 1 = 0.674652 loss)
I0823 11:39:56.834393 28265 solver.cpp:228] Iteration 66500, loss = 0.0743962
I0823 11:39:56.834471 28265 solver.cpp:244]     Train net output #0: loss = 0.0743962 (* 1 = 0.0743962 loss)
I0823 11:39:56.834491 28265 sgd_solver.cpp:106] Iteration 66500, lr = 0.000246741
I0823 11:40:01.348940 28265 solver.cpp:228] Iteration 66600, loss = 0.0633326
I0823 11:40:01.348986 28265 solver.cpp:244]     Train net output #0: loss = 0.0633326 (* 1 = 0.0633326 loss)
I0823 11:40:01.348991 28265 sgd_solver.cpp:106] Iteration 66600, lr = 0.000246528
I0823 11:40:05.855854 28265 solver.cpp:228] Iteration 66700, loss = 0.0125194
I0823 11:40:05.855876 28265 solver.cpp:244]     Train net output #0: loss = 0.0125194 (* 1 = 0.0125194 loss)
I0823 11:40:05.855881 28265 sgd_solver.cpp:106] Iteration 66700, lr = 0.000246314
I0823 11:40:10.370642 28265 solver.cpp:228] Iteration 66800, loss = 0.10806
I0823 11:40:10.370690 28265 solver.cpp:244]     Train net output #0: loss = 0.10806 (* 1 = 0.10806 loss)
I0823 11:40:10.370697 28265 sgd_solver.cpp:106] Iteration 66800, lr = 0.000246102
I0823 11:40:14.877301 28265 solver.cpp:228] Iteration 66900, loss = 0.0305445
I0823 11:40:14.877358 28265 solver.cpp:244]     Train net output #0: loss = 0.0305445 (* 1 = 0.0305445 loss)
I0823 11:40:14.877368 28265 sgd_solver.cpp:106] Iteration 66900, lr = 0.000245889
I0823 11:40:19.342536 28265 solver.cpp:337] Iteration 67000, Testing net (#0)
I0823 11:40:22.943233 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841417
I0823 11:40:22.943305 28265 solver.cpp:404]     Test net output #1: loss = 0.684968 (* 1 = 0.684968 loss)
I0823 11:40:22.958431 28265 solver.cpp:228] Iteration 67000, loss = 0.0192343
I0823 11:40:22.958475 28265 solver.cpp:244]     Train net output #0: loss = 0.0192343 (* 1 = 0.0192343 loss)
I0823 11:40:22.958488 28265 sgd_solver.cpp:106] Iteration 67000, lr = 0.000245677
I0823 11:40:27.468950 28265 solver.cpp:228] Iteration 67100, loss = 0.061888
I0823 11:40:27.468971 28265 solver.cpp:244]     Train net output #0: loss = 0.061888 (* 1 = 0.061888 loss)
I0823 11:40:27.468976 28265 sgd_solver.cpp:106] Iteration 67100, lr = 0.000245466
I0823 11:40:31.973832 28265 solver.cpp:228] Iteration 67200, loss = 0.0718771
I0823 11:40:31.973851 28265 solver.cpp:244]     Train net output #0: loss = 0.0718771 (* 1 = 0.0718771 loss)
I0823 11:40:31.973856 28265 sgd_solver.cpp:106] Iteration 67200, lr = 0.000245254
I0823 11:40:36.479686 28265 solver.cpp:228] Iteration 67300, loss = 0.068781
I0823 11:40:36.479707 28265 solver.cpp:244]     Train net output #0: loss = 0.068781 (* 1 = 0.068781 loss)
I0823 11:40:36.479712 28265 sgd_solver.cpp:106] Iteration 67300, lr = 0.000245044
I0823 11:40:40.986865 28265 solver.cpp:228] Iteration 67400, loss = 0.0609586
I0823 11:40:40.986925 28265 solver.cpp:244]     Train net output #0: loss = 0.0609586 (* 1 = 0.0609586 loss)
I0823 11:40:40.986932 28265 sgd_solver.cpp:106] Iteration 67400, lr = 0.000244833
I0823 11:40:45.451112 28265 solver.cpp:337] Iteration 67500, Testing net (#0)
I0823 11:40:48.634771 28265 solver.cpp:404]     Test net output #0: accuracy = 0.848958
I0823 11:40:48.634843 28265 solver.cpp:404]     Test net output #1: loss = 0.648223 (* 1 = 0.648223 loss)
I0823 11:40:48.649925 28265 solver.cpp:228] Iteration 67500, loss = 0.0234665
I0823 11:40:48.649982 28265 solver.cpp:244]     Train net output #0: loss = 0.0234665 (* 1 = 0.0234665 loss)
I0823 11:40:48.649996 28265 sgd_solver.cpp:106] Iteration 67500, lr = 0.000244623
I0823 11:40:53.164166 28265 solver.cpp:228] Iteration 67600, loss = 0.0648789
I0823 11:40:53.164211 28265 solver.cpp:244]     Train net output #0: loss = 0.0648789 (* 1 = 0.0648789 loss)
I0823 11:40:53.164217 28265 sgd_solver.cpp:106] Iteration 67600, lr = 0.000244414
I0823 11:40:57.686010 28265 solver.cpp:228] Iteration 67700, loss = 0.0113494
I0823 11:40:57.686058 28265 solver.cpp:244]     Train net output #0: loss = 0.0113494 (* 1 = 0.0113494 loss)
I0823 11:40:57.686063 28265 sgd_solver.cpp:106] Iteration 67700, lr = 0.000244205
I0823 11:41:02.217720 28265 solver.cpp:228] Iteration 67800, loss = 0.0804958
I0823 11:41:02.217764 28265 solver.cpp:244]     Train net output #0: loss = 0.0804958 (* 1 = 0.0804958 loss)
I0823 11:41:02.217772 28265 sgd_solver.cpp:106] Iteration 67800, lr = 0.000243996
I0823 11:41:06.725014 28265 solver.cpp:228] Iteration 67900, loss = 0.0192789
I0823 11:41:06.725060 28265 solver.cpp:244]     Train net output #0: loss = 0.0192789 (* 1 = 0.0192789 loss)
I0823 11:41:06.725065 28265 sgd_solver.cpp:106] Iteration 67900, lr = 0.000243788
I0823 11:41:11.188433 28265 solver.cpp:337] Iteration 68000, Testing net (#0)
I0823 11:41:14.377248 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843375
I0823 11:41:14.377352 28265 solver.cpp:404]     Test net output #1: loss = 0.709608 (* 1 = 0.709608 loss)
I0823 11:41:14.394356 28265 solver.cpp:228] Iteration 68000, loss = 0.00746928
I0823 11:41:14.394415 28265 solver.cpp:244]     Train net output #0: loss = 0.00746928 (* 1 = 0.00746928 loss)
I0823 11:41:14.394430 28265 sgd_solver.cpp:106] Iteration 68000, lr = 0.00024358
I0823 11:41:18.906765 28265 solver.cpp:228] Iteration 68100, loss = 0.00921615
I0823 11:41:18.906808 28265 solver.cpp:244]     Train net output #0: loss = 0.00921615 (* 1 = 0.00921615 loss)
I0823 11:41:18.906813 28265 sgd_solver.cpp:106] Iteration 68100, lr = 0.000243373
I0823 11:41:23.418076 28265 solver.cpp:228] Iteration 68200, loss = 0.0649579
I0823 11:41:23.418123 28265 solver.cpp:244]     Train net output #0: loss = 0.0649579 (* 1 = 0.0649579 loss)
I0823 11:41:23.418128 28265 sgd_solver.cpp:106] Iteration 68200, lr = 0.000243166
I0823 11:41:27.933094 28265 solver.cpp:228] Iteration 68300, loss = 0.023725
I0823 11:41:27.933141 28265 solver.cpp:244]     Train net output #0: loss = 0.023725 (* 1 = 0.023725 loss)
I0823 11:41:27.933146 28265 sgd_solver.cpp:106] Iteration 68300, lr = 0.000242959
I0823 11:41:32.438982 28265 solver.cpp:228] Iteration 68400, loss = 0.0347917
I0823 11:41:32.439002 28265 solver.cpp:244]     Train net output #0: loss = 0.0347917 (* 1 = 0.0347917 loss)
I0823 11:41:32.439007 28265 sgd_solver.cpp:106] Iteration 68400, lr = 0.000242753
I0823 11:41:36.911294 28265 solver.cpp:337] Iteration 68500, Testing net (#0)
I0823 11:41:40.318516 28265 solver.cpp:404]     Test net output #0: accuracy = 0.812792
I0823 11:41:40.318569 28265 solver.cpp:404]     Test net output #1: loss = 0.910212 (* 1 = 0.910212 loss)
I0823 11:41:40.333773 28265 solver.cpp:228] Iteration 68500, loss = 0.0226592
I0823 11:41:40.333818 28265 solver.cpp:244]     Train net output #0: loss = 0.0226592 (* 1 = 0.0226592 loss)
I0823 11:41:40.333837 28265 sgd_solver.cpp:106] Iteration 68500, lr = 0.000242547
I0823 11:41:44.839815 28265 solver.cpp:228] Iteration 68600, loss = 0.0537773
I0823 11:41:44.839846 28265 solver.cpp:244]     Train net output #0: loss = 0.0537773 (* 1 = 0.0537773 loss)
I0823 11:41:44.839851 28265 sgd_solver.cpp:106] Iteration 68600, lr = 0.000242342
I0823 11:41:49.350181 28265 solver.cpp:228] Iteration 68700, loss = 0.0290966
I0823 11:41:49.350203 28265 solver.cpp:244]     Train net output #0: loss = 0.0290966 (* 1 = 0.0290966 loss)
I0823 11:41:49.350208 28265 sgd_solver.cpp:106] Iteration 68700, lr = 0.000242137
I0823 11:41:53.856608 28265 solver.cpp:228] Iteration 68800, loss = 0.0220321
I0823 11:41:53.856628 28265 solver.cpp:244]     Train net output #0: loss = 0.0220321 (* 1 = 0.0220321 loss)
I0823 11:41:53.856634 28265 sgd_solver.cpp:106] Iteration 68800, lr = 0.000241933
I0823 11:41:58.368130 28265 solver.cpp:228] Iteration 68900, loss = 0.00411248
I0823 11:41:58.368194 28265 solver.cpp:244]     Train net output #0: loss = 0.00411248 (* 1 = 0.00411248 loss)
I0823 11:41:58.368201 28265 sgd_solver.cpp:106] Iteration 68900, lr = 0.000241729
I0823 11:42:02.839442 28265 solver.cpp:337] Iteration 69000, Testing net (#0)
I0823 11:42:05.074786 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:42:06.332206 28265 solver.cpp:404]     Test net output #0: accuracy = 0.778666
I0823 11:42:06.332274 28265 solver.cpp:404]     Test net output #1: loss = 1.17823 (* 1 = 1.17823 loss)
I0823 11:42:06.347676 28265 solver.cpp:228] Iteration 69000, loss = 0.033558
I0823 11:42:06.347723 28265 solver.cpp:244]     Train net output #0: loss = 0.033558 (* 1 = 0.033558 loss)
I0823 11:42:06.347738 28265 sgd_solver.cpp:106] Iteration 69000, lr = 0.000241525
I0823 11:42:10.860064 28265 solver.cpp:228] Iteration 69100, loss = 0.0528415
I0823 11:42:10.860110 28265 solver.cpp:244]     Train net output #0: loss = 0.0528415 (* 1 = 0.0528415 loss)
I0823 11:42:10.860116 28265 sgd_solver.cpp:106] Iteration 69100, lr = 0.000241321
I0823 11:42:15.378242 28265 solver.cpp:228] Iteration 69200, loss = 0.0482288
I0823 11:42:15.378288 28265 solver.cpp:244]     Train net output #0: loss = 0.0482288 (* 1 = 0.0482288 loss)
I0823 11:42:15.378293 28265 sgd_solver.cpp:106] Iteration 69200, lr = 0.000241119
I0823 11:42:19.900634 28265 solver.cpp:228] Iteration 69300, loss = 0.00902206
I0823 11:42:19.900678 28265 solver.cpp:244]     Train net output #0: loss = 0.00902206 (* 1 = 0.00902206 loss)
I0823 11:42:19.900684 28265 sgd_solver.cpp:106] Iteration 69300, lr = 0.000240916
I0823 11:42:24.410281 28265 solver.cpp:228] Iteration 69400, loss = 0.0194334
I0823 11:42:24.410326 28265 solver.cpp:244]     Train net output #0: loss = 0.0194334 (* 1 = 0.0194334 loss)
I0823 11:42:24.410332 28265 sgd_solver.cpp:106] Iteration 69400, lr = 0.000240714
I0823 11:42:28.872476 28265 solver.cpp:337] Iteration 69500, Testing net (#0)
I0823 11:42:32.202898 28265 solver.cpp:404]     Test net output #0: accuracy = 0.820417
I0823 11:42:32.202944 28265 solver.cpp:404]     Test net output #1: loss = 0.912475 (* 1 = 0.912475 loss)
I0823 11:42:32.218766 28265 solver.cpp:228] Iteration 69500, loss = 0.0713244
I0823 11:42:32.218811 28265 solver.cpp:244]     Train net output #0: loss = 0.0713244 (* 1 = 0.0713244 loss)
I0823 11:42:32.218823 28265 sgd_solver.cpp:106] Iteration 69500, lr = 0.000240512
I0823 11:42:36.727031 28265 solver.cpp:228] Iteration 69600, loss = 0.0564092
I0823 11:42:36.727074 28265 solver.cpp:244]     Train net output #0: loss = 0.0564092 (* 1 = 0.0564092 loss)
I0823 11:42:36.727079 28265 sgd_solver.cpp:106] Iteration 69600, lr = 0.000240311
I0823 11:42:41.232992 28265 solver.cpp:228] Iteration 69700, loss = 0.00528815
I0823 11:42:41.233039 28265 solver.cpp:244]     Train net output #0: loss = 0.00528815 (* 1 = 0.00528815 loss)
I0823 11:42:41.233045 28265 sgd_solver.cpp:106] Iteration 69700, lr = 0.00024011
I0823 11:42:45.747642 28265 solver.cpp:228] Iteration 69800, loss = 0.010679
I0823 11:42:45.747689 28265 solver.cpp:244]     Train net output #0: loss = 0.010679 (* 1 = 0.010679 loss)
I0823 11:42:45.747695 28265 sgd_solver.cpp:106] Iteration 69800, lr = 0.000239909
I0823 11:42:50.253661 28265 solver.cpp:228] Iteration 69900, loss = 0.0711019
I0823 11:42:50.253712 28265 solver.cpp:244]     Train net output #0: loss = 0.0711019 (* 1 = 0.0711019 loss)
I0823 11:42:50.253718 28265 sgd_solver.cpp:106] Iteration 69900, lr = 0.000239709
I0823 11:42:54.720301 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_70000.caffemodel
I0823 11:42:55.197415 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_70000.solverstate
I0823 11:42:55.352941 28265 solver.cpp:337] Iteration 70000, Testing net (#0)
I0823 11:42:58.802194 28265 solver.cpp:404]     Test net output #0: accuracy = 0.848542
I0823 11:42:58.802242 28265 solver.cpp:404]     Test net output #1: loss = 0.753038 (* 1 = 0.753038 loss)
I0823 11:42:58.818011 28265 solver.cpp:228] Iteration 70000, loss = 0.00945148
I0823 11:42:58.818061 28265 solver.cpp:244]     Train net output #0: loss = 0.00945148 (* 1 = 0.00945148 loss)
I0823 11:42:58.818079 28265 sgd_solver.cpp:106] Iteration 70000, lr = 0.000239509
I0823 11:43:03.325335 28265 solver.cpp:228] Iteration 70100, loss = 0.026681
I0823 11:43:03.325392 28265 solver.cpp:244]     Train net output #0: loss = 0.026681 (* 1 = 0.026681 loss)
I0823 11:43:03.325404 28265 sgd_solver.cpp:106] Iteration 70100, lr = 0.00023931
I0823 11:43:07.841572 28265 solver.cpp:228] Iteration 70200, loss = 0.0277402
I0823 11:43:07.841621 28265 solver.cpp:244]     Train net output #0: loss = 0.0277402 (* 1 = 0.0277402 loss)
I0823 11:43:07.841627 28265 sgd_solver.cpp:106] Iteration 70200, lr = 0.000239111
I0823 11:43:12.358089 28265 solver.cpp:228] Iteration 70300, loss = 0.0753767
I0823 11:43:12.358109 28265 solver.cpp:244]     Train net output #0: loss = 0.0753767 (* 1 = 0.0753767 loss)
I0823 11:43:12.358114 28265 sgd_solver.cpp:106] Iteration 70300, lr = 0.000238912
I0823 11:43:16.872956 28265 solver.cpp:228] Iteration 70400, loss = 0.0347524
I0823 11:43:16.873003 28265 solver.cpp:244]     Train net output #0: loss = 0.0347524 (* 1 = 0.0347524 loss)
I0823 11:43:16.873009 28265 sgd_solver.cpp:106] Iteration 70400, lr = 0.000238714
I0823 11:43:21.343452 28265 solver.cpp:337] Iteration 70500, Testing net (#0)
I0823 11:43:24.578765 28265 solver.cpp:404]     Test net output #0: accuracy = 0.852333
I0823 11:43:24.578814 28265 solver.cpp:404]     Test net output #1: loss = 0.746571 (* 1 = 0.746571 loss)
I0823 11:43:24.594048 28265 solver.cpp:228] Iteration 70500, loss = 0.0142728
I0823 11:43:24.594094 28265 solver.cpp:244]     Train net output #0: loss = 0.0142728 (* 1 = 0.0142728 loss)
I0823 11:43:24.594105 28265 sgd_solver.cpp:106] Iteration 70500, lr = 0.000238516
I0823 11:43:29.102041 28265 solver.cpp:228] Iteration 70600, loss = 0.0215641
I0823 11:43:29.102108 28265 solver.cpp:244]     Train net output #0: loss = 0.0215641 (* 1 = 0.0215641 loss)
I0823 11:43:29.102113 28265 sgd_solver.cpp:106] Iteration 70600, lr = 0.000238319
I0823 11:43:33.613559 28265 solver.cpp:228] Iteration 70700, loss = 0.00311477
I0823 11:43:33.613623 28265 solver.cpp:244]     Train net output #0: loss = 0.00311477 (* 1 = 0.00311477 loss)
I0823 11:43:33.613636 28265 sgd_solver.cpp:106] Iteration 70700, lr = 0.000238122
I0823 11:43:38.127037 28265 solver.cpp:228] Iteration 70800, loss = 0.0256042
I0823 11:43:38.127106 28265 solver.cpp:244]     Train net output #0: loss = 0.0256042 (* 1 = 0.0256042 loss)
I0823 11:43:38.127135 28265 sgd_solver.cpp:106] Iteration 70800, lr = 0.000237925
I0823 11:43:42.635571 28265 solver.cpp:228] Iteration 70900, loss = 0.0490144
I0823 11:43:42.635591 28265 solver.cpp:244]     Train net output #0: loss = 0.0490144 (* 1 = 0.0490144 loss)
I0823 11:43:42.635596 28265 sgd_solver.cpp:106] Iteration 70900, lr = 0.000237729
I0823 11:43:47.096309 28265 solver.cpp:337] Iteration 71000, Testing net (#0)
I0823 11:43:50.594704 28265 solver.cpp:404]     Test net output #0: accuracy = 0.836125
I0823 11:43:50.594763 28265 solver.cpp:404]     Test net output #1: loss = 0.840184 (* 1 = 0.840184 loss)
I0823 11:43:50.610172 28265 solver.cpp:228] Iteration 71000, loss = 0.00498451
I0823 11:43:50.610222 28265 solver.cpp:244]     Train net output #0: loss = 0.00498451 (* 1 = 0.00498451 loss)
I0823 11:43:50.610240 28265 sgd_solver.cpp:106] Iteration 71000, lr = 0.000237533
I0823 11:43:55.115075 28265 solver.cpp:228] Iteration 71100, loss = 0.0172015
I0823 11:43:55.115146 28265 solver.cpp:244]     Train net output #0: loss = 0.0172015 (* 1 = 0.0172015 loss)
I0823 11:43:55.115152 28265 sgd_solver.cpp:106] Iteration 71100, lr = 0.000237337
I0823 11:43:59.622951 28265 solver.cpp:228] Iteration 71200, loss = 0.0519951
I0823 11:43:59.623009 28265 solver.cpp:244]     Train net output #0: loss = 0.0519951 (* 1 = 0.0519951 loss)
I0823 11:43:59.623019 28265 sgd_solver.cpp:106] Iteration 71200, lr = 0.000237142
I0823 11:44:04.137737 28265 solver.cpp:228] Iteration 71300, loss = 0.0214573
I0823 11:44:04.137811 28265 solver.cpp:244]     Train net output #0: loss = 0.0214573 (* 1 = 0.0214573 loss)
I0823 11:44:04.137825 28265 sgd_solver.cpp:106] Iteration 71300, lr = 0.000236947
I0823 11:44:08.648954 28265 solver.cpp:228] Iteration 71400, loss = 0.0150021
I0823 11:44:08.649001 28265 solver.cpp:244]     Train net output #0: loss = 0.0150021 (* 1 = 0.0150021 loss)
I0823 11:44:08.649008 28265 sgd_solver.cpp:106] Iteration 71400, lr = 0.000236753
I0823 11:44:13.120733 28265 solver.cpp:337] Iteration 71500, Testing net (#0)
I0823 11:44:16.718932 28265 solver.cpp:404]     Test net output #0: accuracy = 0.817667
I0823 11:44:16.719012 28265 solver.cpp:404]     Test net output #1: loss = 0.953127 (* 1 = 0.953127 loss)
I0823 11:44:16.734844 28265 solver.cpp:228] Iteration 71500, loss = 0.026481
I0823 11:44:16.734907 28265 solver.cpp:244]     Train net output #0: loss = 0.026481 (* 1 = 0.026481 loss)
I0823 11:44:16.734930 28265 sgd_solver.cpp:106] Iteration 71500, lr = 0.000236558
I0823 11:44:21.245674 28265 solver.cpp:228] Iteration 71600, loss = 0.0381646
I0823 11:44:21.245736 28265 solver.cpp:244]     Train net output #0: loss = 0.0381646 (* 1 = 0.0381646 loss)
I0823 11:44:21.245744 28265 sgd_solver.cpp:106] Iteration 71600, lr = 0.000236365
I0823 11:44:25.751863 28265 solver.cpp:228] Iteration 71700, loss = 0.0150894
I0823 11:44:25.751945 28265 solver.cpp:244]     Train net output #0: loss = 0.0150894 (* 1 = 0.0150894 loss)
I0823 11:44:25.751957 28265 sgd_solver.cpp:106] Iteration 71700, lr = 0.000236171
I0823 11:44:30.258082 28265 solver.cpp:228] Iteration 71800, loss = 0.018334
I0823 11:44:30.258126 28265 solver.cpp:244]     Train net output #0: loss = 0.018334 (* 1 = 0.018334 loss)
I0823 11:44:30.258132 28265 sgd_solver.cpp:106] Iteration 71800, lr = 0.000235978
I0823 11:44:34.765748 28265 solver.cpp:228] Iteration 71900, loss = 0.295816
I0823 11:44:34.765769 28265 solver.cpp:244]     Train net output #0: loss = 0.295816 (* 1 = 0.295816 loss)
I0823 11:44:34.765774 28265 sgd_solver.cpp:106] Iteration 71900, lr = 0.000235786
I0823 11:44:39.224905 28265 solver.cpp:337] Iteration 72000, Testing net (#0)
I0823 11:44:41.363970 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:44:42.853479 28265 solver.cpp:404]     Test net output #0: accuracy = 0.847208
I0823 11:44:42.853533 28265 solver.cpp:404]     Test net output #1: loss = 0.761249 (* 1 = 0.761249 loss)
I0823 11:44:42.868672 28265 solver.cpp:228] Iteration 72000, loss = 0.00884671
I0823 11:44:42.868711 28265 solver.cpp:244]     Train net output #0: loss = 0.00884671 (* 1 = 0.00884671 loss)
I0823 11:44:42.868721 28265 sgd_solver.cpp:106] Iteration 72000, lr = 0.000235594
I0823 11:44:47.378840 28265 solver.cpp:228] Iteration 72100, loss = 0.0627061
I0823 11:44:47.378883 28265 solver.cpp:244]     Train net output #0: loss = 0.0627061 (* 1 = 0.0627061 loss)
I0823 11:44:47.378890 28265 sgd_solver.cpp:106] Iteration 72100, lr = 0.000235402
I0823 11:44:51.888852 28265 solver.cpp:228] Iteration 72200, loss = 0.0188555
I0823 11:44:51.888901 28265 solver.cpp:244]     Train net output #0: loss = 0.0188555 (* 1 = 0.0188555 loss)
I0823 11:44:51.888906 28265 sgd_solver.cpp:106] Iteration 72200, lr = 0.00023521
I0823 11:44:56.401865 28265 solver.cpp:228] Iteration 72300, loss = 0.00816421
I0823 11:44:56.401911 28265 solver.cpp:244]     Train net output #0: loss = 0.00816421 (* 1 = 0.00816421 loss)
I0823 11:44:56.401916 28265 sgd_solver.cpp:106] Iteration 72300, lr = 0.000235019
I0823 11:45:00.919600 28265 solver.cpp:228] Iteration 72400, loss = 0.00129074
I0823 11:45:00.919647 28265 solver.cpp:244]     Train net output #0: loss = 0.00129074 (* 1 = 0.00129074 loss)
I0823 11:45:00.919652 28265 sgd_solver.cpp:106] Iteration 72400, lr = 0.000234828
I0823 11:45:05.384155 28265 solver.cpp:337] Iteration 72500, Testing net (#0)
I0823 11:45:08.950742 28265 solver.cpp:404]     Test net output #0: accuracy = 0.848
I0823 11:45:08.950822 28265 solver.cpp:404]     Test net output #1: loss = 0.770859 (* 1 = 0.770859 loss)
I0823 11:45:08.968019 28265 solver.cpp:228] Iteration 72500, loss = 0.059173
I0823 11:45:08.968087 28265 solver.cpp:244]     Train net output #0: loss = 0.059173 (* 1 = 0.059173 loss)
I0823 11:45:08.968106 28265 sgd_solver.cpp:106] Iteration 72500, lr = 0.000234638
I0823 11:45:13.474269 28265 solver.cpp:228] Iteration 72600, loss = 0.00719076
I0823 11:45:13.474313 28265 solver.cpp:244]     Train net output #0: loss = 0.00719076 (* 1 = 0.00719076 loss)
I0823 11:45:13.474318 28265 sgd_solver.cpp:106] Iteration 72600, lr = 0.000234448
I0823 11:45:17.980075 28265 solver.cpp:228] Iteration 72700, loss = 0.00549388
I0823 11:45:17.980096 28265 solver.cpp:244]     Train net output #0: loss = 0.00549388 (* 1 = 0.00549388 loss)
I0823 11:45:17.980101 28265 sgd_solver.cpp:106] Iteration 72700, lr = 0.000234258
I0823 11:45:22.489429 28265 solver.cpp:228] Iteration 72800, loss = 0.081627
I0823 11:45:22.489475 28265 solver.cpp:244]     Train net output #0: loss = 0.081627 (* 1 = 0.081627 loss)
I0823 11:45:22.489480 28265 sgd_solver.cpp:106] Iteration 72800, lr = 0.000234069
I0823 11:45:26.996496 28265 solver.cpp:228] Iteration 72900, loss = 0.0487774
I0823 11:45:26.996541 28265 solver.cpp:244]     Train net output #0: loss = 0.0487774 (* 1 = 0.0487774 loss)
I0823 11:45:26.996546 28265 sgd_solver.cpp:106] Iteration 72900, lr = 0.00023388
I0823 11:45:31.465989 28265 solver.cpp:337] Iteration 73000, Testing net (#0)
I0823 11:45:34.824558 28265 solver.cpp:404]     Test net output #0: accuracy = 0.82175
I0823 11:45:34.824681 28265 solver.cpp:404]     Test net output #1: loss = 0.941735 (* 1 = 0.941735 loss)
I0823 11:45:34.840504 28265 solver.cpp:228] Iteration 73000, loss = 0.0126198
I0823 11:45:34.840566 28265 solver.cpp:244]     Train net output #0: loss = 0.0126198 (* 1 = 0.0126198 loss)
I0823 11:45:34.840586 28265 sgd_solver.cpp:106] Iteration 73000, lr = 0.000233691
I0823 11:45:39.354753 28265 solver.cpp:228] Iteration 73100, loss = 0.00770266
I0823 11:45:39.354799 28265 solver.cpp:244]     Train net output #0: loss = 0.00770266 (* 1 = 0.00770266 loss)
I0823 11:45:39.354804 28265 sgd_solver.cpp:106] Iteration 73100, lr = 0.000233503
I0823 11:45:43.861227 28265 solver.cpp:228] Iteration 73200, loss = 0.0323354
I0823 11:45:43.861277 28265 solver.cpp:244]     Train net output #0: loss = 0.0323354 (* 1 = 0.0323354 loss)
I0823 11:45:43.861284 28265 sgd_solver.cpp:106] Iteration 73200, lr = 0.000233315
I0823 11:45:48.372702 28265 solver.cpp:228] Iteration 73300, loss = 0.010718
I0823 11:45:48.372747 28265 solver.cpp:244]     Train net output #0: loss = 0.010718 (* 1 = 0.010718 loss)
I0823 11:45:48.372752 28265 sgd_solver.cpp:106] Iteration 73300, lr = 0.000233127
I0823 11:45:52.888276 28265 solver.cpp:228] Iteration 73400, loss = 0.0628675
I0823 11:45:52.888324 28265 solver.cpp:244]     Train net output #0: loss = 0.0628675 (* 1 = 0.0628675 loss)
I0823 11:45:52.888330 28265 sgd_solver.cpp:106] Iteration 73400, lr = 0.00023294
I0823 11:45:57.353803 28265 solver.cpp:337] Iteration 73500, Testing net (#0)
I0823 11:46:00.514688 28265 solver.cpp:404]     Test net output #0: accuracy = 0.78275
I0823 11:46:00.514819 28265 solver.cpp:404]     Test net output #1: loss = 1.22085 (* 1 = 1.22085 loss)
I0823 11:46:00.530680 28265 solver.cpp:228] Iteration 73500, loss = 0.0578999
I0823 11:46:00.530752 28265 solver.cpp:244]     Train net output #0: loss = 0.0578999 (* 1 = 0.0578999 loss)
I0823 11:46:00.530772 28265 sgd_solver.cpp:106] Iteration 73500, lr = 0.000232753
I0823 11:46:05.037130 28265 solver.cpp:228] Iteration 73600, loss = 0.0106403
I0823 11:46:05.037173 28265 solver.cpp:244]     Train net output #0: loss = 0.0106403 (* 1 = 0.0106403 loss)
I0823 11:46:05.037178 28265 sgd_solver.cpp:106] Iteration 73600, lr = 0.000232567
I0823 11:46:09.544571 28265 solver.cpp:228] Iteration 73700, loss = 0.0305509
I0823 11:46:09.544591 28265 solver.cpp:244]     Train net output #0: loss = 0.0305509 (* 1 = 0.0305509 loss)
I0823 11:46:09.544595 28265 sgd_solver.cpp:106] Iteration 73700, lr = 0.00023238
I0823 11:46:14.053992 28265 solver.cpp:228] Iteration 73800, loss = 0.0379237
I0823 11:46:14.054013 28265 solver.cpp:244]     Train net output #0: loss = 0.0379237 (* 1 = 0.0379237 loss)
I0823 11:46:14.054016 28265 sgd_solver.cpp:106] Iteration 73800, lr = 0.000232195
I0823 11:46:18.563972 28265 solver.cpp:228] Iteration 73900, loss = 0.0148675
I0823 11:46:18.564038 28265 solver.cpp:244]     Train net output #0: loss = 0.0148675 (* 1 = 0.0148675 loss)
I0823 11:46:18.564045 28265 sgd_solver.cpp:106] Iteration 73900, lr = 0.000232009
I0823 11:46:23.027721 28265 solver.cpp:337] Iteration 74000, Testing net (#0)
I0823 11:46:26.627274 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844792
I0823 11:46:26.627358 28265 solver.cpp:404]     Test net output #1: loss = 0.848728 (* 1 = 0.848728 loss)
I0823 11:46:26.643585 28265 solver.cpp:228] Iteration 74000, loss = 0.0634673
I0823 11:46:26.643645 28265 solver.cpp:244]     Train net output #0: loss = 0.0634673 (* 1 = 0.0634673 loss)
I0823 11:46:26.643659 28265 sgd_solver.cpp:106] Iteration 74000, lr = 0.000231824
I0823 11:46:31.153107 28265 solver.cpp:228] Iteration 74100, loss = 0.00811656
I0823 11:46:31.153151 28265 solver.cpp:244]     Train net output #0: loss = 0.00811656 (* 1 = 0.00811656 loss)
I0823 11:46:31.153157 28265 sgd_solver.cpp:106] Iteration 74100, lr = 0.000231639
I0823 11:46:35.661968 28265 solver.cpp:228] Iteration 74200, loss = 0.00594581
I0823 11:46:35.662016 28265 solver.cpp:244]     Train net output #0: loss = 0.00594581 (* 1 = 0.00594581 loss)
I0823 11:46:35.662022 28265 sgd_solver.cpp:106] Iteration 74200, lr = 0.000231455
I0823 11:46:40.166746 28265 solver.cpp:228] Iteration 74300, loss = 0.0144106
I0823 11:46:40.166791 28265 solver.cpp:244]     Train net output #0: loss = 0.0144106 (* 1 = 0.0144106 loss)
I0823 11:46:40.166796 28265 sgd_solver.cpp:106] Iteration 74300, lr = 0.000231271
I0823 11:46:44.682267 28265 solver.cpp:228] Iteration 74400, loss = 0.0373394
I0823 11:46:44.682327 28265 solver.cpp:244]     Train net output #0: loss = 0.0373394 (* 1 = 0.0373394 loss)
I0823 11:46:44.682337 28265 sgd_solver.cpp:106] Iteration 74400, lr = 0.000231087
I0823 11:46:49.155566 28265 solver.cpp:337] Iteration 74500, Testing net (#0)
I0823 11:46:52.817118 28265 solver.cpp:404]     Test net output #0: accuracy = 0.850667
I0823 11:46:52.817281 28265 solver.cpp:404]     Test net output #1: loss = 0.801692 (* 1 = 0.801692 loss)
I0823 11:46:52.833115 28265 solver.cpp:228] Iteration 74500, loss = 0.045988
I0823 11:46:52.833180 28265 solver.cpp:244]     Train net output #0: loss = 0.045988 (* 1 = 0.045988 loss)
I0823 11:46:52.833194 28265 sgd_solver.cpp:106] Iteration 74500, lr = 0.000230903
I0823 11:46:57.353330 28265 solver.cpp:228] Iteration 74600, loss = 0.0024179
I0823 11:46:57.353386 28265 solver.cpp:244]     Train net output #0: loss = 0.0024179 (* 1 = 0.0024179 loss)
I0823 11:46:57.353394 28265 sgd_solver.cpp:106] Iteration 74600, lr = 0.00023072
I0823 11:47:01.865345 28265 solver.cpp:228] Iteration 74700, loss = 0.00974212
I0823 11:47:01.865411 28265 solver.cpp:244]     Train net output #0: loss = 0.00974212 (* 1 = 0.00974212 loss)
I0823 11:47:01.865417 28265 sgd_solver.cpp:106] Iteration 74700, lr = 0.000230538
I0823 11:47:06.385318 28265 solver.cpp:228] Iteration 74800, loss = 0.0248476
I0823 11:47:06.385377 28265 solver.cpp:244]     Train net output #0: loss = 0.0248476 (* 1 = 0.0248476 loss)
I0823 11:47:06.385385 28265 sgd_solver.cpp:106] Iteration 74800, lr = 0.000230355
I0823 11:47:10.892546 28265 solver.cpp:228] Iteration 74900, loss = 0.0465911
I0823 11:47:10.892568 28265 solver.cpp:244]     Train net output #0: loss = 0.0465911 (* 1 = 0.0465911 loss)
I0823 11:47:10.892573 28265 sgd_solver.cpp:106] Iteration 74900, lr = 0.000230173
I0823 11:47:13.924049 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:47:15.367527 28265 solver.cpp:337] Iteration 75000, Testing net (#0)
I0823 11:47:18.807011 28265 solver.cpp:404]     Test net output #0: accuracy = 0.851875
I0823 11:47:18.807075 28265 solver.cpp:404]     Test net output #1: loss = 0.792951 (* 1 = 0.792951 loss)
I0823 11:47:18.823462 28265 solver.cpp:228] Iteration 75000, loss = 0.0218301
I0823 11:47:18.823503 28265 solver.cpp:244]     Train net output #0: loss = 0.0218301 (* 1 = 0.0218301 loss)
I0823 11:47:18.823511 28265 sgd_solver.cpp:106] Iteration 75000, lr = 0.000229991
I0823 11:47:23.335697 28265 solver.cpp:228] Iteration 75100, loss = 0.0214042
I0823 11:47:23.335758 28265 solver.cpp:244]     Train net output #0: loss = 0.0214042 (* 1 = 0.0214042 loss)
I0823 11:47:23.335767 28265 sgd_solver.cpp:106] Iteration 75100, lr = 0.00022981
I0823 11:47:27.850698 28265 solver.cpp:228] Iteration 75200, loss = 0.0386276
I0823 11:47:27.850774 28265 solver.cpp:244]     Train net output #0: loss = 0.0386276 (* 1 = 0.0386276 loss)
I0823 11:47:27.850785 28265 sgd_solver.cpp:106] Iteration 75200, lr = 0.000229629
I0823 11:47:32.358060 28265 solver.cpp:228] Iteration 75300, loss = 0.00476423
I0823 11:47:32.358108 28265 solver.cpp:244]     Train net output #0: loss = 0.00476423 (* 1 = 0.00476423 loss)
I0823 11:47:32.358113 28265 sgd_solver.cpp:106] Iteration 75300, lr = 0.000229448
I0823 11:47:36.864279 28265 solver.cpp:228] Iteration 75400, loss = 0.0273455
I0823 11:47:36.864300 28265 solver.cpp:244]     Train net output #0: loss = 0.0273455 (* 1 = 0.0273455 loss)
I0823 11:47:36.864305 28265 sgd_solver.cpp:106] Iteration 75400, lr = 0.000229268
I0823 11:47:41.331766 28265 solver.cpp:337] Iteration 75500, Testing net (#0)
I0823 11:47:44.559027 28265 solver.cpp:404]     Test net output #0: accuracy = 0.842334
I0823 11:47:44.559079 28265 solver.cpp:404]     Test net output #1: loss = 0.882419 (* 1 = 0.882419 loss)
I0823 11:47:44.576035 28265 solver.cpp:228] Iteration 75500, loss = 0.00124242
I0823 11:47:44.576110 28265 solver.cpp:244]     Train net output #0: loss = 0.00124242 (* 1 = 0.00124242 loss)
I0823 11:47:44.576127 28265 sgd_solver.cpp:106] Iteration 75500, lr = 0.000229088
I0823 11:47:49.083098 28265 solver.cpp:228] Iteration 75600, loss = 0.00558803
I0823 11:47:49.083148 28265 solver.cpp:244]     Train net output #0: loss = 0.00558803 (* 1 = 0.00558803 loss)
I0823 11:47:49.083153 28265 sgd_solver.cpp:106] Iteration 75600, lr = 0.000228908
I0823 11:47:53.594441 28265 solver.cpp:228] Iteration 75700, loss = 0.00222378
I0823 11:47:53.594488 28265 solver.cpp:244]     Train net output #0: loss = 0.00222378 (* 1 = 0.00222378 loss)
I0823 11:47:53.594493 28265 sgd_solver.cpp:106] Iteration 75700, lr = 0.000228728
I0823 11:47:58.106458 28265 solver.cpp:228] Iteration 75800, loss = 0.0119389
I0823 11:47:58.106505 28265 solver.cpp:244]     Train net output #0: loss = 0.0119389 (* 1 = 0.0119389 loss)
I0823 11:47:58.106511 28265 sgd_solver.cpp:106] Iteration 75800, lr = 0.000228549
I0823 11:48:02.617527 28265 solver.cpp:228] Iteration 75900, loss = 0.0269741
I0823 11:48:02.617575 28265 solver.cpp:244]     Train net output #0: loss = 0.0269741 (* 1 = 0.0269741 loss)
I0823 11:48:02.617580 28265 sgd_solver.cpp:106] Iteration 75900, lr = 0.000228371
I0823 11:48:07.087693 28265 solver.cpp:337] Iteration 76000, Testing net (#0)
I0823 11:48:10.439342 28265 solver.cpp:404]     Test net output #0: accuracy = 0.837584
I0823 11:48:10.439389 28265 solver.cpp:404]     Test net output #1: loss = 0.92588 (* 1 = 0.92588 loss)
I0823 11:48:10.455126 28265 solver.cpp:228] Iteration 76000, loss = 0.00454229
I0823 11:48:10.455183 28265 solver.cpp:244]     Train net output #0: loss = 0.00454229 (* 1 = 0.00454229 loss)
I0823 11:48:10.455198 28265 sgd_solver.cpp:106] Iteration 76000, lr = 0.000228192
I0823 11:48:14.967211 28265 solver.cpp:228] Iteration 76100, loss = 0.0130121
I0823 11:48:14.967279 28265 solver.cpp:244]     Train net output #0: loss = 0.0130121 (* 1 = 0.0130121 loss)
I0823 11:48:14.967285 28265 sgd_solver.cpp:106] Iteration 76100, lr = 0.000228014
I0823 11:48:19.483165 28265 solver.cpp:228] Iteration 76200, loss = 0.00402488
I0823 11:48:19.483211 28265 solver.cpp:244]     Train net output #0: loss = 0.00402488 (* 1 = 0.00402488 loss)
I0823 11:48:19.483216 28265 sgd_solver.cpp:106] Iteration 76200, lr = 0.000227836
I0823 11:48:23.988605 28265 solver.cpp:228] Iteration 76300, loss = 0.00747712
I0823 11:48:23.988626 28265 solver.cpp:244]     Train net output #0: loss = 0.00747712 (* 1 = 0.00747712 loss)
I0823 11:48:23.988631 28265 sgd_solver.cpp:106] Iteration 76300, lr = 0.000227659
I0823 11:48:28.499729 28265 solver.cpp:228] Iteration 76400, loss = 0.0018083
I0823 11:48:28.499775 28265 solver.cpp:244]     Train net output #0: loss = 0.0018083 (* 1 = 0.0018083 loss)
I0823 11:48:28.499780 28265 sgd_solver.cpp:106] Iteration 76400, lr = 0.000227482
I0823 11:48:32.960259 28265 solver.cpp:337] Iteration 76500, Testing net (#0)
I0823 11:48:36.504195 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84275
I0823 11:48:36.504323 28265 solver.cpp:404]     Test net output #1: loss = 0.916454 (* 1 = 0.916454 loss)
I0823 11:48:36.520119 28265 solver.cpp:228] Iteration 76500, loss = 0.00381696
I0823 11:48:36.520190 28265 solver.cpp:244]     Train net output #0: loss = 0.00381696 (* 1 = 0.00381696 loss)
I0823 11:48:36.520206 28265 sgd_solver.cpp:106] Iteration 76500, lr = 0.000227305
I0823 11:48:41.041911 28265 solver.cpp:228] Iteration 76600, loss = 0.00507035
I0823 11:48:41.041972 28265 solver.cpp:244]     Train net output #0: loss = 0.00507035 (* 1 = 0.00507035 loss)
I0823 11:48:41.041980 28265 sgd_solver.cpp:106] Iteration 76600, lr = 0.000227128
I0823 11:48:45.555595 28265 solver.cpp:228] Iteration 76700, loss = 0.00102737
I0823 11:48:45.555644 28265 solver.cpp:244]     Train net output #0: loss = 0.00102737 (* 1 = 0.00102737 loss)
I0823 11:48:45.555649 28265 sgd_solver.cpp:106] Iteration 76700, lr = 0.000226952
I0823 11:48:50.062368 28265 solver.cpp:228] Iteration 76800, loss = 0.00347271
I0823 11:48:50.062391 28265 solver.cpp:244]     Train net output #0: loss = 0.00347271 (* 1 = 0.00347271 loss)
I0823 11:48:50.062394 28265 sgd_solver.cpp:106] Iteration 76800, lr = 0.000226776
I0823 11:48:54.569911 28265 solver.cpp:228] Iteration 76900, loss = 0.00588212
I0823 11:48:54.569931 28265 solver.cpp:244]     Train net output #0: loss = 0.00588212 (* 1 = 0.00588212 loss)
I0823 11:48:54.569936 28265 sgd_solver.cpp:106] Iteration 76900, lr = 0.000226601
I0823 11:48:59.033035 28265 solver.cpp:337] Iteration 77000, Testing net (#0)
I0823 11:49:02.364588 28265 solver.cpp:404]     Test net output #0: accuracy = 0.846875
I0823 11:49:02.364662 28265 solver.cpp:404]     Test net output #1: loss = 0.906977 (* 1 = 0.906977 loss)
I0823 11:49:02.380050 28265 solver.cpp:228] Iteration 77000, loss = 0.00560903
I0823 11:49:02.380094 28265 solver.cpp:244]     Train net output #0: loss = 0.00560903 (* 1 = 0.00560903 loss)
I0823 11:49:02.380102 28265 sgd_solver.cpp:106] Iteration 77000, lr = 0.000226426
I0823 11:49:06.905920 28265 solver.cpp:228] Iteration 77100, loss = 0.0143707
I0823 11:49:06.905972 28265 solver.cpp:244]     Train net output #0: loss = 0.0143707 (* 1 = 0.0143707 loss)
I0823 11:49:06.905977 28265 sgd_solver.cpp:106] Iteration 77100, lr = 0.000226251
I0823 11:49:11.419193 28265 solver.cpp:228] Iteration 77200, loss = 0.00277003
I0823 11:49:11.419240 28265 solver.cpp:244]     Train net output #0: loss = 0.00277003 (* 1 = 0.00277003 loss)
I0823 11:49:11.419245 28265 sgd_solver.cpp:106] Iteration 77200, lr = 0.000226076
I0823 11:49:15.929869 28265 solver.cpp:228] Iteration 77300, loss = 0.00307475
I0823 11:49:15.929919 28265 solver.cpp:244]     Train net output #0: loss = 0.00307475 (* 1 = 0.00307475 loss)
I0823 11:49:15.929924 28265 sgd_solver.cpp:106] Iteration 77300, lr = 0.000225902
I0823 11:49:20.435596 28265 solver.cpp:228] Iteration 77400, loss = 0.00381252
I0823 11:49:20.435618 28265 solver.cpp:244]     Train net output #0: loss = 0.00381252 (* 1 = 0.00381252 loss)
I0823 11:49:20.435623 28265 sgd_solver.cpp:106] Iteration 77400, lr = 0.000225728
I0823 11:49:24.896080 28265 solver.cpp:337] Iteration 77500, Testing net (#0)
I0823 11:49:28.318019 28265 solver.cpp:404]     Test net output #0: accuracy = 0.847
I0823 11:49:28.318068 28265 solver.cpp:404]     Test net output #1: loss = 0.922476 (* 1 = 0.922476 loss)
I0823 11:49:28.333240 28265 solver.cpp:228] Iteration 77500, loss = 0.00232922
I0823 11:49:28.333268 28265 solver.cpp:244]     Train net output #0: loss = 0.00232922 (* 1 = 0.00232922 loss)
I0823 11:49:28.333278 28265 sgd_solver.cpp:106] Iteration 77500, lr = 0.000225554
I0823 11:49:32.841583 28265 solver.cpp:228] Iteration 77600, loss = 0.0187389
I0823 11:49:32.841631 28265 solver.cpp:244]     Train net output #0: loss = 0.0187389 (* 1 = 0.0187389 loss)
I0823 11:49:32.841636 28265 sgd_solver.cpp:106] Iteration 77600, lr = 0.000225381
I0823 11:49:37.347317 28265 solver.cpp:228] Iteration 77700, loss = 0.00306257
I0823 11:49:37.347379 28265 solver.cpp:244]     Train net output #0: loss = 0.00306257 (* 1 = 0.00306257 loss)
I0823 11:49:37.347385 28265 sgd_solver.cpp:106] Iteration 77700, lr = 0.000225208
I0823 11:49:41.858039 28265 solver.cpp:228] Iteration 77800, loss = 0.00498427
I0823 11:49:41.858089 28265 solver.cpp:244]     Train net output #0: loss = 0.00498427 (* 1 = 0.00498427 loss)
I0823 11:49:41.858094 28265 sgd_solver.cpp:106] Iteration 77800, lr = 0.000225035
I0823 11:49:46.368398 28265 solver.cpp:228] Iteration 77900, loss = 0.00143805
I0823 11:49:46.368444 28265 solver.cpp:244]     Train net output #0: loss = 0.00143805 (* 1 = 0.00143805 loss)
I0823 11:49:46.368450 28265 sgd_solver.cpp:106] Iteration 77900, lr = 0.000224863
I0823 11:49:50.847337 28265 solver.cpp:337] Iteration 78000, Testing net (#0)
I0823 11:49:51.516590 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:49:54.159660 28265 solver.cpp:404]     Test net output #0: accuracy = 0.846333
I0823 11:49:54.159723 28265 solver.cpp:404]     Test net output #1: loss = 0.935671 (* 1 = 0.935671 loss)
I0823 11:49:54.175729 28265 solver.cpp:228] Iteration 78000, loss = 0.00194152
I0823 11:49:54.175746 28265 solver.cpp:244]     Train net output #0: loss = 0.00194152 (* 1 = 0.00194152 loss)
I0823 11:49:54.175756 28265 sgd_solver.cpp:106] Iteration 78000, lr = 0.00022469
I0823 11:49:58.686489 28265 solver.cpp:228] Iteration 78100, loss = 0.00612545
I0823 11:49:58.686532 28265 solver.cpp:244]     Train net output #0: loss = 0.00612545 (* 1 = 0.00612545 loss)
I0823 11:49:58.686537 28265 sgd_solver.cpp:106] Iteration 78100, lr = 0.000224519
I0823 11:50:03.197990 28265 solver.cpp:228] Iteration 78200, loss = 0.0313519
I0823 11:50:03.198050 28265 solver.cpp:244]     Train net output #0: loss = 0.0313519 (* 1 = 0.0313519 loss)
I0823 11:50:03.198055 28265 sgd_solver.cpp:106] Iteration 78200, lr = 0.000224347
I0823 11:50:07.714009 28265 solver.cpp:228] Iteration 78300, loss = 0.00677601
I0823 11:50:07.714054 28265 solver.cpp:244]     Train net output #0: loss = 0.00677601 (* 1 = 0.00677601 loss)
I0823 11:50:07.714061 28265 sgd_solver.cpp:106] Iteration 78300, lr = 0.000224176
I0823 11:50:12.230726 28265 solver.cpp:228] Iteration 78400, loss = 0.000826514
I0823 11:50:12.230773 28265 solver.cpp:244]     Train net output #0: loss = 0.000826514 (* 1 = 0.000826514 loss)
I0823 11:50:12.230779 28265 sgd_solver.cpp:106] Iteration 78400, lr = 0.000224005
I0823 11:50:16.697928 28265 solver.cpp:337] Iteration 78500, Testing net (#0)
I0823 11:50:19.992552 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845625
I0823 11:50:19.992624 28265 solver.cpp:404]     Test net output #1: loss = 0.952436 (* 1 = 0.952436 loss)
I0823 11:50:20.007926 28265 solver.cpp:228] Iteration 78500, loss = 0.00237288
I0823 11:50:20.007967 28265 solver.cpp:244]     Train net output #0: loss = 0.00237288 (* 1 = 0.00237288 loss)
I0823 11:50:20.007979 28265 sgd_solver.cpp:106] Iteration 78500, lr = 0.000223835
I0823 11:50:24.522336 28265 solver.cpp:228] Iteration 78600, loss = 0.00891248
I0823 11:50:24.522383 28265 solver.cpp:244]     Train net output #0: loss = 0.00891248 (* 1 = 0.00891248 loss)
I0823 11:50:24.522388 28265 sgd_solver.cpp:106] Iteration 78600, lr = 0.000223664
I0823 11:50:29.037215 28265 solver.cpp:228] Iteration 78700, loss = 0.00340601
I0823 11:50:29.037273 28265 solver.cpp:244]     Train net output #0: loss = 0.00340601 (* 1 = 0.00340601 loss)
I0823 11:50:29.037281 28265 sgd_solver.cpp:106] Iteration 78700, lr = 0.000223494
I0823 11:50:33.553395 28265 solver.cpp:228] Iteration 78800, loss = 0.0015918
I0823 11:50:33.553444 28265 solver.cpp:244]     Train net output #0: loss = 0.0015918 (* 1 = 0.0015918 loss)
I0823 11:50:33.553450 28265 sgd_solver.cpp:106] Iteration 78800, lr = 0.000223325
I0823 11:50:38.063187 28265 solver.cpp:228] Iteration 78900, loss = 0.00266698
I0823 11:50:38.063235 28265 solver.cpp:244]     Train net output #0: loss = 0.00266698 (* 1 = 0.00266698 loss)
I0823 11:50:38.063241 28265 sgd_solver.cpp:106] Iteration 78900, lr = 0.000223155
I0823 11:50:42.529814 28265 solver.cpp:337] Iteration 79000, Testing net (#0)
I0823 11:50:45.849308 28265 solver.cpp:404]     Test net output #0: accuracy = 0.847209
I0823 11:50:45.849354 28265 solver.cpp:404]     Test net output #1: loss = 0.954887 (* 1 = 0.954887 loss)
I0823 11:50:45.864017 28265 solver.cpp:228] Iteration 79000, loss = 0.000364213
I0823 11:50:45.864063 28265 solver.cpp:244]     Train net output #0: loss = 0.000364213 (* 1 = 0.000364213 loss)
I0823 11:50:45.864073 28265 sgd_solver.cpp:106] Iteration 79000, lr = 0.000222986
I0823 11:50:50.374514 28265 solver.cpp:228] Iteration 79100, loss = 0.00493309
I0823 11:50:50.374558 28265 solver.cpp:244]     Train net output #0: loss = 0.00493309 (* 1 = 0.00493309 loss)
I0823 11:50:50.374565 28265 sgd_solver.cpp:106] Iteration 79100, lr = 0.000222817
I0823 11:50:54.881057 28265 solver.cpp:228] Iteration 79200, loss = 0.0012237
I0823 11:50:54.881115 28265 solver.cpp:244]     Train net output #0: loss = 0.0012237 (* 1 = 0.0012237 loss)
I0823 11:50:54.881126 28265 sgd_solver.cpp:106] Iteration 79200, lr = 0.000222649
I0823 11:50:59.386961 28265 solver.cpp:228] Iteration 79300, loss = 0.00144702
I0823 11:50:59.387003 28265 solver.cpp:244]     Train net output #0: loss = 0.00144702 (* 1 = 0.00144702 loss)
I0823 11:50:59.387009 28265 sgd_solver.cpp:106] Iteration 79300, lr = 0.000222481
I0823 11:51:03.892997 28265 solver.cpp:228] Iteration 79400, loss = 0.00111019
I0823 11:51:03.893018 28265 solver.cpp:244]     Train net output #0: loss = 0.00111019 (* 1 = 0.00111019 loss)
I0823 11:51:03.893023 28265 sgd_solver.cpp:106] Iteration 79400, lr = 0.000222313
I0823 11:51:08.353350 28265 solver.cpp:337] Iteration 79500, Testing net (#0)
I0823 11:51:11.880579 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84725
I0823 11:51:11.880633 28265 solver.cpp:404]     Test net output #1: loss = 0.958469 (* 1 = 0.958469 loss)
I0823 11:51:11.895889 28265 solver.cpp:228] Iteration 79500, loss = 0.0127551
I0823 11:51:11.895911 28265 solver.cpp:244]     Train net output #0: loss = 0.0127551 (* 1 = 0.0127551 loss)
I0823 11:51:11.895922 28265 sgd_solver.cpp:106] Iteration 79500, lr = 0.000222145
I0823 11:51:16.405127 28265 solver.cpp:228] Iteration 79600, loss = 0.00135144
I0823 11:51:16.405191 28265 solver.cpp:244]     Train net output #0: loss = 0.00135144 (* 1 = 0.00135144 loss)
I0823 11:51:16.405205 28265 sgd_solver.cpp:106] Iteration 79600, lr = 0.000221978
I0823 11:51:20.916657 28265 solver.cpp:228] Iteration 79700, loss = 0.00162356
I0823 11:51:20.916700 28265 solver.cpp:244]     Train net output #0: loss = 0.00162356 (* 1 = 0.00162356 loss)
I0823 11:51:20.916707 28265 sgd_solver.cpp:106] Iteration 79700, lr = 0.000221811
I0823 11:51:25.422654 28265 solver.cpp:228] Iteration 79800, loss = 0.000500941
I0823 11:51:25.422673 28265 solver.cpp:244]     Train net output #0: loss = 0.000500941 (* 1 = 0.000500941 loss)
I0823 11:51:25.422677 28265 sgd_solver.cpp:106] Iteration 79800, lr = 0.000221644
I0823 11:51:29.937561 28265 solver.cpp:228] Iteration 79900, loss = 0.00172184
I0823 11:51:29.937605 28265 solver.cpp:244]     Train net output #0: loss = 0.00172184 (* 1 = 0.00172184 loss)
I0823 11:51:29.937610 28265 sgd_solver.cpp:106] Iteration 79900, lr = 0.000221478
I0823 11:51:34.404592 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_80000.caffemodel
I0823 11:51:34.881621 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_80000.solverstate
I0823 11:51:35.037058 28265 solver.cpp:337] Iteration 80000, Testing net (#0)
I0823 11:51:38.398440 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84675
I0823 11:51:38.398507 28265 solver.cpp:404]     Test net output #1: loss = 0.970964 (* 1 = 0.970964 loss)
I0823 11:51:38.414016 28265 solver.cpp:228] Iteration 80000, loss = 0.000880872
I0823 11:51:38.414069 28265 solver.cpp:244]     Train net output #0: loss = 0.000880872 (* 1 = 0.000880872 loss)
I0823 11:51:38.414084 28265 sgd_solver.cpp:106] Iteration 80000, lr = 0.000221312
I0823 11:51:42.918494 28265 solver.cpp:228] Iteration 80100, loss = 0.00551424
I0823 11:51:42.918541 28265 solver.cpp:244]     Train net output #0: loss = 0.00551424 (* 1 = 0.00551424 loss)
I0823 11:51:42.918546 28265 sgd_solver.cpp:106] Iteration 80100, lr = 0.000221146
I0823 11:51:47.424407 28265 solver.cpp:228] Iteration 80200, loss = 0.00135577
I0823 11:51:47.424451 28265 solver.cpp:244]     Train net output #0: loss = 0.00135577 (* 1 = 0.00135577 loss)
I0823 11:51:47.424456 28265 sgd_solver.cpp:106] Iteration 80200, lr = 0.00022098
I0823 11:51:51.935559 28265 solver.cpp:228] Iteration 80300, loss = 0.000966201
I0823 11:51:51.935605 28265 solver.cpp:244]     Train net output #0: loss = 0.000966201 (* 1 = 0.000966201 loss)
I0823 11:51:51.935611 28265 sgd_solver.cpp:106] Iteration 80300, lr = 0.000220815
I0823 11:51:56.451973 28265 solver.cpp:228] Iteration 80400, loss = 0.00116467
I0823 11:51:56.452020 28265 solver.cpp:244]     Train net output #0: loss = 0.00116467 (* 1 = 0.00116467 loss)
I0823 11:51:56.452026 28265 sgd_solver.cpp:106] Iteration 80400, lr = 0.00022065
I0823 11:52:00.917820 28265 solver.cpp:337] Iteration 80500, Testing net (#0)
I0823 11:52:04.594895 28265 solver.cpp:404]     Test net output #0: accuracy = 0.846334
I0823 11:52:04.594960 28265 solver.cpp:404]     Test net output #1: loss = 0.984038 (* 1 = 0.984038 loss)
I0823 11:52:04.610370 28265 solver.cpp:228] Iteration 80500, loss = 0.000373095
I0823 11:52:04.610405 28265 solver.cpp:244]     Train net output #0: loss = 0.000373095 (* 1 = 0.000373095 loss)
I0823 11:52:04.610415 28265 sgd_solver.cpp:106] Iteration 80500, lr = 0.000220485
I0823 11:52:09.122619 28265 solver.cpp:228] Iteration 80600, loss = 0.00148051
I0823 11:52:09.122664 28265 solver.cpp:244]     Train net output #0: loss = 0.00148051 (* 1 = 0.00148051 loss)
I0823 11:52:09.122670 28265 sgd_solver.cpp:106] Iteration 80600, lr = 0.000220321
I0823 11:52:13.629647 28265 solver.cpp:228] Iteration 80700, loss = 0.000755825
I0823 11:52:13.629667 28265 solver.cpp:244]     Train net output #0: loss = 0.000755825 (* 1 = 0.000755825 loss)
I0823 11:52:13.629673 28265 sgd_solver.cpp:106] Iteration 80700, lr = 0.000220157
I0823 11:52:18.141863 28265 solver.cpp:228] Iteration 80800, loss = 0.00131671
I0823 11:52:18.141907 28265 solver.cpp:244]     Train net output #0: loss = 0.00131671 (* 1 = 0.00131671 loss)
I0823 11:52:18.141913 28265 sgd_solver.cpp:106] Iteration 80800, lr = 0.000219993
I0823 11:52:22.649952 28265 solver.cpp:228] Iteration 80900, loss = 0.000475891
I0823 11:52:22.650001 28265 solver.cpp:244]     Train net output #0: loss = 0.000475891 (* 1 = 0.000475891 loss)
I0823 11:52:22.650007 28265 sgd_solver.cpp:106] Iteration 80900, lr = 0.000219829
I0823 11:52:27.111006 28265 solver.cpp:337] Iteration 81000, Testing net (#0)
I0823 11:52:30.308233 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:52:30.468821 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844084
I0823 11:52:30.468969 28265 solver.cpp:404]     Test net output #1: loss = 1.00571 (* 1 = 1.00571 loss)
I0823 11:52:30.484778 28265 solver.cpp:228] Iteration 81000, loss = 0.00108432
I0823 11:52:30.484832 28265 solver.cpp:244]     Train net output #0: loss = 0.00108432 (* 1 = 0.00108432 loss)
I0823 11:52:30.484845 28265 sgd_solver.cpp:106] Iteration 81000, lr = 0.000219666
I0823 11:52:34.991850 28265 solver.cpp:228] Iteration 81100, loss = 0.00101309
I0823 11:52:34.991894 28265 solver.cpp:244]     Train net output #0: loss = 0.00101309 (* 1 = 0.00101309 loss)
I0823 11:52:34.991899 28265 sgd_solver.cpp:106] Iteration 81100, lr = 0.000219503
I0823 11:52:39.510879 28265 solver.cpp:228] Iteration 81200, loss = 0.00123987
I0823 11:52:39.510929 28265 solver.cpp:244]     Train net output #0: loss = 0.00123987 (* 1 = 0.00123987 loss)
I0823 11:52:39.510936 28265 sgd_solver.cpp:106] Iteration 81200, lr = 0.00021934
I0823 11:52:44.033928 28265 solver.cpp:228] Iteration 81300, loss = 0.000897385
I0823 11:52:44.033949 28265 solver.cpp:244]     Train net output #0: loss = 0.000897385 (* 1 = 0.000897385 loss)
I0823 11:52:44.033954 28265 sgd_solver.cpp:106] Iteration 81300, lr = 0.000219178
I0823 11:52:48.543030 28265 solver.cpp:228] Iteration 81400, loss = 0.00187035
I0823 11:52:48.543052 28265 solver.cpp:244]     Train net output #0: loss = 0.00187035 (* 1 = 0.00187035 loss)
I0823 11:52:48.543057 28265 sgd_solver.cpp:106] Iteration 81400, lr = 0.000219016
I0823 11:52:53.009533 28265 solver.cpp:337] Iteration 81500, Testing net (#0)
I0823 11:52:56.446674 28265 solver.cpp:404]     Test net output #0: accuracy = 0.846
I0823 11:52:56.446729 28265 solver.cpp:404]     Test net output #1: loss = 1.00137 (* 1 = 1.00137 loss)
I0823 11:52:56.462600 28265 solver.cpp:228] Iteration 81500, loss = 0.000451233
I0823 11:52:56.462644 28265 solver.cpp:244]     Train net output #0: loss = 0.000451233 (* 1 = 0.000451233 loss)
I0823 11:52:56.462662 28265 sgd_solver.cpp:106] Iteration 81500, lr = 0.000218854
I0823 11:53:00.976478 28265 solver.cpp:228] Iteration 81600, loss = 0.0018389
I0823 11:53:00.976546 28265 solver.cpp:244]     Train net output #0: loss = 0.0018389 (* 1 = 0.0018389 loss)
I0823 11:53:00.976552 28265 sgd_solver.cpp:106] Iteration 81600, lr = 0.000218693
I0823 11:53:05.492224 28265 solver.cpp:228] Iteration 81700, loss = 0.000526321
I0823 11:53:05.492293 28265 solver.cpp:244]     Train net output #0: loss = 0.000526321 (* 1 = 0.000526321 loss)
I0823 11:53:05.492300 28265 sgd_solver.cpp:106] Iteration 81700, lr = 0.000218531
I0823 11:53:09.999475 28265 solver.cpp:228] Iteration 81800, loss = 0.000569142
I0823 11:53:09.999517 28265 solver.cpp:244]     Train net output #0: loss = 0.000569142 (* 1 = 0.000569142 loss)
I0823 11:53:09.999523 28265 sgd_solver.cpp:106] Iteration 81800, lr = 0.00021837
I0823 11:53:14.509917 28265 solver.cpp:228] Iteration 81900, loss = 0.00290617
I0823 11:53:14.509938 28265 solver.cpp:244]     Train net output #0: loss = 0.00290617 (* 1 = 0.00290617 loss)
I0823 11:53:14.509943 28265 sgd_solver.cpp:106] Iteration 81900, lr = 0.000218209
I0823 11:53:18.976882 28265 solver.cpp:337] Iteration 82000, Testing net (#0)
I0823 11:53:22.508929 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843833
I0823 11:53:22.508977 28265 solver.cpp:404]     Test net output #1: loss = 1.0237 (* 1 = 1.0237 loss)
I0823 11:53:22.524191 28265 solver.cpp:228] Iteration 82000, loss = 0.000456697
I0823 11:53:22.524237 28265 solver.cpp:244]     Train net output #0: loss = 0.000456697 (* 1 = 0.000456697 loss)
I0823 11:53:22.524248 28265 sgd_solver.cpp:106] Iteration 82000, lr = 0.000218049
I0823 11:53:27.034409 28265 solver.cpp:228] Iteration 82100, loss = 0.0015762
I0823 11:53:27.034453 28265 solver.cpp:244]     Train net output #0: loss = 0.0015762 (* 1 = 0.0015762 loss)
I0823 11:53:27.034458 28265 sgd_solver.cpp:106] Iteration 82100, lr = 0.000217889
I0823 11:53:31.541427 28265 solver.cpp:228] Iteration 82200, loss = 0.00107134
I0823 11:53:31.541473 28265 solver.cpp:244]     Train net output #0: loss = 0.00107134 (* 1 = 0.00107134 loss)
I0823 11:53:31.541478 28265 sgd_solver.cpp:106] Iteration 82200, lr = 0.000217729
I0823 11:53:36.056953 28265 solver.cpp:228] Iteration 82300, loss = 0.000872424
I0823 11:53:36.057027 28265 solver.cpp:244]     Train net output #0: loss = 0.000872424 (* 1 = 0.000872424 loss)
I0823 11:53:36.057042 28265 sgd_solver.cpp:106] Iteration 82300, lr = 0.000217569
I0823 11:53:40.563081 28265 solver.cpp:228] Iteration 82400, loss = 0.00128392
I0823 11:53:40.563138 28265 solver.cpp:244]     Train net output #0: loss = 0.00128392 (* 1 = 0.00128392 loss)
I0823 11:53:40.563144 28265 sgd_solver.cpp:106] Iteration 82400, lr = 0.00021741
I0823 11:53:45.023659 28265 solver.cpp:337] Iteration 82500, Testing net (#0)
I0823 11:53:48.437089 28265 solver.cpp:404]     Test net output #0: accuracy = 0.846125
I0823 11:53:48.437160 28265 solver.cpp:404]     Test net output #1: loss = 1.01324 (* 1 = 1.01324 loss)
I0823 11:53:48.453069 28265 solver.cpp:228] Iteration 82500, loss = 0.00264999
I0823 11:53:48.453131 28265 solver.cpp:244]     Train net output #0: loss = 0.00264999 (* 1 = 0.00264999 loss)
I0823 11:53:48.453150 28265 sgd_solver.cpp:106] Iteration 82500, lr = 0.000217251
I0823 11:53:52.969389 28265 solver.cpp:228] Iteration 82600, loss = 0.0017275
I0823 11:53:52.969440 28265 solver.cpp:244]     Train net output #0: loss = 0.0017275 (* 1 = 0.0017275 loss)
I0823 11:53:52.969451 28265 sgd_solver.cpp:106] Iteration 82600, lr = 0.000217092
I0823 11:53:57.478744 28265 solver.cpp:228] Iteration 82700, loss = 0.000402582
I0823 11:53:57.478790 28265 solver.cpp:244]     Train net output #0: loss = 0.000402582 (* 1 = 0.000402582 loss)
I0823 11:53:57.478796 28265 sgd_solver.cpp:106] Iteration 82700, lr = 0.000216933
I0823 11:54:01.995303 28265 solver.cpp:228] Iteration 82800, loss = 0.000686513
I0823 11:54:01.995347 28265 solver.cpp:244]     Train net output #0: loss = 0.000686513 (* 1 = 0.000686513 loss)
I0823 11:54:01.995352 28265 sgd_solver.cpp:106] Iteration 82800, lr = 0.000216775
I0823 11:54:06.505484 28265 solver.cpp:228] Iteration 82900, loss = 0.00152371
I0823 11:54:06.505506 28265 solver.cpp:244]     Train net output #0: loss = 0.00152371 (* 1 = 0.00152371 loss)
I0823 11:54:06.505511 28265 sgd_solver.cpp:106] Iteration 82900, lr = 0.000216617
I0823 11:54:10.970355 28265 solver.cpp:337] Iteration 83000, Testing net (#0)
I0823 11:54:14.693132 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844459
I0823 11:54:14.693186 28265 solver.cpp:404]     Test net output #1: loss = 1.0329 (* 1 = 1.0329 loss)
I0823 11:54:14.707782 28265 solver.cpp:228] Iteration 83000, loss = 0.000770319
I0823 11:54:14.707833 28265 solver.cpp:244]     Train net output #0: loss = 0.000770319 (* 1 = 0.000770319 loss)
I0823 11:54:14.707844 28265 sgd_solver.cpp:106] Iteration 83000, lr = 0.000216459
I0823 11:54:19.216020 28265 solver.cpp:228] Iteration 83100, loss = 0.000763747
I0823 11:54:19.216063 28265 solver.cpp:244]     Train net output #0: loss = 0.000763747 (* 1 = 0.000763747 loss)
I0823 11:54:19.216068 28265 sgd_solver.cpp:106] Iteration 83100, lr = 0.000216302
I0823 11:54:23.721992 28265 solver.cpp:228] Iteration 83200, loss = 0.0008481
I0823 11:54:23.722012 28265 solver.cpp:244]     Train net output #0: loss = 0.0008481 (* 1 = 0.0008481 loss)
I0823 11:54:23.722017 28265 sgd_solver.cpp:106] Iteration 83200, lr = 0.000216145
I0823 11:54:28.229122 28265 solver.cpp:228] Iteration 83300, loss = 0.000339724
I0823 11:54:28.229176 28265 solver.cpp:244]     Train net output #0: loss = 0.000339724 (* 1 = 0.000339724 loss)
I0823 11:54:28.229184 28265 sgd_solver.cpp:106] Iteration 83300, lr = 0.000215988
I0823 11:54:32.741117 28265 solver.cpp:228] Iteration 83400, loss = 0.00336247
I0823 11:54:32.741174 28265 solver.cpp:244]     Train net output #0: loss = 0.00336247 (* 1 = 0.00336247 loss)
I0823 11:54:32.741183 28265 sgd_solver.cpp:106] Iteration 83400, lr = 0.000215831
I0823 11:54:37.211508 28265 solver.cpp:337] Iteration 83500, Testing net (#0)
I0823 11:54:40.633908 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844667
I0823 11:54:40.633968 28265 solver.cpp:404]     Test net output #1: loss = 1.03605 (* 1 = 1.03605 loss)
I0823 11:54:40.650746 28265 solver.cpp:228] Iteration 83500, loss = 0.000665303
I0823 11:54:40.650804 28265 solver.cpp:244]     Train net output #0: loss = 0.000665303 (* 1 = 0.000665303 loss)
I0823 11:54:40.650820 28265 sgd_solver.cpp:106] Iteration 83500, lr = 0.000215675
I0823 11:54:45.162545 28265 solver.cpp:228] Iteration 83600, loss = 0.000520662
I0823 11:54:45.162602 28265 solver.cpp:244]     Train net output #0: loss = 0.000520662 (* 1 = 0.000520662 loss)
I0823 11:54:45.162613 28265 sgd_solver.cpp:106] Iteration 83600, lr = 0.000215518
I0823 11:54:49.677558 28265 solver.cpp:228] Iteration 83700, loss = 0.000619693
I0823 11:54:49.677629 28265 solver.cpp:244]     Train net output #0: loss = 0.000619693 (* 1 = 0.000619693 loss)
I0823 11:54:49.677640 28265 sgd_solver.cpp:106] Iteration 83700, lr = 0.000215363
I0823 11:54:54.184119 28265 solver.cpp:228] Iteration 83800, loss = 0.00403257
I0823 11:54:54.184171 28265 solver.cpp:244]     Train net output #0: loss = 0.00403257 (* 1 = 0.00403257 loss)
I0823 11:54:54.184177 28265 sgd_solver.cpp:106] Iteration 83800, lr = 0.000215207
I0823 11:54:58.700489 28265 solver.cpp:228] Iteration 83900, loss = 0.000662617
I0823 11:54:58.700534 28265 solver.cpp:244]     Train net output #0: loss = 0.000662617 (* 1 = 0.000662617 loss)
I0823 11:54:58.700541 28265 sgd_solver.cpp:106] Iteration 83900, lr = 0.000215052
I0823 11:55:03.165096 28265 solver.cpp:337] Iteration 84000, Testing net (#0)
I0823 11:55:04.234647 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:55:06.749053 28265 solver.cpp:404]     Test net output #0: accuracy = 0.842875
I0823 11:55:06.749120 28265 solver.cpp:404]     Test net output #1: loss = 1.0525 (* 1 = 1.0525 loss)
I0823 11:55:06.764595 28265 solver.cpp:228] Iteration 84000, loss = 0.00077684
I0823 11:55:06.764652 28265 solver.cpp:244]     Train net output #0: loss = 0.00077684 (* 1 = 0.00077684 loss)
I0823 11:55:06.764665 28265 sgd_solver.cpp:106] Iteration 84000, lr = 0.000214896
I0823 11:55:11.276288 28265 solver.cpp:228] Iteration 84100, loss = 0.000318515
I0823 11:55:11.276371 28265 solver.cpp:244]     Train net output #0: loss = 0.000318515 (* 1 = 0.000318515 loss)
I0823 11:55:11.276383 28265 sgd_solver.cpp:106] Iteration 84100, lr = 0.000214742
I0823 11:55:15.786204 28265 solver.cpp:228] Iteration 84200, loss = 0.000529028
I0823 11:55:15.786249 28265 solver.cpp:244]     Train net output #0: loss = 0.000529028 (* 1 = 0.000529028 loss)
I0823 11:55:15.786255 28265 sgd_solver.cpp:106] Iteration 84200, lr = 0.000214587
I0823 11:55:20.291415 28265 solver.cpp:228] Iteration 84300, loss = 0.000890918
I0823 11:55:20.291435 28265 solver.cpp:244]     Train net output #0: loss = 0.000890918 (* 1 = 0.000890918 loss)
I0823 11:55:20.291440 28265 sgd_solver.cpp:106] Iteration 84300, lr = 0.000214433
I0823 11:55:24.808353 28265 solver.cpp:228] Iteration 84400, loss = 0.000515622
I0823 11:55:24.808403 28265 solver.cpp:244]     Train net output #0: loss = 0.000515622 (* 1 = 0.000515622 loss)
I0823 11:55:24.808408 28265 sgd_solver.cpp:106] Iteration 84400, lr = 0.000214279
I0823 11:55:29.275024 28265 solver.cpp:337] Iteration 84500, Testing net (#0)
I0823 11:55:32.703181 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844083
I0823 11:55:32.703291 28265 solver.cpp:404]     Test net output #1: loss = 1.05246 (* 1 = 1.05246 loss)
I0823 11:55:32.719166 28265 solver.cpp:228] Iteration 84500, loss = 0.000454251
I0823 11:55:32.719219 28265 solver.cpp:244]     Train net output #0: loss = 0.000454251 (* 1 = 0.000454251 loss)
I0823 11:55:32.719233 28265 sgd_solver.cpp:106] Iteration 84500, lr = 0.000214125
I0823 11:55:37.230765 28265 solver.cpp:228] Iteration 84600, loss = 0.00037019
I0823 11:55:37.230810 28265 solver.cpp:244]     Train net output #0: loss = 0.00037019 (* 1 = 0.00037019 loss)
I0823 11:55:37.230816 28265 sgd_solver.cpp:106] Iteration 84600, lr = 0.000213971
I0823 11:55:41.743177 28265 solver.cpp:228] Iteration 84700, loss = 0.000527788
I0823 11:55:41.743224 28265 solver.cpp:244]     Train net output #0: loss = 0.000527788 (* 1 = 0.000527788 loss)
I0823 11:55:41.743230 28265 sgd_solver.cpp:106] Iteration 84700, lr = 0.000213818
I0823 11:55:46.258349 28265 solver.cpp:228] Iteration 84800, loss = 0.00019104
I0823 11:55:46.258397 28265 solver.cpp:244]     Train net output #0: loss = 0.00019104 (* 1 = 0.00019104 loss)
I0823 11:55:46.258404 28265 sgd_solver.cpp:106] Iteration 84800, lr = 0.000213665
I0823 11:55:50.769531 28265 solver.cpp:228] Iteration 84900, loss = 0.00100321
I0823 11:55:50.769574 28265 solver.cpp:244]     Train net output #0: loss = 0.00100321 (* 1 = 0.00100321 loss)
I0823 11:55:50.769579 28265 sgd_solver.cpp:106] Iteration 84900, lr = 0.000213512
I0823 11:55:55.234866 28265 solver.cpp:337] Iteration 85000, Testing net (#0)
I0823 11:55:58.643920 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844875
I0823 11:55:58.643973 28265 solver.cpp:404]     Test net output #1: loss = 1.05749 (* 1 = 1.05749 loss)
I0823 11:55:58.659570 28265 solver.cpp:228] Iteration 85000, loss = 0.000633129
I0823 11:55:58.659626 28265 solver.cpp:244]     Train net output #0: loss = 0.000633129 (* 1 = 0.000633129 loss)
I0823 11:55:58.659638 28265 sgd_solver.cpp:106] Iteration 85000, lr = 0.00021336
I0823 11:56:03.169675 28265 solver.cpp:228] Iteration 85100, loss = 0.000357065
I0823 11:56:03.169744 28265 solver.cpp:244]     Train net output #0: loss = 0.000357065 (* 1 = 0.000357065 loss)
I0823 11:56:03.169750 28265 sgd_solver.cpp:106] Iteration 85100, lr = 0.000213207
I0823 11:56:07.686660 28265 solver.cpp:228] Iteration 85200, loss = 0.000448055
I0823 11:56:07.686705 28265 solver.cpp:244]     Train net output #0: loss = 0.000448055 (* 1 = 0.000448055 loss)
I0823 11:56:07.686710 28265 sgd_solver.cpp:106] Iteration 85200, lr = 0.000213055
I0823 11:56:12.196712 28265 solver.cpp:228] Iteration 85300, loss = 0.00073745
I0823 11:56:12.196759 28265 solver.cpp:244]     Train net output #0: loss = 0.00073745 (* 1 = 0.00073745 loss)
I0823 11:56:12.196765 28265 sgd_solver.cpp:106] Iteration 85300, lr = 0.000212904
I0823 11:56:16.711822 28265 solver.cpp:228] Iteration 85400, loss = 0.00059224
I0823 11:56:16.711871 28265 solver.cpp:244]     Train net output #0: loss = 0.00059224 (* 1 = 0.00059224 loss)
I0823 11:56:16.711876 28265 sgd_solver.cpp:106] Iteration 85400, lr = 0.000212752
I0823 11:56:21.178740 28265 solver.cpp:337] Iteration 85500, Testing net (#0)
I0823 11:56:24.739588 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843667
I0823 11:56:24.739640 28265 solver.cpp:404]     Test net output #1: loss = 1.064 (* 1 = 1.064 loss)
I0823 11:56:24.754556 28265 solver.cpp:228] Iteration 85500, loss = 0.000633433
I0823 11:56:24.754616 28265 solver.cpp:244]     Train net output #0: loss = 0.000633433 (* 1 = 0.000633433 loss)
I0823 11:56:24.754631 28265 sgd_solver.cpp:106] Iteration 85500, lr = 0.000212601
I0823 11:56:29.279739 28265 solver.cpp:228] Iteration 85600, loss = 0.000267478
I0823 11:56:29.279783 28265 solver.cpp:244]     Train net output #0: loss = 0.000267478 (* 1 = 0.000267478 loss)
I0823 11:56:29.279789 28265 sgd_solver.cpp:106] Iteration 85600, lr = 0.00021245
I0823 11:56:33.791481 28265 solver.cpp:228] Iteration 85700, loss = 0.00115391
I0823 11:56:33.791539 28265 solver.cpp:244]     Train net output #0: loss = 0.00115391 (* 1 = 0.00115391 loss)
I0823 11:56:33.791548 28265 sgd_solver.cpp:106] Iteration 85700, lr = 0.000212299
I0823 11:56:38.295778 28265 solver.cpp:228] Iteration 85800, loss = 0.000242835
I0823 11:56:38.295825 28265 solver.cpp:244]     Train net output #0: loss = 0.000242835 (* 1 = 0.000242835 loss)
I0823 11:56:38.295830 28265 sgd_solver.cpp:106] Iteration 85800, lr = 0.000212149
I0823 11:56:42.802814 28265 solver.cpp:228] Iteration 85900, loss = 0.00078935
I0823 11:56:42.802863 28265 solver.cpp:244]     Train net output #0: loss = 0.00078935 (* 1 = 0.00078935 loss)
I0823 11:56:42.802870 28265 sgd_solver.cpp:106] Iteration 85900, lr = 0.000211998
I0823 11:56:47.270717 28265 solver.cpp:337] Iteration 86000, Testing net (#0)
I0823 11:56:50.470180 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845042
I0823 11:56:50.470249 28265 solver.cpp:404]     Test net output #1: loss = 1.06403 (* 1 = 1.06403 loss)
I0823 11:56:50.486160 28265 solver.cpp:228] Iteration 86000, loss = 0.00172834
I0823 11:56:50.486224 28265 solver.cpp:244]     Train net output #0: loss = 0.00172834 (* 1 = 0.00172834 loss)
I0823 11:56:50.486246 28265 sgd_solver.cpp:106] Iteration 86000, lr = 0.000211848
I0823 11:56:54.988993 28265 solver.cpp:228] Iteration 86100, loss = 0.00051269
I0823 11:56:54.989037 28265 solver.cpp:244]     Train net output #0: loss = 0.00051269 (* 1 = 0.00051269 loss)
I0823 11:56:54.989042 28265 sgd_solver.cpp:106] Iteration 86100, lr = 0.000211698
I0823 11:56:59.494748 28265 solver.cpp:228] Iteration 86200, loss = 0.00128965
I0823 11:56:59.494793 28265 solver.cpp:244]     Train net output #0: loss = 0.00128965 (* 1 = 0.00128965 loss)
I0823 11:56:59.494799 28265 sgd_solver.cpp:106] Iteration 86200, lr = 0.000211549
I0823 11:57:04.005962 28265 solver.cpp:228] Iteration 86300, loss = 0.00045943
I0823 11:57:04.006011 28265 solver.cpp:244]     Train net output #0: loss = 0.00045943 (* 1 = 0.00045943 loss)
I0823 11:57:04.006016 28265 sgd_solver.cpp:106] Iteration 86300, lr = 0.0002114
I0823 11:57:08.511239 28265 solver.cpp:228] Iteration 86400, loss = 0.000646459
I0823 11:57:08.511260 28265 solver.cpp:244]     Train net output #0: loss = 0.000646459 (* 1 = 0.000646459 loss)
I0823 11:57:08.511265 28265 sgd_solver.cpp:106] Iteration 86400, lr = 0.000211251
I0823 11:57:12.982822 28265 solver.cpp:337] Iteration 86500, Testing net (#0)
I0823 11:57:16.661756 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:57:16.721946 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843167
I0823 11:57:16.722035 28265 solver.cpp:404]     Test net output #1: loss = 1.0818 (* 1 = 1.0818 loss)
I0823 11:57:16.738035 28265 solver.cpp:228] Iteration 86500, loss = 0.000470306
I0823 11:57:16.738098 28265 solver.cpp:244]     Train net output #0: loss = 0.000470306 (* 1 = 0.000470306 loss)
I0823 11:57:16.738118 28265 sgd_solver.cpp:106] Iteration 86500, lr = 0.000211102
I0823 11:57:21.247628 28265 solver.cpp:228] Iteration 86600, loss = 0.000559616
I0823 11:57:21.247670 28265 solver.cpp:244]     Train net output #0: loss = 0.000559616 (* 1 = 0.000559616 loss)
I0823 11:57:21.247675 28265 sgd_solver.cpp:106] Iteration 86600, lr = 0.000210953
I0823 11:57:25.768124 28265 solver.cpp:228] Iteration 86700, loss = 0.000611161
I0823 11:57:25.768193 28265 solver.cpp:244]     Train net output #0: loss = 0.000611161 (* 1 = 0.000611161 loss)
I0823 11:57:25.768201 28265 sgd_solver.cpp:106] Iteration 86700, lr = 0.000210805
I0823 11:57:30.280827 28265 solver.cpp:228] Iteration 86800, loss = 0.000916845
I0823 11:57:30.280879 28265 solver.cpp:244]     Train net output #0: loss = 0.000916845 (* 1 = 0.000916845 loss)
I0823 11:57:30.280886 28265 sgd_solver.cpp:106] Iteration 86800, lr = 0.000210657
I0823 11:57:34.801729 28265 solver.cpp:228] Iteration 86900, loss = 0.000387027
I0823 11:57:34.801800 28265 solver.cpp:244]     Train net output #0: loss = 0.000387027 (* 1 = 0.000387027 loss)
I0823 11:57:34.801805 28265 sgd_solver.cpp:106] Iteration 86900, lr = 0.000210509
I0823 11:57:39.266016 28265 solver.cpp:337] Iteration 87000, Testing net (#0)
I0823 11:57:42.931437 28265 solver.cpp:404]     Test net output #0: accuracy = 0.840417
I0823 11:57:42.931486 28265 solver.cpp:404]     Test net output #1: loss = 1.10585 (* 1 = 1.10585 loss)
I0823 11:57:42.946559 28265 solver.cpp:228] Iteration 87000, loss = 0.000373485
I0823 11:57:42.946599 28265 solver.cpp:244]     Train net output #0: loss = 0.000373485 (* 1 = 0.000373485 loss)
I0823 11:57:42.946609 28265 sgd_solver.cpp:106] Iteration 87000, lr = 0.000210362
I0823 11:57:47.456739 28265 solver.cpp:228] Iteration 87100, loss = 0.000232271
I0823 11:57:47.456782 28265 solver.cpp:244]     Train net output #0: loss = 0.000232271 (* 1 = 0.000232271 loss)
I0823 11:57:47.456787 28265 sgd_solver.cpp:106] Iteration 87100, lr = 0.000210214
I0823 11:57:51.970248 28265 solver.cpp:228] Iteration 87200, loss = 0.00116456
I0823 11:57:51.970324 28265 solver.cpp:244]     Train net output #0: loss = 0.00116456 (* 1 = 0.00116456 loss)
I0823 11:57:51.970336 28265 sgd_solver.cpp:106] Iteration 87200, lr = 0.000210067
I0823 11:57:56.480012 28265 solver.cpp:228] Iteration 87300, loss = 0.00135547
I0823 11:57:56.480054 28265 solver.cpp:244]     Train net output #0: loss = 0.00135547 (* 1 = 0.00135547 loss)
I0823 11:57:56.480060 28265 sgd_solver.cpp:106] Iteration 87300, lr = 0.00020992
I0823 11:58:00.991709 28265 solver.cpp:228] Iteration 87400, loss = 0.000393704
I0823 11:58:00.991767 28265 solver.cpp:244]     Train net output #0: loss = 0.000393704 (* 1 = 0.000393704 loss)
I0823 11:58:00.991775 28265 sgd_solver.cpp:106] Iteration 87400, lr = 0.000209774
I0823 11:58:05.461729 28265 solver.cpp:337] Iteration 87500, Testing net (#0)
I0823 11:58:08.739171 28265 solver.cpp:404]     Test net output #0: accuracy = 0.83925
I0823 11:58:08.739238 28265 solver.cpp:404]     Test net output #1: loss = 1.11097 (* 1 = 1.11097 loss)
I0823 11:58:08.754530 28265 solver.cpp:228] Iteration 87500, loss = 0.000737371
I0823 11:58:08.754573 28265 solver.cpp:244]     Train net output #0: loss = 0.000737371 (* 1 = 0.000737371 loss)
I0823 11:58:08.754585 28265 sgd_solver.cpp:106] Iteration 87500, lr = 0.000209627
I0823 11:58:13.276551 28265 solver.cpp:228] Iteration 87600, loss = 0.00043667
I0823 11:58:13.276604 28265 solver.cpp:244]     Train net output #0: loss = 0.00043667 (* 1 = 0.00043667 loss)
I0823 11:58:13.276617 28265 sgd_solver.cpp:106] Iteration 87600, lr = 0.000209481
I0823 11:58:17.784068 28265 solver.cpp:228] Iteration 87700, loss = 0.00118354
I0823 11:58:17.784088 28265 solver.cpp:244]     Train net output #0: loss = 0.00118354 (* 1 = 0.00118354 loss)
I0823 11:58:17.784093 28265 sgd_solver.cpp:106] Iteration 87700, lr = 0.000209335
I0823 11:58:22.290822 28265 solver.cpp:228] Iteration 87800, loss = 0.00179287
I0823 11:58:22.290877 28265 solver.cpp:244]     Train net output #0: loss = 0.00179287 (* 1 = 0.00179287 loss)
I0823 11:58:22.290885 28265 sgd_solver.cpp:106] Iteration 87800, lr = 0.00020919
I0823 11:58:26.806556 28265 solver.cpp:228] Iteration 87900, loss = 0.000644736
I0823 11:58:26.806623 28265 solver.cpp:244]     Train net output #0: loss = 0.000644736 (* 1 = 0.000644736 loss)
I0823 11:58:26.806630 28265 sgd_solver.cpp:106] Iteration 87900, lr = 0.000209044
I0823 11:58:31.271201 28265 solver.cpp:337] Iteration 88000, Testing net (#0)
I0823 11:58:34.784982 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841333
I0823 11:58:34.785033 28265 solver.cpp:404]     Test net output #1: loss = 1.10338 (* 1 = 1.10338 loss)
I0823 11:58:34.800995 28265 solver.cpp:228] Iteration 88000, loss = 0.00117564
I0823 11:58:34.801076 28265 solver.cpp:244]     Train net output #0: loss = 0.00117564 (* 1 = 0.00117564 loss)
I0823 11:58:34.801096 28265 sgd_solver.cpp:106] Iteration 88000, lr = 0.000208899
I0823 11:58:39.312903 28265 solver.cpp:228] Iteration 88100, loss = 0.000254771
I0823 11:58:39.312949 28265 solver.cpp:244]     Train net output #0: loss = 0.000254771 (* 1 = 0.000254771 loss)
I0823 11:58:39.312954 28265 sgd_solver.cpp:106] Iteration 88100, lr = 0.000208754
I0823 11:58:43.830565 28265 solver.cpp:228] Iteration 88200, loss = 0.000572614
I0823 11:58:43.830636 28265 solver.cpp:244]     Train net output #0: loss = 0.000572614 (* 1 = 0.000572614 loss)
I0823 11:58:43.830652 28265 sgd_solver.cpp:106] Iteration 88200, lr = 0.000208609
I0823 11:58:48.343140 28265 solver.cpp:228] Iteration 88300, loss = 0.00043786
I0823 11:58:48.343214 28265 solver.cpp:244]     Train net output #0: loss = 0.00043786 (* 1 = 0.00043786 loss)
I0823 11:58:48.343225 28265 sgd_solver.cpp:106] Iteration 88300, lr = 0.000208465
I0823 11:58:52.867764 28265 solver.cpp:228] Iteration 88400, loss = 0.00024835
I0823 11:58:52.867815 28265 solver.cpp:244]     Train net output #0: loss = 0.00024835 (* 1 = 0.00024835 loss)
I0823 11:58:52.867820 28265 sgd_solver.cpp:106] Iteration 88400, lr = 0.000208321
I0823 11:58:57.341148 28265 solver.cpp:337] Iteration 88500, Testing net (#0)
I0823 11:59:00.932304 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841167
I0823 11:59:00.932363 28265 solver.cpp:404]     Test net output #1: loss = 1.11301 (* 1 = 1.11301 loss)
I0823 11:59:00.947636 28265 solver.cpp:228] Iteration 88500, loss = 0.000171946
I0823 11:59:00.947679 28265 solver.cpp:244]     Train net output #0: loss = 0.000171946 (* 1 = 0.000171946 loss)
I0823 11:59:00.947691 28265 sgd_solver.cpp:106] Iteration 88500, lr = 0.000208177
I0823 11:59:05.456784 28265 solver.cpp:228] Iteration 88600, loss = 0.000637678
I0823 11:59:05.456828 28265 solver.cpp:244]     Train net output #0: loss = 0.000637678 (* 1 = 0.000637678 loss)
I0823 11:59:05.456835 28265 sgd_solver.cpp:106] Iteration 88600, lr = 0.000208033
I0823 11:59:09.973331 28265 solver.cpp:228] Iteration 88700, loss = 0.000410626
I0823 11:59:09.973381 28265 solver.cpp:244]     Train net output #0: loss = 0.000410626 (* 1 = 0.000410626 loss)
I0823 11:59:09.973387 28265 sgd_solver.cpp:106] Iteration 88700, lr = 0.000207889
I0823 11:59:14.503417 28265 solver.cpp:228] Iteration 88800, loss = 0.00043356
I0823 11:59:14.503461 28265 solver.cpp:244]     Train net output #0: loss = 0.00043356 (* 1 = 0.00043356 loss)
I0823 11:59:14.503466 28265 sgd_solver.cpp:106] Iteration 88800, lr = 0.000207746
I0823 11:59:19.024240 28265 solver.cpp:228] Iteration 88900, loss = 0.000519325
I0823 11:59:19.024287 28265 solver.cpp:244]     Train net output #0: loss = 0.000519325 (* 1 = 0.000519325 loss)
I0823 11:59:19.024292 28265 sgd_solver.cpp:106] Iteration 88900, lr = 0.000207603
I0823 11:59:23.490403 28265 solver.cpp:337] Iteration 89000, Testing net (#0)
I0823 11:59:27.028137 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841459
I0823 11:59:27.028223 28265 solver.cpp:404]     Test net output #1: loss = 1.11027 (* 1 = 1.11027 loss)
I0823 11:59:27.043174 28265 solver.cpp:228] Iteration 89000, loss = 0.000230306
I0823 11:59:27.043228 28265 solver.cpp:244]     Train net output #0: loss = 0.000230306 (* 1 = 0.000230306 loss)
I0823 11:59:27.043239 28265 sgd_solver.cpp:106] Iteration 89000, lr = 0.00020746
I0823 11:59:31.559062 28265 solver.cpp:228] Iteration 89100, loss = 0.000593112
I0823 11:59:31.559109 28265 solver.cpp:244]     Train net output #0: loss = 0.000593112 (* 1 = 0.000593112 loss)
I0823 11:59:31.559115 28265 sgd_solver.cpp:106] Iteration 89100, lr = 0.000207317
I0823 11:59:36.069583 28265 solver.cpp:228] Iteration 89200, loss = 0.000690013
I0823 11:59:36.069628 28265 solver.cpp:244]     Train net output #0: loss = 0.000690013 (* 1 = 0.000690013 loss)
I0823 11:59:36.069634 28265 sgd_solver.cpp:106] Iteration 89200, lr = 0.000207175
I0823 11:59:40.584580 28265 solver.cpp:228] Iteration 89300, loss = 0.00093096
I0823 11:59:40.584627 28265 solver.cpp:244]     Train net output #0: loss = 0.00093096 (* 1 = 0.00093096 loss)
I0823 11:59:40.584632 28265 sgd_solver.cpp:106] Iteration 89300, lr = 0.000207033
I0823 11:59:45.095791 28265 solver.cpp:228] Iteration 89400, loss = 0.000192032
I0823 11:59:45.095834 28265 solver.cpp:244]     Train net output #0: loss = 0.000192032 (* 1 = 0.000192032 loss)
I0823 11:59:45.095840 28265 sgd_solver.cpp:106] Iteration 89400, lr = 0.000206891
I0823 11:59:49.562841 28265 solver.cpp:337] Iteration 89500, Testing net (#0)
I0823 11:59:52.618818 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 11:59:52.773039 28265 solver.cpp:404]     Test net output #0: accuracy = 0.841917
I0823 11:59:52.773180 28265 solver.cpp:404]     Test net output #1: loss = 1.11603 (* 1 = 1.11603 loss)
I0823 11:59:52.788732 28265 solver.cpp:228] Iteration 89500, loss = 0.00140692
I0823 11:59:52.788774 28265 solver.cpp:244]     Train net output #0: loss = 0.00140692 (* 1 = 0.00140692 loss)
I0823 11:59:52.788789 28265 sgd_solver.cpp:106] Iteration 89500, lr = 0.000206749
I0823 11:59:57.292542 28265 solver.cpp:228] Iteration 89600, loss = 0.000423378
I0823 11:59:57.292585 28265 solver.cpp:244]     Train net output #0: loss = 0.000423378 (* 1 = 0.000423378 loss)
I0823 11:59:57.292590 28265 sgd_solver.cpp:106] Iteration 89600, lr = 0.000206608
I0823 12:00:01.799026 28265 solver.cpp:228] Iteration 89700, loss = 0.000356648
I0823 12:00:01.799048 28265 solver.cpp:244]     Train net output #0: loss = 0.000356648 (* 1 = 0.000356648 loss)
I0823 12:00:01.799053 28265 sgd_solver.cpp:106] Iteration 89700, lr = 0.000206466
I0823 12:00:06.316874 28265 solver.cpp:228] Iteration 89800, loss = 0.000476205
I0823 12:00:06.316920 28265 solver.cpp:244]     Train net output #0: loss = 0.000476205 (* 1 = 0.000476205 loss)
I0823 12:00:06.316926 28265 sgd_solver.cpp:106] Iteration 89800, lr = 0.000206325
I0823 12:00:10.847932 28265 solver.cpp:228] Iteration 89900, loss = 0.000394614
I0823 12:00:10.847978 28265 solver.cpp:244]     Train net output #0: loss = 0.000394614 (* 1 = 0.000394614 loss)
I0823 12:00:10.847985 28265 sgd_solver.cpp:106] Iteration 89900, lr = 0.000206184
I0823 12:00:15.307067 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_90000.caffemodel
I0823 12:00:15.790020 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_90000.solverstate
I0823 12:00:15.950645 28265 solver.cpp:337] Iteration 90000, Testing net (#0)
I0823 12:00:19.573789 28265 solver.cpp:404]     Test net output #0: accuracy = 0.840125
I0823 12:00:19.573873 28265 solver.cpp:404]     Test net output #1: loss = 1.12582 (* 1 = 1.12582 loss)
I0823 12:00:19.589545 28265 solver.cpp:228] Iteration 90000, loss = 0.00122949
I0823 12:00:19.589596 28265 solver.cpp:244]     Train net output #0: loss = 0.00122949 (* 1 = 0.00122949 loss)
I0823 12:00:19.589620 28265 sgd_solver.cpp:106] Iteration 90000, lr = 0.000206044
I0823 12:00:24.104302 28265 solver.cpp:228] Iteration 90100, loss = 0.000205562
I0823 12:00:24.104354 28265 solver.cpp:244]     Train net output #0: loss = 0.000205562 (* 1 = 0.000205562 loss)
I0823 12:00:24.104360 28265 sgd_solver.cpp:106] Iteration 90100, lr = 0.000205903
I0823 12:00:28.624564 28265 solver.cpp:228] Iteration 90200, loss = 0.000713392
I0823 12:00:28.624611 28265 solver.cpp:244]     Train net output #0: loss = 0.000713392 (* 1 = 0.000713392 loss)
I0823 12:00:28.624616 28265 sgd_solver.cpp:106] Iteration 90200, lr = 0.000205763
I0823 12:00:33.142365 28265 solver.cpp:228] Iteration 90300, loss = 0.00079633
I0823 12:00:33.142426 28265 solver.cpp:244]     Train net output #0: loss = 0.00079633 (* 1 = 0.00079633 loss)
I0823 12:00:33.142431 28265 sgd_solver.cpp:106] Iteration 90300, lr = 0.000205623
I0823 12:00:37.665731 28265 solver.cpp:228] Iteration 90400, loss = 0.000543683
I0823 12:00:37.665776 28265 solver.cpp:244]     Train net output #0: loss = 0.000543683 (* 1 = 0.000543683 loss)
I0823 12:00:37.665781 28265 sgd_solver.cpp:106] Iteration 90400, lr = 0.000205484
I0823 12:00:42.137329 28265 solver.cpp:337] Iteration 90500, Testing net (#0)
I0823 12:00:45.445637 28265 solver.cpp:404]     Test net output #0: accuracy = 0.8395
I0823 12:00:45.445745 28265 solver.cpp:404]     Test net output #1: loss = 1.13462 (* 1 = 1.13462 loss)
I0823 12:00:45.460383 28265 solver.cpp:228] Iteration 90500, loss = 0.000595885
I0823 12:00:45.460433 28265 solver.cpp:244]     Train net output #0: loss = 0.000595885 (* 1 = 0.000595885 loss)
I0823 12:00:45.460444 28265 sgd_solver.cpp:106] Iteration 90500, lr = 0.000205344
I0823 12:00:49.968219 28265 solver.cpp:228] Iteration 90600, loss = 0.000366566
I0823 12:00:49.968268 28265 solver.cpp:244]     Train net output #0: loss = 0.000366566 (* 1 = 0.000366566 loss)
I0823 12:00:49.968274 28265 sgd_solver.cpp:106] Iteration 90600, lr = 0.000205205
I0823 12:00:54.484218 28265 solver.cpp:228] Iteration 90700, loss = 0.000541628
I0823 12:00:54.484294 28265 solver.cpp:244]     Train net output #0: loss = 0.000541628 (* 1 = 0.000541628 loss)
I0823 12:00:54.484300 28265 sgd_solver.cpp:106] Iteration 90700, lr = 0.000205066
I0823 12:00:59.005012 28265 solver.cpp:228] Iteration 90800, loss = 0.000420319
I0823 12:00:59.005058 28265 solver.cpp:244]     Train net output #0: loss = 0.000420319 (* 1 = 0.000420319 loss)
I0823 12:00:59.005064 28265 sgd_solver.cpp:106] Iteration 90800, lr = 0.000204927
I0823 12:01:03.526563 28265 solver.cpp:228] Iteration 90900, loss = 0.000289594
I0823 12:01:03.526619 28265 solver.cpp:244]     Train net output #0: loss = 0.000289594 (* 1 = 0.000289594 loss)
I0823 12:01:03.526626 28265 sgd_solver.cpp:106] Iteration 90900, lr = 0.000204788
I0823 12:01:08.005427 28265 solver.cpp:337] Iteration 91000, Testing net (#0)
I0823 12:01:11.606670 28265 solver.cpp:404]     Test net output #0: accuracy = 0.837958
I0823 12:01:11.606770 28265 solver.cpp:404]     Test net output #1: loss = 1.15327 (* 1 = 1.15327 loss)
I0823 12:01:11.622944 28265 solver.cpp:228] Iteration 91000, loss = 0.000359439
I0823 12:01:11.622982 28265 solver.cpp:244]     Train net output #0: loss = 0.000359439 (* 1 = 0.000359439 loss)
I0823 12:01:11.622992 28265 sgd_solver.cpp:106] Iteration 91000, lr = 0.00020465
I0823 12:01:16.134641 28265 solver.cpp:228] Iteration 91100, loss = 0.000320966
I0823 12:01:16.134688 28265 solver.cpp:244]     Train net output #0: loss = 0.000320966 (* 1 = 0.000320966 loss)
I0823 12:01:16.134694 28265 sgd_solver.cpp:106] Iteration 91100, lr = 0.000204512
I0823 12:01:20.655392 28265 solver.cpp:228] Iteration 91200, loss = 0.000162275
I0823 12:01:20.655441 28265 solver.cpp:244]     Train net output #0: loss = 0.000162275 (* 1 = 0.000162275 loss)
I0823 12:01:20.655446 28265 sgd_solver.cpp:106] Iteration 91200, lr = 0.000204374
I0823 12:01:25.162691 28265 solver.cpp:228] Iteration 91300, loss = 0.000312889
I0823 12:01:25.162714 28265 solver.cpp:244]     Train net output #0: loss = 0.000312889 (* 1 = 0.000312889 loss)
I0823 12:01:25.162719 28265 sgd_solver.cpp:106] Iteration 91300, lr = 0.000204236
I0823 12:01:29.672518 28265 solver.cpp:228] Iteration 91400, loss = 0.000159404
I0823 12:01:29.672565 28265 solver.cpp:244]     Train net output #0: loss = 0.000159404 (* 1 = 0.000159404 loss)
I0823 12:01:29.672570 28265 sgd_solver.cpp:106] Iteration 91400, lr = 0.000204099
I0823 12:01:34.138188 28265 solver.cpp:337] Iteration 91500, Testing net (#0)
I0823 12:01:37.700014 28265 solver.cpp:404]     Test net output #0: accuracy = 0.838375
I0823 12:01:37.700110 28265 solver.cpp:404]     Test net output #1: loss = 1.14898 (* 1 = 1.14898 loss)
I0823 12:01:37.714651 28265 solver.cpp:228] Iteration 91500, loss = 0.000853978
I0823 12:01:37.714685 28265 solver.cpp:244]     Train net output #0: loss = 0.000853978 (* 1 = 0.000853978 loss)
I0823 12:01:37.714694 28265 sgd_solver.cpp:106] Iteration 91500, lr = 0.000203961
I0823 12:01:42.228943 28265 solver.cpp:228] Iteration 91600, loss = 0.000674517
I0823 12:01:42.229002 28265 solver.cpp:244]     Train net output #0: loss = 0.000674517 (* 1 = 0.000674517 loss)
I0823 12:01:42.229010 28265 sgd_solver.cpp:106] Iteration 91600, lr = 0.000203824
I0823 12:01:46.744756 28265 solver.cpp:228] Iteration 91700, loss = 0.000365172
I0823 12:01:46.744812 28265 solver.cpp:244]     Train net output #0: loss = 0.000365172 (* 1 = 0.000365172 loss)
I0823 12:01:46.744819 28265 sgd_solver.cpp:106] Iteration 91700, lr = 0.000203687
I0823 12:01:51.272217 28265 solver.cpp:228] Iteration 91800, loss = 0.0012842
I0823 12:01:51.272274 28265 solver.cpp:244]     Train net output #0: loss = 0.0012842 (* 1 = 0.0012842 loss)
I0823 12:01:51.272281 28265 sgd_solver.cpp:106] Iteration 91800, lr = 0.000203551
I0823 12:01:55.790796 28265 solver.cpp:228] Iteration 91900, loss = 0.000361867
I0823 12:01:55.790846 28265 solver.cpp:244]     Train net output #0: loss = 0.000361867 (* 1 = 0.000361867 loss)
I0823 12:01:55.790853 28265 sgd_solver.cpp:106] Iteration 91900, lr = 0.000203414
I0823 12:02:00.253618 28265 solver.cpp:337] Iteration 92000, Testing net (#0)
I0823 12:02:03.708295 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 12:02:03.829814 28265 solver.cpp:404]     Test net output #0: accuracy = 0.839625
I0823 12:02:03.829864 28265 solver.cpp:404]     Test net output #1: loss = 1.14059 (* 1 = 1.14059 loss)
I0823 12:02:03.845098 28265 solver.cpp:228] Iteration 92000, loss = 0.000476226
I0823 12:02:03.845134 28265 solver.cpp:244]     Train net output #0: loss = 0.000476226 (* 1 = 0.000476226 loss)
I0823 12:02:03.845144 28265 sgd_solver.cpp:106] Iteration 92000, lr = 0.000203278
I0823 12:02:08.357944 28265 solver.cpp:228] Iteration 92100, loss = 0.000680294
I0823 12:02:08.357990 28265 solver.cpp:244]     Train net output #0: loss = 0.000680294 (* 1 = 0.000680294 loss)
I0823 12:02:08.357996 28265 sgd_solver.cpp:106] Iteration 92100, lr = 0.000203142
I0823 12:02:12.869670 28265 solver.cpp:228] Iteration 92200, loss = 0.000476506
I0823 12:02:12.869727 28265 solver.cpp:244]     Train net output #0: loss = 0.000476506 (* 1 = 0.000476506 loss)
I0823 12:02:12.869735 28265 sgd_solver.cpp:106] Iteration 92200, lr = 0.000203006
I0823 12:02:17.384106 28265 solver.cpp:228] Iteration 92300, loss = 0.0014148
I0823 12:02:17.384198 28265 solver.cpp:244]     Train net output #0: loss = 0.0014148 (* 1 = 0.0014148 loss)
I0823 12:02:17.384212 28265 sgd_solver.cpp:106] Iteration 92300, lr = 0.000202871
I0823 12:02:21.898982 28265 solver.cpp:228] Iteration 92400, loss = 0.000510664
I0823 12:02:21.899029 28265 solver.cpp:244]     Train net output #0: loss = 0.000510664 (* 1 = 0.000510664 loss)
I0823 12:02:21.899034 28265 sgd_solver.cpp:106] Iteration 92400, lr = 0.000202735
I0823 12:02:26.370903 28265 solver.cpp:337] Iteration 92500, Testing net (#0)
I0823 12:02:29.926630 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84075
I0823 12:02:29.926698 28265 solver.cpp:404]     Test net output #1: loss = 1.13897 (* 1 = 1.13897 loss)
I0823 12:02:29.942240 28265 solver.cpp:228] Iteration 92500, loss = 0.00057645
I0823 12:02:29.942278 28265 solver.cpp:244]     Train net output #0: loss = 0.00057645 (* 1 = 0.00057645 loss)
I0823 12:02:29.942293 28265 sgd_solver.cpp:106] Iteration 92500, lr = 0.0002026
I0823 12:02:34.450139 28265 solver.cpp:228] Iteration 92600, loss = 0.000208584
I0823 12:02:34.450183 28265 solver.cpp:244]     Train net output #0: loss = 0.000208584 (* 1 = 0.000208584 loss)
I0823 12:02:34.450189 28265 sgd_solver.cpp:106] Iteration 92600, lr = 0.000202465
I0823 12:02:38.956219 28265 solver.cpp:228] Iteration 92700, loss = 0.000152714
I0823 12:02:38.956239 28265 solver.cpp:244]     Train net output #0: loss = 0.000152714 (* 1 = 0.000152714 loss)
I0823 12:02:38.956244 28265 sgd_solver.cpp:106] Iteration 92700, lr = 0.00020233
I0823 12:02:43.465605 28265 solver.cpp:228] Iteration 92800, loss = 0.000213075
I0823 12:02:43.465651 28265 solver.cpp:244]     Train net output #0: loss = 0.000213075 (* 1 = 0.000213075 loss)
I0823 12:02:43.465656 28265 sgd_solver.cpp:106] Iteration 92800, lr = 0.000202196
I0823 12:02:47.971767 28265 solver.cpp:228] Iteration 92900, loss = 0.000207866
I0823 12:02:47.971810 28265 solver.cpp:244]     Train net output #0: loss = 0.000207866 (* 1 = 0.000207866 loss)
I0823 12:02:47.971815 28265 sgd_solver.cpp:106] Iteration 92900, lr = 0.000202062
I0823 12:02:52.442798 28265 solver.cpp:337] Iteration 93000, Testing net (#0)
I0823 12:02:55.617691 28265 solver.cpp:404]     Test net output #0: accuracy = 0.842833
I0823 12:02:55.617738 28265 solver.cpp:404]     Test net output #1: loss = 1.12942 (* 1 = 1.12942 loss)
I0823 12:02:55.633034 28265 solver.cpp:228] Iteration 93000, loss = 0.000400364
I0823 12:02:55.633069 28265 solver.cpp:244]     Train net output #0: loss = 0.000400364 (* 1 = 0.000400364 loss)
I0823 12:02:55.633092 28265 sgd_solver.cpp:106] Iteration 93000, lr = 0.000201927
I0823 12:03:00.138221 28265 solver.cpp:228] Iteration 93100, loss = 0.000375018
I0823 12:03:00.138267 28265 solver.cpp:244]     Train net output #0: loss = 0.000375018 (* 1 = 0.000375018 loss)
I0823 12:03:00.138273 28265 sgd_solver.cpp:106] Iteration 93100, lr = 0.000201794
I0823 12:03:04.644153 28265 solver.cpp:228] Iteration 93200, loss = 0.000740547
I0823 12:03:04.644198 28265 solver.cpp:244]     Train net output #0: loss = 0.000740547 (* 1 = 0.000740547 loss)
I0823 12:03:04.644203 28265 sgd_solver.cpp:106] Iteration 93200, lr = 0.00020166
I0823 12:03:09.153615 28265 solver.cpp:228] Iteration 93300, loss = 0.000376346
I0823 12:03:09.153663 28265 solver.cpp:244]     Train net output #0: loss = 0.000376346 (* 1 = 0.000376346 loss)
I0823 12:03:09.153669 28265 sgd_solver.cpp:106] Iteration 93300, lr = 0.000201526
I0823 12:03:13.670490 28265 solver.cpp:228] Iteration 93400, loss = 0.000257053
I0823 12:03:13.670534 28265 solver.cpp:244]     Train net output #0: loss = 0.000257053 (* 1 = 0.000257053 loss)
I0823 12:03:13.670541 28265 sgd_solver.cpp:106] Iteration 93400, lr = 0.000201393
I0823 12:03:18.135608 28265 solver.cpp:337] Iteration 93500, Testing net (#0)
I0823 12:03:21.544083 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843333
I0823 12:03:21.544157 28265 solver.cpp:404]     Test net output #1: loss = 1.11795 (* 1 = 1.11795 loss)
I0823 12:03:21.559320 28265 solver.cpp:228] Iteration 93500, loss = 0.000332378
I0823 12:03:21.559360 28265 solver.cpp:244]     Train net output #0: loss = 0.000332378 (* 1 = 0.000332378 loss)
I0823 12:03:21.559371 28265 sgd_solver.cpp:106] Iteration 93500, lr = 0.00020126
I0823 12:03:26.067070 28265 solver.cpp:228] Iteration 93600, loss = 0.000599493
I0823 12:03:26.067095 28265 solver.cpp:244]     Train net output #0: loss = 0.000599493 (* 1 = 0.000599493 loss)
I0823 12:03:26.067098 28265 sgd_solver.cpp:106] Iteration 93600, lr = 0.000201127
I0823 12:03:30.578986 28265 solver.cpp:228] Iteration 93700, loss = 0.000187488
I0823 12:03:30.579033 28265 solver.cpp:244]     Train net output #0: loss = 0.000187488 (* 1 = 0.000187488 loss)
I0823 12:03:30.579040 28265 sgd_solver.cpp:106] Iteration 93700, lr = 0.000200994
I0823 12:03:35.089303 28265 solver.cpp:228] Iteration 93800, loss = 0.000597312
I0823 12:03:35.089323 28265 solver.cpp:244]     Train net output #0: loss = 0.000597312 (* 1 = 0.000597312 loss)
I0823 12:03:35.089328 28265 sgd_solver.cpp:106] Iteration 93800, lr = 0.000200862
I0823 12:03:39.605792 28265 solver.cpp:228] Iteration 93900, loss = 0.000277494
I0823 12:03:39.605837 28265 solver.cpp:244]     Train net output #0: loss = 0.000277494 (* 1 = 0.000277494 loss)
I0823 12:03:39.605844 28265 sgd_solver.cpp:106] Iteration 93900, lr = 0.00020073
I0823 12:03:44.084064 28265 solver.cpp:337] Iteration 94000, Testing net (#0)
I0823 12:03:47.616446 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844958
I0823 12:03:47.616515 28265 solver.cpp:404]     Test net output #1: loss = 1.11351 (* 1 = 1.11351 loss)
I0823 12:03:47.631956 28265 solver.cpp:228] Iteration 94000, loss = 0.000724379
I0823 12:03:47.632009 28265 solver.cpp:244]     Train net output #0: loss = 0.000724379 (* 1 = 0.000724379 loss)
I0823 12:03:47.632025 28265 sgd_solver.cpp:106] Iteration 94000, lr = 0.000200598
I0823 12:03:52.140127 28265 solver.cpp:228] Iteration 94100, loss = 0.000251086
I0823 12:03:52.140190 28265 solver.cpp:244]     Train net output #0: loss = 0.000251086 (* 1 = 0.000251086 loss)
I0823 12:03:52.140197 28265 sgd_solver.cpp:106] Iteration 94100, lr = 0.000200466
I0823 12:03:56.644099 28265 solver.cpp:228] Iteration 94200, loss = 0.000307156
I0823 12:03:56.644119 28265 solver.cpp:244]     Train net output #0: loss = 0.000307156 (* 1 = 0.000307156 loss)
I0823 12:03:56.644124 28265 sgd_solver.cpp:106] Iteration 94200, lr = 0.000200334
I0823 12:04:01.156991 28265 solver.cpp:228] Iteration 94300, loss = 0.000320071
I0823 12:04:01.157035 28265 solver.cpp:244]     Train net output #0: loss = 0.000320071 (* 1 = 0.000320071 loss)
I0823 12:04:01.157040 28265 sgd_solver.cpp:106] Iteration 94300, lr = 0.000200203
I0823 12:04:05.662070 28265 solver.cpp:228] Iteration 94400, loss = 0.000303237
I0823 12:04:05.662091 28265 solver.cpp:244]     Train net output #0: loss = 0.000303237 (* 1 = 0.000303237 loss)
I0823 12:04:05.662096 28265 sgd_solver.cpp:106] Iteration 94400, lr = 0.000200071
I0823 12:04:10.129060 28265 solver.cpp:337] Iteration 94500, Testing net (#0)
I0823 12:04:13.544653 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845417
I0823 12:04:13.544706 28265 solver.cpp:404]     Test net output #1: loss = 1.11568 (* 1 = 1.11568 loss)
I0823 12:04:13.560020 28265 solver.cpp:228] Iteration 94500, loss = 0.000395016
I0823 12:04:13.560053 28265 solver.cpp:244]     Train net output #0: loss = 0.000395016 (* 1 = 0.000395016 loss)
I0823 12:04:13.560068 28265 sgd_solver.cpp:106] Iteration 94500, lr = 0.00019994
I0823 12:04:18.072816 28265 solver.cpp:228] Iteration 94600, loss = 0.000293157
I0823 12:04:18.072860 28265 solver.cpp:244]     Train net output #0: loss = 0.000293157 (* 1 = 0.000293157 loss)
I0823 12:04:18.072865 28265 sgd_solver.cpp:106] Iteration 94600, lr = 0.000199809
I0823 12:04:22.584040 28265 solver.cpp:228] Iteration 94700, loss = 0.000380683
I0823 12:04:22.584100 28265 solver.cpp:244]     Train net output #0: loss = 0.000380683 (* 1 = 0.000380683 loss)
I0823 12:04:22.584110 28265 sgd_solver.cpp:106] Iteration 94700, lr = 0.000199679
I0823 12:04:27.091109 28265 solver.cpp:228] Iteration 94800, loss = 0.000219503
I0823 12:04:27.091184 28265 solver.cpp:244]     Train net output #0: loss = 0.000219503 (* 1 = 0.000219503 loss)
I0823 12:04:27.091197 28265 sgd_solver.cpp:106] Iteration 94800, lr = 0.000199548
I0823 12:04:31.608464 28265 solver.cpp:228] Iteration 94900, loss = 0.000303527
I0823 12:04:31.608510 28265 solver.cpp:244]     Train net output #0: loss = 0.000303527 (* 1 = 0.000303527 loss)
I0823 12:04:31.608516 28265 sgd_solver.cpp:106] Iteration 94900, lr = 0.000199418
I0823 12:04:36.080191 28265 solver.cpp:337] Iteration 95000, Testing net (#0)
I0823 12:04:39.559005 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845375
I0823 12:04:39.559052 28265 solver.cpp:404]     Test net output #1: loss = 1.11283 (* 1 = 1.11283 loss)
I0823 12:04:39.574304 28265 solver.cpp:228] Iteration 95000, loss = 0.000939217
I0823 12:04:39.574340 28265 solver.cpp:244]     Train net output #0: loss = 0.000939217 (* 1 = 0.000939217 loss)
I0823 12:04:39.574352 28265 sgd_solver.cpp:106] Iteration 95000, lr = 0.000199288
I0823 12:04:44.097573 28265 solver.cpp:228] Iteration 95100, loss = 0.00026042
I0823 12:04:44.097633 28265 solver.cpp:244]     Train net output #0: loss = 0.00026042 (* 1 = 0.00026042 loss)
I0823 12:04:44.097640 28265 sgd_solver.cpp:106] Iteration 95100, lr = 0.000199158
I0823 12:04:48.614526 28265 solver.cpp:228] Iteration 95200, loss = 0.000163913
I0823 12:04:48.614588 28265 solver.cpp:244]     Train net output #0: loss = 0.000163913 (* 1 = 0.000163913 loss)
I0823 12:04:48.614593 28265 sgd_solver.cpp:106] Iteration 95200, lr = 0.000199028
I0823 12:04:53.134127 28265 solver.cpp:228] Iteration 95300, loss = 0.000473982
I0823 12:04:53.134178 28265 solver.cpp:244]     Train net output #0: loss = 0.000473982 (* 1 = 0.000473982 loss)
I0823 12:04:53.134184 28265 sgd_solver.cpp:106] Iteration 95300, lr = 0.000198899
I0823 12:04:57.649039 28265 solver.cpp:228] Iteration 95400, loss = 0.000386532
I0823 12:04:57.649085 28265 solver.cpp:244]     Train net output #0: loss = 0.000386532 (* 1 = 0.000386532 loss)
I0823 12:04:57.649091 28265 sgd_solver.cpp:106] Iteration 95400, lr = 0.00019877
I0823 12:05:02.123002 28265 solver.cpp:337] Iteration 95500, Testing net (#0)
I0823 12:05:04.419529 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 12:05:05.693343 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84525
I0823 12:05:05.693397 28265 solver.cpp:404]     Test net output #1: loss = 1.12121 (* 1 = 1.12121 loss)
I0823 12:05:05.708715 28265 solver.cpp:228] Iteration 95500, loss = 0.000492196
I0823 12:05:05.708744 28265 solver.cpp:244]     Train net output #0: loss = 0.000492196 (* 1 = 0.000492196 loss)
I0823 12:05:05.708755 28265 sgd_solver.cpp:106] Iteration 95500, lr = 0.00019864
I0823 12:05:10.224903 28265 solver.cpp:228] Iteration 95600, loss = 0.000401627
I0823 12:05:10.224947 28265 solver.cpp:244]     Train net output #0: loss = 0.000401627 (* 1 = 0.000401627 loss)
I0823 12:05:10.224953 28265 sgd_solver.cpp:106] Iteration 95600, lr = 0.000198512
I0823 12:05:14.732986 28265 solver.cpp:228] Iteration 95700, loss = 0.000191369
I0823 12:05:14.733048 28265 solver.cpp:244]     Train net output #0: loss = 0.000191369 (* 1 = 0.000191369 loss)
I0823 12:05:14.733058 28265 sgd_solver.cpp:106] Iteration 95700, lr = 0.000198383
I0823 12:05:19.242859 28265 solver.cpp:228] Iteration 95800, loss = 0.00072278
I0823 12:05:19.242899 28265 solver.cpp:244]     Train net output #0: loss = 0.00072278 (* 1 = 0.00072278 loss)
I0823 12:05:19.242904 28265 sgd_solver.cpp:106] Iteration 95800, lr = 0.000198254
I0823 12:05:23.748003 28265 solver.cpp:228] Iteration 95900, loss = 0.000783337
I0823 12:05:23.748064 28265 solver.cpp:244]     Train net output #0: loss = 0.000783337 (* 1 = 0.000783337 loss)
I0823 12:05:23.748071 28265 sgd_solver.cpp:106] Iteration 95900, lr = 0.000198126
I0823 12:05:28.219609 28265 solver.cpp:337] Iteration 96000, Testing net (#0)
I0823 12:05:31.561441 28265 solver.cpp:404]     Test net output #0: accuracy = 0.845416
I0823 12:05:31.561542 28265 solver.cpp:404]     Test net output #1: loss = 1.12064 (* 1 = 1.12064 loss)
I0823 12:05:31.577488 28265 solver.cpp:228] Iteration 96000, loss = 0.000232285
I0823 12:05:31.577553 28265 solver.cpp:244]     Train net output #0: loss = 0.000232285 (* 1 = 0.000232285 loss)
I0823 12:05:31.577567 28265 sgd_solver.cpp:106] Iteration 96000, lr = 0.000197998
I0823 12:05:36.097496 28265 solver.cpp:228] Iteration 96100, loss = 0.00199951
I0823 12:05:36.097570 28265 solver.cpp:244]     Train net output #0: loss = 0.00199951 (* 1 = 0.00199951 loss)
I0823 12:05:36.097578 28265 sgd_solver.cpp:106] Iteration 96100, lr = 0.00019787
I0823 12:05:40.604672 28265 solver.cpp:228] Iteration 96200, loss = 0.000154011
I0823 12:05:40.604718 28265 solver.cpp:244]     Train net output #0: loss = 0.000154011 (* 1 = 0.000154011 loss)
I0823 12:05:40.604724 28265 sgd_solver.cpp:106] Iteration 96200, lr = 0.000197742
I0823 12:05:45.113404 28265 solver.cpp:228] Iteration 96300, loss = 0.000337873
I0823 12:05:45.113461 28265 solver.cpp:244]     Train net output #0: loss = 0.000337873 (* 1 = 0.000337873 loss)
I0823 12:05:45.113469 28265 sgd_solver.cpp:106] Iteration 96300, lr = 0.000197615
I0823 12:05:49.626375 28265 solver.cpp:228] Iteration 96400, loss = 0.000281698
I0823 12:05:49.626432 28265 solver.cpp:244]     Train net output #0: loss = 0.000281698 (* 1 = 0.000281698 loss)
I0823 12:05:49.626441 28265 sgd_solver.cpp:106] Iteration 96400, lr = 0.000197487
I0823 12:05:54.097090 28265 solver.cpp:337] Iteration 96500, Testing net (#0)
I0823 12:05:57.734779 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844959
I0823 12:05:57.734833 28265 solver.cpp:404]     Test net output #1: loss = 1.1291 (* 1 = 1.1291 loss)
I0823 12:05:57.750167 28265 solver.cpp:228] Iteration 96500, loss = 0.000296676
I0823 12:05:57.750192 28265 solver.cpp:244]     Train net output #0: loss = 0.000296676 (* 1 = 0.000296676 loss)
I0823 12:05:57.750205 28265 sgd_solver.cpp:106] Iteration 96500, lr = 0.00019736
I0823 12:06:02.256888 28265 solver.cpp:228] Iteration 96600, loss = 0.0012303
I0823 12:06:02.256950 28265 solver.cpp:244]     Train net output #0: loss = 0.0012303 (* 1 = 0.0012303 loss)
I0823 12:06:02.256958 28265 sgd_solver.cpp:106] Iteration 96600, lr = 0.000197233
I0823 12:06:06.765599 28265 solver.cpp:228] Iteration 96700, loss = 0.00094447
I0823 12:06:06.765655 28265 solver.cpp:244]     Train net output #0: loss = 0.00094447 (* 1 = 0.00094447 loss)
I0823 12:06:06.765663 28265 sgd_solver.cpp:106] Iteration 96700, lr = 0.000197107
I0823 12:06:11.275099 28265 solver.cpp:228] Iteration 96800, loss = 0.000350833
I0823 12:06:11.275156 28265 solver.cpp:244]     Train net output #0: loss = 0.000350833 (* 1 = 0.000350833 loss)
I0823 12:06:11.275163 28265 sgd_solver.cpp:106] Iteration 96800, lr = 0.00019698
I0823 12:06:15.786593 28265 solver.cpp:228] Iteration 96900, loss = 0.000295225
I0823 12:06:15.786639 28265 solver.cpp:244]     Train net output #0: loss = 0.000295225 (* 1 = 0.000295225 loss)
I0823 12:06:15.786645 28265 sgd_solver.cpp:106] Iteration 96900, lr = 0.000196854
I0823 12:06:20.248937 28265 solver.cpp:337] Iteration 97000, Testing net (#0)
I0823 12:06:23.881449 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844333
I0823 12:06:23.881500 28265 solver.cpp:404]     Test net output #1: loss = 1.13754 (* 1 = 1.13754 loss)
I0823 12:06:23.897390 28265 solver.cpp:228] Iteration 97000, loss = 0.000156563
I0823 12:06:23.897425 28265 solver.cpp:244]     Train net output #0: loss = 0.000156563 (* 1 = 0.000156563 loss)
I0823 12:06:23.897438 28265 sgd_solver.cpp:106] Iteration 97000, lr = 0.000196727
I0823 12:06:28.405614 28265 solver.cpp:228] Iteration 97100, loss = 0.000337057
I0823 12:06:28.405658 28265 solver.cpp:244]     Train net output #0: loss = 0.000337057 (* 1 = 0.000337057 loss)
I0823 12:06:28.405663 28265 sgd_solver.cpp:106] Iteration 97100, lr = 0.000196601
I0823 12:06:32.916721 28265 solver.cpp:228] Iteration 97200, loss = 0.000185307
I0823 12:06:32.916767 28265 solver.cpp:244]     Train net output #0: loss = 0.000185307 (* 1 = 0.000185307 loss)
I0823 12:06:32.916774 28265 sgd_solver.cpp:106] Iteration 97200, lr = 0.000196476
I0823 12:06:37.426213 28265 solver.cpp:228] Iteration 97300, loss = 0.000322531
I0823 12:06:37.426234 28265 solver.cpp:244]     Train net output #0: loss = 0.000322531 (* 1 = 0.000322531 loss)
I0823 12:06:37.426239 28265 sgd_solver.cpp:106] Iteration 97300, lr = 0.00019635
I0823 12:06:41.937086 28265 solver.cpp:228] Iteration 97400, loss = 0.000348889
I0823 12:06:41.937131 28265 solver.cpp:244]     Train net output #0: loss = 0.000348889 (* 1 = 0.000348889 loss)
I0823 12:06:41.937136 28265 sgd_solver.cpp:106] Iteration 97400, lr = 0.000196224
I0823 12:06:46.405113 28265 solver.cpp:337] Iteration 97500, Testing net (#0)
I0823 12:06:49.985605 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844709
I0823 12:06:49.985671 28265 solver.cpp:404]     Test net output #1: loss = 1.14455 (* 1 = 1.14455 loss)
I0823 12:06:50.000792 28265 solver.cpp:228] Iteration 97500, loss = 0.000447791
I0823 12:06:50.000840 28265 solver.cpp:244]     Train net output #0: loss = 0.000447791 (* 1 = 0.000447791 loss)
I0823 12:06:50.000852 28265 sgd_solver.cpp:106] Iteration 97500, lr = 0.000196099
I0823 12:06:54.518836 28265 solver.cpp:228] Iteration 97600, loss = 0.000345678
I0823 12:06:54.518900 28265 solver.cpp:244]     Train net output #0: loss = 0.000345678 (* 1 = 0.000345678 loss)
I0823 12:06:54.518908 28265 sgd_solver.cpp:106] Iteration 97600, lr = 0.000195974
I0823 12:06:59.030979 28265 solver.cpp:228] Iteration 97700, loss = 0.000193628
I0823 12:06:59.031041 28265 solver.cpp:244]     Train net output #0: loss = 0.000193628 (* 1 = 0.000193628 loss)
I0823 12:06:59.031047 28265 sgd_solver.cpp:106] Iteration 97700, lr = 0.000195849
I0823 12:07:03.547523 28265 solver.cpp:228] Iteration 97800, loss = 0.000351485
I0823 12:07:03.547569 28265 solver.cpp:244]     Train net output #0: loss = 0.000351485 (* 1 = 0.000351485 loss)
I0823 12:07:03.547574 28265 sgd_solver.cpp:106] Iteration 97800, lr = 0.000195725
I0823 12:07:08.063081 28265 solver.cpp:228] Iteration 97900, loss = 0.000344886
I0823 12:07:08.063127 28265 solver.cpp:244]     Train net output #0: loss = 0.000344886 (* 1 = 0.000344886 loss)
I0823 12:07:08.063133 28265 sgd_solver.cpp:106] Iteration 97900, lr = 0.0001956
I0823 12:07:12.538228 28265 solver.cpp:337] Iteration 98000, Testing net (#0)
I0823 12:07:15.763018 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844209
I0823 12:07:15.763075 28265 solver.cpp:404]     Test net output #1: loss = 1.14829 (* 1 = 1.14829 loss)
I0823 12:07:15.778363 28265 solver.cpp:228] Iteration 98000, loss = 0.000757966
I0823 12:07:15.778401 28265 solver.cpp:244]     Train net output #0: loss = 0.000757966 (* 1 = 0.000757966 loss)
I0823 12:07:15.778414 28265 sgd_solver.cpp:106] Iteration 98000, lr = 0.000195476
I0823 12:07:20.287828 28265 solver.cpp:228] Iteration 98100, loss = 0.000320924
I0823 12:07:20.287870 28265 solver.cpp:244]     Train net output #0: loss = 0.000320924 (* 1 = 0.000320924 loss)
I0823 12:07:20.287875 28265 sgd_solver.cpp:106] Iteration 98100, lr = 0.000195352
I0823 12:07:24.795128 28265 solver.cpp:228] Iteration 98200, loss = 0.000122663
I0823 12:07:24.795173 28265 solver.cpp:244]     Train net output #0: loss = 0.000122663 (* 1 = 0.000122663 loss)
I0823 12:07:24.795178 28265 sgd_solver.cpp:106] Iteration 98200, lr = 0.000195228
I0823 12:07:29.305219 28265 solver.cpp:228] Iteration 98300, loss = 0.000470212
I0823 12:07:29.305264 28265 solver.cpp:244]     Train net output #0: loss = 0.000470212 (* 1 = 0.000470212 loss)
I0823 12:07:29.305269 28265 sgd_solver.cpp:106] Iteration 98300, lr = 0.000195104
I0823 12:07:33.810739 28265 solver.cpp:228] Iteration 98400, loss = 0.000226124
I0823 12:07:33.810760 28265 solver.cpp:244]     Train net output #0: loss = 0.000226124 (* 1 = 0.000226124 loss)
I0823 12:07:33.810765 28265 sgd_solver.cpp:106] Iteration 98400, lr = 0.00019498
I0823 12:07:38.272752 28265 solver.cpp:337] Iteration 98500, Testing net (#0)
I0823 12:07:41.008538 28265 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 12:07:41.844943 28265 solver.cpp:404]     Test net output #0: accuracy = 0.84375
I0823 12:07:41.844983 28265 solver.cpp:404]     Test net output #1: loss = 1.15761 (* 1 = 1.15761 loss)
I0823 12:07:41.860371 28265 solver.cpp:228] Iteration 98500, loss = 0.000100144
I0823 12:07:41.860395 28265 solver.cpp:244]     Train net output #0: loss = 0.000100144 (* 1 = 0.000100144 loss)
I0823 12:07:41.860407 28265 sgd_solver.cpp:106] Iteration 98500, lr = 0.000194857
I0823 12:07:46.367918 28265 solver.cpp:228] Iteration 98600, loss = 0.00018755
I0823 12:07:46.367980 28265 solver.cpp:244]     Train net output #0: loss = 0.00018755 (* 1 = 0.00018755 loss)
I0823 12:07:46.367991 28265 sgd_solver.cpp:106] Iteration 98600, lr = 0.000194734
I0823 12:07:50.879240 28265 solver.cpp:228] Iteration 98700, loss = 0.000134376
I0823 12:07:50.879302 28265 solver.cpp:244]     Train net output #0: loss = 0.000134376 (* 1 = 0.000134376 loss)
I0823 12:07:50.879313 28265 sgd_solver.cpp:106] Iteration 98700, lr = 0.00019461
I0823 12:07:55.391896 28265 solver.cpp:228] Iteration 98800, loss = 0.000220866
I0823 12:07:55.391942 28265 solver.cpp:244]     Train net output #0: loss = 0.000220866 (* 1 = 0.000220866 loss)
I0823 12:07:55.391947 28265 sgd_solver.cpp:106] Iteration 98800, lr = 0.000194488
I0823 12:07:59.897694 28265 solver.cpp:228] Iteration 98900, loss = 0.000223399
I0823 12:07:59.897743 28265 solver.cpp:244]     Train net output #0: loss = 0.000223399 (* 1 = 0.000223399 loss)
I0823 12:07:59.897749 28265 sgd_solver.cpp:106] Iteration 98900, lr = 0.000194365
I0823 12:08:04.370587 28265 solver.cpp:337] Iteration 99000, Testing net (#0)
I0823 12:08:07.893556 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843876
I0823 12:08:07.893615 28265 solver.cpp:404]     Test net output #1: loss = 1.15914 (* 1 = 1.15914 loss)
I0823 12:08:07.908921 28265 solver.cpp:228] Iteration 99000, loss = 0.000636155
I0823 12:08:07.908954 28265 solver.cpp:244]     Train net output #0: loss = 0.000636155 (* 1 = 0.000636155 loss)
I0823 12:08:07.908967 28265 sgd_solver.cpp:106] Iteration 99000, lr = 0.000194242
I0823 12:08:12.422714 28265 solver.cpp:228] Iteration 99100, loss = 0.000316454
I0823 12:08:12.422760 28265 solver.cpp:244]     Train net output #0: loss = 0.000316454 (* 1 = 0.000316454 loss)
I0823 12:08:12.422768 28265 sgd_solver.cpp:106] Iteration 99100, lr = 0.00019412
I0823 12:08:16.943605 28265 solver.cpp:228] Iteration 99200, loss = 0.000177331
I0823 12:08:16.943651 28265 solver.cpp:244]     Train net output #0: loss = 0.000177331 (* 1 = 0.000177331 loss)
I0823 12:08:16.943656 28265 sgd_solver.cpp:106] Iteration 99200, lr = 0.000193998
I0823 12:08:21.455446 28265 solver.cpp:228] Iteration 99300, loss = 0.000765986
I0823 12:08:21.455466 28265 solver.cpp:244]     Train net output #0: loss = 0.000765986 (* 1 = 0.000765986 loss)
I0823 12:08:21.455471 28265 sgd_solver.cpp:106] Iteration 99300, lr = 0.000193876
I0823 12:08:25.974359 28265 solver.cpp:228] Iteration 99400, loss = 0.000237083
I0823 12:08:25.974406 28265 solver.cpp:244]     Train net output #0: loss = 0.000237083 (* 1 = 0.000237083 loss)
I0823 12:08:25.974411 28265 sgd_solver.cpp:106] Iteration 99400, lr = 0.000193754
I0823 12:08:30.441015 28265 solver.cpp:337] Iteration 99500, Testing net (#0)
I0823 12:08:33.908471 28265 solver.cpp:404]     Test net output #0: accuracy = 0.844417
I0823 12:08:33.908530 28265 solver.cpp:404]     Test net output #1: loss = 1.15748 (* 1 = 1.15748 loss)
I0823 12:08:33.923421 28265 solver.cpp:228] Iteration 99500, loss = 0.000208548
I0823 12:08:33.923455 28265 solver.cpp:244]     Train net output #0: loss = 0.000208548 (* 1 = 0.000208548 loss)
I0823 12:08:33.923468 28265 sgd_solver.cpp:106] Iteration 99500, lr = 0.000193633
I0823 12:08:38.447320 28265 solver.cpp:228] Iteration 99600, loss = 0.000296506
I0823 12:08:38.447374 28265 solver.cpp:244]     Train net output #0: loss = 0.000296506 (* 1 = 0.000296506 loss)
I0823 12:08:38.447381 28265 sgd_solver.cpp:106] Iteration 99600, lr = 0.000193511
I0823 12:08:42.952424 28265 solver.cpp:228] Iteration 99700, loss = 0.000287327
I0823 12:08:42.952471 28265 solver.cpp:244]     Train net output #0: loss = 0.000287327 (* 1 = 0.000287327 loss)
I0823 12:08:42.952476 28265 sgd_solver.cpp:106] Iteration 99700, lr = 0.00019339
I0823 12:08:47.457901 28265 solver.cpp:228] Iteration 99800, loss = 0.000451856
I0823 12:08:47.457921 28265 solver.cpp:244]     Train net output #0: loss = 0.000451856 (* 1 = 0.000451856 loss)
I0823 12:08:47.457927 28265 sgd_solver.cpp:106] Iteration 99800, lr = 0.000193269
I0823 12:08:51.968216 28265 solver.cpp:228] Iteration 99900, loss = 0.000213152
I0823 12:08:51.968266 28265 solver.cpp:244]     Train net output #0: loss = 0.000213152 (* 1 = 0.000213152 loss)
I0823 12:08:51.968271 28265 sgd_solver.cpp:106] Iteration 99900, lr = 0.000193148
I0823 12:08:56.429864 28265 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_100000.caffemodel
I0823 12:08:56.914302 28265 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.00074_iter_100000.solverstate
I0823 12:08:57.074389 28265 solver.cpp:337] Iteration 100000, Testing net (#0)
I0823 12:09:00.642966 28265 solver.cpp:404]     Test net output #0: accuracy = 0.843959
I0823 12:09:00.643041 28265 solver.cpp:404]     Test net output #1: loss = 1.15997 (* 1 = 1.15997 loss)
I0823 12:09:00.658138 28265 solver.cpp:228] Iteration 100000, loss = 0.000466741
I0823 12:09:00.658179 28265 solver.cpp:244]     Train net output #0: loss = 0.000466741 (* 1 = 0.000466741 loss)
I0823 12:09:00.658196 28265 sgd_solver.cpp:106] Iteration 100000, lr = 0.000193027
nets/person_vs_background_vs_random_alex_net/solver.prototxt
