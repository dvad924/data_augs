WARNING: Logging before InitGoogleLogging() is written to STDERR
I0822 11:25:43.088631 31776 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 10000
snapshot_prefix: "models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006"
solver_mode: GPU
net: "nets/person_vs_background_vs_random_alex_net/trainval.prototxt"
I0822 11:25:43.088752 31776 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random_alex_net/trainval.prototxt
I0822 11:25:43.089054 31776 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0822 11:25:43.089073 31776 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0822 11:25:43.089213 31776 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 11:25:43.089289 31776 layer_factory.hpp:77] Creating layer mnist
I0822 11:25:43.089821 31776 net.cpp:100] Creating Layer mnist
I0822 11:25:43.089834 31776 net.cpp:408] mnist -> data
I0822 11:25:43.089913 31776 net.cpp:408] mnist -> label
I0822 11:25:43.089998 31776 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0822 11:25:43.091389 31788 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0822 11:25:43.125095 31776 data_layer.cpp:41] output data size: 128,3,128,128
I0822 11:25:43.195036 31776 net.cpp:150] Setting up mnist
I0822 11:25:43.195075 31776 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0822 11:25:43.195082 31776 net.cpp:157] Top shape: 128 (128)
I0822 11:25:43.195086 31776 net.cpp:165] Memory required for data: 25166336
I0822 11:25:43.195093 31776 layer_factory.hpp:77] Creating layer conv1
I0822 11:25:43.195122 31776 net.cpp:100] Creating Layer conv1
I0822 11:25:43.195127 31776 net.cpp:434] conv1 <- data
I0822 11:25:43.195138 31776 net.cpp:408] conv1 -> conv1
I0822 11:25:43.507895 31776 net.cpp:150] Setting up conv1
I0822 11:25:43.507928 31776 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0822 11:25:43.507932 31776 net.cpp:165] Memory required for data: 69403136
I0822 11:25:43.507949 31776 layer_factory.hpp:77] Creating layer relu1
I0822 11:25:43.507964 31776 net.cpp:100] Creating Layer relu1
I0822 11:25:43.507968 31776 net.cpp:434] relu1 <- conv1
I0822 11:25:43.507975 31776 net.cpp:395] relu1 -> conv1 (in-place)
I0822 11:25:43.508174 31776 net.cpp:150] Setting up relu1
I0822 11:25:43.508186 31776 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0822 11:25:43.508189 31776 net.cpp:165] Memory required for data: 113639936
I0822 11:25:43.508193 31776 layer_factory.hpp:77] Creating layer norm1
I0822 11:25:43.508201 31776 net.cpp:100] Creating Layer norm1
I0822 11:25:43.508204 31776 net.cpp:434] norm1 <- conv1
I0822 11:25:43.508209 31776 net.cpp:408] norm1 -> norm1
I0822 11:25:43.508783 31776 net.cpp:150] Setting up norm1
I0822 11:25:43.508798 31776 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0822 11:25:43.508801 31776 net.cpp:165] Memory required for data: 157876736
I0822 11:25:43.508805 31776 layer_factory.hpp:77] Creating layer pool1
I0822 11:25:43.508813 31776 net.cpp:100] Creating Layer pool1
I0822 11:25:43.508817 31776 net.cpp:434] pool1 <- norm1
I0822 11:25:43.508822 31776 net.cpp:408] pool1 -> pool1
I0822 11:25:43.508884 31776 net.cpp:150] Setting up pool1
I0822 11:25:43.508893 31776 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0822 11:25:43.508898 31776 net.cpp:165] Memory required for data: 168935936
I0822 11:25:43.508900 31776 layer_factory.hpp:77] Creating layer conv2
I0822 11:25:43.508913 31776 net.cpp:100] Creating Layer conv2
I0822 11:25:43.508919 31776 net.cpp:434] conv2 <- pool1
I0822 11:25:43.508924 31776 net.cpp:408] conv2 -> conv2
I0822 11:25:43.515630 31776 net.cpp:150] Setting up conv2
I0822 11:25:43.515650 31776 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0822 11:25:43.515653 31776 net.cpp:165] Memory required for data: 198427136
I0822 11:25:43.515663 31776 layer_factory.hpp:77] Creating layer relu2
I0822 11:25:43.515669 31776 net.cpp:100] Creating Layer relu2
I0822 11:25:43.515672 31776 net.cpp:434] relu2 <- conv2
I0822 11:25:43.515677 31776 net.cpp:395] relu2 -> conv2 (in-place)
I0822 11:25:43.516224 31776 net.cpp:150] Setting up relu2
I0822 11:25:43.516240 31776 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0822 11:25:43.516243 31776 net.cpp:165] Memory required for data: 227918336
I0822 11:25:43.516247 31776 layer_factory.hpp:77] Creating layer norm2
I0822 11:25:43.516253 31776 net.cpp:100] Creating Layer norm2
I0822 11:25:43.516257 31776 net.cpp:434] norm2 <- conv2
I0822 11:25:43.516263 31776 net.cpp:408] norm2 -> norm2
I0822 11:25:43.516492 31776 net.cpp:150] Setting up norm2
I0822 11:25:43.516505 31776 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0822 11:25:43.516507 31776 net.cpp:165] Memory required for data: 257409536
I0822 11:25:43.516510 31776 layer_factory.hpp:77] Creating layer pool2
I0822 11:25:43.516518 31776 net.cpp:100] Creating Layer pool2
I0822 11:25:43.516521 31776 net.cpp:434] pool2 <- norm2
I0822 11:25:43.516526 31776 net.cpp:408] pool2 -> pool2
I0822 11:25:43.516582 31776 net.cpp:150] Setting up pool2
I0822 11:25:43.516589 31776 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0822 11:25:43.516592 31776 net.cpp:165] Memory required for data: 263832064
I0822 11:25:43.516595 31776 layer_factory.hpp:77] Creating layer conv3
I0822 11:25:43.516604 31776 net.cpp:100] Creating Layer conv3
I0822 11:25:43.516607 31776 net.cpp:434] conv3 <- pool2
I0822 11:25:43.516613 31776 net.cpp:408] conv3 -> conv3
I0822 11:25:43.530642 31776 net.cpp:150] Setting up conv3
I0822 11:25:43.530658 31776 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0822 11:25:43.530661 31776 net.cpp:165] Memory required for data: 273465856
I0822 11:25:43.530670 31776 layer_factory.hpp:77] Creating layer relu3
I0822 11:25:43.530676 31776 net.cpp:100] Creating Layer relu3
I0822 11:25:43.530680 31776 net.cpp:434] relu3 <- conv3
I0822 11:25:43.530688 31776 net.cpp:395] relu3 -> conv3 (in-place)
I0822 11:25:43.530891 31776 net.cpp:150] Setting up relu3
I0822 11:25:43.530903 31776 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0822 11:25:43.530905 31776 net.cpp:165] Memory required for data: 283099648
I0822 11:25:43.530908 31776 layer_factory.hpp:77] Creating layer conv4
I0822 11:25:43.530922 31776 net.cpp:100] Creating Layer conv4
I0822 11:25:43.530927 31776 net.cpp:434] conv4 <- conv3
I0822 11:25:43.530935 31776 net.cpp:408] conv4 -> conv4
I0822 11:25:43.542940 31776 net.cpp:150] Setting up conv4
I0822 11:25:43.542956 31776 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0822 11:25:43.542959 31776 net.cpp:165] Memory required for data: 292733440
I0822 11:25:43.542966 31776 layer_factory.hpp:77] Creating layer relu4
I0822 11:25:43.542973 31776 net.cpp:100] Creating Layer relu4
I0822 11:25:43.542975 31776 net.cpp:434] relu4 <- conv4
I0822 11:25:43.542982 31776 net.cpp:395] relu4 -> conv4 (in-place)
I0822 11:25:43.543192 31776 net.cpp:150] Setting up relu4
I0822 11:25:43.543205 31776 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0822 11:25:43.543206 31776 net.cpp:165] Memory required for data: 302367232
I0822 11:25:43.543210 31776 layer_factory.hpp:77] Creating layer conv5
I0822 11:25:43.543221 31776 net.cpp:100] Creating Layer conv5
I0822 11:25:43.543225 31776 net.cpp:434] conv5 <- conv4
I0822 11:25:43.543233 31776 net.cpp:408] conv5 -> conv5
I0822 11:25:43.552472 31776 net.cpp:150] Setting up conv5
I0822 11:25:43.552490 31776 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0822 11:25:43.552495 31776 net.cpp:165] Memory required for data: 308789760
I0822 11:25:43.552503 31776 layer_factory.hpp:77] Creating layer relu5
I0822 11:25:43.552510 31776 net.cpp:100] Creating Layer relu5
I0822 11:25:43.552513 31776 net.cpp:434] relu5 <- conv5
I0822 11:25:43.552520 31776 net.cpp:395] relu5 -> conv5 (in-place)
I0822 11:25:43.552732 31776 net.cpp:150] Setting up relu5
I0822 11:25:43.552744 31776 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0822 11:25:43.552747 31776 net.cpp:165] Memory required for data: 315212288
I0822 11:25:43.552749 31776 layer_factory.hpp:77] Creating layer pool5
I0822 11:25:43.552757 31776 net.cpp:100] Creating Layer pool5
I0822 11:25:43.552762 31776 net.cpp:434] pool5 <- conv5
I0822 11:25:43.552767 31776 net.cpp:408] pool5 -> pool5
I0822 11:25:43.552839 31776 net.cpp:150] Setting up pool5
I0822 11:25:43.552847 31776 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0822 11:25:43.552850 31776 net.cpp:165] Memory required for data: 316391936
I0822 11:25:43.552853 31776 layer_factory.hpp:77] Creating layer fc6
I0822 11:25:43.552865 31776 net.cpp:100] Creating Layer fc6
I0822 11:25:43.552870 31776 net.cpp:434] fc6 <- pool5
I0822 11:25:43.552876 31776 net.cpp:408] fc6 -> fc6
I0822 11:25:43.686503 31776 net.cpp:150] Setting up fc6
I0822 11:25:43.686543 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.686547 31776 net.cpp:165] Memory required for data: 318489088
I0822 11:25:43.686561 31776 layer_factory.hpp:77] Creating layer relu6
I0822 11:25:43.686574 31776 net.cpp:100] Creating Layer relu6
I0822 11:25:43.686579 31776 net.cpp:434] relu6 <- fc6
I0822 11:25:43.686589 31776 net.cpp:395] relu6 -> fc6 (in-place)
I0822 11:25:43.687253 31776 net.cpp:150] Setting up relu6
I0822 11:25:43.687268 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.687271 31776 net.cpp:165] Memory required for data: 320586240
I0822 11:25:43.687274 31776 layer_factory.hpp:77] Creating layer drop6
I0822 11:25:43.687285 31776 net.cpp:100] Creating Layer drop6
I0822 11:25:43.687288 31776 net.cpp:434] drop6 <- fc6
I0822 11:25:43.687294 31776 net.cpp:395] drop6 -> fc6 (in-place)
I0822 11:25:43.687332 31776 net.cpp:150] Setting up drop6
I0822 11:25:43.687341 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.687343 31776 net.cpp:165] Memory required for data: 322683392
I0822 11:25:43.687346 31776 layer_factory.hpp:77] Creating layer fc7
I0822 11:25:43.687356 31776 net.cpp:100] Creating Layer fc7
I0822 11:25:43.687360 31776 net.cpp:434] fc7 <- fc6
I0822 11:25:43.687366 31776 net.cpp:408] fc7 -> fc7
I0822 11:25:43.921448 31776 net.cpp:150] Setting up fc7
I0822 11:25:43.921495 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.921499 31776 net.cpp:165] Memory required for data: 324780544
I0822 11:25:43.921512 31776 layer_factory.hpp:77] Creating layer relu7
I0822 11:25:43.921527 31776 net.cpp:100] Creating Layer relu7
I0822 11:25:43.921531 31776 net.cpp:434] relu7 <- fc7
I0822 11:25:43.921540 31776 net.cpp:395] relu7 -> fc7 (in-place)
I0822 11:25:43.921833 31776 net.cpp:150] Setting up relu7
I0822 11:25:43.921844 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.921846 31776 net.cpp:165] Memory required for data: 326877696
I0822 11:25:43.921849 31776 layer_factory.hpp:77] Creating layer drop7
I0822 11:25:43.921857 31776 net.cpp:100] Creating Layer drop7
I0822 11:25:43.921860 31776 net.cpp:434] drop7 <- fc7
I0822 11:25:43.921867 31776 net.cpp:395] drop7 -> fc7 (in-place)
I0822 11:25:43.921902 31776 net.cpp:150] Setting up drop7
I0822 11:25:43.921911 31776 net.cpp:157] Top shape: 128 4096 (524288)
I0822 11:25:43.921913 31776 net.cpp:165] Memory required for data: 328974848
I0822 11:25:43.921916 31776 layer_factory.hpp:77] Creating layer fc8
I0822 11:25:43.921926 31776 net.cpp:100] Creating Layer fc8
I0822 11:25:43.921928 31776 net.cpp:434] fc8 <- fc7
I0822 11:25:43.921934 31776 net.cpp:408] fc8 -> fc8
I0822 11:25:43.923923 31776 net.cpp:150] Setting up fc8
I0822 11:25:43.923938 31776 net.cpp:157] Top shape: 128 3 (384)
I0822 11:25:43.923941 31776 net.cpp:165] Memory required for data: 328976384
I0822 11:25:43.923949 31776 layer_factory.hpp:77] Creating layer loss
I0822 11:25:43.923956 31776 net.cpp:100] Creating Layer loss
I0822 11:25:43.923960 31776 net.cpp:434] loss <- fc8
I0822 11:25:43.923964 31776 net.cpp:434] loss <- label
I0822 11:25:43.923969 31776 net.cpp:408] loss -> loss
I0822 11:25:43.923979 31776 layer_factory.hpp:77] Creating layer loss
I0822 11:25:43.924355 31776 net.cpp:150] Setting up loss
I0822 11:25:43.924367 31776 net.cpp:157] Top shape: (1)
I0822 11:25:43.924371 31776 net.cpp:160]     with loss weight 1
I0822 11:25:43.924388 31776 net.cpp:165] Memory required for data: 328976388
I0822 11:25:43.924392 31776 net.cpp:226] loss needs backward computation.
I0822 11:25:43.924398 31776 net.cpp:226] fc8 needs backward computation.
I0822 11:25:43.924402 31776 net.cpp:226] drop7 needs backward computation.
I0822 11:25:43.924406 31776 net.cpp:226] relu7 needs backward computation.
I0822 11:25:43.924408 31776 net.cpp:226] fc7 needs backward computation.
I0822 11:25:43.924412 31776 net.cpp:226] drop6 needs backward computation.
I0822 11:25:43.924414 31776 net.cpp:226] relu6 needs backward computation.
I0822 11:25:43.924417 31776 net.cpp:226] fc6 needs backward computation.
I0822 11:25:43.924422 31776 net.cpp:226] pool5 needs backward computation.
I0822 11:25:43.924424 31776 net.cpp:226] relu5 needs backward computation.
I0822 11:25:43.924427 31776 net.cpp:226] conv5 needs backward computation.
I0822 11:25:43.924432 31776 net.cpp:226] relu4 needs backward computation.
I0822 11:25:43.924434 31776 net.cpp:226] conv4 needs backward computation.
I0822 11:25:43.924437 31776 net.cpp:226] relu3 needs backward computation.
I0822 11:25:43.924440 31776 net.cpp:226] conv3 needs backward computation.
I0822 11:25:43.924443 31776 net.cpp:226] pool2 needs backward computation.
I0822 11:25:43.924448 31776 net.cpp:226] norm2 needs backward computation.
I0822 11:25:43.924450 31776 net.cpp:226] relu2 needs backward computation.
I0822 11:25:43.924453 31776 net.cpp:226] conv2 needs backward computation.
I0822 11:25:43.924456 31776 net.cpp:226] pool1 needs backward computation.
I0822 11:25:43.924459 31776 net.cpp:226] norm1 needs backward computation.
I0822 11:25:43.924463 31776 net.cpp:226] relu1 needs backward computation.
I0822 11:25:43.924466 31776 net.cpp:226] conv1 needs backward computation.
I0822 11:25:43.924470 31776 net.cpp:228] mnist does not need backward computation.
I0822 11:25:43.924474 31776 net.cpp:270] This network produces output loss
I0822 11:25:43.924490 31776 net.cpp:283] Network initialization done.
I0822 11:25:43.924847 31776 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random_alex_net/trainval.prototxt
I0822 11:25:43.924890 31776 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0822 11:25:43.925060 31776 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 11:25:43.925178 31776 layer_factory.hpp:77] Creating layer mnist
I0822 11:25:43.925307 31776 net.cpp:100] Creating Layer mnist
I0822 11:25:43.925319 31776 net.cpp:408] mnist -> data
I0822 11:25:43.925328 31776 net.cpp:408] mnist -> label
I0822 11:25:43.925335 31776 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0822 11:25:43.926892 31790 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0822 11:25:43.927315 31776 data_layer.cpp:41] output data size: 100,3,128,128
I0822 11:25:43.988214 31776 net.cpp:150] Setting up mnist
I0822 11:25:43.988253 31776 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0822 11:25:43.988261 31776 net.cpp:157] Top shape: 100 (100)
I0822 11:25:43.988265 31776 net.cpp:165] Memory required for data: 19661200
I0822 11:25:43.988275 31776 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0822 11:25:43.988293 31776 net.cpp:100] Creating Layer label_mnist_1_split
I0822 11:25:43.988299 31776 net.cpp:434] label_mnist_1_split <- label
I0822 11:25:43.988311 31776 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I0822 11:25:43.988327 31776 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I0822 11:25:43.988631 31776 net.cpp:150] Setting up label_mnist_1_split
I0822 11:25:43.988662 31776 net.cpp:157] Top shape: 100 (100)
I0822 11:25:43.988669 31776 net.cpp:157] Top shape: 100 (100)
I0822 11:25:43.988674 31776 net.cpp:165] Memory required for data: 19662000
I0822 11:25:43.988680 31776 layer_factory.hpp:77] Creating layer conv1
I0822 11:25:43.988706 31776 net.cpp:100] Creating Layer conv1
I0822 11:25:43.988714 31776 net.cpp:434] conv1 <- data
I0822 11:25:43.988734 31776 net.cpp:408] conv1 -> conv1
I0822 11:25:43.994019 31776 net.cpp:150] Setting up conv1
I0822 11:25:43.994053 31776 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 11:25:43.994060 31776 net.cpp:165] Memory required for data: 54222000
I0822 11:25:43.994081 31776 layer_factory.hpp:77] Creating layer relu1
I0822 11:25:43.994097 31776 net.cpp:100] Creating Layer relu1
I0822 11:25:43.994105 31776 net.cpp:434] relu1 <- conv1
I0822 11:25:43.994115 31776 net.cpp:395] relu1 -> conv1 (in-place)
I0822 11:25:43.994494 31776 net.cpp:150] Setting up relu1
I0822 11:25:43.994513 31776 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 11:25:43.994518 31776 net.cpp:165] Memory required for data: 88782000
I0822 11:25:43.994524 31776 layer_factory.hpp:77] Creating layer norm1
I0822 11:25:43.994541 31776 net.cpp:100] Creating Layer norm1
I0822 11:25:43.994547 31776 net.cpp:434] norm1 <- conv1
I0822 11:25:43.994559 31776 net.cpp:408] norm1 -> norm1
I0822 11:25:43.995723 31776 net.cpp:150] Setting up norm1
I0822 11:25:43.995751 31776 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 11:25:43.995759 31776 net.cpp:165] Memory required for data: 123342000
I0822 11:25:43.995764 31776 layer_factory.hpp:77] Creating layer pool1
I0822 11:25:43.995779 31776 net.cpp:100] Creating Layer pool1
I0822 11:25:43.995784 31776 net.cpp:434] pool1 <- norm1
I0822 11:25:43.995796 31776 net.cpp:408] pool1 -> pool1
I0822 11:25:43.995924 31776 net.cpp:150] Setting up pool1
I0822 11:25:43.995939 31776 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0822 11:25:43.995944 31776 net.cpp:165] Memory required for data: 131982000
I0822 11:25:43.995949 31776 layer_factory.hpp:77] Creating layer conv2
I0822 11:25:43.995970 31776 net.cpp:100] Creating Layer conv2
I0822 11:25:43.995978 31776 net.cpp:434] conv2 <- pool1
I0822 11:25:43.995991 31776 net.cpp:408] conv2 -> conv2
I0822 11:25:44.009045 31776 net.cpp:150] Setting up conv2
I0822 11:25:44.009080 31776 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 11:25:44.009088 31776 net.cpp:165] Memory required for data: 155022000
I0822 11:25:44.009106 31776 layer_factory.hpp:77] Creating layer relu2
I0822 11:25:44.009121 31776 net.cpp:100] Creating Layer relu2
I0822 11:25:44.009129 31776 net.cpp:434] relu2 <- conv2
I0822 11:25:44.009138 31776 net.cpp:395] relu2 -> conv2 (in-place)
I0822 11:25:44.010169 31776 net.cpp:150] Setting up relu2
I0822 11:25:44.010195 31776 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 11:25:44.010200 31776 net.cpp:165] Memory required for data: 178062000
I0822 11:25:44.010205 31776 layer_factory.hpp:77] Creating layer norm2
I0822 11:25:44.010226 31776 net.cpp:100] Creating Layer norm2
I0822 11:25:44.010231 31776 net.cpp:434] norm2 <- conv2
I0822 11:25:44.010242 31776 net.cpp:408] norm2 -> norm2
I0822 11:25:44.010730 31776 net.cpp:150] Setting up norm2
I0822 11:25:44.010751 31776 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 11:25:44.010761 31776 net.cpp:165] Memory required for data: 201102000
I0822 11:25:44.010766 31776 layer_factory.hpp:77] Creating layer pool2
I0822 11:25:44.010782 31776 net.cpp:100] Creating Layer pool2
I0822 11:25:44.010787 31776 net.cpp:434] pool2 <- norm2
I0822 11:25:44.010797 31776 net.cpp:408] pool2 -> pool2
I0822 11:25:44.010911 31776 net.cpp:150] Setting up pool2
I0822 11:25:44.010926 31776 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 11:25:44.010931 31776 net.cpp:165] Memory required for data: 206119600
I0822 11:25:44.010936 31776 layer_factory.hpp:77] Creating layer conv3
I0822 11:25:44.010959 31776 net.cpp:100] Creating Layer conv3
I0822 11:25:44.010967 31776 net.cpp:434] conv3 <- pool2
I0822 11:25:44.010978 31776 net.cpp:408] conv3 -> conv3
I0822 11:25:44.034536 31776 net.cpp:150] Setting up conv3
I0822 11:25:44.034580 31776 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 11:25:44.034585 31776 net.cpp:165] Memory required for data: 213646000
I0822 11:25:44.034610 31776 layer_factory.hpp:77] Creating layer relu3
I0822 11:25:44.034636 31776 net.cpp:100] Creating Layer relu3
I0822 11:25:44.034644 31776 net.cpp:434] relu3 <- conv3
I0822 11:25:44.034656 31776 net.cpp:395] relu3 -> conv3 (in-place)
I0822 11:25:44.035007 31776 net.cpp:150] Setting up relu3
I0822 11:25:44.035028 31776 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 11:25:44.035032 31776 net.cpp:165] Memory required for data: 221172400
I0822 11:25:44.035037 31776 layer_factory.hpp:77] Creating layer conv4
I0822 11:25:44.035059 31776 net.cpp:100] Creating Layer conv4
I0822 11:25:44.035065 31776 net.cpp:434] conv4 <- conv3
I0822 11:25:44.035079 31776 net.cpp:408] conv4 -> conv4
I0822 11:25:44.053159 31776 net.cpp:150] Setting up conv4
I0822 11:25:44.053200 31776 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 11:25:44.053205 31776 net.cpp:165] Memory required for data: 228698800
I0822 11:25:44.053225 31776 layer_factory.hpp:77] Creating layer relu4
I0822 11:25:44.053241 31776 net.cpp:100] Creating Layer relu4
I0822 11:25:44.053248 31776 net.cpp:434] relu4 <- conv4
I0822 11:25:44.053258 31776 net.cpp:395] relu4 -> conv4 (in-place)
I0822 11:25:44.054116 31776 net.cpp:150] Setting up relu4
I0822 11:25:44.054136 31776 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 11:25:44.054141 31776 net.cpp:165] Memory required for data: 236225200
I0822 11:25:44.054147 31776 layer_factory.hpp:77] Creating layer conv5
I0822 11:25:44.054167 31776 net.cpp:100] Creating Layer conv5
I0822 11:25:44.054173 31776 net.cpp:434] conv5 <- conv4
I0822 11:25:44.054186 31776 net.cpp:408] conv5 -> conv5
I0822 11:25:44.067008 31776 net.cpp:150] Setting up conv5
I0822 11:25:44.067031 31776 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 11:25:44.067035 31776 net.cpp:165] Memory required for data: 241242800
I0822 11:25:44.067052 31776 layer_factory.hpp:77] Creating layer relu5
I0822 11:25:44.067065 31776 net.cpp:100] Creating Layer relu5
I0822 11:25:44.067070 31776 net.cpp:434] relu5 <- conv5
I0822 11:25:44.067076 31776 net.cpp:395] relu5 -> conv5 (in-place)
I0822 11:25:44.067363 31776 net.cpp:150] Setting up relu5
I0822 11:25:44.067378 31776 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 11:25:44.067381 31776 net.cpp:165] Memory required for data: 246260400
I0822 11:25:44.067385 31776 layer_factory.hpp:77] Creating layer pool5
I0822 11:25:44.067401 31776 net.cpp:100] Creating Layer pool5
I0822 11:25:44.067406 31776 net.cpp:434] pool5 <- conv5
I0822 11:25:44.067414 31776 net.cpp:408] pool5 -> pool5
I0822 11:25:44.067530 31776 net.cpp:150] Setting up pool5
I0822 11:25:44.067541 31776 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0822 11:25:44.067545 31776 net.cpp:165] Memory required for data: 247182000
I0822 11:25:44.067548 31776 layer_factory.hpp:77] Creating layer fc6
I0822 11:25:44.067564 31776 net.cpp:100] Creating Layer fc6
I0822 11:25:44.067569 31776 net.cpp:434] fc6 <- pool5
I0822 11:25:44.067576 31776 net.cpp:408] fc6 -> fc6
I0822 11:25:44.207679 31776 net.cpp:150] Setting up fc6
I0822 11:25:44.207722 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.207726 31776 net.cpp:165] Memory required for data: 248820400
I0822 11:25:44.207738 31776 layer_factory.hpp:77] Creating layer relu6
I0822 11:25:44.207752 31776 net.cpp:100] Creating Layer relu6
I0822 11:25:44.207757 31776 net.cpp:434] relu6 <- fc6
I0822 11:25:44.207765 31776 net.cpp:395] relu6 -> fc6 (in-place)
I0822 11:25:44.208063 31776 net.cpp:150] Setting up relu6
I0822 11:25:44.208075 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.208076 31776 net.cpp:165] Memory required for data: 250458800
I0822 11:25:44.208079 31776 layer_factory.hpp:77] Creating layer drop6
I0822 11:25:44.208087 31776 net.cpp:100] Creating Layer drop6
I0822 11:25:44.208091 31776 net.cpp:434] drop6 <- fc6
I0822 11:25:44.208099 31776 net.cpp:395] drop6 -> fc6 (in-place)
I0822 11:25:44.208159 31776 net.cpp:150] Setting up drop6
I0822 11:25:44.208168 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.208170 31776 net.cpp:165] Memory required for data: 252097200
I0822 11:25:44.208173 31776 layer_factory.hpp:77] Creating layer fc7
I0822 11:25:44.208184 31776 net.cpp:100] Creating Layer fc7
I0822 11:25:44.208187 31776 net.cpp:434] fc7 <- fc6
I0822 11:25:44.208194 31776 net.cpp:408] fc7 -> fc7
I0822 11:25:44.442317 31776 net.cpp:150] Setting up fc7
I0822 11:25:44.442365 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.442369 31776 net.cpp:165] Memory required for data: 253735600
I0822 11:25:44.442381 31776 layer_factory.hpp:77] Creating layer relu7
I0822 11:25:44.442396 31776 net.cpp:100] Creating Layer relu7
I0822 11:25:44.442402 31776 net.cpp:434] relu7 <- fc7
I0822 11:25:44.442410 31776 net.cpp:395] relu7 -> fc7 (in-place)
I0822 11:25:44.443271 31776 net.cpp:150] Setting up relu7
I0822 11:25:44.443289 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.443292 31776 net.cpp:165] Memory required for data: 255374000
I0822 11:25:44.443295 31776 layer_factory.hpp:77] Creating layer drop7
I0822 11:25:44.443305 31776 net.cpp:100] Creating Layer drop7
I0822 11:25:44.443308 31776 net.cpp:434] drop7 <- fc7
I0822 11:25:44.443315 31776 net.cpp:395] drop7 -> fc7 (in-place)
I0822 11:25:44.443373 31776 net.cpp:150] Setting up drop7
I0822 11:25:44.443382 31776 net.cpp:157] Top shape: 100 4096 (409600)
I0822 11:25:44.443385 31776 net.cpp:165] Memory required for data: 257012400
I0822 11:25:44.443388 31776 layer_factory.hpp:77] Creating layer fc8
I0822 11:25:44.443400 31776 net.cpp:100] Creating Layer fc8
I0822 11:25:44.443403 31776 net.cpp:434] fc8 <- fc7
I0822 11:25:44.443408 31776 net.cpp:408] fc8 -> fc8
I0822 11:25:44.443779 31776 net.cpp:150] Setting up fc8
I0822 11:25:44.443789 31776 net.cpp:157] Top shape: 100 3 (300)
I0822 11:25:44.443792 31776 net.cpp:165] Memory required for data: 257013600
I0822 11:25:44.443799 31776 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0822 11:25:44.443806 31776 net.cpp:100] Creating Layer fc8_fc8_0_split
I0822 11:25:44.443809 31776 net.cpp:434] fc8_fc8_0_split <- fc8
I0822 11:25:44.443814 31776 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0822 11:25:44.443821 31776 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0822 11:25:44.443891 31776 net.cpp:150] Setting up fc8_fc8_0_split
I0822 11:25:44.443898 31776 net.cpp:157] Top shape: 100 3 (300)
I0822 11:25:44.443902 31776 net.cpp:157] Top shape: 100 3 (300)
I0822 11:25:44.443904 31776 net.cpp:165] Memory required for data: 257016000
I0822 11:25:44.443907 31776 layer_factory.hpp:77] Creating layer accuracy
I0822 11:25:44.443917 31776 net.cpp:100] Creating Layer accuracy
I0822 11:25:44.443920 31776 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0822 11:25:44.443924 31776 net.cpp:434] accuracy <- label_mnist_1_split_0
I0822 11:25:44.443929 31776 net.cpp:408] accuracy -> accuracy
I0822 11:25:44.443939 31776 net.cpp:150] Setting up accuracy
I0822 11:25:44.443944 31776 net.cpp:157] Top shape: (1)
I0822 11:25:44.443946 31776 net.cpp:165] Memory required for data: 257016004
I0822 11:25:44.443949 31776 layer_factory.hpp:77] Creating layer loss
I0822 11:25:44.443954 31776 net.cpp:100] Creating Layer loss
I0822 11:25:44.443958 31776 net.cpp:434] loss <- fc8_fc8_0_split_1
I0822 11:25:44.443961 31776 net.cpp:434] loss <- label_mnist_1_split_1
I0822 11:25:44.443966 31776 net.cpp:408] loss -> loss
I0822 11:25:44.443974 31776 layer_factory.hpp:77] Creating layer loss
I0822 11:25:44.444367 31776 net.cpp:150] Setting up loss
I0822 11:25:44.444380 31776 net.cpp:157] Top shape: (1)
I0822 11:25:44.444382 31776 net.cpp:160]     with loss weight 1
I0822 11:25:44.444394 31776 net.cpp:165] Memory required for data: 257016008
I0822 11:25:44.444397 31776 net.cpp:226] loss needs backward computation.
I0822 11:25:44.444402 31776 net.cpp:228] accuracy does not need backward computation.
I0822 11:25:44.444407 31776 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0822 11:25:44.444411 31776 net.cpp:226] fc8 needs backward computation.
I0822 11:25:44.444413 31776 net.cpp:226] drop7 needs backward computation.
I0822 11:25:44.444416 31776 net.cpp:226] relu7 needs backward computation.
I0822 11:25:44.444418 31776 net.cpp:226] fc7 needs backward computation.
I0822 11:25:44.444422 31776 net.cpp:226] drop6 needs backward computation.
I0822 11:25:44.444424 31776 net.cpp:226] relu6 needs backward computation.
I0822 11:25:44.444427 31776 net.cpp:226] fc6 needs backward computation.
I0822 11:25:44.444432 31776 net.cpp:226] pool5 needs backward computation.
I0822 11:25:44.444434 31776 net.cpp:226] relu5 needs backward computation.
I0822 11:25:44.444437 31776 net.cpp:226] conv5 needs backward computation.
I0822 11:25:44.444442 31776 net.cpp:226] relu4 needs backward computation.
I0822 11:25:44.444444 31776 net.cpp:226] conv4 needs backward computation.
I0822 11:25:44.444448 31776 net.cpp:226] relu3 needs backward computation.
I0822 11:25:44.444452 31776 net.cpp:226] conv3 needs backward computation.
I0822 11:25:44.444454 31776 net.cpp:226] pool2 needs backward computation.
I0822 11:25:44.444458 31776 net.cpp:226] norm2 needs backward computation.
I0822 11:25:44.444460 31776 net.cpp:226] relu2 needs backward computation.
I0822 11:25:44.444464 31776 net.cpp:226] conv2 needs backward computation.
I0822 11:25:44.444468 31776 net.cpp:226] pool1 needs backward computation.
I0822 11:25:44.444473 31776 net.cpp:226] norm1 needs backward computation.
I0822 11:25:44.444476 31776 net.cpp:226] relu1 needs backward computation.
I0822 11:25:44.444479 31776 net.cpp:226] conv1 needs backward computation.
I0822 11:25:44.444483 31776 net.cpp:228] label_mnist_1_split does not need backward computation.
I0822 11:25:44.444488 31776 net.cpp:228] mnist does not need backward computation.
I0822 11:25:44.444490 31776 net.cpp:270] This network produces output accuracy
I0822 11:25:44.444494 31776 net.cpp:270] This network produces output loss
I0822 11:25:44.444514 31776 net.cpp:283] Network initialization done.
I0822 11:25:44.444612 31776 solver.cpp:60] Solver scaffolding done.
I0822 11:25:44.448909 31776 solver.cpp:337] Iteration 0, Testing net (#0)
I0822 11:25:44.554591 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:25:47.692991 31776 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0822 11:25:47.693028 31776 solver.cpp:404]     Test net output #1: loss = 1.08992 (* 1 = 1.08992 loss)
I0822 11:25:47.732054 31776 solver.cpp:228] Iteration 0, loss = 1.09277
I0822 11:25:47.732074 31776 solver.cpp:244]     Train net output #0: loss = 1.09277 (* 1 = 1.09277 loss)
I0822 11:25:47.732084 31776 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0822 11:25:52.205724 31776 solver.cpp:228] Iteration 100, loss = 1.11122
I0822 11:25:52.205752 31776 solver.cpp:244]     Train net output #0: loss = 1.11122 (* 1 = 1.11122 loss)
I0822 11:25:52.205759 31776 sgd_solver.cpp:106] Iteration 100, lr = 0.000996266
I0822 11:25:56.699558 31776 solver.cpp:228] Iteration 200, loss = 1.09836
I0822 11:25:56.699578 31776 solver.cpp:244]     Train net output #0: loss = 1.09836 (* 1 = 1.09836 loss)
I0822 11:25:56.699582 31776 sgd_solver.cpp:106] Iteration 200, lr = 0.000992565
I0822 11:26:01.196045 31776 solver.cpp:228] Iteration 300, loss = 1.10436
I0822 11:26:01.196061 31776 solver.cpp:244]     Train net output #0: loss = 1.10436 (* 1 = 1.10436 loss)
I0822 11:26:01.196066 31776 sgd_solver.cpp:106] Iteration 300, lr = 0.000988896
I0822 11:26:05.695467 31776 solver.cpp:228] Iteration 400, loss = 1.10035
I0822 11:26:05.695483 31776 solver.cpp:244]     Train net output #0: loss = 1.10035 (* 1 = 1.10035 loss)
I0822 11:26:05.695488 31776 sgd_solver.cpp:106] Iteration 400, lr = 0.000985258
I0822 11:26:10.152349 31776 solver.cpp:337] Iteration 500, Testing net (#0)
I0822 11:26:13.572024 31776 solver.cpp:404]     Test net output #0: accuracy = 0.579292
I0822 11:26:13.572083 31776 solver.cpp:404]     Test net output #1: loss = 1.09438 (* 1 = 1.09438 loss)
I0822 11:26:13.587528 31776 solver.cpp:228] Iteration 500, loss = 1.09521
I0822 11:26:13.587551 31776 solver.cpp:244]     Train net output #0: loss = 1.09521 (* 1 = 1.09521 loss)
I0822 11:26:13.587566 31776 sgd_solver.cpp:106] Iteration 500, lr = 0.000981651
I0822 11:26:18.095594 31776 solver.cpp:228] Iteration 600, loss = 1.11241
I0822 11:26:18.095650 31776 solver.cpp:244]     Train net output #0: loss = 1.11241 (* 1 = 1.11241 loss)
I0822 11:26:18.095656 31776 sgd_solver.cpp:106] Iteration 600, lr = 0.000978075
I0822 11:26:22.603305 31776 solver.cpp:228] Iteration 700, loss = 1.10208
I0822 11:26:22.603364 31776 solver.cpp:244]     Train net output #0: loss = 1.10208 (* 1 = 1.10208 loss)
I0822 11:26:22.603370 31776 sgd_solver.cpp:106] Iteration 700, lr = 0.000974529
I0822 11:26:27.110461 31776 solver.cpp:228] Iteration 800, loss = 1.09891
I0822 11:26:27.110497 31776 solver.cpp:244]     Train net output #0: loss = 1.09891 (* 1 = 1.09891 loss)
I0822 11:26:27.110502 31776 sgd_solver.cpp:106] Iteration 800, lr = 0.000971013
I0822 11:26:31.619385 31776 solver.cpp:228] Iteration 900, loss = 1.115
I0822 11:26:31.619424 31776 solver.cpp:244]     Train net output #0: loss = 1.115 (* 1 = 1.115 loss)
I0822 11:26:31.619429 31776 sgd_solver.cpp:106] Iteration 900, lr = 0.000967526
I0822 11:26:36.089531 31776 solver.cpp:337] Iteration 1000, Testing net (#0)
I0822 11:26:39.553628 31776 solver.cpp:404]     Test net output #0: accuracy = 0.578167
I0822 11:26:39.553663 31776 solver.cpp:404]     Test net output #1: loss = 1.09453 (* 1 = 1.09453 loss)
I0822 11:26:39.568912 31776 solver.cpp:228] Iteration 1000, loss = 1.10971
I0822 11:26:39.568929 31776 solver.cpp:244]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0822 11:26:39.568939 31776 sgd_solver.cpp:106] Iteration 1000, lr = 0.000964069
I0822 11:26:44.082429 31776 solver.cpp:228] Iteration 1100, loss = 1.10048
I0822 11:26:44.082484 31776 solver.cpp:244]     Train net output #0: loss = 1.10048 (* 1 = 1.10048 loss)
I0822 11:26:44.082494 31776 sgd_solver.cpp:106] Iteration 1100, lr = 0.00096064
I0822 11:26:48.597426 31776 solver.cpp:228] Iteration 1200, loss = 1.10155
I0822 11:26:48.597465 31776 solver.cpp:244]     Train net output #0: loss = 1.10155 (* 1 = 1.10155 loss)
I0822 11:26:48.597470 31776 sgd_solver.cpp:106] Iteration 1200, lr = 0.00095724
I0822 11:26:53.110007 31776 solver.cpp:228] Iteration 1300, loss = 1.10116
I0822 11:26:53.110049 31776 solver.cpp:244]     Train net output #0: loss = 1.10116 (* 1 = 1.10116 loss)
I0822 11:26:53.110054 31776 sgd_solver.cpp:106] Iteration 1300, lr = 0.000953867
I0822 11:26:57.623450 31776 solver.cpp:228] Iteration 1400, loss = 1.10281
I0822 11:26:57.623487 31776 solver.cpp:244]     Train net output #0: loss = 1.10281 (* 1 = 1.10281 loss)
I0822 11:26:57.623492 31776 sgd_solver.cpp:106] Iteration 1400, lr = 0.000950522
I0822 11:27:02.088510 31776 solver.cpp:337] Iteration 1500, Testing net (#0)
I0822 11:27:05.699268 31776 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0822 11:27:05.699321 31776 solver.cpp:404]     Test net output #1: loss = 1.10053 (* 1 = 1.10053 loss)
I0822 11:27:05.714243 31776 solver.cpp:228] Iteration 1500, loss = 1.10261
I0822 11:27:05.714298 31776 solver.cpp:244]     Train net output #0: loss = 1.10261 (* 1 = 1.10261 loss)
I0822 11:27:05.714313 31776 sgd_solver.cpp:106] Iteration 1500, lr = 0.000947204
I0822 11:27:10.231196 31776 solver.cpp:228] Iteration 1600, loss = 1.10044
I0822 11:27:10.231245 31776 solver.cpp:244]     Train net output #0: loss = 1.10044 (* 1 = 1.10044 loss)
I0822 11:27:10.231256 31776 sgd_solver.cpp:106] Iteration 1600, lr = 0.000943913
I0822 11:27:14.752373 31776 solver.cpp:228] Iteration 1700, loss = 1.11087
I0822 11:27:14.752440 31776 solver.cpp:244]     Train net output #0: loss = 1.11087 (* 1 = 1.11087 loss)
I0822 11:27:14.752452 31776 sgd_solver.cpp:106] Iteration 1700, lr = 0.000940649
I0822 11:27:19.284812 31776 solver.cpp:228] Iteration 1800, loss = 1.10498
I0822 11:27:19.284850 31776 solver.cpp:244]     Train net output #0: loss = 1.10498 (* 1 = 1.10498 loss)
I0822 11:27:19.284857 31776 sgd_solver.cpp:106] Iteration 1800, lr = 0.000937411
I0822 11:27:23.805874 31776 solver.cpp:228] Iteration 1900, loss = 1.11267
I0822 11:27:23.805914 31776 solver.cpp:244]     Train net output #0: loss = 1.11267 (* 1 = 1.11267 loss)
I0822 11:27:23.805919 31776 sgd_solver.cpp:106] Iteration 1900, lr = 0.000934199
I0822 11:27:28.281656 31776 solver.cpp:337] Iteration 2000, Testing net (#0)
I0822 11:27:31.771380 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0822 11:27:31.771423 31776 solver.cpp:404]     Test net output #1: loss = 1.09886 (* 1 = 1.09886 loss)
I0822 11:27:31.786782 31776 solver.cpp:228] Iteration 2000, loss = 1.10084
I0822 11:27:31.786815 31776 solver.cpp:244]     Train net output #0: loss = 1.10084 (* 1 = 1.10084 loss)
I0822 11:27:31.786828 31776 sgd_solver.cpp:106] Iteration 2000, lr = 0.000931013
I0822 11:27:36.297924 31776 solver.cpp:228] Iteration 2100, loss = 1.09777
I0822 11:27:36.297962 31776 solver.cpp:244]     Train net output #0: loss = 1.09777 (* 1 = 1.09777 loss)
I0822 11:27:36.297968 31776 sgd_solver.cpp:106] Iteration 2100, lr = 0.000927851
I0822 11:27:40.812445 31776 solver.cpp:228] Iteration 2200, loss = 1.09892
I0822 11:27:40.812500 31776 solver.cpp:244]     Train net output #0: loss = 1.09892 (* 1 = 1.09892 loss)
I0822 11:27:40.812511 31776 sgd_solver.cpp:106] Iteration 2200, lr = 0.000924715
I0822 11:27:45.331776 31776 solver.cpp:228] Iteration 2300, loss = 1.09669
I0822 11:27:45.331815 31776 solver.cpp:244]     Train net output #0: loss = 1.09669 (* 1 = 1.09669 loss)
I0822 11:27:45.331820 31776 sgd_solver.cpp:106] Iteration 2300, lr = 0.000921603
I0822 11:27:49.857659 31776 solver.cpp:228] Iteration 2400, loss = 1.09935
I0822 11:27:49.857697 31776 solver.cpp:244]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0822 11:27:49.857702 31776 sgd_solver.cpp:106] Iteration 2400, lr = 0.000918516
I0822 11:27:54.333729 31776 solver.cpp:337] Iteration 2500, Testing net (#0)
I0822 11:27:57.696176 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152667
I0822 11:27:57.696219 31776 solver.cpp:404]     Test net output #1: loss = 1.10426 (* 1 = 1.10426 loss)
I0822 11:27:57.711112 31776 solver.cpp:228] Iteration 2500, loss = 1.09805
I0822 11:27:57.711148 31776 solver.cpp:244]     Train net output #0: loss = 1.09805 (* 1 = 1.09805 loss)
I0822 11:27:57.711166 31776 sgd_solver.cpp:106] Iteration 2500, lr = 0.000915452
I0822 11:28:02.226702 31776 solver.cpp:228] Iteration 2600, loss = 1.10002
I0822 11:28:02.226758 31776 solver.cpp:244]     Train net output #0: loss = 1.10002 (* 1 = 1.10002 loss)
I0822 11:28:02.226768 31776 sgd_solver.cpp:106] Iteration 2600, lr = 0.000912412
I0822 11:28:06.746002 31776 solver.cpp:228] Iteration 2700, loss = 1.0961
I0822 11:28:06.746068 31776 solver.cpp:244]     Train net output #0: loss = 1.0961 (* 1 = 1.0961 loss)
I0822 11:28:06.746076 31776 sgd_solver.cpp:106] Iteration 2700, lr = 0.000909396
I0822 11:28:11.270398 31776 solver.cpp:228] Iteration 2800, loss = 1.10656
I0822 11:28:11.270437 31776 solver.cpp:244]     Train net output #0: loss = 1.10656 (* 1 = 1.10656 loss)
I0822 11:28:11.270443 31776 sgd_solver.cpp:106] Iteration 2800, lr = 0.000906403
I0822 11:28:15.782106 31776 solver.cpp:228] Iteration 2900, loss = 1.09321
I0822 11:28:15.782162 31776 solver.cpp:244]     Train net output #0: loss = 1.09321 (* 1 = 1.09321 loss)
I0822 11:28:15.782174 31776 sgd_solver.cpp:106] Iteration 2900, lr = 0.000903433
I0822 11:28:20.257001 31776 solver.cpp:337] Iteration 3000, Testing net (#0)
I0822 11:28:23.641137 31776 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0822 11:28:23.641180 31776 solver.cpp:404]     Test net output #1: loss = 1.10354 (* 1 = 1.10354 loss)
I0822 11:28:23.657516 31776 solver.cpp:228] Iteration 3000, loss = 1.08977
I0822 11:28:23.657587 31776 solver.cpp:244]     Train net output #0: loss = 1.08977 (* 1 = 1.08977 loss)
I0822 11:28:23.657611 31776 sgd_solver.cpp:106] Iteration 3000, lr = 0.000900485
I0822 11:28:28.178164 31776 solver.cpp:228] Iteration 3100, loss = 1.0963
I0822 11:28:28.178206 31776 solver.cpp:244]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0822 11:28:28.178212 31776 sgd_solver.cpp:106] Iteration 3100, lr = 0.00089756
I0822 11:28:32.701392 31776 solver.cpp:228] Iteration 3200, loss = 1.10468
I0822 11:28:32.701433 31776 solver.cpp:244]     Train net output #0: loss = 1.10468 (* 1 = 1.10468 loss)
I0822 11:28:32.701439 31776 sgd_solver.cpp:106] Iteration 3200, lr = 0.000894657
I0822 11:28:37.223320 31776 solver.cpp:228] Iteration 3300, loss = 1.09843
I0822 11:28:37.223361 31776 solver.cpp:244]     Train net output #0: loss = 1.09843 (* 1 = 1.09843 loss)
I0822 11:28:37.223366 31776 sgd_solver.cpp:106] Iteration 3300, lr = 0.000891776
I0822 11:28:41.737200 31776 solver.cpp:228] Iteration 3400, loss = 1.11086
I0822 11:28:41.737239 31776 solver.cpp:244]     Train net output #0: loss = 1.11086 (* 1 = 1.11086 loss)
I0822 11:28:41.737246 31776 sgd_solver.cpp:106] Iteration 3400, lr = 0.000888916
I0822 11:28:46.217222 31776 solver.cpp:337] Iteration 3500, Testing net (#0)
I0822 11:28:46.479020 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:28:49.880580 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0822 11:28:49.880631 31776 solver.cpp:404]     Test net output #1: loss = 1.10387 (* 1 = 1.10387 loss)
I0822 11:28:49.896971 31776 solver.cpp:228] Iteration 3500, loss = 1.09969
I0822 11:28:49.897038 31776 solver.cpp:244]     Train net output #0: loss = 1.09969 (* 1 = 1.09969 loss)
I0822 11:28:49.897061 31776 sgd_solver.cpp:106] Iteration 3500, lr = 0.000886077
I0822 11:28:54.414496 31776 solver.cpp:228] Iteration 3600, loss = 1.10338
I0822 11:28:54.414546 31776 solver.cpp:244]     Train net output #0: loss = 1.10338 (* 1 = 1.10338 loss)
I0822 11:28:54.414554 31776 sgd_solver.cpp:106] Iteration 3600, lr = 0.00088326
I0822 11:28:58.932404 31776 solver.cpp:228] Iteration 3700, loss = 1.10134
I0822 11:28:58.932452 31776 solver.cpp:244]     Train net output #0: loss = 1.10134 (* 1 = 1.10134 loss)
I0822 11:28:58.932459 31776 sgd_solver.cpp:106] Iteration 3700, lr = 0.000880463
I0822 11:29:03.446485 31776 solver.cpp:228] Iteration 3800, loss = 1.10162
I0822 11:29:03.446523 31776 solver.cpp:244]     Train net output #0: loss = 1.10162 (* 1 = 1.10162 loss)
I0822 11:29:03.446529 31776 sgd_solver.cpp:106] Iteration 3800, lr = 0.000877687
I0822 11:29:07.962015 31776 solver.cpp:228] Iteration 3900, loss = 1.1
I0822 11:29:07.962055 31776 solver.cpp:244]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0822 11:29:07.962060 31776 sgd_solver.cpp:106] Iteration 3900, lr = 0.000874932
I0822 11:29:12.431910 31776 solver.cpp:337] Iteration 4000, Testing net (#0)
I0822 11:29:15.875910 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0822 11:29:15.875960 31776 solver.cpp:404]     Test net output #1: loss = 1.10562 (* 1 = 1.10562 loss)
I0822 11:29:15.891228 31776 solver.cpp:228] Iteration 4000, loss = 1.10054
I0822 11:29:15.891263 31776 solver.cpp:244]     Train net output #0: loss = 1.10054 (* 1 = 1.10054 loss)
I0822 11:29:15.891274 31776 sgd_solver.cpp:106] Iteration 4000, lr = 0.000872196
I0822 11:29:20.409287 31776 solver.cpp:228] Iteration 4100, loss = 1.09604
I0822 11:29:20.409340 31776 solver.cpp:244]     Train net output #0: loss = 1.09604 (* 1 = 1.09604 loss)
I0822 11:29:20.409348 31776 sgd_solver.cpp:106] Iteration 4100, lr = 0.00086948
I0822 11:29:24.926021 31776 solver.cpp:228] Iteration 4200, loss = 1.10415
I0822 11:29:24.926038 31776 solver.cpp:244]     Train net output #0: loss = 1.10415 (* 1 = 1.10415 loss)
I0822 11:29:24.926041 31776 sgd_solver.cpp:106] Iteration 4200, lr = 0.000866784
I0822 11:29:29.447180 31776 solver.cpp:228] Iteration 4300, loss = 1.10531
I0822 11:29:29.447197 31776 solver.cpp:244]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0822 11:29:29.447201 31776 sgd_solver.cpp:106] Iteration 4300, lr = 0.000864108
I0822 11:29:33.964246 31776 solver.cpp:228] Iteration 4400, loss = 1.10133
I0822 11:29:33.964282 31776 solver.cpp:244]     Train net output #0: loss = 1.10133 (* 1 = 1.10133 loss)
I0822 11:29:33.964288 31776 sgd_solver.cpp:106] Iteration 4400, lr = 0.00086145
I0822 11:29:38.439007 31776 solver.cpp:337] Iteration 4500, Testing net (#0)
I0822 11:29:41.886247 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0822 11:29:41.886288 31776 solver.cpp:404]     Test net output #1: loss = 1.11189 (* 1 = 1.11189 loss)
I0822 11:29:41.902196 31776 solver.cpp:228] Iteration 4500, loss = 1.10356
I0822 11:29:41.902267 31776 solver.cpp:244]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0822 11:29:41.902284 31776 sgd_solver.cpp:106] Iteration 4500, lr = 0.000858812
I0822 11:29:46.430227 31776 solver.cpp:228] Iteration 4600, loss = 1.10164
I0822 11:29:46.430287 31776 solver.cpp:244]     Train net output #0: loss = 1.10164 (* 1 = 1.10164 loss)
I0822 11:29:46.430294 31776 sgd_solver.cpp:106] Iteration 4600, lr = 0.000856192
I0822 11:29:50.961768 31776 solver.cpp:228] Iteration 4700, loss = 1.10836
I0822 11:29:50.961827 31776 solver.cpp:244]     Train net output #0: loss = 1.10836 (* 1 = 1.10836 loss)
I0822 11:29:50.961836 31776 sgd_solver.cpp:106] Iteration 4700, lr = 0.000853591
I0822 11:29:55.500126 31776 solver.cpp:228] Iteration 4800, loss = 1.10261
I0822 11:29:55.500170 31776 solver.cpp:244]     Train net output #0: loss = 1.10261 (* 1 = 1.10261 loss)
I0822 11:29:55.500176 31776 sgd_solver.cpp:106] Iteration 4800, lr = 0.000851008
I0822 11:30:00.027467 31776 solver.cpp:228] Iteration 4900, loss = 1.10857
I0822 11:30:00.027505 31776 solver.cpp:244]     Train net output #0: loss = 1.10857 (* 1 = 1.10857 loss)
I0822 11:30:00.027510 31776 sgd_solver.cpp:106] Iteration 4900, lr = 0.000848444
I0822 11:30:04.509037 31776 solver.cpp:337] Iteration 5000, Testing net (#0)
I0822 11:30:07.971411 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0822 11:30:07.971457 31776 solver.cpp:404]     Test net output #1: loss = 1.1123 (* 1 = 1.1123 loss)
I0822 11:30:07.986702 31776 solver.cpp:228] Iteration 5000, loss = 1.09931
I0822 11:30:07.986727 31776 solver.cpp:244]     Train net output #0: loss = 1.09931 (* 1 = 1.09931 loss)
I0822 11:30:07.986735 31776 sgd_solver.cpp:106] Iteration 5000, lr = 0.000845897
I0822 11:30:12.510813 31776 solver.cpp:228] Iteration 5100, loss = 1.0958
I0822 11:30:12.510850 31776 solver.cpp:244]     Train net output #0: loss = 1.0958 (* 1 = 1.0958 loss)
I0822 11:30:12.510856 31776 sgd_solver.cpp:106] Iteration 5100, lr = 0.000843368
I0822 11:30:17.039106 31776 solver.cpp:228] Iteration 5200, loss = 1.08968
I0822 11:30:17.039146 31776 solver.cpp:244]     Train net output #0: loss = 1.08968 (* 1 = 1.08968 loss)
I0822 11:30:17.039152 31776 sgd_solver.cpp:106] Iteration 5200, lr = 0.000840857
I0822 11:30:21.562616 31776 solver.cpp:228] Iteration 5300, loss = 1.097
I0822 11:30:21.562656 31776 solver.cpp:244]     Train net output #0: loss = 1.097 (* 1 = 1.097 loss)
I0822 11:30:21.562661 31776 sgd_solver.cpp:106] Iteration 5300, lr = 0.000838363
I0822 11:30:26.086921 31776 solver.cpp:228] Iteration 5400, loss = 1.09577
I0822 11:30:26.086941 31776 solver.cpp:244]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0822 11:30:26.086946 31776 sgd_solver.cpp:106] Iteration 5400, lr = 0.000835886
I0822 11:30:30.570462 31776 solver.cpp:337] Iteration 5500, Testing net (#0)
I0822 11:30:34.003689 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0822 11:30:34.003739 31776 solver.cpp:404]     Test net output #1: loss = 1.11443 (* 1 = 1.11443 loss)
I0822 11:30:34.019057 31776 solver.cpp:228] Iteration 5500, loss = 1.0979
I0822 11:30:34.019088 31776 solver.cpp:244]     Train net output #0: loss = 1.0979 (* 1 = 1.0979 loss)
I0822 11:30:34.019099 31776 sgd_solver.cpp:106] Iteration 5500, lr = 0.000833427
I0822 11:30:38.540154 31776 solver.cpp:228] Iteration 5600, loss = 1.10171
I0822 11:30:38.540200 31776 solver.cpp:244]     Train net output #0: loss = 1.10171 (* 1 = 1.10171 loss)
I0822 11:30:38.540206 31776 sgd_solver.cpp:106] Iteration 5600, lr = 0.000830984
I0822 11:30:43.066709 31776 solver.cpp:228] Iteration 5700, loss = 1.10338
I0822 11:30:43.066746 31776 solver.cpp:244]     Train net output #0: loss = 1.10338 (* 1 = 1.10338 loss)
I0822 11:30:43.066751 31776 sgd_solver.cpp:106] Iteration 5700, lr = 0.000828558
I0822 11:30:47.585995 31776 solver.cpp:228] Iteration 5800, loss = 1.09698
I0822 11:30:47.586014 31776 solver.cpp:244]     Train net output #0: loss = 1.09698 (* 1 = 1.09698 loss)
I0822 11:30:47.586019 31776 sgd_solver.cpp:106] Iteration 5800, lr = 0.000826148
I0822 11:30:52.115357 31776 solver.cpp:228] Iteration 5900, loss = 1.09583
I0822 11:30:52.115397 31776 solver.cpp:244]     Train net output #0: loss = 1.09583 (* 1 = 1.09583 loss)
I0822 11:30:52.115402 31776 sgd_solver.cpp:106] Iteration 5900, lr = 0.000823754
I0822 11:30:56.596505 31776 solver.cpp:337] Iteration 6000, Testing net (#0)
I0822 11:30:59.958879 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0822 11:30:59.958928 31776 solver.cpp:404]     Test net output #1: loss = 1.11297 (* 1 = 1.11297 loss)
I0822 11:30:59.974427 31776 solver.cpp:228] Iteration 6000, loss = 1.10523
I0822 11:30:59.974464 31776 solver.cpp:244]     Train net output #0: loss = 1.10523 (* 1 = 1.10523 loss)
I0822 11:30:59.974474 31776 sgd_solver.cpp:106] Iteration 6000, lr = 0.000821377
I0822 11:31:04.505544 31776 solver.cpp:228] Iteration 6100, loss = 1.11025
I0822 11:31:04.505584 31776 solver.cpp:244]     Train net output #0: loss = 1.11025 (* 1 = 1.11025 loss)
I0822 11:31:04.505589 31776 sgd_solver.cpp:106] Iteration 6100, lr = 0.000819015
I0822 11:31:05.318663 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:31:09.029122 31776 solver.cpp:228] Iteration 6200, loss = 1.0987
I0822 11:31:09.029161 31776 solver.cpp:244]     Train net output #0: loss = 1.0987 (* 1 = 1.0987 loss)
I0822 11:31:09.029167 31776 sgd_solver.cpp:106] Iteration 6200, lr = 0.00081667
I0822 11:31:13.555487 31776 solver.cpp:228] Iteration 6300, loss = 1.09665
I0822 11:31:13.555526 31776 solver.cpp:244]     Train net output #0: loss = 1.09665 (* 1 = 1.09665 loss)
I0822 11:31:13.555531 31776 sgd_solver.cpp:106] Iteration 6300, lr = 0.00081434
I0822 11:31:18.086622 31776 solver.cpp:228] Iteration 6400, loss = 1.10003
I0822 11:31:18.086661 31776 solver.cpp:244]     Train net output #0: loss = 1.10003 (* 1 = 1.10003 loss)
I0822 11:31:18.086668 31776 sgd_solver.cpp:106] Iteration 6400, lr = 0.000812025
I0822 11:31:22.566826 31776 solver.cpp:337] Iteration 6500, Testing net (#0)
I0822 11:31:26.171063 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0822 11:31:26.171123 31776 solver.cpp:404]     Test net output #1: loss = 1.10571 (* 1 = 1.10571 loss)
I0822 11:31:26.187604 31776 solver.cpp:228] Iteration 6500, loss = 1.09989
I0822 11:31:26.187662 31776 solver.cpp:244]     Train net output #0: loss = 1.09989 (* 1 = 1.09989 loss)
I0822 11:31:26.187683 31776 sgd_solver.cpp:106] Iteration 6500, lr = 0.000809726
I0822 11:31:30.714547 31776 solver.cpp:228] Iteration 6600, loss = 1.09364
I0822 11:31:30.714599 31776 solver.cpp:244]     Train net output #0: loss = 1.09364 (* 1 = 1.09364 loss)
I0822 11:31:30.714609 31776 sgd_solver.cpp:106] Iteration 6600, lr = 0.000807442
I0822 11:31:35.238813 31776 solver.cpp:228] Iteration 6700, loss = 1.09517
I0822 11:31:35.238873 31776 solver.cpp:244]     Train net output #0: loss = 1.09517 (* 1 = 1.09517 loss)
I0822 11:31:35.238878 31776 sgd_solver.cpp:106] Iteration 6700, lr = 0.000805173
I0822 11:31:39.765380 31776 solver.cpp:228] Iteration 6800, loss = 1.1012
I0822 11:31:39.765415 31776 solver.cpp:244]     Train net output #0: loss = 1.1012 (* 1 = 1.1012 loss)
I0822 11:31:39.765421 31776 sgd_solver.cpp:106] Iteration 6800, lr = 0.000802918
I0822 11:31:44.296517 31776 solver.cpp:228] Iteration 6900, loss = 1.1085
I0822 11:31:44.296556 31776 solver.cpp:244]     Train net output #0: loss = 1.1085 (* 1 = 1.1085 loss)
I0822 11:31:44.296562 31776 sgd_solver.cpp:106] Iteration 6900, lr = 0.000800679
I0822 11:31:48.781105 31776 solver.cpp:337] Iteration 7000, Testing net (#0)
I0822 11:31:52.268339 31776 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0822 11:31:52.268384 31776 solver.cpp:404]     Test net output #1: loss = 1.10071 (* 1 = 1.10071 loss)
I0822 11:31:52.283960 31776 solver.cpp:228] Iteration 7000, loss = 1.10179
I0822 11:31:52.283982 31776 solver.cpp:244]     Train net output #0: loss = 1.10179 (* 1 = 1.10179 loss)
I0822 11:31:52.283995 31776 sgd_solver.cpp:106] Iteration 7000, lr = 0.000798454
I0822 11:31:56.806622 31776 solver.cpp:228] Iteration 7100, loss = 1.09773
I0822 11:31:56.806681 31776 solver.cpp:244]     Train net output #0: loss = 1.09773 (* 1 = 1.09773 loss)
I0822 11:31:56.806689 31776 sgd_solver.cpp:106] Iteration 7100, lr = 0.000796243
I0822 11:32:01.330528 31776 solver.cpp:228] Iteration 7200, loss = 1.1046
I0822 11:32:01.330585 31776 solver.cpp:244]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0822 11:32:01.330591 31776 sgd_solver.cpp:106] Iteration 7200, lr = 0.000794046
I0822 11:32:05.856247 31776 solver.cpp:228] Iteration 7300, loss = 1.09228
I0822 11:32:05.856287 31776 solver.cpp:244]     Train net output #0: loss = 1.09228 (* 1 = 1.09228 loss)
I0822 11:32:05.856292 31776 sgd_solver.cpp:106] Iteration 7300, lr = 0.000791864
I0822 11:32:10.397826 31776 solver.cpp:228] Iteration 7400, loss = 1.10731
I0822 11:32:10.397872 31776 solver.cpp:244]     Train net output #0: loss = 1.10731 (* 1 = 1.10731 loss)
I0822 11:32:10.397879 31776 sgd_solver.cpp:106] Iteration 7400, lr = 0.000789695
I0822 11:32:14.879987 31776 solver.cpp:337] Iteration 7500, Testing net (#0)
I0822 11:32:18.512549 31776 solver.cpp:404]     Test net output #0: accuracy = 0.578583
I0822 11:32:18.512616 31776 solver.cpp:404]     Test net output #1: loss = 1.09319 (* 1 = 1.09319 loss)
I0822 11:32:18.527858 31776 solver.cpp:228] Iteration 7500, loss = 1.10221
I0822 11:32:18.527880 31776 solver.cpp:244]     Train net output #0: loss = 1.10221 (* 1 = 1.10221 loss)
I0822 11:32:18.527894 31776 sgd_solver.cpp:106] Iteration 7500, lr = 0.000787541
I0822 11:32:23.056540 31776 solver.cpp:228] Iteration 7600, loss = 1.10079
I0822 11:32:23.056579 31776 solver.cpp:244]     Train net output #0: loss = 1.10079 (* 1 = 1.10079 loss)
I0822 11:32:23.056584 31776 sgd_solver.cpp:106] Iteration 7600, lr = 0.0007854
I0822 11:32:27.587461 31776 solver.cpp:228] Iteration 7700, loss = 1.09629
I0822 11:32:27.587502 31776 solver.cpp:244]     Train net output #0: loss = 1.09629 (* 1 = 1.09629 loss)
I0822 11:32:27.587507 31776 sgd_solver.cpp:106] Iteration 7700, lr = 0.000783272
I0822 11:32:32.119307 31776 solver.cpp:228] Iteration 7800, loss = 1.09706
I0822 11:32:32.119362 31776 solver.cpp:244]     Train net output #0: loss = 1.09706 (* 1 = 1.09706 loss)
I0822 11:32:32.119371 31776 sgd_solver.cpp:106] Iteration 7800, lr = 0.000781158
I0822 11:32:36.649106 31776 solver.cpp:228] Iteration 7900, loss = 1.09834
I0822 11:32:36.649144 31776 solver.cpp:244]     Train net output #0: loss = 1.09834 (* 1 = 1.09834 loss)
I0822 11:32:36.649149 31776 sgd_solver.cpp:106] Iteration 7900, lr = 0.000779057
I0822 11:32:41.135994 31776 solver.cpp:337] Iteration 8000, Testing net (#0)
I0822 11:32:44.551811 31776 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0822 11:32:44.551856 31776 solver.cpp:404]     Test net output #1: loss = 1.09127 (* 1 = 1.09127 loss)
I0822 11:32:44.566764 31776 solver.cpp:228] Iteration 8000, loss = 1.0984
I0822 11:32:44.566823 31776 solver.cpp:244]     Train net output #0: loss = 1.0984 (* 1 = 1.0984 loss)
I0822 11:32:44.566836 31776 sgd_solver.cpp:106] Iteration 8000, lr = 0.00077697
I0822 11:32:49.093590 31776 solver.cpp:228] Iteration 8100, loss = 1.10137
I0822 11:32:49.093631 31776 solver.cpp:244]     Train net output #0: loss = 1.10137 (* 1 = 1.10137 loss)
I0822 11:32:49.093636 31776 sgd_solver.cpp:106] Iteration 8100, lr = 0.000774895
I0822 11:32:53.622241 31776 solver.cpp:228] Iteration 8200, loss = 1.10061
I0822 11:32:53.622280 31776 solver.cpp:244]     Train net output #0: loss = 1.10061 (* 1 = 1.10061 loss)
I0822 11:32:53.622287 31776 sgd_solver.cpp:106] Iteration 8200, lr = 0.000772833
I0822 11:32:58.154296 31776 solver.cpp:228] Iteration 8300, loss = 1.09977
I0822 11:32:58.154343 31776 solver.cpp:244]     Train net output #0: loss = 1.09977 (* 1 = 1.09977 loss)
I0822 11:32:58.154351 31776 sgd_solver.cpp:106] Iteration 8300, lr = 0.000770784
I0822 11:33:02.674882 31776 solver.cpp:228] Iteration 8400, loss = 1.09536
I0822 11:33:02.674901 31776 solver.cpp:244]     Train net output #0: loss = 1.09536 (* 1 = 1.09536 loss)
I0822 11:33:02.674906 31776 sgd_solver.cpp:106] Iteration 8400, lr = 0.000768748
I0822 11:33:07.162138 31776 solver.cpp:337] Iteration 8500, Testing net (#0)
I0822 11:33:10.595587 31776 solver.cpp:404]     Test net output #0: accuracy = 0.578083
I0822 11:33:10.595623 31776 solver.cpp:404]     Test net output #1: loss = 1.09357 (* 1 = 1.09357 loss)
I0822 11:33:10.611064 31776 solver.cpp:228] Iteration 8500, loss = 1.09567
I0822 11:33:10.611102 31776 solver.cpp:244]     Train net output #0: loss = 1.09567 (* 1 = 1.09567 loss)
I0822 11:33:10.611114 31776 sgd_solver.cpp:106] Iteration 8500, lr = 0.000766724
I0822 11:33:15.137810 31776 solver.cpp:228] Iteration 8600, loss = 1.0937
I0822 11:33:15.137858 31776 solver.cpp:244]     Train net output #0: loss = 1.0937 (* 1 = 1.0937 loss)
I0822 11:33:15.137866 31776 sgd_solver.cpp:106] Iteration 8600, lr = 0.000764712
I0822 11:33:19.666245 31776 solver.cpp:228] Iteration 8700, loss = 1.10086
I0822 11:33:19.666292 31776 solver.cpp:244]     Train net output #0: loss = 1.10086 (* 1 = 1.10086 loss)
I0822 11:33:19.666298 31776 sgd_solver.cpp:106] Iteration 8700, lr = 0.000762713
I0822 11:33:24.191867 31776 solver.cpp:228] Iteration 8800, loss = 1.102
I0822 11:33:24.191918 31776 solver.cpp:244]     Train net output #0: loss = 1.102 (* 1 = 1.102 loss)
I0822 11:33:24.191931 31776 sgd_solver.cpp:106] Iteration 8800, lr = 0.000760726
I0822 11:33:28.712646 31776 solver.cpp:228] Iteration 8900, loss = 1.10111
I0822 11:33:28.712680 31776 solver.cpp:244]     Train net output #0: loss = 1.10111 (* 1 = 1.10111 loss)
I0822 11:33:28.712685 31776 sgd_solver.cpp:106] Iteration 8900, lr = 0.000758751
I0822 11:33:33.197693 31776 solver.cpp:337] Iteration 9000, Testing net (#0)
I0822 11:33:34.750288 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:33:36.858252 31776 solver.cpp:404]     Test net output #0: accuracy = 0.363209
I0822 11:33:36.858307 31776 solver.cpp:404]     Test net output #1: loss = 1.09643 (* 1 = 1.09643 loss)
I0822 11:33:36.873950 31776 solver.cpp:228] Iteration 9000, loss = 1.09482
I0822 11:33:36.874012 31776 solver.cpp:244]     Train net output #0: loss = 1.09482 (* 1 = 1.09482 loss)
I0822 11:33:36.874042 31776 sgd_solver.cpp:106] Iteration 9000, lr = 0.000756788
I0822 11:33:41.399724 31776 solver.cpp:228] Iteration 9100, loss = 1.09318
I0822 11:33:41.399783 31776 solver.cpp:244]     Train net output #0: loss = 1.09318 (* 1 = 1.09318 loss)
I0822 11:33:41.399798 31776 sgd_solver.cpp:106] Iteration 9100, lr = 0.000754836
I0822 11:33:45.930397 31776 solver.cpp:228] Iteration 9200, loss = 1.1074
I0822 11:33:45.930444 31776 solver.cpp:244]     Train net output #0: loss = 1.1074 (* 1 = 1.1074 loss)
I0822 11:33:45.930451 31776 sgd_solver.cpp:106] Iteration 9200, lr = 0.000752897
I0822 11:33:50.458117 31776 solver.cpp:228] Iteration 9300, loss = 1.09641
I0822 11:33:50.458134 31776 solver.cpp:244]     Train net output #0: loss = 1.09641 (* 1 = 1.09641 loss)
I0822 11:33:50.458139 31776 sgd_solver.cpp:106] Iteration 9300, lr = 0.000750969
I0822 11:33:54.983556 31776 solver.cpp:228] Iteration 9400, loss = 1.0972
I0822 11:33:54.983592 31776 solver.cpp:244]     Train net output #0: loss = 1.0972 (* 1 = 1.0972 loss)
I0822 11:33:54.983597 31776 sgd_solver.cpp:106] Iteration 9400, lr = 0.000749052
I0822 11:33:59.474479 31776 solver.cpp:337] Iteration 9500, Testing net (#0)
I0822 11:34:02.671728 31776 solver.cpp:404]     Test net output #0: accuracy = 0.22075
I0822 11:34:02.671766 31776 solver.cpp:404]     Test net output #1: loss = 1.09878 (* 1 = 1.09878 loss)
I0822 11:34:02.687114 31776 solver.cpp:228] Iteration 9500, loss = 1.09687
I0822 11:34:02.687142 31776 solver.cpp:244]     Train net output #0: loss = 1.09687 (* 1 = 1.09687 loss)
I0822 11:34:02.687150 31776 sgd_solver.cpp:106] Iteration 9500, lr = 0.000747147
I0822 11:34:07.216177 31776 solver.cpp:228] Iteration 9600, loss = 1.09246
I0822 11:34:07.216217 31776 solver.cpp:244]     Train net output #0: loss = 1.09246 (* 1 = 1.09246 loss)
I0822 11:34:07.216222 31776 sgd_solver.cpp:106] Iteration 9600, lr = 0.000745253
I0822 11:34:11.743603 31776 solver.cpp:228] Iteration 9700, loss = 1.09349
I0822 11:34:11.743640 31776 solver.cpp:244]     Train net output #0: loss = 1.09349 (* 1 = 1.09349 loss)
I0822 11:34:11.743645 31776 sgd_solver.cpp:106] Iteration 9700, lr = 0.00074337
I0822 11:34:16.272050 31776 solver.cpp:228] Iteration 9800, loss = 1.09516
I0822 11:34:16.272090 31776 solver.cpp:244]     Train net output #0: loss = 1.09516 (* 1 = 1.09516 loss)
I0822 11:34:16.272095 31776 sgd_solver.cpp:106] Iteration 9800, lr = 0.000741499
I0822 11:34:20.802592 31776 solver.cpp:228] Iteration 9900, loss = 1.09384
I0822 11:34:20.802631 31776 solver.cpp:244]     Train net output #0: loss = 1.09384 (* 1 = 1.09384 loss)
I0822 11:34:20.802636 31776 sgd_solver.cpp:106] Iteration 9900, lr = 0.000739638
I0822 11:34:25.283514 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_10000.caffemodel
I0822 11:34:25.832605 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_10000.solverstate
I0822 11:34:26.101987 31776 solver.cpp:337] Iteration 10000, Testing net (#0)
I0822 11:34:29.576036 31776 solver.cpp:404]     Test net output #0: accuracy = 0.402125
I0822 11:34:29.576084 31776 solver.cpp:404]     Test net output #1: loss = 1.09448 (* 1 = 1.09448 loss)
I0822 11:34:29.590878 31776 solver.cpp:228] Iteration 10000, loss = 1.09249
I0822 11:34:29.590924 31776 solver.cpp:244]     Train net output #0: loss = 1.09249 (* 1 = 1.09249 loss)
I0822 11:34:29.590934 31776 sgd_solver.cpp:106] Iteration 10000, lr = 0.000737788
I0822 11:34:34.110028 31776 solver.cpp:228] Iteration 10100, loss = 1.08914
I0822 11:34:34.110066 31776 solver.cpp:244]     Train net output #0: loss = 1.08914 (* 1 = 1.08914 loss)
I0822 11:34:34.110071 31776 sgd_solver.cpp:106] Iteration 10100, lr = 0.000735949
I0822 11:34:38.636250 31776 solver.cpp:228] Iteration 10200, loss = 1.08145
I0822 11:34:38.636296 31776 solver.cpp:244]     Train net output #0: loss = 1.08145 (* 1 = 1.08145 loss)
I0822 11:34:38.636302 31776 sgd_solver.cpp:106] Iteration 10200, lr = 0.00073412
I0822 11:34:43.158409 31776 solver.cpp:228] Iteration 10300, loss = 1.05234
I0822 11:34:43.158447 31776 solver.cpp:244]     Train net output #0: loss = 1.05234 (* 1 = 1.05234 loss)
I0822 11:34:43.158452 31776 sgd_solver.cpp:106] Iteration 10300, lr = 0.000732303
I0822 11:34:47.675956 31776 solver.cpp:228] Iteration 10400, loss = 1.03028
I0822 11:34:47.675997 31776 solver.cpp:244]     Train net output #0: loss = 1.03028 (* 1 = 1.03028 loss)
I0822 11:34:47.676002 31776 sgd_solver.cpp:106] Iteration 10400, lr = 0.000730495
I0822 11:34:52.157167 31776 solver.cpp:337] Iteration 10500, Testing net (#0)
I0822 11:34:55.392180 31776 solver.cpp:404]     Test net output #0: accuracy = 0.450042
I0822 11:34:55.392218 31776 solver.cpp:404]     Test net output #1: loss = 1.02659 (* 1 = 1.02659 loss)
I0822 11:34:55.407299 31776 solver.cpp:228] Iteration 10500, loss = 0.997451
I0822 11:34:55.407351 31776 solver.cpp:244]     Train net output #0: loss = 0.997451 (* 1 = 0.997451 loss)
I0822 11:34:55.407366 31776 sgd_solver.cpp:106] Iteration 10500, lr = 0.000728698
I0822 11:34:59.926523 31776 solver.cpp:228] Iteration 10600, loss = 1.06649
I0822 11:34:59.926568 31776 solver.cpp:244]     Train net output #0: loss = 1.06649 (* 1 = 1.06649 loss)
I0822 11:34:59.926573 31776 sgd_solver.cpp:106] Iteration 10600, lr = 0.000726911
I0822 11:35:04.440778 31776 solver.cpp:228] Iteration 10700, loss = 0.996416
I0822 11:35:04.440815 31776 solver.cpp:244]     Train net output #0: loss = 0.996416 (* 1 = 0.996416 loss)
I0822 11:35:04.440820 31776 sgd_solver.cpp:106] Iteration 10700, lr = 0.000725135
I0822 11:35:08.958120 31776 solver.cpp:228] Iteration 10800, loss = 1.03058
I0822 11:35:08.958164 31776 solver.cpp:244]     Train net output #0: loss = 1.03058 (* 1 = 1.03058 loss)
I0822 11:35:08.958170 31776 sgd_solver.cpp:106] Iteration 10800, lr = 0.000723368
I0822 11:35:13.480619 31776 solver.cpp:228] Iteration 10900, loss = 0.956142
I0822 11:35:13.480659 31776 solver.cpp:244]     Train net output #0: loss = 0.956142 (* 1 = 0.956142 loss)
I0822 11:35:13.480664 31776 sgd_solver.cpp:106] Iteration 10900, lr = 0.000721612
I0822 11:35:17.955382 31776 solver.cpp:337] Iteration 11000, Testing net (#0)
I0822 11:35:21.665443 31776 solver.cpp:404]     Test net output #0: accuracy = 0.464458
I0822 11:35:21.665488 31776 solver.cpp:404]     Test net output #1: loss = 0.983901 (* 1 = 0.983901 loss)
I0822 11:35:21.680845 31776 solver.cpp:228] Iteration 11000, loss = 0.860981
I0822 11:35:21.680881 31776 solver.cpp:244]     Train net output #0: loss = 0.860981 (* 1 = 0.860981 loss)
I0822 11:35:21.680896 31776 sgd_solver.cpp:106] Iteration 11000, lr = 0.000719865
I0822 11:35:26.201624 31776 solver.cpp:228] Iteration 11100, loss = 0.92256
I0822 11:35:26.201679 31776 solver.cpp:244]     Train net output #0: loss = 0.92256 (* 1 = 0.92256 loss)
I0822 11:35:26.201689 31776 sgd_solver.cpp:106] Iteration 11100, lr = 0.000718129
I0822 11:35:30.729919 31776 solver.cpp:228] Iteration 11200, loss = 0.935121
I0822 11:35:30.729956 31776 solver.cpp:244]     Train net output #0: loss = 0.935121 (* 1 = 0.935121 loss)
I0822 11:35:30.729961 31776 sgd_solver.cpp:106] Iteration 11200, lr = 0.000716402
I0822 11:35:35.255107 31776 solver.cpp:228] Iteration 11300, loss = 0.864266
I0822 11:35:35.255146 31776 solver.cpp:244]     Train net output #0: loss = 0.864266 (* 1 = 0.864266 loss)
I0822 11:35:35.255151 31776 sgd_solver.cpp:106] Iteration 11300, lr = 0.000714684
I0822 11:35:39.781951 31776 solver.cpp:228] Iteration 11400, loss = 0.851276
I0822 11:35:39.781992 31776 solver.cpp:244]     Train net output #0: loss = 0.851276 (* 1 = 0.851276 loss)
I0822 11:35:39.781997 31776 sgd_solver.cpp:106] Iteration 11400, lr = 0.000712977
I0822 11:35:44.255373 31776 solver.cpp:337] Iteration 11500, Testing net (#0)
I0822 11:35:47.737356 31776 solver.cpp:404]     Test net output #0: accuracy = 0.591333
I0822 11:35:47.737416 31776 solver.cpp:404]     Test net output #1: loss = 0.815523 (* 1 = 0.815523 loss)
I0822 11:35:47.753650 31776 solver.cpp:228] Iteration 11500, loss = 0.871454
I0822 11:35:47.753700 31776 solver.cpp:244]     Train net output #0: loss = 0.871454 (* 1 = 0.871454 loss)
I0822 11:35:47.753720 31776 sgd_solver.cpp:106] Iteration 11500, lr = 0.000711278
I0822 11:35:52.273116 31776 solver.cpp:228] Iteration 11600, loss = 0.899751
I0822 11:35:52.273165 31776 solver.cpp:244]     Train net output #0: loss = 0.899751 (* 1 = 0.899751 loss)
I0822 11:35:52.273175 31776 sgd_solver.cpp:106] Iteration 11600, lr = 0.00070959
I0822 11:35:56.797621 31776 solver.cpp:228] Iteration 11700, loss = 0.851904
I0822 11:35:56.797660 31776 solver.cpp:244]     Train net output #0: loss = 0.851904 (* 1 = 0.851904 loss)
I0822 11:35:56.797665 31776 sgd_solver.cpp:106] Iteration 11700, lr = 0.00070791
I0822 11:36:01.315577 31776 solver.cpp:228] Iteration 11800, loss = 0.864725
I0822 11:36:01.315614 31776 solver.cpp:244]     Train net output #0: loss = 0.864725 (* 1 = 0.864725 loss)
I0822 11:36:01.315620 31776 sgd_solver.cpp:106] Iteration 11800, lr = 0.00070624
I0822 11:36:05.838479 31776 solver.cpp:228] Iteration 11900, loss = 0.841097
I0822 11:36:05.838517 31776 solver.cpp:244]     Train net output #0: loss = 0.841097 (* 1 = 0.841097 loss)
I0822 11:36:05.838523 31776 sgd_solver.cpp:106] Iteration 11900, lr = 0.000704579
I0822 11:36:10.316761 31776 solver.cpp:337] Iteration 12000, Testing net (#0)
I0822 11:36:10.794773 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:36:14.026998 31776 solver.cpp:404]     Test net output #0: accuracy = 0.634334
I0822 11:36:14.027060 31776 solver.cpp:404]     Test net output #1: loss = 0.742943 (* 1 = 0.742943 loss)
I0822 11:36:14.043436 31776 solver.cpp:228] Iteration 12000, loss = 0.753756
I0822 11:36:14.043509 31776 solver.cpp:244]     Train net output #0: loss = 0.753756 (* 1 = 0.753756 loss)
I0822 11:36:14.043534 31776 sgd_solver.cpp:106] Iteration 12000, lr = 0.000702927
I0822 11:36:18.564649 31776 solver.cpp:228] Iteration 12100, loss = 0.845667
I0822 11:36:18.564692 31776 solver.cpp:244]     Train net output #0: loss = 0.845667 (* 1 = 0.845667 loss)
I0822 11:36:18.564698 31776 sgd_solver.cpp:106] Iteration 12100, lr = 0.000701284
I0822 11:36:23.088868 31776 solver.cpp:228] Iteration 12200, loss = 0.800303
I0822 11:36:23.088907 31776 solver.cpp:244]     Train net output #0: loss = 0.800303 (* 1 = 0.800303 loss)
I0822 11:36:23.088913 31776 sgd_solver.cpp:106] Iteration 12200, lr = 0.00069965
I0822 11:36:27.615154 31776 solver.cpp:228] Iteration 12300, loss = 0.860752
I0822 11:36:27.615191 31776 solver.cpp:244]     Train net output #0: loss = 0.860752 (* 1 = 0.860752 loss)
I0822 11:36:27.615196 31776 sgd_solver.cpp:106] Iteration 12300, lr = 0.000698024
I0822 11:36:32.132587 31776 solver.cpp:228] Iteration 12400, loss = 0.753087
I0822 11:36:32.132623 31776 solver.cpp:244]     Train net output #0: loss = 0.753087 (* 1 = 0.753087 loss)
I0822 11:36:32.132628 31776 sgd_solver.cpp:106] Iteration 12400, lr = 0.000696408
I0822 11:36:36.602855 31776 solver.cpp:337] Iteration 12500, Testing net (#0)
I0822 11:36:39.846304 31776 solver.cpp:404]     Test net output #0: accuracy = 0.629333
I0822 11:36:39.846361 31776 solver.cpp:404]     Test net output #1: loss = 0.772659 (* 1 = 0.772659 loss)
I0822 11:36:39.862120 31776 solver.cpp:228] Iteration 12500, loss = 0.793402
I0822 11:36:39.862182 31776 solver.cpp:244]     Train net output #0: loss = 0.793402 (* 1 = 0.793402 loss)
I0822 11:36:39.862196 31776 sgd_solver.cpp:106] Iteration 12500, lr = 0.0006948
I0822 11:36:44.385643 31776 solver.cpp:228] Iteration 12600, loss = 0.823435
I0822 11:36:44.385684 31776 solver.cpp:244]     Train net output #0: loss = 0.823435 (* 1 = 0.823435 loss)
I0822 11:36:44.385689 31776 sgd_solver.cpp:106] Iteration 12600, lr = 0.000693201
I0822 11:36:48.908360 31776 solver.cpp:228] Iteration 12700, loss = 0.839698
I0822 11:36:48.908412 31776 solver.cpp:244]     Train net output #0: loss = 0.839698 (* 1 = 0.839698 loss)
I0822 11:36:48.908419 31776 sgd_solver.cpp:106] Iteration 12700, lr = 0.000691611
I0822 11:36:53.434418 31776 solver.cpp:228] Iteration 12800, loss = 0.801671
I0822 11:36:53.434466 31776 solver.cpp:244]     Train net output #0: loss = 0.801671 (* 1 = 0.801671 loss)
I0822 11:36:53.434473 31776 sgd_solver.cpp:106] Iteration 12800, lr = 0.000690029
I0822 11:36:57.954675 31776 solver.cpp:228] Iteration 12900, loss = 0.832596
I0822 11:36:57.954717 31776 solver.cpp:244]     Train net output #0: loss = 0.832596 (* 1 = 0.832596 loss)
I0822 11:36:57.954722 31776 sgd_solver.cpp:106] Iteration 12900, lr = 0.000688455
I0822 11:37:02.441215 31776 solver.cpp:337] Iteration 13000, Testing net (#0)
I0822 11:37:06.064339 31776 solver.cpp:404]     Test net output #0: accuracy = 0.659125
I0822 11:37:06.064404 31776 solver.cpp:404]     Test net output #1: loss = 0.740405 (* 1 = 0.740405 loss)
I0822 11:37:06.080133 31776 solver.cpp:228] Iteration 13000, loss = 0.71559
I0822 11:37:06.080173 31776 solver.cpp:244]     Train net output #0: loss = 0.71559 (* 1 = 0.71559 loss)
I0822 11:37:06.080188 31776 sgd_solver.cpp:106] Iteration 13000, lr = 0.00068689
I0822 11:37:10.597103 31776 solver.cpp:228] Iteration 13100, loss = 0.746571
I0822 11:37:10.597162 31776 solver.cpp:244]     Train net output #0: loss = 0.746571 (* 1 = 0.746571 loss)
I0822 11:37:10.597169 31776 sgd_solver.cpp:106] Iteration 13100, lr = 0.000685333
I0822 11:37:15.117552 31776 solver.cpp:228] Iteration 13200, loss = 0.784187
I0822 11:37:15.117620 31776 solver.cpp:244]     Train net output #0: loss = 0.784187 (* 1 = 0.784187 loss)
I0822 11:37:15.117632 31776 sgd_solver.cpp:106] Iteration 13200, lr = 0.000683784
I0822 11:37:19.643273 31776 solver.cpp:228] Iteration 13300, loss = 0.669409
I0822 11:37:19.643313 31776 solver.cpp:244]     Train net output #0: loss = 0.669409 (* 1 = 0.669409 loss)
I0822 11:37:19.643318 31776 sgd_solver.cpp:106] Iteration 13300, lr = 0.000682243
I0822 11:37:24.164805 31776 solver.cpp:228] Iteration 13400, loss = 0.778648
I0822 11:37:24.164871 31776 solver.cpp:244]     Train net output #0: loss = 0.778648 (* 1 = 0.778648 loss)
I0822 11:37:24.164877 31776 sgd_solver.cpp:106] Iteration 13400, lr = 0.000680711
I0822 11:37:28.647544 31776 solver.cpp:337] Iteration 13500, Testing net (#0)
I0822 11:37:32.150759 31776 solver.cpp:404]     Test net output #0: accuracy = 0.71375
I0822 11:37:32.150825 31776 solver.cpp:404]     Test net output #1: loss = 0.635916 (* 1 = 0.635916 loss)
I0822 11:37:32.166848 31776 solver.cpp:228] Iteration 13500, loss = 0.720228
I0822 11:37:32.166920 31776 solver.cpp:244]     Train net output #0: loss = 0.720228 (* 1 = 0.720228 loss)
I0822 11:37:32.166940 31776 sgd_solver.cpp:106] Iteration 13500, lr = 0.000679186
I0822 11:37:36.685206 31776 solver.cpp:228] Iteration 13600, loss = 0.722288
I0822 11:37:36.685245 31776 solver.cpp:244]     Train net output #0: loss = 0.722288 (* 1 = 0.722288 loss)
I0822 11:37:36.685250 31776 sgd_solver.cpp:106] Iteration 13600, lr = 0.00067767
I0822 11:37:41.208039 31776 solver.cpp:228] Iteration 13700, loss = 0.692336
I0822 11:37:41.208078 31776 solver.cpp:244]     Train net output #0: loss = 0.692336 (* 1 = 0.692336 loss)
I0822 11:37:41.208083 31776 sgd_solver.cpp:106] Iteration 13700, lr = 0.000676161
I0822 11:37:45.729892 31776 solver.cpp:228] Iteration 13800, loss = 0.760269
I0822 11:37:45.729931 31776 solver.cpp:244]     Train net output #0: loss = 0.760269 (* 1 = 0.760269 loss)
I0822 11:37:45.729938 31776 sgd_solver.cpp:106] Iteration 13800, lr = 0.00067466
I0822 11:37:50.256616 31776 solver.cpp:228] Iteration 13900, loss = 0.648469
I0822 11:37:50.256659 31776 solver.cpp:244]     Train net output #0: loss = 0.648469 (* 1 = 0.648469 loss)
I0822 11:37:50.256664 31776 sgd_solver.cpp:106] Iteration 13900, lr = 0.000673167
I0822 11:37:54.737720 31776 solver.cpp:337] Iteration 14000, Testing net (#0)
I0822 11:37:58.315026 31776 solver.cpp:404]     Test net output #0: accuracy = 0.67025
I0822 11:37:58.315091 31776 solver.cpp:404]     Test net output #1: loss = 0.715563 (* 1 = 0.715563 loss)
I0822 11:37:58.330454 31776 solver.cpp:228] Iteration 14000, loss = 0.620426
I0822 11:37:58.330481 31776 solver.cpp:244]     Train net output #0: loss = 0.620426 (* 1 = 0.620426 loss)
I0822 11:37:58.330494 31776 sgd_solver.cpp:106] Iteration 14000, lr = 0.000671681
I0822 11:38:02.853700 31776 solver.cpp:228] Iteration 14100, loss = 0.776083
I0822 11:38:02.853762 31776 solver.cpp:244]     Train net output #0: loss = 0.776083 (* 1 = 0.776083 loss)
I0822 11:38:02.853768 31776 sgd_solver.cpp:106] Iteration 14100, lr = 0.000670204
I0822 11:38:07.370870 31776 solver.cpp:228] Iteration 14200, loss = 0.720206
I0822 11:38:07.370930 31776 solver.cpp:244]     Train net output #0: loss = 0.720206 (* 1 = 0.720206 loss)
I0822 11:38:07.370936 31776 sgd_solver.cpp:106] Iteration 14200, lr = 0.000668733
I0822 11:38:11.896318 31776 solver.cpp:228] Iteration 14300, loss = 0.682531
I0822 11:38:11.896365 31776 solver.cpp:244]     Train net output #0: loss = 0.682531 (* 1 = 0.682531 loss)
I0822 11:38:11.896373 31776 sgd_solver.cpp:106] Iteration 14300, lr = 0.000667271
I0822 11:38:16.415081 31776 solver.cpp:228] Iteration 14400, loss = 0.691519
I0822 11:38:16.415132 31776 solver.cpp:244]     Train net output #0: loss = 0.691519 (* 1 = 0.691519 loss)
I0822 11:38:16.415138 31776 sgd_solver.cpp:106] Iteration 14400, lr = 0.000665815
I0822 11:38:20.896220 31776 solver.cpp:337] Iteration 14500, Testing net (#0)
I0822 11:38:21.475877 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:38:24.534679 31776 solver.cpp:404]     Test net output #0: accuracy = 0.738292
I0822 11:38:24.534729 31776 solver.cpp:404]     Test net output #1: loss = 0.593478 (* 1 = 0.593478 loss)
I0822 11:38:24.550976 31776 solver.cpp:228] Iteration 14500, loss = 0.718525
I0822 11:38:24.551057 31776 solver.cpp:244]     Train net output #0: loss = 0.718525 (* 1 = 0.718525 loss)
I0822 11:38:24.551080 31776 sgd_solver.cpp:106] Iteration 14500, lr = 0.000664367
I0822 11:38:29.076086 31776 solver.cpp:228] Iteration 14600, loss = 0.694956
I0822 11:38:29.076136 31776 solver.cpp:244]     Train net output #0: loss = 0.694956 (* 1 = 0.694956 loss)
I0822 11:38:29.076148 31776 sgd_solver.cpp:106] Iteration 14600, lr = 0.000662927
I0822 11:38:33.596175 31776 solver.cpp:228] Iteration 14700, loss = 0.655608
I0822 11:38:33.596215 31776 solver.cpp:244]     Train net output #0: loss = 0.655608 (* 1 = 0.655608 loss)
I0822 11:38:33.596221 31776 sgd_solver.cpp:106] Iteration 14700, lr = 0.000661493
I0822 11:38:38.113258 31776 solver.cpp:228] Iteration 14800, loss = 0.637158
I0822 11:38:38.113276 31776 solver.cpp:244]     Train net output #0: loss = 0.637158 (* 1 = 0.637158 loss)
I0822 11:38:38.113281 31776 sgd_solver.cpp:106] Iteration 14800, lr = 0.000660067
I0822 11:38:42.635707 31776 solver.cpp:228] Iteration 14900, loss = 0.651066
I0822 11:38:42.635745 31776 solver.cpp:244]     Train net output #0: loss = 0.651066 (* 1 = 0.651066 loss)
I0822 11:38:42.635751 31776 sgd_solver.cpp:106] Iteration 14900, lr = 0.000658648
I0822 11:38:47.111052 31776 solver.cpp:337] Iteration 15000, Testing net (#0)
I0822 11:38:50.787344 31776 solver.cpp:404]     Test net output #0: accuracy = 0.695292
I0822 11:38:50.787395 31776 solver.cpp:404]     Test net output #1: loss = 0.674626 (* 1 = 0.674626 loss)
I0822 11:38:50.802974 31776 solver.cpp:228] Iteration 15000, loss = 0.712402
I0822 11:38:50.803001 31776 solver.cpp:244]     Train net output #0: loss = 0.712402 (* 1 = 0.712402 loss)
I0822 11:38:50.803023 31776 sgd_solver.cpp:106] Iteration 15000, lr = 0.000657236
I0822 11:38:55.325767 31776 solver.cpp:228] Iteration 15100, loss = 0.669899
I0822 11:38:55.325830 31776 solver.cpp:244]     Train net output #0: loss = 0.669899 (* 1 = 0.669899 loss)
I0822 11:38:55.325844 31776 sgd_solver.cpp:106] Iteration 15100, lr = 0.000655831
I0822 11:38:59.841207 31776 solver.cpp:228] Iteration 15200, loss = 0.646194
I0822 11:38:59.841228 31776 solver.cpp:244]     Train net output #0: loss = 0.646194 (* 1 = 0.646194 loss)
I0822 11:38:59.841233 31776 sgd_solver.cpp:106] Iteration 15200, lr = 0.000654434
I0822 11:39:04.355059 31776 solver.cpp:228] Iteration 15300, loss = 0.646194
I0822 11:39:04.355087 31776 solver.cpp:244]     Train net output #0: loss = 0.646194 (* 1 = 0.646194 loss)
I0822 11:39:04.355098 31776 sgd_solver.cpp:106] Iteration 15300, lr = 0.000653043
I0822 11:39:08.884233 31776 solver.cpp:228] Iteration 15400, loss = 0.64081
I0822 11:39:08.884307 31776 solver.cpp:244]     Train net output #0: loss = 0.64081 (* 1 = 0.64081 loss)
I0822 11:39:08.884315 31776 sgd_solver.cpp:106] Iteration 15400, lr = 0.000651659
I0822 11:39:13.364336 31776 solver.cpp:337] Iteration 15500, Testing net (#0)
I0822 11:39:16.694744 31776 solver.cpp:404]     Test net output #0: accuracy = 0.728209
I0822 11:39:16.694780 31776 solver.cpp:404]     Test net output #1: loss = 0.614952 (* 1 = 0.614952 loss)
I0822 11:39:16.710683 31776 solver.cpp:228] Iteration 15500, loss = 0.717261
I0822 11:39:16.710757 31776 solver.cpp:244]     Train net output #0: loss = 0.717261 (* 1 = 0.717261 loss)
I0822 11:39:16.710773 31776 sgd_solver.cpp:106] Iteration 15500, lr = 0.000650281
I0822 11:39:21.241499 31776 solver.cpp:228] Iteration 15600, loss = 0.64902
I0822 11:39:21.241534 31776 solver.cpp:244]     Train net output #0: loss = 0.64902 (* 1 = 0.64902 loss)
I0822 11:39:21.241539 31776 sgd_solver.cpp:106] Iteration 15600, lr = 0.000648911
I0822 11:39:25.766434 31776 solver.cpp:228] Iteration 15700, loss = 0.787257
I0822 11:39:25.766472 31776 solver.cpp:244]     Train net output #0: loss = 0.787257 (* 1 = 0.787257 loss)
I0822 11:39:25.766479 31776 sgd_solver.cpp:106] Iteration 15700, lr = 0.000647547
I0822 11:39:30.286185 31776 solver.cpp:228] Iteration 15800, loss = 0.719757
I0822 11:39:30.286226 31776 solver.cpp:244]     Train net output #0: loss = 0.719757 (* 1 = 0.719757 loss)
I0822 11:39:30.286231 31776 sgd_solver.cpp:106] Iteration 15800, lr = 0.00064619
I0822 11:39:34.802863 31776 solver.cpp:228] Iteration 15900, loss = 0.685447
I0822 11:39:34.802903 31776 solver.cpp:244]     Train net output #0: loss = 0.685447 (* 1 = 0.685447 loss)
I0822 11:39:34.802908 31776 sgd_solver.cpp:106] Iteration 15900, lr = 0.00064484
I0822 11:39:39.283229 31776 solver.cpp:337] Iteration 16000, Testing net (#0)
I0822 11:39:42.751150 31776 solver.cpp:404]     Test net output #0: accuracy = 0.744625
I0822 11:39:42.751199 31776 solver.cpp:404]     Test net output #1: loss = 0.580378 (* 1 = 0.580378 loss)
I0822 11:39:42.766618 31776 solver.cpp:228] Iteration 16000, loss = 0.60062
I0822 11:39:42.766657 31776 solver.cpp:244]     Train net output #0: loss = 0.60062 (* 1 = 0.60062 loss)
I0822 11:39:42.766667 31776 sgd_solver.cpp:106] Iteration 16000, lr = 0.000643496
I0822 11:39:47.289767 31776 solver.cpp:228] Iteration 16100, loss = 0.660711
I0822 11:39:47.289805 31776 solver.cpp:244]     Train net output #0: loss = 0.660711 (* 1 = 0.660711 loss)
I0822 11:39:47.289811 31776 sgd_solver.cpp:106] Iteration 16100, lr = 0.000642158
I0822 11:39:51.805853 31776 solver.cpp:228] Iteration 16200, loss = 0.515025
I0822 11:39:51.805893 31776 solver.cpp:244]     Train net output #0: loss = 0.515025 (* 1 = 0.515025 loss)
I0822 11:39:51.805898 31776 sgd_solver.cpp:106] Iteration 16200, lr = 0.000640827
I0822 11:39:56.329808 31776 solver.cpp:228] Iteration 16300, loss = 0.657996
I0822 11:39:56.329846 31776 solver.cpp:244]     Train net output #0: loss = 0.657996 (* 1 = 0.657996 loss)
I0822 11:39:56.329851 31776 sgd_solver.cpp:106] Iteration 16300, lr = 0.000639503
I0822 11:40:00.851549 31776 solver.cpp:228] Iteration 16400, loss = 0.57301
I0822 11:40:00.851589 31776 solver.cpp:244]     Train net output #0: loss = 0.57301 (* 1 = 0.57301 loss)
I0822 11:40:00.851595 31776 sgd_solver.cpp:106] Iteration 16400, lr = 0.000638185
I0822 11:40:05.325654 31776 solver.cpp:337] Iteration 16500, Testing net (#0)
I0822 11:40:08.732774 31776 solver.cpp:404]     Test net output #0: accuracy = 0.745333
I0822 11:40:08.732816 31776 solver.cpp:404]     Test net output #1: loss = 0.578713 (* 1 = 0.578713 loss)
I0822 11:40:08.748080 31776 solver.cpp:228] Iteration 16500, loss = 0.623148
I0822 11:40:08.748111 31776 solver.cpp:244]     Train net output #0: loss = 0.623148 (* 1 = 0.623148 loss)
I0822 11:40:08.748119 31776 sgd_solver.cpp:106] Iteration 16500, lr = 0.000636873
I0822 11:40:13.278861 31776 solver.cpp:228] Iteration 16600, loss = 0.6361
I0822 11:40:13.278910 31776 solver.cpp:244]     Train net output #0: loss = 0.6361 (* 1 = 0.6361 loss)
I0822 11:40:13.278918 31776 sgd_solver.cpp:106] Iteration 16600, lr = 0.000635568
I0822 11:40:17.789258 31776 solver.cpp:228] Iteration 16700, loss = 0.620581
I0822 11:40:17.789274 31776 solver.cpp:244]     Train net output #0: loss = 0.620581 (* 1 = 0.620581 loss)
I0822 11:40:17.789279 31776 sgd_solver.cpp:106] Iteration 16700, lr = 0.000634268
I0822 11:40:22.306069 31776 solver.cpp:228] Iteration 16800, loss = 0.519024
I0822 11:40:22.306087 31776 solver.cpp:244]     Train net output #0: loss = 0.519024 (* 1 = 0.519024 loss)
I0822 11:40:22.306092 31776 sgd_solver.cpp:106] Iteration 16800, lr = 0.000632975
I0822 11:40:26.823509 31776 solver.cpp:228] Iteration 16900, loss = 0.541364
I0822 11:40:26.823560 31776 solver.cpp:244]     Train net output #0: loss = 0.541364 (* 1 = 0.541364 loss)
I0822 11:40:26.823567 31776 sgd_solver.cpp:106] Iteration 16900, lr = 0.000631688
I0822 11:40:31.298671 31776 solver.cpp:337] Iteration 17000, Testing net (#0)
I0822 11:40:34.491554 31776 solver.cpp:404]     Test net output #0: accuracy = 0.724083
I0822 11:40:34.491611 31776 solver.cpp:404]     Test net output #1: loss = 0.618897 (* 1 = 0.618897 loss)
I0822 11:40:34.507302 31776 solver.cpp:228] Iteration 17000, loss = 0.560918
I0822 11:40:34.507355 31776 solver.cpp:244]     Train net output #0: loss = 0.560918 (* 1 = 0.560918 loss)
I0822 11:40:34.507369 31776 sgd_solver.cpp:106] Iteration 17000, lr = 0.000630407
I0822 11:40:39.030280 31776 solver.cpp:228] Iteration 17100, loss = 0.694856
I0822 11:40:39.030345 31776 solver.cpp:244]     Train net output #0: loss = 0.694856 (* 1 = 0.694856 loss)
I0822 11:40:39.030364 31776 sgd_solver.cpp:106] Iteration 17100, lr = 0.000629132
I0822 11:40:43.563678 31776 solver.cpp:228] Iteration 17200, loss = 0.560874
I0822 11:40:43.563731 31776 solver.cpp:244]     Train net output #0: loss = 0.560874 (* 1 = 0.560874 loss)
I0822 11:40:43.563741 31776 sgd_solver.cpp:106] Iteration 17200, lr = 0.000627864
I0822 11:40:48.089334 31776 solver.cpp:228] Iteration 17300, loss = 0.58138
I0822 11:40:48.089388 31776 solver.cpp:244]     Train net output #0: loss = 0.58138 (* 1 = 0.58138 loss)
I0822 11:40:48.089396 31776 sgd_solver.cpp:106] Iteration 17300, lr = 0.000626601
I0822 11:40:52.609798 31776 solver.cpp:228] Iteration 17400, loss = 0.587129
I0822 11:40:52.609839 31776 solver.cpp:244]     Train net output #0: loss = 0.587129 (* 1 = 0.587129 loss)
I0822 11:40:52.609845 31776 sgd_solver.cpp:106] Iteration 17400, lr = 0.000625344
I0822 11:40:57.085731 31776 solver.cpp:337] Iteration 17500, Testing net (#0)
I0822 11:40:58.150526 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:41:00.359005 31776 solver.cpp:404]     Test net output #0: accuracy = 0.752792
I0822 11:41:00.359030 31776 solver.cpp:404]     Test net output #1: loss = 0.563203 (* 1 = 0.563203 loss)
I0822 11:41:00.374451 31776 solver.cpp:228] Iteration 17500, loss = 0.602547
I0822 11:41:00.374471 31776 solver.cpp:244]     Train net output #0: loss = 0.602547 (* 1 = 0.602547 loss)
I0822 11:41:00.374495 31776 sgd_solver.cpp:106] Iteration 17500, lr = 0.000624093
I0822 11:41:04.897403 31776 solver.cpp:228] Iteration 17600, loss = 0.62454
I0822 11:41:04.897452 31776 solver.cpp:244]     Train net output #0: loss = 0.62454 (* 1 = 0.62454 loss)
I0822 11:41:04.897462 31776 sgd_solver.cpp:106] Iteration 17600, lr = 0.000622847
I0822 11:41:09.409907 31776 solver.cpp:228] Iteration 17700, loss = 0.597346
I0822 11:41:09.409972 31776 solver.cpp:244]     Train net output #0: loss = 0.597346 (* 1 = 0.597346 loss)
I0822 11:41:09.409984 31776 sgd_solver.cpp:106] Iteration 17700, lr = 0.000621608
I0822 11:41:13.932754 31776 solver.cpp:228] Iteration 17800, loss = 0.502536
I0822 11:41:13.932791 31776 solver.cpp:244]     Train net output #0: loss = 0.502536 (* 1 = 0.502536 loss)
I0822 11:41:13.932797 31776 sgd_solver.cpp:106] Iteration 17800, lr = 0.000620374
I0822 11:41:18.448843 31776 solver.cpp:228] Iteration 17900, loss = 0.615332
I0822 11:41:18.448884 31776 solver.cpp:244]     Train net output #0: loss = 0.615332 (* 1 = 0.615332 loss)
I0822 11:41:18.448889 31776 sgd_solver.cpp:106] Iteration 17900, lr = 0.000619146
I0822 11:41:22.921995 31776 solver.cpp:337] Iteration 18000, Testing net (#0)
I0822 11:41:26.525424 31776 solver.cpp:404]     Test net output #0: accuracy = 0.744667
I0822 11:41:26.525478 31776 solver.cpp:404]     Test net output #1: loss = 0.588797 (* 1 = 0.588797 loss)
I0822 11:41:26.541748 31776 solver.cpp:228] Iteration 18000, loss = 0.52529
I0822 11:41:26.541805 31776 solver.cpp:244]     Train net output #0: loss = 0.52529 (* 1 = 0.52529 loss)
I0822 11:41:26.541818 31776 sgd_solver.cpp:106] Iteration 18000, lr = 0.000617924
I0822 11:41:31.060143 31776 solver.cpp:228] Iteration 18100, loss = 0.603507
I0822 11:41:31.060205 31776 solver.cpp:244]     Train net output #0: loss = 0.603507 (* 1 = 0.603507 loss)
I0822 11:41:31.060211 31776 sgd_solver.cpp:106] Iteration 18100, lr = 0.000616707
I0822 11:41:35.593545 31776 solver.cpp:228] Iteration 18200, loss = 0.549884
I0822 11:41:35.593603 31776 solver.cpp:244]     Train net output #0: loss = 0.549884 (* 1 = 0.549884 loss)
I0822 11:41:35.593612 31776 sgd_solver.cpp:106] Iteration 18200, lr = 0.000615496
I0822 11:41:40.125635 31776 solver.cpp:228] Iteration 18300, loss = 0.521557
I0822 11:41:40.125691 31776 solver.cpp:244]     Train net output #0: loss = 0.521557 (* 1 = 0.521557 loss)
I0822 11:41:40.125700 31776 sgd_solver.cpp:106] Iteration 18300, lr = 0.00061429
I0822 11:41:44.654775 31776 solver.cpp:228] Iteration 18400, loss = 0.480803
I0822 11:41:44.654837 31776 solver.cpp:244]     Train net output #0: loss = 0.480803 (* 1 = 0.480803 loss)
I0822 11:41:44.654846 31776 sgd_solver.cpp:106] Iteration 18400, lr = 0.00061309
I0822 11:41:49.131878 31776 solver.cpp:337] Iteration 18500, Testing net (#0)
I0822 11:41:52.341053 31776 solver.cpp:404]     Test net output #0: accuracy = 0.756958
I0822 11:41:52.341099 31776 solver.cpp:404]     Test net output #1: loss = 0.558518 (* 1 = 0.558518 loss)
I0822 11:41:52.356436 31776 solver.cpp:228] Iteration 18500, loss = 0.590668
I0822 11:41:52.356487 31776 solver.cpp:244]     Train net output #0: loss = 0.590668 (* 1 = 0.590668 loss)
I0822 11:41:52.356498 31776 sgd_solver.cpp:106] Iteration 18500, lr = 0.000611895
I0822 11:41:56.880589 31776 solver.cpp:228] Iteration 18600, loss = 0.606693
I0822 11:41:56.880646 31776 solver.cpp:244]     Train net output #0: loss = 0.606693 (* 1 = 0.606693 loss)
I0822 11:41:56.880657 31776 sgd_solver.cpp:106] Iteration 18600, lr = 0.000610706
I0822 11:42:01.404287 31776 solver.cpp:228] Iteration 18700, loss = 0.55922
I0822 11:42:01.404342 31776 solver.cpp:244]     Train net output #0: loss = 0.55922 (* 1 = 0.55922 loss)
I0822 11:42:01.404351 31776 sgd_solver.cpp:106] Iteration 18700, lr = 0.000609522
I0822 11:42:05.929059 31776 solver.cpp:228] Iteration 18800, loss = 0.638664
I0822 11:42:05.929118 31776 solver.cpp:244]     Train net output #0: loss = 0.638664 (* 1 = 0.638664 loss)
I0822 11:42:05.929127 31776 sgd_solver.cpp:106] Iteration 18800, lr = 0.000608343
I0822 11:42:10.453299 31776 solver.cpp:228] Iteration 18900, loss = 0.612037
I0822 11:42:10.453352 31776 solver.cpp:244]     Train net output #0: loss = 0.612037 (* 1 = 0.612037 loss)
I0822 11:42:10.453361 31776 sgd_solver.cpp:106] Iteration 18900, lr = 0.00060717
I0822 11:42:14.927640 31776 solver.cpp:337] Iteration 19000, Testing net (#0)
I0822 11:42:18.423938 31776 solver.cpp:404]     Test net output #0: accuracy = 0.779291
I0822 11:42:18.423997 31776 solver.cpp:404]     Test net output #1: loss = 0.508597 (* 1 = 0.508597 loss)
I0822 11:42:18.439484 31776 solver.cpp:228] Iteration 19000, loss = 0.484996
I0822 11:42:18.439553 31776 solver.cpp:244]     Train net output #0: loss = 0.484996 (* 1 = 0.484996 loss)
I0822 11:42:18.439568 31776 sgd_solver.cpp:106] Iteration 19000, lr = 0.000606002
I0822 11:42:22.965661 31776 solver.cpp:228] Iteration 19100, loss = 0.59983
I0822 11:42:22.965714 31776 solver.cpp:244]     Train net output #0: loss = 0.59983 (* 1 = 0.59983 loss)
I0822 11:42:22.965728 31776 sgd_solver.cpp:106] Iteration 19100, lr = 0.000604839
I0822 11:42:27.488241 31776 solver.cpp:228] Iteration 19200, loss = 0.542291
I0822 11:42:27.488297 31776 solver.cpp:244]     Train net output #0: loss = 0.542291 (* 1 = 0.542291 loss)
I0822 11:42:27.488306 31776 sgd_solver.cpp:106] Iteration 19200, lr = 0.000603682
I0822 11:42:32.014312 31776 solver.cpp:228] Iteration 19300, loss = 0.516419
I0822 11:42:32.014370 31776 solver.cpp:244]     Train net output #0: loss = 0.516419 (* 1 = 0.516419 loss)
I0822 11:42:32.014379 31776 sgd_solver.cpp:106] Iteration 19300, lr = 0.000602529
I0822 11:42:36.541901 31776 solver.cpp:228] Iteration 19400, loss = 0.51874
I0822 11:42:36.541965 31776 solver.cpp:244]     Train net output #0: loss = 0.51874 (* 1 = 0.51874 loss)
I0822 11:42:36.541973 31776 sgd_solver.cpp:106] Iteration 19400, lr = 0.000601382
I0822 11:42:41.020457 31776 solver.cpp:337] Iteration 19500, Testing net (#0)
I0822 11:42:44.299055 31776 solver.cpp:404]     Test net output #0: accuracy = 0.759458
I0822 11:42:44.299109 31776 solver.cpp:404]     Test net output #1: loss = 0.563438 (* 1 = 0.563438 loss)
I0822 11:42:44.315536 31776 solver.cpp:228] Iteration 19500, loss = 0.526333
I0822 11:42:44.315598 31776 solver.cpp:244]     Train net output #0: loss = 0.526333 (* 1 = 0.526333 loss)
I0822 11:42:44.315611 31776 sgd_solver.cpp:106] Iteration 19500, lr = 0.00060024
I0822 11:42:48.838516 31776 solver.cpp:228] Iteration 19600, loss = 0.535367
I0822 11:42:48.838572 31776 solver.cpp:244]     Train net output #0: loss = 0.535367 (* 1 = 0.535367 loss)
I0822 11:42:48.838580 31776 sgd_solver.cpp:106] Iteration 19600, lr = 0.000599102
I0822 11:42:53.360865 31776 solver.cpp:228] Iteration 19700, loss = 0.483323
I0822 11:42:53.360919 31776 solver.cpp:244]     Train net output #0: loss = 0.483323 (* 1 = 0.483323 loss)
I0822 11:42:53.360927 31776 sgd_solver.cpp:106] Iteration 19700, lr = 0.00059797
I0822 11:42:57.887958 31776 solver.cpp:228] Iteration 19800, loss = 0.493061
I0822 11:42:57.888010 31776 solver.cpp:244]     Train net output #0: loss = 0.493061 (* 1 = 0.493061 loss)
I0822 11:42:57.888018 31776 sgd_solver.cpp:106] Iteration 19800, lr = 0.000596843
I0822 11:43:02.413610 31776 solver.cpp:228] Iteration 19900, loss = 0.634828
I0822 11:43:02.413676 31776 solver.cpp:244]     Train net output #0: loss = 0.634828 (* 1 = 0.634828 loss)
I0822 11:43:02.413684 31776 sgd_solver.cpp:106] Iteration 19900, lr = 0.000595721
I0822 11:43:06.892460 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_20000.caffemodel
I0822 11:43:07.367365 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_20000.solverstate
I0822 11:43:07.522778 31776 solver.cpp:337] Iteration 20000, Testing net (#0)
I0822 11:43:10.732301 31776 solver.cpp:404]     Test net output #0: accuracy = 0.780917
I0822 11:43:10.732365 31776 solver.cpp:404]     Test net output #1: loss = 0.509744 (* 1 = 0.509744 loss)
I0822 11:43:10.747714 31776 solver.cpp:228] Iteration 20000, loss = 0.595057
I0822 11:43:10.747784 31776 solver.cpp:244]     Train net output #0: loss = 0.595057 (* 1 = 0.595057 loss)
I0822 11:43:10.747793 31776 sgd_solver.cpp:106] Iteration 20000, lr = 0.000594604
I0822 11:43:15.270282 31776 solver.cpp:228] Iteration 20100, loss = 0.556412
I0822 11:43:15.270325 31776 solver.cpp:244]     Train net output #0: loss = 0.556412 (* 1 = 0.556412 loss)
I0822 11:43:15.270334 31776 sgd_solver.cpp:106] Iteration 20100, lr = 0.000593491
I0822 11:43:19.792099 31776 solver.cpp:228] Iteration 20200, loss = 0.580988
I0822 11:43:19.792171 31776 solver.cpp:244]     Train net output #0: loss = 0.580988 (* 1 = 0.580988 loss)
I0822 11:43:19.792179 31776 sgd_solver.cpp:106] Iteration 20200, lr = 0.000592384
I0822 11:43:24.316707 31776 solver.cpp:228] Iteration 20300, loss = 0.541269
I0822 11:43:24.316769 31776 solver.cpp:244]     Train net output #0: loss = 0.541269 (* 1 = 0.541269 loss)
I0822 11:43:24.316778 31776 sgd_solver.cpp:106] Iteration 20300, lr = 0.000591281
I0822 11:43:28.844696 31776 solver.cpp:228] Iteration 20400, loss = 0.549544
I0822 11:43:28.844751 31776 solver.cpp:244]     Train net output #0: loss = 0.549544 (* 1 = 0.549544 loss)
I0822 11:43:28.844760 31776 sgd_solver.cpp:106] Iteration 20400, lr = 0.000590183
I0822 11:43:33.325312 31776 solver.cpp:337] Iteration 20500, Testing net (#0)
I0822 11:43:36.565675 31776 solver.cpp:404]     Test net output #0: accuracy = 0.795833
I0822 11:43:36.565734 31776 solver.cpp:404]     Test net output #1: loss = 0.476303 (* 1 = 0.476303 loss)
I0822 11:43:36.581187 31776 solver.cpp:228] Iteration 20500, loss = 0.3953
I0822 11:43:36.581257 31776 solver.cpp:244]     Train net output #0: loss = 0.3953 (* 1 = 0.3953 loss)
I0822 11:43:36.581269 31776 sgd_solver.cpp:106] Iteration 20500, lr = 0.000589089
I0822 11:43:41.104519 31776 solver.cpp:228] Iteration 20600, loss = 0.429718
I0822 11:43:41.104575 31776 solver.cpp:244]     Train net output #0: loss = 0.429718 (* 1 = 0.429718 loss)
I0822 11:43:41.104583 31776 sgd_solver.cpp:106] Iteration 20600, lr = 0.000588001
I0822 11:43:45.631336 31776 solver.cpp:228] Iteration 20700, loss = 0.449371
I0822 11:43:45.631388 31776 solver.cpp:244]     Train net output #0: loss = 0.449371 (* 1 = 0.449371 loss)
I0822 11:43:45.631397 31776 sgd_solver.cpp:106] Iteration 20700, lr = 0.000586917
I0822 11:43:50.154207 31776 solver.cpp:228] Iteration 20800, loss = 0.42747
I0822 11:43:50.154260 31776 solver.cpp:244]     Train net output #0: loss = 0.42747 (* 1 = 0.42747 loss)
I0822 11:43:50.154269 31776 sgd_solver.cpp:106] Iteration 20800, lr = 0.000585838
I0822 11:43:54.676091 31776 solver.cpp:228] Iteration 20900, loss = 0.536684
I0822 11:43:54.676162 31776 solver.cpp:244]     Train net output #0: loss = 0.536684 (* 1 = 0.536684 loss)
I0822 11:43:54.676172 31776 sgd_solver.cpp:106] Iteration 20900, lr = 0.000584763
I0822 11:43:59.157430 31776 solver.cpp:337] Iteration 21000, Testing net (#0)
I0822 11:44:02.399269 31776 solver.cpp:404]     Test net output #0: accuracy = 0.753333
I0822 11:44:02.399339 31776 solver.cpp:404]     Test net output #1: loss = 0.584329 (* 1 = 0.584329 loss)
I0822 11:44:02.414918 31776 solver.cpp:228] Iteration 21000, loss = 0.594547
I0822 11:44:02.414990 31776 solver.cpp:244]     Train net output #0: loss = 0.594547 (* 1 = 0.594547 loss)
I0822 11:44:02.415001 31776 sgd_solver.cpp:106] Iteration 21000, lr = 0.000583693
I0822 11:44:06.936367 31776 solver.cpp:228] Iteration 21100, loss = 0.427883
I0822 11:44:06.936420 31776 solver.cpp:244]     Train net output #0: loss = 0.427883 (* 1 = 0.427883 loss)
I0822 11:44:06.936429 31776 sgd_solver.cpp:106] Iteration 21100, lr = 0.000582628
I0822 11:44:11.461699 31776 solver.cpp:228] Iteration 21200, loss = 0.495131
I0822 11:44:11.461753 31776 solver.cpp:244]     Train net output #0: loss = 0.495131 (* 1 = 0.495131 loss)
I0822 11:44:11.461761 31776 sgd_solver.cpp:106] Iteration 21200, lr = 0.000581567
I0822 11:44:15.981300 31776 solver.cpp:228] Iteration 21300, loss = 0.560564
I0822 11:44:15.981353 31776 solver.cpp:244]     Train net output #0: loss = 0.560564 (* 1 = 0.560564 loss)
I0822 11:44:15.981361 31776 sgd_solver.cpp:106] Iteration 21300, lr = 0.00058051
I0822 11:44:20.499917 31776 solver.cpp:228] Iteration 21400, loss = 0.510599
I0822 11:44:20.499979 31776 solver.cpp:244]     Train net output #0: loss = 0.510599 (* 1 = 0.510599 loss)
I0822 11:44:20.499989 31776 sgd_solver.cpp:106] Iteration 21400, lr = 0.000579458
I0822 11:44:24.979434 31776 solver.cpp:337] Iteration 21500, Testing net (#0)
I0822 11:44:28.239980 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8025
I0822 11:44:28.240038 31776 solver.cpp:404]     Test net output #1: loss = 0.463508 (* 1 = 0.463508 loss)
I0822 11:44:28.255537 31776 solver.cpp:228] Iteration 21500, loss = 0.394786
I0822 11:44:28.255601 31776 solver.cpp:244]     Train net output #0: loss = 0.394786 (* 1 = 0.394786 loss)
I0822 11:44:28.255615 31776 sgd_solver.cpp:106] Iteration 21500, lr = 0.000578411
I0822 11:44:32.780853 31776 solver.cpp:228] Iteration 21600, loss = 0.42345
I0822 11:44:32.780910 31776 solver.cpp:244]     Train net output #0: loss = 0.42345 (* 1 = 0.42345 loss)
I0822 11:44:32.780921 31776 sgd_solver.cpp:106] Iteration 21600, lr = 0.000577368
I0822 11:44:37.304831 31776 solver.cpp:228] Iteration 21700, loss = 0.424494
I0822 11:44:37.304883 31776 solver.cpp:244]     Train net output #0: loss = 0.424494 (* 1 = 0.424494 loss)
I0822 11:44:37.304893 31776 sgd_solver.cpp:106] Iteration 21700, lr = 0.000576329
I0822 11:44:41.832684 31776 solver.cpp:228] Iteration 21800, loss = 0.483974
I0822 11:44:41.832737 31776 solver.cpp:244]     Train net output #0: loss = 0.483974 (* 1 = 0.483974 loss)
I0822 11:44:41.832746 31776 sgd_solver.cpp:106] Iteration 21800, lr = 0.000575295
I0822 11:44:46.355273 31776 solver.cpp:228] Iteration 21900, loss = 0.433089
I0822 11:44:46.355331 31776 solver.cpp:244]     Train net output #0: loss = 0.433089 (* 1 = 0.433089 loss)
I0822 11:44:46.355340 31776 sgd_solver.cpp:106] Iteration 21900, lr = 0.000574265
I0822 11:44:50.835096 31776 solver.cpp:337] Iteration 22000, Testing net (#0)
I0822 11:44:54.060572 31776 solver.cpp:404]     Test net output #0: accuracy = 0.790292
I0822 11:44:54.060637 31776 solver.cpp:404]     Test net output #1: loss = 0.500544 (* 1 = 0.500544 loss)
I0822 11:44:54.076197 31776 solver.cpp:228] Iteration 22000, loss = 0.457462
I0822 11:44:54.076277 31776 solver.cpp:244]     Train net output #0: loss = 0.457462 (* 1 = 0.457462 loss)
I0822 11:44:54.076288 31776 sgd_solver.cpp:106] Iteration 22000, lr = 0.000573239
I0822 11:44:58.597039 31776 solver.cpp:228] Iteration 22100, loss = 0.34583
I0822 11:44:58.597093 31776 solver.cpp:244]     Train net output #0: loss = 0.34583 (* 1 = 0.34583 loss)
I0822 11:44:58.597102 31776 sgd_solver.cpp:106] Iteration 22100, lr = 0.000572217
I0822 11:45:03.115736 31776 solver.cpp:228] Iteration 22200, loss = 0.429976
I0822 11:45:03.115795 31776 solver.cpp:244]     Train net output #0: loss = 0.429976 (* 1 = 0.429976 loss)
I0822 11:45:03.115803 31776 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005712
I0822 11:45:07.637069 31776 solver.cpp:228] Iteration 22300, loss = 0.379543
I0822 11:45:07.637126 31776 solver.cpp:244]     Train net output #0: loss = 0.379543 (* 1 = 0.379543 loss)
I0822 11:45:07.637136 31776 sgd_solver.cpp:106] Iteration 22300, lr = 0.000570187
I0822 11:45:12.158133 31776 solver.cpp:228] Iteration 22400, loss = 0.38088
I0822 11:45:12.158193 31776 solver.cpp:244]     Train net output #0: loss = 0.38088 (* 1 = 0.38088 loss)
I0822 11:45:12.158206 31776 sgd_solver.cpp:106] Iteration 22400, lr = 0.000569178
I0822 11:45:16.632328 31776 solver.cpp:337] Iteration 22500, Testing net (#0)
I0822 11:45:17.034476 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:45:19.843619 31776 solver.cpp:404]     Test net output #0: accuracy = 0.806833
I0822 11:45:19.843669 31776 solver.cpp:404]     Test net output #1: loss = 0.458559 (* 1 = 0.458559 loss)
I0822 11:45:19.861078 31776 solver.cpp:228] Iteration 22500, loss = 0.47418
I0822 11:45:19.861132 31776 solver.cpp:244]     Train net output #0: loss = 0.47418 (* 1 = 0.47418 loss)
I0822 11:45:19.861143 31776 sgd_solver.cpp:106] Iteration 22500, lr = 0.000568173
I0822 11:45:24.379818 31776 solver.cpp:228] Iteration 22600, loss = 0.413794
I0822 11:45:24.379881 31776 solver.cpp:244]     Train net output #0: loss = 0.413794 (* 1 = 0.413794 loss)
I0822 11:45:24.379889 31776 sgd_solver.cpp:106] Iteration 22600, lr = 0.000567173
I0822 11:45:28.899185 31776 solver.cpp:228] Iteration 22700, loss = 0.347332
I0822 11:45:28.899240 31776 solver.cpp:244]     Train net output #0: loss = 0.347332 (* 1 = 0.347332 loss)
I0822 11:45:28.899250 31776 sgd_solver.cpp:106] Iteration 22700, lr = 0.000566176
I0822 11:45:33.422533 31776 solver.cpp:228] Iteration 22800, loss = 0.481253
I0822 11:45:33.422585 31776 solver.cpp:244]     Train net output #0: loss = 0.481253 (* 1 = 0.481253 loss)
I0822 11:45:33.422595 31776 sgd_solver.cpp:106] Iteration 22800, lr = 0.000565184
I0822 11:45:37.945416 31776 solver.cpp:228] Iteration 22900, loss = 0.525658
I0822 11:45:37.945469 31776 solver.cpp:244]     Train net output #0: loss = 0.525658 (* 1 = 0.525658 loss)
I0822 11:45:37.945477 31776 sgd_solver.cpp:106] Iteration 22900, lr = 0.000564195
I0822 11:45:42.421891 31776 solver.cpp:337] Iteration 23000, Testing net (#0)
I0822 11:45:45.733795 31776 solver.cpp:404]     Test net output #0: accuracy = 0.811083
I0822 11:45:45.733858 31776 solver.cpp:404]     Test net output #1: loss = 0.450712 (* 1 = 0.450712 loss)
I0822 11:45:45.749102 31776 solver.cpp:228] Iteration 23000, loss = 0.436499
I0822 11:45:45.749176 31776 solver.cpp:244]     Train net output #0: loss = 0.436499 (* 1 = 0.436499 loss)
I0822 11:45:45.749186 31776 sgd_solver.cpp:106] Iteration 23000, lr = 0.000563211
I0822 11:45:50.270829 31776 solver.cpp:228] Iteration 23100, loss = 0.429566
I0822 11:45:50.270886 31776 solver.cpp:244]     Train net output #0: loss = 0.429566 (* 1 = 0.429566 loss)
I0822 11:45:50.270896 31776 sgd_solver.cpp:106] Iteration 23100, lr = 0.000562231
I0822 11:45:54.797173 31776 solver.cpp:228] Iteration 23200, loss = 0.383806
I0822 11:45:54.797229 31776 solver.cpp:244]     Train net output #0: loss = 0.383806 (* 1 = 0.383806 loss)
I0822 11:45:54.797236 31776 sgd_solver.cpp:106] Iteration 23200, lr = 0.000561254
I0822 11:45:59.318869 31776 solver.cpp:228] Iteration 23300, loss = 0.471828
I0822 11:45:59.318924 31776 solver.cpp:244]     Train net output #0: loss = 0.471828 (* 1 = 0.471828 loss)
I0822 11:45:59.318933 31776 sgd_solver.cpp:106] Iteration 23300, lr = 0.000560282
I0822 11:46:03.844362 31776 solver.cpp:228] Iteration 23400, loss = 0.485714
I0822 11:46:03.844419 31776 solver.cpp:244]     Train net output #0: loss = 0.485714 (* 1 = 0.485714 loss)
I0822 11:46:03.844429 31776 sgd_solver.cpp:106] Iteration 23400, lr = 0.000559313
I0822 11:46:08.318814 31776 solver.cpp:337] Iteration 23500, Testing net (#0)
I0822 11:46:11.596753 31776 solver.cpp:404]     Test net output #0: accuracy = 0.78875
I0822 11:46:11.596812 31776 solver.cpp:404]     Test net output #1: loss = 0.509783 (* 1 = 0.509783 loss)
I0822 11:46:11.612249 31776 solver.cpp:228] Iteration 23500, loss = 0.528786
I0822 11:46:11.612316 31776 solver.cpp:244]     Train net output #0: loss = 0.528786 (* 1 = 0.528786 loss)
I0822 11:46:11.612326 31776 sgd_solver.cpp:106] Iteration 23500, lr = 0.000558349
I0822 11:46:16.132630 31776 solver.cpp:228] Iteration 23600, loss = 0.457169
I0822 11:46:16.132689 31776 solver.cpp:244]     Train net output #0: loss = 0.457169 (* 1 = 0.457169 loss)
I0822 11:46:16.132697 31776 sgd_solver.cpp:106] Iteration 23600, lr = 0.000557388
I0822 11:46:20.652709 31776 solver.cpp:228] Iteration 23700, loss = 0.416488
I0822 11:46:20.652765 31776 solver.cpp:244]     Train net output #0: loss = 0.416488 (* 1 = 0.416488 loss)
I0822 11:46:20.652772 31776 sgd_solver.cpp:106] Iteration 23700, lr = 0.000556431
I0822 11:46:25.168936 31776 solver.cpp:228] Iteration 23800, loss = 0.320114
I0822 11:46:25.168990 31776 solver.cpp:244]     Train net output #0: loss = 0.320114 (* 1 = 0.320114 loss)
I0822 11:46:25.168999 31776 sgd_solver.cpp:106] Iteration 23800, lr = 0.000555478
I0822 11:46:29.691493 31776 solver.cpp:228] Iteration 23900, loss = 0.362381
I0822 11:46:29.691550 31776 solver.cpp:244]     Train net output #0: loss = 0.362381 (* 1 = 0.362381 loss)
I0822 11:46:29.691557 31776 sgd_solver.cpp:106] Iteration 23900, lr = 0.000554529
I0822 11:46:34.166185 31776 solver.cpp:337] Iteration 24000, Testing net (#0)
I0822 11:46:37.440665 31776 solver.cpp:404]     Test net output #0: accuracy = 0.81275
I0822 11:46:37.440721 31776 solver.cpp:404]     Test net output #1: loss = 0.453345 (* 1 = 0.453345 loss)
I0822 11:46:37.456104 31776 solver.cpp:228] Iteration 24000, loss = 0.328065
I0822 11:46:37.456194 31776 solver.cpp:244]     Train net output #0: loss = 0.328065 (* 1 = 0.328065 loss)
I0822 11:46:37.456207 31776 sgd_solver.cpp:106] Iteration 24000, lr = 0.000553583
I0822 11:46:41.977982 31776 solver.cpp:228] Iteration 24100, loss = 0.35235
I0822 11:46:41.978040 31776 solver.cpp:244]     Train net output #0: loss = 0.35235 (* 1 = 0.35235 loss)
I0822 11:46:41.978049 31776 sgd_solver.cpp:106] Iteration 24100, lr = 0.000552642
I0822 11:46:46.499377 31776 solver.cpp:228] Iteration 24200, loss = 0.477715
I0822 11:46:46.499434 31776 solver.cpp:244]     Train net output #0: loss = 0.477715 (* 1 = 0.477715 loss)
I0822 11:46:46.499444 31776 sgd_solver.cpp:106] Iteration 24200, lr = 0.000551704
I0822 11:46:51.016693 31776 solver.cpp:228] Iteration 24300, loss = 0.341459
I0822 11:46:51.016741 31776 solver.cpp:244]     Train net output #0: loss = 0.341459 (* 1 = 0.341459 loss)
I0822 11:46:51.016749 31776 sgd_solver.cpp:106] Iteration 24300, lr = 0.000550769
I0822 11:46:55.542698 31776 solver.cpp:228] Iteration 24400, loss = 0.395452
I0822 11:46:55.542749 31776 solver.cpp:244]     Train net output #0: loss = 0.395452 (* 1 = 0.395452 loss)
I0822 11:46:55.542758 31776 sgd_solver.cpp:106] Iteration 24400, lr = 0.000549839
I0822 11:47:00.022908 31776 solver.cpp:337] Iteration 24500, Testing net (#0)
I0822 11:47:03.305611 31776 solver.cpp:404]     Test net output #0: accuracy = 0.829167
I0822 11:47:03.305670 31776 solver.cpp:404]     Test net output #1: loss = 0.419719 (* 1 = 0.419719 loss)
I0822 11:47:03.321173 31776 solver.cpp:228] Iteration 24500, loss = 0.457428
I0822 11:47:03.321244 31776 solver.cpp:244]     Train net output #0: loss = 0.457428 (* 1 = 0.457428 loss)
I0822 11:47:03.321252 31776 sgd_solver.cpp:106] Iteration 24500, lr = 0.000548912
I0822 11:47:07.841311 31776 solver.cpp:228] Iteration 24600, loss = 0.459384
I0822 11:47:07.841367 31776 solver.cpp:244]     Train net output #0: loss = 0.459384 (* 1 = 0.459384 loss)
I0822 11:47:07.841374 31776 sgd_solver.cpp:106] Iteration 24600, lr = 0.000547988
I0822 11:47:12.360422 31776 solver.cpp:228] Iteration 24700, loss = 0.512946
I0822 11:47:12.360489 31776 solver.cpp:244]     Train net output #0: loss = 0.512946 (* 1 = 0.512946 loss)
I0822 11:47:12.360499 31776 sgd_solver.cpp:106] Iteration 24700, lr = 0.000547069
I0822 11:47:16.882067 31776 solver.cpp:228] Iteration 24800, loss = 0.448556
I0822 11:47:16.882122 31776 solver.cpp:244]     Train net output #0: loss = 0.448556 (* 1 = 0.448556 loss)
I0822 11:47:16.882131 31776 sgd_solver.cpp:106] Iteration 24800, lr = 0.000546153
I0822 11:47:21.400007 31776 solver.cpp:228] Iteration 24900, loss = 0.363378
I0822 11:47:21.400059 31776 solver.cpp:244]     Train net output #0: loss = 0.363378 (* 1 = 0.363378 loss)
I0822 11:47:21.400068 31776 sgd_solver.cpp:106] Iteration 24900, lr = 0.00054524
I0822 11:47:25.873610 31776 solver.cpp:337] Iteration 25000, Testing net (#0)
I0822 11:47:29.155823 31776 solver.cpp:404]     Test net output #0: accuracy = 0.823709
I0822 11:47:29.155884 31776 solver.cpp:404]     Test net output #1: loss = 0.434872 (* 1 = 0.434872 loss)
I0822 11:47:29.171281 31776 solver.cpp:228] Iteration 25000, loss = 0.347008
I0822 11:47:29.171344 31776 solver.cpp:244]     Train net output #0: loss = 0.347008 (* 1 = 0.347008 loss)
I0822 11:47:29.171358 31776 sgd_solver.cpp:106] Iteration 25000, lr = 0.000544331
I0822 11:47:33.689338 31776 solver.cpp:228] Iteration 25100, loss = 0.365806
I0822 11:47:33.689393 31776 solver.cpp:244]     Train net output #0: loss = 0.365806 (* 1 = 0.365806 loss)
I0822 11:47:33.689402 31776 sgd_solver.cpp:106] Iteration 25100, lr = 0.000543426
I0822 11:47:38.208389 31776 solver.cpp:228] Iteration 25200, loss = 0.501686
I0822 11:47:38.208441 31776 solver.cpp:244]     Train net output #0: loss = 0.501686 (* 1 = 0.501686 loss)
I0822 11:47:38.208451 31776 sgd_solver.cpp:106] Iteration 25200, lr = 0.000542524
I0822 11:47:42.732270 31776 solver.cpp:228] Iteration 25300, loss = 0.444748
I0822 11:47:42.732324 31776 solver.cpp:244]     Train net output #0: loss = 0.444748 (* 1 = 0.444748 loss)
I0822 11:47:42.732332 31776 sgd_solver.cpp:106] Iteration 25300, lr = 0.000541625
I0822 11:47:47.255525 31776 solver.cpp:228] Iteration 25400, loss = 0.371819
I0822 11:47:47.255584 31776 solver.cpp:244]     Train net output #0: loss = 0.371819 (* 1 = 0.371819 loss)
I0822 11:47:47.255594 31776 sgd_solver.cpp:106] Iteration 25400, lr = 0.00054073
I0822 11:47:51.727200 31776 solver.cpp:337] Iteration 25500, Testing net (#0)
I0822 11:47:54.949242 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83
I0822 11:47:54.949313 31776 solver.cpp:404]     Test net output #1: loss = 0.422383 (* 1 = 0.422383 loss)
I0822 11:47:54.964752 31776 solver.cpp:228] Iteration 25500, loss = 0.421742
I0822 11:47:54.964821 31776 solver.cpp:244]     Train net output #0: loss = 0.421742 (* 1 = 0.421742 loss)
I0822 11:47:54.964834 31776 sgd_solver.cpp:106] Iteration 25500, lr = 0.000539839
I0822 11:47:59.481578 31776 solver.cpp:228] Iteration 25600, loss = 0.402736
I0822 11:47:59.481632 31776 solver.cpp:244]     Train net output #0: loss = 0.402736 (* 1 = 0.402736 loss)
I0822 11:47:59.481640 31776 sgd_solver.cpp:106] Iteration 25600, lr = 0.00053895
I0822 11:48:03.997995 31776 solver.cpp:228] Iteration 25700, loss = 0.416026
I0822 11:48:03.998036 31776 solver.cpp:244]     Train net output #0: loss = 0.416026 (* 1 = 0.416026 loss)
I0822 11:48:03.998044 31776 sgd_solver.cpp:106] Iteration 25700, lr = 0.000538066
I0822 11:48:08.512202 31776 solver.cpp:228] Iteration 25800, loss = 0.27101
I0822 11:48:08.512256 31776 solver.cpp:244]     Train net output #0: loss = 0.27101 (* 1 = 0.27101 loss)
I0822 11:48:08.512264 31776 sgd_solver.cpp:106] Iteration 25800, lr = 0.000537184
I0822 11:48:13.029325 31776 solver.cpp:228] Iteration 25900, loss = 0.276394
I0822 11:48:13.029381 31776 solver.cpp:244]     Train net output #0: loss = 0.276394 (* 1 = 0.276394 loss)
I0822 11:48:13.029391 31776 sgd_solver.cpp:106] Iteration 25900, lr = 0.000536306
I0822 11:48:17.504197 31776 solver.cpp:337] Iteration 26000, Testing net (#0)
I0822 11:48:20.705037 31776 solver.cpp:404]     Test net output #0: accuracy = 0.817792
I0822 11:48:20.705101 31776 solver.cpp:404]     Test net output #1: loss = 0.462335 (* 1 = 0.462335 loss)
I0822 11:48:20.720638 31776 solver.cpp:228] Iteration 26000, loss = 0.274746
I0822 11:48:20.720702 31776 solver.cpp:244]     Train net output #0: loss = 0.274746 (* 1 = 0.274746 loss)
I0822 11:48:20.720715 31776 sgd_solver.cpp:106] Iteration 26000, lr = 0.000535432
I0822 11:48:25.240460 31776 solver.cpp:228] Iteration 26100, loss = 0.29166
I0822 11:48:25.240517 31776 solver.cpp:244]     Train net output #0: loss = 0.29166 (* 1 = 0.29166 loss)
I0822 11:48:25.240525 31776 sgd_solver.cpp:106] Iteration 26100, lr = 0.00053456
I0822 11:48:29.761499 31776 solver.cpp:228] Iteration 26200, loss = 0.350649
I0822 11:48:29.761556 31776 solver.cpp:244]     Train net output #0: loss = 0.350649 (* 1 = 0.350649 loss)
I0822 11:48:29.761564 31776 sgd_solver.cpp:106] Iteration 26200, lr = 0.000533692
I0822 11:48:34.278472 31776 solver.cpp:228] Iteration 26300, loss = 0.346485
I0822 11:48:34.278532 31776 solver.cpp:244]     Train net output #0: loss = 0.346485 (* 1 = 0.346485 loss)
I0822 11:48:34.278543 31776 sgd_solver.cpp:106] Iteration 26300, lr = 0.000532828
I0822 11:48:38.800624 31776 solver.cpp:228] Iteration 26400, loss = 0.278395
I0822 11:48:38.800676 31776 solver.cpp:244]     Train net output #0: loss = 0.278395 (* 1 = 0.278395 loss)
I0822 11:48:38.800684 31776 sgd_solver.cpp:106] Iteration 26400, lr = 0.000531966
I0822 11:48:43.274147 31776 solver.cpp:337] Iteration 26500, Testing net (#0)
I0822 11:48:46.534833 31776 solver.cpp:404]     Test net output #0: accuracy = 0.800667
I0822 11:48:46.534898 31776 solver.cpp:404]     Test net output #1: loss = 0.502791 (* 1 = 0.502791 loss)
I0822 11:48:46.550345 31776 solver.cpp:228] Iteration 26500, loss = 0.24822
I0822 11:48:46.550410 31776 solver.cpp:244]     Train net output #0: loss = 0.24822 (* 1 = 0.24822 loss)
I0822 11:48:46.550422 31776 sgd_solver.cpp:106] Iteration 26500, lr = 0.000531108
I0822 11:48:51.070078 31776 solver.cpp:228] Iteration 26600, loss = 0.418322
I0822 11:48:51.070133 31776 solver.cpp:244]     Train net output #0: loss = 0.418322 (* 1 = 0.418322 loss)
I0822 11:48:51.070142 31776 sgd_solver.cpp:106] Iteration 26600, lr = 0.000530253
I0822 11:48:55.593540 31776 solver.cpp:228] Iteration 26700, loss = 0.264707
I0822 11:48:55.593600 31776 solver.cpp:244]     Train net output #0: loss = 0.264707 (* 1 = 0.264707 loss)
I0822 11:48:55.593608 31776 sgd_solver.cpp:106] Iteration 26700, lr = 0.000529401
I0822 11:49:00.115595 31776 solver.cpp:228] Iteration 26800, loss = 0.380669
I0822 11:49:00.115648 31776 solver.cpp:244]     Train net output #0: loss = 0.380669 (* 1 = 0.380669 loss)
I0822 11:49:00.115656 31776 sgd_solver.cpp:106] Iteration 26800, lr = 0.000528553
I0822 11:49:04.629482 31776 solver.cpp:228] Iteration 26900, loss = 0.249895
I0822 11:49:04.629535 31776 solver.cpp:244]     Train net output #0: loss = 0.249895 (* 1 = 0.249895 loss)
I0822 11:49:04.629544 31776 sgd_solver.cpp:106] Iteration 26900, lr = 0.000527707
I0822 11:49:09.095046 31776 solver.cpp:337] Iteration 27000, Testing net (#0)
I0822 11:49:12.371928 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8435
I0822 11:49:12.371985 31776 solver.cpp:404]     Test net output #1: loss = 0.393938 (* 1 = 0.393938 loss)
I0822 11:49:12.387411 31776 solver.cpp:228] Iteration 27000, loss = 0.273924
I0822 11:49:12.387482 31776 solver.cpp:244]     Train net output #0: loss = 0.273924 (* 1 = 0.273924 loss)
I0822 11:49:12.387492 31776 sgd_solver.cpp:106] Iteration 27000, lr = 0.000526865
I0822 11:49:16.905351 31776 solver.cpp:228] Iteration 27100, loss = 0.275981
I0822 11:49:16.905406 31776 solver.cpp:244]     Train net output #0: loss = 0.275981 (* 1 = 0.275981 loss)
I0822 11:49:16.905414 31776 sgd_solver.cpp:106] Iteration 27100, lr = 0.000526026
I0822 11:49:21.422109 31776 solver.cpp:228] Iteration 27200, loss = 0.358854
I0822 11:49:21.422164 31776 solver.cpp:244]     Train net output #0: loss = 0.358854 (* 1 = 0.358854 loss)
I0822 11:49:21.422173 31776 sgd_solver.cpp:106] Iteration 27200, lr = 0.000525189
I0822 11:49:25.936378 31776 solver.cpp:228] Iteration 27300, loss = 0.349195
I0822 11:49:25.936431 31776 solver.cpp:244]     Train net output #0: loss = 0.349195 (* 1 = 0.349195 loss)
I0822 11:49:25.936439 31776 sgd_solver.cpp:106] Iteration 27300, lr = 0.000524356
I0822 11:49:30.446789 31776 solver.cpp:228] Iteration 27400, loss = 0.254331
I0822 11:49:30.446844 31776 solver.cpp:244]     Train net output #0: loss = 0.254331 (* 1 = 0.254331 loss)
I0822 11:49:30.446852 31776 sgd_solver.cpp:106] Iteration 27400, lr = 0.000523527
I0822 11:49:34.916697 31776 solver.cpp:337] Iteration 27500, Testing net (#0)
I0822 11:49:38.176616 31776 solver.cpp:404]     Test net output #0: accuracy = 0.780792
I0822 11:49:38.176676 31776 solver.cpp:404]     Test net output #1: loss = 0.581182 (* 1 = 0.581182 loss)
I0822 11:49:38.192147 31776 solver.cpp:228] Iteration 27500, loss = 0.313998
I0822 11:49:38.192219 31776 solver.cpp:244]     Train net output #0: loss = 0.313998 (* 1 = 0.313998 loss)
I0822 11:49:38.192232 31776 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005227
I0822 11:49:42.713177 31776 solver.cpp:228] Iteration 27600, loss = 0.301686
I0822 11:49:42.713230 31776 solver.cpp:244]     Train net output #0: loss = 0.301686 (* 1 = 0.301686 loss)
I0822 11:49:42.713238 31776 sgd_solver.cpp:106] Iteration 27600, lr = 0.000521876
I0822 11:49:47.228420 31776 solver.cpp:228] Iteration 27700, loss = 0.423757
I0822 11:49:47.228472 31776 solver.cpp:244]     Train net output #0: loss = 0.423757 (* 1 = 0.423757 loss)
I0822 11:49:47.228480 31776 sgd_solver.cpp:106] Iteration 27700, lr = 0.000521055
I0822 11:49:51.740756 31776 solver.cpp:228] Iteration 27800, loss = 0.2029
I0822 11:49:51.740813 31776 solver.cpp:244]     Train net output #0: loss = 0.2029 (* 1 = 0.2029 loss)
I0822 11:49:51.740823 31776 sgd_solver.cpp:106] Iteration 27800, lr = 0.000520237
I0822 11:49:56.254571 31776 solver.cpp:228] Iteration 27900, loss = 0.326055
I0822 11:49:56.254626 31776 solver.cpp:244]     Train net output #0: loss = 0.326055 (* 1 = 0.326055 loss)
I0822 11:49:56.254634 31776 sgd_solver.cpp:106] Iteration 27900, lr = 0.000519423
I0822 11:50:00.729609 31776 solver.cpp:337] Iteration 28000, Testing net (#0)
I0822 11:50:04.004211 31776 solver.cpp:404]     Test net output #0: accuracy = 0.842792
I0822 11:50:04.004271 31776 solver.cpp:404]     Test net output #1: loss = 0.394334 (* 1 = 0.394334 loss)
I0822 11:50:04.019451 31776 solver.cpp:228] Iteration 28000, loss = 0.265805
I0822 11:50:04.019503 31776 solver.cpp:244]     Train net output #0: loss = 0.265805 (* 1 = 0.265805 loss)
I0822 11:50:04.019515 31776 sgd_solver.cpp:106] Iteration 28000, lr = 0.000518611
I0822 11:50:08.535636 31776 solver.cpp:228] Iteration 28100, loss = 0.484008
I0822 11:50:08.535693 31776 solver.cpp:244]     Train net output #0: loss = 0.484008 (* 1 = 0.484008 loss)
I0822 11:50:08.535701 31776 sgd_solver.cpp:106] Iteration 28100, lr = 0.000517802
I0822 11:50:13.044916 31776 solver.cpp:228] Iteration 28200, loss = 0.355959
I0822 11:50:13.044972 31776 solver.cpp:244]     Train net output #0: loss = 0.355959 (* 1 = 0.355959 loss)
I0822 11:50:13.044981 31776 sgd_solver.cpp:106] Iteration 28200, lr = 0.000516996
I0822 11:50:17.555286 31776 solver.cpp:228] Iteration 28300, loss = 0.19195
I0822 11:50:17.555338 31776 solver.cpp:244]     Train net output #0: loss = 0.19195 (* 1 = 0.19195 loss)
I0822 11:50:17.555346 31776 sgd_solver.cpp:106] Iteration 28300, lr = 0.000516193
I0822 11:50:22.063446 31776 solver.cpp:228] Iteration 28400, loss = 0.282191
I0822 11:50:22.063504 31776 solver.cpp:244]     Train net output #0: loss = 0.282191 (* 1 = 0.282191 loss)
I0822 11:50:22.063519 31776 sgd_solver.cpp:106] Iteration 28400, lr = 0.000515393
I0822 11:50:26.528566 31776 solver.cpp:337] Iteration 28500, Testing net (#0)
I0822 11:50:29.765492 31776 solver.cpp:404]     Test net output #0: accuracy = 0.78275
I0822 11:50:29.765553 31776 solver.cpp:404]     Test net output #1: loss = 0.591838 (* 1 = 0.591838 loss)
I0822 11:50:29.781039 31776 solver.cpp:228] Iteration 28500, loss = 0.206445
I0822 11:50:29.781102 31776 solver.cpp:244]     Train net output #0: loss = 0.206445 (* 1 = 0.206445 loss)
I0822 11:50:29.781124 31776 sgd_solver.cpp:106] Iteration 28500, lr = 0.000514596
I0822 11:50:34.291337 31776 solver.cpp:228] Iteration 28600, loss = 0.223579
I0822 11:50:34.291398 31776 solver.cpp:244]     Train net output #0: loss = 0.223579 (* 1 = 0.223579 loss)
I0822 11:50:34.291405 31776 sgd_solver.cpp:106] Iteration 28600, lr = 0.000513801
I0822 11:50:38.803936 31776 solver.cpp:228] Iteration 28700, loss = 0.370929
I0822 11:50:38.803990 31776 solver.cpp:244]     Train net output #0: loss = 0.370929 (* 1 = 0.370929 loss)
I0822 11:50:38.803998 31776 sgd_solver.cpp:106] Iteration 28700, lr = 0.00051301
I0822 11:50:43.315935 31776 solver.cpp:228] Iteration 28800, loss = 0.19961
I0822 11:50:43.315994 31776 solver.cpp:244]     Train net output #0: loss = 0.19961 (* 1 = 0.19961 loss)
I0822 11:50:43.316001 31776 sgd_solver.cpp:106] Iteration 28800, lr = 0.000512221
I0822 11:50:47.826004 31776 solver.cpp:228] Iteration 28900, loss = 0.328327
I0822 11:50:47.826045 31776 solver.cpp:244]     Train net output #0: loss = 0.328327 (* 1 = 0.328327 loss)
I0822 11:50:47.826053 31776 sgd_solver.cpp:106] Iteration 28900, lr = 0.000511436
I0822 11:50:52.292228 31776 solver.cpp:337] Iteration 29000, Testing net (#0)
I0822 11:50:55.478550 31776 solver.cpp:404]     Test net output #0: accuracy = 0.822084
I0822 11:50:55.478612 31776 solver.cpp:404]     Test net output #1: loss = 0.472666 (* 1 = 0.472666 loss)
I0822 11:50:55.494154 31776 solver.cpp:228] Iteration 29000, loss = 0.383559
I0822 11:50:55.494223 31776 solver.cpp:244]     Train net output #0: loss = 0.383559 (* 1 = 0.383559 loss)
I0822 11:50:55.494245 31776 sgd_solver.cpp:106] Iteration 29000, lr = 0.000510653
I0822 11:51:00.007489 31776 solver.cpp:228] Iteration 29100, loss = 0.347235
I0822 11:51:00.007546 31776 solver.cpp:244]     Train net output #0: loss = 0.347235 (* 1 = 0.347235 loss)
I0822 11:51:00.007553 31776 sgd_solver.cpp:106] Iteration 29100, lr = 0.000509872
I0822 11:51:04.517483 31776 solver.cpp:228] Iteration 29200, loss = 0.264868
I0822 11:51:04.517535 31776 solver.cpp:244]     Train net output #0: loss = 0.264868 (* 1 = 0.264868 loss)
I0822 11:51:04.517544 31776 sgd_solver.cpp:106] Iteration 29200, lr = 0.000509095
I0822 11:51:09.030570 31776 solver.cpp:228] Iteration 29300, loss = 0.14186
I0822 11:51:09.030627 31776 solver.cpp:244]     Train net output #0: loss = 0.14186 (* 1 = 0.14186 loss)
I0822 11:51:09.030635 31776 sgd_solver.cpp:106] Iteration 29300, lr = 0.00050832
I0822 11:51:13.541000 31776 solver.cpp:228] Iteration 29400, loss = 0.269561
I0822 11:51:13.541054 31776 solver.cpp:244]     Train net output #0: loss = 0.269561 (* 1 = 0.269561 loss)
I0822 11:51:13.541065 31776 sgd_solver.cpp:106] Iteration 29400, lr = 0.000507548
I0822 11:51:18.002755 31776 solver.cpp:337] Iteration 29500, Testing net (#0)
I0822 11:51:21.196295 31776 solver.cpp:404]     Test net output #0: accuracy = 0.718208
I0822 11:51:21.196357 31776 solver.cpp:404]     Test net output #1: loss = 0.862246 (* 1 = 0.862246 loss)
I0822 11:51:21.211797 31776 solver.cpp:228] Iteration 29500, loss = 0.435863
I0822 11:51:21.211858 31776 solver.cpp:244]     Train net output #0: loss = 0.435863 (* 1 = 0.435863 loss)
I0822 11:51:21.211869 31776 sgd_solver.cpp:106] Iteration 29500, lr = 0.000506779
I0822 11:51:25.722841 31776 solver.cpp:228] Iteration 29600, loss = 0.294949
I0822 11:51:25.722904 31776 solver.cpp:244]     Train net output #0: loss = 0.294949 (* 1 = 0.294949 loss)
I0822 11:51:25.722913 31776 sgd_solver.cpp:106] Iteration 29600, lr = 0.000506013
I0822 11:51:30.236171 31776 solver.cpp:228] Iteration 29700, loss = 0.182098
I0822 11:51:30.236229 31776 solver.cpp:244]     Train net output #0: loss = 0.182098 (* 1 = 0.182098 loss)
I0822 11:51:30.236238 31776 sgd_solver.cpp:106] Iteration 29700, lr = 0.000505249
I0822 11:51:34.749738 31776 solver.cpp:228] Iteration 29800, loss = 0.185122
I0822 11:51:34.749795 31776 solver.cpp:244]     Train net output #0: loss = 0.185122 (* 1 = 0.185122 loss)
I0822 11:51:34.749804 31776 sgd_solver.cpp:106] Iteration 29800, lr = 0.000504488
I0822 11:51:39.261778 31776 solver.cpp:228] Iteration 29900, loss = 0.297621
I0822 11:51:39.261832 31776 solver.cpp:244]     Train net output #0: loss = 0.297621 (* 1 = 0.297621 loss)
I0822 11:51:39.261842 31776 sgd_solver.cpp:106] Iteration 29900, lr = 0.000503729
I0822 11:51:43.727949 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_30000.caffemodel
I0822 11:51:44.218222 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_30000.solverstate
I0822 11:51:44.373993 31776 solver.cpp:337] Iteration 30000, Testing net (#0)
I0822 11:51:47.567034 31776 solver.cpp:404]     Test net output #0: accuracy = 0.824292
I0822 11:51:47.567083 31776 solver.cpp:404]     Test net output #1: loss = 0.480263 (* 1 = 0.480263 loss)
I0822 11:51:47.582480 31776 solver.cpp:228] Iteration 30000, loss = 0.647351
I0822 11:51:47.582541 31776 solver.cpp:244]     Train net output #0: loss = 0.647351 (* 1 = 0.647351 loss)
I0822 11:51:47.582563 31776 sgd_solver.cpp:106] Iteration 30000, lr = 0.000502973
I0822 11:51:52.092411 31776 solver.cpp:228] Iteration 30100, loss = 0.239783
I0822 11:51:52.092453 31776 solver.cpp:244]     Train net output #0: loss = 0.239783 (* 1 = 0.239783 loss)
I0822 11:51:52.092459 31776 sgd_solver.cpp:106] Iteration 30100, lr = 0.00050222
I0822 11:51:56.603081 31776 solver.cpp:228] Iteration 30200, loss = 0.298679
I0822 11:51:56.603142 31776 solver.cpp:244]     Train net output #0: loss = 0.298679 (* 1 = 0.298679 loss)
I0822 11:51:56.603149 31776 sgd_solver.cpp:106] Iteration 30200, lr = 0.00050147
I0822 11:52:01.118912 31776 solver.cpp:228] Iteration 30300, loss = 0.282271
I0822 11:52:01.118968 31776 solver.cpp:244]     Train net output #0: loss = 0.282271 (* 1 = 0.282271 loss)
I0822 11:52:01.118974 31776 sgd_solver.cpp:106] Iteration 30300, lr = 0.000500722
I0822 11:52:05.627032 31776 solver.cpp:228] Iteration 30400, loss = 0.273376
I0822 11:52:05.627085 31776 solver.cpp:244]     Train net output #0: loss = 0.273376 (* 1 = 0.273376 loss)
I0822 11:52:05.627094 31776 sgd_solver.cpp:106] Iteration 30400, lr = 0.000499977
I0822 11:52:10.087327 31776 solver.cpp:337] Iteration 30500, Testing net (#0)
I0822 11:52:13.368415 31776 solver.cpp:404]     Test net output #0: accuracy = 0.768583
I0822 11:52:13.368474 31776 solver.cpp:404]     Test net output #1: loss = 0.684159 (* 1 = 0.684159 loss)
I0822 11:52:13.383831 31776 solver.cpp:228] Iteration 30500, loss = 0.386545
I0822 11:52:13.383900 31776 solver.cpp:244]     Train net output #0: loss = 0.386545 (* 1 = 0.386545 loss)
I0822 11:52:13.383910 31776 sgd_solver.cpp:106] Iteration 30500, lr = 0.000499234
I0822 11:52:17.892735 31776 solver.cpp:228] Iteration 30600, loss = 0.231155
I0822 11:52:17.892787 31776 solver.cpp:244]     Train net output #0: loss = 0.231155 (* 1 = 0.231155 loss)
I0822 11:52:17.892794 31776 sgd_solver.cpp:106] Iteration 30600, lr = 0.000498494
I0822 11:52:22.398087 31776 solver.cpp:228] Iteration 30700, loss = 0.247348
I0822 11:52:22.398142 31776 solver.cpp:244]     Train net output #0: loss = 0.247348 (* 1 = 0.247348 loss)
I0822 11:52:22.398150 31776 sgd_solver.cpp:106] Iteration 30700, lr = 0.000497756
I0822 11:52:26.905319 31776 solver.cpp:228] Iteration 30800, loss = 0.126464
I0822 11:52:26.905374 31776 solver.cpp:244]     Train net output #0: loss = 0.126464 (* 1 = 0.126464 loss)
I0822 11:52:26.905382 31776 sgd_solver.cpp:106] Iteration 30800, lr = 0.000497021
I0822 11:52:31.413048 31776 solver.cpp:228] Iteration 30900, loss = 0.175902
I0822 11:52:31.413106 31776 solver.cpp:244]     Train net output #0: loss = 0.175902 (* 1 = 0.175902 loss)
I0822 11:52:31.413116 31776 sgd_solver.cpp:106] Iteration 30900, lr = 0.000496288
I0822 11:52:35.874547 31776 solver.cpp:337] Iteration 31000, Testing net (#0)
I0822 11:52:36.640116 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:52:39.317428 31776 solver.cpp:404]     Test net output #0: accuracy = 0.824667
I0822 11:52:39.317492 31776 solver.cpp:404]     Test net output #1: loss = 0.50319 (* 1 = 0.50319 loss)
I0822 11:52:39.332819 31776 solver.cpp:228] Iteration 31000, loss = 0.305538
I0822 11:52:39.332893 31776 solver.cpp:244]     Train net output #0: loss = 0.305538 (* 1 = 0.305538 loss)
I0822 11:52:39.332904 31776 sgd_solver.cpp:106] Iteration 31000, lr = 0.000495558
I0822 11:52:43.838918 31776 solver.cpp:228] Iteration 31100, loss = 0.220458
I0822 11:52:43.838973 31776 solver.cpp:244]     Train net output #0: loss = 0.220458 (* 1 = 0.220458 loss)
I0822 11:52:43.838982 31776 sgd_solver.cpp:106] Iteration 31100, lr = 0.000494831
I0822 11:52:48.354097 31776 solver.cpp:228] Iteration 31200, loss = 0.261598
I0822 11:52:48.354151 31776 solver.cpp:244]     Train net output #0: loss = 0.261598 (* 1 = 0.261598 loss)
I0822 11:52:48.354158 31776 sgd_solver.cpp:106] Iteration 31200, lr = 0.000494106
I0822 11:52:52.867420 31776 solver.cpp:228] Iteration 31300, loss = 0.197705
I0822 11:52:52.867476 31776 solver.cpp:244]     Train net output #0: loss = 0.197705 (* 1 = 0.197705 loss)
I0822 11:52:52.867486 31776 sgd_solver.cpp:106] Iteration 31300, lr = 0.000493383
I0822 11:52:57.373405 31776 solver.cpp:228] Iteration 31400, loss = 0.213861
I0822 11:52:57.373464 31776 solver.cpp:244]     Train net output #0: loss = 0.213861 (* 1 = 0.213861 loss)
I0822 11:52:57.373473 31776 sgd_solver.cpp:106] Iteration 31400, lr = 0.000492663
I0822 11:53:01.833201 31776 solver.cpp:337] Iteration 31500, Testing net (#0)
I0822 11:53:05.049559 31776 solver.cpp:404]     Test net output #0: accuracy = 0.826459
I0822 11:53:05.049618 31776 solver.cpp:404]     Test net output #1: loss = 0.472334 (* 1 = 0.472334 loss)
I0822 11:53:05.065068 31776 solver.cpp:228] Iteration 31500, loss = 0.228334
I0822 11:53:05.065150 31776 solver.cpp:244]     Train net output #0: loss = 0.228334 (* 1 = 0.228334 loss)
I0822 11:53:05.065160 31776 sgd_solver.cpp:106] Iteration 31500, lr = 0.000491946
I0822 11:53:09.573789 31776 solver.cpp:228] Iteration 31600, loss = 0.170934
I0822 11:53:09.573843 31776 solver.cpp:244]     Train net output #0: loss = 0.170934 (* 1 = 0.170934 loss)
I0822 11:53:09.573851 31776 sgd_solver.cpp:106] Iteration 31600, lr = 0.00049123
I0822 11:53:14.080595 31776 solver.cpp:228] Iteration 31700, loss = 0.170831
I0822 11:53:14.080651 31776 solver.cpp:244]     Train net output #0: loss = 0.170831 (* 1 = 0.170831 loss)
I0822 11:53:14.080659 31776 sgd_solver.cpp:106] Iteration 31700, lr = 0.000490518
I0822 11:53:18.590425 31776 solver.cpp:228] Iteration 31800, loss = 0.221807
I0822 11:53:18.590471 31776 solver.cpp:244]     Train net output #0: loss = 0.221807 (* 1 = 0.221807 loss)
I0822 11:53:18.590478 31776 sgd_solver.cpp:106] Iteration 31800, lr = 0.000489807
I0822 11:53:23.095988 31776 solver.cpp:228] Iteration 31900, loss = 0.236816
I0822 11:53:23.096045 31776 solver.cpp:244]     Train net output #0: loss = 0.236816 (* 1 = 0.236816 loss)
I0822 11:53:23.096053 31776 sgd_solver.cpp:106] Iteration 31900, lr = 0.000489099
I0822 11:53:27.559952 31776 solver.cpp:337] Iteration 32000, Testing net (#0)
I0822 11:53:30.842751 31776 solver.cpp:404]     Test net output #0: accuracy = 0.811333
I0822 11:53:30.842815 31776 solver.cpp:404]     Test net output #1: loss = 0.536439 (* 1 = 0.536439 loss)
I0822 11:53:30.858265 31776 solver.cpp:228] Iteration 32000, loss = 0.166951
I0822 11:53:30.858340 31776 solver.cpp:244]     Train net output #0: loss = 0.166951 (* 1 = 0.166951 loss)
I0822 11:53:30.858350 31776 sgd_solver.cpp:106] Iteration 32000, lr = 0.000488394
I0822 11:53:35.364403 31776 solver.cpp:228] Iteration 32100, loss = 0.0805042
I0822 11:53:35.364457 31776 solver.cpp:244]     Train net output #0: loss = 0.0805042 (* 1 = 0.0805042 loss)
I0822 11:53:35.364466 31776 sgd_solver.cpp:106] Iteration 32100, lr = 0.00048769
I0822 11:53:39.874399 31776 solver.cpp:228] Iteration 32200, loss = 0.230836
I0822 11:53:39.874455 31776 solver.cpp:244]     Train net output #0: loss = 0.230836 (* 1 = 0.230836 loss)
I0822 11:53:39.874464 31776 sgd_solver.cpp:106] Iteration 32200, lr = 0.00048699
I0822 11:53:44.384457 31776 solver.cpp:228] Iteration 32300, loss = 0.140727
I0822 11:53:44.384512 31776 solver.cpp:244]     Train net output #0: loss = 0.140727 (* 1 = 0.140727 loss)
I0822 11:53:44.384521 31776 sgd_solver.cpp:106] Iteration 32300, lr = 0.000486291
I0822 11:53:48.890219 31776 solver.cpp:228] Iteration 32400, loss = 0.167929
I0822 11:53:48.890275 31776 solver.cpp:244]     Train net output #0: loss = 0.167929 (* 1 = 0.167929 loss)
I0822 11:53:48.890282 31776 sgd_solver.cpp:106] Iteration 32400, lr = 0.000485595
I0822 11:53:53.349978 31776 solver.cpp:337] Iteration 32500, Testing net (#0)
I0822 11:53:56.541972 31776 solver.cpp:404]     Test net output #0: accuracy = 0.801166
I0822 11:53:56.542031 31776 solver.cpp:404]     Test net output #1: loss = 0.601546 (* 1 = 0.601546 loss)
I0822 11:53:56.557473 31776 solver.cpp:228] Iteration 32500, loss = 0.171803
I0822 11:53:56.557544 31776 solver.cpp:244]     Train net output #0: loss = 0.171803 (* 1 = 0.171803 loss)
I0822 11:53:56.557569 31776 sgd_solver.cpp:106] Iteration 32500, lr = 0.000484901
I0822 11:54:01.066764 31776 solver.cpp:228] Iteration 32600, loss = 0.120063
I0822 11:54:01.066828 31776 solver.cpp:244]     Train net output #0: loss = 0.120063 (* 1 = 0.120063 loss)
I0822 11:54:01.066839 31776 sgd_solver.cpp:106] Iteration 32600, lr = 0.000484209
I0822 11:54:05.570045 31776 solver.cpp:228] Iteration 32700, loss = 0.227415
I0822 11:54:05.570099 31776 solver.cpp:244]     Train net output #0: loss = 0.227415 (* 1 = 0.227415 loss)
I0822 11:54:05.570106 31776 sgd_solver.cpp:106] Iteration 32700, lr = 0.00048352
I0822 11:54:10.076617 31776 solver.cpp:228] Iteration 32800, loss = 0.157595
I0822 11:54:10.076673 31776 solver.cpp:244]     Train net output #0: loss = 0.157595 (* 1 = 0.157595 loss)
I0822 11:54:10.076683 31776 sgd_solver.cpp:106] Iteration 32800, lr = 0.000482833
I0822 11:54:14.582125 31776 solver.cpp:228] Iteration 32900, loss = 0.155182
I0822 11:54:14.582172 31776 solver.cpp:244]     Train net output #0: loss = 0.155182 (* 1 = 0.155182 loss)
I0822 11:54:14.582180 31776 sgd_solver.cpp:106] Iteration 32900, lr = 0.000482148
I0822 11:54:19.044365 31776 solver.cpp:337] Iteration 33000, Testing net (#0)
I0822 11:54:22.264803 31776 solver.cpp:404]     Test net output #0: accuracy = 0.832458
I0822 11:54:22.264861 31776 solver.cpp:404]     Test net output #1: loss = 0.505166 (* 1 = 0.505166 loss)
I0822 11:54:22.280320 31776 solver.cpp:228] Iteration 33000, loss = 0.14862
I0822 11:54:22.280387 31776 solver.cpp:244]     Train net output #0: loss = 0.14862 (* 1 = 0.14862 loss)
I0822 11:54:22.280398 31776 sgd_solver.cpp:106] Iteration 33000, lr = 0.000481466
I0822 11:54:26.788640 31776 solver.cpp:228] Iteration 33100, loss = 0.102965
I0822 11:54:26.788697 31776 solver.cpp:244]     Train net output #0: loss = 0.102965 (* 1 = 0.102965 loss)
I0822 11:54:26.788705 31776 sgd_solver.cpp:106] Iteration 33100, lr = 0.000480786
I0822 11:54:31.294333 31776 solver.cpp:228] Iteration 33200, loss = 0.21382
I0822 11:54:31.294386 31776 solver.cpp:244]     Train net output #0: loss = 0.21382 (* 1 = 0.21382 loss)
I0822 11:54:31.294394 31776 sgd_solver.cpp:106] Iteration 33200, lr = 0.000480108
I0822 11:54:35.801093 31776 solver.cpp:228] Iteration 33300, loss = 0.262026
I0822 11:54:35.801153 31776 solver.cpp:244]     Train net output #0: loss = 0.262026 (* 1 = 0.262026 loss)
I0822 11:54:35.801162 31776 sgd_solver.cpp:106] Iteration 33300, lr = 0.000479432
I0822 11:54:40.307688 31776 solver.cpp:228] Iteration 33400, loss = 0.0935396
I0822 11:54:40.307742 31776 solver.cpp:244]     Train net output #0: loss = 0.0935396 (* 1 = 0.0935396 loss)
I0822 11:54:40.307752 31776 sgd_solver.cpp:106] Iteration 33400, lr = 0.000478759
I0822 11:54:44.771682 31776 solver.cpp:337] Iteration 33500, Testing net (#0)
I0822 11:54:48.038291 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841708
I0822 11:54:48.038350 31776 solver.cpp:404]     Test net output #1: loss = 0.500418 (* 1 = 0.500418 loss)
I0822 11:54:48.053836 31776 solver.cpp:228] Iteration 33500, loss = 0.190399
I0822 11:54:48.053902 31776 solver.cpp:244]     Train net output #0: loss = 0.190399 (* 1 = 0.190399 loss)
I0822 11:54:48.053913 31776 sgd_solver.cpp:106] Iteration 33500, lr = 0.000478087
I0822 11:54:52.560513 31776 solver.cpp:228] Iteration 33600, loss = 0.0764745
I0822 11:54:52.560556 31776 solver.cpp:244]     Train net output #0: loss = 0.0764745 (* 1 = 0.0764745 loss)
I0822 11:54:52.560562 31776 sgd_solver.cpp:106] Iteration 33600, lr = 0.000477418
I0822 11:54:57.065171 31776 solver.cpp:228] Iteration 33700, loss = 0.127531
I0822 11:54:57.065217 31776 solver.cpp:244]     Train net output #0: loss = 0.127531 (* 1 = 0.127531 loss)
I0822 11:54:57.065225 31776 sgd_solver.cpp:106] Iteration 33700, lr = 0.000476751
I0822 11:55:01.570425 31776 solver.cpp:228] Iteration 33800, loss = 0.110072
I0822 11:55:01.570487 31776 solver.cpp:244]     Train net output #0: loss = 0.110072 (* 1 = 0.110072 loss)
I0822 11:55:01.570498 31776 sgd_solver.cpp:106] Iteration 33800, lr = 0.000476086
I0822 11:55:06.076747 31776 solver.cpp:228] Iteration 33900, loss = 0.174552
I0822 11:55:06.076802 31776 solver.cpp:244]     Train net output #0: loss = 0.174552 (* 1 = 0.174552 loss)
I0822 11:55:06.076809 31776 sgd_solver.cpp:106] Iteration 33900, lr = 0.000475424
I0822 11:55:10.538641 31776 solver.cpp:337] Iteration 34000, Testing net (#0)
I0822 11:55:13.817097 31776 solver.cpp:404]     Test net output #0: accuracy = 0.792833
I0822 11:55:13.817167 31776 solver.cpp:404]     Test net output #1: loss = 0.711317 (* 1 = 0.711317 loss)
I0822 11:55:13.832579 31776 solver.cpp:228] Iteration 34000, loss = 0.182014
I0822 11:55:13.832653 31776 solver.cpp:244]     Train net output #0: loss = 0.182014 (* 1 = 0.182014 loss)
I0822 11:55:13.832662 31776 sgd_solver.cpp:106] Iteration 34000, lr = 0.000474763
I0822 11:55:18.338112 31776 solver.cpp:228] Iteration 34100, loss = 0.113062
I0822 11:55:18.338167 31776 solver.cpp:244]     Train net output #0: loss = 0.113062 (* 1 = 0.113062 loss)
I0822 11:55:18.338176 31776 sgd_solver.cpp:106] Iteration 34100, lr = 0.000474105
I0822 11:55:22.839831 31776 solver.cpp:228] Iteration 34200, loss = 0.128094
I0822 11:55:22.839875 31776 solver.cpp:244]     Train net output #0: loss = 0.128094 (* 1 = 0.128094 loss)
I0822 11:55:22.839884 31776 sgd_solver.cpp:106] Iteration 34200, lr = 0.000473449
I0822 11:55:27.345105 31776 solver.cpp:228] Iteration 34300, loss = 0.273698
I0822 11:55:27.345162 31776 solver.cpp:244]     Train net output #0: loss = 0.273698 (* 1 = 0.273698 loss)
I0822 11:55:27.345170 31776 sgd_solver.cpp:106] Iteration 34300, lr = 0.000472795
I0822 11:55:31.850947 31776 solver.cpp:228] Iteration 34400, loss = 0.129925
I0822 11:55:31.850996 31776 solver.cpp:244]     Train net output #0: loss = 0.129925 (* 1 = 0.129925 loss)
I0822 11:55:31.851006 31776 sgd_solver.cpp:106] Iteration 34400, lr = 0.000472143
I0822 11:55:36.312212 31776 solver.cpp:337] Iteration 34500, Testing net (#0)
I0822 11:55:39.578217 31776 solver.cpp:404]     Test net output #0: accuracy = 0.851167
I0822 11:55:39.578272 31776 solver.cpp:404]     Test net output #1: loss = 0.457748 (* 1 = 0.457748 loss)
I0822 11:55:39.594784 31776 solver.cpp:228] Iteration 34500, loss = 0.16134
I0822 11:55:39.594840 31776 solver.cpp:244]     Train net output #0: loss = 0.16134 (* 1 = 0.16134 loss)
I0822 11:55:39.594851 31776 sgd_solver.cpp:106] Iteration 34500, lr = 0.000471493
I0822 11:55:44.103580 31776 solver.cpp:228] Iteration 34600, loss = 0.496542
I0822 11:55:44.103637 31776 solver.cpp:244]     Train net output #0: loss = 0.496542 (* 1 = 0.496542 loss)
I0822 11:55:44.103646 31776 sgd_solver.cpp:106] Iteration 34600, lr = 0.000470845
I0822 11:55:48.610987 31776 solver.cpp:228] Iteration 34700, loss = 0.199988
I0822 11:55:48.611054 31776 solver.cpp:244]     Train net output #0: loss = 0.199988 (* 1 = 0.199988 loss)
I0822 11:55:48.611063 31776 sgd_solver.cpp:106] Iteration 34700, lr = 0.000470199
I0822 11:55:53.118163 31776 solver.cpp:228] Iteration 34800, loss = 0.193186
I0822 11:55:53.118218 31776 solver.cpp:244]     Train net output #0: loss = 0.193186 (* 1 = 0.193186 loss)
I0822 11:55:53.118227 31776 sgd_solver.cpp:106] Iteration 34800, lr = 0.000469556
I0822 11:55:57.624941 31776 solver.cpp:228] Iteration 34900, loss = 0.489574
I0822 11:55:57.624999 31776 solver.cpp:244]     Train net output #0: loss = 0.489574 (* 1 = 0.489574 loss)
I0822 11:55:57.625006 31776 sgd_solver.cpp:106] Iteration 34900, lr = 0.000468914
I0822 11:56:02.085185 31776 solver.cpp:337] Iteration 35000, Testing net (#0)
I0822 11:56:05.298152 31776 solver.cpp:404]     Test net output #0: accuracy = 0.847709
I0822 11:56:05.298215 31776 solver.cpp:404]     Test net output #1: loss = 0.487196 (* 1 = 0.487196 loss)
I0822 11:56:05.313736 31776 solver.cpp:228] Iteration 35000, loss = 0.114819
I0822 11:56:05.313802 31776 solver.cpp:244]     Train net output #0: loss = 0.114819 (* 1 = 0.114819 loss)
I0822 11:56:05.313812 31776 sgd_solver.cpp:106] Iteration 35000, lr = 0.000468274
I0822 11:56:09.819816 31776 solver.cpp:228] Iteration 35100, loss = 0.159308
I0822 11:56:09.819874 31776 solver.cpp:244]     Train net output #0: loss = 0.159308 (* 1 = 0.159308 loss)
I0822 11:56:09.819880 31776 sgd_solver.cpp:106] Iteration 35100, lr = 0.000467637
I0822 11:56:14.325343 31776 solver.cpp:228] Iteration 35200, loss = 0.228468
I0822 11:56:14.325400 31776 solver.cpp:244]     Train net output #0: loss = 0.228468 (* 1 = 0.228468 loss)
I0822 11:56:14.325409 31776 sgd_solver.cpp:106] Iteration 35200, lr = 0.000467001
I0822 11:56:18.831625 31776 solver.cpp:228] Iteration 35300, loss = 0.101832
I0822 11:56:18.831681 31776 solver.cpp:244]     Train net output #0: loss = 0.101832 (* 1 = 0.101832 loss)
I0822 11:56:18.831689 31776 sgd_solver.cpp:106] Iteration 35300, lr = 0.000466368
I0822 11:56:23.337255 31776 solver.cpp:228] Iteration 35400, loss = 0.328103
I0822 11:56:23.337313 31776 solver.cpp:244]     Train net output #0: loss = 0.328103 (* 1 = 0.328103 loss)
I0822 11:56:23.337321 31776 sgd_solver.cpp:106] Iteration 35400, lr = 0.000465736
I0822 11:56:27.800407 31776 solver.cpp:337] Iteration 35500, Testing net (#0)
I0822 11:56:31.117441 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836333
I0822 11:56:31.117492 31776 solver.cpp:404]     Test net output #1: loss = 0.521041 (* 1 = 0.521041 loss)
I0822 11:56:31.134804 31776 solver.cpp:228] Iteration 35500, loss = 0.140347
I0822 11:56:31.134867 31776 solver.cpp:244]     Train net output #0: loss = 0.140347 (* 1 = 0.140347 loss)
I0822 11:56:31.134876 31776 sgd_solver.cpp:106] Iteration 35500, lr = 0.000465107
I0822 11:56:35.638860 31776 solver.cpp:228] Iteration 35600, loss = 0.154114
I0822 11:56:35.638909 31776 solver.cpp:244]     Train net output #0: loss = 0.154114 (* 1 = 0.154114 loss)
I0822 11:56:35.638917 31776 sgd_solver.cpp:106] Iteration 35600, lr = 0.000464479
I0822 11:56:40.145028 31776 solver.cpp:228] Iteration 35700, loss = 0.0751958
I0822 11:56:40.145073 31776 solver.cpp:244]     Train net output #0: loss = 0.0751958 (* 1 = 0.0751958 loss)
I0822 11:56:40.145081 31776 sgd_solver.cpp:106] Iteration 35700, lr = 0.000463854
I0822 11:56:44.652441 31776 solver.cpp:228] Iteration 35800, loss = 0.0594199
I0822 11:56:44.652501 31776 solver.cpp:244]     Train net output #0: loss = 0.0594199 (* 1 = 0.0594199 loss)
I0822 11:56:44.652509 31776 sgd_solver.cpp:106] Iteration 35800, lr = 0.00046323
I0822 11:56:49.157667 31776 solver.cpp:228] Iteration 35900, loss = 0.249909
I0822 11:56:49.157719 31776 solver.cpp:244]     Train net output #0: loss = 0.249909 (* 1 = 0.249909 loss)
I0822 11:56:49.157728 31776 sgd_solver.cpp:106] Iteration 35900, lr = 0.000462609
I0822 11:56:53.612977 31776 solver.cpp:337] Iteration 36000, Testing net (#0)
I0822 11:56:56.879328 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84125
I0822 11:56:56.879390 31776 solver.cpp:404]     Test net output #1: loss = 0.538462 (* 1 = 0.538462 loss)
I0822 11:56:56.896134 31776 solver.cpp:228] Iteration 36000, loss = 0.072868
I0822 11:56:56.896214 31776 solver.cpp:244]     Train net output #0: loss = 0.072868 (* 1 = 0.072868 loss)
I0822 11:56:56.896225 31776 sgd_solver.cpp:106] Iteration 36000, lr = 0.000461989
I0822 11:57:01.402091 31776 solver.cpp:228] Iteration 36100, loss = 0.167601
I0822 11:57:01.402151 31776 solver.cpp:244]     Train net output #0: loss = 0.167601 (* 1 = 0.167601 loss)
I0822 11:57:01.402159 31776 sgd_solver.cpp:106] Iteration 36100, lr = 0.000461371
I0822 11:57:05.908591 31776 solver.cpp:228] Iteration 36200, loss = 0.0540347
I0822 11:57:05.908643 31776 solver.cpp:244]     Train net output #0: loss = 0.0540347 (* 1 = 0.0540347 loss)
I0822 11:57:05.908650 31776 sgd_solver.cpp:106] Iteration 36200, lr = 0.000460755
I0822 11:57:10.413727 31776 solver.cpp:228] Iteration 36300, loss = 0.0647651
I0822 11:57:10.413786 31776 solver.cpp:244]     Train net output #0: loss = 0.0647651 (* 1 = 0.0647651 loss)
I0822 11:57:10.413794 31776 sgd_solver.cpp:106] Iteration 36300, lr = 0.000460141
I0822 11:57:14.919646 31776 solver.cpp:228] Iteration 36400, loss = 0.0933344
I0822 11:57:14.919708 31776 solver.cpp:244]     Train net output #0: loss = 0.0933344 (* 1 = 0.0933344 loss)
I0822 11:57:14.919716 31776 sgd_solver.cpp:106] Iteration 36400, lr = 0.000459529
I0822 11:57:19.380962 31776 solver.cpp:337] Iteration 36500, Testing net (#0)
I0822 11:57:20.935348 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 11:57:22.822684 31776 solver.cpp:404]     Test net output #0: accuracy = 0.831125
I0822 11:57:22.822742 31776 solver.cpp:404]     Test net output #1: loss = 0.629461 (* 1 = 0.629461 loss)
I0822 11:57:22.838184 31776 solver.cpp:228] Iteration 36500, loss = 0.0429169
I0822 11:57:22.838259 31776 solver.cpp:244]     Train net output #0: loss = 0.0429169 (* 1 = 0.0429169 loss)
I0822 11:57:22.838270 31776 sgd_solver.cpp:106] Iteration 36500, lr = 0.000458919
I0822 11:57:27.344347 31776 solver.cpp:228] Iteration 36600, loss = 0.0455053
I0822 11:57:27.344391 31776 solver.cpp:244]     Train net output #0: loss = 0.0455053 (* 1 = 0.0455053 loss)
I0822 11:57:27.344399 31776 sgd_solver.cpp:106] Iteration 36600, lr = 0.000458311
I0822 11:57:31.850047 31776 solver.cpp:228] Iteration 36700, loss = 0.0589697
I0822 11:57:31.850095 31776 solver.cpp:244]     Train net output #0: loss = 0.0589697 (* 1 = 0.0589697 loss)
I0822 11:57:31.850102 31776 sgd_solver.cpp:106] Iteration 36700, lr = 0.000457705
I0822 11:57:36.356147 31776 solver.cpp:228] Iteration 36800, loss = 0.0257218
I0822 11:57:36.356204 31776 solver.cpp:244]     Train net output #0: loss = 0.0257218 (* 1 = 0.0257218 loss)
I0822 11:57:36.356211 31776 sgd_solver.cpp:106] Iteration 36800, lr = 0.0004571
I0822 11:57:40.861611 31776 solver.cpp:228] Iteration 36900, loss = 0.0478428
I0822 11:57:40.861657 31776 solver.cpp:244]     Train net output #0: loss = 0.0478428 (* 1 = 0.0478428 loss)
I0822 11:57:40.861665 31776 sgd_solver.cpp:106] Iteration 36900, lr = 0.000456497
I0822 11:57:45.322698 31776 solver.cpp:337] Iteration 37000, Testing net (#0)
I0822 11:57:48.579512 31776 solver.cpp:404]     Test net output #0: accuracy = 0.781042
I0822 11:57:48.579571 31776 solver.cpp:404]     Test net output #1: loss = 0.888942 (* 1 = 0.888942 loss)
I0822 11:57:48.594981 31776 solver.cpp:228] Iteration 37000, loss = 0.165597
I0822 11:57:48.595053 31776 solver.cpp:244]     Train net output #0: loss = 0.165597 (* 1 = 0.165597 loss)
I0822 11:57:48.595063 31776 sgd_solver.cpp:106] Iteration 37000, lr = 0.000455897
I0822 11:57:53.098274 31776 solver.cpp:228] Iteration 37100, loss = 0.0379559
I0822 11:57:53.098323 31776 solver.cpp:244]     Train net output #0: loss = 0.0379559 (* 1 = 0.0379559 loss)
I0822 11:57:53.098331 31776 sgd_solver.cpp:106] Iteration 37100, lr = 0.000455298
I0822 11:57:57.604189 31776 solver.cpp:228] Iteration 37200, loss = 0.113429
I0822 11:57:57.604244 31776 solver.cpp:244]     Train net output #0: loss = 0.113429 (* 1 = 0.113429 loss)
I0822 11:57:57.604252 31776 sgd_solver.cpp:106] Iteration 37200, lr = 0.000454701
I0822 11:58:02.111543 31776 solver.cpp:228] Iteration 37300, loss = 0.0433794
I0822 11:58:02.111598 31776 solver.cpp:244]     Train net output #0: loss = 0.0433794 (* 1 = 0.0433794 loss)
I0822 11:58:02.111605 31776 sgd_solver.cpp:106] Iteration 37300, lr = 0.000454105
I0822 11:58:06.619645 31776 solver.cpp:228] Iteration 37400, loss = 0.146193
I0822 11:58:06.619700 31776 solver.cpp:244]     Train net output #0: loss = 0.146193 (* 1 = 0.146193 loss)
I0822 11:58:06.619709 31776 sgd_solver.cpp:106] Iteration 37400, lr = 0.000453512
I0822 11:58:11.080852 31776 solver.cpp:337] Iteration 37500, Testing net (#0)
I0822 11:58:14.381036 31776 solver.cpp:404]     Test net output #0: accuracy = 0.844042
I0822 11:58:14.381095 31776 solver.cpp:404]     Test net output #1: loss = 0.627989 (* 1 = 0.627989 loss)
I0822 11:58:14.396550 31776 solver.cpp:228] Iteration 37500, loss = 0.0512587
I0822 11:58:14.396634 31776 solver.cpp:244]     Train net output #0: loss = 0.0512587 (* 1 = 0.0512587 loss)
I0822 11:58:14.396646 31776 sgd_solver.cpp:106] Iteration 37500, lr = 0.00045292
I0822 11:58:18.900437 31776 solver.cpp:228] Iteration 37600, loss = 0.065416
I0822 11:58:18.900493 31776 solver.cpp:244]     Train net output #0: loss = 0.065416 (* 1 = 0.065416 loss)
I0822 11:58:18.900502 31776 sgd_solver.cpp:106] Iteration 37600, lr = 0.00045233
I0822 11:58:23.405616 31776 solver.cpp:228] Iteration 37700, loss = 0.0508092
I0822 11:58:23.405669 31776 solver.cpp:244]     Train net output #0: loss = 0.0508092 (* 1 = 0.0508092 loss)
I0822 11:58:23.405678 31776 sgd_solver.cpp:106] Iteration 37700, lr = 0.000451742
I0822 11:58:27.911535 31776 solver.cpp:228] Iteration 37800, loss = 0.175655
I0822 11:58:27.911590 31776 solver.cpp:244]     Train net output #0: loss = 0.175655 (* 1 = 0.175655 loss)
I0822 11:58:27.911598 31776 sgd_solver.cpp:106] Iteration 37800, lr = 0.000451156
I0822 11:58:32.417340 31776 solver.cpp:228] Iteration 37900, loss = 0.0870228
I0822 11:58:32.417398 31776 solver.cpp:244]     Train net output #0: loss = 0.0870228 (* 1 = 0.0870228 loss)
I0822 11:58:32.417408 31776 sgd_solver.cpp:106] Iteration 37900, lr = 0.000450571
I0822 11:58:36.877754 31776 solver.cpp:337] Iteration 38000, Testing net (#0)
I0822 11:58:40.109871 31776 solver.cpp:404]     Test net output #0: accuracy = 0.848542
I0822 11:58:40.109931 31776 solver.cpp:404]     Test net output #1: loss = 0.560069 (* 1 = 0.560069 loss)
I0822 11:58:40.125419 31776 solver.cpp:228] Iteration 38000, loss = 0.0527976
I0822 11:58:40.125493 31776 solver.cpp:244]     Train net output #0: loss = 0.0527976 (* 1 = 0.0527976 loss)
I0822 11:58:40.125504 31776 sgd_solver.cpp:106] Iteration 38000, lr = 0.000449989
I0822 11:58:44.621803 31776 solver.cpp:228] Iteration 38100, loss = 0.237226
I0822 11:58:44.621862 31776 solver.cpp:244]     Train net output #0: loss = 0.237226 (* 1 = 0.237226 loss)
I0822 11:58:44.621870 31776 sgd_solver.cpp:106] Iteration 38100, lr = 0.000449408
I0822 11:58:49.128981 31776 solver.cpp:228] Iteration 38200, loss = 0.0747402
I0822 11:58:49.129039 31776 solver.cpp:244]     Train net output #0: loss = 0.0747402 (* 1 = 0.0747402 loss)
I0822 11:58:49.129046 31776 sgd_solver.cpp:106] Iteration 38200, lr = 0.000448828
I0822 11:58:53.636718 31776 solver.cpp:228] Iteration 38300, loss = 0.135999
I0822 11:58:53.636775 31776 solver.cpp:244]     Train net output #0: loss = 0.135999 (* 1 = 0.135999 loss)
I0822 11:58:53.636785 31776 sgd_solver.cpp:106] Iteration 38300, lr = 0.000448251
I0822 11:58:58.142009 31776 solver.cpp:228] Iteration 38400, loss = 0.195538
I0822 11:58:58.142066 31776 solver.cpp:244]     Train net output #0: loss = 0.195538 (* 1 = 0.195538 loss)
I0822 11:58:58.142074 31776 sgd_solver.cpp:106] Iteration 38400, lr = 0.000447675
I0822 11:59:02.603122 31776 solver.cpp:337] Iteration 38500, Testing net (#0)
I0822 11:59:05.829821 31776 solver.cpp:404]     Test net output #0: accuracy = 0.794667
I0822 11:59:05.829895 31776 solver.cpp:404]     Test net output #1: loss = 0.778541 (* 1 = 0.778541 loss)
I0822 11:59:05.845319 31776 solver.cpp:228] Iteration 38500, loss = 0.115467
I0822 11:59:05.845392 31776 solver.cpp:244]     Train net output #0: loss = 0.115467 (* 1 = 0.115467 loss)
I0822 11:59:05.845403 31776 sgd_solver.cpp:106] Iteration 38500, lr = 0.000447101
I0822 11:59:10.348798 31776 solver.cpp:228] Iteration 38600, loss = 0.279592
I0822 11:59:10.348850 31776 solver.cpp:244]     Train net output #0: loss = 0.279592 (* 1 = 0.279592 loss)
I0822 11:59:10.348857 31776 sgd_solver.cpp:106] Iteration 38600, lr = 0.000446529
I0822 11:59:14.852211 31776 solver.cpp:228] Iteration 38700, loss = 0.150761
I0822 11:59:14.852265 31776 solver.cpp:244]     Train net output #0: loss = 0.150761 (* 1 = 0.150761 loss)
I0822 11:59:14.852274 31776 sgd_solver.cpp:106] Iteration 38700, lr = 0.000445958
I0822 11:59:19.357851 31776 solver.cpp:228] Iteration 38800, loss = 0.15581
I0822 11:59:19.357908 31776 solver.cpp:244]     Train net output #0: loss = 0.15581 (* 1 = 0.15581 loss)
I0822 11:59:19.357916 31776 sgd_solver.cpp:106] Iteration 38800, lr = 0.000445389
I0822 11:59:23.860095 31776 solver.cpp:228] Iteration 38900, loss = 0.194041
I0822 11:59:23.860172 31776 solver.cpp:244]     Train net output #0: loss = 0.194041 (* 1 = 0.194041 loss)
I0822 11:59:23.860182 31776 sgd_solver.cpp:106] Iteration 38900, lr = 0.000444822
I0822 11:59:28.315160 31776 solver.cpp:337] Iteration 39000, Testing net (#0)
I0822 11:59:31.538067 31776 solver.cpp:404]     Test net output #0: accuracy = 0.824459
I0822 11:59:31.538125 31776 solver.cpp:404]     Test net output #1: loss = 0.650275 (* 1 = 0.650275 loss)
I0822 11:59:31.553432 31776 solver.cpp:228] Iteration 39000, loss = 0.106442
I0822 11:59:31.553499 31776 solver.cpp:244]     Train net output #0: loss = 0.106442 (* 1 = 0.106442 loss)
I0822 11:59:31.553509 31776 sgd_solver.cpp:106] Iteration 39000, lr = 0.000444256
I0822 11:59:36.054738 31776 solver.cpp:228] Iteration 39100, loss = 0.158017
I0822 11:59:36.054793 31776 solver.cpp:244]     Train net output #0: loss = 0.158017 (* 1 = 0.158017 loss)
I0822 11:59:36.054800 31776 sgd_solver.cpp:106] Iteration 39100, lr = 0.000443692
I0822 11:59:40.554756 31776 solver.cpp:228] Iteration 39200, loss = 0.258004
I0822 11:59:40.554811 31776 solver.cpp:244]     Train net output #0: loss = 0.258004 (* 1 = 0.258004 loss)
I0822 11:59:40.554818 31776 sgd_solver.cpp:106] Iteration 39200, lr = 0.00044313
I0822 11:59:45.053864 31776 solver.cpp:228] Iteration 39300, loss = 0.226646
I0822 11:59:45.053918 31776 solver.cpp:244]     Train net output #0: loss = 0.226646 (* 1 = 0.226646 loss)
I0822 11:59:45.053926 31776 sgd_solver.cpp:106] Iteration 39300, lr = 0.00044257
I0822 11:59:49.559406 31776 solver.cpp:228] Iteration 39400, loss = 0.0922452
I0822 11:59:49.559463 31776 solver.cpp:244]     Train net output #0: loss = 0.0922452 (* 1 = 0.0922452 loss)
I0822 11:59:49.559470 31776 sgd_solver.cpp:106] Iteration 39400, lr = 0.000442011
I0822 11:59:54.018162 31776 solver.cpp:337] Iteration 39500, Testing net (#0)
I0822 11:59:57.304288 31776 solver.cpp:404]     Test net output #0: accuracy = 0.777417
I0822 11:59:57.304348 31776 solver.cpp:404]     Test net output #1: loss = 0.861052 (* 1 = 0.861052 loss)
I0822 11:59:57.319639 31776 solver.cpp:228] Iteration 39500, loss = 0.216166
I0822 11:59:57.319700 31776 solver.cpp:244]     Train net output #0: loss = 0.216166 (* 1 = 0.216166 loss)
I0822 11:59:57.319710 31776 sgd_solver.cpp:106] Iteration 39500, lr = 0.000441453
I0822 12:00:01.823911 31776 solver.cpp:228] Iteration 39600, loss = 0.117987
I0822 12:00:01.823968 31776 solver.cpp:244]     Train net output #0: loss = 0.117987 (* 1 = 0.117987 loss)
I0822 12:00:01.823976 31776 sgd_solver.cpp:106] Iteration 39600, lr = 0.000440898
I0822 12:00:06.328972 31776 solver.cpp:228] Iteration 39700, loss = 0.0386492
I0822 12:00:06.329032 31776 solver.cpp:244]     Train net output #0: loss = 0.0386492 (* 1 = 0.0386492 loss)
I0822 12:00:06.329041 31776 sgd_solver.cpp:106] Iteration 39700, lr = 0.000440344
I0822 12:00:10.832167 31776 solver.cpp:228] Iteration 39800, loss = 0.291742
I0822 12:00:10.832219 31776 solver.cpp:244]     Train net output #0: loss = 0.291742 (* 1 = 0.291742 loss)
I0822 12:00:10.832226 31776 sgd_solver.cpp:106] Iteration 39800, lr = 0.000439791
I0822 12:00:15.335536 31776 solver.cpp:228] Iteration 39900, loss = 0.0668231
I0822 12:00:15.335597 31776 solver.cpp:244]     Train net output #0: loss = 0.0668231 (* 1 = 0.0668231 loss)
I0822 12:00:15.335604 31776 sgd_solver.cpp:106] Iteration 39900, lr = 0.000439241
I0822 12:00:19.793661 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_40000.caffemodel
I0822 12:00:20.286864 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_40000.solverstate
I0822 12:00:20.443181 31776 solver.cpp:337] Iteration 40000, Testing net (#0)
I0822 12:00:23.707706 31776 solver.cpp:404]     Test net output #0: accuracy = 0.803208
I0822 12:00:23.707751 31776 solver.cpp:404]     Test net output #1: loss = 0.776423 (* 1 = 0.776423 loss)
I0822 12:00:23.724362 31776 solver.cpp:228] Iteration 40000, loss = 0.0685162
I0822 12:00:23.724421 31776 solver.cpp:244]     Train net output #0: loss = 0.0685162 (* 1 = 0.0685162 loss)
I0822 12:00:23.724431 31776 sgd_solver.cpp:106] Iteration 40000, lr = 0.000438691
I0822 12:00:28.227063 31776 solver.cpp:228] Iteration 40100, loss = 0.0544566
I0822 12:00:28.227113 31776 solver.cpp:244]     Train net output #0: loss = 0.0544566 (* 1 = 0.0544566 loss)
I0822 12:00:28.227121 31776 sgd_solver.cpp:106] Iteration 40100, lr = 0.000438144
I0822 12:00:32.729511 31776 solver.cpp:228] Iteration 40200, loss = 0.0514101
I0822 12:00:32.729568 31776 solver.cpp:244]     Train net output #0: loss = 0.0514101 (* 1 = 0.0514101 loss)
I0822 12:00:32.729576 31776 sgd_solver.cpp:106] Iteration 40200, lr = 0.000437598
I0822 12:00:37.235468 31776 solver.cpp:228] Iteration 40300, loss = 0.0533734
I0822 12:00:37.235528 31776 solver.cpp:244]     Train net output #0: loss = 0.0533734 (* 1 = 0.0533734 loss)
I0822 12:00:37.235538 31776 sgd_solver.cpp:106] Iteration 40300, lr = 0.000437053
I0822 12:00:41.735473 31776 solver.cpp:228] Iteration 40400, loss = 0.0391671
I0822 12:00:41.735533 31776 solver.cpp:244]     Train net output #0: loss = 0.0391671 (* 1 = 0.0391671 loss)
I0822 12:00:41.735543 31776 sgd_solver.cpp:106] Iteration 40400, lr = 0.000436511
I0822 12:00:46.193342 31776 solver.cpp:337] Iteration 40500, Testing net (#0)
I0822 12:00:49.474164 31776 solver.cpp:404]     Test net output #0: accuracy = 0.800542
I0822 12:00:49.474225 31776 solver.cpp:404]     Test net output #1: loss = 0.839151 (* 1 = 0.839151 loss)
I0822 12:00:49.489598 31776 solver.cpp:228] Iteration 40500, loss = 0.100561
I0822 12:00:49.489672 31776 solver.cpp:244]     Train net output #0: loss = 0.100561 (* 1 = 0.100561 loss)
I0822 12:00:49.489684 31776 sgd_solver.cpp:106] Iteration 40500, lr = 0.000435969
I0822 12:00:53.992656 31776 solver.cpp:228] Iteration 40600, loss = 0.168124
I0822 12:00:53.992710 31776 solver.cpp:244]     Train net output #0: loss = 0.168124 (* 1 = 0.168124 loss)
I0822 12:00:53.992718 31776 sgd_solver.cpp:106] Iteration 40600, lr = 0.00043543
I0822 12:00:58.499620 31776 solver.cpp:228] Iteration 40700, loss = 0.0340751
I0822 12:00:58.499676 31776 solver.cpp:244]     Train net output #0: loss = 0.0340751 (* 1 = 0.0340751 loss)
I0822 12:00:58.499686 31776 sgd_solver.cpp:106] Iteration 40700, lr = 0.000434892
I0822 12:01:03.004894 31776 solver.cpp:228] Iteration 40800, loss = 0.260131
I0822 12:01:03.004943 31776 solver.cpp:244]     Train net output #0: loss = 0.260131 (* 1 = 0.260131 loss)
I0822 12:01:03.004952 31776 sgd_solver.cpp:106] Iteration 40800, lr = 0.000434355
I0822 12:01:07.510828 31776 solver.cpp:228] Iteration 40900, loss = 0.0512665
I0822 12:01:07.510881 31776 solver.cpp:244]     Train net output #0: loss = 0.0512665 (* 1 = 0.0512665 loss)
I0822 12:01:07.510890 31776 sgd_solver.cpp:106] Iteration 40900, lr = 0.00043382
I0822 12:01:11.972487 31776 solver.cpp:337] Iteration 41000, Testing net (#0)
I0822 12:01:15.208369 31776 solver.cpp:404]     Test net output #0: accuracy = 0.846042
I0822 12:01:15.208425 31776 solver.cpp:404]     Test net output #1: loss = 0.606738 (* 1 = 0.606738 loss)
I0822 12:01:15.223788 31776 solver.cpp:228] Iteration 41000, loss = 0.0454434
I0822 12:01:15.223856 31776 solver.cpp:244]     Train net output #0: loss = 0.0454434 (* 1 = 0.0454434 loss)
I0822 12:01:15.223865 31776 sgd_solver.cpp:106] Iteration 41000, lr = 0.000433286
I0822 12:01:19.728272 31776 solver.cpp:228] Iteration 41100, loss = 0.0385599
I0822 12:01:19.728325 31776 solver.cpp:244]     Train net output #0: loss = 0.0385599 (* 1 = 0.0385599 loss)
I0822 12:01:19.728333 31776 sgd_solver.cpp:106] Iteration 41100, lr = 0.000432755
I0822 12:01:24.228613 31776 solver.cpp:228] Iteration 41200, loss = 0.0227353
I0822 12:01:24.228677 31776 solver.cpp:244]     Train net output #0: loss = 0.0227353 (* 1 = 0.0227353 loss)
I0822 12:01:24.228687 31776 sgd_solver.cpp:106] Iteration 41200, lr = 0.000432224
I0822 12:01:28.729354 31776 solver.cpp:228] Iteration 41300, loss = 0.116595
I0822 12:01:28.729408 31776 solver.cpp:244]     Train net output #0: loss = 0.116595 (* 1 = 0.116595 loss)
I0822 12:01:28.729416 31776 sgd_solver.cpp:106] Iteration 41300, lr = 0.000431695
I0822 12:01:33.232640 31776 solver.cpp:228] Iteration 41400, loss = 0.0162008
I0822 12:01:33.232697 31776 solver.cpp:244]     Train net output #0: loss = 0.0162008 (* 1 = 0.0162008 loss)
I0822 12:01:33.232705 31776 sgd_solver.cpp:106] Iteration 41400, lr = 0.000431168
I0822 12:01:37.693315 31776 solver.cpp:337] Iteration 41500, Testing net (#0)
I0822 12:01:40.929903 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837542
I0822 12:01:40.929963 31776 solver.cpp:404]     Test net output #1: loss = 0.700664 (* 1 = 0.700664 loss)
I0822 12:01:40.945372 31776 solver.cpp:228] Iteration 41500, loss = 0.0784986
I0822 12:01:40.945441 31776 solver.cpp:244]     Train net output #0: loss = 0.0784986 (* 1 = 0.0784986 loss)
I0822 12:01:40.945452 31776 sgd_solver.cpp:106] Iteration 41500, lr = 0.000430642
I0822 12:01:45.447037 31776 solver.cpp:228] Iteration 41600, loss = 0.0100815
I0822 12:01:45.447099 31776 solver.cpp:244]     Train net output #0: loss = 0.0100815 (* 1 = 0.0100815 loss)
I0822 12:01:45.447108 31776 sgd_solver.cpp:106] Iteration 41600, lr = 0.000430117
I0822 12:01:49.946537 31776 solver.cpp:228] Iteration 41700, loss = 0.034523
I0822 12:01:49.946591 31776 solver.cpp:244]     Train net output #0: loss = 0.034523 (* 1 = 0.034523 loss)
I0822 12:01:49.946599 31776 sgd_solver.cpp:106] Iteration 41700, lr = 0.000429594
I0822 12:01:54.450572 31776 solver.cpp:228] Iteration 41800, loss = 0.0294943
I0822 12:01:54.450630 31776 solver.cpp:244]     Train net output #0: loss = 0.0294943 (* 1 = 0.0294943 loss)
I0822 12:01:54.450639 31776 sgd_solver.cpp:106] Iteration 41800, lr = 0.000429073
I0822 12:01:58.954957 31776 solver.cpp:228] Iteration 41900, loss = 0.0184113
I0822 12:01:58.955014 31776 solver.cpp:244]     Train net output #0: loss = 0.0184113 (* 1 = 0.0184113 loss)
I0822 12:01:58.955024 31776 sgd_solver.cpp:106] Iteration 41900, lr = 0.000428553
I0822 12:02:03.413786 31776 solver.cpp:337] Iteration 42000, Testing net (#0)
I0822 12:02:06.662137 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84575
I0822 12:02:06.662206 31776 solver.cpp:404]     Test net output #1: loss = 0.695026 (* 1 = 0.695026 loss)
I0822 12:02:06.677647 31776 solver.cpp:228] Iteration 42000, loss = 0.00938875
I0822 12:02:06.677711 31776 solver.cpp:244]     Train net output #0: loss = 0.00938875 (* 1 = 0.00938875 loss)
I0822 12:02:06.677721 31776 sgd_solver.cpp:106] Iteration 42000, lr = 0.000428034
I0822 12:02:11.182056 31776 solver.cpp:228] Iteration 42100, loss = 0.00825706
I0822 12:02:11.182109 31776 solver.cpp:244]     Train net output #0: loss = 0.00825706 (* 1 = 0.00825706 loss)
I0822 12:02:11.182117 31776 sgd_solver.cpp:106] Iteration 42100, lr = 0.000427517
I0822 12:02:15.683868 31776 solver.cpp:228] Iteration 42200, loss = 0.0237418
I0822 12:02:15.683925 31776 solver.cpp:244]     Train net output #0: loss = 0.0237418 (* 1 = 0.0237418 loss)
I0822 12:02:15.683933 31776 sgd_solver.cpp:106] Iteration 42200, lr = 0.000427002
I0822 12:02:20.185031 31776 solver.cpp:228] Iteration 42300, loss = 0.0063931
I0822 12:02:20.185088 31776 solver.cpp:244]     Train net output #0: loss = 0.0063931 (* 1 = 0.0063931 loss)
I0822 12:02:20.185096 31776 sgd_solver.cpp:106] Iteration 42300, lr = 0.000426488
I0822 12:02:24.687683 31776 solver.cpp:228] Iteration 42400, loss = 0.017347
I0822 12:02:24.687741 31776 solver.cpp:244]     Train net output #0: loss = 0.017347 (* 1 = 0.017347 loss)
I0822 12:02:24.687749 31776 sgd_solver.cpp:106] Iteration 42400, lr = 0.000425975
I0822 12:02:29.150650 31776 solver.cpp:337] Iteration 42500, Testing net (#0)
I0822 12:02:32.416460 31776 solver.cpp:404]     Test net output #0: accuracy = 0.844834
I0822 12:02:32.416524 31776 solver.cpp:404]     Test net output #1: loss = 0.728679 (* 1 = 0.728679 loss)
I0822 12:02:32.431792 31776 solver.cpp:228] Iteration 42500, loss = 0.00774233
I0822 12:02:32.431855 31776 solver.cpp:244]     Train net output #0: loss = 0.00774233 (* 1 = 0.00774233 loss)
I0822 12:02:32.431865 31776 sgd_solver.cpp:106] Iteration 42500, lr = 0.000425464
I0822 12:02:36.933032 31776 solver.cpp:228] Iteration 42600, loss = 0.00861117
I0822 12:02:36.933096 31776 solver.cpp:244]     Train net output #0: loss = 0.00861117 (* 1 = 0.00861117 loss)
I0822 12:02:36.933105 31776 sgd_solver.cpp:106] Iteration 42600, lr = 0.000424954
I0822 12:02:41.438232 31776 solver.cpp:228] Iteration 42700, loss = 0.00729893
I0822 12:02:41.438289 31776 solver.cpp:244]     Train net output #0: loss = 0.00729893 (* 1 = 0.00729893 loss)
I0822 12:02:41.438300 31776 sgd_solver.cpp:106] Iteration 42700, lr = 0.000424445
I0822 12:02:45.943835 31776 solver.cpp:228] Iteration 42800, loss = 0.0136366
I0822 12:02:45.943897 31776 solver.cpp:244]     Train net output #0: loss = 0.0136366 (* 1 = 0.0136366 loss)
I0822 12:02:45.943904 31776 sgd_solver.cpp:106] Iteration 42800, lr = 0.000423938
I0822 12:02:50.449173 31776 solver.cpp:228] Iteration 42900, loss = 0.0101292
I0822 12:02:50.449229 31776 solver.cpp:244]     Train net output #0: loss = 0.0101292 (* 1 = 0.0101292 loss)
I0822 12:02:50.449237 31776 sgd_solver.cpp:106] Iteration 42900, lr = 0.000423433
I0822 12:02:54.907572 31776 solver.cpp:337] Iteration 43000, Testing net (#0)
I0822 12:02:58.165736 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837917
I0822 12:02:58.165796 31776 solver.cpp:404]     Test net output #1: loss = 0.795294 (* 1 = 0.795294 loss)
I0822 12:02:58.181185 31776 solver.cpp:228] Iteration 43000, loss = 0.00660995
I0822 12:02:58.181257 31776 solver.cpp:244]     Train net output #0: loss = 0.00660995 (* 1 = 0.00660995 loss)
I0822 12:02:58.181267 31776 sgd_solver.cpp:106] Iteration 43000, lr = 0.000422929
I0822 12:03:02.685029 31776 solver.cpp:228] Iteration 43100, loss = 0.0114
I0822 12:03:02.685084 31776 solver.cpp:244]     Train net output #0: loss = 0.0114 (* 1 = 0.0114 loss)
I0822 12:03:02.685092 31776 sgd_solver.cpp:106] Iteration 43100, lr = 0.000422426
I0822 12:03:07.186679 31776 solver.cpp:228] Iteration 43200, loss = 0.0056709
I0822 12:03:07.186736 31776 solver.cpp:244]     Train net output #0: loss = 0.0056709 (* 1 = 0.0056709 loss)
I0822 12:03:07.186744 31776 sgd_solver.cpp:106] Iteration 43200, lr = 0.000421924
I0822 12:03:11.689568 31776 solver.cpp:228] Iteration 43300, loss = 0.00455452
I0822 12:03:11.689620 31776 solver.cpp:244]     Train net output #0: loss = 0.00455452 (* 1 = 0.00455452 loss)
I0822 12:03:11.689630 31776 sgd_solver.cpp:106] Iteration 43300, lr = 0.000421424
I0822 12:03:16.194752 31776 solver.cpp:228] Iteration 43400, loss = 0.00387998
I0822 12:03:16.194813 31776 solver.cpp:244]     Train net output #0: loss = 0.00387998 (* 1 = 0.00387998 loss)
I0822 12:03:16.194821 31776 sgd_solver.cpp:106] Iteration 43400, lr = 0.000420926
I0822 12:03:20.656991 31776 solver.cpp:337] Iteration 43500, Testing net (#0)
I0822 12:03:23.910070 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834708
I0822 12:03:23.910115 31776 solver.cpp:404]     Test net output #1: loss = 0.849674 (* 1 = 0.849674 loss)
I0822 12:03:23.927501 31776 solver.cpp:228] Iteration 43500, loss = 0.00281524
I0822 12:03:23.927554 31776 solver.cpp:244]     Train net output #0: loss = 0.00281524 (* 1 = 0.00281524 loss)
I0822 12:03:23.927577 31776 sgd_solver.cpp:106] Iteration 43500, lr = 0.000420429
I0822 12:03:28.429651 31776 solver.cpp:228] Iteration 43600, loss = 0.00666506
I0822 12:03:28.429694 31776 solver.cpp:244]     Train net output #0: loss = 0.00666506 (* 1 = 0.00666506 loss)
I0822 12:03:28.429703 31776 sgd_solver.cpp:106] Iteration 43600, lr = 0.000419933
I0822 12:03:32.936281 31776 solver.cpp:228] Iteration 43700, loss = 0.01687
I0822 12:03:32.936329 31776 solver.cpp:244]     Train net output #0: loss = 0.01687 (* 1 = 0.01687 loss)
I0822 12:03:32.936338 31776 sgd_solver.cpp:106] Iteration 43700, lr = 0.000419438
I0822 12:03:37.442749 31776 solver.cpp:228] Iteration 43800, loss = 0.00393176
I0822 12:03:37.442796 31776 solver.cpp:244]     Train net output #0: loss = 0.00393176 (* 1 = 0.00393176 loss)
I0822 12:03:37.442805 31776 sgd_solver.cpp:106] Iteration 43800, lr = 0.000418945
I0822 12:03:41.948237 31776 solver.cpp:228] Iteration 43900, loss = 0.0115217
I0822 12:03:41.948292 31776 solver.cpp:244]     Train net output #0: loss = 0.0115217 (* 1 = 0.0115217 loss)
I0822 12:03:41.948299 31776 sgd_solver.cpp:106] Iteration 43900, lr = 0.000418453
I0822 12:03:46.405835 31776 solver.cpp:337] Iteration 44000, Testing net (#0)
I0822 12:03:49.590379 31776 solver.cpp:404]     Test net output #0: accuracy = 0.826917
I0822 12:03:49.590440 31776 solver.cpp:404]     Test net output #1: loss = 0.907854 (* 1 = 0.907854 loss)
I0822 12:03:49.605919 31776 solver.cpp:228] Iteration 44000, loss = 0.00127689
I0822 12:03:49.605991 31776 solver.cpp:244]     Train net output #0: loss = 0.00127689 (* 1 = 0.00127689 loss)
I0822 12:03:49.606001 31776 sgd_solver.cpp:106] Iteration 44000, lr = 0.000417963
I0822 12:03:54.113319 31776 solver.cpp:228] Iteration 44100, loss = 0.00214074
I0822 12:03:54.113379 31776 solver.cpp:244]     Train net output #0: loss = 0.00214074 (* 1 = 0.00214074 loss)
I0822 12:03:54.113386 31776 sgd_solver.cpp:106] Iteration 44100, lr = 0.000417474
I0822 12:03:58.619626 31776 solver.cpp:228] Iteration 44200, loss = 0.0078193
I0822 12:03:58.619685 31776 solver.cpp:244]     Train net output #0: loss = 0.0078193 (* 1 = 0.0078193 loss)
I0822 12:03:58.619694 31776 sgd_solver.cpp:106] Iteration 44200, lr = 0.000416986
I0822 12:04:03.125226 31776 solver.cpp:228] Iteration 44300, loss = 0.00483538
I0822 12:04:03.125282 31776 solver.cpp:244]     Train net output #0: loss = 0.00483538 (* 1 = 0.00483538 loss)
I0822 12:04:03.125289 31776 sgd_solver.cpp:106] Iteration 44300, lr = 0.000416499
I0822 12:04:07.630583 31776 solver.cpp:228] Iteration 44400, loss = 0.0109908
I0822 12:04:07.630643 31776 solver.cpp:244]     Train net output #0: loss = 0.0109908 (* 1 = 0.0109908 loss)
I0822 12:04:07.630652 31776 sgd_solver.cpp:106] Iteration 44400, lr = 0.000416014
I0822 12:04:12.091323 31776 solver.cpp:337] Iteration 44500, Testing net (#0)
I0822 12:04:12.401223 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:04:15.277892 31776 solver.cpp:404]     Test net output #0: accuracy = 0.82925
I0822 12:04:15.277942 31776 solver.cpp:404]     Test net output #1: loss = 0.908598 (* 1 = 0.908598 loss)
I0822 12:04:15.293442 31776 solver.cpp:228] Iteration 44500, loss = 0.00215139
I0822 12:04:15.293519 31776 solver.cpp:244]     Train net output #0: loss = 0.00215139 (* 1 = 0.00215139 loss)
I0822 12:04:15.293548 31776 sgd_solver.cpp:106] Iteration 44500, lr = 0.00041553
I0822 12:04:19.796350 31776 solver.cpp:228] Iteration 44600, loss = 0.00735302
I0822 12:04:19.796411 31776 solver.cpp:244]     Train net output #0: loss = 0.00735302 (* 1 = 0.00735302 loss)
I0822 12:04:19.796419 31776 sgd_solver.cpp:106] Iteration 44600, lr = 0.000415048
I0822 12:04:24.302515 31776 solver.cpp:228] Iteration 44700, loss = 0.00235546
I0822 12:04:24.302573 31776 solver.cpp:244]     Train net output #0: loss = 0.00235546 (* 1 = 0.00235546 loss)
I0822 12:04:24.302582 31776 sgd_solver.cpp:106] Iteration 44700, lr = 0.000414567
I0822 12:04:28.805213 31776 solver.cpp:228] Iteration 44800, loss = 0.00499524
I0822 12:04:28.805271 31776 solver.cpp:244]     Train net output #0: loss = 0.00499524 (* 1 = 0.00499524 loss)
I0822 12:04:28.805279 31776 sgd_solver.cpp:106] Iteration 44800, lr = 0.000414087
I0822 12:04:33.311321 31776 solver.cpp:228] Iteration 44900, loss = 0.0227449
I0822 12:04:33.311378 31776 solver.cpp:244]     Train net output #0: loss = 0.0227449 (* 1 = 0.0227449 loss)
I0822 12:04:33.311385 31776 sgd_solver.cpp:106] Iteration 44900, lr = 0.000413608
I0822 12:04:37.772477 31776 solver.cpp:337] Iteration 45000, Testing net (#0)
I0822 12:04:41.032413 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836083
I0822 12:04:41.032465 31776 solver.cpp:404]     Test net output #1: loss = 0.898741 (* 1 = 0.898741 loss)
I0822 12:04:41.047849 31776 solver.cpp:228] Iteration 45000, loss = 0.00153271
I0822 12:04:41.047915 31776 solver.cpp:244]     Train net output #0: loss = 0.00153271 (* 1 = 0.00153271 loss)
I0822 12:04:41.047925 31776 sgd_solver.cpp:106] Iteration 45000, lr = 0.000413131
I0822 12:04:45.555302 31776 solver.cpp:228] Iteration 45100, loss = 0.00341502
I0822 12:04:45.555344 31776 solver.cpp:244]     Train net output #0: loss = 0.00341502 (* 1 = 0.00341502 loss)
I0822 12:04:45.555352 31776 sgd_solver.cpp:106] Iteration 45100, lr = 0.000412655
I0822 12:04:50.061358 31776 solver.cpp:228] Iteration 45200, loss = 0.00752528
I0822 12:04:50.061415 31776 solver.cpp:244]     Train net output #0: loss = 0.00752528 (* 1 = 0.00752528 loss)
I0822 12:04:50.061425 31776 sgd_solver.cpp:106] Iteration 45200, lr = 0.00041218
I0822 12:04:54.567906 31776 solver.cpp:228] Iteration 45300, loss = 0.00175448
I0822 12:04:54.567965 31776 solver.cpp:244]     Train net output #0: loss = 0.00175448 (* 1 = 0.00175448 loss)
I0822 12:04:54.567973 31776 sgd_solver.cpp:106] Iteration 45300, lr = 0.000411706
I0822 12:04:59.072898 31776 solver.cpp:228] Iteration 45400, loss = 0.00436676
I0822 12:04:59.072954 31776 solver.cpp:244]     Train net output #0: loss = 0.00436676 (* 1 = 0.00436676 loss)
I0822 12:04:59.072963 31776 sgd_solver.cpp:106] Iteration 45400, lr = 0.000411234
I0822 12:05:03.529649 31776 solver.cpp:337] Iteration 45500, Testing net (#0)
I0822 12:05:06.788341 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836917
I0822 12:05:06.788399 31776 solver.cpp:404]     Test net output #1: loss = 0.904773 (* 1 = 0.904773 loss)
I0822 12:05:06.803741 31776 solver.cpp:228] Iteration 45500, loss = 0.00291508
I0822 12:05:06.803819 31776 solver.cpp:244]     Train net output #0: loss = 0.00291508 (* 1 = 0.00291508 loss)
I0822 12:05:06.803830 31776 sgd_solver.cpp:106] Iteration 45500, lr = 0.000410763
I0822 12:05:11.309569 31776 solver.cpp:228] Iteration 45600, loss = 0.011573
I0822 12:05:11.309623 31776 solver.cpp:244]     Train net output #0: loss = 0.011573 (* 1 = 0.011573 loss)
I0822 12:05:11.309630 31776 sgd_solver.cpp:106] Iteration 45600, lr = 0.000410293
I0822 12:05:15.812722 31776 solver.cpp:228] Iteration 45700, loss = 0.00114007
I0822 12:05:15.812783 31776 solver.cpp:244]     Train net output #0: loss = 0.00114007 (* 1 = 0.00114007 loss)
I0822 12:05:15.812790 31776 sgd_solver.cpp:106] Iteration 45700, lr = 0.000409825
I0822 12:05:20.315258 31776 solver.cpp:228] Iteration 45800, loss = 0.00206023
I0822 12:05:20.315315 31776 solver.cpp:244]     Train net output #0: loss = 0.00206023 (* 1 = 0.00206023 loss)
I0822 12:05:20.315323 31776 sgd_solver.cpp:106] Iteration 45800, lr = 0.000409358
I0822 12:05:24.820744 31776 solver.cpp:228] Iteration 45900, loss = 0.00279247
I0822 12:05:24.820801 31776 solver.cpp:244]     Train net output #0: loss = 0.00279247 (* 1 = 0.00279247 loss)
I0822 12:05:24.820809 31776 sgd_solver.cpp:106] Iteration 45900, lr = 0.000408892
I0822 12:05:29.283663 31776 solver.cpp:337] Iteration 46000, Testing net (#0)
I0822 12:05:32.541615 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836834
I0822 12:05:32.541674 31776 solver.cpp:404]     Test net output #1: loss = 0.918154 (* 1 = 0.918154 loss)
I0822 12:05:32.557147 31776 solver.cpp:228] Iteration 46000, loss = 0.00170038
I0822 12:05:32.557230 31776 solver.cpp:244]     Train net output #0: loss = 0.00170038 (* 1 = 0.00170038 loss)
I0822 12:05:32.557241 31776 sgd_solver.cpp:106] Iteration 46000, lr = 0.000408427
I0822 12:05:37.064534 31776 solver.cpp:228] Iteration 46100, loss = 0.00119841
I0822 12:05:37.064597 31776 solver.cpp:244]     Train net output #0: loss = 0.00119841 (* 1 = 0.00119841 loss)
I0822 12:05:37.064605 31776 sgd_solver.cpp:106] Iteration 46100, lr = 0.000407964
I0822 12:05:41.571630 31776 solver.cpp:228] Iteration 46200, loss = 0.00367627
I0822 12:05:41.571684 31776 solver.cpp:244]     Train net output #0: loss = 0.00367627 (* 1 = 0.00367627 loss)
I0822 12:05:41.571692 31776 sgd_solver.cpp:106] Iteration 46200, lr = 0.000407501
I0822 12:05:46.079124 31776 solver.cpp:228] Iteration 46300, loss = 0.00101804
I0822 12:05:46.079180 31776 solver.cpp:244]     Train net output #0: loss = 0.00101804 (* 1 = 0.00101804 loss)
I0822 12:05:46.079190 31776 sgd_solver.cpp:106] Iteration 46300, lr = 0.00040704
I0822 12:05:50.586709 31776 solver.cpp:228] Iteration 46400, loss = 0.00138022
I0822 12:05:50.586773 31776 solver.cpp:244]     Train net output #0: loss = 0.00138022 (* 1 = 0.00138022 loss)
I0822 12:05:50.586783 31776 sgd_solver.cpp:106] Iteration 46400, lr = 0.00040658
I0822 12:05:55.048351 31776 solver.cpp:337] Iteration 46500, Testing net (#0)
I0822 12:05:58.256826 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83675
I0822 12:05:58.256889 31776 solver.cpp:404]     Test net output #1: loss = 0.932867 (* 1 = 0.932867 loss)
I0822 12:05:58.272354 31776 solver.cpp:228] Iteration 46500, loss = 0.000987566
I0822 12:05:58.272438 31776 solver.cpp:244]     Train net output #0: loss = 0.000987566 (* 1 = 0.000987566 loss)
I0822 12:05:58.272449 31776 sgd_solver.cpp:106] Iteration 46500, lr = 0.000406122
I0822 12:06:02.776391 31776 solver.cpp:228] Iteration 46600, loss = 0.000367096
I0822 12:06:02.776433 31776 solver.cpp:244]     Train net output #0: loss = 0.000367096 (* 1 = 0.000367096 loss)
I0822 12:06:02.776443 31776 sgd_solver.cpp:106] Iteration 46600, lr = 0.000405664
I0822 12:06:07.275988 31776 solver.cpp:228] Iteration 46700, loss = 0.00144129
I0822 12:06:07.276036 31776 solver.cpp:244]     Train net output #0: loss = 0.00144129 (* 1 = 0.00144129 loss)
I0822 12:06:07.276043 31776 sgd_solver.cpp:106] Iteration 46700, lr = 0.000405208
I0822 12:06:11.779577 31776 solver.cpp:228] Iteration 46800, loss = 0.000930533
I0822 12:06:11.779633 31776 solver.cpp:244]     Train net output #0: loss = 0.000930533 (* 1 = 0.000930533 loss)
I0822 12:06:11.779641 31776 sgd_solver.cpp:106] Iteration 46800, lr = 0.000404753
I0822 12:06:16.282876 31776 solver.cpp:228] Iteration 46900, loss = 0.000525639
I0822 12:06:16.282933 31776 solver.cpp:244]     Train net output #0: loss = 0.000525639 (* 1 = 0.000525639 loss)
I0822 12:06:16.282943 31776 sgd_solver.cpp:106] Iteration 46900, lr = 0.000404299
I0822 12:06:20.741158 31776 solver.cpp:337] Iteration 47000, Testing net (#0)
I0822 12:06:23.907605 31776 solver.cpp:404]     Test net output #0: accuracy = 0.833584
I0822 12:06:23.907665 31776 solver.cpp:404]     Test net output #1: loss = 0.963344 (* 1 = 0.963344 loss)
I0822 12:06:23.923158 31776 solver.cpp:228] Iteration 47000, loss = 0.000712706
I0822 12:06:23.923238 31776 solver.cpp:244]     Train net output #0: loss = 0.000712706 (* 1 = 0.000712706 loss)
I0822 12:06:23.923249 31776 sgd_solver.cpp:106] Iteration 47000, lr = 0.000403847
I0822 12:06:28.422865 31776 solver.cpp:228] Iteration 47100, loss = 0.000464496
I0822 12:06:28.422921 31776 solver.cpp:244]     Train net output #0: loss = 0.000464496 (* 1 = 0.000464496 loss)
I0822 12:06:28.422930 31776 sgd_solver.cpp:106] Iteration 47100, lr = 0.000403395
I0822 12:06:32.928416 31776 solver.cpp:228] Iteration 47200, loss = 0.00172176
I0822 12:06:32.928481 31776 solver.cpp:244]     Train net output #0: loss = 0.00172176 (* 1 = 0.00172176 loss)
I0822 12:06:32.928490 31776 sgd_solver.cpp:106] Iteration 47200, lr = 0.000402945
I0822 12:06:37.433455 31776 solver.cpp:228] Iteration 47300, loss = 0.00220169
I0822 12:06:37.433524 31776 solver.cpp:244]     Train net output #0: loss = 0.00220169 (* 1 = 0.00220169 loss)
I0822 12:06:37.433533 31776 sgd_solver.cpp:106] Iteration 47300, lr = 0.000402496
I0822 12:06:41.939448 31776 solver.cpp:228] Iteration 47400, loss = 0.00071754
I0822 12:06:41.939507 31776 solver.cpp:244]     Train net output #0: loss = 0.00071754 (* 1 = 0.00071754 loss)
I0822 12:06:41.939517 31776 sgd_solver.cpp:106] Iteration 47400, lr = 0.000402048
I0822 12:06:46.395606 31776 solver.cpp:337] Iteration 47500, Testing net (#0)
I0822 12:06:49.580130 31776 solver.cpp:404]     Test net output #0: accuracy = 0.833584
I0822 12:06:49.580198 31776 solver.cpp:404]     Test net output #1: loss = 0.96885 (* 1 = 0.96885 loss)
I0822 12:06:49.595710 31776 solver.cpp:228] Iteration 47500, loss = 0.000663621
I0822 12:06:49.595772 31776 solver.cpp:244]     Train net output #0: loss = 0.000663621 (* 1 = 0.000663621 loss)
I0822 12:06:49.595782 31776 sgd_solver.cpp:106] Iteration 47500, lr = 0.000401601
I0822 12:06:54.102792 31776 solver.cpp:228] Iteration 47600, loss = 0.000886905
I0822 12:06:54.102849 31776 solver.cpp:244]     Train net output #0: loss = 0.000886905 (* 1 = 0.000886905 loss)
I0822 12:06:54.102857 31776 sgd_solver.cpp:106] Iteration 47600, lr = 0.000401155
I0822 12:06:58.607208 31776 solver.cpp:228] Iteration 47700, loss = 0.00188658
I0822 12:06:58.607267 31776 solver.cpp:244]     Train net output #0: loss = 0.00188658 (* 1 = 0.00188658 loss)
I0822 12:06:58.607275 31776 sgd_solver.cpp:106] Iteration 47700, lr = 0.000400711
I0822 12:07:03.111448 31776 solver.cpp:228] Iteration 47800, loss = 0.00173522
I0822 12:07:03.111502 31776 solver.cpp:244]     Train net output #0: loss = 0.00173522 (* 1 = 0.00173522 loss)
I0822 12:07:03.111511 31776 sgd_solver.cpp:106] Iteration 47800, lr = 0.000400267
I0822 12:07:07.612646 31776 solver.cpp:228] Iteration 47900, loss = 0.000617236
I0822 12:07:07.612701 31776 solver.cpp:244]     Train net output #0: loss = 0.000617236 (* 1 = 0.000617236 loss)
I0822 12:07:07.612709 31776 sgd_solver.cpp:106] Iteration 47900, lr = 0.000399825
I0822 12:07:12.074658 31776 solver.cpp:337] Iteration 48000, Testing net (#0)
I0822 12:07:15.249614 31776 solver.cpp:404]     Test net output #0: accuracy = 0.828083
I0822 12:07:15.249672 31776 solver.cpp:404]     Test net output #1: loss = 1.01822 (* 1 = 1.01822 loss)
I0822 12:07:15.265171 31776 solver.cpp:228] Iteration 48000, loss = 0.00219753
I0822 12:07:15.265239 31776 solver.cpp:244]     Train net output #0: loss = 0.00219753 (* 1 = 0.00219753 loss)
I0822 12:07:15.265252 31776 sgd_solver.cpp:106] Iteration 48000, lr = 0.000399384
I0822 12:07:19.768116 31776 solver.cpp:228] Iteration 48100, loss = 0.000481813
I0822 12:07:19.768194 31776 solver.cpp:244]     Train net output #0: loss = 0.000481813 (* 1 = 0.000481813 loss)
I0822 12:07:19.768203 31776 sgd_solver.cpp:106] Iteration 48100, lr = 0.000398944
I0822 12:07:24.273574 31776 solver.cpp:228] Iteration 48200, loss = 0.00158005
I0822 12:07:24.273636 31776 solver.cpp:244]     Train net output #0: loss = 0.00158005 (* 1 = 0.00158005 loss)
I0822 12:07:24.273644 31776 sgd_solver.cpp:106] Iteration 48200, lr = 0.000398505
I0822 12:07:28.775035 31776 solver.cpp:228] Iteration 48300, loss = 0.00174394
I0822 12:07:28.775094 31776 solver.cpp:244]     Train net output #0: loss = 0.00174394 (* 1 = 0.00174394 loss)
I0822 12:07:28.775102 31776 sgd_solver.cpp:106] Iteration 48300, lr = 0.000398068
I0822 12:07:33.277313 31776 solver.cpp:228] Iteration 48400, loss = 0.00074376
I0822 12:07:33.277370 31776 solver.cpp:244]     Train net output #0: loss = 0.00074376 (* 1 = 0.00074376 loss)
I0822 12:07:33.277379 31776 sgd_solver.cpp:106] Iteration 48400, lr = 0.000397631
I0822 12:07:37.737699 31776 solver.cpp:337] Iteration 48500, Testing net (#0)
I0822 12:07:41.005273 31776 solver.cpp:404]     Test net output #0: accuracy = 0.824334
I0822 12:07:41.005323 31776 solver.cpp:404]     Test net output #1: loss = 1.05294 (* 1 = 1.05294 loss)
I0822 12:07:41.020733 31776 solver.cpp:228] Iteration 48500, loss = 0.00131347
I0822 12:07:41.020799 31776 solver.cpp:244]     Train net output #0: loss = 0.00131347 (* 1 = 0.00131347 loss)
I0822 12:07:41.020813 31776 sgd_solver.cpp:106] Iteration 48500, lr = 0.000397196
I0822 12:07:45.527117 31776 solver.cpp:228] Iteration 48600, loss = 0.00233891
I0822 12:07:45.527173 31776 solver.cpp:244]     Train net output #0: loss = 0.00233891 (* 1 = 0.00233891 loss)
I0822 12:07:45.527182 31776 sgd_solver.cpp:106] Iteration 48600, lr = 0.000396761
I0822 12:07:50.031393 31776 solver.cpp:228] Iteration 48700, loss = 0.00118445
I0822 12:07:50.031452 31776 solver.cpp:244]     Train net output #0: loss = 0.00118445 (* 1 = 0.00118445 loss)
I0822 12:07:50.031461 31776 sgd_solver.cpp:106] Iteration 48700, lr = 0.000396328
I0822 12:07:54.536957 31776 solver.cpp:228] Iteration 48800, loss = 0.00042637
I0822 12:07:54.537012 31776 solver.cpp:244]     Train net output #0: loss = 0.00042637 (* 1 = 0.00042637 loss)
I0822 12:07:54.537020 31776 sgd_solver.cpp:106] Iteration 48800, lr = 0.000395896
I0822 12:07:59.041738 31776 solver.cpp:228] Iteration 48900, loss = 0.000280298
I0822 12:07:59.041800 31776 solver.cpp:244]     Train net output #0: loss = 0.000280298 (* 1 = 0.000280298 loss)
I0822 12:07:59.041808 31776 sgd_solver.cpp:106] Iteration 48900, lr = 0.000395465
I0822 12:08:03.505303 31776 solver.cpp:337] Iteration 49000, Testing net (#0)
I0822 12:08:06.760812 31776 solver.cpp:404]     Test net output #0: accuracy = 0.828126
I0822 12:08:06.760871 31776 solver.cpp:404]     Test net output #1: loss = 1.03726 (* 1 = 1.03726 loss)
I0822 12:08:06.776270 31776 solver.cpp:228] Iteration 49000, loss = 0.000742544
I0822 12:08:06.776335 31776 solver.cpp:244]     Train net output #0: loss = 0.000742544 (* 1 = 0.000742544 loss)
I0822 12:08:06.776346 31776 sgd_solver.cpp:106] Iteration 49000, lr = 0.000395035
I0822 12:08:11.279199 31776 solver.cpp:228] Iteration 49100, loss = 0.00113106
I0822 12:08:11.279263 31776 solver.cpp:244]     Train net output #0: loss = 0.00113106 (* 1 = 0.00113106 loss)
I0822 12:08:11.279271 31776 sgd_solver.cpp:106] Iteration 49100, lr = 0.000394606
I0822 12:08:15.786437 31776 solver.cpp:228] Iteration 49200, loss = 0.00063737
I0822 12:08:15.786494 31776 solver.cpp:244]     Train net output #0: loss = 0.00063737 (* 1 = 0.00063737 loss)
I0822 12:08:15.786502 31776 sgd_solver.cpp:106] Iteration 49200, lr = 0.000394178
I0822 12:08:20.291579 31776 solver.cpp:228] Iteration 49300, loss = 0.000700841
I0822 12:08:20.291625 31776 solver.cpp:244]     Train net output #0: loss = 0.000700841 (* 1 = 0.000700841 loss)
I0822 12:08:20.291635 31776 sgd_solver.cpp:106] Iteration 49300, lr = 0.000393752
I0822 12:08:24.799298 31776 solver.cpp:228] Iteration 49400, loss = 0.000517846
I0822 12:08:24.799351 31776 solver.cpp:244]     Train net output #0: loss = 0.000517846 (* 1 = 0.000517846 loss)
I0822 12:08:24.799360 31776 sgd_solver.cpp:106] Iteration 49400, lr = 0.000393326
I0822 12:08:29.260232 31776 solver.cpp:337] Iteration 49500, Testing net (#0)
I0822 12:08:32.532192 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83325
I0822 12:08:32.532253 31776 solver.cpp:404]     Test net output #1: loss = 1.01721 (* 1 = 1.01721 loss)
I0822 12:08:32.547662 31776 solver.cpp:228] Iteration 49500, loss = 0.00168545
I0822 12:08:32.547727 31776 solver.cpp:244]     Train net output #0: loss = 0.00168545 (* 1 = 0.00168545 loss)
I0822 12:08:32.547739 31776 sgd_solver.cpp:106] Iteration 49500, lr = 0.000392902
I0822 12:08:37.051513 31776 solver.cpp:228] Iteration 49600, loss = 0.00267021
I0822 12:08:37.051558 31776 solver.cpp:244]     Train net output #0: loss = 0.00267021 (* 1 = 0.00267021 loss)
I0822 12:08:37.051566 31776 sgd_solver.cpp:106] Iteration 49600, lr = 0.000392478
I0822 12:08:41.554271 31776 solver.cpp:228] Iteration 49700, loss = 0.000693595
I0822 12:08:41.554316 31776 solver.cpp:244]     Train net output #0: loss = 0.000693595 (* 1 = 0.000693595 loss)
I0822 12:08:41.554324 31776 sgd_solver.cpp:106] Iteration 49700, lr = 0.000392056
I0822 12:08:46.056613 31776 solver.cpp:228] Iteration 49800, loss = 0.000551534
I0822 12:08:46.056660 31776 solver.cpp:244]     Train net output #0: loss = 0.000551534 (* 1 = 0.000551534 loss)
I0822 12:08:46.056668 31776 sgd_solver.cpp:106] Iteration 49800, lr = 0.000391635
I0822 12:08:50.562048 31776 solver.cpp:228] Iteration 49900, loss = 0.00248671
I0822 12:08:50.562103 31776 solver.cpp:244]     Train net output #0: loss = 0.00248671 (* 1 = 0.00248671 loss)
I0822 12:08:50.562110 31776 sgd_solver.cpp:106] Iteration 49900, lr = 0.000391214
I0822 12:08:55.024670 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_50000.caffemodel
I0822 12:08:55.496592 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_50000.solverstate
I0822 12:08:55.652667 31776 solver.cpp:337] Iteration 50000, Testing net (#0)
I0822 12:08:58.854109 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836292
I0822 12:08:58.854166 31776 solver.cpp:404]     Test net output #1: loss = 1.00748 (* 1 = 1.00748 loss)
I0822 12:08:58.869629 31776 solver.cpp:228] Iteration 50000, loss = 0.000569556
I0822 12:08:58.869702 31776 solver.cpp:244]     Train net output #0: loss = 0.000569556 (* 1 = 0.000569556 loss)
I0822 12:08:58.869714 31776 sgd_solver.cpp:106] Iteration 50000, lr = 0.000390795
I0822 12:09:03.370329 31776 solver.cpp:228] Iteration 50100, loss = 0.000806856
I0822 12:09:03.370388 31776 solver.cpp:244]     Train net output #0: loss = 0.000806856 (* 1 = 0.000806856 loss)
I0822 12:09:03.370396 31776 sgd_solver.cpp:106] Iteration 50100, lr = 0.000390377
I0822 12:09:07.877001 31776 solver.cpp:228] Iteration 50200, loss = 0.00054132
I0822 12:09:07.877058 31776 solver.cpp:244]     Train net output #0: loss = 0.00054132 (* 1 = 0.00054132 loss)
I0822 12:09:07.877065 31776 sgd_solver.cpp:106] Iteration 50200, lr = 0.00038996
I0822 12:09:12.380937 31776 solver.cpp:228] Iteration 50300, loss = 0.00074956
I0822 12:09:12.380992 31776 solver.cpp:244]     Train net output #0: loss = 0.00074956 (* 1 = 0.00074956 loss)
I0822 12:09:12.381000 31776 sgd_solver.cpp:106] Iteration 50300, lr = 0.000389544
I0822 12:09:16.888520 31776 solver.cpp:228] Iteration 50400, loss = 0.000498311
I0822 12:09:16.888586 31776 solver.cpp:244]     Train net output #0: loss = 0.000498311 (* 1 = 0.000498311 loss)
I0822 12:09:16.888595 31776 sgd_solver.cpp:106] Iteration 50400, lr = 0.000389128
I0822 12:09:21.346585 31776 solver.cpp:337] Iteration 50500, Testing net (#0)
I0822 12:09:24.576042 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838709
I0822 12:09:24.576107 31776 solver.cpp:404]     Test net output #1: loss = 1.00191 (* 1 = 1.00191 loss)
I0822 12:09:24.591564 31776 solver.cpp:228] Iteration 50500, loss = 0.000534332
I0822 12:09:24.591642 31776 solver.cpp:244]     Train net output #0: loss = 0.000534332 (* 1 = 0.000534332 loss)
I0822 12:09:24.591652 31776 sgd_solver.cpp:106] Iteration 50500, lr = 0.000388714
I0822 12:09:29.097427 31776 solver.cpp:228] Iteration 50600, loss = 0.000878648
I0822 12:09:29.097483 31776 solver.cpp:244]     Train net output #0: loss = 0.000878648 (* 1 = 0.000878648 loss)
I0822 12:09:29.097491 31776 sgd_solver.cpp:106] Iteration 50600, lr = 0.000388301
I0822 12:09:33.603400 31776 solver.cpp:228] Iteration 50700, loss = 0.000515193
I0822 12:09:33.603458 31776 solver.cpp:244]     Train net output #0: loss = 0.000515193 (* 1 = 0.000515193 loss)
I0822 12:09:33.603466 31776 sgd_solver.cpp:106] Iteration 50700, lr = 0.000387889
I0822 12:09:38.109493 31776 solver.cpp:228] Iteration 50800, loss = 0.00050538
I0822 12:09:38.109546 31776 solver.cpp:244]     Train net output #0: loss = 0.00050538 (* 1 = 0.00050538 loss)
I0822 12:09:38.109555 31776 sgd_solver.cpp:106] Iteration 50800, lr = 0.000387478
I0822 12:09:42.613843 31776 solver.cpp:228] Iteration 50900, loss = 0.000480471
I0822 12:09:42.613900 31776 solver.cpp:244]     Train net output #0: loss = 0.000480471 (* 1 = 0.000480471 loss)
I0822 12:09:42.613909 31776 sgd_solver.cpp:106] Iteration 50900, lr = 0.000387069
I0822 12:09:47.072672 31776 solver.cpp:337] Iteration 51000, Testing net (#0)
I0822 12:09:50.334234 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841
I0822 12:09:50.334292 31776 solver.cpp:404]     Test net output #1: loss = 0.986191 (* 1 = 0.986191 loss)
I0822 12:09:50.349639 31776 solver.cpp:228] Iteration 51000, loss = 0.00125008
I0822 12:09:50.349699 31776 solver.cpp:244]     Train net output #0: loss = 0.00125008 (* 1 = 0.00125008 loss)
I0822 12:09:50.349709 31776 sgd_solver.cpp:106] Iteration 51000, lr = 0.00038666
I0822 12:09:54.855643 31776 solver.cpp:228] Iteration 51100, loss = 0.000879871
I0822 12:09:54.855697 31776 solver.cpp:244]     Train net output #0: loss = 0.000879871 (* 1 = 0.000879871 loss)
I0822 12:09:54.855705 31776 sgd_solver.cpp:106] Iteration 51100, lr = 0.000386252
I0822 12:09:59.361059 31776 solver.cpp:228] Iteration 51200, loss = 0.000355574
I0822 12:09:59.361121 31776 solver.cpp:244]     Train net output #0: loss = 0.000355574 (* 1 = 0.000355574 loss)
I0822 12:09:59.361129 31776 sgd_solver.cpp:106] Iteration 51200, lr = 0.000385845
I0822 12:10:03.868376 31776 solver.cpp:228] Iteration 51300, loss = 0.000784435
I0822 12:10:03.868422 31776 solver.cpp:244]     Train net output #0: loss = 0.000784435 (* 1 = 0.000784435 loss)
I0822 12:10:03.868429 31776 sgd_solver.cpp:106] Iteration 51300, lr = 0.000385439
I0822 12:10:08.371387 31776 solver.cpp:228] Iteration 51400, loss = 0.000995237
I0822 12:10:08.371439 31776 solver.cpp:244]     Train net output #0: loss = 0.000995237 (* 1 = 0.000995237 loss)
I0822 12:10:08.371448 31776 sgd_solver.cpp:106] Iteration 51400, lr = 0.000385034
I0822 12:10:12.830852 31776 solver.cpp:337] Iteration 51500, Testing net (#0)
I0822 12:10:16.107182 31776 solver.cpp:404]     Test net output #0: accuracy = 0.842917
I0822 12:10:16.107247 31776 solver.cpp:404]     Test net output #1: loss = 0.982867 (* 1 = 0.982867 loss)
I0822 12:10:16.122613 31776 solver.cpp:228] Iteration 51500, loss = 0.000397915
I0822 12:10:16.122689 31776 solver.cpp:244]     Train net output #0: loss = 0.000397915 (* 1 = 0.000397915 loss)
I0822 12:10:16.122706 31776 sgd_solver.cpp:106] Iteration 51500, lr = 0.00038463
I0822 12:10:20.628020 31776 solver.cpp:228] Iteration 51600, loss = 0.000517907
I0822 12:10:20.628072 31776 solver.cpp:244]     Train net output #0: loss = 0.000517907 (* 1 = 0.000517907 loss)
I0822 12:10:20.628080 31776 sgd_solver.cpp:106] Iteration 51600, lr = 0.000384227
I0822 12:10:25.132345 31776 solver.cpp:228] Iteration 51700, loss = 0.000339954
I0822 12:10:25.132391 31776 solver.cpp:244]     Train net output #0: loss = 0.000339954 (* 1 = 0.000339954 loss)
I0822 12:10:25.132400 31776 sgd_solver.cpp:106] Iteration 51700, lr = 0.000383825
I0822 12:10:29.641142 31776 solver.cpp:228] Iteration 51800, loss = 0.000695134
I0822 12:10:29.641206 31776 solver.cpp:244]     Train net output #0: loss = 0.000695134 (* 1 = 0.000695134 loss)
I0822 12:10:29.641212 31776 sgd_solver.cpp:106] Iteration 51800, lr = 0.000383424
I0822 12:10:34.146003 31776 solver.cpp:228] Iteration 51900, loss = 0.000445796
I0822 12:10:34.146066 31776 solver.cpp:244]     Train net output #0: loss = 0.000445796 (* 1 = 0.000445796 loss)
I0822 12:10:34.146075 31776 sgd_solver.cpp:106] Iteration 51900, lr = 0.000383024
I0822 12:10:38.604681 31776 solver.cpp:337] Iteration 52000, Testing net (#0)
I0822 12:10:41.867395 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841917
I0822 12:10:41.867460 31776 solver.cpp:404]     Test net output #1: loss = 0.993505 (* 1 = 0.993505 loss)
I0822 12:10:41.882895 31776 solver.cpp:228] Iteration 52000, loss = 0.00109579
I0822 12:10:41.882973 31776 solver.cpp:244]     Train net output #0: loss = 0.00109579 (* 1 = 0.00109579 loss)
I0822 12:10:41.882985 31776 sgd_solver.cpp:106] Iteration 52000, lr = 0.000382625
I0822 12:10:46.388165 31776 solver.cpp:228] Iteration 52100, loss = 0.00321857
I0822 12:10:46.388212 31776 solver.cpp:244]     Train net output #0: loss = 0.00321857 (* 1 = 0.00321857 loss)
I0822 12:10:46.388221 31776 sgd_solver.cpp:106] Iteration 52100, lr = 0.000382227
I0822 12:10:50.894111 31776 solver.cpp:228] Iteration 52200, loss = 0.000636648
I0822 12:10:50.894157 31776 solver.cpp:244]     Train net output #0: loss = 0.000636648 (* 1 = 0.000636648 loss)
I0822 12:10:50.894165 31776 sgd_solver.cpp:106] Iteration 52200, lr = 0.00038183
I0822 12:10:55.400424 31776 solver.cpp:228] Iteration 52300, loss = 0.000476828
I0822 12:10:55.400467 31776 solver.cpp:244]     Train net output #0: loss = 0.000476828 (* 1 = 0.000476828 loss)
I0822 12:10:55.400476 31776 sgd_solver.cpp:106] Iteration 52300, lr = 0.000381433
I0822 12:10:59.905815 31776 solver.cpp:228] Iteration 52400, loss = 0.0507242
I0822 12:10:59.905875 31776 solver.cpp:244]     Train net output #0: loss = 0.0507242 (* 1 = 0.0507242 loss)
I0822 12:10:59.905884 31776 sgd_solver.cpp:106] Iteration 52400, lr = 0.000381038
I0822 12:11:04.364192 31776 solver.cpp:337] Iteration 52500, Testing net (#0)
I0822 12:11:07.585345 31776 solver.cpp:404]     Test net output #0: accuracy = 0.843375
I0822 12:11:07.585408 31776 solver.cpp:404]     Test net output #1: loss = 0.990849 (* 1 = 0.990849 loss)
I0822 12:11:07.600769 31776 solver.cpp:228] Iteration 52500, loss = 0.000636858
I0822 12:11:07.600831 31776 solver.cpp:244]     Train net output #0: loss = 0.000636858 (* 1 = 0.000636858 loss)
I0822 12:11:07.600841 31776 sgd_solver.cpp:106] Iteration 52500, lr = 0.000380644
I0822 12:11:12.105808 31776 solver.cpp:228] Iteration 52600, loss = 0.000601934
I0822 12:11:12.105865 31776 solver.cpp:244]     Train net output #0: loss = 0.000601934 (* 1 = 0.000601934 loss)
I0822 12:11:12.105875 31776 sgd_solver.cpp:106] Iteration 52600, lr = 0.000380251
I0822 12:11:16.613313 31776 solver.cpp:228] Iteration 52700, loss = 0.000244592
I0822 12:11:16.613369 31776 solver.cpp:244]     Train net output #0: loss = 0.000244592 (* 1 = 0.000244592 loss)
I0822 12:11:16.613378 31776 sgd_solver.cpp:106] Iteration 52700, lr = 0.000379858
I0822 12:11:21.118510 31776 solver.cpp:228] Iteration 52800, loss = 0.000679695
I0822 12:11:21.118567 31776 solver.cpp:244]     Train net output #0: loss = 0.000679695 (* 1 = 0.000679695 loss)
I0822 12:11:21.118576 31776 sgd_solver.cpp:106] Iteration 52800, lr = 0.000379467
I0822 12:11:25.621531 31776 solver.cpp:228] Iteration 52900, loss = 0.000355074
I0822 12:11:25.621588 31776 solver.cpp:244]     Train net output #0: loss = 0.000355074 (* 1 = 0.000355074 loss)
I0822 12:11:25.621597 31776 sgd_solver.cpp:106] Iteration 52900, lr = 0.000379077
I0822 12:11:30.079725 31776 solver.cpp:337] Iteration 53000, Testing net (#0)
I0822 12:11:30.264508 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:11:33.322881 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8445
I0822 12:11:33.322938 31776 solver.cpp:404]     Test net output #1: loss = 0.99359 (* 1 = 0.99359 loss)
I0822 12:11:33.338296 31776 solver.cpp:228] Iteration 53000, loss = 0.000567034
I0822 12:11:33.338364 31776 solver.cpp:244]     Train net output #0: loss = 0.000567034 (* 1 = 0.000567034 loss)
I0822 12:11:33.338374 31776 sgd_solver.cpp:106] Iteration 53000, lr = 0.000378687
I0822 12:11:37.844966 31776 solver.cpp:228] Iteration 53100, loss = 0.000400439
I0822 12:11:37.845007 31776 solver.cpp:244]     Train net output #0: loss = 0.000400439 (* 1 = 0.000400439 loss)
I0822 12:11:37.845028 31776 sgd_solver.cpp:106] Iteration 53100, lr = 0.000378298
I0822 12:11:42.349105 31776 solver.cpp:228] Iteration 53200, loss = 0.000152915
I0822 12:11:42.349162 31776 solver.cpp:244]     Train net output #0: loss = 0.000152915 (* 1 = 0.000152915 loss)
I0822 12:11:42.349170 31776 sgd_solver.cpp:106] Iteration 53200, lr = 0.000377911
I0822 12:11:46.855906 31776 solver.cpp:228] Iteration 53300, loss = 0.000560479
I0822 12:11:46.855967 31776 solver.cpp:244]     Train net output #0: loss = 0.000560479 (* 1 = 0.000560479 loss)
I0822 12:11:46.855976 31776 sgd_solver.cpp:106] Iteration 53300, lr = 0.000377524
I0822 12:11:51.361670 31776 solver.cpp:228] Iteration 53400, loss = 0.000882816
I0822 12:11:51.361714 31776 solver.cpp:244]     Train net output #0: loss = 0.000882816 (* 1 = 0.000882816 loss)
I0822 12:11:51.361722 31776 sgd_solver.cpp:106] Iteration 53400, lr = 0.000377138
I0822 12:11:55.822232 31776 solver.cpp:337] Iteration 53500, Testing net (#0)
I0822 12:11:59.100519 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84425
I0822 12:11:59.100594 31776 solver.cpp:404]     Test net output #1: loss = 1.00066 (* 1 = 1.00066 loss)
I0822 12:11:59.115936 31776 solver.cpp:228] Iteration 53500, loss = 0.000466972
I0822 12:11:59.115999 31776 solver.cpp:244]     Train net output #0: loss = 0.000466972 (* 1 = 0.000466972 loss)
I0822 12:11:59.116009 31776 sgd_solver.cpp:106] Iteration 53500, lr = 0.000376753
I0822 12:12:03.624135 31776 solver.cpp:228] Iteration 53600, loss = 0.0013739
I0822 12:12:03.624197 31776 solver.cpp:244]     Train net output #0: loss = 0.0013739 (* 1 = 0.0013739 loss)
I0822 12:12:03.624205 31776 sgd_solver.cpp:106] Iteration 53600, lr = 0.000376369
I0822 12:12:08.128204 31776 solver.cpp:228] Iteration 53700, loss = 0.000477807
I0822 12:12:08.128248 31776 solver.cpp:244]     Train net output #0: loss = 0.000477807 (* 1 = 0.000477807 loss)
I0822 12:12:08.128257 31776 sgd_solver.cpp:106] Iteration 53700, lr = 0.000375986
I0822 12:12:12.634867 31776 solver.cpp:228] Iteration 53800, loss = 0.000937255
I0822 12:12:12.634934 31776 solver.cpp:244]     Train net output #0: loss = 0.000937255 (* 1 = 0.000937255 loss)
I0822 12:12:12.634945 31776 sgd_solver.cpp:106] Iteration 53800, lr = 0.000375604
I0822 12:12:17.140969 31776 solver.cpp:228] Iteration 53900, loss = 0.00132328
I0822 12:12:17.141026 31776 solver.cpp:244]     Train net output #0: loss = 0.00132328 (* 1 = 0.00132328 loss)
I0822 12:12:17.141034 31776 sgd_solver.cpp:106] Iteration 53900, lr = 0.000375223
I0822 12:12:21.599901 31776 solver.cpp:337] Iteration 54000, Testing net (#0)
I0822 12:12:24.885761 31776 solver.cpp:404]     Test net output #0: accuracy = 0.843792
I0822 12:12:24.885818 31776 solver.cpp:404]     Test net output #1: loss = 1.00719 (* 1 = 1.00719 loss)
I0822 12:12:24.902357 31776 solver.cpp:228] Iteration 54000, loss = 0.000654019
I0822 12:12:24.902431 31776 solver.cpp:244]     Train net output #0: loss = 0.000654019 (* 1 = 0.000654019 loss)
I0822 12:12:24.902446 31776 sgd_solver.cpp:106] Iteration 54000, lr = 0.000374842
I0822 12:12:29.411126 31776 solver.cpp:228] Iteration 54100, loss = 0.00565851
I0822 12:12:29.411185 31776 solver.cpp:244]     Train net output #0: loss = 0.00565851 (* 1 = 0.00565851 loss)
I0822 12:12:29.411193 31776 sgd_solver.cpp:106] Iteration 54100, lr = 0.000374463
I0822 12:12:33.918377 31776 solver.cpp:228] Iteration 54200, loss = 0.000459383
I0822 12:12:33.918439 31776 solver.cpp:244]     Train net output #0: loss = 0.000459383 (* 1 = 0.000459383 loss)
I0822 12:12:33.918447 31776 sgd_solver.cpp:106] Iteration 54200, lr = 0.000374084
I0822 12:12:38.426120 31776 solver.cpp:228] Iteration 54300, loss = 0.000748494
I0822 12:12:38.426180 31776 solver.cpp:244]     Train net output #0: loss = 0.000748494 (* 1 = 0.000748494 loss)
I0822 12:12:38.426189 31776 sgd_solver.cpp:106] Iteration 54300, lr = 0.000373707
I0822 12:12:42.930943 31776 solver.cpp:228] Iteration 54400, loss = 0.000457498
I0822 12:12:42.931015 31776 solver.cpp:244]     Train net output #0: loss = 0.000457498 (* 1 = 0.000457498 loss)
I0822 12:12:42.931022 31776 sgd_solver.cpp:106] Iteration 54400, lr = 0.00037333
I0822 12:12:47.392457 31776 solver.cpp:337] Iteration 54500, Testing net (#0)
I0822 12:12:50.629639 31776 solver.cpp:404]     Test net output #0: accuracy = 0.844042
I0822 12:12:50.629703 31776 solver.cpp:404]     Test net output #1: loss = 1.01484 (* 1 = 1.01484 loss)
I0822 12:12:50.645146 31776 solver.cpp:228] Iteration 54500, loss = 0.000413472
I0822 12:12:50.645215 31776 solver.cpp:244]     Train net output #0: loss = 0.000413472 (* 1 = 0.000413472 loss)
I0822 12:12:50.645226 31776 sgd_solver.cpp:106] Iteration 54500, lr = 0.000372954
I0822 12:12:55.151367 31776 solver.cpp:228] Iteration 54600, loss = 0.000319865
I0822 12:12:55.151412 31776 solver.cpp:244]     Train net output #0: loss = 0.000319865 (* 1 = 0.000319865 loss)
I0822 12:12:55.151420 31776 sgd_solver.cpp:106] Iteration 54600, lr = 0.000372579
I0822 12:12:59.657413 31776 solver.cpp:228] Iteration 54700, loss = 0.00061318
I0822 12:12:59.657472 31776 solver.cpp:244]     Train net output #0: loss = 0.00061318 (* 1 = 0.00061318 loss)
I0822 12:12:59.657480 31776 sgd_solver.cpp:106] Iteration 54700, lr = 0.000372205
I0822 12:13:04.162606 31776 solver.cpp:228] Iteration 54800, loss = 0.000504116
I0822 12:13:04.162667 31776 solver.cpp:244]     Train net output #0: loss = 0.000504116 (* 1 = 0.000504116 loss)
I0822 12:13:04.162674 31776 sgd_solver.cpp:106] Iteration 54800, lr = 0.000371832
I0822 12:13:08.663090 31776 solver.cpp:228] Iteration 54900, loss = 0.000483516
I0822 12:13:08.663147 31776 solver.cpp:244]     Train net output #0: loss = 0.000483516 (* 1 = 0.000483516 loss)
I0822 12:13:08.663156 31776 sgd_solver.cpp:106] Iteration 54900, lr = 0.000371459
I0822 12:13:13.125288 31776 solver.cpp:337] Iteration 55000, Testing net (#0)
I0822 12:13:16.322559 31776 solver.cpp:404]     Test net output #0: accuracy = 0.842792
I0822 12:13:16.322605 31776 solver.cpp:404]     Test net output #1: loss = 1.02131 (* 1 = 1.02131 loss)
I0822 12:13:16.338068 31776 solver.cpp:228] Iteration 55000, loss = 0.000416057
I0822 12:13:16.338141 31776 solver.cpp:244]     Train net output #0: loss = 0.000416057 (* 1 = 0.000416057 loss)
I0822 12:13:16.338151 31776 sgd_solver.cpp:106] Iteration 55000, lr = 0.000371088
I0822 12:13:20.842041 31776 solver.cpp:228] Iteration 55100, loss = 0.000342003
I0822 12:13:20.842097 31776 solver.cpp:244]     Train net output #0: loss = 0.000342003 (* 1 = 0.000342003 loss)
I0822 12:13:20.842105 31776 sgd_solver.cpp:106] Iteration 55100, lr = 0.000370717
I0822 12:13:25.348072 31776 solver.cpp:228] Iteration 55200, loss = 0.000291623
I0822 12:13:25.348125 31776 solver.cpp:244]     Train net output #0: loss = 0.000291623 (* 1 = 0.000291623 loss)
I0822 12:13:25.348135 31776 sgd_solver.cpp:106] Iteration 55200, lr = 0.000370347
I0822 12:13:29.853370 31776 solver.cpp:228] Iteration 55300, loss = 0.000638752
I0822 12:13:29.853425 31776 solver.cpp:244]     Train net output #0: loss = 0.000638752 (* 1 = 0.000638752 loss)
I0822 12:13:29.853433 31776 sgd_solver.cpp:106] Iteration 55300, lr = 0.000369978
I0822 12:13:34.358952 31776 solver.cpp:228] Iteration 55400, loss = 0.000549022
I0822 12:13:34.358996 31776 solver.cpp:244]     Train net output #0: loss = 0.000549022 (* 1 = 0.000549022 loss)
I0822 12:13:34.359004 31776 sgd_solver.cpp:106] Iteration 55400, lr = 0.00036961
I0822 12:13:38.818624 31776 solver.cpp:337] Iteration 55500, Testing net (#0)
I0822 12:13:42.076619 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841833
I0822 12:13:42.076680 31776 solver.cpp:404]     Test net output #1: loss = 1.03256 (* 1 = 1.03256 loss)
I0822 12:13:42.091967 31776 solver.cpp:228] Iteration 55500, loss = 0.000232377
I0822 12:13:42.092032 31776 solver.cpp:244]     Train net output #0: loss = 0.000232377 (* 1 = 0.000232377 loss)
I0822 12:13:42.092042 31776 sgd_solver.cpp:106] Iteration 55500, lr = 0.000369243
I0822 12:13:46.593163 31776 solver.cpp:228] Iteration 55600, loss = 0.000653773
I0822 12:13:46.593219 31776 solver.cpp:244]     Train net output #0: loss = 0.000653773 (* 1 = 0.000653773 loss)
I0822 12:13:46.593227 31776 sgd_solver.cpp:106] Iteration 55600, lr = 0.000368877
I0822 12:13:51.098969 31776 solver.cpp:228] Iteration 55700, loss = 0.000447868
I0822 12:13:51.099022 31776 solver.cpp:244]     Train net output #0: loss = 0.000447868 (* 1 = 0.000447868 loss)
I0822 12:13:51.099030 31776 sgd_solver.cpp:106] Iteration 55700, lr = 0.000368511
I0822 12:13:55.599191 31776 solver.cpp:228] Iteration 55800, loss = 0.000233388
I0822 12:13:55.599246 31776 solver.cpp:244]     Train net output #0: loss = 0.000233388 (* 1 = 0.000233388 loss)
I0822 12:13:55.599254 31776 sgd_solver.cpp:106] Iteration 55800, lr = 0.000368146
I0822 12:14:00.106608 31776 solver.cpp:228] Iteration 55900, loss = 0.00034509
I0822 12:14:00.106664 31776 solver.cpp:244]     Train net output #0: loss = 0.00034509 (* 1 = 0.00034509 loss)
I0822 12:14:00.106673 31776 sgd_solver.cpp:106] Iteration 55900, lr = 0.000367783
I0822 12:14:04.567147 31776 solver.cpp:337] Iteration 56000, Testing net (#0)
I0822 12:14:07.852969 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841709
I0822 12:14:07.853029 31776 solver.cpp:404]     Test net output #1: loss = 1.03929 (* 1 = 1.03929 loss)
I0822 12:14:07.868407 31776 solver.cpp:228] Iteration 56000, loss = 0.000285742
I0822 12:14:07.868470 31776 solver.cpp:244]     Train net output #0: loss = 0.000285742 (* 1 = 0.000285742 loss)
I0822 12:14:07.868481 31776 sgd_solver.cpp:106] Iteration 56000, lr = 0.00036742
I0822 12:14:12.370601 31776 solver.cpp:228] Iteration 56100, loss = 0.000699677
I0822 12:14:12.370661 31776 solver.cpp:244]     Train net output #0: loss = 0.000699677 (* 1 = 0.000699677 loss)
I0822 12:14:12.370667 31776 sgd_solver.cpp:106] Iteration 56100, lr = 0.000367057
I0822 12:14:16.876896 31776 solver.cpp:228] Iteration 56200, loss = 0.000289973
I0822 12:14:16.876950 31776 solver.cpp:244]     Train net output #0: loss = 0.000289973 (* 1 = 0.000289973 loss)
I0822 12:14:16.876960 31776 sgd_solver.cpp:106] Iteration 56200, lr = 0.000366696
I0822 12:14:21.377285 31776 solver.cpp:228] Iteration 56300, loss = 0.000292775
I0822 12:14:21.377341 31776 solver.cpp:244]     Train net output #0: loss = 0.000292775 (* 1 = 0.000292775 loss)
I0822 12:14:21.377351 31776 sgd_solver.cpp:106] Iteration 56300, lr = 0.000366336
I0822 12:14:25.883463 31776 solver.cpp:228] Iteration 56400, loss = 0.00149781
I0822 12:14:25.883509 31776 solver.cpp:244]     Train net output #0: loss = 0.00149781 (* 1 = 0.00149781 loss)
I0822 12:14:25.883517 31776 sgd_solver.cpp:106] Iteration 56400, lr = 0.000365976
I0822 12:14:30.340312 31776 solver.cpp:337] Iteration 56500, Testing net (#0)
I0822 12:14:33.558706 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84225
I0822 12:14:33.558764 31776 solver.cpp:404]     Test net output #1: loss = 1.04286 (* 1 = 1.04286 loss)
I0822 12:14:33.574196 31776 solver.cpp:228] Iteration 56500, loss = 0.000363587
I0822 12:14:33.574280 31776 solver.cpp:244]     Train net output #0: loss = 0.000363587 (* 1 = 0.000363587 loss)
I0822 12:14:33.574292 31776 sgd_solver.cpp:106] Iteration 56500, lr = 0.000365617
I0822 12:14:38.081375 31776 solver.cpp:228] Iteration 56600, loss = 0.000490327
I0822 12:14:38.081419 31776 solver.cpp:244]     Train net output #0: loss = 0.000490327 (* 1 = 0.000490327 loss)
I0822 12:14:38.081428 31776 sgd_solver.cpp:106] Iteration 56600, lr = 0.000365259
I0822 12:14:42.588987 31776 solver.cpp:228] Iteration 56700, loss = 0.000811293
I0822 12:14:42.589042 31776 solver.cpp:244]     Train net output #0: loss = 0.000811293 (* 1 = 0.000811293 loss)
I0822 12:14:42.589051 31776 sgd_solver.cpp:106] Iteration 56700, lr = 0.000364902
I0822 12:14:47.097293 31776 solver.cpp:228] Iteration 56800, loss = 0.000645069
I0822 12:14:47.097354 31776 solver.cpp:244]     Train net output #0: loss = 0.000645069 (* 1 = 0.000645069 loss)
I0822 12:14:47.097362 31776 sgd_solver.cpp:106] Iteration 56800, lr = 0.000364545
I0822 12:14:51.602655 31776 solver.cpp:228] Iteration 56900, loss = 0.000548137
I0822 12:14:51.602720 31776 solver.cpp:244]     Train net output #0: loss = 0.000548137 (* 1 = 0.000548137 loss)
I0822 12:14:51.602727 31776 sgd_solver.cpp:106] Iteration 56900, lr = 0.00036419
I0822 12:14:56.063091 31776 solver.cpp:337] Iteration 57000, Testing net (#0)
I0822 12:14:59.309041 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841751
I0822 12:14:59.309099 31776 solver.cpp:404]     Test net output #1: loss = 1.05369 (* 1 = 1.05369 loss)
I0822 12:14:59.324565 31776 solver.cpp:228] Iteration 57000, loss = 0.000168082
I0822 12:14:59.324646 31776 solver.cpp:244]     Train net output #0: loss = 0.000168082 (* 1 = 0.000168082 loss)
I0822 12:14:59.324658 31776 sgd_solver.cpp:106] Iteration 57000, lr = 0.000363835
I0822 12:15:03.828824 31776 solver.cpp:228] Iteration 57100, loss = 0.000577123
I0822 12:15:03.828871 31776 solver.cpp:244]     Train net output #0: loss = 0.000577123 (* 1 = 0.000577123 loss)
I0822 12:15:03.828878 31776 sgd_solver.cpp:106] Iteration 57100, lr = 0.000363481
I0822 12:15:08.334334 31776 solver.cpp:228] Iteration 57200, loss = 0.000282196
I0822 12:15:08.334380 31776 solver.cpp:244]     Train net output #0: loss = 0.000282196 (* 1 = 0.000282196 loss)
I0822 12:15:08.334388 31776 sgd_solver.cpp:106] Iteration 57200, lr = 0.000363128
I0822 12:15:12.837589 31776 solver.cpp:228] Iteration 57300, loss = 0.000460372
I0822 12:15:12.837642 31776 solver.cpp:244]     Train net output #0: loss = 0.000460372 (* 1 = 0.000460372 loss)
I0822 12:15:12.837651 31776 sgd_solver.cpp:106] Iteration 57300, lr = 0.000362775
I0822 12:15:17.340389 31776 solver.cpp:228] Iteration 57400, loss = 0.000392676
I0822 12:15:17.340442 31776 solver.cpp:244]     Train net output #0: loss = 0.000392676 (* 1 = 0.000392676 loss)
I0822 12:15:17.340451 31776 sgd_solver.cpp:106] Iteration 57400, lr = 0.000362424
I0822 12:15:21.802283 31776 solver.cpp:337] Iteration 57500, Testing net (#0)
I0822 12:15:25.048660 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841959
I0822 12:15:25.048724 31776 solver.cpp:404]     Test net output #1: loss = 1.0513 (* 1 = 1.0513 loss)
I0822 12:15:25.064231 31776 solver.cpp:228] Iteration 57500, loss = 0.000275759
I0822 12:15:25.064306 31776 solver.cpp:244]     Train net output #0: loss = 0.000275759 (* 1 = 0.000275759 loss)
I0822 12:15:25.064317 31776 sgd_solver.cpp:106] Iteration 57500, lr = 0.000362073
I0822 12:15:29.570379 31776 solver.cpp:228] Iteration 57600, loss = 0.00094601
I0822 12:15:29.570435 31776 solver.cpp:244]     Train net output #0: loss = 0.00094601 (* 1 = 0.00094601 loss)
I0822 12:15:29.570443 31776 sgd_solver.cpp:106] Iteration 57600, lr = 0.000361723
I0822 12:15:34.077222 31776 solver.cpp:228] Iteration 57700, loss = 0.000589877
I0822 12:15:34.077287 31776 solver.cpp:244]     Train net output #0: loss = 0.000589877 (* 1 = 0.000589877 loss)
I0822 12:15:34.077296 31776 sgd_solver.cpp:106] Iteration 57700, lr = 0.000361374
I0822 12:15:38.584357 31776 solver.cpp:228] Iteration 57800, loss = 0.000148642
I0822 12:15:38.584410 31776 solver.cpp:244]     Train net output #0: loss = 0.000148642 (* 1 = 0.000148642 loss)
I0822 12:15:38.584419 31776 sgd_solver.cpp:106] Iteration 57800, lr = 0.000361025
I0822 12:15:43.090016 31776 solver.cpp:228] Iteration 57900, loss = 0.000712304
I0822 12:15:43.090072 31776 solver.cpp:244]     Train net output #0: loss = 0.000712304 (* 1 = 0.000712304 loss)
I0822 12:15:43.090081 31776 sgd_solver.cpp:106] Iteration 57900, lr = 0.000360678
I0822 12:15:47.552683 31776 solver.cpp:337] Iteration 58000, Testing net (#0)
I0822 12:15:50.808325 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84175
I0822 12:15:50.808383 31776 solver.cpp:404]     Test net output #1: loss = 1.05836 (* 1 = 1.05836 loss)
I0822 12:15:50.823721 31776 solver.cpp:228] Iteration 58000, loss = 0.000653174
I0822 12:15:50.823786 31776 solver.cpp:244]     Train net output #0: loss = 0.000653174 (* 1 = 0.000653174 loss)
I0822 12:15:50.823796 31776 sgd_solver.cpp:106] Iteration 58000, lr = 0.000360331
I0822 12:15:55.328702 31776 solver.cpp:228] Iteration 58100, loss = 0.000453792
I0822 12:15:55.328765 31776 solver.cpp:244]     Train net output #0: loss = 0.000453792 (* 1 = 0.000453792 loss)
I0822 12:15:55.328773 31776 sgd_solver.cpp:106] Iteration 58100, lr = 0.000359985
I0822 12:15:59.835801 31776 solver.cpp:228] Iteration 58200, loss = 0.000166702
I0822 12:15:59.835858 31776 solver.cpp:244]     Train net output #0: loss = 0.000166702 (* 1 = 0.000166702 loss)
I0822 12:15:59.835866 31776 sgd_solver.cpp:106] Iteration 58200, lr = 0.00035964
I0822 12:16:04.341738 31776 solver.cpp:228] Iteration 58300, loss = 0.000427973
I0822 12:16:04.341792 31776 solver.cpp:244]     Train net output #0: loss = 0.000427973 (* 1 = 0.000427973 loss)
I0822 12:16:04.341801 31776 sgd_solver.cpp:106] Iteration 58300, lr = 0.000359295
I0822 12:16:08.845147 31776 solver.cpp:228] Iteration 58400, loss = 0.00143772
I0822 12:16:08.845216 31776 solver.cpp:244]     Train net output #0: loss = 0.00143772 (* 1 = 0.00143772 loss)
I0822 12:16:08.845226 31776 sgd_solver.cpp:106] Iteration 58400, lr = 0.000358951
I0822 12:16:13.307698 31776 solver.cpp:337] Iteration 58500, Testing net (#0)
I0822 12:16:16.576514 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841625
I0822 12:16:16.576586 31776 solver.cpp:404]     Test net output #1: loss = 1.06106 (* 1 = 1.06106 loss)
I0822 12:16:16.591958 31776 solver.cpp:228] Iteration 58500, loss = 0.000411003
I0822 12:16:16.592026 31776 solver.cpp:244]     Train net output #0: loss = 0.000411003 (* 1 = 0.000411003 loss)
I0822 12:16:16.592036 31776 sgd_solver.cpp:106] Iteration 58500, lr = 0.000358608
I0822 12:16:21.098451 31776 solver.cpp:228] Iteration 58600, loss = 0.000517525
I0822 12:16:21.098510 31776 solver.cpp:244]     Train net output #0: loss = 0.000517525 (* 1 = 0.000517525 loss)
I0822 12:16:21.098520 31776 sgd_solver.cpp:106] Iteration 58600, lr = 0.000358266
I0822 12:16:25.601404 31776 solver.cpp:228] Iteration 58700, loss = 0.000191184
I0822 12:16:25.601464 31776 solver.cpp:244]     Train net output #0: loss = 0.000191184 (* 1 = 0.000191184 loss)
I0822 12:16:25.601471 31776 sgd_solver.cpp:106] Iteration 58700, lr = 0.000357925
I0822 12:16:30.104996 31776 solver.cpp:228] Iteration 58800, loss = 0.000408262
I0822 12:16:30.105051 31776 solver.cpp:244]     Train net output #0: loss = 0.000408262 (* 1 = 0.000408262 loss)
I0822 12:16:30.105058 31776 sgd_solver.cpp:106] Iteration 58800, lr = 0.000357584
I0822 12:16:34.609208 31776 solver.cpp:228] Iteration 58900, loss = 0.000274164
I0822 12:16:34.609272 31776 solver.cpp:244]     Train net output #0: loss = 0.000274164 (* 1 = 0.000274164 loss)
I0822 12:16:34.609280 31776 sgd_solver.cpp:106] Iteration 58900, lr = 0.000357244
I0822 12:16:39.067425 31776 solver.cpp:337] Iteration 59000, Testing net (#0)
I0822 12:16:42.301589 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841042
I0822 12:16:42.301652 31776 solver.cpp:404]     Test net output #1: loss = 1.06789 (* 1 = 1.06789 loss)
I0822 12:16:42.316978 31776 solver.cpp:228] Iteration 59000, loss = 0.000393224
I0822 12:16:42.317046 31776 solver.cpp:244]     Train net output #0: loss = 0.000393224 (* 1 = 0.000393224 loss)
I0822 12:16:42.317056 31776 sgd_solver.cpp:106] Iteration 59000, lr = 0.000356905
I0822 12:16:46.823676 31776 solver.cpp:228] Iteration 59100, loss = 0.000650874
I0822 12:16:46.823734 31776 solver.cpp:244]     Train net output #0: loss = 0.000650874 (* 1 = 0.000650874 loss)
I0822 12:16:46.823742 31776 sgd_solver.cpp:106] Iteration 59100, lr = 0.000356566
I0822 12:16:51.326167 31776 solver.cpp:228] Iteration 59200, loss = 0.000506968
I0822 12:16:51.326225 31776 solver.cpp:244]     Train net output #0: loss = 0.000506968 (* 1 = 0.000506968 loss)
I0822 12:16:51.326233 31776 sgd_solver.cpp:106] Iteration 59200, lr = 0.000356228
I0822 12:16:55.827163 31776 solver.cpp:228] Iteration 59300, loss = 0.00037119
I0822 12:16:55.827220 31776 solver.cpp:244]     Train net output #0: loss = 0.00037119 (* 1 = 0.00037119 loss)
I0822 12:16:55.827229 31776 sgd_solver.cpp:106] Iteration 59300, lr = 0.000355892
I0822 12:17:00.331887 31776 solver.cpp:228] Iteration 59400, loss = 0.000274575
I0822 12:17:00.331946 31776 solver.cpp:244]     Train net output #0: loss = 0.000274575 (* 1 = 0.000274575 loss)
I0822 12:17:00.331954 31776 sgd_solver.cpp:106] Iteration 59400, lr = 0.000355555
I0822 12:17:04.789696 31776 solver.cpp:337] Iteration 59500, Testing net (#0)
I0822 12:17:07.994222 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841084
I0822 12:17:07.994285 31776 solver.cpp:404]     Test net output #1: loss = 1.07289 (* 1 = 1.07289 loss)
I0822 12:17:08.009733 31776 solver.cpp:228] Iteration 59500, loss = 0.000189625
I0822 12:17:08.009804 31776 solver.cpp:244]     Train net output #0: loss = 0.000189625 (* 1 = 0.000189625 loss)
I0822 12:17:08.009814 31776 sgd_solver.cpp:106] Iteration 59500, lr = 0.00035522
I0822 12:17:12.514701 31776 solver.cpp:228] Iteration 59600, loss = 0.000493211
I0822 12:17:12.514756 31776 solver.cpp:244]     Train net output #0: loss = 0.000493211 (* 1 = 0.000493211 loss)
I0822 12:17:12.514765 31776 sgd_solver.cpp:106] Iteration 59600, lr = 0.000354885
I0822 12:17:17.020866 31776 solver.cpp:228] Iteration 59700, loss = 0.000760956
I0822 12:17:17.020922 31776 solver.cpp:244]     Train net output #0: loss = 0.000760956 (* 1 = 0.000760956 loss)
I0822 12:17:17.020931 31776 sgd_solver.cpp:106] Iteration 59700, lr = 0.000354551
I0822 12:17:21.526679 31776 solver.cpp:228] Iteration 59800, loss = 0.000237344
I0822 12:17:21.526736 31776 solver.cpp:244]     Train net output #0: loss = 0.000237344 (* 1 = 0.000237344 loss)
I0822 12:17:21.526744 31776 sgd_solver.cpp:106] Iteration 59800, lr = 0.000354218
I0822 12:17:26.028043 31776 solver.cpp:228] Iteration 59900, loss = 0.000307178
I0822 12:17:26.028098 31776 solver.cpp:244]     Train net output #0: loss = 0.000307178 (* 1 = 0.000307178 loss)
I0822 12:17:26.028106 31776 sgd_solver.cpp:106] Iteration 59900, lr = 0.000353885
I0822 12:17:30.488359 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_60000.caffemodel
I0822 12:17:30.980428 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_60000.solverstate
I0822 12:17:31.138887 31776 solver.cpp:337] Iteration 60000, Testing net (#0)
I0822 12:17:31.675436 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:17:34.405478 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840958
I0822 12:17:34.405541 31776 solver.cpp:404]     Test net output #1: loss = 1.0794 (* 1 = 1.0794 loss)
I0822 12:17:34.420924 31776 solver.cpp:228] Iteration 60000, loss = 0.000254634
I0822 12:17:34.420989 31776 solver.cpp:244]     Train net output #0: loss = 0.000254634 (* 1 = 0.000254634 loss)
I0822 12:17:34.421000 31776 sgd_solver.cpp:106] Iteration 60000, lr = 0.000353553
I0822 12:17:38.923190 31776 solver.cpp:228] Iteration 60100, loss = 0.000747045
I0822 12:17:38.923244 31776 solver.cpp:244]     Train net output #0: loss = 0.000747045 (* 1 = 0.000747045 loss)
I0822 12:17:38.923252 31776 sgd_solver.cpp:106] Iteration 60100, lr = 0.000353222
I0822 12:17:43.430171 31776 solver.cpp:228] Iteration 60200, loss = 0.000258692
I0822 12:17:43.430228 31776 solver.cpp:244]     Train net output #0: loss = 0.000258692 (* 1 = 0.000258692 loss)
I0822 12:17:43.430238 31776 sgd_solver.cpp:106] Iteration 60200, lr = 0.000352892
I0822 12:17:47.937408 31776 solver.cpp:228] Iteration 60300, loss = 0.000168607
I0822 12:17:47.937469 31776 solver.cpp:244]     Train net output #0: loss = 0.000168607 (* 1 = 0.000168607 loss)
I0822 12:17:47.937479 31776 sgd_solver.cpp:106] Iteration 60300, lr = 0.000352562
I0822 12:17:52.443402 31776 solver.cpp:228] Iteration 60400, loss = 0.000210563
I0822 12:17:52.443462 31776 solver.cpp:244]     Train net output #0: loss = 0.000210563 (* 1 = 0.000210563 loss)
I0822 12:17:52.443470 31776 sgd_solver.cpp:106] Iteration 60400, lr = 0.000352233
I0822 12:17:56.905551 31776 solver.cpp:337] Iteration 60500, Testing net (#0)
I0822 12:18:00.187201 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840209
I0822 12:18:00.187258 31776 solver.cpp:404]     Test net output #1: loss = 1.08524 (* 1 = 1.08524 loss)
I0822 12:18:00.202545 31776 solver.cpp:228] Iteration 60500, loss = 0.000190417
I0822 12:18:00.202608 31776 solver.cpp:244]     Train net output #0: loss = 0.000190417 (* 1 = 0.000190417 loss)
I0822 12:18:00.202630 31776 sgd_solver.cpp:106] Iteration 60500, lr = 0.000351905
I0822 12:18:04.703433 31776 solver.cpp:228] Iteration 60600, loss = 0.000350628
I0822 12:18:04.703495 31776 solver.cpp:244]     Train net output #0: loss = 0.000350628 (* 1 = 0.000350628 loss)
I0822 12:18:04.703503 31776 sgd_solver.cpp:106] Iteration 60600, lr = 0.000351578
I0822 12:18:09.209821 31776 solver.cpp:228] Iteration 60700, loss = 0.000354263
I0822 12:18:09.209875 31776 solver.cpp:244]     Train net output #0: loss = 0.000354263 (* 1 = 0.000354263 loss)
I0822 12:18:09.209883 31776 sgd_solver.cpp:106] Iteration 60700, lr = 0.000351251
I0822 12:18:13.715845 31776 solver.cpp:228] Iteration 60800, loss = 0.000353996
I0822 12:18:13.715906 31776 solver.cpp:244]     Train net output #0: loss = 0.000353996 (* 1 = 0.000353996 loss)
I0822 12:18:13.715914 31776 sgd_solver.cpp:106] Iteration 60800, lr = 0.000350925
I0822 12:18:18.218022 31776 solver.cpp:228] Iteration 60900, loss = 0.000375885
I0822 12:18:18.218077 31776 solver.cpp:244]     Train net output #0: loss = 0.000375885 (* 1 = 0.000375885 loss)
I0822 12:18:18.218086 31776 sgd_solver.cpp:106] Iteration 60900, lr = 0.000350599
I0822 12:18:22.678098 31776 solver.cpp:337] Iteration 61000, Testing net (#0)
I0822 12:18:25.934058 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8405
I0822 12:18:25.934118 31776 solver.cpp:404]     Test net output #1: loss = 1.08889 (* 1 = 1.08889 loss)
I0822 12:18:25.949450 31776 solver.cpp:228] Iteration 61000, loss = 0.000156803
I0822 12:18:25.949522 31776 solver.cpp:244]     Train net output #0: loss = 0.000156803 (* 1 = 0.000156803 loss)
I0822 12:18:25.949532 31776 sgd_solver.cpp:106] Iteration 61000, lr = 0.000350275
I0822 12:18:30.453313 31776 solver.cpp:228] Iteration 61100, loss = 0.000427933
I0822 12:18:30.453369 31776 solver.cpp:244]     Train net output #0: loss = 0.000427933 (* 1 = 0.000427933 loss)
I0822 12:18:30.453378 31776 sgd_solver.cpp:106] Iteration 61100, lr = 0.000349951
I0822 12:18:34.955705 31776 solver.cpp:228] Iteration 61200, loss = 0.000361715
I0822 12:18:34.955762 31776 solver.cpp:244]     Train net output #0: loss = 0.000361715 (* 1 = 0.000361715 loss)
I0822 12:18:34.955771 31776 sgd_solver.cpp:106] Iteration 61200, lr = 0.000349627
I0822 12:18:39.461061 31776 solver.cpp:228] Iteration 61300, loss = 0.00013782
I0822 12:18:39.461122 31776 solver.cpp:244]     Train net output #0: loss = 0.00013782 (* 1 = 0.00013782 loss)
I0822 12:18:39.461133 31776 sgd_solver.cpp:106] Iteration 61300, lr = 0.000349305
I0822 12:18:43.967739 31776 solver.cpp:228] Iteration 61400, loss = 0.000397681
I0822 12:18:43.967794 31776 solver.cpp:244]     Train net output #0: loss = 0.000397681 (* 1 = 0.000397681 loss)
I0822 12:18:43.967803 31776 sgd_solver.cpp:106] Iteration 61400, lr = 0.000348983
I0822 12:18:48.428874 31776 solver.cpp:337] Iteration 61500, Testing net (#0)
I0822 12:18:51.714252 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839667
I0822 12:18:51.714310 31776 solver.cpp:404]     Test net output #1: loss = 1.09683 (* 1 = 1.09683 loss)
I0822 12:18:51.730849 31776 solver.cpp:228] Iteration 61500, loss = 0.000258
I0822 12:18:51.730916 31776 solver.cpp:244]     Train net output #0: loss = 0.000258 (* 1 = 0.000258 loss)
I0822 12:18:51.730928 31776 sgd_solver.cpp:106] Iteration 61500, lr = 0.000348662
I0822 12:18:56.237766 31776 solver.cpp:228] Iteration 61600, loss = 0.000425842
I0822 12:18:56.237821 31776 solver.cpp:244]     Train net output #0: loss = 0.000425842 (* 1 = 0.000425842 loss)
I0822 12:18:56.237830 31776 sgd_solver.cpp:106] Iteration 61600, lr = 0.000348341
I0822 12:19:00.742713 31776 solver.cpp:228] Iteration 61700, loss = 0.000202592
I0822 12:19:00.742772 31776 solver.cpp:244]     Train net output #0: loss = 0.000202592 (* 1 = 0.000202592 loss)
I0822 12:19:00.742782 31776 sgd_solver.cpp:106] Iteration 61700, lr = 0.000348021
I0822 12:19:05.251153 31776 solver.cpp:228] Iteration 61800, loss = 0.000450915
I0822 12:19:05.251211 31776 solver.cpp:244]     Train net output #0: loss = 0.000450915 (* 1 = 0.000450915 loss)
I0822 12:19:05.251220 31776 sgd_solver.cpp:106] Iteration 61800, lr = 0.000347702
I0822 12:19:09.758890 31776 solver.cpp:228] Iteration 61900, loss = 0.000661632
I0822 12:19:09.758955 31776 solver.cpp:244]     Train net output #0: loss = 0.000661632 (* 1 = 0.000661632 loss)
I0822 12:19:09.758963 31776 sgd_solver.cpp:106] Iteration 61900, lr = 0.000347384
I0822 12:19:14.219072 31776 solver.cpp:337] Iteration 62000, Testing net (#0)
I0822 12:19:17.746337 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838417
I0822 12:19:17.746402 31776 solver.cpp:404]     Test net output #1: loss = 1.10922 (* 1 = 1.10922 loss)
I0822 12:19:17.761970 31776 solver.cpp:228] Iteration 62000, loss = 0.000381838
I0822 12:19:17.762048 31776 solver.cpp:244]     Train net output #0: loss = 0.000381838 (* 1 = 0.000381838 loss)
I0822 12:19:17.762059 31776 sgd_solver.cpp:106] Iteration 62000, lr = 0.000347066
I0822 12:19:22.266326 31776 solver.cpp:228] Iteration 62100, loss = 0.000210725
I0822 12:19:22.266386 31776 solver.cpp:244]     Train net output #0: loss = 0.000210725 (* 1 = 0.000210725 loss)
I0822 12:19:22.266396 31776 sgd_solver.cpp:106] Iteration 62100, lr = 0.000346749
I0822 12:19:26.771808 31776 solver.cpp:228] Iteration 62200, loss = 0.00036779
I0822 12:19:26.771873 31776 solver.cpp:244]     Train net output #0: loss = 0.00036779 (* 1 = 0.00036779 loss)
I0822 12:19:26.771883 31776 sgd_solver.cpp:106] Iteration 62200, lr = 0.000346433
I0822 12:19:31.277936 31776 solver.cpp:228] Iteration 62300, loss = 0.000282688
I0822 12:19:31.277990 31776 solver.cpp:244]     Train net output #0: loss = 0.000282688 (* 1 = 0.000282688 loss)
I0822 12:19:31.277998 31776 sgd_solver.cpp:106] Iteration 62300, lr = 0.000346117
I0822 12:19:35.784078 31776 solver.cpp:228] Iteration 62400, loss = 0.000318257
I0822 12:19:35.784133 31776 solver.cpp:244]     Train net output #0: loss = 0.000318257 (* 1 = 0.000318257 loss)
I0822 12:19:35.784162 31776 sgd_solver.cpp:106] Iteration 62400, lr = 0.000345802
I0822 12:19:40.244737 31776 solver.cpp:337] Iteration 62500, Testing net (#0)
I0822 12:19:43.525586 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838834
I0822 12:19:43.525650 31776 solver.cpp:404]     Test net output #1: loss = 1.11167 (* 1 = 1.11167 loss)
I0822 12:19:43.540984 31776 solver.cpp:228] Iteration 62500, loss = 0.00017951
I0822 12:19:43.541062 31776 solver.cpp:244]     Train net output #0: loss = 0.00017951 (* 1 = 0.00017951 loss)
I0822 12:19:43.541074 31776 sgd_solver.cpp:106] Iteration 62500, lr = 0.000345487
I0822 12:19:48.044919 31776 solver.cpp:228] Iteration 62600, loss = 0.000244475
I0822 12:19:48.044975 31776 solver.cpp:244]     Train net output #0: loss = 0.000244475 (* 1 = 0.000244475 loss)
I0822 12:19:48.044982 31776 sgd_solver.cpp:106] Iteration 62600, lr = 0.000345174
I0822 12:19:52.547310 31776 solver.cpp:228] Iteration 62700, loss = 0.000177645
I0822 12:19:52.547365 31776 solver.cpp:244]     Train net output #0: loss = 0.000177645 (* 1 = 0.000177645 loss)
I0822 12:19:52.547374 31776 sgd_solver.cpp:106] Iteration 62700, lr = 0.00034486
I0822 12:19:57.053313 31776 solver.cpp:228] Iteration 62800, loss = 0.000398299
I0822 12:19:57.053369 31776 solver.cpp:244]     Train net output #0: loss = 0.000398299 (* 1 = 0.000398299 loss)
I0822 12:19:57.053376 31776 sgd_solver.cpp:106] Iteration 62800, lr = 0.000344548
I0822 12:20:01.559216 31776 solver.cpp:228] Iteration 62900, loss = 0.000159243
I0822 12:20:01.559278 31776 solver.cpp:244]     Train net output #0: loss = 0.000159243 (* 1 = 0.000159243 loss)
I0822 12:20:01.559284 31776 sgd_solver.cpp:106] Iteration 62900, lr = 0.000344236
I0822 12:20:06.016505 31776 solver.cpp:337] Iteration 63000, Testing net (#0)
I0822 12:20:09.275564 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837958
I0822 12:20:09.275627 31776 solver.cpp:404]     Test net output #1: loss = 1.12193 (* 1 = 1.12193 loss)
I0822 12:20:09.290972 31776 solver.cpp:228] Iteration 63000, loss = 0.000152142
I0822 12:20:09.291035 31776 solver.cpp:244]     Train net output #0: loss = 0.000152142 (* 1 = 0.000152142 loss)
I0822 12:20:09.291046 31776 sgd_solver.cpp:106] Iteration 63000, lr = 0.000343925
I0822 12:20:13.795246 31776 solver.cpp:228] Iteration 63100, loss = 0.000252397
I0822 12:20:13.795302 31776 solver.cpp:244]     Train net output #0: loss = 0.000252397 (* 1 = 0.000252397 loss)
I0822 12:20:13.795311 31776 sgd_solver.cpp:106] Iteration 63100, lr = 0.000343615
I0822 12:20:18.298656 31776 solver.cpp:228] Iteration 63200, loss = 0.000323973
I0822 12:20:18.298712 31776 solver.cpp:244]     Train net output #0: loss = 0.000323973 (* 1 = 0.000323973 loss)
I0822 12:20:18.298719 31776 sgd_solver.cpp:106] Iteration 63200, lr = 0.000343305
I0822 12:20:22.804982 31776 solver.cpp:228] Iteration 63300, loss = 0.000173879
I0822 12:20:22.805035 31776 solver.cpp:244]     Train net output #0: loss = 0.000173879 (* 1 = 0.000173879 loss)
I0822 12:20:22.805043 31776 sgd_solver.cpp:106] Iteration 63300, lr = 0.000342996
I0822 12:20:27.307600 31776 solver.cpp:228] Iteration 63400, loss = 0.000262534
I0822 12:20:27.307652 31776 solver.cpp:244]     Train net output #0: loss = 0.000262534 (* 1 = 0.000262534 loss)
I0822 12:20:27.307660 31776 sgd_solver.cpp:106] Iteration 63400, lr = 0.000342687
I0822 12:20:31.765354 31776 solver.cpp:337] Iteration 63500, Testing net (#0)
I0822 12:20:34.982625 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838792
I0822 12:20:34.982686 31776 solver.cpp:404]     Test net output #1: loss = 1.12047 (* 1 = 1.12047 loss)
I0822 12:20:34.998101 31776 solver.cpp:228] Iteration 63500, loss = 0.000703765
I0822 12:20:34.998167 31776 solver.cpp:244]     Train net output #0: loss = 0.000703765 (* 1 = 0.000703765 loss)
I0822 12:20:34.998183 31776 sgd_solver.cpp:106] Iteration 63500, lr = 0.000342379
I0822 12:20:39.501631 31776 solver.cpp:228] Iteration 63600, loss = 0.000361856
I0822 12:20:39.501695 31776 solver.cpp:244]     Train net output #0: loss = 0.000361856 (* 1 = 0.000361856 loss)
I0822 12:20:39.501704 31776 sgd_solver.cpp:106] Iteration 63600, lr = 0.000342072
I0822 12:20:44.006444 31776 solver.cpp:228] Iteration 63700, loss = 0.000200577
I0822 12:20:44.006501 31776 solver.cpp:244]     Train net output #0: loss = 0.000200577 (* 1 = 0.000200577 loss)
I0822 12:20:44.006510 31776 sgd_solver.cpp:106] Iteration 63700, lr = 0.000341766
I0822 12:20:48.512115 31776 solver.cpp:228] Iteration 63800, loss = 0.000249415
I0822 12:20:48.512187 31776 solver.cpp:244]     Train net output #0: loss = 0.000249415 (* 1 = 0.000249415 loss)
I0822 12:20:48.512195 31776 sgd_solver.cpp:106] Iteration 63800, lr = 0.00034146
I0822 12:20:53.017706 31776 solver.cpp:228] Iteration 63900, loss = 0.000621239
I0822 12:20:53.017760 31776 solver.cpp:244]     Train net output #0: loss = 0.000621239 (* 1 = 0.000621239 loss)
I0822 12:20:53.017768 31776 sgd_solver.cpp:106] Iteration 63900, lr = 0.000341154
I0822 12:20:57.480058 31776 solver.cpp:337] Iteration 64000, Testing net (#0)
I0822 12:21:00.652494 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838292
I0822 12:21:00.652566 31776 solver.cpp:404]     Test net output #1: loss = 1.12382 (* 1 = 1.12382 loss)
I0822 12:21:00.667912 31776 solver.cpp:228] Iteration 64000, loss = 0.000553885
I0822 12:21:00.667973 31776 solver.cpp:244]     Train net output #0: loss = 0.000553885 (* 1 = 0.000553885 loss)
I0822 12:21:00.667984 31776 sgd_solver.cpp:106] Iteration 64000, lr = 0.00034085
I0822 12:21:05.174062 31776 solver.cpp:228] Iteration 64100, loss = 0.000603405
I0822 12:21:05.174118 31776 solver.cpp:244]     Train net output #0: loss = 0.000603405 (* 1 = 0.000603405 loss)
I0822 12:21:05.174126 31776 sgd_solver.cpp:106] Iteration 64100, lr = 0.000340546
I0822 12:21:09.681283 31776 solver.cpp:228] Iteration 64200, loss = 0.000711813
I0822 12:21:09.681344 31776 solver.cpp:244]     Train net output #0: loss = 0.000711813 (* 1 = 0.000711813 loss)
I0822 12:21:09.681351 31776 sgd_solver.cpp:106] Iteration 64200, lr = 0.000340242
I0822 12:21:14.181589 31776 solver.cpp:228] Iteration 64300, loss = 0.000181558
I0822 12:21:14.181635 31776 solver.cpp:244]     Train net output #0: loss = 0.000181558 (* 1 = 0.000181558 loss)
I0822 12:21:14.181644 31776 sgd_solver.cpp:106] Iteration 64300, lr = 0.00033994
I0822 12:21:18.683579 31776 solver.cpp:228] Iteration 64400, loss = 0.00039028
I0822 12:21:18.683634 31776 solver.cpp:244]     Train net output #0: loss = 0.00039028 (* 1 = 0.00039028 loss)
I0822 12:21:18.683642 31776 sgd_solver.cpp:106] Iteration 64400, lr = 0.000339638
I0822 12:21:23.145912 31776 solver.cpp:337] Iteration 64500, Testing net (#0)
I0822 12:21:26.451578 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838417
I0822 12:21:26.451638 31776 solver.cpp:404]     Test net output #1: loss = 1.12872 (* 1 = 1.12872 loss)
I0822 12:21:26.467059 31776 solver.cpp:228] Iteration 64500, loss = 0.000469783
I0822 12:21:26.467142 31776 solver.cpp:244]     Train net output #0: loss = 0.000469783 (* 1 = 0.000469783 loss)
I0822 12:21:26.467152 31776 sgd_solver.cpp:106] Iteration 64500, lr = 0.000339336
I0822 12:21:30.970999 31776 solver.cpp:228] Iteration 64600, loss = 0.000140481
I0822 12:21:30.971063 31776 solver.cpp:244]     Train net output #0: loss = 0.000140481 (* 1 = 0.000140481 loss)
I0822 12:21:30.971073 31776 sgd_solver.cpp:106] Iteration 64600, lr = 0.000339035
I0822 12:21:35.476527 31776 solver.cpp:228] Iteration 64700, loss = 0.000143821
I0822 12:21:35.476588 31776 solver.cpp:244]     Train net output #0: loss = 0.000143821 (* 1 = 0.000143821 loss)
I0822 12:21:35.476596 31776 sgd_solver.cpp:106] Iteration 64700, lr = 0.000338735
I0822 12:21:39.977768 31776 solver.cpp:228] Iteration 64800, loss = 0.0001493
I0822 12:21:39.977826 31776 solver.cpp:244]     Train net output #0: loss = 0.0001493 (* 1 = 0.0001493 loss)
I0822 12:21:39.977835 31776 sgd_solver.cpp:106] Iteration 64800, lr = 0.000338435
I0822 12:21:44.484350 31776 solver.cpp:228] Iteration 64900, loss = 0.000301274
I0822 12:21:44.484406 31776 solver.cpp:244]     Train net output #0: loss = 0.000301274 (* 1 = 0.000301274 loss)
I0822 12:21:44.484414 31776 sgd_solver.cpp:106] Iteration 64900, lr = 0.000338136
I0822 12:21:48.944715 31776 solver.cpp:337] Iteration 65000, Testing net (#0)
I0822 12:21:52.214890 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837875
I0822 12:21:52.214959 31776 solver.cpp:404]     Test net output #1: loss = 1.13198 (* 1 = 1.13198 loss)
I0822 12:21:52.232573 31776 solver.cpp:228] Iteration 65000, loss = 0.000364494
I0822 12:21:52.232640 31776 solver.cpp:244]     Train net output #0: loss = 0.000364494 (* 1 = 0.000364494 loss)
I0822 12:21:52.232650 31776 sgd_solver.cpp:106] Iteration 65000, lr = 0.000337838
I0822 12:21:56.736312 31776 solver.cpp:228] Iteration 65100, loss = 0.000236507
I0822 12:21:56.736354 31776 solver.cpp:244]     Train net output #0: loss = 0.000236507 (* 1 = 0.000236507 loss)
I0822 12:21:56.736362 31776 sgd_solver.cpp:106] Iteration 65100, lr = 0.00033754
I0822 12:22:01.242760 31776 solver.cpp:228] Iteration 65200, loss = 0.000241153
I0822 12:22:01.242815 31776 solver.cpp:244]     Train net output #0: loss = 0.000241153 (* 1 = 0.000241153 loss)
I0822 12:22:01.242823 31776 sgd_solver.cpp:106] Iteration 65200, lr = 0.000337243
I0822 12:22:05.748760 31776 solver.cpp:228] Iteration 65300, loss = 0.000174043
I0822 12:22:05.748816 31776 solver.cpp:244]     Train net output #0: loss = 0.000174043 (* 1 = 0.000174043 loss)
I0822 12:22:05.748824 31776 sgd_solver.cpp:106] Iteration 65300, lr = 0.000336946
I0822 12:22:10.254793 31776 solver.cpp:228] Iteration 65400, loss = 0.000293203
I0822 12:22:10.254838 31776 solver.cpp:244]     Train net output #0: loss = 0.000293203 (* 1 = 0.000293203 loss)
I0822 12:22:10.254847 31776 sgd_solver.cpp:106] Iteration 65400, lr = 0.00033665
I0822 12:22:14.716051 31776 solver.cpp:337] Iteration 65500, Testing net (#0)
I0822 12:22:15.422338 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:22:18.020311 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836875
I0822 12:22:18.020373 31776 solver.cpp:404]     Test net output #1: loss = 1.14134 (* 1 = 1.14134 loss)
I0822 12:22:18.035720 31776 solver.cpp:228] Iteration 65500, loss = 0.000210292
I0822 12:22:18.035796 31776 solver.cpp:244]     Train net output #0: loss = 0.000210292 (* 1 = 0.000210292 loss)
I0822 12:22:18.035809 31776 sgd_solver.cpp:106] Iteration 65500, lr = 0.000336355
I0822 12:22:22.541524 31776 solver.cpp:228] Iteration 65600, loss = 0.000124592
I0822 12:22:22.541568 31776 solver.cpp:244]     Train net output #0: loss = 0.000124592 (* 1 = 0.000124592 loss)
I0822 12:22:22.541576 31776 sgd_solver.cpp:106] Iteration 65600, lr = 0.00033606
I0822 12:22:27.043375 31776 solver.cpp:228] Iteration 65700, loss = 0.00025206
I0822 12:22:27.043421 31776 solver.cpp:244]     Train net output #0: loss = 0.00025206 (* 1 = 0.00025206 loss)
I0822 12:22:27.043429 31776 sgd_solver.cpp:106] Iteration 65700, lr = 0.000335766
I0822 12:22:31.546460 31776 solver.cpp:228] Iteration 65800, loss = 0.000231234
I0822 12:22:31.546502 31776 solver.cpp:244]     Train net output #0: loss = 0.000231234 (* 1 = 0.000231234 loss)
I0822 12:22:31.546510 31776 sgd_solver.cpp:106] Iteration 65800, lr = 0.000335473
I0822 12:22:36.054370 31776 solver.cpp:228] Iteration 65900, loss = 0.000266678
I0822 12:22:36.054430 31776 solver.cpp:244]     Train net output #0: loss = 0.000266678 (* 1 = 0.000266678 loss)
I0822 12:22:36.054440 31776 sgd_solver.cpp:106] Iteration 65900, lr = 0.00033518
I0822 12:22:40.513872 31776 solver.cpp:337] Iteration 66000, Testing net (#0)
I0822 12:22:43.721956 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837292
I0822 12:22:43.722007 31776 solver.cpp:404]     Test net output #1: loss = 1.14355 (* 1 = 1.14355 loss)
I0822 12:22:43.737404 31776 solver.cpp:228] Iteration 66000, loss = 0.000107767
I0822 12:22:43.737478 31776 solver.cpp:244]     Train net output #0: loss = 0.000107767 (* 1 = 0.000107767 loss)
I0822 12:22:43.737488 31776 sgd_solver.cpp:106] Iteration 66000, lr = 0.000334887
I0822 12:22:48.245285 31776 solver.cpp:228] Iteration 66100, loss = 0.000328947
I0822 12:22:48.245340 31776 solver.cpp:244]     Train net output #0: loss = 0.000328947 (* 1 = 0.000328947 loss)
I0822 12:22:48.245349 31776 sgd_solver.cpp:106] Iteration 66100, lr = 0.000334596
I0822 12:22:52.748904 31776 solver.cpp:228] Iteration 66200, loss = 0.000366155
I0822 12:22:52.748962 31776 solver.cpp:244]     Train net output #0: loss = 0.000366155 (* 1 = 0.000366155 loss)
I0822 12:22:52.748970 31776 sgd_solver.cpp:106] Iteration 66200, lr = 0.000334304
I0822 12:22:57.250305 31776 solver.cpp:228] Iteration 66300, loss = 0.000286584
I0822 12:22:57.250365 31776 solver.cpp:244]     Train net output #0: loss = 0.000286584 (* 1 = 0.000286584 loss)
I0822 12:22:57.250375 31776 sgd_solver.cpp:106] Iteration 66300, lr = 0.000334014
I0822 12:23:01.755987 31776 solver.cpp:228] Iteration 66400, loss = 0.000174761
I0822 12:23:01.756048 31776 solver.cpp:244]     Train net output #0: loss = 0.000174761 (* 1 = 0.000174761 loss)
I0822 12:23:01.756057 31776 sgd_solver.cpp:106] Iteration 66400, lr = 0.000333724
I0822 12:23:06.216507 31776 solver.cpp:337] Iteration 66500, Testing net (#0)
I0822 12:23:09.410524 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837708
I0822 12:23:09.410584 31776 solver.cpp:404]     Test net output #1: loss = 1.14301 (* 1 = 1.14301 loss)
I0822 12:23:09.426007 31776 solver.cpp:228] Iteration 66500, loss = 0.00031452
I0822 12:23:09.426089 31776 solver.cpp:244]     Train net output #0: loss = 0.00031452 (* 1 = 0.00031452 loss)
I0822 12:23:09.426100 31776 sgd_solver.cpp:106] Iteration 66500, lr = 0.000333434
I0822 12:23:13.931725 31776 solver.cpp:228] Iteration 66600, loss = 0.000212485
I0822 12:23:13.931780 31776 solver.cpp:244]     Train net output #0: loss = 0.000212485 (* 1 = 0.000212485 loss)
I0822 12:23:13.931789 31776 sgd_solver.cpp:106] Iteration 66600, lr = 0.000333146
I0822 12:23:18.437703 31776 solver.cpp:228] Iteration 66700, loss = 0.000144994
I0822 12:23:18.437757 31776 solver.cpp:244]     Train net output #0: loss = 0.000144994 (* 1 = 0.000144994 loss)
I0822 12:23:18.437764 31776 sgd_solver.cpp:106] Iteration 66700, lr = 0.000332857
I0822 12:23:22.943872 31776 solver.cpp:228] Iteration 66800, loss = 0.000166803
I0822 12:23:22.943935 31776 solver.cpp:244]     Train net output #0: loss = 0.000166803 (* 1 = 0.000166803 loss)
I0822 12:23:22.943945 31776 sgd_solver.cpp:106] Iteration 66800, lr = 0.00033257
I0822 12:23:27.451392 31776 solver.cpp:228] Iteration 66900, loss = 0.000217359
I0822 12:23:27.451450 31776 solver.cpp:244]     Train net output #0: loss = 0.000217359 (* 1 = 0.000217359 loss)
I0822 12:23:27.451458 31776 sgd_solver.cpp:106] Iteration 66900, lr = 0.000332283
I0822 12:23:31.912626 31776 solver.cpp:337] Iteration 67000, Testing net (#0)
I0822 12:23:35.191829 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837333
I0822 12:23:35.191887 31776 solver.cpp:404]     Test net output #1: loss = 1.1487 (* 1 = 1.1487 loss)
I0822 12:23:35.207265 31776 solver.cpp:228] Iteration 67000, loss = 0.000243027
I0822 12:23:35.207339 31776 solver.cpp:244]     Train net output #0: loss = 0.000243027 (* 1 = 0.000243027 loss)
I0822 12:23:35.207350 31776 sgd_solver.cpp:106] Iteration 67000, lr = 0.000331996
I0822 12:23:39.715246 31776 solver.cpp:228] Iteration 67100, loss = 0.000373741
I0822 12:23:39.715302 31776 solver.cpp:244]     Train net output #0: loss = 0.000373741 (* 1 = 0.000373741 loss)
I0822 12:23:39.715311 31776 sgd_solver.cpp:106] Iteration 67100, lr = 0.00033171
I0822 12:23:44.220547 31776 solver.cpp:228] Iteration 67200, loss = 0.000174239
I0822 12:23:44.220588 31776 solver.cpp:244]     Train net output #0: loss = 0.000174239 (* 1 = 0.000174239 loss)
I0822 12:23:44.220597 31776 sgd_solver.cpp:106] Iteration 67200, lr = 0.000331425
I0822 12:23:48.729473 31776 solver.cpp:228] Iteration 67300, loss = 0.00017654
I0822 12:23:48.729535 31776 solver.cpp:244]     Train net output #0: loss = 0.00017654 (* 1 = 0.00017654 loss)
I0822 12:23:48.729544 31776 sgd_solver.cpp:106] Iteration 67300, lr = 0.00033114
I0822 12:23:53.233573 31776 solver.cpp:228] Iteration 67400, loss = 0.000261011
I0822 12:23:53.233621 31776 solver.cpp:244]     Train net output #0: loss = 0.000261011 (* 1 = 0.000261011 loss)
I0822 12:23:53.233629 31776 sgd_solver.cpp:106] Iteration 67400, lr = 0.000330856
I0822 12:23:57.694713 31776 solver.cpp:337] Iteration 67500, Testing net (#0)
I0822 12:24:00.970953 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836584
I0822 12:24:00.971016 31776 solver.cpp:404]     Test net output #1: loss = 1.15615 (* 1 = 1.15615 loss)
I0822 12:24:00.986352 31776 solver.cpp:228] Iteration 67500, loss = 0.000131459
I0822 12:24:00.986407 31776 solver.cpp:244]     Train net output #0: loss = 0.000131459 (* 1 = 0.000131459 loss)
I0822 12:24:00.986418 31776 sgd_solver.cpp:106] Iteration 67500, lr = 0.000330572
I0822 12:24:05.487176 31776 solver.cpp:228] Iteration 67600, loss = 0.000154131
I0822 12:24:05.487237 31776 solver.cpp:244]     Train net output #0: loss = 0.000154131 (* 1 = 0.000154131 loss)
I0822 12:24:05.487246 31776 sgd_solver.cpp:106] Iteration 67600, lr = 0.000330289
I0822 12:24:09.989785 31776 solver.cpp:228] Iteration 67700, loss = 0.000207027
I0822 12:24:09.989841 31776 solver.cpp:244]     Train net output #0: loss = 0.000207027 (* 1 = 0.000207027 loss)
I0822 12:24:09.989850 31776 sgd_solver.cpp:106] Iteration 67700, lr = 0.000330007
I0822 12:24:14.496184 31776 solver.cpp:228] Iteration 67800, loss = 0.00026417
I0822 12:24:14.496235 31776 solver.cpp:244]     Train net output #0: loss = 0.00026417 (* 1 = 0.00026417 loss)
I0822 12:24:14.496244 31776 sgd_solver.cpp:106] Iteration 67800, lr = 0.000329725
I0822 12:24:19.001730 31776 solver.cpp:228] Iteration 67900, loss = 0.000123106
I0822 12:24:19.001786 31776 solver.cpp:244]     Train net output #0: loss = 0.000123106 (* 1 = 0.000123106 loss)
I0822 12:24:19.001794 31776 sgd_solver.cpp:106] Iteration 67900, lr = 0.000329443
I0822 12:24:23.459055 31776 solver.cpp:337] Iteration 68000, Testing net (#0)
I0822 12:24:26.724725 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836542
I0822 12:24:26.724788 31776 solver.cpp:404]     Test net output #1: loss = 1.16241 (* 1 = 1.16241 loss)
I0822 12:24:26.740232 31776 solver.cpp:228] Iteration 68000, loss = 0.000148839
I0822 12:24:26.740298 31776 solver.cpp:244]     Train net output #0: loss = 0.000148839 (* 1 = 0.000148839 loss)
I0822 12:24:26.740309 31776 sgd_solver.cpp:106] Iteration 68000, lr = 0.000329163
I0822 12:24:31.248558 31776 solver.cpp:228] Iteration 68100, loss = 0.000215546
I0822 12:24:31.248622 31776 solver.cpp:244]     Train net output #0: loss = 0.000215546 (* 1 = 0.000215546 loss)
I0822 12:24:31.248631 31776 sgd_solver.cpp:106] Iteration 68100, lr = 0.000328882
I0822 12:24:35.751221 31776 solver.cpp:228] Iteration 68200, loss = 0.000462352
I0822 12:24:35.751281 31776 solver.cpp:244]     Train net output #0: loss = 0.000462352 (* 1 = 0.000462352 loss)
I0822 12:24:35.751289 31776 sgd_solver.cpp:106] Iteration 68200, lr = 0.000328603
I0822 12:24:40.254710 31776 solver.cpp:228] Iteration 68300, loss = 0.000357048
I0822 12:24:40.254757 31776 solver.cpp:244]     Train net output #0: loss = 0.000357048 (* 1 = 0.000357048 loss)
I0822 12:24:40.254765 31776 sgd_solver.cpp:106] Iteration 68300, lr = 0.000328324
I0822 12:24:44.763126 31776 solver.cpp:228] Iteration 68400, loss = 0.000283321
I0822 12:24:44.763180 31776 solver.cpp:244]     Train net output #0: loss = 0.000283321 (* 1 = 0.000283321 loss)
I0822 12:24:44.763190 31776 sgd_solver.cpp:106] Iteration 68400, lr = 0.000328045
I0822 12:24:49.227434 31776 solver.cpp:337] Iteration 68500, Testing net (#0)
I0822 12:24:52.612690 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836292
I0822 12:24:52.612752 31776 solver.cpp:404]     Test net output #1: loss = 1.16852 (* 1 = 1.16852 loss)
I0822 12:24:52.628119 31776 solver.cpp:228] Iteration 68500, loss = 0.000311506
I0822 12:24:52.628185 31776 solver.cpp:244]     Train net output #0: loss = 0.000311506 (* 1 = 0.000311506 loss)
I0822 12:24:52.628199 31776 sgd_solver.cpp:106] Iteration 68500, lr = 0.000327767
I0822 12:24:57.132796 31776 solver.cpp:228] Iteration 68600, loss = 0.00031259
I0822 12:24:57.132851 31776 solver.cpp:244]     Train net output #0: loss = 0.00031259 (* 1 = 0.00031259 loss)
I0822 12:24:57.132859 31776 sgd_solver.cpp:106] Iteration 68600, lr = 0.000327489
I0822 12:25:01.638818 31776 solver.cpp:228] Iteration 68700, loss = 0.00025822
I0822 12:25:01.638877 31776 solver.cpp:244]     Train net output #0: loss = 0.00025822 (* 1 = 0.00025822 loss)
I0822 12:25:01.638886 31776 sgd_solver.cpp:106] Iteration 68700, lr = 0.000327212
I0822 12:25:06.140748 31776 solver.cpp:228] Iteration 68800, loss = 0.000432304
I0822 12:25:06.140802 31776 solver.cpp:244]     Train net output #0: loss = 0.000432304 (* 1 = 0.000432304 loss)
I0822 12:25:06.140810 31776 sgd_solver.cpp:106] Iteration 68800, lr = 0.000326936
I0822 12:25:10.645184 31776 solver.cpp:228] Iteration 68900, loss = 0.000146176
I0822 12:25:10.645238 31776 solver.cpp:244]     Train net output #0: loss = 0.000146176 (* 1 = 0.000146176 loss)
I0822 12:25:10.645246 31776 sgd_solver.cpp:106] Iteration 68900, lr = 0.00032666
I0822 12:25:15.106384 31776 solver.cpp:337] Iteration 69000, Testing net (#0)
I0822 12:25:18.370352 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835542
I0822 12:25:18.370417 31776 solver.cpp:404]     Test net output #1: loss = 1.17631 (* 1 = 1.17631 loss)
I0822 12:25:18.385792 31776 solver.cpp:228] Iteration 69000, loss = 0.00014359
I0822 12:25:18.385845 31776 solver.cpp:244]     Train net output #0: loss = 0.00014359 (* 1 = 0.00014359 loss)
I0822 12:25:18.385859 31776 sgd_solver.cpp:106] Iteration 69000, lr = 0.000326385
I0822 12:25:22.891732 31776 solver.cpp:228] Iteration 69100, loss = 0.000618712
I0822 12:25:22.891791 31776 solver.cpp:244]     Train net output #0: loss = 0.000618712 (* 1 = 0.000618712 loss)
I0822 12:25:22.891800 31776 sgd_solver.cpp:106] Iteration 69100, lr = 0.00032611
I0822 12:25:27.397197 31776 solver.cpp:228] Iteration 69200, loss = 0.000313634
I0822 12:25:27.397258 31776 solver.cpp:244]     Train net output #0: loss = 0.000313634 (* 1 = 0.000313634 loss)
I0822 12:25:27.397266 31776 sgd_solver.cpp:106] Iteration 69200, lr = 0.000325836
I0822 12:25:31.900874 31776 solver.cpp:228] Iteration 69300, loss = 0.000322559
I0822 12:25:31.900938 31776 solver.cpp:244]     Train net output #0: loss = 0.000322559 (* 1 = 0.000322559 loss)
I0822 12:25:31.900945 31776 sgd_solver.cpp:106] Iteration 69300, lr = 0.000325562
I0822 12:25:36.400868 31776 solver.cpp:228] Iteration 69400, loss = 0.000206466
I0822 12:25:36.400926 31776 solver.cpp:244]     Train net output #0: loss = 0.000206466 (* 1 = 0.000206466 loss)
I0822 12:25:36.400934 31776 sgd_solver.cpp:106] Iteration 69400, lr = 0.000325289
I0822 12:25:40.860790 31776 solver.cpp:337] Iteration 69500, Testing net (#0)
I0822 12:25:44.118000 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834875
I0822 12:25:44.118062 31776 solver.cpp:404]     Test net output #1: loss = 1.18295 (* 1 = 1.18295 loss)
I0822 12:25:44.133414 31776 solver.cpp:228] Iteration 69500, loss = 0.000183128
I0822 12:25:44.133487 31776 solver.cpp:244]     Train net output #0: loss = 0.000183128 (* 1 = 0.000183128 loss)
I0822 12:25:44.133497 31776 sgd_solver.cpp:106] Iteration 69500, lr = 0.000325016
I0822 12:25:48.637290 31776 solver.cpp:228] Iteration 69600, loss = 0.000165638
I0822 12:25:48.637346 31776 solver.cpp:244]     Train net output #0: loss = 0.000165638 (* 1 = 0.000165638 loss)
I0822 12:25:48.637357 31776 sgd_solver.cpp:106] Iteration 69600, lr = 0.000324744
I0822 12:25:53.145860 31776 solver.cpp:228] Iteration 69700, loss = 0.000280238
I0822 12:25:53.145920 31776 solver.cpp:244]     Train net output #0: loss = 0.000280238 (* 1 = 0.000280238 loss)
I0822 12:25:53.145928 31776 sgd_solver.cpp:106] Iteration 69700, lr = 0.000324473
I0822 12:25:57.653337 31776 solver.cpp:228] Iteration 69800, loss = 0.000123083
I0822 12:25:57.653400 31776 solver.cpp:244]     Train net output #0: loss = 0.000123083 (* 1 = 0.000123083 loss)
I0822 12:25:57.653408 31776 sgd_solver.cpp:106] Iteration 69800, lr = 0.000324202
I0822 12:26:02.159495 31776 solver.cpp:228] Iteration 69900, loss = 0.000102324
I0822 12:26:02.159550 31776 solver.cpp:244]     Train net output #0: loss = 0.000102324 (* 1 = 0.000102324 loss)
I0822 12:26:02.159559 31776 sgd_solver.cpp:106] Iteration 69900, lr = 0.000323931
I0822 12:26:06.619057 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_70000.caffemodel
I0822 12:26:07.106276 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_70000.solverstate
I0822 12:26:07.263675 31776 solver.cpp:337] Iteration 70000, Testing net (#0)
I0822 12:26:10.502360 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8345
I0822 12:26:10.502418 31776 solver.cpp:404]     Test net output #1: loss = 1.19122 (* 1 = 1.19122 loss)
I0822 12:26:10.517802 31776 solver.cpp:228] Iteration 70000, loss = 0.000120999
I0822 12:26:10.517870 31776 solver.cpp:244]     Train net output #0: loss = 0.000120999 (* 1 = 0.000120999 loss)
I0822 12:26:10.517880 31776 sgd_solver.cpp:106] Iteration 70000, lr = 0.000323661
I0822 12:26:15.019357 31776 solver.cpp:228] Iteration 70100, loss = 0.000177074
I0822 12:26:15.019405 31776 solver.cpp:244]     Train net output #0: loss = 0.000177074 (* 1 = 0.000177074 loss)
I0822 12:26:15.019413 31776 sgd_solver.cpp:106] Iteration 70100, lr = 0.000323392
I0822 12:26:19.526302 31776 solver.cpp:228] Iteration 70200, loss = 0.000136436
I0822 12:26:19.526355 31776 solver.cpp:244]     Train net output #0: loss = 0.000136436 (* 1 = 0.000136436 loss)
I0822 12:26:19.526363 31776 sgd_solver.cpp:106] Iteration 70200, lr = 0.000323123
I0822 12:26:24.031849 31776 solver.cpp:228] Iteration 70300, loss = 0.000185619
I0822 12:26:24.031893 31776 solver.cpp:244]     Train net output #0: loss = 0.000185619 (* 1 = 0.000185619 loss)
I0822 12:26:24.031900 31776 sgd_solver.cpp:106] Iteration 70300, lr = 0.000322854
I0822 12:26:28.537626 31776 solver.cpp:228] Iteration 70400, loss = 0.000200442
I0822 12:26:28.537672 31776 solver.cpp:244]     Train net output #0: loss = 0.000200442 (* 1 = 0.000200442 loss)
I0822 12:26:28.537679 31776 sgd_solver.cpp:106] Iteration 70400, lr = 0.000322587
I0822 12:26:32.998765 31776 solver.cpp:337] Iteration 70500, Testing net (#0)
I0822 12:26:36.207630 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834042
I0822 12:26:36.207682 31776 solver.cpp:404]     Test net output #1: loss = 1.19144 (* 1 = 1.19144 loss)
I0822 12:26:36.223106 31776 solver.cpp:228] Iteration 70500, loss = 0.000258525
I0822 12:26:36.223183 31776 solver.cpp:244]     Train net output #0: loss = 0.000258525 (* 1 = 0.000258525 loss)
I0822 12:26:36.223194 31776 sgd_solver.cpp:106] Iteration 70500, lr = 0.000322319
I0822 12:26:40.727614 31776 solver.cpp:228] Iteration 70600, loss = 0.000251233
I0822 12:26:40.727676 31776 solver.cpp:244]     Train net output #0: loss = 0.000251233 (* 1 = 0.000251233 loss)
I0822 12:26:40.727684 31776 sgd_solver.cpp:106] Iteration 70600, lr = 0.000322052
I0822 12:26:45.235090 31776 solver.cpp:228] Iteration 70700, loss = 0.000164573
I0822 12:26:45.235144 31776 solver.cpp:244]     Train net output #0: loss = 0.000164573 (* 1 = 0.000164573 loss)
I0822 12:26:45.235153 31776 sgd_solver.cpp:106] Iteration 70700, lr = 0.000321786
I0822 12:26:49.740649 31776 solver.cpp:228] Iteration 70800, loss = 0.000118175
I0822 12:26:49.740702 31776 solver.cpp:244]     Train net output #0: loss = 0.000118175 (* 1 = 0.000118175 loss)
I0822 12:26:49.740710 31776 sgd_solver.cpp:106] Iteration 70800, lr = 0.00032152
I0822 12:26:54.248442 31776 solver.cpp:228] Iteration 70900, loss = 0.000277962
I0822 12:26:54.248499 31776 solver.cpp:244]     Train net output #0: loss = 0.000277962 (* 1 = 0.000277962 loss)
I0822 12:26:54.248510 31776 sgd_solver.cpp:106] Iteration 70900, lr = 0.000321255
I0822 12:26:58.709822 31776 solver.cpp:337] Iteration 71000, Testing net (#0)
I0822 12:27:01.996343 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834084
I0822 12:27:01.996403 31776 solver.cpp:404]     Test net output #1: loss = 1.19512 (* 1 = 1.19512 loss)
I0822 12:27:02.011852 31776 solver.cpp:228] Iteration 71000, loss = 9.33385e-05
I0822 12:27:02.011940 31776 solver.cpp:244]     Train net output #0: loss = 9.33385e-05 (* 1 = 9.33385e-05 loss)
I0822 12:27:02.011951 31776 sgd_solver.cpp:106] Iteration 71000, lr = 0.00032099
I0822 12:27:06.518009 31776 solver.cpp:228] Iteration 71100, loss = 0.000276279
I0822 12:27:06.518069 31776 solver.cpp:244]     Train net output #0: loss = 0.000276279 (* 1 = 0.000276279 loss)
I0822 12:27:06.518079 31776 sgd_solver.cpp:106] Iteration 71100, lr = 0.000320726
I0822 12:27:11.021430 31776 solver.cpp:228] Iteration 71200, loss = 0.00016518
I0822 12:27:11.021487 31776 solver.cpp:244]     Train net output #0: loss = 0.00016518 (* 1 = 0.00016518 loss)
I0822 12:27:11.021508 31776 sgd_solver.cpp:106] Iteration 71200, lr = 0.000320462
I0822 12:27:15.528479 31776 solver.cpp:228] Iteration 71300, loss = 0.000222635
I0822 12:27:15.528553 31776 solver.cpp:244]     Train net output #0: loss = 0.000222635 (* 1 = 0.000222635 loss)
I0822 12:27:15.528574 31776 sgd_solver.cpp:106] Iteration 71300, lr = 0.000320199
I0822 12:27:20.030486 31776 solver.cpp:228] Iteration 71400, loss = 0.000193337
I0822 12:27:20.030544 31776 solver.cpp:244]     Train net output #0: loss = 0.000193337 (* 1 = 0.000193337 loss)
I0822 12:27:20.030551 31776 sgd_solver.cpp:106] Iteration 71400, lr = 0.000319936
I0822 12:27:24.488237 31776 solver.cpp:337] Iteration 71500, Testing net (#0)
I0822 12:27:27.741053 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834209
I0822 12:27:27.741112 31776 solver.cpp:404]     Test net output #1: loss = 1.19497 (* 1 = 1.19497 loss)
I0822 12:27:27.756502 31776 solver.cpp:228] Iteration 71500, loss = 0.000180235
I0822 12:27:27.756567 31776 solver.cpp:244]     Train net output #0: loss = 0.000180235 (* 1 = 0.000180235 loss)
I0822 12:27:27.756578 31776 sgd_solver.cpp:106] Iteration 71500, lr = 0.000319674
I0822 12:27:32.260552 31776 solver.cpp:228] Iteration 71600, loss = 0.000114157
I0822 12:27:32.260612 31776 solver.cpp:244]     Train net output #0: loss = 0.000114157 (* 1 = 0.000114157 loss)
I0822 12:27:32.260620 31776 sgd_solver.cpp:106] Iteration 71600, lr = 0.000319412
I0822 12:27:36.761239 31776 solver.cpp:228] Iteration 71700, loss = 0.000160121
I0822 12:27:36.761296 31776 solver.cpp:244]     Train net output #0: loss = 0.000160121 (* 1 = 0.000160121 loss)
I0822 12:27:36.761306 31776 sgd_solver.cpp:106] Iteration 71700, lr = 0.00031915
I0822 12:27:41.266711 31776 solver.cpp:228] Iteration 71800, loss = 9.98269e-05
I0822 12:27:41.266767 31776 solver.cpp:244]     Train net output #0: loss = 9.98269e-05 (* 1 = 9.98269e-05 loss)
I0822 12:27:41.266774 31776 sgd_solver.cpp:106] Iteration 71800, lr = 0.00031889
I0822 12:27:45.770236 31776 solver.cpp:228] Iteration 71900, loss = 0.000148288
I0822 12:27:45.770295 31776 solver.cpp:244]     Train net output #0: loss = 0.000148288 (* 1 = 0.000148288 loss)
I0822 12:27:45.770303 31776 sgd_solver.cpp:106] Iteration 71900, lr = 0.000318629
I0822 12:27:50.231338 31776 solver.cpp:337] Iteration 72000, Testing net (#0)
I0822 12:27:53.511615 31776 solver.cpp:404]     Test net output #0: accuracy = 0.834042
I0822 12:27:53.511682 31776 solver.cpp:404]     Test net output #1: loss = 1.19668 (* 1 = 1.19668 loss)
I0822 12:27:53.527006 31776 solver.cpp:228] Iteration 72000, loss = 0.000206782
I0822 12:27:53.527071 31776 solver.cpp:244]     Train net output #0: loss = 0.000206782 (* 1 = 0.000206782 loss)
I0822 12:27:53.527081 31776 sgd_solver.cpp:106] Iteration 72000, lr = 0.00031837
I0822 12:27:58.030944 31776 solver.cpp:228] Iteration 72100, loss = 0.000168109
I0822 12:27:58.030999 31776 solver.cpp:244]     Train net output #0: loss = 0.000168109 (* 1 = 0.000168109 loss)
I0822 12:27:58.031008 31776 sgd_solver.cpp:106] Iteration 72100, lr = 0.00031811
I0822 12:28:02.535743 31776 solver.cpp:228] Iteration 72200, loss = 9.02759e-05
I0822 12:28:02.535802 31776 solver.cpp:244]     Train net output #0: loss = 9.02759e-05 (* 1 = 9.02759e-05 loss)
I0822 12:28:02.535811 31776 sgd_solver.cpp:106] Iteration 72200, lr = 0.000317852
I0822 12:28:07.042613 31776 solver.cpp:228] Iteration 72300, loss = 0.00011243
I0822 12:28:07.042670 31776 solver.cpp:244]     Train net output #0: loss = 0.00011243 (* 1 = 0.00011243 loss)
I0822 12:28:07.042677 31776 sgd_solver.cpp:106] Iteration 72300, lr = 0.000317593
I0822 12:28:11.547821 31776 solver.cpp:228] Iteration 72400, loss = 4.85947e-05
I0822 12:28:11.547878 31776 solver.cpp:244]     Train net output #0: loss = 4.85947e-05 (* 1 = 4.85947e-05 loss)
I0822 12:28:11.547886 31776 sgd_solver.cpp:106] Iteration 72400, lr = 0.000317335
I0822 12:28:16.010041 31776 solver.cpp:337] Iteration 72500, Testing net (#0)
I0822 12:28:19.257370 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8345
I0822 12:28:19.257429 31776 solver.cpp:404]     Test net output #1: loss = 1.19568 (* 1 = 1.19568 loss)
I0822 12:28:19.272797 31776 solver.cpp:228] Iteration 72500, loss = 0.000264695
I0822 12:28:19.272878 31776 solver.cpp:244]     Train net output #0: loss = 0.000264695 (* 1 = 0.000264695 loss)
I0822 12:28:19.272892 31776 sgd_solver.cpp:106] Iteration 72500, lr = 0.000317078
I0822 12:28:23.777654 31776 solver.cpp:228] Iteration 72600, loss = 0.000127902
I0822 12:28:23.777710 31776 solver.cpp:244]     Train net output #0: loss = 0.000127902 (* 1 = 0.000127902 loss)
I0822 12:28:23.777719 31776 sgd_solver.cpp:106] Iteration 72600, lr = 0.000316821
I0822 12:28:28.283903 31776 solver.cpp:228] Iteration 72700, loss = 0.000171886
I0822 12:28:28.283958 31776 solver.cpp:244]     Train net output #0: loss = 0.000171886 (* 1 = 0.000171886 loss)
I0822 12:28:28.283967 31776 sgd_solver.cpp:106] Iteration 72700, lr = 0.000316565
I0822 12:28:32.789242 31776 solver.cpp:228] Iteration 72800, loss = 0.000286127
I0822 12:28:32.789296 31776 solver.cpp:244]     Train net output #0: loss = 0.000286127 (* 1 = 0.000286127 loss)
I0822 12:28:32.789306 31776 sgd_solver.cpp:106] Iteration 72800, lr = 0.000316309
I0822 12:28:37.296272 31776 solver.cpp:228] Iteration 72900, loss = 0.000163845
I0822 12:28:37.296329 31776 solver.cpp:244]     Train net output #0: loss = 0.000163845 (* 1 = 0.000163845 loss)
I0822 12:28:37.296337 31776 sgd_solver.cpp:106] Iteration 72900, lr = 0.000316054
I0822 12:28:41.756279 31776 solver.cpp:337] Iteration 73000, Testing net (#0)
I0822 12:28:42.247424 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:28:44.949142 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835542
I0822 12:28:44.949205 31776 solver.cpp:404]     Test net output #1: loss = 1.19565 (* 1 = 1.19565 loss)
I0822 12:28:44.964637 31776 solver.cpp:228] Iteration 73000, loss = 0.000218329
I0822 12:28:44.964710 31776 solver.cpp:244]     Train net output #0: loss = 0.000218329 (* 1 = 0.000218329 loss)
I0822 12:28:44.964721 31776 sgd_solver.cpp:106] Iteration 73000, lr = 0.000315799
I0822 12:28:49.471940 31776 solver.cpp:228] Iteration 73100, loss = 0.000180799
I0822 12:28:49.472007 31776 solver.cpp:244]     Train net output #0: loss = 0.000180799 (* 1 = 0.000180799 loss)
I0822 12:28:49.472017 31776 sgd_solver.cpp:106] Iteration 73100, lr = 0.000315544
I0822 12:28:53.977581 31776 solver.cpp:228] Iteration 73200, loss = 0.000189373
I0822 12:28:53.977637 31776 solver.cpp:244]     Train net output #0: loss = 0.000189373 (* 1 = 0.000189373 loss)
I0822 12:28:53.977645 31776 sgd_solver.cpp:106] Iteration 73200, lr = 0.00031529
I0822 12:28:58.483567 31776 solver.cpp:228] Iteration 73300, loss = 9.9429e-05
I0822 12:28:58.483624 31776 solver.cpp:244]     Train net output #0: loss = 9.9429e-05 (* 1 = 9.9429e-05 loss)
I0822 12:28:58.483633 31776 sgd_solver.cpp:106] Iteration 73300, lr = 0.000315037
I0822 12:29:02.990058 31776 solver.cpp:228] Iteration 73400, loss = 0.000407802
I0822 12:29:02.990116 31776 solver.cpp:244]     Train net output #0: loss = 0.000407802 (* 1 = 0.000407802 loss)
I0822 12:29:02.990125 31776 sgd_solver.cpp:106] Iteration 73400, lr = 0.000314784
I0822 12:29:07.451570 31776 solver.cpp:337] Iteration 73500, Testing net (#0)
I0822 12:29:10.739361 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835334
I0822 12:29:10.739428 31776 solver.cpp:404]     Test net output #1: loss = 1.19702 (* 1 = 1.19702 loss)
I0822 12:29:10.756310 31776 solver.cpp:228] Iteration 73500, loss = 0.000168299
I0822 12:29:10.756397 31776 solver.cpp:244]     Train net output #0: loss = 0.000168299 (* 1 = 0.000168299 loss)
I0822 12:29:10.756412 31776 sgd_solver.cpp:106] Iteration 73500, lr = 0.000314531
I0822 12:29:15.262404 31776 solver.cpp:228] Iteration 73600, loss = 0.000152093
I0822 12:29:15.262457 31776 solver.cpp:244]     Train net output #0: loss = 0.000152093 (* 1 = 0.000152093 loss)
I0822 12:29:15.262465 31776 sgd_solver.cpp:106] Iteration 73600, lr = 0.000314279
I0822 12:29:19.769912 31776 solver.cpp:228] Iteration 73700, loss = 0.000219293
I0822 12:29:19.769969 31776 solver.cpp:244]     Train net output #0: loss = 0.000219293 (* 1 = 0.000219293 loss)
I0822 12:29:19.769979 31776 sgd_solver.cpp:106] Iteration 73700, lr = 0.000314028
I0822 12:29:24.276223 31776 solver.cpp:228] Iteration 73800, loss = 0.000359297
I0822 12:29:24.276279 31776 solver.cpp:244]     Train net output #0: loss = 0.000359297 (* 1 = 0.000359297 loss)
I0822 12:29:24.276288 31776 sgd_solver.cpp:106] Iteration 73800, lr = 0.000313777
I0822 12:29:28.781810 31776 solver.cpp:228] Iteration 73900, loss = 0.000141524
I0822 12:29:28.781867 31776 solver.cpp:244]     Train net output #0: loss = 0.000141524 (* 1 = 0.000141524 loss)
I0822 12:29:28.781877 31776 sgd_solver.cpp:106] Iteration 73900, lr = 0.000313526
I0822 12:29:33.242605 31776 solver.cpp:337] Iteration 74000, Testing net (#0)
I0822 12:29:36.463589 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836708
I0822 12:29:36.463647 31776 solver.cpp:404]     Test net output #1: loss = 1.18621 (* 1 = 1.18621 loss)
I0822 12:29:36.479001 31776 solver.cpp:228] Iteration 74000, loss = 0.00025173
I0822 12:29:36.479064 31776 solver.cpp:244]     Train net output #0: loss = 0.00025173 (* 1 = 0.00025173 loss)
I0822 12:29:36.479074 31776 sgd_solver.cpp:106] Iteration 74000, lr = 0.000313276
I0822 12:29:40.983242 31776 solver.cpp:228] Iteration 74100, loss = 0.000124216
I0822 12:29:40.983296 31776 solver.cpp:244]     Train net output #0: loss = 0.000124216 (* 1 = 0.000124216 loss)
I0822 12:29:40.983305 31776 sgd_solver.cpp:106] Iteration 74100, lr = 0.000313026
I0822 12:29:45.490700 31776 solver.cpp:228] Iteration 74200, loss = 0.000245521
I0822 12:29:45.490757 31776 solver.cpp:244]     Train net output #0: loss = 0.000245521 (* 1 = 0.000245521 loss)
I0822 12:29:45.490766 31776 sgd_solver.cpp:106] Iteration 74200, lr = 0.000312777
I0822 12:29:49.996654 31776 solver.cpp:228] Iteration 74300, loss = 0.000174029
I0822 12:29:49.996711 31776 solver.cpp:244]     Train net output #0: loss = 0.000174029 (* 1 = 0.000174029 loss)
I0822 12:29:49.996721 31776 sgd_solver.cpp:106] Iteration 74300, lr = 0.000312528
I0822 12:29:54.502255 31776 solver.cpp:228] Iteration 74400, loss = 9.62936e-05
I0822 12:29:54.502312 31776 solver.cpp:244]     Train net output #0: loss = 9.62936e-05 (* 1 = 9.62936e-05 loss)
I0822 12:29:54.502323 31776 sgd_solver.cpp:106] Iteration 74400, lr = 0.00031228
I0822 12:29:58.962527 31776 solver.cpp:337] Iteration 74500, Testing net (#0)
I0822 12:30:02.257997 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837208
I0822 12:30:02.258056 31776 solver.cpp:404]     Test net output #1: loss = 1.18252 (* 1 = 1.18252 loss)
I0822 12:30:02.273499 31776 solver.cpp:228] Iteration 74500, loss = 0.000107773
I0822 12:30:02.273557 31776 solver.cpp:244]     Train net output #0: loss = 0.000107773 (* 1 = 0.000107773 loss)
I0822 12:30:02.273568 31776 sgd_solver.cpp:106] Iteration 74500, lr = 0.000312032
I0822 12:30:06.777014 31776 solver.cpp:228] Iteration 74600, loss = 0.000178639
I0822 12:30:06.777071 31776 solver.cpp:244]     Train net output #0: loss = 0.000178639 (* 1 = 0.000178639 loss)
I0822 12:30:06.777081 31776 sgd_solver.cpp:106] Iteration 74600, lr = 0.000311784
I0822 12:30:11.282999 31776 solver.cpp:228] Iteration 74700, loss = 6.26066e-05
I0822 12:30:11.283064 31776 solver.cpp:244]     Train net output #0: loss = 6.26066e-05 (* 1 = 6.26066e-05 loss)
I0822 12:30:11.283074 31776 sgd_solver.cpp:106] Iteration 74700, lr = 0.000311537
I0822 12:30:15.790343 31776 solver.cpp:228] Iteration 74800, loss = 0.000442953
I0822 12:30:15.790396 31776 solver.cpp:244]     Train net output #0: loss = 0.000442953 (* 1 = 0.000442953 loss)
I0822 12:30:15.790405 31776 sgd_solver.cpp:106] Iteration 74800, lr = 0.000311291
I0822 12:30:20.297792 31776 solver.cpp:228] Iteration 74900, loss = 0.000164552
I0822 12:30:20.297853 31776 solver.cpp:244]     Train net output #0: loss = 0.000164552 (* 1 = 0.000164552 loss)
I0822 12:30:20.297864 31776 sgd_solver.cpp:106] Iteration 74900, lr = 0.000311045
I0822 12:30:24.760422 31776 solver.cpp:337] Iteration 75000, Testing net (#0)
I0822 12:30:28.001154 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837125
I0822 12:30:28.001214 31776 solver.cpp:404]     Test net output #1: loss = 1.18286 (* 1 = 1.18286 loss)
I0822 12:30:28.016651 31776 solver.cpp:228] Iteration 75000, loss = 7.3959e-05
I0822 12:30:28.016729 31776 solver.cpp:244]     Train net output #0: loss = 7.3959e-05 (* 1 = 7.3959e-05 loss)
I0822 12:30:28.016741 31776 sgd_solver.cpp:106] Iteration 75000, lr = 0.000310799
I0822 12:30:32.526243 31776 solver.cpp:228] Iteration 75100, loss = 0.00022002
I0822 12:30:32.526298 31776 solver.cpp:244]     Train net output #0: loss = 0.00022002 (* 1 = 0.00022002 loss)
I0822 12:30:32.526305 31776 sgd_solver.cpp:106] Iteration 75100, lr = 0.000310554
I0822 12:30:37.032218 31776 solver.cpp:228] Iteration 75200, loss = 0.00021576
I0822 12:30:37.032284 31776 solver.cpp:244]     Train net output #0: loss = 0.00021576 (* 1 = 0.00021576 loss)
I0822 12:30:37.032292 31776 sgd_solver.cpp:106] Iteration 75200, lr = 0.000310309
I0822 12:30:41.537901 31776 solver.cpp:228] Iteration 75300, loss = 9.51887e-05
I0822 12:30:41.537956 31776 solver.cpp:244]     Train net output #0: loss = 9.51887e-05 (* 1 = 9.51887e-05 loss)
I0822 12:30:41.537964 31776 sgd_solver.cpp:106] Iteration 75300, lr = 0.000310065
I0822 12:30:46.042873 31776 solver.cpp:228] Iteration 75400, loss = 0.000379433
I0822 12:30:46.042930 31776 solver.cpp:244]     Train net output #0: loss = 0.000379433 (* 1 = 0.000379433 loss)
I0822 12:30:46.042938 31776 sgd_solver.cpp:106] Iteration 75400, lr = 0.000309821
I0822 12:30:50.504547 31776 solver.cpp:337] Iteration 75500, Testing net (#0)
I0822 12:30:53.728143 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837917
I0822 12:30:53.728207 31776 solver.cpp:404]     Test net output #1: loss = 1.17913 (* 1 = 1.17913 loss)
I0822 12:30:53.743691 31776 solver.cpp:228] Iteration 75500, loss = 0.000132947
I0822 12:30:53.743765 31776 solver.cpp:244]     Train net output #0: loss = 0.000132947 (* 1 = 0.000132947 loss)
I0822 12:30:53.743774 31776 sgd_solver.cpp:106] Iteration 75500, lr = 0.000309578
I0822 12:30:58.250447 31776 solver.cpp:228] Iteration 75600, loss = 0.00022199
I0822 12:30:58.250502 31776 solver.cpp:244]     Train net output #0: loss = 0.00022199 (* 1 = 0.00022199 loss)
I0822 12:30:58.250511 31776 sgd_solver.cpp:106] Iteration 75600, lr = 0.000309335
I0822 12:31:02.755640 31776 solver.cpp:228] Iteration 75700, loss = 0.000127059
I0822 12:31:02.755694 31776 solver.cpp:244]     Train net output #0: loss = 0.000127059 (* 1 = 0.000127059 loss)
I0822 12:31:02.755702 31776 sgd_solver.cpp:106] Iteration 75700, lr = 0.000309093
I0822 12:31:07.257891 31776 solver.cpp:228] Iteration 75800, loss = 0.000312085
I0822 12:31:07.257946 31776 solver.cpp:244]     Train net output #0: loss = 0.000312085 (* 1 = 0.000312085 loss)
I0822 12:31:07.257954 31776 sgd_solver.cpp:106] Iteration 75800, lr = 0.000308851
I0822 12:31:11.762533 31776 solver.cpp:228] Iteration 75900, loss = 0.000159809
I0822 12:31:11.762589 31776 solver.cpp:244]     Train net output #0: loss = 0.000159809 (* 1 = 0.000159809 loss)
I0822 12:31:11.762598 31776 sgd_solver.cpp:106] Iteration 75900, lr = 0.000308609
I0822 12:31:16.220248 31776 solver.cpp:337] Iteration 76000, Testing net (#0)
I0822 12:31:19.410277 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838625
I0822 12:31:19.410336 31776 solver.cpp:404]     Test net output #1: loss = 1.17962 (* 1 = 1.17962 loss)
I0822 12:31:19.425691 31776 solver.cpp:228] Iteration 76000, loss = 0.000171672
I0822 12:31:19.425767 31776 solver.cpp:244]     Train net output #0: loss = 0.000171672 (* 1 = 0.000171672 loss)
I0822 12:31:19.425781 31776 sgd_solver.cpp:106] Iteration 76000, lr = 0.000308368
I0822 12:31:23.926887 31776 solver.cpp:228] Iteration 76100, loss = 8.14207e-05
I0822 12:31:23.926942 31776 solver.cpp:244]     Train net output #0: loss = 8.14207e-05 (* 1 = 8.14207e-05 loss)
I0822 12:31:23.926956 31776 sgd_solver.cpp:106] Iteration 76100, lr = 0.000308127
I0822 12:31:28.430408 31776 solver.cpp:228] Iteration 76200, loss = 9.25192e-05
I0822 12:31:28.430461 31776 solver.cpp:244]     Train net output #0: loss = 9.25192e-05 (* 1 = 9.25192e-05 loss)
I0822 12:31:28.430470 31776 sgd_solver.cpp:106] Iteration 76200, lr = 0.000307887
I0822 12:31:32.935180 31776 solver.cpp:228] Iteration 76300, loss = 0.000187543
I0822 12:31:32.935237 31776 solver.cpp:244]     Train net output #0: loss = 0.000187543 (* 1 = 0.000187543 loss)
I0822 12:31:32.935245 31776 sgd_solver.cpp:106] Iteration 76300, lr = 0.000307647
I0822 12:31:37.440554 31776 solver.cpp:228] Iteration 76400, loss = 0.000102166
I0822 12:31:37.440609 31776 solver.cpp:244]     Train net output #0: loss = 0.000102166 (* 1 = 0.000102166 loss)
I0822 12:31:37.440618 31776 sgd_solver.cpp:106] Iteration 76400, lr = 0.000307408
I0822 12:31:41.902039 31776 solver.cpp:337] Iteration 76500, Testing net (#0)
I0822 12:31:45.107030 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839417
I0822 12:31:45.107097 31776 solver.cpp:404]     Test net output #1: loss = 1.17158 (* 1 = 1.17158 loss)
I0822 12:31:45.122423 31776 solver.cpp:228] Iteration 76500, loss = 0.000140959
I0822 12:31:45.122488 31776 solver.cpp:244]     Train net output #0: loss = 0.000140959 (* 1 = 0.000140959 loss)
I0822 12:31:45.122499 31776 sgd_solver.cpp:106] Iteration 76500, lr = 0.000307169
I0822 12:31:49.624536 31776 solver.cpp:228] Iteration 76600, loss = 0.000155716
I0822 12:31:49.624603 31776 solver.cpp:244]     Train net output #0: loss = 0.000155716 (* 1 = 0.000155716 loss)
I0822 12:31:49.624624 31776 sgd_solver.cpp:106] Iteration 76600, lr = 0.00030693
I0822 12:31:54.130486 31776 solver.cpp:228] Iteration 76700, loss = 3.42971e-05
I0822 12:31:54.130544 31776 solver.cpp:244]     Train net output #0: loss = 3.42971e-05 (* 1 = 3.42971e-05 loss)
I0822 12:31:54.130553 31776 sgd_solver.cpp:106] Iteration 76700, lr = 0.000306692
I0822 12:31:58.635579 31776 solver.cpp:228] Iteration 76800, loss = 0.000127118
I0822 12:31:58.635637 31776 solver.cpp:244]     Train net output #0: loss = 0.000127118 (* 1 = 0.000127118 loss)
I0822 12:31:58.635644 31776 sgd_solver.cpp:106] Iteration 76800, lr = 0.000306454
I0822 12:32:03.141981 31776 solver.cpp:228] Iteration 76900, loss = 0.000166603
I0822 12:32:03.142040 31776 solver.cpp:244]     Train net output #0: loss = 0.000166603 (* 1 = 0.000166603 loss)
I0822 12:32:03.142047 31776 sgd_solver.cpp:106] Iteration 76900, lr = 0.000306217
I0822 12:32:07.604526 31776 solver.cpp:337] Iteration 77000, Testing net (#0)
I0822 12:32:10.854364 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839375
I0822 12:32:10.854423 31776 solver.cpp:404]     Test net output #1: loss = 1.17399 (* 1 = 1.17399 loss)
I0822 12:32:10.869807 31776 solver.cpp:228] Iteration 77000, loss = 0.000267883
I0822 12:32:10.869874 31776 solver.cpp:244]     Train net output #0: loss = 0.000267883 (* 1 = 0.000267883 loss)
I0822 12:32:10.869884 31776 sgd_solver.cpp:106] Iteration 77000, lr = 0.00030598
I0822 12:32:15.373925 31776 solver.cpp:228] Iteration 77100, loss = 0.000282737
I0822 12:32:15.373988 31776 solver.cpp:244]     Train net output #0: loss = 0.000282737 (* 1 = 0.000282737 loss)
I0822 12:32:15.373996 31776 sgd_solver.cpp:106] Iteration 77100, lr = 0.000305744
I0822 12:32:19.879222 31776 solver.cpp:228] Iteration 77200, loss = 6.42767e-05
I0822 12:32:19.879287 31776 solver.cpp:244]     Train net output #0: loss = 6.42767e-05 (* 1 = 6.42767e-05 loss)
I0822 12:32:19.879295 31776 sgd_solver.cpp:106] Iteration 77200, lr = 0.000305508
I0822 12:32:24.385782 31776 solver.cpp:228] Iteration 77300, loss = 0.000138354
I0822 12:32:24.385839 31776 solver.cpp:244]     Train net output #0: loss = 0.000138354 (* 1 = 0.000138354 loss)
I0822 12:32:24.385848 31776 sgd_solver.cpp:106] Iteration 77300, lr = 0.000305273
I0822 12:32:28.893237 31776 solver.cpp:228] Iteration 77400, loss = 0.000182882
I0822 12:32:28.893295 31776 solver.cpp:244]     Train net output #0: loss = 0.000182882 (* 1 = 0.000182882 loss)
I0822 12:32:28.893302 31776 sgd_solver.cpp:106] Iteration 77400, lr = 0.000305038
I0822 12:32:33.355489 31776 solver.cpp:337] Iteration 77500, Testing net (#0)
I0822 12:32:36.608314 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839792
I0822 12:32:36.608376 31776 solver.cpp:404]     Test net output #1: loss = 1.17369 (* 1 = 1.17369 loss)
I0822 12:32:36.623772 31776 solver.cpp:228] Iteration 77500, loss = 0.000150723
I0822 12:32:36.623845 31776 solver.cpp:244]     Train net output #0: loss = 0.000150723 (* 1 = 0.000150723 loss)
I0822 12:32:36.623855 31776 sgd_solver.cpp:106] Iteration 77500, lr = 0.000304803
I0822 12:32:41.128736 31776 solver.cpp:228] Iteration 77600, loss = 0.000628806
I0822 12:32:41.128790 31776 solver.cpp:244]     Train net output #0: loss = 0.000628806 (* 1 = 0.000628806 loss)
I0822 12:32:41.128798 31776 sgd_solver.cpp:106] Iteration 77600, lr = 0.000304569
I0822 12:32:45.634407 31776 solver.cpp:228] Iteration 77700, loss = 0.000354624
I0822 12:32:45.634466 31776 solver.cpp:244]     Train net output #0: loss = 0.000354624 (* 1 = 0.000354624 loss)
I0822 12:32:45.634474 31776 sgd_solver.cpp:106] Iteration 77700, lr = 0.000304335
I0822 12:32:50.141253 31776 solver.cpp:228] Iteration 77800, loss = 0.000308993
I0822 12:32:50.141309 31776 solver.cpp:244]     Train net output #0: loss = 0.000308993 (* 1 = 0.000308993 loss)
I0822 12:32:50.141317 31776 sgd_solver.cpp:106] Iteration 77800, lr = 0.000304101
I0822 12:32:54.645464 31776 solver.cpp:228] Iteration 77900, loss = 0.00010517
I0822 12:32:54.645519 31776 solver.cpp:244]     Train net output #0: loss = 0.00010517 (* 1 = 0.00010517 loss)
I0822 12:32:54.645529 31776 sgd_solver.cpp:106] Iteration 77900, lr = 0.000303868
I0822 12:32:59.103145 31776 solver.cpp:337] Iteration 78000, Testing net (#0)
I0822 12:33:02.345191 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839083
I0822 12:33:02.345253 31776 solver.cpp:404]     Test net output #1: loss = 1.17942 (* 1 = 1.17942 loss)
I0822 12:33:02.360647 31776 solver.cpp:228] Iteration 78000, loss = 0.00020633
I0822 12:33:02.360723 31776 solver.cpp:244]     Train net output #0: loss = 0.00020633 (* 1 = 0.00020633 loss)
I0822 12:33:02.360738 31776 sgd_solver.cpp:106] Iteration 78000, lr = 0.000303636
I0822 12:33:06.867005 31776 solver.cpp:228] Iteration 78100, loss = 0.000442135
I0822 12:33:06.867064 31776 solver.cpp:244]     Train net output #0: loss = 0.000442135 (* 1 = 0.000442135 loss)
I0822 12:33:06.867074 31776 sgd_solver.cpp:106] Iteration 78100, lr = 0.000303404
I0822 12:33:11.371978 31776 solver.cpp:228] Iteration 78200, loss = 0.000155881
I0822 12:33:11.372038 31776 solver.cpp:244]     Train net output #0: loss = 0.000155881 (* 1 = 0.000155881 loss)
I0822 12:33:11.372047 31776 sgd_solver.cpp:106] Iteration 78200, lr = 0.000303172
I0822 12:33:15.879072 31776 solver.cpp:228] Iteration 78300, loss = 0.000210052
I0822 12:33:15.879132 31776 solver.cpp:244]     Train net output #0: loss = 0.000210052 (* 1 = 0.000210052 loss)
I0822 12:33:15.879140 31776 sgd_solver.cpp:106] Iteration 78300, lr = 0.000302941
I0822 12:33:20.386565 31776 solver.cpp:228] Iteration 78400, loss = 0.000113856
I0822 12:33:20.386622 31776 solver.cpp:244]     Train net output #0: loss = 0.000113856 (* 1 = 0.000113856 loss)
I0822 12:33:20.386631 31776 sgd_solver.cpp:106] Iteration 78400, lr = 0.00030271
I0822 12:33:24.845424 31776 solver.cpp:337] Iteration 78500, Testing net (#0)
I0822 12:33:28.018931 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840084
I0822 12:33:28.018990 31776 solver.cpp:404]     Test net output #1: loss = 1.17631 (* 1 = 1.17631 loss)
I0822 12:33:28.034528 31776 solver.cpp:228] Iteration 78500, loss = 0.000319606
I0822 12:33:28.034598 31776 solver.cpp:244]     Train net output #0: loss = 0.000319606 (* 1 = 0.000319606 loss)
I0822 12:33:28.034610 31776 sgd_solver.cpp:106] Iteration 78500, lr = 0.000302479
I0822 12:33:32.543568 31776 solver.cpp:228] Iteration 78600, loss = 0.000151543
I0822 12:33:32.543623 31776 solver.cpp:244]     Train net output #0: loss = 0.000151543 (* 1 = 0.000151543 loss)
I0822 12:33:32.543632 31776 sgd_solver.cpp:106] Iteration 78600, lr = 0.000302249
I0822 12:33:37.048074 31776 solver.cpp:228] Iteration 78700, loss = 0.000162918
I0822 12:33:37.048161 31776 solver.cpp:244]     Train net output #0: loss = 0.000162918 (* 1 = 0.000162918 loss)
I0822 12:33:37.048171 31776 sgd_solver.cpp:106] Iteration 78700, lr = 0.000302019
I0822 12:33:41.557991 31776 solver.cpp:228] Iteration 78800, loss = 0.000112735
I0822 12:33:41.558048 31776 solver.cpp:244]     Train net output #0: loss = 0.000112735 (* 1 = 0.000112735 loss)
I0822 12:33:41.558058 31776 sgd_solver.cpp:106] Iteration 78800, lr = 0.00030179
I0822 12:33:46.063992 31776 solver.cpp:228] Iteration 78900, loss = 0.000111719
I0822 12:33:46.064049 31776 solver.cpp:244]     Train net output #0: loss = 0.000111719 (* 1 = 0.000111719 loss)
I0822 12:33:46.064056 31776 sgd_solver.cpp:106] Iteration 78900, lr = 0.000301561
I0822 12:33:50.523216 31776 solver.cpp:337] Iteration 79000, Testing net (#0)
I0822 12:33:53.795227 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840542
I0822 12:33:53.795289 31776 solver.cpp:404]     Test net output #1: loss = 1.17245 (* 1 = 1.17245 loss)
I0822 12:33:53.810679 31776 solver.cpp:228] Iteration 79000, loss = 6.6653e-05
I0822 12:33:53.810756 31776 solver.cpp:244]     Train net output #0: loss = 6.6653e-05 (* 1 = 6.6653e-05 loss)
I0822 12:33:53.810768 31776 sgd_solver.cpp:106] Iteration 79000, lr = 0.000301333
I0822 12:33:58.318811 31776 solver.cpp:228] Iteration 79100, loss = 0.000530038
I0822 12:33:58.318867 31776 solver.cpp:244]     Train net output #0: loss = 0.000530038 (* 1 = 0.000530038 loss)
I0822 12:33:58.318876 31776 sgd_solver.cpp:106] Iteration 79100, lr = 0.000301105
I0822 12:34:02.823818 31776 solver.cpp:228] Iteration 79200, loss = 0.000107862
I0822 12:34:02.823884 31776 solver.cpp:244]     Train net output #0: loss = 0.000107862 (* 1 = 0.000107862 loss)
I0822 12:34:02.823896 31776 sgd_solver.cpp:106] Iteration 79200, lr = 0.000300877
I0822 12:34:07.325161 31776 solver.cpp:228] Iteration 79300, loss = 0.000144756
I0822 12:34:07.325218 31776 solver.cpp:244]     Train net output #0: loss = 0.000144756 (* 1 = 0.000144756 loss)
I0822 12:34:07.325227 31776 sgd_solver.cpp:106] Iteration 79300, lr = 0.00030065
I0822 12:34:11.828402 31776 solver.cpp:228] Iteration 79400, loss = 0.000269547
I0822 12:34:11.828456 31776 solver.cpp:244]     Train net output #0: loss = 0.000269547 (* 1 = 0.000269547 loss)
I0822 12:34:11.828464 31776 sgd_solver.cpp:106] Iteration 79400, lr = 0.000300423
I0822 12:34:16.292083 31776 solver.cpp:337] Iteration 79500, Testing net (#0)
I0822 12:34:18.149703 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:34:19.681565 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840417
I0822 12:34:19.681620 31776 solver.cpp:404]     Test net output #1: loss = 1.17334 (* 1 = 1.17334 loss)
I0822 12:34:19.698328 31776 solver.cpp:228] Iteration 79500, loss = 0.000292077
I0822 12:34:19.698388 31776 solver.cpp:244]     Train net output #0: loss = 0.000292077 (* 1 = 0.000292077 loss)
I0822 12:34:19.698401 31776 sgd_solver.cpp:106] Iteration 79500, lr = 0.000300196
I0822 12:34:24.202227 31776 solver.cpp:228] Iteration 79600, loss = 0.000100244
I0822 12:34:24.202282 31776 solver.cpp:244]     Train net output #0: loss = 0.000100244 (* 1 = 0.000100244 loss)
I0822 12:34:24.202291 31776 sgd_solver.cpp:106] Iteration 79600, lr = 0.00029997
I0822 12:34:28.707528 31776 solver.cpp:228] Iteration 79700, loss = 0.000226708
I0822 12:34:28.707589 31776 solver.cpp:244]     Train net output #0: loss = 0.000226708 (* 1 = 0.000226708 loss)
I0822 12:34:28.707597 31776 sgd_solver.cpp:106] Iteration 79700, lr = 0.000299744
I0822 12:34:33.213596 31776 solver.cpp:228] Iteration 79800, loss = 8.02623e-05
I0822 12:34:33.213654 31776 solver.cpp:244]     Train net output #0: loss = 8.02623e-05 (* 1 = 8.02623e-05 loss)
I0822 12:34:33.213662 31776 sgd_solver.cpp:106] Iteration 79800, lr = 0.000299519
I0822 12:34:37.719199 31776 solver.cpp:228] Iteration 79900, loss = 0.000173846
I0822 12:34:37.719256 31776 solver.cpp:244]     Train net output #0: loss = 0.000173846 (* 1 = 0.000173846 loss)
I0822 12:34:37.719265 31776 sgd_solver.cpp:106] Iteration 79900, lr = 0.000299294
I0822 12:34:42.180503 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_80000.caffemodel
I0822 12:34:42.652876 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_80000.solverstate
I0822 12:34:42.808492 31776 solver.cpp:337] Iteration 80000, Testing net (#0)
I0822 12:34:46.025144 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840833
I0822 12:34:46.025204 31776 solver.cpp:404]     Test net output #1: loss = 1.1726 (* 1 = 1.1726 loss)
I0822 12:34:46.040581 31776 solver.cpp:228] Iteration 80000, loss = 0.000122909
I0822 12:34:46.040649 31776 solver.cpp:244]     Train net output #0: loss = 0.000122909 (* 1 = 0.000122909 loss)
I0822 12:34:46.040659 31776 sgd_solver.cpp:106] Iteration 80000, lr = 0.00029907
I0822 12:34:50.543885 31776 solver.cpp:228] Iteration 80100, loss = 0.000266554
I0822 12:34:50.543943 31776 solver.cpp:244]     Train net output #0: loss = 0.000266554 (* 1 = 0.000266554 loss)
I0822 12:34:50.543952 31776 sgd_solver.cpp:106] Iteration 80100, lr = 0.000298846
I0822 12:34:55.050477 31776 solver.cpp:228] Iteration 80200, loss = 9.0266e-05
I0822 12:34:55.050534 31776 solver.cpp:244]     Train net output #0: loss = 9.0266e-05 (* 1 = 9.0266e-05 loss)
I0822 12:34:55.050544 31776 sgd_solver.cpp:106] Iteration 80200, lr = 0.000298622
I0822 12:34:59.556710 31776 solver.cpp:228] Iteration 80300, loss = 0.000107519
I0822 12:34:59.556769 31776 solver.cpp:244]     Train net output #0: loss = 0.000107519 (* 1 = 0.000107519 loss)
I0822 12:34:59.556778 31776 sgd_solver.cpp:106] Iteration 80300, lr = 0.000298399
I0822 12:35:04.062736 31776 solver.cpp:228] Iteration 80400, loss = 0.000121793
I0822 12:35:04.062793 31776 solver.cpp:244]     Train net output #0: loss = 0.000121793 (* 1 = 0.000121793 loss)
I0822 12:35:04.062801 31776 sgd_solver.cpp:106] Iteration 80400, lr = 0.000298176
I0822 12:35:08.524132 31776 solver.cpp:337] Iteration 80500, Testing net (#0)
I0822 12:35:11.736786 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840958
I0822 12:35:11.736845 31776 solver.cpp:404]     Test net output #1: loss = 1.17535 (* 1 = 1.17535 loss)
I0822 12:35:11.752362 31776 solver.cpp:228] Iteration 80500, loss = 4.29784e-05
I0822 12:35:11.752430 31776 solver.cpp:244]     Train net output #0: loss = 4.29784e-05 (* 1 = 4.29784e-05 loss)
I0822 12:35:11.752440 31776 sgd_solver.cpp:106] Iteration 80500, lr = 0.000297953
I0822 12:35:16.258113 31776 solver.cpp:228] Iteration 80600, loss = 0.000149874
I0822 12:35:16.258180 31776 solver.cpp:244]     Train net output #0: loss = 0.000149874 (* 1 = 0.000149874 loss)
I0822 12:35:16.258189 31776 sgd_solver.cpp:106] Iteration 80600, lr = 0.000297731
I0822 12:35:20.763253 31776 solver.cpp:228] Iteration 80700, loss = 0.000111001
I0822 12:35:20.763310 31776 solver.cpp:244]     Train net output #0: loss = 0.000111001 (* 1 = 0.000111001 loss)
I0822 12:35:20.763319 31776 sgd_solver.cpp:106] Iteration 80700, lr = 0.000297509
I0822 12:35:25.269430 31776 solver.cpp:228] Iteration 80800, loss = 0.000124122
I0822 12:35:25.269486 31776 solver.cpp:244]     Train net output #0: loss = 0.000124122 (* 1 = 0.000124122 loss)
I0822 12:35:25.269495 31776 sgd_solver.cpp:106] Iteration 80800, lr = 0.000297288
I0822 12:35:29.775377 31776 solver.cpp:228] Iteration 80900, loss = 7.49008e-05
I0822 12:35:29.775434 31776 solver.cpp:244]     Train net output #0: loss = 7.49008e-05 (* 1 = 7.49008e-05 loss)
I0822 12:35:29.775441 31776 sgd_solver.cpp:106] Iteration 80900, lr = 0.000297067
I0822 12:35:34.236553 31776 solver.cpp:337] Iteration 81000, Testing net (#0)
I0822 12:35:37.514017 31776 solver.cpp:404]     Test net output #0: accuracy = 0.84025
I0822 12:35:37.514077 31776 solver.cpp:404]     Test net output #1: loss = 1.18159 (* 1 = 1.18159 loss)
I0822 12:35:37.529427 31776 solver.cpp:228] Iteration 81000, loss = 7.50196e-05
I0822 12:35:37.529491 31776 solver.cpp:244]     Train net output #0: loss = 7.50196e-05 (* 1 = 7.50196e-05 loss)
I0822 12:35:37.529501 31776 sgd_solver.cpp:106] Iteration 81000, lr = 0.000296846
I0822 12:35:42.037492 31776 solver.cpp:228] Iteration 81100, loss = 0.000170741
I0822 12:35:42.037544 31776 solver.cpp:244]     Train net output #0: loss = 0.000170741 (* 1 = 0.000170741 loss)
I0822 12:35:42.037552 31776 sgd_solver.cpp:106] Iteration 81100, lr = 0.000296626
I0822 12:35:46.545117 31776 solver.cpp:228] Iteration 81200, loss = 0.000246401
I0822 12:35:46.545172 31776 solver.cpp:244]     Train net output #0: loss = 0.000246401 (* 1 = 0.000246401 loss)
I0822 12:35:46.545181 31776 sgd_solver.cpp:106] Iteration 81200, lr = 0.000296406
I0822 12:35:51.052275 31776 solver.cpp:228] Iteration 81300, loss = 0.000112635
I0822 12:35:51.052328 31776 solver.cpp:244]     Train net output #0: loss = 0.000112635 (* 1 = 0.000112635 loss)
I0822 12:35:51.052337 31776 sgd_solver.cpp:106] Iteration 81300, lr = 0.000296187
I0822 12:35:55.560374 31776 solver.cpp:228] Iteration 81400, loss = 0.000151556
I0822 12:35:55.560430 31776 solver.cpp:244]     Train net output #0: loss = 0.000151556 (* 1 = 0.000151556 loss)
I0822 12:35:55.560437 31776 sgd_solver.cpp:106] Iteration 81400, lr = 0.000295968
I0822 12:36:00.021363 31776 solver.cpp:337] Iteration 81500, Testing net (#0)
I0822 12:36:03.296901 31776 solver.cpp:404]     Test net output #0: accuracy = 0.841208
I0822 12:36:03.296964 31776 solver.cpp:404]     Test net output #1: loss = 1.17552 (* 1 = 1.17552 loss)
I0822 12:36:03.312458 31776 solver.cpp:228] Iteration 81500, loss = 0.000111292
I0822 12:36:03.312532 31776 solver.cpp:244]     Train net output #0: loss = 0.000111292 (* 1 = 0.000111292 loss)
I0822 12:36:03.312544 31776 sgd_solver.cpp:106] Iteration 81500, lr = 0.000295749
I0822 12:36:07.815922 31776 solver.cpp:228] Iteration 81600, loss = 0.000152044
I0822 12:36:07.815976 31776 solver.cpp:244]     Train net output #0: loss = 0.000152044 (* 1 = 0.000152044 loss)
I0822 12:36:07.815985 31776 sgd_solver.cpp:106] Iteration 81600, lr = 0.00029553
I0822 12:36:12.316836 31776 solver.cpp:228] Iteration 81700, loss = 0.000118215
I0822 12:36:12.316874 31776 solver.cpp:244]     Train net output #0: loss = 0.000118215 (* 1 = 0.000118215 loss)
I0822 12:36:12.316879 31776 sgd_solver.cpp:106] Iteration 81700, lr = 0.000295312
I0822 12:36:16.822832 31776 solver.cpp:228] Iteration 81800, loss = 9.392e-05
I0822 12:36:16.822886 31776 solver.cpp:244]     Train net output #0: loss = 9.392e-05 (* 1 = 9.392e-05 loss)
I0822 12:36:16.822896 31776 sgd_solver.cpp:106] Iteration 81800, lr = 0.000295095
I0822 12:36:21.323336 31776 solver.cpp:228] Iteration 81900, loss = 0.00028296
I0822 12:36:21.323395 31776 solver.cpp:244]     Train net output #0: loss = 0.00028296 (* 1 = 0.00028296 loss)
I0822 12:36:21.323405 31776 sgd_solver.cpp:106] Iteration 81900, lr = 0.000294878
I0822 12:36:25.782845 31776 solver.cpp:337] Iteration 82000, Testing net (#0)
I0822 12:36:29.046269 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840625
I0822 12:36:29.046327 31776 solver.cpp:404]     Test net output #1: loss = 1.18038 (* 1 = 1.18038 loss)
I0822 12:36:29.061692 31776 solver.cpp:228] Iteration 82000, loss = 7.69947e-05
I0822 12:36:29.061770 31776 solver.cpp:244]     Train net output #0: loss = 7.69947e-05 (* 1 = 7.69947e-05 loss)
I0822 12:36:29.061781 31776 sgd_solver.cpp:106] Iteration 82000, lr = 0.000294661
I0822 12:36:33.568446 31776 solver.cpp:228] Iteration 82100, loss = 0.000330512
I0822 12:36:33.568509 31776 solver.cpp:244]     Train net output #0: loss = 0.000330512 (* 1 = 0.000330512 loss)
I0822 12:36:33.568517 31776 sgd_solver.cpp:106] Iteration 82100, lr = 0.000294444
I0822 12:36:38.074594 31776 solver.cpp:228] Iteration 82200, loss = 0.000119708
I0822 12:36:38.074654 31776 solver.cpp:244]     Train net output #0: loss = 0.000119708 (* 1 = 0.000119708 loss)
I0822 12:36:38.074662 31776 sgd_solver.cpp:106] Iteration 82200, lr = 0.000294228
I0822 12:36:42.581401 31776 solver.cpp:228] Iteration 82300, loss = 0.000161819
I0822 12:36:42.581456 31776 solver.cpp:244]     Train net output #0: loss = 0.000161819 (* 1 = 0.000161819 loss)
I0822 12:36:42.581466 31776 sgd_solver.cpp:106] Iteration 82300, lr = 0.000294013
I0822 12:36:47.088088 31776 solver.cpp:228] Iteration 82400, loss = 0.000117798
I0822 12:36:47.088160 31776 solver.cpp:244]     Train net output #0: loss = 0.000117798 (* 1 = 0.000117798 loss)
I0822 12:36:47.088168 31776 sgd_solver.cpp:106] Iteration 82400, lr = 0.000293797
I0822 12:36:51.550325 31776 solver.cpp:337] Iteration 82500, Testing net (#0)
I0822 12:36:54.784993 31776 solver.cpp:404]     Test net output #0: accuracy = 0.840375
I0822 12:36:54.785054 31776 solver.cpp:404]     Test net output #1: loss = 1.18379 (* 1 = 1.18379 loss)
I0822 12:36:54.800408 31776 solver.cpp:228] Iteration 82500, loss = 0.000282727
I0822 12:36:54.800472 31776 solver.cpp:244]     Train net output #0: loss = 0.000282727 (* 1 = 0.000282727 loss)
I0822 12:36:54.800482 31776 sgd_solver.cpp:106] Iteration 82500, lr = 0.000293582
I0822 12:36:59.306403 31776 solver.cpp:228] Iteration 82600, loss = 0.000178822
I0822 12:36:59.306463 31776 solver.cpp:244]     Train net output #0: loss = 0.000178822 (* 1 = 0.000178822 loss)
I0822 12:36:59.306470 31776 sgd_solver.cpp:106] Iteration 82600, lr = 0.000293367
I0822 12:37:03.814357 31776 solver.cpp:228] Iteration 82700, loss = 8.63439e-05
I0822 12:37:03.814406 31776 solver.cpp:244]     Train net output #0: loss = 8.63439e-05 (* 1 = 8.63439e-05 loss)
I0822 12:37:03.814414 31776 sgd_solver.cpp:106] Iteration 82700, lr = 0.000293153
I0822 12:37:08.317273 31776 solver.cpp:228] Iteration 82800, loss = 0.000157528
I0822 12:37:08.317332 31776 solver.cpp:244]     Train net output #0: loss = 0.000157528 (* 1 = 0.000157528 loss)
I0822 12:37:08.317340 31776 sgd_solver.cpp:106] Iteration 82800, lr = 0.000292939
I0822 12:37:12.820461 31776 solver.cpp:228] Iteration 82900, loss = 0.000100344
I0822 12:37:12.820514 31776 solver.cpp:244]     Train net output #0: loss = 0.000100344 (* 1 = 0.000100344 loss)
I0822 12:37:12.820524 31776 sgd_solver.cpp:106] Iteration 82900, lr = 0.000292726
I0822 12:37:17.284903 31776 solver.cpp:337] Iteration 83000, Testing net (#0)
I0822 12:37:20.492507 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839917
I0822 12:37:20.492568 31776 solver.cpp:404]     Test net output #1: loss = 1.18818 (* 1 = 1.18818 loss)
I0822 12:37:20.507993 31776 solver.cpp:228] Iteration 83000, loss = 0.000134397
I0822 12:37:20.508064 31776 solver.cpp:244]     Train net output #0: loss = 0.000134397 (* 1 = 0.000134397 loss)
I0822 12:37:20.508087 31776 sgd_solver.cpp:106] Iteration 83000, lr = 0.000292513
I0822 12:37:25.013422 31776 solver.cpp:228] Iteration 83100, loss = 0.000116107
I0822 12:37:25.013486 31776 solver.cpp:244]     Train net output #0: loss = 0.000116107 (* 1 = 0.000116107 loss)
I0822 12:37:25.013494 31776 sgd_solver.cpp:106] Iteration 83100, lr = 0.0002923
I0822 12:37:29.518571 31776 solver.cpp:228] Iteration 83200, loss = 0.0001084
I0822 12:37:29.518625 31776 solver.cpp:244]     Train net output #0: loss = 0.0001084 (* 1 = 0.0001084 loss)
I0822 12:37:29.518633 31776 sgd_solver.cpp:106] Iteration 83200, lr = 0.000292087
I0822 12:37:34.023227 31776 solver.cpp:228] Iteration 83300, loss = 9.75238e-05
I0822 12:37:34.023285 31776 solver.cpp:244]     Train net output #0: loss = 9.75238e-05 (* 1 = 9.75238e-05 loss)
I0822 12:37:34.023294 31776 sgd_solver.cpp:106] Iteration 83300, lr = 0.000291875
I0822 12:37:38.528766 31776 solver.cpp:228] Iteration 83400, loss = 0.0004208
I0822 12:37:38.528820 31776 solver.cpp:244]     Train net output #0: loss = 0.0004208 (* 1 = 0.0004208 loss)
I0822 12:37:38.528828 31776 sgd_solver.cpp:106] Iteration 83400, lr = 0.000291664
I0822 12:37:42.990252 31776 solver.cpp:337] Iteration 83500, Testing net (#0)
I0822 12:37:46.260825 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839583
I0822 12:37:46.260892 31776 solver.cpp:404]     Test net output #1: loss = 1.19307 (* 1 = 1.19307 loss)
I0822 12:37:46.276216 31776 solver.cpp:228] Iteration 83500, loss = 6.93643e-05
I0822 12:37:46.276269 31776 solver.cpp:244]     Train net output #0: loss = 6.93643e-05 (* 1 = 6.93643e-05 loss)
I0822 12:37:46.276281 31776 sgd_solver.cpp:106] Iteration 83500, lr = 0.000291452
I0822 12:37:50.782124 31776 solver.cpp:228] Iteration 83600, loss = 0.00011174
I0822 12:37:50.782181 31776 solver.cpp:244]     Train net output #0: loss = 0.00011174 (* 1 = 0.00011174 loss)
I0822 12:37:50.782189 31776 sgd_solver.cpp:106] Iteration 83600, lr = 0.000291241
I0822 12:37:55.286886 31776 solver.cpp:228] Iteration 83700, loss = 0.000196926
I0822 12:37:55.286952 31776 solver.cpp:244]     Train net output #0: loss = 0.000196926 (* 1 = 0.000196926 loss)
I0822 12:37:55.286960 31776 sgd_solver.cpp:106] Iteration 83700, lr = 0.00029103
I0822 12:37:59.793853 31776 solver.cpp:228] Iteration 83800, loss = 0.000342319
I0822 12:37:59.793911 31776 solver.cpp:244]     Train net output #0: loss = 0.000342319 (* 1 = 0.000342319 loss)
I0822 12:37:59.793920 31776 sgd_solver.cpp:106] Iteration 83800, lr = 0.00029082
I0822 12:38:04.300787 31776 solver.cpp:228] Iteration 83900, loss = 0.000104585
I0822 12:38:04.300843 31776 solver.cpp:244]     Train net output #0: loss = 0.000104585 (* 1 = 0.000104585 loss)
I0822 12:38:04.300851 31776 sgd_solver.cpp:106] Iteration 83900, lr = 0.00029061
I0822 12:38:08.764660 31776 solver.cpp:337] Iteration 84000, Testing net (#0)
I0822 12:38:12.036919 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839708
I0822 12:38:12.036976 31776 solver.cpp:404]     Test net output #1: loss = 1.19033 (* 1 = 1.19033 loss)
I0822 12:38:12.052418 31776 solver.cpp:228] Iteration 84000, loss = 0.000129773
I0822 12:38:12.052476 31776 solver.cpp:244]     Train net output #0: loss = 0.000129773 (* 1 = 0.000129773 loss)
I0822 12:38:12.052489 31776 sgd_solver.cpp:106] Iteration 84000, lr = 0.000290401
I0822 12:38:16.558470 31776 solver.cpp:228] Iteration 84100, loss = 7.16234e-05
I0822 12:38:16.558513 31776 solver.cpp:244]     Train net output #0: loss = 7.16234e-05 (* 1 = 7.16234e-05 loss)
I0822 12:38:16.558521 31776 sgd_solver.cpp:106] Iteration 84100, lr = 0.000290191
I0822 12:38:21.064692 31776 solver.cpp:228] Iteration 84200, loss = 0.000141189
I0822 12:38:21.064744 31776 solver.cpp:244]     Train net output #0: loss = 0.000141189 (* 1 = 0.000141189 loss)
I0822 12:38:21.064754 31776 sgd_solver.cpp:106] Iteration 84200, lr = 0.000289982
I0822 12:38:25.571285 31776 solver.cpp:228] Iteration 84300, loss = 0.000156681
I0822 12:38:25.571348 31776 solver.cpp:244]     Train net output #0: loss = 0.000156681 (* 1 = 0.000156681 loss)
I0822 12:38:25.571357 31776 sgd_solver.cpp:106] Iteration 84300, lr = 0.000289774
I0822 12:38:30.077873 31776 solver.cpp:228] Iteration 84400, loss = 8.60295e-05
I0822 12:38:30.077921 31776 solver.cpp:244]     Train net output #0: loss = 8.60295e-05 (* 1 = 8.60295e-05 loss)
I0822 12:38:30.077929 31776 sgd_solver.cpp:106] Iteration 84400, lr = 0.000289566
I0822 12:38:34.538676 31776 solver.cpp:337] Iteration 84500, Testing net (#0)
I0822 12:38:37.831485 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839708
I0822 12:38:37.831532 31776 solver.cpp:404]     Test net output #1: loss = 1.19192 (* 1 = 1.19192 loss)
I0822 12:38:37.846874 31776 solver.cpp:228] Iteration 84500, loss = 0.000133644
I0822 12:38:37.846938 31776 solver.cpp:244]     Train net output #0: loss = 0.000133644 (* 1 = 0.000133644 loss)
I0822 12:38:37.846947 31776 sgd_solver.cpp:106] Iteration 84500, lr = 0.000289358
I0822 12:38:42.352638 31776 solver.cpp:228] Iteration 84600, loss = 0.000114496
I0822 12:38:42.352679 31776 solver.cpp:244]     Train net output #0: loss = 0.000114496 (* 1 = 0.000114496 loss)
I0822 12:38:42.352687 31776 sgd_solver.cpp:106] Iteration 84600, lr = 0.00028915
I0822 12:38:46.857669 31776 solver.cpp:228] Iteration 84700, loss = 9.58697e-05
I0822 12:38:46.857717 31776 solver.cpp:244]     Train net output #0: loss = 9.58697e-05 (* 1 = 9.58697e-05 loss)
I0822 12:38:46.857724 31776 sgd_solver.cpp:106] Iteration 84700, lr = 0.000288943
I0822 12:38:51.364006 31776 solver.cpp:228] Iteration 84800, loss = 6.2615e-05
I0822 12:38:51.364059 31776 solver.cpp:244]     Train net output #0: loss = 6.2615e-05 (* 1 = 6.2615e-05 loss)
I0822 12:38:51.364068 31776 sgd_solver.cpp:106] Iteration 84800, lr = 0.000288736
I0822 12:38:55.869894 31776 solver.cpp:228] Iteration 84900, loss = 0.000180268
I0822 12:38:55.869942 31776 solver.cpp:244]     Train net output #0: loss = 0.000180268 (* 1 = 0.000180268 loss)
I0822 12:38:55.869951 31776 sgd_solver.cpp:106] Iteration 84900, lr = 0.00028853
I0822 12:39:00.332471 31776 solver.cpp:337] Iteration 85000, Testing net (#0)
I0822 12:39:03.589617 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839209
I0822 12:39:03.589679 31776 solver.cpp:404]     Test net output #1: loss = 1.1988 (* 1 = 1.1988 loss)
I0822 12:39:03.605024 31776 solver.cpp:228] Iteration 85000, loss = 9.41867e-05
I0822 12:39:03.605077 31776 solver.cpp:244]     Train net output #0: loss = 9.41867e-05 (* 1 = 9.41867e-05 loss)
I0822 12:39:03.605101 31776 sgd_solver.cpp:106] Iteration 85000, lr = 0.000288324
I0822 12:39:08.112264 31776 solver.cpp:228] Iteration 85100, loss = 8.51738e-05
I0822 12:39:08.112321 31776 solver.cpp:244]     Train net output #0: loss = 8.51738e-05 (* 1 = 8.51738e-05 loss)
I0822 12:39:08.112330 31776 sgd_solver.cpp:106] Iteration 85100, lr = 0.000288118
I0822 12:39:12.614090 31776 solver.cpp:228] Iteration 85200, loss = 9.5012e-05
I0822 12:39:12.614137 31776 solver.cpp:244]     Train net output #0: loss = 9.5012e-05 (* 1 = 9.5012e-05 loss)
I0822 12:39:12.614145 31776 sgd_solver.cpp:106] Iteration 85200, lr = 0.000287913
I0822 12:39:17.114611 31776 solver.cpp:228] Iteration 85300, loss = 0.000126487
I0822 12:39:17.114670 31776 solver.cpp:244]     Train net output #0: loss = 0.000126487 (* 1 = 0.000126487 loss)
I0822 12:39:17.114677 31776 sgd_solver.cpp:106] Iteration 85300, lr = 0.000287708
I0822 12:39:21.621002 31776 solver.cpp:228] Iteration 85400, loss = 0.000108265
I0822 12:39:21.621057 31776 solver.cpp:244]     Train net output #0: loss = 0.000108265 (* 1 = 0.000108265 loss)
I0822 12:39:21.621065 31776 sgd_solver.cpp:106] Iteration 85400, lr = 0.000287503
I0822 12:39:26.081815 31776 solver.cpp:337] Iteration 85500, Testing net (#0)
I0822 12:39:29.302629 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839042
I0822 12:39:29.302691 31776 solver.cpp:404]     Test net output #1: loss = 1.20128 (* 1 = 1.20128 loss)
I0822 12:39:29.317996 31776 solver.cpp:228] Iteration 85500, loss = 0.000178252
I0822 12:39:29.318070 31776 solver.cpp:244]     Train net output #0: loss = 0.000178252 (* 1 = 0.000178252 loss)
I0822 12:39:29.318083 31776 sgd_solver.cpp:106] Iteration 85500, lr = 0.000287298
I0822 12:39:33.822000 31776 solver.cpp:228] Iteration 85600, loss = 8.91909e-05
I0822 12:39:33.822058 31776 solver.cpp:244]     Train net output #0: loss = 8.91909e-05 (* 1 = 8.91909e-05 loss)
I0822 12:39:33.822067 31776 sgd_solver.cpp:106] Iteration 85600, lr = 0.000287094
I0822 12:39:38.327831 31776 solver.cpp:228] Iteration 85700, loss = 0.000207852
I0822 12:39:38.327886 31776 solver.cpp:244]     Train net output #0: loss = 0.000207852 (* 1 = 0.000207852 loss)
I0822 12:39:38.327895 31776 sgd_solver.cpp:106] Iteration 85700, lr = 0.000286891
I0822 12:39:42.833569 31776 solver.cpp:228] Iteration 85800, loss = 0.000129466
I0822 12:39:42.833629 31776 solver.cpp:244]     Train net output #0: loss = 0.000129466 (* 1 = 0.000129466 loss)
I0822 12:39:42.833637 31776 sgd_solver.cpp:106] Iteration 85800, lr = 0.000286687
I0822 12:39:47.339784 31776 solver.cpp:228] Iteration 85900, loss = 0.000200674
I0822 12:39:47.339833 31776 solver.cpp:244]     Train net output #0: loss = 0.000200674 (* 1 = 0.000200674 loss)
I0822 12:39:47.339841 31776 sgd_solver.cpp:106] Iteration 85900, lr = 0.000286484
I0822 12:39:51.800621 31776 solver.cpp:337] Iteration 86000, Testing net (#0)
I0822 12:39:55.075880 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838792
I0822 12:39:55.075937 31776 solver.cpp:404]     Test net output #1: loss = 1.20485 (* 1 = 1.20485 loss)
I0822 12:39:55.091392 31776 solver.cpp:228] Iteration 86000, loss = 0.000337316
I0822 12:39:55.091462 31776 solver.cpp:244]     Train net output #0: loss = 0.000337316 (* 1 = 0.000337316 loss)
I0822 12:39:55.091472 31776 sgd_solver.cpp:106] Iteration 86000, lr = 0.000286281
I0822 12:39:59.597364 31776 solver.cpp:228] Iteration 86100, loss = 0.000110855
I0822 12:39:59.597419 31776 solver.cpp:244]     Train net output #0: loss = 0.000110855 (* 1 = 0.000110855 loss)
I0822 12:39:59.597427 31776 sgd_solver.cpp:106] Iteration 86100, lr = 0.000286079
I0822 12:40:04.098291 31776 solver.cpp:228] Iteration 86200, loss = 0.000257246
I0822 12:40:04.098351 31776 solver.cpp:244]     Train net output #0: loss = 0.000257246 (* 1 = 0.000257246 loss)
I0822 12:40:04.098359 31776 sgd_solver.cpp:106] Iteration 86200, lr = 0.000285877
I0822 12:40:08.603050 31776 solver.cpp:228] Iteration 86300, loss = 8.56152e-05
I0822 12:40:08.603113 31776 solver.cpp:244]     Train net output #0: loss = 8.56152e-05 (* 1 = 8.56152e-05 loss)
I0822 12:40:08.603121 31776 sgd_solver.cpp:106] Iteration 86300, lr = 0.000285675
I0822 12:40:13.108952 31776 solver.cpp:228] Iteration 86400, loss = 0.000189886
I0822 12:40:13.109011 31776 solver.cpp:244]     Train net output #0: loss = 0.000189886 (* 1 = 0.000189886 loss)
I0822 12:40:13.109020 31776 sgd_solver.cpp:106] Iteration 86400, lr = 0.000285474
I0822 12:40:17.572178 31776 solver.cpp:337] Iteration 86500, Testing net (#0)
I0822 12:40:20.792271 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838333
I0822 12:40:20.792335 31776 solver.cpp:404]     Test net output #1: loss = 1.21149 (* 1 = 1.21149 loss)
I0822 12:40:20.807765 31776 solver.cpp:228] Iteration 86500, loss = 0.000118881
I0822 12:40:20.807839 31776 solver.cpp:244]     Train net output #0: loss = 0.000118881 (* 1 = 0.000118881 loss)
I0822 12:40:20.807850 31776 sgd_solver.cpp:106] Iteration 86500, lr = 0.000285273
I0822 12:40:25.313897 31776 solver.cpp:228] Iteration 86600, loss = 6.38543e-05
I0822 12:40:25.313951 31776 solver.cpp:244]     Train net output #0: loss = 6.38543e-05 (* 1 = 6.38543e-05 loss)
I0822 12:40:25.313959 31776 sgd_solver.cpp:106] Iteration 86600, lr = 0.000285072
I0822 12:40:29.818722 31776 solver.cpp:228] Iteration 86700, loss = 0.000125632
I0822 12:40:29.818781 31776 solver.cpp:244]     Train net output #0: loss = 0.000125632 (* 1 = 0.000125632 loss)
I0822 12:40:29.818789 31776 sgd_solver.cpp:106] Iteration 86700, lr = 0.000284872
I0822 12:40:34.325454 31776 solver.cpp:228] Iteration 86800, loss = 0.000163524
I0822 12:40:34.325515 31776 solver.cpp:244]     Train net output #0: loss = 0.000163524 (* 1 = 0.000163524 loss)
I0822 12:40:34.325523 31776 sgd_solver.cpp:106] Iteration 86800, lr = 0.000284672
I0822 12:40:38.832619 31776 solver.cpp:228] Iteration 86900, loss = 0.000118742
I0822 12:40:38.832674 31776 solver.cpp:244]     Train net output #0: loss = 0.000118742 (* 1 = 0.000118742 loss)
I0822 12:40:38.832681 31776 sgd_solver.cpp:106] Iteration 86900, lr = 0.000284472
I0822 12:40:43.290760 31776 solver.cpp:337] Iteration 87000, Testing net (#0)
I0822 12:40:43.931082 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:40:46.569941 31776 solver.cpp:404]     Test net output #0: accuracy = 0.839417
I0822 12:40:46.570001 31776 solver.cpp:404]     Test net output #1: loss = 1.20514 (* 1 = 1.20514 loss)
I0822 12:40:46.585311 31776 solver.cpp:228] Iteration 87000, loss = 7.09093e-05
I0822 12:40:46.585376 31776 solver.cpp:244]     Train net output #0: loss = 7.09093e-05 (* 1 = 7.09093e-05 loss)
I0822 12:40:46.585386 31776 sgd_solver.cpp:106] Iteration 87000, lr = 0.000284272
I0822 12:40:51.091727 31776 solver.cpp:228] Iteration 87100, loss = 7.24311e-05
I0822 12:40:51.091787 31776 solver.cpp:244]     Train net output #0: loss = 7.24311e-05 (* 1 = 7.24311e-05 loss)
I0822 12:40:51.091796 31776 sgd_solver.cpp:106] Iteration 87100, lr = 0.000284073
I0822 12:40:55.595054 31776 solver.cpp:228] Iteration 87200, loss = 8.75675e-05
I0822 12:40:55.595108 31776 solver.cpp:244]     Train net output #0: loss = 8.75675e-05 (* 1 = 8.75675e-05 loss)
I0822 12:40:55.595116 31776 sgd_solver.cpp:106] Iteration 87200, lr = 0.000283875
I0822 12:41:00.100304 31776 solver.cpp:228] Iteration 87300, loss = 0.000253016
I0822 12:41:00.100363 31776 solver.cpp:244]     Train net output #0: loss = 0.000253016 (* 1 = 0.000253016 loss)
I0822 12:41:00.100373 31776 sgd_solver.cpp:106] Iteration 87300, lr = 0.000283676
I0822 12:41:04.606549 31776 solver.cpp:228] Iteration 87400, loss = 8.79376e-05
I0822 12:41:04.606621 31776 solver.cpp:244]     Train net output #0: loss = 8.79376e-05 (* 1 = 8.79376e-05 loss)
I0822 12:41:04.606631 31776 sgd_solver.cpp:106] Iteration 87400, lr = 0.000283478
I0822 12:41:09.066823 31776 solver.cpp:337] Iteration 87500, Testing net (#0)
I0822 12:41:12.292824 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838083
I0822 12:41:12.292881 31776 solver.cpp:404]     Test net output #1: loss = 1.21296 (* 1 = 1.21296 loss)
I0822 12:41:12.308292 31776 solver.cpp:228] Iteration 87500, loss = 9.57471e-05
I0822 12:41:12.308353 31776 solver.cpp:244]     Train net output #0: loss = 9.57471e-05 (* 1 = 9.57471e-05 loss)
I0822 12:41:12.308363 31776 sgd_solver.cpp:106] Iteration 87500, lr = 0.00028328
I0822 12:41:16.811220 31776 solver.cpp:228] Iteration 87600, loss = 0.000142273
I0822 12:41:16.811288 31776 solver.cpp:244]     Train net output #0: loss = 0.000142273 (* 1 = 0.000142273 loss)
I0822 12:41:16.811297 31776 sgd_solver.cpp:106] Iteration 87600, lr = 0.000283083
I0822 12:41:21.311163 31776 solver.cpp:228] Iteration 87700, loss = 0.000254287
I0822 12:41:21.311224 31776 solver.cpp:244]     Train net output #0: loss = 0.000254287 (* 1 = 0.000254287 loss)
I0822 12:41:21.311233 31776 sgd_solver.cpp:106] Iteration 87700, lr = 0.000282886
I0822 12:41:25.816972 31776 solver.cpp:228] Iteration 87800, loss = 0.000554224
I0822 12:41:25.817034 31776 solver.cpp:244]     Train net output #0: loss = 0.000554224 (* 1 = 0.000554224 loss)
I0822 12:41:25.817044 31776 sgd_solver.cpp:106] Iteration 87800, lr = 0.000282689
I0822 12:41:30.324337 31776 solver.cpp:228] Iteration 87900, loss = 0.000105786
I0822 12:41:30.324395 31776 solver.cpp:244]     Train net output #0: loss = 0.000105786 (* 1 = 0.000105786 loss)
I0822 12:41:30.324405 31776 sgd_solver.cpp:106] Iteration 87900, lr = 0.000282492
I0822 12:41:34.785425 31776 solver.cpp:337] Iteration 88000, Testing net (#0)
I0822 12:41:38.014328 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838208
I0822 12:41:38.014390 31776 solver.cpp:404]     Test net output #1: loss = 1.21473 (* 1 = 1.21473 loss)
I0822 12:41:38.029814 31776 solver.cpp:228] Iteration 88000, loss = 0.000277366
I0822 12:41:38.029882 31776 solver.cpp:244]     Train net output #0: loss = 0.000277366 (* 1 = 0.000277366 loss)
I0822 12:41:38.029892 31776 sgd_solver.cpp:106] Iteration 88000, lr = 0.000282296
I0822 12:41:42.535522 31776 solver.cpp:228] Iteration 88100, loss = 0.000135999
I0822 12:41:42.535578 31776 solver.cpp:244]     Train net output #0: loss = 0.000135999 (* 1 = 0.000135999 loss)
I0822 12:41:42.535588 31776 sgd_solver.cpp:106] Iteration 88100, lr = 0.0002821
I0822 12:41:47.042011 31776 solver.cpp:228] Iteration 88200, loss = 0.000150311
I0822 12:41:47.042068 31776 solver.cpp:244]     Train net output #0: loss = 0.000150311 (* 1 = 0.000150311 loss)
I0822 12:41:47.042076 31776 sgd_solver.cpp:106] Iteration 88200, lr = 0.000281905
I0822 12:41:51.547757 31776 solver.cpp:228] Iteration 88300, loss = 0.0001468
I0822 12:41:51.547812 31776 solver.cpp:244]     Train net output #0: loss = 0.0001468 (* 1 = 0.0001468 loss)
I0822 12:41:51.547821 31776 sgd_solver.cpp:106] Iteration 88300, lr = 0.000281709
I0822 12:41:56.052968 31776 solver.cpp:228] Iteration 88400, loss = 8.9889e-05
I0822 12:41:56.053023 31776 solver.cpp:244]     Train net output #0: loss = 8.9889e-05 (* 1 = 8.9889e-05 loss)
I0822 12:41:56.053030 31776 sgd_solver.cpp:106] Iteration 88400, lr = 0.000281514
I0822 12:42:00.513962 31776 solver.cpp:337] Iteration 88500, Testing net (#0)
I0822 12:42:03.774863 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837417
I0822 12:42:03.774925 31776 solver.cpp:404]     Test net output #1: loss = 1.22092 (* 1 = 1.22092 loss)
I0822 12:42:03.790230 31776 solver.cpp:228] Iteration 88500, loss = 0.000127611
I0822 12:42:03.790303 31776 solver.cpp:244]     Train net output #0: loss = 0.000127611 (* 1 = 0.000127611 loss)
I0822 12:42:03.790314 31776 sgd_solver.cpp:106] Iteration 88500, lr = 0.00028132
I0822 12:42:08.293726 31776 solver.cpp:228] Iteration 88600, loss = 0.000159599
I0822 12:42:08.293786 31776 solver.cpp:244]     Train net output #0: loss = 0.000159599 (* 1 = 0.000159599 loss)
I0822 12:42:08.293794 31776 sgd_solver.cpp:106] Iteration 88600, lr = 0.000281125
I0822 12:42:12.799602 31776 solver.cpp:228] Iteration 88700, loss = 6.63604e-05
I0822 12:42:12.799659 31776 solver.cpp:244]     Train net output #0: loss = 6.63604e-05 (* 1 = 6.63604e-05 loss)
I0822 12:42:12.799666 31776 sgd_solver.cpp:106] Iteration 88700, lr = 0.000280931
I0822 12:42:17.305675 31776 solver.cpp:228] Iteration 88800, loss = 7.21537e-05
I0822 12:42:17.305734 31776 solver.cpp:244]     Train net output #0: loss = 7.21537e-05 (* 1 = 7.21537e-05 loss)
I0822 12:42:17.305743 31776 sgd_solver.cpp:106] Iteration 88800, lr = 0.000280738
I0822 12:42:21.811276 31776 solver.cpp:228] Iteration 88900, loss = 9.22113e-05
I0822 12:42:21.811336 31776 solver.cpp:244]     Train net output #0: loss = 9.22113e-05 (* 1 = 9.22113e-05 loss)
I0822 12:42:21.811344 31776 sgd_solver.cpp:106] Iteration 88900, lr = 0.000280544
I0822 12:42:26.274852 31776 solver.cpp:337] Iteration 89000, Testing net (#0)
I0822 12:42:29.485512 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837417
I0822 12:42:29.485575 31776 solver.cpp:404]     Test net output #1: loss = 1.22523 (* 1 = 1.22523 loss)
I0822 12:42:29.500953 31776 solver.cpp:228] Iteration 89000, loss = 5.46534e-05
I0822 12:42:29.501019 31776 solver.cpp:244]     Train net output #0: loss = 5.46534e-05 (* 1 = 5.46534e-05 loss)
I0822 12:42:29.501029 31776 sgd_solver.cpp:106] Iteration 89000, lr = 0.000280351
I0822 12:42:34.006974 31776 solver.cpp:228] Iteration 89100, loss = 8.55794e-05
I0822 12:42:34.007030 31776 solver.cpp:244]     Train net output #0: loss = 8.55794e-05 (* 1 = 8.55794e-05 loss)
I0822 12:42:34.007038 31776 sgd_solver.cpp:106] Iteration 89100, lr = 0.000280159
I0822 12:42:38.511461 31776 solver.cpp:228] Iteration 89200, loss = 9.04496e-05
I0822 12:42:38.511518 31776 solver.cpp:244]     Train net output #0: loss = 9.04496e-05 (* 1 = 9.04496e-05 loss)
I0822 12:42:38.511528 31776 sgd_solver.cpp:106] Iteration 89200, lr = 0.000279966
I0822 12:42:43.015926 31776 solver.cpp:228] Iteration 89300, loss = 0.000123623
I0822 12:42:43.015983 31776 solver.cpp:244]     Train net output #0: loss = 0.000123623 (* 1 = 0.000123623 loss)
I0822 12:42:43.015991 31776 sgd_solver.cpp:106] Iteration 89300, lr = 0.000279774
I0822 12:42:47.521455 31776 solver.cpp:228] Iteration 89400, loss = 0.000142614
I0822 12:42:47.521507 31776 solver.cpp:244]     Train net output #0: loss = 0.000142614 (* 1 = 0.000142614 loss)
I0822 12:42:47.521517 31776 sgd_solver.cpp:106] Iteration 89400, lr = 0.000279582
I0822 12:42:51.981276 31776 solver.cpp:337] Iteration 89500, Testing net (#0)
I0822 12:42:55.603205 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837333
I0822 12:42:55.603269 31776 solver.cpp:404]     Test net output #1: loss = 1.22764 (* 1 = 1.22764 loss)
I0822 12:42:55.618671 31776 solver.cpp:228] Iteration 89500, loss = 0.000144736
I0822 12:42:55.618741 31776 solver.cpp:244]     Train net output #0: loss = 0.000144736 (* 1 = 0.000144736 loss)
I0822 12:42:55.618751 31776 sgd_solver.cpp:106] Iteration 89500, lr = 0.000279391
I0822 12:43:00.125402 31776 solver.cpp:228] Iteration 89600, loss = 7.00212e-05
I0822 12:43:00.125458 31776 solver.cpp:244]     Train net output #0: loss = 7.00212e-05 (* 1 = 7.00212e-05 loss)
I0822 12:43:00.125465 31776 sgd_solver.cpp:106] Iteration 89600, lr = 0.000279199
I0822 12:43:04.631532 31776 solver.cpp:228] Iteration 89700, loss = 4.96253e-05
I0822 12:43:04.631588 31776 solver.cpp:244]     Train net output #0: loss = 4.96253e-05 (* 1 = 4.96253e-05 loss)
I0822 12:43:04.631597 31776 sgd_solver.cpp:106] Iteration 89700, lr = 0.000279009
I0822 12:43:09.137425 31776 solver.cpp:228] Iteration 89800, loss = 0.000108614
I0822 12:43:09.137482 31776 solver.cpp:244]     Train net output #0: loss = 0.000108614 (* 1 = 0.000108614 loss)
I0822 12:43:09.137490 31776 sgd_solver.cpp:106] Iteration 89800, lr = 0.000278818
I0822 12:43:13.643653 31776 solver.cpp:228] Iteration 89900, loss = 6.9505e-05
I0822 12:43:13.643712 31776 solver.cpp:244]     Train net output #0: loss = 6.9505e-05 (* 1 = 6.9505e-05 loss)
I0822 12:43:13.643724 31776 sgd_solver.cpp:106] Iteration 89900, lr = 0.000278628
I0822 12:43:18.104869 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_90000.caffemodel
I0822 12:43:18.598251 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_90000.solverstate
I0822 12:43:18.754034 31776 solver.cpp:337] Iteration 90000, Testing net (#0)
I0822 12:43:22.009518 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836958
I0822 12:43:22.009582 31776 solver.cpp:404]     Test net output #1: loss = 1.23409 (* 1 = 1.23409 loss)
I0822 12:43:22.024965 31776 solver.cpp:228] Iteration 90000, loss = 0.000181159
I0822 12:43:22.025039 31776 solver.cpp:244]     Train net output #0: loss = 0.000181159 (* 1 = 0.000181159 loss)
I0822 12:43:22.025051 31776 sgd_solver.cpp:106] Iteration 90000, lr = 0.000278438
I0822 12:43:26.530546 31776 solver.cpp:228] Iteration 90100, loss = 9.60452e-05
I0822 12:43:26.530606 31776 solver.cpp:244]     Train net output #0: loss = 9.60452e-05 (* 1 = 9.60452e-05 loss)
I0822 12:43:26.530616 31776 sgd_solver.cpp:106] Iteration 90100, lr = 0.000278248
I0822 12:43:31.038414 31776 solver.cpp:228] Iteration 90200, loss = 0.000192772
I0822 12:43:31.038470 31776 solver.cpp:244]     Train net output #0: loss = 0.000192772 (* 1 = 0.000192772 loss)
I0822 12:43:31.038478 31776 sgd_solver.cpp:106] Iteration 90200, lr = 0.000278059
I0822 12:43:35.544312 31776 solver.cpp:228] Iteration 90300, loss = 0.00034277
I0822 12:43:35.544365 31776 solver.cpp:244]     Train net output #0: loss = 0.00034277 (* 1 = 0.00034277 loss)
I0822 12:43:35.544373 31776 sgd_solver.cpp:106] Iteration 90300, lr = 0.00027787
I0822 12:43:40.052050 31776 solver.cpp:228] Iteration 90400, loss = 0.000168482
I0822 12:43:40.052110 31776 solver.cpp:244]     Train net output #0: loss = 0.000168482 (* 1 = 0.000168482 loss)
I0822 12:43:40.052119 31776 sgd_solver.cpp:106] Iteration 90400, lr = 0.000277681
I0822 12:43:44.513214 31776 solver.cpp:337] Iteration 90500, Testing net (#0)
I0822 12:43:47.739998 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836417
I0822 12:43:47.740047 31776 solver.cpp:404]     Test net output #1: loss = 1.2379 (* 1 = 1.2379 loss)
I0822 12:43:47.755378 31776 solver.cpp:228] Iteration 90500, loss = 0.000126046
I0822 12:43:47.755432 31776 solver.cpp:244]     Train net output #0: loss = 0.000126046 (* 1 = 0.000126046 loss)
I0822 12:43:47.755442 31776 sgd_solver.cpp:106] Iteration 90500, lr = 0.000277492
I0822 12:43:52.260550 31776 solver.cpp:228] Iteration 90600, loss = 0.000203943
I0822 12:43:52.260607 31776 solver.cpp:244]     Train net output #0: loss = 0.000203943 (* 1 = 0.000203943 loss)
I0822 12:43:52.260615 31776 sgd_solver.cpp:106] Iteration 90600, lr = 0.000277304
I0822 12:43:56.763876 31776 solver.cpp:228] Iteration 90700, loss = 0.000171639
I0822 12:43:56.763938 31776 solver.cpp:244]     Train net output #0: loss = 0.000171639 (* 1 = 0.000171639 loss)
I0822 12:43:56.763948 31776 sgd_solver.cpp:106] Iteration 90700, lr = 0.000277116
I0822 12:44:01.270618 31776 solver.cpp:228] Iteration 90800, loss = 9.46735e-05
I0822 12:44:01.270683 31776 solver.cpp:244]     Train net output #0: loss = 9.46735e-05 (* 1 = 9.46735e-05 loss)
I0822 12:44:01.270691 31776 sgd_solver.cpp:106] Iteration 90800, lr = 0.000276929
I0822 12:44:05.776994 31776 solver.cpp:228] Iteration 90900, loss = 4.14234e-05
I0822 12:44:05.777052 31776 solver.cpp:244]     Train net output #0: loss = 4.14234e-05 (* 1 = 4.14234e-05 loss)
I0822 12:44:05.777060 31776 sgd_solver.cpp:106] Iteration 90900, lr = 0.000276741
I0822 12:44:10.238407 31776 solver.cpp:337] Iteration 91000, Testing net (#0)
I0822 12:44:13.477332 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8365
I0822 12:44:13.477383 31776 solver.cpp:404]     Test net output #1: loss = 1.24126 (* 1 = 1.24126 loss)
I0822 12:44:13.492877 31776 solver.cpp:228] Iteration 91000, loss = 0.00012489
I0822 12:44:13.492938 31776 solver.cpp:244]     Train net output #0: loss = 0.00012489 (* 1 = 0.00012489 loss)
I0822 12:44:13.492950 31776 sgd_solver.cpp:106] Iteration 91000, lr = 0.000276554
I0822 12:44:17.995568 31776 solver.cpp:228] Iteration 91100, loss = 8.45874e-05
I0822 12:44:17.995618 31776 solver.cpp:244]     Train net output #0: loss = 8.45874e-05 (* 1 = 8.45874e-05 loss)
I0822 12:44:17.995627 31776 sgd_solver.cpp:106] Iteration 91100, lr = 0.000276368
I0822 12:44:22.501564 31776 solver.cpp:228] Iteration 91200, loss = 0.000109639
I0822 12:44:22.501613 31776 solver.cpp:244]     Train net output #0: loss = 0.000109639 (* 1 = 0.000109639 loss)
I0822 12:44:22.501634 31776 sgd_solver.cpp:106] Iteration 91200, lr = 0.000276181
I0822 12:44:27.006378 31776 solver.cpp:228] Iteration 91300, loss = 8.83423e-05
I0822 12:44:27.006443 31776 solver.cpp:244]     Train net output #0: loss = 8.83423e-05 (* 1 = 8.83423e-05 loss)
I0822 12:44:27.006450 31776 sgd_solver.cpp:106] Iteration 91300, lr = 0.000275995
I0822 12:44:31.511256 31776 solver.cpp:228] Iteration 91400, loss = 0.000106547
I0822 12:44:31.511312 31776 solver.cpp:244]     Train net output #0: loss = 0.000106547 (* 1 = 0.000106547 loss)
I0822 12:44:31.511320 31776 sgd_solver.cpp:106] Iteration 91400, lr = 0.000275809
I0822 12:44:35.970695 31776 solver.cpp:337] Iteration 91500, Testing net (#0)
I0822 12:44:39.206308 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835917
I0822 12:44:39.206356 31776 solver.cpp:404]     Test net output #1: loss = 1.24745 (* 1 = 1.24745 loss)
I0822 12:44:39.221673 31776 solver.cpp:228] Iteration 91500, loss = 0.000288845
I0822 12:44:39.221734 31776 solver.cpp:244]     Train net output #0: loss = 0.000288845 (* 1 = 0.000288845 loss)
I0822 12:44:39.221742 31776 sgd_solver.cpp:106] Iteration 91500, lr = 0.000275624
I0822 12:44:43.728096 31776 solver.cpp:228] Iteration 91600, loss = 0.00024522
I0822 12:44:43.728145 31776 solver.cpp:244]     Train net output #0: loss = 0.00024522 (* 1 = 0.00024522 loss)
I0822 12:44:43.728164 31776 sgd_solver.cpp:106] Iteration 91600, lr = 0.000275438
I0822 12:44:48.233690 31776 solver.cpp:228] Iteration 91700, loss = 6.84741e-05
I0822 12:44:48.233736 31776 solver.cpp:244]     Train net output #0: loss = 6.84741e-05 (* 1 = 6.84741e-05 loss)
I0822 12:44:48.233743 31776 sgd_solver.cpp:106] Iteration 91700, lr = 0.000275253
I0822 12:44:52.738067 31776 solver.cpp:228] Iteration 91800, loss = 0.000167258
I0822 12:44:52.738112 31776 solver.cpp:244]     Train net output #0: loss = 0.000167258 (* 1 = 0.000167258 loss)
I0822 12:44:52.738121 31776 sgd_solver.cpp:106] Iteration 91800, lr = 0.000275069
I0822 12:44:57.243891 31776 solver.cpp:228] Iteration 91900, loss = 0.000105942
I0822 12:44:57.243942 31776 solver.cpp:244]     Train net output #0: loss = 0.000105942 (* 1 = 0.000105942 loss)
I0822 12:44:57.243950 31776 sgd_solver.cpp:106] Iteration 91900, lr = 0.000274884
I0822 12:45:01.704888 31776 solver.cpp:337] Iteration 92000, Testing net (#0)
I0822 12:45:04.950016 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835792
I0822 12:45:04.950069 31776 solver.cpp:404]     Test net output #1: loss = 1.2476 (* 1 = 1.2476 loss)
I0822 12:45:04.965459 31776 solver.cpp:228] Iteration 92000, loss = 0.000106212
I0822 12:45:04.965513 31776 solver.cpp:244]     Train net output #0: loss = 0.000106212 (* 1 = 0.000106212 loss)
I0822 12:45:04.965523 31776 sgd_solver.cpp:106] Iteration 92000, lr = 0.0002747
I0822 12:45:09.468794 31776 solver.cpp:228] Iteration 92100, loss = 0.000220129
I0822 12:45:09.468852 31776 solver.cpp:244]     Train net output #0: loss = 0.000220129 (* 1 = 0.000220129 loss)
I0822 12:45:09.468861 31776 sgd_solver.cpp:106] Iteration 92100, lr = 0.000274516
I0822 12:45:13.976673 31776 solver.cpp:228] Iteration 92200, loss = 0.000136491
I0822 12:45:13.976732 31776 solver.cpp:244]     Train net output #0: loss = 0.000136491 (* 1 = 0.000136491 loss)
I0822 12:45:13.976739 31776 sgd_solver.cpp:106] Iteration 92200, lr = 0.000274333
I0822 12:45:18.482607 31776 solver.cpp:228] Iteration 92300, loss = 0.000655283
I0822 12:45:18.482671 31776 solver.cpp:244]     Train net output #0: loss = 0.000655283 (* 1 = 0.000655283 loss)
I0822 12:45:18.482679 31776 sgd_solver.cpp:106] Iteration 92300, lr = 0.00027415
I0822 12:45:22.987426 31776 solver.cpp:228] Iteration 92400, loss = 0.000108789
I0822 12:45:22.987488 31776 solver.cpp:244]     Train net output #0: loss = 0.000108789 (* 1 = 0.000108789 loss)
I0822 12:45:22.987495 31776 sgd_solver.cpp:106] Iteration 92400, lr = 0.000273967
I0822 12:45:27.442622 31776 solver.cpp:337] Iteration 92500, Testing net (#0)
I0822 12:45:30.724915 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835292
I0822 12:45:30.724961 31776 solver.cpp:404]     Test net output #1: loss = 1.25221 (* 1 = 1.25221 loss)
I0822 12:45:30.742467 31776 solver.cpp:228] Iteration 92500, loss = 0.000156197
I0822 12:45:30.742527 31776 solver.cpp:244]     Train net output #0: loss = 0.000156197 (* 1 = 0.000156197 loss)
I0822 12:45:30.742539 31776 sgd_solver.cpp:106] Iteration 92500, lr = 0.000273784
I0822 12:45:35.249840 31776 solver.cpp:228] Iteration 92600, loss = 8.42993e-05
I0822 12:45:35.249884 31776 solver.cpp:244]     Train net output #0: loss = 8.42993e-05 (* 1 = 8.42993e-05 loss)
I0822 12:45:35.249892 31776 sgd_solver.cpp:106] Iteration 92600, lr = 0.000273602
I0822 12:45:39.754536 31776 solver.cpp:228] Iteration 92700, loss = 5.88563e-05
I0822 12:45:39.754595 31776 solver.cpp:244]     Train net output #0: loss = 5.88563e-05 (* 1 = 5.88563e-05 loss)
I0822 12:45:39.754602 31776 sgd_solver.cpp:106] Iteration 92700, lr = 0.00027342
I0822 12:45:44.260568 31776 solver.cpp:228] Iteration 92800, loss = 0.000107183
I0822 12:45:44.260625 31776 solver.cpp:244]     Train net output #0: loss = 0.000107183 (* 1 = 0.000107183 loss)
I0822 12:45:44.260633 31776 sgd_solver.cpp:106] Iteration 92800, lr = 0.000273238
I0822 12:45:48.763314 31776 solver.cpp:228] Iteration 92900, loss = 0.000130276
I0822 12:45:48.763367 31776 solver.cpp:244]     Train net output #0: loss = 0.000130276 (* 1 = 0.000130276 loss)
I0822 12:45:48.763375 31776 sgd_solver.cpp:106] Iteration 92900, lr = 0.000273056
I0822 12:45:53.221802 31776 solver.cpp:337] Iteration 93000, Testing net (#0)
I0822 12:45:56.468082 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835167
I0822 12:45:56.468153 31776 solver.cpp:404]     Test net output #1: loss = 1.25743 (* 1 = 1.25743 loss)
I0822 12:45:56.483657 31776 solver.cpp:228] Iteration 93000, loss = 0.000130143
I0822 12:45:56.483710 31776 solver.cpp:244]     Train net output #0: loss = 0.000130143 (* 1 = 0.000130143 loss)
I0822 12:45:56.483721 31776 sgd_solver.cpp:106] Iteration 93000, lr = 0.000272875
I0822 12:46:00.987483 31776 solver.cpp:228] Iteration 93100, loss = 9.12214e-05
I0822 12:46:00.987537 31776 solver.cpp:244]     Train net output #0: loss = 9.12214e-05 (* 1 = 9.12214e-05 loss)
I0822 12:46:00.987546 31776 sgd_solver.cpp:106] Iteration 93100, lr = 0.000272694
I0822 12:46:05.494429 31776 solver.cpp:228] Iteration 93200, loss = 9.08489e-05
I0822 12:46:05.494490 31776 solver.cpp:244]     Train net output #0: loss = 9.08489e-05 (* 1 = 9.08489e-05 loss)
I0822 12:46:05.494499 31776 sgd_solver.cpp:106] Iteration 93200, lr = 0.000272513
I0822 12:46:09.995013 31776 solver.cpp:228] Iteration 93300, loss = 7.48511e-05
I0822 12:46:09.995069 31776 solver.cpp:244]     Train net output #0: loss = 7.48511e-05 (* 1 = 7.48511e-05 loss)
I0822 12:46:09.995079 31776 sgd_solver.cpp:106] Iteration 93300, lr = 0.000272333
I0822 12:46:14.499948 31776 solver.cpp:228] Iteration 93400, loss = 7.59015e-05
I0822 12:46:14.500005 31776 solver.cpp:244]     Train net output #0: loss = 7.59015e-05 (* 1 = 7.59015e-05 loss)
I0822 12:46:14.500013 31776 sgd_solver.cpp:106] Iteration 93400, lr = 0.000272153
I0822 12:46:18.959832 31776 solver.cpp:337] Iteration 93500, Testing net (#0)
I0822 12:46:19.410914 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:46:22.229503 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835459
I0822 12:46:22.229567 31776 solver.cpp:404]     Test net output #1: loss = 1.25279 (* 1 = 1.25279 loss)
I0822 12:46:22.245038 31776 solver.cpp:228] Iteration 93500, loss = 0.000173631
I0822 12:46:22.245115 31776 solver.cpp:244]     Train net output #0: loss = 0.000173631 (* 1 = 0.000173631 loss)
I0822 12:46:22.245131 31776 sgd_solver.cpp:106] Iteration 93500, lr = 0.000271973
I0822 12:46:26.751121 31776 solver.cpp:228] Iteration 93600, loss = 0.000267346
I0822 12:46:26.751179 31776 solver.cpp:244]     Train net output #0: loss = 0.000267346 (* 1 = 0.000267346 loss)
I0822 12:46:26.751188 31776 sgd_solver.cpp:106] Iteration 93600, lr = 0.000271793
I0822 12:46:31.256839 31776 solver.cpp:228] Iteration 93700, loss = 7.38975e-05
I0822 12:46:31.256898 31776 solver.cpp:244]     Train net output #0: loss = 7.38975e-05 (* 1 = 7.38975e-05 loss)
I0822 12:46:31.256913 31776 sgd_solver.cpp:106] Iteration 93700, lr = 0.000271614
I0822 12:46:35.762426 31776 solver.cpp:228] Iteration 93800, loss = 0.00011089
I0822 12:46:35.762485 31776 solver.cpp:244]     Train net output #0: loss = 0.00011089 (* 1 = 0.00011089 loss)
I0822 12:46:35.762492 31776 sgd_solver.cpp:106] Iteration 93800, lr = 0.000271435
I0822 12:46:40.268190 31776 solver.cpp:228] Iteration 93900, loss = 7.92029e-05
I0822 12:46:40.268245 31776 solver.cpp:244]     Train net output #0: loss = 7.92029e-05 (* 1 = 7.92029e-05 loss)
I0822 12:46:40.268254 31776 sgd_solver.cpp:106] Iteration 93900, lr = 0.000271256
I0822 12:46:44.727999 31776 solver.cpp:337] Iteration 94000, Testing net (#0)
I0822 12:46:48.000100 31776 solver.cpp:404]     Test net output #0: accuracy = 0.8355
I0822 12:46:48.000180 31776 solver.cpp:404]     Test net output #1: loss = 1.25565 (* 1 = 1.25565 loss)
I0822 12:46:48.015455 31776 solver.cpp:228] Iteration 94000, loss = 9.15876e-05
I0822 12:46:48.015511 31776 solver.cpp:244]     Train net output #0: loss = 9.15876e-05 (* 1 = 9.15876e-05 loss)
I0822 12:46:48.015523 31776 sgd_solver.cpp:106] Iteration 94000, lr = 0.000271078
I0822 12:46:52.524588 31776 solver.cpp:228] Iteration 94100, loss = 0.000119923
I0822 12:46:52.524644 31776 solver.cpp:244]     Train net output #0: loss = 0.000119923 (* 1 = 0.000119923 loss)
I0822 12:46:52.524653 31776 sgd_solver.cpp:106] Iteration 94100, lr = 0.0002709
I0822 12:46:57.030601 31776 solver.cpp:228] Iteration 94200, loss = 6.50958e-05
I0822 12:46:57.030661 31776 solver.cpp:244]     Train net output #0: loss = 6.50958e-05 (* 1 = 6.50958e-05 loss)
I0822 12:46:57.030670 31776 sgd_solver.cpp:106] Iteration 94200, lr = 0.000270722
I0822 12:47:01.534448 31776 solver.cpp:228] Iteration 94300, loss = 0.000104161
I0822 12:47:01.534503 31776 solver.cpp:244]     Train net output #0: loss = 0.000104161 (* 1 = 0.000104161 loss)
I0822 12:47:01.534512 31776 sgd_solver.cpp:106] Iteration 94300, lr = 0.000270544
I0822 12:47:06.039371 31776 solver.cpp:228] Iteration 94400, loss = 7.2949e-05
I0822 12:47:06.039428 31776 solver.cpp:244]     Train net output #0: loss = 7.2949e-05 (* 1 = 7.2949e-05 loss)
I0822 12:47:06.039438 31776 sgd_solver.cpp:106] Iteration 94400, lr = 0.000270367
I0822 12:47:10.501299 31776 solver.cpp:337] Iteration 94500, Testing net (#0)
I0822 12:47:13.793829 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835584
I0822 12:47:13.793895 31776 solver.cpp:404]     Test net output #1: loss = 1.25566 (* 1 = 1.25566 loss)
I0822 12:47:13.809377 31776 solver.cpp:228] Iteration 94500, loss = 0.000124848
I0822 12:47:13.809448 31776 solver.cpp:244]     Train net output #0: loss = 0.000124848 (* 1 = 0.000124848 loss)
I0822 12:47:13.809460 31776 sgd_solver.cpp:106] Iteration 94500, lr = 0.000270189
I0822 12:47:18.315690 31776 solver.cpp:228] Iteration 94600, loss = 0.000368949
I0822 12:47:18.315747 31776 solver.cpp:244]     Train net output #0: loss = 0.000368949 (* 1 = 0.000368949 loss)
I0822 12:47:18.315755 31776 sgd_solver.cpp:106] Iteration 94600, lr = 0.000270013
I0822 12:47:22.821892 31776 solver.cpp:228] Iteration 94700, loss = 0.00012834
I0822 12:47:22.821951 31776 solver.cpp:244]     Train net output #0: loss = 0.00012834 (* 1 = 0.00012834 loss)
I0822 12:47:22.821959 31776 sgd_solver.cpp:106] Iteration 94700, lr = 0.000269836
I0822 12:47:27.327011 31776 solver.cpp:228] Iteration 94800, loss = 8.85556e-05
I0822 12:47:27.327067 31776 solver.cpp:244]     Train net output #0: loss = 8.85556e-05 (* 1 = 8.85556e-05 loss)
I0822 12:47:27.327075 31776 sgd_solver.cpp:106] Iteration 94800, lr = 0.00026966
I0822 12:47:31.834159 31776 solver.cpp:228] Iteration 94900, loss = 7.59878e-05
I0822 12:47:31.834214 31776 solver.cpp:244]     Train net output #0: loss = 7.59878e-05 (* 1 = 7.59878e-05 loss)
I0822 12:47:31.834225 31776 sgd_solver.cpp:106] Iteration 94900, lr = 0.000269484
I0822 12:47:36.296167 31776 solver.cpp:337] Iteration 95000, Testing net (#0)
I0822 12:47:39.581634 31776 solver.cpp:404]     Test net output #0: accuracy = 0.836125
I0822 12:47:39.581692 31776 solver.cpp:404]     Test net output #1: loss = 1.25272 (* 1 = 1.25272 loss)
I0822 12:47:39.597092 31776 solver.cpp:228] Iteration 95000, loss = 0.00021328
I0822 12:47:39.597162 31776 solver.cpp:244]     Train net output #0: loss = 0.00021328 (* 1 = 0.00021328 loss)
I0822 12:47:39.597177 31776 sgd_solver.cpp:106] Iteration 95000, lr = 0.000269308
I0822 12:47:44.106127 31776 solver.cpp:228] Iteration 95100, loss = 0.000131589
I0822 12:47:44.106184 31776 solver.cpp:244]     Train net output #0: loss = 0.000131589 (* 1 = 0.000131589 loss)
I0822 12:47:44.106191 31776 sgd_solver.cpp:106] Iteration 95100, lr = 0.000269132
I0822 12:47:48.611835 31776 solver.cpp:228] Iteration 95200, loss = 6.33944e-05
I0822 12:47:48.611881 31776 solver.cpp:244]     Train net output #0: loss = 6.33944e-05 (* 1 = 6.33944e-05 loss)
I0822 12:47:48.611889 31776 sgd_solver.cpp:106] Iteration 95200, lr = 0.000268957
I0822 12:47:53.117101 31776 solver.cpp:228] Iteration 95300, loss = 0.000106243
I0822 12:47:53.117162 31776 solver.cpp:244]     Train net output #0: loss = 0.000106243 (* 1 = 0.000106243 loss)
I0822 12:47:53.117171 31776 sgd_solver.cpp:106] Iteration 95300, lr = 0.000268782
I0822 12:47:57.623934 31776 solver.cpp:228] Iteration 95400, loss = 0.000103536
I0822 12:47:57.623980 31776 solver.cpp:244]     Train net output #0: loss = 0.000103536 (* 1 = 0.000103536 loss)
I0822 12:47:57.623987 31776 sgd_solver.cpp:106] Iteration 95400, lr = 0.000268608
I0822 12:48:02.086474 31776 solver.cpp:337] Iteration 95500, Testing net (#0)
I0822 12:48:05.332041 31776 solver.cpp:404]     Test net output #0: accuracy = 0.835875
I0822 12:48:05.332106 31776 solver.cpp:404]     Test net output #1: loss = 1.25218 (* 1 = 1.25218 loss)
I0822 12:48:05.347468 31776 solver.cpp:228] Iteration 95500, loss = 0.000169128
I0822 12:48:05.347530 31776 solver.cpp:244]     Train net output #0: loss = 0.000169128 (* 1 = 0.000169128 loss)
I0822 12:48:05.347542 31776 sgd_solver.cpp:106] Iteration 95500, lr = 0.000268433
I0822 12:48:09.854195 31776 solver.cpp:228] Iteration 95600, loss = 6.49816e-05
I0822 12:48:09.854260 31776 solver.cpp:244]     Train net output #0: loss = 6.49816e-05 (* 1 = 6.49816e-05 loss)
I0822 12:48:09.854270 31776 sgd_solver.cpp:106] Iteration 95600, lr = 0.000268259
I0822 12:48:14.358253 31776 solver.cpp:228] Iteration 95700, loss = 0.000107206
I0822 12:48:14.358311 31776 solver.cpp:244]     Train net output #0: loss = 0.000107206 (* 1 = 0.000107206 loss)
I0822 12:48:14.358320 31776 sgd_solver.cpp:106] Iteration 95700, lr = 0.000268085
I0822 12:48:18.859966 31776 solver.cpp:228] Iteration 95800, loss = 0.00025802
I0822 12:48:18.860023 31776 solver.cpp:244]     Train net output #0: loss = 0.00025802 (* 1 = 0.00025802 loss)
I0822 12:48:18.860033 31776 sgd_solver.cpp:106] Iteration 95800, lr = 0.000267911
I0822 12:48:23.366710 31776 solver.cpp:228] Iteration 95900, loss = 0.000102102
I0822 12:48:23.366766 31776 solver.cpp:244]     Train net output #0: loss = 0.000102102 (* 1 = 0.000102102 loss)
I0822 12:48:23.366775 31776 sgd_solver.cpp:106] Iteration 95900, lr = 0.000267738
I0822 12:48:27.826766 31776 solver.cpp:337] Iteration 96000, Testing net (#0)
I0822 12:48:31.135846 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83625
I0822 12:48:31.135906 31776 solver.cpp:404]     Test net output #1: loss = 1.25219 (* 1 = 1.25219 loss)
I0822 12:48:31.151294 31776 solver.cpp:228] Iteration 96000, loss = 7.84661e-05
I0822 12:48:31.151360 31776 solver.cpp:244]     Train net output #0: loss = 7.84661e-05 (* 1 = 7.84661e-05 loss)
I0822 12:48:31.151370 31776 sgd_solver.cpp:106] Iteration 96000, lr = 0.000267565
I0822 12:48:35.656471 31776 solver.cpp:228] Iteration 96100, loss = 0.000372434
I0822 12:48:35.656527 31776 solver.cpp:244]     Train net output #0: loss = 0.000372434 (* 1 = 0.000372434 loss)
I0822 12:48:35.656536 31776 sgd_solver.cpp:106] Iteration 96100, lr = 0.000267392
I0822 12:48:40.165191 31776 solver.cpp:228] Iteration 96200, loss = 0.000140017
I0822 12:48:40.165246 31776 solver.cpp:244]     Train net output #0: loss = 0.000140017 (* 1 = 0.000140017 loss)
I0822 12:48:40.165254 31776 sgd_solver.cpp:106] Iteration 96200, lr = 0.000267219
I0822 12:48:44.670552 31776 solver.cpp:228] Iteration 96300, loss = 9.79156e-05
I0822 12:48:44.670610 31776 solver.cpp:244]     Train net output #0: loss = 9.79156e-05 (* 1 = 9.79156e-05 loss)
I0822 12:48:44.670619 31776 sgd_solver.cpp:106] Iteration 96300, lr = 0.000267047
I0822 12:48:49.177989 31776 solver.cpp:228] Iteration 96400, loss = 4.77288e-05
I0822 12:48:49.178043 31776 solver.cpp:244]     Train net output #0: loss = 4.77288e-05 (* 1 = 4.77288e-05 loss)
I0822 12:48:49.178051 31776 sgd_solver.cpp:106] Iteration 96400, lr = 0.000266875
I0822 12:48:53.635854 31776 solver.cpp:337] Iteration 96500, Testing net (#0)
I0822 12:48:56.936429 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837292
I0822 12:48:56.936491 31776 solver.cpp:404]     Test net output #1: loss = 1.24903 (* 1 = 1.24903 loss)
I0822 12:48:56.952899 31776 solver.cpp:228] Iteration 96500, loss = 8.13936e-05
I0822 12:48:56.952973 31776 solver.cpp:244]     Train net output #0: loss = 8.13936e-05 (* 1 = 8.13936e-05 loss)
I0822 12:48:56.952988 31776 sgd_solver.cpp:106] Iteration 96500, lr = 0.000266703
I0822 12:49:01.458582 31776 solver.cpp:228] Iteration 96600, loss = 0.000393156
I0822 12:49:01.458643 31776 solver.cpp:244]     Train net output #0: loss = 0.000393156 (* 1 = 0.000393156 loss)
I0822 12:49:01.458652 31776 sgd_solver.cpp:106] Iteration 96600, lr = 0.000266532
I0822 12:49:05.963563 31776 solver.cpp:228] Iteration 96700, loss = 0.000151902
I0822 12:49:05.963618 31776 solver.cpp:244]     Train net output #0: loss = 0.000151902 (* 1 = 0.000151902 loss)
I0822 12:49:05.963627 31776 sgd_solver.cpp:106] Iteration 96700, lr = 0.00026636
I0822 12:49:10.471359 31776 solver.cpp:228] Iteration 96800, loss = 0.000105833
I0822 12:49:10.471421 31776 solver.cpp:244]     Train net output #0: loss = 0.000105833 (* 1 = 0.000105833 loss)
I0822 12:49:10.471434 31776 sgd_solver.cpp:106] Iteration 96800, lr = 0.000266189
I0822 12:49:14.975750 31776 solver.cpp:228] Iteration 96900, loss = 7.09496e-05
I0822 12:49:14.975805 31776 solver.cpp:244]     Train net output #0: loss = 7.09496e-05 (* 1 = 7.09496e-05 loss)
I0822 12:49:14.975814 31776 sgd_solver.cpp:106] Iteration 96900, lr = 0.000266018
I0822 12:49:19.437160 31776 solver.cpp:337] Iteration 97000, Testing net (#0)
I0822 12:49:22.725234 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837209
I0822 12:49:22.725297 31776 solver.cpp:404]     Test net output #1: loss = 1.24639 (* 1 = 1.24639 loss)
I0822 12:49:22.740682 31776 solver.cpp:228] Iteration 97000, loss = 0.000109364
I0822 12:49:22.740741 31776 solver.cpp:244]     Train net output #0: loss = 0.000109364 (* 1 = 0.000109364 loss)
I0822 12:49:22.740756 31776 sgd_solver.cpp:106] Iteration 97000, lr = 0.000265848
I0822 12:49:27.245604 31776 solver.cpp:228] Iteration 97100, loss = 0.00011395
I0822 12:49:27.245666 31776 solver.cpp:244]     Train net output #0: loss = 0.00011395 (* 1 = 0.00011395 loss)
I0822 12:49:27.245676 31776 sgd_solver.cpp:106] Iteration 97100, lr = 0.000265678
I0822 12:49:31.750211 31776 solver.cpp:228] Iteration 97200, loss = 0.000151744
I0822 12:49:31.750267 31776 solver.cpp:244]     Train net output #0: loss = 0.000151744 (* 1 = 0.000151744 loss)
I0822 12:49:31.750277 31776 sgd_solver.cpp:106] Iteration 97200, lr = 0.000265508
I0822 12:49:36.253442 31776 solver.cpp:228] Iteration 97300, loss = 8.61454e-05
I0822 12:49:36.253494 31776 solver.cpp:244]     Train net output #0: loss = 8.61454e-05 (* 1 = 8.61454e-05 loss)
I0822 12:49:36.253502 31776 sgd_solver.cpp:106] Iteration 97300, lr = 0.000265338
I0822 12:49:40.760217 31776 solver.cpp:228] Iteration 97400, loss = 0.000126416
I0822 12:49:40.760275 31776 solver.cpp:244]     Train net output #0: loss = 0.000126416 (* 1 = 0.000126416 loss)
I0822 12:49:40.760284 31776 sgd_solver.cpp:106] Iteration 97400, lr = 0.000265168
I0822 12:49:45.221526 31776 solver.cpp:337] Iteration 97500, Testing net (#0)
I0822 12:49:48.499625 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83775
I0822 12:49:48.499689 31776 solver.cpp:404]     Test net output #1: loss = 1.24808 (* 1 = 1.24808 loss)
I0822 12:49:48.515015 31776 solver.cpp:228] Iteration 97500, loss = 0.000133124
I0822 12:49:48.515072 31776 solver.cpp:244]     Train net output #0: loss = 0.000133124 (* 1 = 0.000133124 loss)
I0822 12:49:48.515084 31776 sgd_solver.cpp:106] Iteration 97500, lr = 0.000264999
I0822 12:49:53.021433 31776 solver.cpp:228] Iteration 97600, loss = 6.5824e-05
I0822 12:49:53.021498 31776 solver.cpp:244]     Train net output #0: loss = 6.5824e-05 (* 1 = 6.5824e-05 loss)
I0822 12:49:53.021507 31776 sgd_solver.cpp:106] Iteration 97600, lr = 0.00026483
I0822 12:49:57.526347 31776 solver.cpp:228] Iteration 97700, loss = 0.000149414
I0822 12:49:57.526406 31776 solver.cpp:244]     Train net output #0: loss = 0.000149414 (* 1 = 0.000149414 loss)
I0822 12:49:57.526414 31776 sgd_solver.cpp:106] Iteration 97700, lr = 0.000264661
I0822 12:50:02.033211 31776 solver.cpp:228] Iteration 97800, loss = 0.000203128
I0822 12:50:02.033267 31776 solver.cpp:244]     Train net output #0: loss = 0.000203128 (* 1 = 0.000203128 loss)
I0822 12:50:02.033275 31776 sgd_solver.cpp:106] Iteration 97800, lr = 0.000264493
I0822 12:50:06.540487 31776 solver.cpp:228] Iteration 97900, loss = 0.000120873
I0822 12:50:06.540541 31776 solver.cpp:244]     Train net output #0: loss = 0.000120873 (* 1 = 0.000120873 loss)
I0822 12:50:06.540550 31776 sgd_solver.cpp:106] Iteration 97900, lr = 0.000264324
I0822 12:50:10.998580 31776 solver.cpp:337] Iteration 98000, Testing net (#0)
I0822 12:50:14.271530 31776 solver.cpp:404]     Test net output #0: accuracy = 0.83775
I0822 12:50:14.271602 31776 solver.cpp:404]     Test net output #1: loss = 1.24544 (* 1 = 1.24544 loss)
I0822 12:50:14.286873 31776 solver.cpp:228] Iteration 98000, loss = 0.000241515
I0822 12:50:14.286931 31776 solver.cpp:244]     Train net output #0: loss = 0.000241515 (* 1 = 0.000241515 loss)
I0822 12:50:14.286942 31776 sgd_solver.cpp:106] Iteration 98000, lr = 0.000264156
I0822 12:50:18.789079 31776 solver.cpp:228] Iteration 98100, loss = 8.83439e-05
I0822 12:50:18.789134 31776 solver.cpp:244]     Train net output #0: loss = 8.83439e-05 (* 1 = 8.83439e-05 loss)
I0822 12:50:18.789144 31776 sgd_solver.cpp:106] Iteration 98100, lr = 0.000263989
I0822 12:50:23.295039 31776 solver.cpp:228] Iteration 98200, loss = 9.16825e-05
I0822 12:50:23.295091 31776 solver.cpp:244]     Train net output #0: loss = 9.16825e-05 (* 1 = 9.16825e-05 loss)
I0822 12:50:23.295099 31776 sgd_solver.cpp:106] Iteration 98200, lr = 0.000263821
I0822 12:50:27.800969 31776 solver.cpp:228] Iteration 98300, loss = 0.000174756
I0822 12:50:27.801025 31776 solver.cpp:244]     Train net output #0: loss = 0.000174756 (* 1 = 0.000174756 loss)
I0822 12:50:27.801035 31776 sgd_solver.cpp:106] Iteration 98300, lr = 0.000263654
I0822 12:50:32.306356 31776 solver.cpp:228] Iteration 98400, loss = 0.000103544
I0822 12:50:32.306411 31776 solver.cpp:244]     Train net output #0: loss = 0.000103544 (* 1 = 0.000103544 loss)
I0822 12:50:32.306419 31776 sgd_solver.cpp:106] Iteration 98400, lr = 0.000263487
I0822 12:50:36.768760 31776 solver.cpp:337] Iteration 98500, Testing net (#0)
I0822 12:50:40.160635 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837917
I0822 12:50:40.160698 31776 solver.cpp:404]     Test net output #1: loss = 1.24514 (* 1 = 1.24514 loss)
I0822 12:50:40.176057 31776 solver.cpp:228] Iteration 98500, loss = 5.63162e-05
I0822 12:50:40.176113 31776 solver.cpp:244]     Train net output #0: loss = 5.63162e-05 (* 1 = 5.63162e-05 loss)
I0822 12:50:40.176126 31776 sgd_solver.cpp:106] Iteration 98500, lr = 0.00026332
I0822 12:50:44.683668 31776 solver.cpp:228] Iteration 98600, loss = 6.57363e-05
I0822 12:50:44.683734 31776 solver.cpp:244]     Train net output #0: loss = 6.57363e-05 (* 1 = 6.57363e-05 loss)
I0822 12:50:44.683743 31776 sgd_solver.cpp:106] Iteration 98600, lr = 0.000263153
I0822 12:50:49.189025 31776 solver.cpp:228] Iteration 98700, loss = 6.64892e-05
I0822 12:50:49.189080 31776 solver.cpp:244]     Train net output #0: loss = 6.64892e-05 (* 1 = 6.64892e-05 loss)
I0822 12:50:49.189091 31776 sgd_solver.cpp:106] Iteration 98700, lr = 0.000262987
I0822 12:50:53.695809 31776 solver.cpp:228] Iteration 98800, loss = 0.000127463
I0822 12:50:53.695865 31776 solver.cpp:244]     Train net output #0: loss = 0.000127463 (* 1 = 0.000127463 loss)
I0822 12:50:53.695873 31776 sgd_solver.cpp:106] Iteration 98800, lr = 0.000262821
I0822 12:50:58.201755 31776 solver.cpp:228] Iteration 98900, loss = 8.59976e-05
I0822 12:50:58.201805 31776 solver.cpp:244]     Train net output #0: loss = 8.59976e-05 (* 1 = 8.59976e-05 loss)
I0822 12:50:58.201813 31776 sgd_solver.cpp:106] Iteration 98900, lr = 0.000262655
I0822 12:51:02.662276 31776 solver.cpp:337] Iteration 99000, Testing net (#0)
I0822 12:51:05.944933 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837708
I0822 12:51:05.944986 31776 solver.cpp:404]     Test net output #1: loss = 1.24841 (* 1 = 1.24841 loss)
I0822 12:51:05.961567 31776 solver.cpp:228] Iteration 99000, loss = 0.000112033
I0822 12:51:05.961637 31776 solver.cpp:244]     Train net output #0: loss = 0.000112033 (* 1 = 0.000112033 loss)
I0822 12:51:05.961647 31776 sgd_solver.cpp:106] Iteration 99000, lr = 0.00026249
I0822 12:51:10.467954 31776 solver.cpp:228] Iteration 99100, loss = 0.000124881
I0822 12:51:10.468009 31776 solver.cpp:244]     Train net output #0: loss = 0.000124881 (* 1 = 0.000124881 loss)
I0822 12:51:10.468019 31776 sgd_solver.cpp:106] Iteration 99100, lr = 0.000262324
I0822 12:51:14.973853 31776 solver.cpp:228] Iteration 99200, loss = 3.32397e-05
I0822 12:51:14.973907 31776 solver.cpp:244]     Train net output #0: loss = 3.32397e-05 (* 1 = 3.32397e-05 loss)
I0822 12:51:14.973914 31776 sgd_solver.cpp:106] Iteration 99200, lr = 0.000262159
I0822 12:51:19.480067 31776 solver.cpp:228] Iteration 99300, loss = 0.000143091
I0822 12:51:19.480118 31776 solver.cpp:244]     Train net output #0: loss = 0.000143091 (* 1 = 0.000143091 loss)
I0822 12:51:19.480125 31776 sgd_solver.cpp:106] Iteration 99300, lr = 0.000261995
I0822 12:51:23.987305 31776 solver.cpp:228] Iteration 99400, loss = 7.04892e-05
I0822 12:51:23.987357 31776 solver.cpp:244]     Train net output #0: loss = 7.04892e-05 (* 1 = 7.04892e-05 loss)
I0822 12:51:23.987366 31776 sgd_solver.cpp:106] Iteration 99400, lr = 0.00026183
I0822 12:51:28.446738 31776 solver.cpp:337] Iteration 99500, Testing net (#0)
I0822 12:51:28.524463 31776 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 12:51:31.720188 31776 solver.cpp:404]     Test net output #0: accuracy = 0.837709
I0822 12:51:31.720245 31776 solver.cpp:404]     Test net output #1: loss = 1.24693 (* 1 = 1.24693 loss)
I0822 12:51:31.735551 31776 solver.cpp:228] Iteration 99500, loss = 4.41566e-05
I0822 12:51:31.735618 31776 solver.cpp:244]     Train net output #0: loss = 4.41566e-05 (* 1 = 4.41566e-05 loss)
I0822 12:51:31.735631 31776 sgd_solver.cpp:106] Iteration 99500, lr = 0.000261666
I0822 12:51:36.238281 31776 solver.cpp:228] Iteration 99600, loss = 0.000131662
I0822 12:51:36.238337 31776 solver.cpp:244]     Train net output #0: loss = 0.000131662 (* 1 = 0.000131662 loss)
I0822 12:51:36.238345 31776 sgd_solver.cpp:106] Iteration 99600, lr = 0.000261501
I0822 12:51:40.746409 31776 solver.cpp:228] Iteration 99700, loss = 8.23229e-05
I0822 12:51:40.746464 31776 solver.cpp:244]     Train net output #0: loss = 8.23229e-05 (* 1 = 8.23229e-05 loss)
I0822 12:51:40.746471 31776 sgd_solver.cpp:106] Iteration 99700, lr = 0.000261338
I0822 12:51:45.252507 31776 solver.cpp:228] Iteration 99800, loss = 0.00015374
I0822 12:51:45.252578 31776 solver.cpp:244]     Train net output #0: loss = 0.00015374 (* 1 = 0.00015374 loss)
I0822 12:51:45.252588 31776 sgd_solver.cpp:106] Iteration 99800, lr = 0.000261174
I0822 12:51:49.758462 31776 solver.cpp:228] Iteration 99900, loss = 4.60301e-05
I0822 12:51:49.758520 31776 solver.cpp:244]     Train net output #0: loss = 4.60301e-05 (* 1 = 4.60301e-05 loss)
I0822 12:51:49.758528 31776 sgd_solver.cpp:106] Iteration 99900, lr = 0.000261011
I0822 12:51:54.221220 31776 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_100000.caffemodel
I0822 12:51:54.694633 31776 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_alex_net/person_vs_background_vs_random_alex_net_newserver_lr_0.0006_iter_100000.solverstate
I0822 12:51:54.851099 31776 solver.cpp:337] Iteration 100000, Testing net (#0)
I0822 12:51:58.077446 31776 solver.cpp:404]     Test net output #0: accuracy = 0.838042
I0822 12:51:58.077505 31776 solver.cpp:404]     Test net output #1: loss = 1.24292 (* 1 = 1.24292 loss)
I0822 12:51:58.093055 31776 solver.cpp:228] Iteration 100000, loss = 0.000103103
I0822 12:51:58.093113 31776 solver.cpp:244]     Train net output #0: loss = 0.000103103 (* 1 = 0.000103103 loss)
I0822 12:51:58.093125 31776 sgd_solver.cpp:106] Iteration 100000, lr = 0.000260847
nets/person_vs_background_vs_random_alex_net/solver.prototxt
