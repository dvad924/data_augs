WARNING: Logging before InitGoogleLogging() is written to STDERR
I1013 17:43:31.465804 15780 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 100000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 20000
snapshot_prefix: "models/21class_pascal_plus_pre_trained_alex_net/21class_pascal_plus_pre_trained_alex_net_lr_0.001"
solver_mode: GPU
net: "nets/21class_pascal_plus_pre_trained_alex_net/trainval.prototxt"
I1013 17:43:31.465957 15780 solver.cpp:91] Creating training net from net file: nets/21class_pascal_plus_pre_trained_alex_net/trainval.prototxt
I1013 17:43:31.466624 15780 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1013 17:43:31.466651 15780 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1013 17:43:31.466811 15780 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/21class_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/pascal_plus_21cls_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6new"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1013 17:43:31.466913 15780 layer_factory.hpp:77] Creating layer mnist
I1013 17:43:31.467540 15780 net.cpp:100] Creating Layer mnist
I1013 17:43:31.467556 15780 net.cpp:408] mnist -> data
I1013 17:43:31.467577 15780 net.cpp:408] mnist -> label
I1013 17:43:31.467720 15780 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/21class_mean.binaryproto
I1013 17:43:31.469553 15826 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/pascal_plus_21cls_train_lmdb
I1013 17:43:31.489712 15780 data_layer.cpp:41] output data size: 128,3,128,128
I1013 17:43:31.537066 15780 net.cpp:150] Setting up mnist
I1013 17:43:31.537112 15780 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I1013 17:43:31.537118 15780 net.cpp:157] Top shape: 128 (128)
I1013 17:43:31.537122 15780 net.cpp:165] Memory required for data: 25166336
I1013 17:43:31.537128 15780 layer_factory.hpp:77] Creating layer conv1
I1013 17:43:31.537152 15780 net.cpp:100] Creating Layer conv1
I1013 17:43:31.537170 15780 net.cpp:434] conv1 <- data
I1013 17:43:31.537194 15780 net.cpp:408] conv1 -> conv1
I1013 17:43:31.845433 15780 net.cpp:150] Setting up conv1
I1013 17:43:31.845473 15780 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I1013 17:43:31.845477 15780 net.cpp:165] Memory required for data: 69403136
I1013 17:43:31.845504 15780 layer_factory.hpp:77] Creating layer relu1
I1013 17:43:31.845520 15780 net.cpp:100] Creating Layer relu1
I1013 17:43:31.845525 15780 net.cpp:434] relu1 <- conv1
I1013 17:43:31.845532 15780 net.cpp:395] relu1 -> conv1 (in-place)
I1013 17:43:31.845727 15780 net.cpp:150] Setting up relu1
I1013 17:43:31.845739 15780 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I1013 17:43:31.845742 15780 net.cpp:165] Memory required for data: 113639936
I1013 17:43:31.845747 15780 layer_factory.hpp:77] Creating layer norm1
I1013 17:43:31.845758 15780 net.cpp:100] Creating Layer norm1
I1013 17:43:31.845762 15780 net.cpp:434] norm1 <- conv1
I1013 17:43:31.845767 15780 net.cpp:408] norm1 -> norm1
I1013 17:43:31.846493 15780 net.cpp:150] Setting up norm1
I1013 17:43:31.846509 15780 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I1013 17:43:31.846513 15780 net.cpp:165] Memory required for data: 157876736
I1013 17:43:31.846518 15780 layer_factory.hpp:77] Creating layer pool1
I1013 17:43:31.846530 15780 net.cpp:100] Creating Layer pool1
I1013 17:43:31.846535 15780 net.cpp:434] pool1 <- norm1
I1013 17:43:31.846541 15780 net.cpp:408] pool1 -> pool1
I1013 17:43:31.846606 15780 net.cpp:150] Setting up pool1
I1013 17:43:31.846616 15780 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I1013 17:43:31.846621 15780 net.cpp:165] Memory required for data: 168935936
I1013 17:43:31.846624 15780 layer_factory.hpp:77] Creating layer conv2
I1013 17:43:31.846637 15780 net.cpp:100] Creating Layer conv2
I1013 17:43:31.846645 15780 net.cpp:434] conv2 <- pool1
I1013 17:43:31.846652 15780 net.cpp:408] conv2 -> conv2
I1013 17:43:31.861186 15780 net.cpp:150] Setting up conv2
I1013 17:43:31.861204 15780 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I1013 17:43:31.861209 15780 net.cpp:165] Memory required for data: 198427136
I1013 17:43:31.861219 15780 layer_factory.hpp:77] Creating layer relu2
I1013 17:43:31.861227 15780 net.cpp:100] Creating Layer relu2
I1013 17:43:31.861232 15780 net.cpp:434] relu2 <- conv2
I1013 17:43:31.861238 15780 net.cpp:395] relu2 -> conv2 (in-place)
I1013 17:43:31.861897 15780 net.cpp:150] Setting up relu2
I1013 17:43:31.861914 15780 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I1013 17:43:31.861918 15780 net.cpp:165] Memory required for data: 227918336
I1013 17:43:31.861923 15780 layer_factory.hpp:77] Creating layer norm2
I1013 17:43:31.861930 15780 net.cpp:100] Creating Layer norm2
I1013 17:43:31.861934 15780 net.cpp:434] norm2 <- conv2
I1013 17:43:31.861941 15780 net.cpp:408] norm2 -> norm2
I1013 17:43:31.862182 15780 net.cpp:150] Setting up norm2
I1013 17:43:31.862197 15780 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I1013 17:43:31.862201 15780 net.cpp:165] Memory required for data: 257409536
I1013 17:43:31.862205 15780 layer_factory.hpp:77] Creating layer pool2
I1013 17:43:31.862215 15780 net.cpp:100] Creating Layer pool2
I1013 17:43:31.862218 15780 net.cpp:434] pool2 <- norm2
I1013 17:43:31.862224 15780 net.cpp:408] pool2 -> pool2
I1013 17:43:31.862282 15780 net.cpp:150] Setting up pool2
I1013 17:43:31.862290 15780 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I1013 17:43:31.862294 15780 net.cpp:165] Memory required for data: 263832064
I1013 17:43:31.862298 15780 layer_factory.hpp:77] Creating layer conv3
I1013 17:43:31.862308 15780 net.cpp:100] Creating Layer conv3
I1013 17:43:31.862311 15780 net.cpp:434] conv3 <- pool2
I1013 17:43:31.862318 15780 net.cpp:408] conv3 -> conv3
I1013 17:43:31.898473 15780 net.cpp:150] Setting up conv3
I1013 17:43:31.898491 15780 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I1013 17:43:31.898495 15780 net.cpp:165] Memory required for data: 273465856
I1013 17:43:31.898509 15780 layer_factory.hpp:77] Creating layer relu3
I1013 17:43:31.898516 15780 net.cpp:100] Creating Layer relu3
I1013 17:43:31.898521 15780 net.cpp:434] relu3 <- conv3
I1013 17:43:31.898527 15780 net.cpp:395] relu3 -> conv3 (in-place)
I1013 17:43:31.898736 15780 net.cpp:150] Setting up relu3
I1013 17:43:31.898749 15780 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I1013 17:43:31.898753 15780 net.cpp:165] Memory required for data: 283099648
I1013 17:43:31.898757 15780 layer_factory.hpp:77] Creating layer conv4
I1013 17:43:31.898769 15780 net.cpp:100] Creating Layer conv4
I1013 17:43:31.898773 15780 net.cpp:434] conv4 <- conv3
I1013 17:43:31.898779 15780 net.cpp:408] conv4 -> conv4
I1013 17:43:31.927633 15780 net.cpp:150] Setting up conv4
I1013 17:43:31.927650 15780 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I1013 17:43:31.927655 15780 net.cpp:165] Memory required for data: 292733440
I1013 17:43:31.927664 15780 layer_factory.hpp:77] Creating layer relu4
I1013 17:43:31.927670 15780 net.cpp:100] Creating Layer relu4
I1013 17:43:31.927675 15780 net.cpp:434] relu4 <- conv4
I1013 17:43:31.927683 15780 net.cpp:395] relu4 -> conv4 (in-place)
I1013 17:43:31.927891 15780 net.cpp:150] Setting up relu4
I1013 17:43:31.927902 15780 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I1013 17:43:31.927906 15780 net.cpp:165] Memory required for data: 302367232
I1013 17:43:31.927911 15780 layer_factory.hpp:77] Creating layer conv5
I1013 17:43:31.927924 15780 net.cpp:100] Creating Layer conv5
I1013 17:43:31.927928 15780 net.cpp:434] conv5 <- conv4
I1013 17:43:31.927935 15780 net.cpp:408] conv5 -> conv5
I1013 17:43:31.948562 15780 net.cpp:150] Setting up conv5
I1013 17:43:31.948585 15780 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I1013 17:43:31.948588 15780 net.cpp:165] Memory required for data: 308789760
I1013 17:43:31.948601 15780 layer_factory.hpp:77] Creating layer relu5
I1013 17:43:31.948607 15780 net.cpp:100] Creating Layer relu5
I1013 17:43:31.948612 15780 net.cpp:434] relu5 <- conv5
I1013 17:43:31.948617 15780 net.cpp:395] relu5 -> conv5 (in-place)
I1013 17:43:31.948827 15780 net.cpp:150] Setting up relu5
I1013 17:43:31.948840 15780 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I1013 17:43:31.948843 15780 net.cpp:165] Memory required for data: 315212288
I1013 17:43:31.948848 15780 layer_factory.hpp:77] Creating layer pool5
I1013 17:43:31.948854 15780 net.cpp:100] Creating Layer pool5
I1013 17:43:31.948858 15780 net.cpp:434] pool5 <- conv5
I1013 17:43:31.948866 15780 net.cpp:408] pool5 -> pool5
I1013 17:43:31.948950 15780 net.cpp:150] Setting up pool5
I1013 17:43:31.948958 15780 net.cpp:157] Top shape: 128 256 3 3 (294912)
I1013 17:43:31.948962 15780 net.cpp:165] Memory required for data: 316391936
I1013 17:43:31.948966 15780 layer_factory.hpp:77] Creating layer fc6new
I1013 17:43:31.948982 15780 net.cpp:100] Creating Layer fc6new
I1013 17:43:31.948985 15780 net.cpp:434] fc6new <- pool5
I1013 17:43:31.948992 15780 net.cpp:408] fc6new -> fc6
I1013 17:43:32.264453 15780 net.cpp:150] Setting up fc6new
I1013 17:43:32.264488 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.264492 15780 net.cpp:165] Memory required for data: 318489088
I1013 17:43:32.264503 15780 layer_factory.hpp:77] Creating layer relu6
I1013 17:43:32.264520 15780 net.cpp:100] Creating Layer relu6
I1013 17:43:32.264525 15780 net.cpp:434] relu6 <- fc6
I1013 17:43:32.264533 15780 net.cpp:395] relu6 -> fc6 (in-place)
I1013 17:43:32.265269 15780 net.cpp:150] Setting up relu6
I1013 17:43:32.265283 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.265286 15780 net.cpp:165] Memory required for data: 320586240
I1013 17:43:32.265290 15780 layer_factory.hpp:77] Creating layer drop6
I1013 17:43:32.265302 15780 net.cpp:100] Creating Layer drop6
I1013 17:43:32.265305 15780 net.cpp:434] drop6 <- fc6
I1013 17:43:32.265311 15780 net.cpp:395] drop6 -> fc6 (in-place)
I1013 17:43:32.265354 15780 net.cpp:150] Setting up drop6
I1013 17:43:32.265360 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.265363 15780 net.cpp:165] Memory required for data: 322683392
I1013 17:43:32.265365 15780 layer_factory.hpp:77] Creating layer fc7new
I1013 17:43:32.265377 15780 net.cpp:100] Creating Layer fc7new
I1013 17:43:32.265379 15780 net.cpp:434] fc7new <- fc6
I1013 17:43:32.265384 15780 net.cpp:408] fc7new -> fc7
I1013 17:43:32.738272 15780 net.cpp:150] Setting up fc7new
I1013 17:43:32.738312 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.738317 15780 net.cpp:165] Memory required for data: 324780544
I1013 17:43:32.738328 15780 layer_factory.hpp:77] Creating layer relu7
I1013 17:43:32.738340 15780 net.cpp:100] Creating Layer relu7
I1013 17:43:32.738345 15780 net.cpp:434] relu7 <- fc7
I1013 17:43:32.738353 15780 net.cpp:395] relu7 -> fc7 (in-place)
I1013 17:43:32.738622 15780 net.cpp:150] Setting up relu7
I1013 17:43:32.738632 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.738636 15780 net.cpp:165] Memory required for data: 326877696
I1013 17:43:32.738638 15780 layer_factory.hpp:77] Creating layer drop7
I1013 17:43:32.738646 15780 net.cpp:100] Creating Layer drop7
I1013 17:43:32.738648 15780 net.cpp:434] drop7 <- fc7
I1013 17:43:32.738654 15780 net.cpp:395] drop7 -> fc7 (in-place)
I1013 17:43:32.738685 15780 net.cpp:150] Setting up drop7
I1013 17:43:32.738690 15780 net.cpp:157] Top shape: 128 4096 (524288)
I1013 17:43:32.738693 15780 net.cpp:165] Memory required for data: 328974848
I1013 17:43:32.738695 15780 layer_factory.hpp:77] Creating layer fc8new
I1013 17:43:32.738704 15780 net.cpp:100] Creating Layer fc8new
I1013 17:43:32.738706 15780 net.cpp:434] fc8new <- fc7
I1013 17:43:32.738713 15780 net.cpp:408] fc8new -> fc8
I1013 17:43:32.741291 15780 net.cpp:150] Setting up fc8new
I1013 17:43:32.741299 15780 net.cpp:157] Top shape: 128 21 (2688)
I1013 17:43:32.741313 15780 net.cpp:165] Memory required for data: 328985600
I1013 17:43:32.741318 15780 layer_factory.hpp:77] Creating layer loss
I1013 17:43:32.741346 15780 net.cpp:100] Creating Layer loss
I1013 17:43:32.741349 15780 net.cpp:434] loss <- fc8
I1013 17:43:32.741353 15780 net.cpp:434] loss <- label
I1013 17:43:32.741358 15780 net.cpp:408] loss -> loss
I1013 17:43:32.741381 15780 layer_factory.hpp:77] Creating layer loss
I1013 17:43:32.741698 15780 net.cpp:150] Setting up loss
I1013 17:43:32.741708 15780 net.cpp:157] Top shape: (1)
I1013 17:43:32.741710 15780 net.cpp:160]     with loss weight 1
I1013 17:43:32.741726 15780 net.cpp:165] Memory required for data: 328985604
I1013 17:43:32.741729 15780 net.cpp:226] loss needs backward computation.
I1013 17:43:32.741734 15780 net.cpp:226] fc8new needs backward computation.
I1013 17:43:32.741736 15780 net.cpp:226] drop7 needs backward computation.
I1013 17:43:32.741739 15780 net.cpp:226] relu7 needs backward computation.
I1013 17:43:32.741742 15780 net.cpp:226] fc7new needs backward computation.
I1013 17:43:32.741745 15780 net.cpp:226] drop6 needs backward computation.
I1013 17:43:32.741747 15780 net.cpp:226] relu6 needs backward computation.
I1013 17:43:32.741750 15780 net.cpp:226] fc6new needs backward computation.
I1013 17:43:32.741755 15780 net.cpp:226] pool5 needs backward computation.
I1013 17:43:32.741757 15780 net.cpp:226] relu5 needs backward computation.
I1013 17:43:32.741760 15780 net.cpp:226] conv5 needs backward computation.
I1013 17:43:32.741763 15780 net.cpp:226] relu4 needs backward computation.
I1013 17:43:32.741766 15780 net.cpp:226] conv4 needs backward computation.
I1013 17:43:32.741770 15780 net.cpp:226] relu3 needs backward computation.
I1013 17:43:32.741772 15780 net.cpp:226] conv3 needs backward computation.
I1013 17:43:32.741775 15780 net.cpp:226] pool2 needs backward computation.
I1013 17:43:32.741778 15780 net.cpp:226] norm2 needs backward computation.
I1013 17:43:32.741781 15780 net.cpp:226] relu2 needs backward computation.
I1013 17:43:32.741785 15780 net.cpp:226] conv2 needs backward computation.
I1013 17:43:32.741787 15780 net.cpp:226] pool1 needs backward computation.
I1013 17:43:32.741791 15780 net.cpp:226] norm1 needs backward computation.
I1013 17:43:32.741793 15780 net.cpp:226] relu1 needs backward computation.
I1013 17:43:32.741796 15780 net.cpp:226] conv1 needs backward computation.
I1013 17:43:32.741799 15780 net.cpp:228] mnist does not need backward computation.
I1013 17:43:32.741802 15780 net.cpp:270] This network produces output loss
I1013 17:43:32.741816 15780 net.cpp:283] Network initialization done.
I1013 17:43:32.742424 15780 solver.cpp:181] Creating test net (#0) specified by net file: nets/21class_pascal_plus_pre_trained_alex_net/trainval.prototxt
I1013 17:43:32.742483 15780 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1013 17:43:32.742653 15780 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/21class_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/pascal_plus_21cls_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6new"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7new"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8new"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1013 17:43:32.742768 15780 layer_factory.hpp:77] Creating layer mnist
I1013 17:43:32.742887 15780 net.cpp:100] Creating Layer mnist
I1013 17:43:32.742897 15780 net.cpp:408] mnist -> data
I1013 17:43:32.742903 15780 net.cpp:408] mnist -> label
I1013 17:43:32.742910 15780 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/21class_mean.binaryproto
I1013 17:43:32.744875 15828 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/pascal_plus_21cls_test_lmdb
I1013 17:43:32.745188 15780 data_layer.cpp:41] output data size: 100,3,128,128
I1013 17:43:32.789824 15780 net.cpp:150] Setting up mnist
I1013 17:43:32.789860 15780 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I1013 17:43:32.789867 15780 net.cpp:157] Top shape: 100 (100)
I1013 17:43:32.789871 15780 net.cpp:165] Memory required for data: 19661200
I1013 17:43:32.789880 15780 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1013 17:43:32.789903 15780 net.cpp:100] Creating Layer label_mnist_1_split
I1013 17:43:32.789908 15780 net.cpp:434] label_mnist_1_split <- label
I1013 17:43:32.789916 15780 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I1013 17:43:32.789929 15780 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I1013 17:43:32.790125 15780 net.cpp:150] Setting up label_mnist_1_split
I1013 17:43:32.790138 15780 net.cpp:157] Top shape: 100 (100)
I1013 17:43:32.790143 15780 net.cpp:157] Top shape: 100 (100)
I1013 17:43:32.790146 15780 net.cpp:165] Memory required for data: 19662000
I1013 17:43:32.790150 15780 layer_factory.hpp:77] Creating layer conv1
I1013 17:43:32.790168 15780 net.cpp:100] Creating Layer conv1
I1013 17:43:32.790171 15780 net.cpp:434] conv1 <- data
I1013 17:43:32.790179 15780 net.cpp:408] conv1 -> conv1
I1013 17:43:32.796293 15780 net.cpp:150] Setting up conv1
I1013 17:43:32.796310 15780 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1013 17:43:32.796315 15780 net.cpp:165] Memory required for data: 54222000
I1013 17:43:32.796329 15780 layer_factory.hpp:77] Creating layer relu1
I1013 17:43:32.796337 15780 net.cpp:100] Creating Layer relu1
I1013 17:43:32.796341 15780 net.cpp:434] relu1 <- conv1
I1013 17:43:32.796347 15780 net.cpp:395] relu1 -> conv1 (in-place)
I1013 17:43:32.796535 15780 net.cpp:150] Setting up relu1
I1013 17:43:32.796547 15780 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1013 17:43:32.796550 15780 net.cpp:165] Memory required for data: 88782000
I1013 17:43:32.796555 15780 layer_factory.hpp:77] Creating layer norm1
I1013 17:43:32.796564 15780 net.cpp:100] Creating Layer norm1
I1013 17:43:32.796568 15780 net.cpp:434] norm1 <- conv1
I1013 17:43:32.796574 15780 net.cpp:408] norm1 -> norm1
I1013 17:43:32.797323 15780 net.cpp:150] Setting up norm1
I1013 17:43:32.797340 15780 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1013 17:43:32.797344 15780 net.cpp:165] Memory required for data: 123342000
I1013 17:43:32.797348 15780 layer_factory.hpp:77] Creating layer pool1
I1013 17:43:32.797360 15780 net.cpp:100] Creating Layer pool1
I1013 17:43:32.797365 15780 net.cpp:434] pool1 <- norm1
I1013 17:43:32.797371 15780 net.cpp:408] pool1 -> pool1
I1013 17:43:32.797436 15780 net.cpp:150] Setting up pool1
I1013 17:43:32.797443 15780 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I1013 17:43:32.797446 15780 net.cpp:165] Memory required for data: 131982000
I1013 17:43:32.797449 15780 layer_factory.hpp:77] Creating layer conv2
I1013 17:43:32.797461 15780 net.cpp:100] Creating Layer conv2
I1013 17:43:32.797464 15780 net.cpp:434] conv2 <- pool1
I1013 17:43:32.797471 15780 net.cpp:408] conv2 -> conv2
I1013 17:43:32.815119 15780 net.cpp:150] Setting up conv2
I1013 17:43:32.815138 15780 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I1013 17:43:32.815143 15780 net.cpp:165] Memory required for data: 155022000
I1013 17:43:32.815153 15780 layer_factory.hpp:77] Creating layer relu2
I1013 17:43:32.815161 15780 net.cpp:100] Creating Layer relu2
I1013 17:43:32.815165 15780 net.cpp:434] relu2 <- conv2
I1013 17:43:32.815171 15780 net.cpp:395] relu2 -> conv2 (in-place)
I1013 17:43:32.815883 15780 net.cpp:150] Setting up relu2
I1013 17:43:32.815899 15780 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I1013 17:43:32.815903 15780 net.cpp:165] Memory required for data: 178062000
I1013 17:43:32.815907 15780 layer_factory.hpp:77] Creating layer norm2
I1013 17:43:32.815918 15780 net.cpp:100] Creating Layer norm2
I1013 17:43:32.815922 15780 net.cpp:434] norm2 <- conv2
I1013 17:43:32.815928 15780 net.cpp:408] norm2 -> norm2
I1013 17:43:32.816190 15780 net.cpp:150] Setting up norm2
I1013 17:43:32.816202 15780 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I1013 17:43:32.816206 15780 net.cpp:165] Memory required for data: 201102000
I1013 17:43:32.816210 15780 layer_factory.hpp:77] Creating layer pool2
I1013 17:43:32.816217 15780 net.cpp:100] Creating Layer pool2
I1013 17:43:32.816226 15780 net.cpp:434] pool2 <- norm2
I1013 17:43:32.816242 15780 net.cpp:408] pool2 -> pool2
I1013 17:43:32.816308 15780 net.cpp:150] Setting up pool2
I1013 17:43:32.816316 15780 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I1013 17:43:32.816319 15780 net.cpp:165] Memory required for data: 206119600
I1013 17:43:32.816323 15780 layer_factory.hpp:77] Creating layer conv3
I1013 17:43:32.816335 15780 net.cpp:100] Creating Layer conv3
I1013 17:43:32.816339 15780 net.cpp:434] conv3 <- pool2
I1013 17:43:32.816345 15780 net.cpp:408] conv3 -> conv3
I1013 17:43:32.852234 15780 net.cpp:150] Setting up conv3
I1013 17:43:32.852252 15780 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I1013 17:43:32.852257 15780 net.cpp:165] Memory required for data: 213646000
I1013 17:43:32.852270 15780 layer_factory.hpp:77] Creating layer relu3
I1013 17:43:32.852278 15780 net.cpp:100] Creating Layer relu3
I1013 17:43:32.852283 15780 net.cpp:434] relu3 <- conv3
I1013 17:43:32.852288 15780 net.cpp:395] relu3 -> conv3 (in-place)
I1013 17:43:32.852510 15780 net.cpp:150] Setting up relu3
I1013 17:43:32.852524 15780 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I1013 17:43:32.852529 15780 net.cpp:165] Memory required for data: 221172400
I1013 17:43:32.852532 15780 layer_factory.hpp:77] Creating layer conv4
I1013 17:43:32.852543 15780 net.cpp:100] Creating Layer conv4
I1013 17:43:32.852548 15780 net.cpp:434] conv4 <- conv3
I1013 17:43:32.852555 15780 net.cpp:408] conv4 -> conv4
I1013 17:43:32.881518 15780 net.cpp:150] Setting up conv4
I1013 17:43:32.881536 15780 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I1013 17:43:32.881541 15780 net.cpp:165] Memory required for data: 228698800
I1013 17:43:32.881548 15780 layer_factory.hpp:77] Creating layer relu4
I1013 17:43:32.881556 15780 net.cpp:100] Creating Layer relu4
I1013 17:43:32.881561 15780 net.cpp:434] relu4 <- conv4
I1013 17:43:32.881568 15780 net.cpp:395] relu4 -> conv4 (in-place)
I1013 17:43:32.883718 15780 net.cpp:150] Setting up relu4
I1013 17:43:32.883733 15780 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I1013 17:43:32.883739 15780 net.cpp:165] Memory required for data: 236225200
I1013 17:43:32.883744 15780 layer_factory.hpp:77] Creating layer conv5
I1013 17:43:32.883754 15780 net.cpp:100] Creating Layer conv5
I1013 17:43:32.883760 15780 net.cpp:434] conv5 <- conv4
I1013 17:43:32.883769 15780 net.cpp:408] conv5 -> conv5
I1013 17:43:32.904357 15780 net.cpp:150] Setting up conv5
I1013 17:43:32.904376 15780 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I1013 17:43:32.904379 15780 net.cpp:165] Memory required for data: 241242800
I1013 17:43:32.904392 15780 layer_factory.hpp:77] Creating layer relu5
I1013 17:43:32.904400 15780 net.cpp:100] Creating Layer relu5
I1013 17:43:32.904404 15780 net.cpp:434] relu5 <- conv5
I1013 17:43:32.904412 15780 net.cpp:395] relu5 -> conv5 (in-place)
I1013 17:43:32.904623 15780 net.cpp:150] Setting up relu5
I1013 17:43:32.904635 15780 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I1013 17:43:32.904639 15780 net.cpp:165] Memory required for data: 246260400
I1013 17:43:32.904644 15780 layer_factory.hpp:77] Creating layer pool5
I1013 17:43:32.904654 15780 net.cpp:100] Creating Layer pool5
I1013 17:43:32.904657 15780 net.cpp:434] pool5 <- conv5
I1013 17:43:32.904664 15780 net.cpp:408] pool5 -> pool5
I1013 17:43:32.904742 15780 net.cpp:150] Setting up pool5
I1013 17:43:32.904752 15780 net.cpp:157] Top shape: 100 256 3 3 (230400)
I1013 17:43:32.904754 15780 net.cpp:165] Memory required for data: 247182000
I1013 17:43:32.904757 15780 layer_factory.hpp:77] Creating layer fc6new
I1013 17:43:32.904769 15780 net.cpp:100] Creating Layer fc6new
I1013 17:43:32.904773 15780 net.cpp:434] fc6new <- pool5
I1013 17:43:32.904778 15780 net.cpp:408] fc6new -> fc6
I1013 17:43:33.200467 15780 net.cpp:150] Setting up fc6new
I1013 17:43:33.200506 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.200510 15780 net.cpp:165] Memory required for data: 248820400
I1013 17:43:33.200520 15780 layer_factory.hpp:77] Creating layer relu6
I1013 17:43:33.200532 15780 net.cpp:100] Creating Layer relu6
I1013 17:43:33.200537 15780 net.cpp:434] relu6 <- fc6
I1013 17:43:33.200543 15780 net.cpp:395] relu6 -> fc6 (in-place)
I1013 17:43:33.200817 15780 net.cpp:150] Setting up relu6
I1013 17:43:33.200827 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.200830 15780 net.cpp:165] Memory required for data: 250458800
I1013 17:43:33.200834 15780 layer_factory.hpp:77] Creating layer drop6
I1013 17:43:33.200841 15780 net.cpp:100] Creating Layer drop6
I1013 17:43:33.200845 15780 net.cpp:434] drop6 <- fc6
I1013 17:43:33.200850 15780 net.cpp:395] drop6 -> fc6 (in-place)
I1013 17:43:33.200896 15780 net.cpp:150] Setting up drop6
I1013 17:43:33.200902 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.200906 15780 net.cpp:165] Memory required for data: 252097200
I1013 17:43:33.200908 15780 layer_factory.hpp:77] Creating layer fc7new
I1013 17:43:33.200917 15780 net.cpp:100] Creating Layer fc7new
I1013 17:43:33.200918 15780 net.cpp:434] fc7new <- fc6
I1013 17:43:33.200925 15780 net.cpp:408] fc7new -> fc7
I1013 17:43:33.674336 15780 net.cpp:150] Setting up fc7new
I1013 17:43:33.674372 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.674376 15780 net.cpp:165] Memory required for data: 253735600
I1013 17:43:33.674386 15780 layer_factory.hpp:77] Creating layer relu7
I1013 17:43:33.674396 15780 net.cpp:100] Creating Layer relu7
I1013 17:43:33.674401 15780 net.cpp:434] relu7 <- fc7
I1013 17:43:33.674409 15780 net.cpp:395] relu7 -> fc7 (in-place)
I1013 17:43:33.675253 15780 net.cpp:150] Setting up relu7
I1013 17:43:33.675266 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.675269 15780 net.cpp:165] Memory required for data: 255374000
I1013 17:43:33.675272 15780 layer_factory.hpp:77] Creating layer drop7
I1013 17:43:33.675279 15780 net.cpp:100] Creating Layer drop7
I1013 17:43:33.675284 15780 net.cpp:434] drop7 <- fc7
I1013 17:43:33.675288 15780 net.cpp:395] drop7 -> fc7 (in-place)
I1013 17:43:33.675343 15780 net.cpp:150] Setting up drop7
I1013 17:43:33.675349 15780 net.cpp:157] Top shape: 100 4096 (409600)
I1013 17:43:33.675353 15780 net.cpp:165] Memory required for data: 257012400
I1013 17:43:33.675354 15780 layer_factory.hpp:77] Creating layer fc8new
I1013 17:43:33.675364 15780 net.cpp:100] Creating Layer fc8new
I1013 17:43:33.675367 15780 net.cpp:434] fc8new <- fc7
I1013 17:43:33.675371 15780 net.cpp:408] fc8new -> fc8
I1013 17:43:33.677981 15780 net.cpp:150] Setting up fc8new
I1013 17:43:33.677990 15780 net.cpp:157] Top shape: 100 21 (2100)
I1013 17:43:33.677994 15780 net.cpp:165] Memory required for data: 257020800
I1013 17:43:33.677999 15780 layer_factory.hpp:77] Creating layer fc8_fc8new_0_split
I1013 17:43:33.678030 15780 net.cpp:100] Creating Layer fc8_fc8new_0_split
I1013 17:43:33.678035 15780 net.cpp:434] fc8_fc8new_0_split <- fc8
I1013 17:43:33.678050 15780 net.cpp:408] fc8_fc8new_0_split -> fc8_fc8new_0_split_0
I1013 17:43:33.678056 15780 net.cpp:408] fc8_fc8new_0_split -> fc8_fc8new_0_split_1
I1013 17:43:33.678123 15780 net.cpp:150] Setting up fc8_fc8new_0_split
I1013 17:43:33.678129 15780 net.cpp:157] Top shape: 100 21 (2100)
I1013 17:43:33.678133 15780 net.cpp:157] Top shape: 100 21 (2100)
I1013 17:43:33.678135 15780 net.cpp:165] Memory required for data: 257037600
I1013 17:43:33.678138 15780 layer_factory.hpp:77] Creating layer accuracy
I1013 17:43:33.678158 15780 net.cpp:100] Creating Layer accuracy
I1013 17:43:33.678172 15780 net.cpp:434] accuracy <- fc8_fc8new_0_split_0
I1013 17:43:33.678177 15780 net.cpp:434] accuracy <- label_mnist_1_split_0
I1013 17:43:33.678181 15780 net.cpp:408] accuracy -> accuracy
I1013 17:43:33.678191 15780 net.cpp:150] Setting up accuracy
I1013 17:43:33.678196 15780 net.cpp:157] Top shape: (1)
I1013 17:43:33.678200 15780 net.cpp:165] Memory required for data: 257037604
I1013 17:43:33.678202 15780 layer_factory.hpp:77] Creating layer loss
I1013 17:43:33.678210 15780 net.cpp:100] Creating Layer loss
I1013 17:43:33.678213 15780 net.cpp:434] loss <- fc8_fc8new_0_split_1
I1013 17:43:33.678217 15780 net.cpp:434] loss <- label_mnist_1_split_1
I1013 17:43:33.678221 15780 net.cpp:408] loss -> loss
I1013 17:43:33.678236 15780 layer_factory.hpp:77] Creating layer loss
I1013 17:43:33.678597 15780 net.cpp:150] Setting up loss
I1013 17:43:33.678608 15780 net.cpp:157] Top shape: (1)
I1013 17:43:33.678622 15780 net.cpp:160]     with loss weight 1
I1013 17:43:33.678632 15780 net.cpp:165] Memory required for data: 257037608
I1013 17:43:33.678637 15780 net.cpp:226] loss needs backward computation.
I1013 17:43:33.678640 15780 net.cpp:228] accuracy does not need backward computation.
I1013 17:43:33.678643 15780 net.cpp:226] fc8_fc8new_0_split needs backward computation.
I1013 17:43:33.678647 15780 net.cpp:226] fc8new needs backward computation.
I1013 17:43:33.678653 15780 net.cpp:226] drop7 needs backward computation.
I1013 17:43:33.678655 15780 net.cpp:226] relu7 needs backward computation.
I1013 17:43:33.678658 15780 net.cpp:226] fc7new needs backward computation.
I1013 17:43:33.678661 15780 net.cpp:226] drop6 needs backward computation.
I1013 17:43:33.678663 15780 net.cpp:226] relu6 needs backward computation.
I1013 17:43:33.678666 15780 net.cpp:226] fc6new needs backward computation.
I1013 17:43:33.678669 15780 net.cpp:226] pool5 needs backward computation.
I1013 17:43:33.678673 15780 net.cpp:226] relu5 needs backward computation.
I1013 17:43:33.678675 15780 net.cpp:226] conv5 needs backward computation.
I1013 17:43:33.678678 15780 net.cpp:226] relu4 needs backward computation.
I1013 17:43:33.678681 15780 net.cpp:226] conv4 needs backward computation.
I1013 17:43:33.678684 15780 net.cpp:226] relu3 needs backward computation.
I1013 17:43:33.678688 15780 net.cpp:226] conv3 needs backward computation.
I1013 17:43:33.678690 15780 net.cpp:226] pool2 needs backward computation.
I1013 17:43:33.678694 15780 net.cpp:226] norm2 needs backward computation.
I1013 17:43:33.678696 15780 net.cpp:226] relu2 needs backward computation.
I1013 17:43:33.678699 15780 net.cpp:226] conv2 needs backward computation.
I1013 17:43:33.678701 15780 net.cpp:226] pool1 needs backward computation.
I1013 17:43:33.678705 15780 net.cpp:226] norm1 needs backward computation.
I1013 17:43:33.678707 15780 net.cpp:226] relu1 needs backward computation.
I1013 17:43:33.678710 15780 net.cpp:226] conv1 needs backward computation.
I1013 17:43:33.678714 15780 net.cpp:228] label_mnist_1_split does not need backward computation.
I1013 17:43:33.678717 15780 net.cpp:228] mnist does not need backward computation.
I1013 17:43:33.678720 15780 net.cpp:270] This network produces output accuracy
I1013 17:43:33.678724 15780 net.cpp:270] This network produces output loss
I1013 17:43:33.678738 15780 net.cpp:283] Network initialization done.
I1013 17:43:33.678828 15780 solver.cpp:60] Solver scaffolding done.
I1013 17:43:33.683182 15780 solver.cpp:337] Iteration 0, Testing net (#0)
I1013 17:43:33.777592 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:43:38.639657 15780 solver.cpp:404]     Test net output #0: accuracy = 0.0145
I1013 17:43:38.639701 15780 solver.cpp:404]     Test net output #1: loss = 3.04085 (* 1 = 3.04085 loss)
I1013 17:43:38.672914 15780 solver.cpp:228] Iteration 0, loss = 3.03416
I1013 17:43:38.672961 15780 solver.cpp:244]     Train net output #0: loss = 3.03416 (* 1 = 3.03416 loss)
I1013 17:43:38.672982 15780 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1013 17:43:43.100793 15780 solver.cpp:228] Iteration 100, loss = 2.18365
I1013 17:43:43.100843 15780 solver.cpp:244]     Train net output #0: loss = 2.18365 (* 1 = 2.18365 loss)
I1013 17:43:43.100852 15780 sgd_solver.cpp:106] Iteration 100, lr = 0.000996266
I1013 17:43:47.513916 15780 solver.cpp:228] Iteration 200, loss = 2.12547
I1013 17:43:47.513960 15780 solver.cpp:244]     Train net output #0: loss = 2.12547 (* 1 = 2.12547 loss)
I1013 17:43:47.513968 15780 sgd_solver.cpp:106] Iteration 200, lr = 0.000992565
I1013 17:43:51.860947 15780 solver.cpp:228] Iteration 300, loss = 2.02948
I1013 17:43:51.860985 15780 solver.cpp:244]     Train net output #0: loss = 2.02948 (* 1 = 2.02948 loss)
I1013 17:43:51.860991 15780 sgd_solver.cpp:106] Iteration 300, lr = 0.000988896
I1013 17:43:56.213325 15780 solver.cpp:228] Iteration 400, loss = 2.03994
I1013 17:43:56.213376 15780 solver.cpp:244]     Train net output #0: loss = 2.03994 (* 1 = 2.03994 loss)
I1013 17:43:56.213382 15780 sgd_solver.cpp:106] Iteration 400, lr = 0.000985258
I1013 17:44:00.530844 15780 solver.cpp:337] Iteration 500, Testing net (#0)
I1013 17:44:05.527112 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430917
I1013 17:44:05.527168 15780 solver.cpp:404]     Test net output #1: loss = 2.01864 (* 1 = 2.01864 loss)
I1013 17:44:05.541754 15780 solver.cpp:228] Iteration 500, loss = 2.03128
I1013 17:44:05.541821 15780 solver.cpp:244]     Train net output #0: loss = 2.03128 (* 1 = 2.03128 loss)
I1013 17:44:05.541837 15780 sgd_solver.cpp:106] Iteration 500, lr = 0.000981651
I1013 17:44:09.981364 15780 solver.cpp:228] Iteration 600, loss = 2.18056
I1013 17:44:09.981451 15780 solver.cpp:244]     Train net output #0: loss = 2.18056 (* 1 = 2.18056 loss)
I1013 17:44:09.981467 15780 sgd_solver.cpp:106] Iteration 600, lr = 0.000978075
I1013 17:44:14.464418 15780 solver.cpp:228] Iteration 700, loss = 2.08344
I1013 17:44:14.464490 15780 solver.cpp:244]     Train net output #0: loss = 2.08344 (* 1 = 2.08344 loss)
I1013 17:44:14.464501 15780 sgd_solver.cpp:106] Iteration 700, lr = 0.000974529
I1013 17:44:18.943351 15780 solver.cpp:228] Iteration 800, loss = 2.03535
I1013 17:44:18.943408 15780 solver.cpp:244]     Train net output #0: loss = 2.03535 (* 1 = 2.03535 loss)
I1013 17:44:18.943418 15780 sgd_solver.cpp:106] Iteration 800, lr = 0.000971013
I1013 17:44:23.408138 15780 solver.cpp:228] Iteration 900, loss = 1.91084
I1013 17:44:23.408180 15780 solver.cpp:244]     Train net output #0: loss = 1.91084 (* 1 = 1.91084 loss)
I1013 17:44:23.408187 15780 sgd_solver.cpp:106] Iteration 900, lr = 0.000967526
I1013 17:44:27.826702 15780 solver.cpp:337] Iteration 1000, Testing net (#0)
I1013 17:44:32.425312 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431042
I1013 17:44:32.425390 15780 solver.cpp:404]     Test net output #1: loss = 2.01841 (* 1 = 2.01841 loss)
I1013 17:44:32.440666 15780 solver.cpp:228] Iteration 1000, loss = 2.00736
I1013 17:44:32.440704 15780 solver.cpp:244]     Train net output #0: loss = 2.00736 (* 1 = 2.00736 loss)
I1013 17:44:32.440719 15780 sgd_solver.cpp:106] Iteration 1000, lr = 0.000964069
I1013 17:44:36.919483 15780 solver.cpp:228] Iteration 1100, loss = 2.05774
I1013 17:44:36.919539 15780 solver.cpp:244]     Train net output #0: loss = 2.05774 (* 1 = 2.05774 loss)
I1013 17:44:36.919549 15780 sgd_solver.cpp:106] Iteration 1100, lr = 0.00096064
I1013 17:44:41.384016 15780 solver.cpp:228] Iteration 1200, loss = 2.04978
I1013 17:44:41.384065 15780 solver.cpp:244]     Train net output #0: loss = 2.04978 (* 1 = 2.04978 loss)
I1013 17:44:41.384073 15780 sgd_solver.cpp:106] Iteration 1200, lr = 0.00095724
I1013 17:44:45.760594 15780 solver.cpp:228] Iteration 1300, loss = 1.79886
I1013 17:44:45.760655 15780 solver.cpp:244]     Train net output #0: loss = 1.79886 (* 1 = 1.79886 loss)
I1013 17:44:45.760663 15780 sgd_solver.cpp:106] Iteration 1300, lr = 0.000953867
I1013 17:44:50.141984 15780 solver.cpp:228] Iteration 1400, loss = 2.16033
I1013 17:44:50.142033 15780 solver.cpp:244]     Train net output #0: loss = 2.16033 (* 1 = 2.16033 loss)
I1013 17:44:50.142040 15780 sgd_solver.cpp:106] Iteration 1400, lr = 0.000950522
I1013 17:44:54.475469 15780 solver.cpp:337] Iteration 1500, Testing net (#0)
I1013 17:44:56.160456 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:44:59.332044 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430792
I1013 17:44:59.332126 15780 solver.cpp:404]     Test net output #1: loss = 2.02002 (* 1 = 2.02002 loss)
I1013 17:44:59.347456 15780 solver.cpp:228] Iteration 1500, loss = 2.18366
I1013 17:44:59.347482 15780 solver.cpp:244]     Train net output #0: loss = 2.18366 (* 1 = 2.18366 loss)
I1013 17:44:59.347497 15780 sgd_solver.cpp:106] Iteration 1500, lr = 0.000947204
I1013 17:45:03.798604 15780 solver.cpp:228] Iteration 1600, loss = 2.10746
I1013 17:45:03.798641 15780 solver.cpp:244]     Train net output #0: loss = 2.10746 (* 1 = 2.10746 loss)
I1013 17:45:03.798647 15780 sgd_solver.cpp:106] Iteration 1600, lr = 0.000943913
I1013 17:45:08.221252 15780 solver.cpp:228] Iteration 1700, loss = 2.1926
I1013 17:45:08.221272 15780 solver.cpp:244]     Train net output #0: loss = 2.1926 (* 1 = 2.1926 loss)
I1013 17:45:08.221278 15780 sgd_solver.cpp:106] Iteration 1700, lr = 0.000940649
I1013 17:45:12.667517 15780 solver.cpp:228] Iteration 1800, loss = 2.16491
I1013 17:45:12.667542 15780 solver.cpp:244]     Train net output #0: loss = 2.16491 (* 1 = 2.16491 loss)
I1013 17:45:12.667548 15780 sgd_solver.cpp:106] Iteration 1800, lr = 0.000937411
I1013 17:45:17.124017 15780 solver.cpp:228] Iteration 1900, loss = 2.03484
I1013 17:45:17.124037 15780 solver.cpp:244]     Train net output #0: loss = 2.03484 (* 1 = 2.03484 loss)
I1013 17:45:17.124043 15780 sgd_solver.cpp:106] Iteration 1900, lr = 0.000934199
I1013 17:45:21.521049 15780 solver.cpp:337] Iteration 2000, Testing net (#0)
I1013 17:45:26.282631 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430875
I1013 17:45:26.282699 15780 solver.cpp:404]     Test net output #1: loss = 2.01898 (* 1 = 2.01898 loss)
I1013 17:45:26.297104 15780 solver.cpp:228] Iteration 2000, loss = 1.96984
I1013 17:45:26.297152 15780 solver.cpp:244]     Train net output #0: loss = 1.96984 (* 1 = 1.96984 loss)
I1013 17:45:26.297164 15780 sgd_solver.cpp:106] Iteration 2000, lr = 0.000931013
I1013 17:45:30.795686 15780 solver.cpp:228] Iteration 2100, loss = 1.81749
I1013 17:45:30.795768 15780 solver.cpp:244]     Train net output #0: loss = 1.81749 (* 1 = 1.81749 loss)
I1013 17:45:30.795780 15780 sgd_solver.cpp:106] Iteration 2100, lr = 0.000927851
I1013 17:45:35.275712 15780 solver.cpp:228] Iteration 2200, loss = 2.18726
I1013 17:45:35.275746 15780 solver.cpp:244]     Train net output #0: loss = 2.18726 (* 1 = 2.18726 loss)
I1013 17:45:35.275753 15780 sgd_solver.cpp:106] Iteration 2200, lr = 0.000924715
I1013 17:45:39.754909 15780 solver.cpp:228] Iteration 2300, loss = 2.17142
I1013 17:45:39.754931 15780 solver.cpp:244]     Train net output #0: loss = 2.17142 (* 1 = 2.17142 loss)
I1013 17:45:39.754937 15780 sgd_solver.cpp:106] Iteration 2300, lr = 0.000921603
I1013 17:45:44.211724 15780 solver.cpp:228] Iteration 2400, loss = 2.24139
I1013 17:45:44.211769 15780 solver.cpp:244]     Train net output #0: loss = 2.24139 (* 1 = 2.24139 loss)
I1013 17:45:44.211776 15780 sgd_solver.cpp:106] Iteration 2400, lr = 0.000918516
I1013 17:45:48.639400 15780 solver.cpp:337] Iteration 2500, Testing net (#0)
I1013 17:45:54.084520 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430792
I1013 17:45:54.084599 15780 solver.cpp:404]     Test net output #1: loss = 2.01869 (* 1 = 2.01869 loss)
I1013 17:45:54.099233 15780 solver.cpp:228] Iteration 2500, loss = 1.96101
I1013 17:45:54.099275 15780 solver.cpp:244]     Train net output #0: loss = 1.96101 (* 1 = 1.96101 loss)
I1013 17:45:54.099288 15780 sgd_solver.cpp:106] Iteration 2500, lr = 0.000915452
I1013 17:45:58.573592 15780 solver.cpp:228] Iteration 2600, loss = 2.15351
I1013 17:45:58.573631 15780 solver.cpp:244]     Train net output #0: loss = 2.15351 (* 1 = 2.15351 loss)
I1013 17:45:58.573637 15780 sgd_solver.cpp:106] Iteration 2600, lr = 0.000912412
I1013 17:46:02.995740 15780 solver.cpp:228] Iteration 2700, loss = 1.98413
I1013 17:46:02.995776 15780 solver.cpp:244]     Train net output #0: loss = 1.98413 (* 1 = 1.98413 loss)
I1013 17:46:02.995784 15780 sgd_solver.cpp:106] Iteration 2700, lr = 0.000909396
I1013 17:46:07.395643 15780 solver.cpp:228] Iteration 2800, loss = 2.04037
I1013 17:46:07.395696 15780 solver.cpp:244]     Train net output #0: loss = 2.04037 (* 1 = 2.04037 loss)
I1013 17:46:07.395717 15780 sgd_solver.cpp:106] Iteration 2800, lr = 0.000906403
I1013 17:46:11.785449 15780 solver.cpp:228] Iteration 2900, loss = 2.20145
I1013 17:46:11.785485 15780 solver.cpp:244]     Train net output #0: loss = 2.20145 (* 1 = 2.20145 loss)
I1013 17:46:11.785491 15780 sgd_solver.cpp:106] Iteration 2900, lr = 0.000903433
I1013 17:46:16.152184 15780 solver.cpp:337] Iteration 3000, Testing net (#0)
I1013 17:46:17.184363 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:46:21.043046 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431
I1013 17:46:21.043090 15780 solver.cpp:404]     Test net output #1: loss = 2.01837 (* 1 = 2.01837 loss)
I1013 17:46:21.058727 15780 solver.cpp:228] Iteration 3000, loss = 2.15624
I1013 17:46:21.058749 15780 solver.cpp:244]     Train net output #0: loss = 2.15624 (* 1 = 2.15624 loss)
I1013 17:46:21.058763 15780 sgd_solver.cpp:106] Iteration 3000, lr = 0.000900485
I1013 17:46:25.548388 15780 solver.cpp:228] Iteration 3100, loss = 2.04694
I1013 17:46:25.548429 15780 solver.cpp:244]     Train net output #0: loss = 2.04694 (* 1 = 2.04694 loss)
I1013 17:46:25.548435 15780 sgd_solver.cpp:106] Iteration 3100, lr = 0.00089756
I1013 17:46:30.050909 15780 solver.cpp:228] Iteration 3200, loss = 2.30162
I1013 17:46:30.050971 15780 solver.cpp:244]     Train net output #0: loss = 2.30162 (* 1 = 2.30162 loss)
I1013 17:46:30.050981 15780 sgd_solver.cpp:106] Iteration 3200, lr = 0.000894657
I1013 17:46:34.565135 15780 solver.cpp:228] Iteration 3300, loss = 2.04838
I1013 17:46:34.565183 15780 solver.cpp:244]     Train net output #0: loss = 2.04838 (* 1 = 2.04838 loss)
I1013 17:46:34.565193 15780 sgd_solver.cpp:106] Iteration 3300, lr = 0.000891776
I1013 17:46:39.030959 15780 solver.cpp:228] Iteration 3400, loss = 1.87157
I1013 17:46:39.031014 15780 solver.cpp:244]     Train net output #0: loss = 1.87157 (* 1 = 1.87157 loss)
I1013 17:46:39.031023 15780 sgd_solver.cpp:106] Iteration 3400, lr = 0.000888916
I1013 17:46:43.453173 15780 solver.cpp:337] Iteration 3500, Testing net (#0)
I1013 17:46:48.348803 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430917
I1013 17:46:48.348842 15780 solver.cpp:404]     Test net output #1: loss = 2.01838 (* 1 = 2.01838 loss)
I1013 17:46:48.364724 15780 solver.cpp:228] Iteration 3500, loss = 2.26987
I1013 17:46:48.364775 15780 solver.cpp:244]     Train net output #0: loss = 2.26987 (* 1 = 2.26987 loss)
I1013 17:46:48.364792 15780 sgd_solver.cpp:106] Iteration 3500, lr = 0.000886077
I1013 17:46:52.841084 15780 solver.cpp:228] Iteration 3600, loss = 2.04003
I1013 17:46:52.841141 15780 solver.cpp:244]     Train net output #0: loss = 2.04003 (* 1 = 2.04003 loss)
I1013 17:46:52.841150 15780 sgd_solver.cpp:106] Iteration 3600, lr = 0.00088326
I1013 17:46:57.341078 15780 solver.cpp:228] Iteration 3700, loss = 1.84515
I1013 17:46:57.341157 15780 solver.cpp:244]     Train net output #0: loss = 1.84515 (* 1 = 1.84515 loss)
I1013 17:46:57.341167 15780 sgd_solver.cpp:106] Iteration 3700, lr = 0.000880463
I1013 17:47:01.854804 15780 solver.cpp:228] Iteration 3800, loss = 2.08075
I1013 17:47:01.854861 15780 solver.cpp:244]     Train net output #0: loss = 2.08075 (* 1 = 2.08075 loss)
I1013 17:47:01.854871 15780 sgd_solver.cpp:106] Iteration 3800, lr = 0.000877687
I1013 17:47:06.296967 15780 solver.cpp:228] Iteration 3900, loss = 2.08147
I1013 17:47:06.297005 15780 solver.cpp:244]     Train net output #0: loss = 2.08147 (* 1 = 2.08147 loss)
I1013 17:47:06.297013 15780 sgd_solver.cpp:106] Iteration 3900, lr = 0.000874932
I1013 17:47:10.729226 15780 solver.cpp:337] Iteration 4000, Testing net (#0)
I1013 17:47:15.614624 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430833
I1013 17:47:15.614675 15780 solver.cpp:404]     Test net output #1: loss = 2.01851 (* 1 = 2.01851 loss)
I1013 17:47:15.631093 15780 solver.cpp:228] Iteration 4000, loss = 2.13665
I1013 17:47:15.631136 15780 solver.cpp:244]     Train net output #0: loss = 2.13665 (* 1 = 2.13665 loss)
I1013 17:47:15.631148 15780 sgd_solver.cpp:106] Iteration 4000, lr = 0.000872196
I1013 17:47:20.050587 15780 solver.cpp:228] Iteration 4100, loss = 2.01355
I1013 17:47:20.050647 15780 solver.cpp:244]     Train net output #0: loss = 2.01355 (* 1 = 2.01355 loss)
I1013 17:47:20.050654 15780 sgd_solver.cpp:106] Iteration 4100, lr = 0.00086948
I1013 17:47:24.509637 15780 solver.cpp:228] Iteration 4200, loss = 2.12647
I1013 17:47:24.509708 15780 solver.cpp:244]     Train net output #0: loss = 2.12647 (* 1 = 2.12647 loss)
I1013 17:47:24.509719 15780 sgd_solver.cpp:106] Iteration 4200, lr = 0.000866784
I1013 17:47:28.972622 15780 solver.cpp:228] Iteration 4300, loss = 1.95152
I1013 17:47:28.972690 15780 solver.cpp:244]     Train net output #0: loss = 1.95152 (* 1 = 1.95152 loss)
I1013 17:47:28.972712 15780 sgd_solver.cpp:106] Iteration 4300, lr = 0.000864108
I1013 17:47:33.427361 15780 solver.cpp:228] Iteration 4400, loss = 1.69447
I1013 17:47:33.427445 15780 solver.cpp:244]     Train net output #0: loss = 1.69447 (* 1 = 1.69447 loss)
I1013 17:47:33.427455 15780 sgd_solver.cpp:106] Iteration 4400, lr = 0.00086145
I1013 17:47:37.867843 15780 solver.cpp:337] Iteration 4500, Testing net (#0)
I1013 17:47:41.779276 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:47:42.862450 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431125
I1013 17:47:42.862488 15780 solver.cpp:404]     Test net output #1: loss = 2.01748 (* 1 = 2.01748 loss)
I1013 17:47:42.878589 15780 solver.cpp:228] Iteration 4500, loss = 2.20572
I1013 17:47:42.878643 15780 solver.cpp:244]     Train net output #0: loss = 2.20572 (* 1 = 2.20572 loss)
I1013 17:47:42.878659 15780 sgd_solver.cpp:106] Iteration 4500, lr = 0.000858812
I1013 17:47:47.336596 15780 solver.cpp:228] Iteration 4600, loss = 1.86587
I1013 17:47:47.336640 15780 solver.cpp:244]     Train net output #0: loss = 1.86587 (* 1 = 1.86587 loss)
I1013 17:47:47.336652 15780 sgd_solver.cpp:106] Iteration 4600, lr = 0.000856192
I1013 17:47:51.764966 15780 solver.cpp:228] Iteration 4700, loss = 2.06415
I1013 17:47:51.765008 15780 solver.cpp:244]     Train net output #0: loss = 2.06415 (* 1 = 2.06415 loss)
I1013 17:47:51.765014 15780 sgd_solver.cpp:106] Iteration 4700, lr = 0.000853591
I1013 17:47:56.226462 15780 solver.cpp:228] Iteration 4800, loss = 1.9908
I1013 17:47:56.226501 15780 solver.cpp:244]     Train net output #0: loss = 1.9908 (* 1 = 1.9908 loss)
I1013 17:47:56.226511 15780 sgd_solver.cpp:106] Iteration 4800, lr = 0.000851008
I1013 17:48:00.725476 15780 solver.cpp:228] Iteration 4900, loss = 2.23383
I1013 17:48:00.725533 15780 solver.cpp:244]     Train net output #0: loss = 2.23383 (* 1 = 2.23383 loss)
I1013 17:48:00.725543 15780 sgd_solver.cpp:106] Iteration 4900, lr = 0.000848444
I1013 17:48:05.175616 15780 solver.cpp:337] Iteration 5000, Testing net (#0)
I1013 17:48:10.099612 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430792
I1013 17:48:10.099653 15780 solver.cpp:404]     Test net output #1: loss = 2.01832 (* 1 = 2.01832 loss)
I1013 17:48:10.115759 15780 solver.cpp:228] Iteration 5000, loss = 2.06794
I1013 17:48:10.115806 15780 solver.cpp:244]     Train net output #0: loss = 2.06794 (* 1 = 2.06794 loss)
I1013 17:48:10.115818 15780 sgd_solver.cpp:106] Iteration 5000, lr = 0.000845897
I1013 17:48:14.543718 15780 solver.cpp:228] Iteration 5100, loss = 2.02826
I1013 17:48:14.543772 15780 solver.cpp:244]     Train net output #0: loss = 2.02826 (* 1 = 2.02826 loss)
I1013 17:48:14.543778 15780 sgd_solver.cpp:106] Iteration 5100, lr = 0.000843368
I1013 17:48:19.016412 15780 solver.cpp:228] Iteration 5200, loss = 2.09421
I1013 17:48:19.016458 15780 solver.cpp:244]     Train net output #0: loss = 2.09421 (* 1 = 2.09421 loss)
I1013 17:48:19.016465 15780 sgd_solver.cpp:106] Iteration 5200, lr = 0.000840857
I1013 17:48:23.484602 15780 solver.cpp:228] Iteration 5300, loss = 1.96075
I1013 17:48:23.484632 15780 solver.cpp:244]     Train net output #0: loss = 1.96075 (* 1 = 1.96075 loss)
I1013 17:48:23.484637 15780 sgd_solver.cpp:106] Iteration 5300, lr = 0.000838363
I1013 17:48:27.993813 15780 solver.cpp:228] Iteration 5400, loss = 1.91877
I1013 17:48:27.993855 15780 solver.cpp:244]     Train net output #0: loss = 1.91877 (* 1 = 1.91877 loss)
I1013 17:48:27.993865 15780 sgd_solver.cpp:106] Iteration 5400, lr = 0.000835886
I1013 17:48:32.441117 15780 solver.cpp:337] Iteration 5500, Testing net (#0)
I1013 17:48:37.282750 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430958
I1013 17:48:37.282815 15780 solver.cpp:404]     Test net output #1: loss = 2.01877 (* 1 = 2.01877 loss)
I1013 17:48:37.298542 15780 solver.cpp:228] Iteration 5500, loss = 1.94865
I1013 17:48:37.298588 15780 solver.cpp:244]     Train net output #0: loss = 1.94865 (* 1 = 1.94865 loss)
I1013 17:48:37.298612 15780 sgd_solver.cpp:106] Iteration 5500, lr = 0.000833427
I1013 17:48:41.719835 15780 solver.cpp:228] Iteration 5600, loss = 1.95653
I1013 17:48:41.719872 15780 solver.cpp:244]     Train net output #0: loss = 1.95653 (* 1 = 1.95653 loss)
I1013 17:48:41.719879 15780 sgd_solver.cpp:106] Iteration 5600, lr = 0.000830984
I1013 17:48:46.213604 15780 solver.cpp:228] Iteration 5700, loss = 2.15826
I1013 17:48:46.213644 15780 solver.cpp:244]     Train net output #0: loss = 2.15826 (* 1 = 2.15826 loss)
I1013 17:48:46.213656 15780 sgd_solver.cpp:106] Iteration 5700, lr = 0.000828558
I1013 17:48:50.732015 15780 solver.cpp:228] Iteration 5800, loss = 2.05178
I1013 17:48:50.732059 15780 solver.cpp:244]     Train net output #0: loss = 2.05178 (* 1 = 2.05178 loss)
I1013 17:48:50.732067 15780 sgd_solver.cpp:106] Iteration 5800, lr = 0.000826148
I1013 17:48:55.245256 15780 solver.cpp:228] Iteration 5900, loss = 1.83022
I1013 17:48:55.245311 15780 solver.cpp:244]     Train net output #0: loss = 1.83022 (* 1 = 1.83022 loss)
I1013 17:48:55.245321 15780 sgd_solver.cpp:106] Iteration 5900, lr = 0.000823754
I1013 17:48:59.703640 15780 solver.cpp:337] Iteration 6000, Testing net (#0)
I1013 17:49:02.706390 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:49:04.576346 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430833
I1013 17:49:04.576403 15780 solver.cpp:404]     Test net output #1: loss = 2.019 (* 1 = 2.019 loss)
I1013 17:49:04.592965 15780 solver.cpp:228] Iteration 6000, loss = 2.02146
I1013 17:49:04.593025 15780 solver.cpp:244]     Train net output #0: loss = 2.02146 (* 1 = 2.02146 loss)
I1013 17:49:04.593052 15780 sgd_solver.cpp:106] Iteration 6000, lr = 0.000821377
I1013 17:49:09.099452 15780 solver.cpp:228] Iteration 6100, loss = 1.90241
I1013 17:49:09.099550 15780 solver.cpp:244]     Train net output #0: loss = 1.90241 (* 1 = 1.90241 loss)
I1013 17:49:09.099560 15780 sgd_solver.cpp:106] Iteration 6100, lr = 0.000819015
I1013 17:49:13.585623 15780 solver.cpp:228] Iteration 6200, loss = 2.01067
I1013 17:49:13.585661 15780 solver.cpp:244]     Train net output #0: loss = 2.01067 (* 1 = 2.01067 loss)
I1013 17:49:13.585667 15780 sgd_solver.cpp:106] Iteration 6200, lr = 0.00081667
I1013 17:49:18.079398 15780 solver.cpp:228] Iteration 6300, loss = 2.0534
I1013 17:49:18.079432 15780 solver.cpp:244]     Train net output #0: loss = 2.0534 (* 1 = 2.0534 loss)
I1013 17:49:18.079439 15780 sgd_solver.cpp:106] Iteration 6300, lr = 0.00081434
I1013 17:49:22.586277 15780 solver.cpp:228] Iteration 6400, loss = 2.10321
I1013 17:49:22.586338 15780 solver.cpp:244]     Train net output #0: loss = 2.10321 (* 1 = 2.10321 loss)
I1013 17:49:22.586349 15780 sgd_solver.cpp:106] Iteration 6400, lr = 0.000812025
I1013 17:49:27.045917 15780 solver.cpp:337] Iteration 6500, Testing net (#0)
I1013 17:49:31.985183 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430959
I1013 17:49:31.985249 15780 solver.cpp:404]     Test net output #1: loss = 2.01882 (* 1 = 2.01882 loss)
I1013 17:49:32.000973 15780 solver.cpp:228] Iteration 6500, loss = 2.03487
I1013 17:49:32.001019 15780 solver.cpp:244]     Train net output #0: loss = 2.03487 (* 1 = 2.03487 loss)
I1013 17:49:32.001032 15780 sgd_solver.cpp:106] Iteration 6500, lr = 0.000809726
I1013 17:49:36.470784 15780 solver.cpp:228] Iteration 6600, loss = 2.1433
I1013 17:49:36.470852 15780 solver.cpp:244]     Train net output #0: loss = 2.1433 (* 1 = 2.1433 loss)
I1013 17:49:36.470861 15780 sgd_solver.cpp:106] Iteration 6600, lr = 0.000807442
I1013 17:49:40.935115 15780 solver.cpp:228] Iteration 6700, loss = 2.11708
I1013 17:49:40.935176 15780 solver.cpp:244]     Train net output #0: loss = 2.11708 (* 1 = 2.11708 loss)
I1013 17:49:40.935185 15780 sgd_solver.cpp:106] Iteration 6700, lr = 0.000805173
I1013 17:49:45.448259 15780 solver.cpp:228] Iteration 6800, loss = 2.01235
I1013 17:49:45.448324 15780 solver.cpp:244]     Train net output #0: loss = 2.01235 (* 1 = 2.01235 loss)
I1013 17:49:45.448335 15780 sgd_solver.cpp:106] Iteration 6800, lr = 0.000802918
I1013 17:49:49.957674 15780 solver.cpp:228] Iteration 6900, loss = 1.78765
I1013 17:49:49.957736 15780 solver.cpp:244]     Train net output #0: loss = 1.78765 (* 1 = 1.78765 loss)
I1013 17:49:49.957746 15780 sgd_solver.cpp:106] Iteration 6900, lr = 0.000800679
I1013 17:49:54.399569 15780 solver.cpp:337] Iteration 7000, Testing net (#0)
I1013 17:49:59.285936 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430917
I1013 17:49:59.285998 15780 solver.cpp:404]     Test net output #1: loss = 2.0184 (* 1 = 2.0184 loss)
I1013 17:49:59.301879 15780 solver.cpp:228] Iteration 7000, loss = 2.0994
I1013 17:49:59.301903 15780 solver.cpp:244]     Train net output #0: loss = 2.0994 (* 1 = 2.0994 loss)
I1013 17:49:59.301916 15780 sgd_solver.cpp:106] Iteration 7000, lr = 0.000798454
I1013 17:50:03.718786 15780 solver.cpp:228] Iteration 7100, loss = 2.18421
I1013 17:50:03.718842 15780 solver.cpp:244]     Train net output #0: loss = 2.18421 (* 1 = 2.18421 loss)
I1013 17:50:03.718853 15780 sgd_solver.cpp:106] Iteration 7100, lr = 0.000796243
I1013 17:50:08.134428 15780 solver.cpp:228] Iteration 7200, loss = 2.04575
I1013 17:50:08.134479 15780 solver.cpp:244]     Train net output #0: loss = 2.04575 (* 1 = 2.04575 loss)
I1013 17:50:08.134492 15780 sgd_solver.cpp:106] Iteration 7200, lr = 0.000794046
I1013 17:50:12.548882 15780 solver.cpp:228] Iteration 7300, loss = 2.04436
I1013 17:50:12.548939 15780 solver.cpp:244]     Train net output #0: loss = 2.04436 (* 1 = 2.04436 loss)
I1013 17:50:12.548954 15780 sgd_solver.cpp:106] Iteration 7300, lr = 0.000791864
I1013 17:50:16.970607 15780 solver.cpp:228] Iteration 7400, loss = 2.00357
I1013 17:50:16.970679 15780 solver.cpp:244]     Train net output #0: loss = 2.00357 (* 1 = 2.00357 loss)
I1013 17:50:16.970691 15780 sgd_solver.cpp:106] Iteration 7400, lr = 0.000789695
I1013 17:50:21.404686 15780 solver.cpp:337] Iteration 7500, Testing net (#0)
I1013 17:50:26.274281 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431
I1013 17:50:26.274354 15780 solver.cpp:404]     Test net output #1: loss = 2.01842 (* 1 = 2.01842 loss)
I1013 17:50:26.290297 15780 solver.cpp:228] Iteration 7500, loss = 1.83678
I1013 17:50:26.290349 15780 solver.cpp:244]     Train net output #0: loss = 1.83678 (* 1 = 1.83678 loss)
I1013 17:50:26.290372 15780 sgd_solver.cpp:106] Iteration 7500, lr = 0.000787541
I1013 17:50:30.802466 15780 solver.cpp:228] Iteration 7600, loss = 2.26752
I1013 17:50:30.802537 15780 solver.cpp:244]     Train net output #0: loss = 2.26752 (* 1 = 2.26752 loss)
I1013 17:50:30.802556 15780 sgd_solver.cpp:106] Iteration 7600, lr = 0.0007854
I1013 17:50:33.817040 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:50:35.302552 15780 solver.cpp:228] Iteration 7700, loss = 1.82365
I1013 17:50:35.302599 15780 solver.cpp:244]     Train net output #0: loss = 1.82365 (* 1 = 1.82365 loss)
I1013 17:50:35.302608 15780 sgd_solver.cpp:106] Iteration 7700, lr = 0.000783272
I1013 17:50:39.792273 15780 solver.cpp:228] Iteration 7800, loss = 2.16967
I1013 17:50:39.792312 15780 solver.cpp:244]     Train net output #0: loss = 2.16967 (* 1 = 2.16967 loss)
I1013 17:50:39.792320 15780 sgd_solver.cpp:106] Iteration 7800, lr = 0.000781158
I1013 17:50:44.267509 15780 solver.cpp:228] Iteration 7900, loss = 2.14813
I1013 17:50:44.267529 15780 solver.cpp:244]     Train net output #0: loss = 2.14813 (* 1 = 2.14813 loss)
I1013 17:50:44.267534 15780 sgd_solver.cpp:106] Iteration 7900, lr = 0.000779057
I1013 17:50:48.711443 15780 solver.cpp:337] Iteration 8000, Testing net (#0)
I1013 17:50:53.606153 15780 solver.cpp:404]     Test net output #0: accuracy = 0.43075
I1013 17:50:53.606215 15780 solver.cpp:404]     Test net output #1: loss = 2.01866 (* 1 = 2.01866 loss)
I1013 17:50:53.622453 15780 solver.cpp:228] Iteration 8000, loss = 2.16928
I1013 17:50:53.622514 15780 solver.cpp:244]     Train net output #0: loss = 2.16928 (* 1 = 2.16928 loss)
I1013 17:50:53.622525 15780 sgd_solver.cpp:106] Iteration 8000, lr = 0.00077697
I1013 17:50:58.104496 15780 solver.cpp:228] Iteration 8100, loss = 1.99308
I1013 17:50:58.104547 15780 solver.cpp:244]     Train net output #0: loss = 1.99308 (* 1 = 1.99308 loss)
I1013 17:50:58.104553 15780 sgd_solver.cpp:106] Iteration 8100, lr = 0.000774895
I1013 17:51:02.567800 15780 solver.cpp:228] Iteration 8200, loss = 2.13659
I1013 17:51:02.567832 15780 solver.cpp:244]     Train net output #0: loss = 2.13659 (* 1 = 2.13659 loss)
I1013 17:51:02.567838 15780 sgd_solver.cpp:106] Iteration 8200, lr = 0.000772833
I1013 17:51:07.032277 15780 solver.cpp:228] Iteration 8300, loss = 2.06577
I1013 17:51:07.032311 15780 solver.cpp:244]     Train net output #0: loss = 2.06577 (* 1 = 2.06577 loss)
I1013 17:51:07.032317 15780 sgd_solver.cpp:106] Iteration 8300, lr = 0.000770784
I1013 17:51:11.526728 15780 solver.cpp:228] Iteration 8400, loss = 2.11208
I1013 17:51:11.526768 15780 solver.cpp:244]     Train net output #0: loss = 2.11208 (* 1 = 2.11208 loss)
I1013 17:51:11.526777 15780 sgd_solver.cpp:106] Iteration 8400, lr = 0.000768748
I1013 17:51:15.959578 15780 solver.cpp:337] Iteration 8500, Testing net (#0)
I1013 17:51:20.849997 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430708
I1013 17:51:20.850062 15780 solver.cpp:404]     Test net output #1: loss = 2.01863 (* 1 = 2.01863 loss)
I1013 17:51:20.866109 15780 solver.cpp:228] Iteration 8500, loss = 2.09944
I1013 17:51:20.866163 15780 solver.cpp:244]     Train net output #0: loss = 2.09944 (* 1 = 2.09944 loss)
I1013 17:51:20.866174 15780 sgd_solver.cpp:106] Iteration 8500, lr = 0.000766724
I1013 17:51:25.357897 15780 solver.cpp:228] Iteration 8600, loss = 1.92394
I1013 17:51:25.357962 15780 solver.cpp:244]     Train net output #0: loss = 1.92394 (* 1 = 1.92394 loss)
I1013 17:51:25.357973 15780 sgd_solver.cpp:106] Iteration 8600, lr = 0.000764712
I1013 17:51:29.828863 15780 solver.cpp:228] Iteration 8700, loss = 1.97693
I1013 17:51:29.828905 15780 solver.cpp:244]     Train net output #0: loss = 1.97693 (* 1 = 1.97693 loss)
I1013 17:51:29.828912 15780 sgd_solver.cpp:106] Iteration 8700, lr = 0.000762713
I1013 17:51:34.229183 15780 solver.cpp:228] Iteration 8800, loss = 1.97705
I1013 17:51:34.229202 15780 solver.cpp:244]     Train net output #0: loss = 1.97705 (* 1 = 1.97705 loss)
I1013 17:51:34.229218 15780 sgd_solver.cpp:106] Iteration 8800, lr = 0.000760726
I1013 17:51:38.628500 15780 solver.cpp:228] Iteration 8900, loss = 1.92883
I1013 17:51:38.628518 15780 solver.cpp:244]     Train net output #0: loss = 1.92883 (* 1 = 1.92883 loss)
I1013 17:51:38.628523 15780 sgd_solver.cpp:106] Iteration 8900, lr = 0.000758751
I1013 17:51:42.989038 15780 solver.cpp:337] Iteration 9000, Testing net (#0)
I1013 17:51:47.562585 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:51:47.823989 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431
I1013 17:51:47.824030 15780 solver.cpp:404]     Test net output #1: loss = 2.01768 (* 1 = 2.01768 loss)
I1013 17:51:47.840435 15780 solver.cpp:228] Iteration 9000, loss = 1.79163
I1013 17:51:47.840461 15780 solver.cpp:244]     Train net output #0: loss = 1.79163 (* 1 = 1.79163 loss)
I1013 17:51:47.840471 15780 sgd_solver.cpp:106] Iteration 9000, lr = 0.000756788
I1013 17:51:52.356401 15780 solver.cpp:228] Iteration 9100, loss = 2.24761
I1013 17:51:52.356433 15780 solver.cpp:244]     Train net output #0: loss = 2.24761 (* 1 = 2.24761 loss)
I1013 17:51:52.356438 15780 sgd_solver.cpp:106] Iteration 9100, lr = 0.000754836
I1013 17:51:56.809044 15780 solver.cpp:228] Iteration 9200, loss = 1.94328
I1013 17:51:56.809088 15780 solver.cpp:244]     Train net output #0: loss = 1.94328 (* 1 = 1.94328 loss)
I1013 17:51:56.809094 15780 sgd_solver.cpp:106] Iteration 9200, lr = 0.000752897
I1013 17:52:01.234388 15780 solver.cpp:228] Iteration 9300, loss = 2.22837
I1013 17:52:01.234419 15780 solver.cpp:244]     Train net output #0: loss = 2.22837 (* 1 = 2.22837 loss)
I1013 17:52:01.234426 15780 sgd_solver.cpp:106] Iteration 9300, lr = 0.000750969
I1013 17:52:05.705843 15780 solver.cpp:228] Iteration 9400, loss = 1.93736
I1013 17:52:05.705862 15780 solver.cpp:244]     Train net output #0: loss = 1.93736 (* 1 = 1.93736 loss)
I1013 17:52:05.705868 15780 sgd_solver.cpp:106] Iteration 9400, lr = 0.000749052
I1013 17:52:10.061019 15780 solver.cpp:337] Iteration 9500, Testing net (#0)
I1013 17:52:14.948860 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430917
I1013 17:52:14.948884 15780 solver.cpp:404]     Test net output #1: loss = 2.01655 (* 1 = 2.01655 loss)
I1013 17:52:14.964975 15780 solver.cpp:228] Iteration 9500, loss = 2.06239
I1013 17:52:14.965029 15780 solver.cpp:244]     Train net output #0: loss = 2.06239 (* 1 = 2.06239 loss)
I1013 17:52:14.965039 15780 sgd_solver.cpp:106] Iteration 9500, lr = 0.000747147
I1013 17:52:19.489178 15780 solver.cpp:228] Iteration 9600, loss = 2.1181
I1013 17:52:19.489205 15780 solver.cpp:244]     Train net output #0: loss = 2.1181 (* 1 = 2.1181 loss)
I1013 17:52:19.489213 15780 sgd_solver.cpp:106] Iteration 9600, lr = 0.000745253
I1013 17:52:23.992995 15780 solver.cpp:228] Iteration 9700, loss = 1.94224
I1013 17:52:23.993012 15780 solver.cpp:244]     Train net output #0: loss = 1.94224 (* 1 = 1.94224 loss)
I1013 17:52:23.993018 15780 sgd_solver.cpp:106] Iteration 9700, lr = 0.00074337
I1013 17:52:28.490805 15780 solver.cpp:228] Iteration 9800, loss = 2.28412
I1013 17:52:28.490833 15780 solver.cpp:244]     Train net output #0: loss = 2.28412 (* 1 = 2.28412 loss)
I1013 17:52:28.490839 15780 sgd_solver.cpp:106] Iteration 9800, lr = 0.000741499
I1013 17:52:32.958359 15780 solver.cpp:228] Iteration 9900, loss = 1.94707
I1013 17:52:32.958410 15780 solver.cpp:244]     Train net output #0: loss = 1.94707 (* 1 = 1.94707 loss)
I1013 17:52:32.958420 15780 sgd_solver.cpp:106] Iteration 9900, lr = 0.000739638
I1013 17:52:37.420624 15780 solver.cpp:337] Iteration 10000, Testing net (#0)
I1013 17:52:42.395745 15780 solver.cpp:404]     Test net output #0: accuracy = 0.430875
I1013 17:52:42.395771 15780 solver.cpp:404]     Test net output #1: loss = 2.01337 (* 1 = 2.01337 loss)
I1013 17:52:42.411665 15780 solver.cpp:228] Iteration 10000, loss = 1.93086
I1013 17:52:42.411712 15780 solver.cpp:244]     Train net output #0: loss = 1.93086 (* 1 = 1.93086 loss)
I1013 17:52:42.411726 15780 sgd_solver.cpp:106] Iteration 10000, lr = 0.000737788
I1013 17:52:46.939437 15780 solver.cpp:228] Iteration 10100, loss = 2.20737
I1013 17:52:46.939535 15780 solver.cpp:244]     Train net output #0: loss = 2.20737 (* 1 = 2.20737 loss)
I1013 17:52:46.939548 15780 sgd_solver.cpp:106] Iteration 10100, lr = 0.000735949
I1013 17:52:51.449117 15780 solver.cpp:228] Iteration 10200, loss = 2.01659
I1013 17:52:51.449156 15780 solver.cpp:244]     Train net output #0: loss = 2.01659 (* 1 = 2.01659 loss)
I1013 17:52:51.449162 15780 sgd_solver.cpp:106] Iteration 10200, lr = 0.00073412
I1013 17:52:55.896427 15780 solver.cpp:228] Iteration 10300, loss = 2.11155
I1013 17:52:55.896481 15780 solver.cpp:244]     Train net output #0: loss = 2.11155 (* 1 = 2.11155 loss)
I1013 17:52:55.896488 15780 sgd_solver.cpp:106] Iteration 10300, lr = 0.000732303
I1013 17:53:00.302265 15780 solver.cpp:228] Iteration 10400, loss = 1.88467
I1013 17:53:00.302307 15780 solver.cpp:244]     Train net output #0: loss = 1.88467 (* 1 = 1.88467 loss)
I1013 17:53:00.302317 15780 sgd_solver.cpp:106] Iteration 10400, lr = 0.000730495
I1013 17:53:04.659451 15780 solver.cpp:337] Iteration 10500, Testing net (#0)
I1013 17:53:09.579869 15780 solver.cpp:404]     Test net output #0: accuracy = 0.431
I1013 17:53:09.579917 15780 solver.cpp:404]     Test net output #1: loss = 1.96189 (* 1 = 1.96189 loss)
I1013 17:53:09.596400 15780 solver.cpp:228] Iteration 10500, loss = 1.92578
I1013 17:53:09.596421 15780 solver.cpp:244]     Train net output #0: loss = 1.92578 (* 1 = 1.92578 loss)
I1013 17:53:09.596429 15780 sgd_solver.cpp:106] Iteration 10500, lr = 0.000728698
I1013 17:53:10.130483 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:53:14.049199 15780 solver.cpp:228] Iteration 10600, loss = 2.06659
I1013 17:53:14.049243 15780 solver.cpp:244]     Train net output #0: loss = 2.06659 (* 1 = 2.06659 loss)
I1013 17:53:14.049249 15780 sgd_solver.cpp:106] Iteration 10600, lr = 0.000726911
I1013 17:53:18.531888 15780 solver.cpp:228] Iteration 10700, loss = 1.99918
I1013 17:53:18.531906 15780 solver.cpp:244]     Train net output #0: loss = 1.99918 (* 1 = 1.99918 loss)
I1013 17:53:18.531913 15780 sgd_solver.cpp:106] Iteration 10700, lr = 0.000725135
I1013 17:53:23.032393 15780 solver.cpp:228] Iteration 10800, loss = 1.81619
I1013 17:53:23.032413 15780 solver.cpp:244]     Train net output #0: loss = 1.81619 (* 1 = 1.81619 loss)
I1013 17:53:23.032419 15780 sgd_solver.cpp:106] Iteration 10800, lr = 0.000723368
I1013 17:53:27.534356 15780 solver.cpp:228] Iteration 10900, loss = 2.2238
I1013 17:53:27.534376 15780 solver.cpp:244]     Train net output #0: loss = 2.2238 (* 1 = 2.2238 loss)
I1013 17:53:27.534382 15780 sgd_solver.cpp:106] Iteration 10900, lr = 0.000721612
I1013 17:53:31.951189 15780 solver.cpp:337] Iteration 11000, Testing net (#0)
I1013 17:53:36.830977 15780 solver.cpp:404]     Test net output #0: accuracy = 0.449125
I1013 17:53:36.831043 15780 solver.cpp:404]     Test net output #1: loss = 1.88973 (* 1 = 1.88973 loss)
I1013 17:53:36.847268 15780 solver.cpp:228] Iteration 11000, loss = 2.02912
I1013 17:53:36.847308 15780 solver.cpp:244]     Train net output #0: loss = 2.02912 (* 1 = 2.02912 loss)
I1013 17:53:36.847319 15780 sgd_solver.cpp:106] Iteration 11000, lr = 0.000719865
I1013 17:53:41.332269 15780 solver.cpp:228] Iteration 11100, loss = 2.11953
I1013 17:53:41.332303 15780 solver.cpp:244]     Train net output #0: loss = 2.11953 (* 1 = 2.11953 loss)
I1013 17:53:41.332309 15780 sgd_solver.cpp:106] Iteration 11100, lr = 0.000718129
I1013 17:53:45.783170 15780 solver.cpp:228] Iteration 11200, loss = 1.89133
I1013 17:53:45.783206 15780 solver.cpp:244]     Train net output #0: loss = 1.89133 (* 1 = 1.89133 loss)
I1013 17:53:45.783213 15780 sgd_solver.cpp:106] Iteration 11200, lr = 0.000716402
I1013 17:53:50.271867 15780 solver.cpp:228] Iteration 11300, loss = 1.92059
I1013 17:53:50.271898 15780 solver.cpp:244]     Train net output #0: loss = 1.92059 (* 1 = 1.92059 loss)
I1013 17:53:50.271904 15780 sgd_solver.cpp:106] Iteration 11300, lr = 0.000714684
I1013 17:53:54.733698 15780 solver.cpp:228] Iteration 11400, loss = 1.93684
I1013 17:53:54.733747 15780 solver.cpp:244]     Train net output #0: loss = 1.93684 (* 1 = 1.93684 loss)
I1013 17:53:54.733755 15780 sgd_solver.cpp:106] Iteration 11400, lr = 0.000712977
I1013 17:53:59.190419 15780 solver.cpp:337] Iteration 11500, Testing net (#0)
I1013 17:54:04.098537 15780 solver.cpp:404]     Test net output #0: accuracy = 0.526542
I1013 17:54:04.098583 15780 solver.cpp:404]     Test net output #1: loss = 1.75802 (* 1 = 1.75802 loss)
I1013 17:54:04.114490 15780 solver.cpp:228] Iteration 11500, loss = 1.93196
I1013 17:54:04.114538 15780 solver.cpp:244]     Train net output #0: loss = 1.93196 (* 1 = 1.93196 loss)
I1013 17:54:04.114549 15780 sgd_solver.cpp:106] Iteration 11500, lr = 0.000711278
I1013 17:54:08.637781 15780 solver.cpp:228] Iteration 11600, loss = 1.69572
I1013 17:54:08.637859 15780 solver.cpp:244]     Train net output #0: loss = 1.69572 (* 1 = 1.69572 loss)
I1013 17:54:08.637871 15780 sgd_solver.cpp:106] Iteration 11600, lr = 0.00070959
I1013 17:54:13.146606 15780 solver.cpp:228] Iteration 11700, loss = 1.82997
I1013 17:54:13.146648 15780 solver.cpp:244]     Train net output #0: loss = 1.82997 (* 1 = 1.82997 loss)
I1013 17:54:13.146656 15780 sgd_solver.cpp:106] Iteration 11700, lr = 0.00070791
I1013 17:54:17.621392 15780 solver.cpp:228] Iteration 11800, loss = 1.88813
I1013 17:54:17.621457 15780 solver.cpp:244]     Train net output #0: loss = 1.88813 (* 1 = 1.88813 loss)
I1013 17:54:17.621472 15780 sgd_solver.cpp:106] Iteration 11800, lr = 0.00070624
I1013 17:54:22.045131 15780 solver.cpp:228] Iteration 11900, loss = 1.96658
I1013 17:54:22.045181 15780 solver.cpp:244]     Train net output #0: loss = 1.96658 (* 1 = 1.96658 loss)
I1013 17:54:22.045205 15780 sgd_solver.cpp:106] Iteration 11900, lr = 0.000704579
I1013 17:54:26.464032 15780 solver.cpp:337] Iteration 12000, Testing net (#0)
I1013 17:54:30.372184 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:54:31.363000 15780 solver.cpp:404]     Test net output #0: accuracy = 0.539042
I1013 17:54:31.363030 15780 solver.cpp:404]     Test net output #1: loss = 1.71752 (* 1 = 1.71752 loss)
I1013 17:54:31.378865 15780 solver.cpp:228] Iteration 12000, loss = 1.67259
I1013 17:54:31.378888 15780 solver.cpp:244]     Train net output #0: loss = 1.67259 (* 1 = 1.67259 loss)
I1013 17:54:31.378898 15780 sgd_solver.cpp:106] Iteration 12000, lr = 0.000702927
I1013 17:54:35.821626 15780 solver.cpp:228] Iteration 12100, loss = 1.65064
I1013 17:54:35.821645 15780 solver.cpp:244]     Train net output #0: loss = 1.65064 (* 1 = 1.65064 loss)
I1013 17:54:35.821650 15780 sgd_solver.cpp:106] Iteration 12100, lr = 0.000701284
I1013 17:54:40.223075 15780 solver.cpp:228] Iteration 12200, loss = 1.73125
I1013 17:54:40.223104 15780 solver.cpp:244]     Train net output #0: loss = 1.73125 (* 1 = 1.73125 loss)
I1013 17:54:40.223110 15780 sgd_solver.cpp:106] Iteration 12200, lr = 0.00069965
I1013 17:54:44.625003 15780 solver.cpp:228] Iteration 12300, loss = 1.69664
I1013 17:54:44.625020 15780 solver.cpp:244]     Train net output #0: loss = 1.69664 (* 1 = 1.69664 loss)
I1013 17:54:44.625026 15780 sgd_solver.cpp:106] Iteration 12300, lr = 0.000698024
I1013 17:54:49.027098 15780 solver.cpp:228] Iteration 12400, loss = 1.57608
I1013 17:54:49.027129 15780 solver.cpp:244]     Train net output #0: loss = 1.57608 (* 1 = 1.57608 loss)
I1013 17:54:49.027135 15780 sgd_solver.cpp:106] Iteration 12400, lr = 0.000696408
I1013 17:54:53.386093 15780 solver.cpp:337] Iteration 12500, Testing net (#0)
I1013 17:54:58.253481 15780 solver.cpp:404]     Test net output #0: accuracy = 0.552042
I1013 17:54:58.253525 15780 solver.cpp:404]     Test net output #1: loss = 1.68744 (* 1 = 1.68744 loss)
I1013 17:54:58.269384 15780 solver.cpp:228] Iteration 12500, loss = 1.70138
I1013 17:54:58.269428 15780 solver.cpp:244]     Train net output #0: loss = 1.70138 (* 1 = 1.70138 loss)
I1013 17:54:58.269438 15780 sgd_solver.cpp:106] Iteration 12500, lr = 0.0006948
I1013 17:55:02.732620 15780 solver.cpp:228] Iteration 12600, loss = 1.69174
I1013 17:55:02.732676 15780 solver.cpp:244]     Train net output #0: loss = 1.69174 (* 1 = 1.69174 loss)
I1013 17:55:02.732683 15780 sgd_solver.cpp:106] Iteration 12600, lr = 0.000693201
I1013 17:55:07.132046 15780 solver.cpp:228] Iteration 12700, loss = 1.78725
I1013 17:55:07.132100 15780 solver.cpp:244]     Train net output #0: loss = 1.78725 (* 1 = 1.78725 loss)
I1013 17:55:07.132107 15780 sgd_solver.cpp:106] Iteration 12700, lr = 0.000691611
I1013 17:55:11.539532 15780 solver.cpp:228] Iteration 12800, loss = 1.56454
I1013 17:55:11.539575 15780 solver.cpp:244]     Train net output #0: loss = 1.56454 (* 1 = 1.56454 loss)
I1013 17:55:11.539582 15780 sgd_solver.cpp:106] Iteration 12800, lr = 0.000690029
I1013 17:55:15.964313 15780 solver.cpp:228] Iteration 12900, loss = 1.66825
I1013 17:55:15.964366 15780 solver.cpp:244]     Train net output #0: loss = 1.66825 (* 1 = 1.66825 loss)
I1013 17:55:15.964386 15780 sgd_solver.cpp:106] Iteration 12900, lr = 0.000688455
I1013 17:55:20.426395 15780 solver.cpp:337] Iteration 13000, Testing net (#0)
I1013 17:55:25.312368 15780 solver.cpp:404]     Test net output #0: accuracy = 0.567125
I1013 17:55:25.312429 15780 solver.cpp:404]     Test net output #1: loss = 1.65367 (* 1 = 1.65367 loss)
I1013 17:55:25.327909 15780 solver.cpp:228] Iteration 13000, loss = 1.37443
I1013 17:55:25.327930 15780 solver.cpp:244]     Train net output #0: loss = 1.37443 (* 1 = 1.37443 loss)
I1013 17:55:25.327939 15780 sgd_solver.cpp:106] Iteration 13000, lr = 0.00068689
I1013 17:55:29.820356 15780 solver.cpp:228] Iteration 13100, loss = 1.84519
I1013 17:55:29.820375 15780 solver.cpp:244]     Train net output #0: loss = 1.84519 (* 1 = 1.84519 loss)
I1013 17:55:29.820381 15780 sgd_solver.cpp:106] Iteration 13100, lr = 0.000685333
I1013 17:55:34.275349 15780 solver.cpp:228] Iteration 13200, loss = 1.84208
I1013 17:55:34.275379 15780 solver.cpp:244]     Train net output #0: loss = 1.84208 (* 1 = 1.84208 loss)
I1013 17:55:34.275385 15780 sgd_solver.cpp:106] Iteration 13200, lr = 0.000683784
I1013 17:55:38.766710 15780 solver.cpp:228] Iteration 13300, loss = 1.57508
I1013 17:55:38.766728 15780 solver.cpp:244]     Train net output #0: loss = 1.57508 (* 1 = 1.57508 loss)
I1013 17:55:38.766734 15780 sgd_solver.cpp:106] Iteration 13300, lr = 0.000682243
I1013 17:55:43.247349 15780 solver.cpp:228] Iteration 13400, loss = 1.63917
I1013 17:55:43.247411 15780 solver.cpp:244]     Train net output #0: loss = 1.63917 (* 1 = 1.63917 loss)
I1013 17:55:43.247422 15780 sgd_solver.cpp:106] Iteration 13400, lr = 0.000680711
I1013 17:55:47.647478 15780 solver.cpp:337] Iteration 13500, Testing net (#0)
I1013 17:55:52.532177 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:55:52.552985 15780 solver.cpp:404]     Test net output #0: accuracy = 0.572958
I1013 17:55:52.553031 15780 solver.cpp:404]     Test net output #1: loss = 1.65044 (* 1 = 1.65044 loss)
I1013 17:55:52.569377 15780 solver.cpp:228] Iteration 13500, loss = 1.65682
I1013 17:55:52.569401 15780 solver.cpp:244]     Train net output #0: loss = 1.65682 (* 1 = 1.65682 loss)
I1013 17:55:52.569409 15780 sgd_solver.cpp:106] Iteration 13500, lr = 0.000679186
I1013 17:55:57.072561 15780 solver.cpp:228] Iteration 13600, loss = 1.6902
I1013 17:55:57.072598 15780 solver.cpp:244]     Train net output #0: loss = 1.6902 (* 1 = 1.6902 loss)
I1013 17:55:57.072604 15780 sgd_solver.cpp:106] Iteration 13600, lr = 0.00067767
I1013 17:56:01.482007 15780 solver.cpp:228] Iteration 13700, loss = 1.88183
I1013 17:56:01.482077 15780 solver.cpp:244]     Train net output #0: loss = 1.88183 (* 1 = 1.88183 loss)
I1013 17:56:01.482089 15780 sgd_solver.cpp:106] Iteration 13700, lr = 0.000676161
I1013 17:56:05.976402 15780 solver.cpp:228] Iteration 13800, loss = 1.68031
I1013 17:56:05.976475 15780 solver.cpp:244]     Train net output #0: loss = 1.68031 (* 1 = 1.68031 loss)
I1013 17:56:05.976497 15780 sgd_solver.cpp:106] Iteration 13800, lr = 0.00067466
I1013 17:56:10.481545 15780 solver.cpp:228] Iteration 13900, loss = 1.66238
I1013 17:56:10.481600 15780 solver.cpp:244]     Train net output #0: loss = 1.66238 (* 1 = 1.66238 loss)
I1013 17:56:10.481609 15780 sgd_solver.cpp:106] Iteration 13900, lr = 0.000673167
I1013 17:56:14.919394 15780 solver.cpp:337] Iteration 14000, Testing net (#0)
I1013 17:56:19.786171 15780 solver.cpp:404]     Test net output #0: accuracy = 0.58475
I1013 17:56:19.786211 15780 solver.cpp:404]     Test net output #1: loss = 1.61769 (* 1 = 1.61769 loss)
I1013 17:56:19.802258 15780 solver.cpp:228] Iteration 14000, loss = 1.75842
I1013 17:56:19.802301 15780 solver.cpp:244]     Train net output #0: loss = 1.75842 (* 1 = 1.75842 loss)
I1013 17:56:19.802316 15780 sgd_solver.cpp:106] Iteration 14000, lr = 0.000671681
I1013 17:56:24.310920 15780 solver.cpp:228] Iteration 14100, loss = 1.65487
I1013 17:56:24.310969 15780 solver.cpp:244]     Train net output #0: loss = 1.65487 (* 1 = 1.65487 loss)
I1013 17:56:24.310976 15780 sgd_solver.cpp:106] Iteration 14100, lr = 0.000670204
I1013 17:56:28.831348 15780 solver.cpp:228] Iteration 14200, loss = 1.775
I1013 17:56:28.831399 15780 solver.cpp:244]     Train net output #0: loss = 1.775 (* 1 = 1.775 loss)
I1013 17:56:28.831408 15780 sgd_solver.cpp:106] Iteration 14200, lr = 0.000668733
I1013 17:56:33.329305 15780 solver.cpp:228] Iteration 14300, loss = 1.62212
I1013 17:56:33.329340 15780 solver.cpp:244]     Train net output #0: loss = 1.62212 (* 1 = 1.62212 loss)
I1013 17:56:33.329346 15780 sgd_solver.cpp:106] Iteration 14300, lr = 0.000667271
I1013 17:56:37.754549 15780 solver.cpp:228] Iteration 14400, loss = 1.7458
I1013 17:56:37.754606 15780 solver.cpp:244]     Train net output #0: loss = 1.7458 (* 1 = 1.7458 loss)
I1013 17:56:37.754614 15780 sgd_solver.cpp:106] Iteration 14400, lr = 0.000665815
I1013 17:56:42.116857 15780 solver.cpp:337] Iteration 14500, Testing net (#0)
I1013 17:56:47.020267 15780 solver.cpp:404]     Test net output #0: accuracy = 0.5885
I1013 17:56:47.020329 15780 solver.cpp:404]     Test net output #1: loss = 1.59443 (* 1 = 1.59443 loss)
I1013 17:56:47.036321 15780 solver.cpp:228] Iteration 14500, loss = 1.6967
I1013 17:56:47.036365 15780 solver.cpp:244]     Train net output #0: loss = 1.6967 (* 1 = 1.6967 loss)
I1013 17:56:47.036379 15780 sgd_solver.cpp:106] Iteration 14500, lr = 0.000664367
I1013 17:56:51.552705 15780 solver.cpp:228] Iteration 14600, loss = 1.46852
I1013 17:56:51.552778 15780 solver.cpp:244]     Train net output #0: loss = 1.46852 (* 1 = 1.46852 loss)
I1013 17:56:51.552798 15780 sgd_solver.cpp:106] Iteration 14600, lr = 0.000662927
I1013 17:56:56.006497 15780 solver.cpp:228] Iteration 14700, loss = 1.63692
I1013 17:56:56.006561 15780 solver.cpp:244]     Train net output #0: loss = 1.63692 (* 1 = 1.63692 loss)
I1013 17:56:56.006572 15780 sgd_solver.cpp:106] Iteration 14700, lr = 0.000661493
I1013 17:57:00.490140 15780 solver.cpp:228] Iteration 14800, loss = 1.51151
I1013 17:57:00.490211 15780 solver.cpp:244]     Train net output #0: loss = 1.51151 (* 1 = 1.51151 loss)
I1013 17:57:00.490221 15780 sgd_solver.cpp:106] Iteration 14800, lr = 0.000660067
I1013 17:57:04.953121 15780 solver.cpp:228] Iteration 14900, loss = 1.54668
I1013 17:57:04.953179 15780 solver.cpp:244]     Train net output #0: loss = 1.54668 (* 1 = 1.54668 loss)
I1013 17:57:04.953191 15780 sgd_solver.cpp:106] Iteration 14900, lr = 0.000658648
I1013 17:57:09.346345 15780 solver.cpp:337] Iteration 15000, Testing net (#0)
I1013 17:57:14.163197 15780 solver.cpp:404]     Test net output #0: accuracy = 0.591542
I1013 17:57:14.163259 15780 solver.cpp:404]     Test net output #1: loss = 1.58565 (* 1 = 1.58565 loss)
I1013 17:57:14.179549 15780 solver.cpp:228] Iteration 15000, loss = 1.70847
I1013 17:57:14.179576 15780 solver.cpp:244]     Train net output #0: loss = 1.70847 (* 1 = 1.70847 loss)
I1013 17:57:14.179590 15780 sgd_solver.cpp:106] Iteration 15000, lr = 0.000657236
I1013 17:57:18.633008 15780 solver.cpp:228] Iteration 15100, loss = 1.43074
I1013 17:57:18.633038 15780 solver.cpp:244]     Train net output #0: loss = 1.43074 (* 1 = 1.43074 loss)
I1013 17:57:18.633044 15780 sgd_solver.cpp:106] Iteration 15100, lr = 0.000655831
I1013 17:57:23.082411 15780 solver.cpp:228] Iteration 15200, loss = 1.62034
I1013 17:57:23.082443 15780 solver.cpp:244]     Train net output #0: loss = 1.62034 (* 1 = 1.62034 loss)
I1013 17:57:23.082449 15780 sgd_solver.cpp:106] Iteration 15200, lr = 0.000654434
I1013 17:57:27.487332 15780 solver.cpp:228] Iteration 15300, loss = 1.56464
I1013 17:57:27.487385 15780 solver.cpp:244]     Train net output #0: loss = 1.56464 (* 1 = 1.56464 loss)
I1013 17:57:27.487391 15780 sgd_solver.cpp:106] Iteration 15300, lr = 0.000653043
I1013 17:57:31.916350 15780 solver.cpp:228] Iteration 15400, loss = 1.59136
I1013 17:57:31.916398 15780 solver.cpp:244]     Train net output #0: loss = 1.59136 (* 1 = 1.59136 loss)
I1013 17:57:31.916404 15780 sgd_solver.cpp:106] Iteration 15400, lr = 0.000651659
I1013 17:57:36.274962 15780 solver.cpp:337] Iteration 15500, Testing net (#0)
I1013 17:57:36.762202 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:57:41.090591 15780 solver.cpp:404]     Test net output #0: accuracy = 0.595125
I1013 17:57:41.090641 15780 solver.cpp:404]     Test net output #1: loss = 1.56009 (* 1 = 1.56009 loss)
I1013 17:57:41.106832 15780 solver.cpp:228] Iteration 15500, loss = 1.36944
I1013 17:57:41.106879 15780 solver.cpp:244]     Train net output #0: loss = 1.36944 (* 1 = 1.36944 loss)
I1013 17:57:41.106892 15780 sgd_solver.cpp:106] Iteration 15500, lr = 0.000650281
I1013 17:57:45.571925 15780 solver.cpp:228] Iteration 15600, loss = 1.73938
I1013 17:57:45.571964 15780 solver.cpp:244]     Train net output #0: loss = 1.73938 (* 1 = 1.73938 loss)
I1013 17:57:45.571969 15780 sgd_solver.cpp:106] Iteration 15600, lr = 0.000648911
I1013 17:57:49.998106 15780 solver.cpp:228] Iteration 15700, loss = 2.02838
I1013 17:57:49.998127 15780 solver.cpp:244]     Train net output #0: loss = 2.02838 (* 1 = 2.02838 loss)
I1013 17:57:49.998133 15780 sgd_solver.cpp:106] Iteration 15700, lr = 0.000647547
I1013 17:57:54.493602 15780 solver.cpp:228] Iteration 15800, loss = 1.48205
I1013 17:57:54.493659 15780 solver.cpp:244]     Train net output #0: loss = 1.48205 (* 1 = 1.48205 loss)
I1013 17:57:54.493664 15780 sgd_solver.cpp:106] Iteration 15800, lr = 0.00064619
I1013 17:57:58.974544 15780 solver.cpp:228] Iteration 15900, loss = 1.25219
I1013 17:57:58.974599 15780 solver.cpp:244]     Train net output #0: loss = 1.25219 (* 1 = 1.25219 loss)
I1013 17:57:58.974606 15780 sgd_solver.cpp:106] Iteration 15900, lr = 0.00064484
I1013 17:58:03.413642 15780 solver.cpp:337] Iteration 16000, Testing net (#0)
I1013 17:58:08.368324 15780 solver.cpp:404]     Test net output #0: accuracy = 0.601
I1013 17:58:08.368391 15780 solver.cpp:404]     Test net output #1: loss = 1.55755 (* 1 = 1.55755 loss)
I1013 17:58:08.384511 15780 solver.cpp:228] Iteration 16000, loss = 1.55062
I1013 17:58:08.384534 15780 solver.cpp:244]     Train net output #0: loss = 1.55062 (* 1 = 1.55062 loss)
I1013 17:58:08.384546 15780 sgd_solver.cpp:106] Iteration 16000, lr = 0.000643496
I1013 17:58:12.847972 15780 solver.cpp:228] Iteration 16100, loss = 1.39178
I1013 17:58:12.848034 15780 solver.cpp:244]     Train net output #0: loss = 1.39178 (* 1 = 1.39178 loss)
I1013 17:58:12.848044 15780 sgd_solver.cpp:106] Iteration 16100, lr = 0.000642158
I1013 17:58:17.360786 15780 solver.cpp:228] Iteration 16200, loss = 1.439
I1013 17:58:17.360854 15780 solver.cpp:244]     Train net output #0: loss = 1.439 (* 1 = 1.439 loss)
I1013 17:58:17.360865 15780 sgd_solver.cpp:106] Iteration 16200, lr = 0.000640827
I1013 17:58:21.879040 15780 solver.cpp:228] Iteration 16300, loss = 1.84743
I1013 17:58:21.879079 15780 solver.cpp:244]     Train net output #0: loss = 1.84743 (* 1 = 1.84743 loss)
I1013 17:58:21.879089 15780 sgd_solver.cpp:106] Iteration 16300, lr = 0.000639503
I1013 17:58:26.398749 15780 solver.cpp:228] Iteration 16400, loss = 1.54551
I1013 17:58:26.398794 15780 solver.cpp:244]     Train net output #0: loss = 1.54551 (* 1 = 1.54551 loss)
I1013 17:58:26.398804 15780 sgd_solver.cpp:106] Iteration 16400, lr = 0.000638185
I1013 17:58:30.783207 15780 solver.cpp:337] Iteration 16500, Testing net (#0)
I1013 17:58:35.741148 15780 solver.cpp:404]     Test net output #0: accuracy = 0.607708
I1013 17:58:35.741232 15780 solver.cpp:404]     Test net output #1: loss = 1.55109 (* 1 = 1.55109 loss)
I1013 17:58:35.757516 15780 solver.cpp:228] Iteration 16500, loss = 1.65819
I1013 17:58:35.757539 15780 solver.cpp:244]     Train net output #0: loss = 1.65819 (* 1 = 1.65819 loss)
I1013 17:58:35.757555 15780 sgd_solver.cpp:106] Iteration 16500, lr = 0.000636873
I1013 17:58:40.245689 15780 solver.cpp:228] Iteration 16600, loss = 1.47226
I1013 17:58:40.245746 15780 solver.cpp:244]     Train net output #0: loss = 1.47226 (* 1 = 1.47226 loss)
I1013 17:58:40.245756 15780 sgd_solver.cpp:106] Iteration 16600, lr = 0.000635568
I1013 17:58:44.691208 15780 solver.cpp:228] Iteration 16700, loss = 1.40111
I1013 17:58:44.691246 15780 solver.cpp:244]     Train net output #0: loss = 1.40111 (* 1 = 1.40111 loss)
I1013 17:58:44.691253 15780 sgd_solver.cpp:106] Iteration 16700, lr = 0.000634268
I1013 17:58:49.093159 15780 solver.cpp:228] Iteration 16800, loss = 1.49917
I1013 17:58:49.093178 15780 solver.cpp:244]     Train net output #0: loss = 1.49917 (* 1 = 1.49917 loss)
I1013 17:58:49.093191 15780 sgd_solver.cpp:106] Iteration 16800, lr = 0.000632975
I1013 17:58:53.551759 15780 solver.cpp:228] Iteration 16900, loss = 1.75611
I1013 17:58:53.551777 15780 solver.cpp:244]     Train net output #0: loss = 1.75611 (* 1 = 1.75611 loss)
I1013 17:58:53.551784 15780 sgd_solver.cpp:106] Iteration 16900, lr = 0.000631688
I1013 17:58:58.002533 15780 solver.cpp:337] Iteration 17000, Testing net (#0)
I1013 17:58:59.371660 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 17:59:02.866168 15780 solver.cpp:404]     Test net output #0: accuracy = 0.621375
I1013 17:59:02.866191 15780 solver.cpp:404]     Test net output #1: loss = 1.49337 (* 1 = 1.49337 loss)
I1013 17:59:02.882143 15780 solver.cpp:228] Iteration 17000, loss = 1.51543
I1013 17:59:02.882201 15780 solver.cpp:244]     Train net output #0: loss = 1.51543 (* 1 = 1.51543 loss)
I1013 17:59:02.882215 15780 sgd_solver.cpp:106] Iteration 17000, lr = 0.000630407
I1013 17:59:07.379540 15780 solver.cpp:228] Iteration 17100, loss = 1.63228
I1013 17:59:07.379590 15780 solver.cpp:244]     Train net output #0: loss = 1.63228 (* 1 = 1.63228 loss)
I1013 17:59:07.379597 15780 sgd_solver.cpp:106] Iteration 17100, lr = 0.000629132
I1013 17:59:11.783023 15780 solver.cpp:228] Iteration 17200, loss = 1.69462
I1013 17:59:11.783067 15780 solver.cpp:244]     Train net output #0: loss = 1.69462 (* 1 = 1.69462 loss)
I1013 17:59:11.783074 15780 sgd_solver.cpp:106] Iteration 17200, lr = 0.000627864
I1013 17:59:16.188832 15780 solver.cpp:228] Iteration 17300, loss = 1.41884
I1013 17:59:16.188872 15780 solver.cpp:244]     Train net output #0: loss = 1.41884 (* 1 = 1.41884 loss)
I1013 17:59:16.188879 15780 sgd_solver.cpp:106] Iteration 17300, lr = 0.000626601
I1013 17:59:20.623201 15780 solver.cpp:228] Iteration 17400, loss = 1.66476
I1013 17:59:20.623270 15780 solver.cpp:244]     Train net output #0: loss = 1.66476 (* 1 = 1.66476 loss)
I1013 17:59:20.623281 15780 sgd_solver.cpp:106] Iteration 17400, lr = 0.000625344
I1013 17:59:25.057132 15780 solver.cpp:337] Iteration 17500, Testing net (#0)
I1013 17:59:30.039901 15780 solver.cpp:404]     Test net output #0: accuracy = 0.611833
I1013 17:59:30.039968 15780 solver.cpp:404]     Test net output #1: loss = 1.53147 (* 1 = 1.53147 loss)
I1013 17:59:30.054240 15780 solver.cpp:228] Iteration 17500, loss = 1.55697
I1013 17:59:30.054266 15780 solver.cpp:244]     Train net output #0: loss = 1.55697 (* 1 = 1.55697 loss)
I1013 17:59:30.054278 15780 sgd_solver.cpp:106] Iteration 17500, lr = 0.000624093
I1013 17:59:34.551195 15780 solver.cpp:228] Iteration 17600, loss = 1.60443
I1013 17:59:34.551231 15780 solver.cpp:244]     Train net output #0: loss = 1.60443 (* 1 = 1.60443 loss)
I1013 17:59:34.551237 15780 sgd_solver.cpp:106] Iteration 17600, lr = 0.000622847
I1013 17:59:39.038594 15780 solver.cpp:228] Iteration 17700, loss = 1.11801
I1013 17:59:39.038632 15780 solver.cpp:244]     Train net output #0: loss = 1.11801 (* 1 = 1.11801 loss)
I1013 17:59:39.038641 15780 sgd_solver.cpp:106] Iteration 17700, lr = 0.000621608
I1013 17:59:43.521134 15780 solver.cpp:228] Iteration 17800, loss = 1.54389
I1013 17:59:43.521179 15780 solver.cpp:244]     Train net output #0: loss = 1.54389 (* 1 = 1.54389 loss)
I1013 17:59:43.521188 15780 sgd_solver.cpp:106] Iteration 17800, lr = 0.000620374
I1013 17:59:48.020221 15780 solver.cpp:228] Iteration 17900, loss = 1.34202
I1013 17:59:48.020283 15780 solver.cpp:244]     Train net output #0: loss = 1.34202 (* 1 = 1.34202 loss)
I1013 17:59:48.020300 15780 sgd_solver.cpp:106] Iteration 17900, lr = 0.000619146
I1013 17:59:52.383580 15780 solver.cpp:337] Iteration 18000, Testing net (#0)
I1013 17:59:57.136970 15780 solver.cpp:404]     Test net output #0: accuracy = 0.629
I1013 17:59:57.137053 15780 solver.cpp:404]     Test net output #1: loss = 1.46815 (* 1 = 1.46815 loss)
I1013 17:59:57.152349 15780 solver.cpp:228] Iteration 18000, loss = 1.4181
I1013 17:59:57.152392 15780 solver.cpp:244]     Train net output #0: loss = 1.4181 (* 1 = 1.4181 loss)
I1013 17:59:57.152403 15780 sgd_solver.cpp:106] Iteration 18000, lr = 0.000617924
I1013 18:00:01.688503 15780 solver.cpp:228] Iteration 18100, loss = 1.48394
I1013 18:00:01.688541 15780 solver.cpp:244]     Train net output #0: loss = 1.48394 (* 1 = 1.48394 loss)
I1013 18:00:01.688550 15780 sgd_solver.cpp:106] Iteration 18100, lr = 0.000616707
I1013 18:00:06.218034 15780 solver.cpp:228] Iteration 18200, loss = 1.35392
I1013 18:00:06.218089 15780 solver.cpp:244]     Train net output #0: loss = 1.35392 (* 1 = 1.35392 loss)
I1013 18:00:06.218101 15780 sgd_solver.cpp:106] Iteration 18200, lr = 0.000615496
I1013 18:00:10.905854 15780 solver.cpp:228] Iteration 18300, loss = 1.37766
I1013 18:00:10.905911 15780 solver.cpp:244]     Train net output #0: loss = 1.37766 (* 1 = 1.37766 loss)
I1013 18:00:10.905921 15780 sgd_solver.cpp:106] Iteration 18300, lr = 0.00061429
I1013 18:00:18.129536 15780 solver.cpp:228] Iteration 18400, loss = 1.34432
I1013 18:00:18.129585 15780 solver.cpp:244]     Train net output #0: loss = 1.34432 (* 1 = 1.34432 loss)
I1013 18:00:18.129595 15780 sgd_solver.cpp:106] Iteration 18400, lr = 0.00061309
I1013 18:00:27.079412 15780 solver.cpp:337] Iteration 18500, Testing net (#0)
I1013 18:00:35.874173 15780 solver.cpp:404]     Test net output #0: accuracy = 0.636917
I1013 18:00:35.874215 15780 solver.cpp:404]     Test net output #1: loss = 1.43028 (* 1 = 1.43028 loss)
I1013 18:00:35.917685 15780 solver.cpp:228] Iteration 18500, loss = 1.52367
I1013 18:00:35.917731 15780 solver.cpp:244]     Train net output #0: loss = 1.52367 (* 1 = 1.52367 loss)
I1013 18:00:35.917743 15780 sgd_solver.cpp:106] Iteration 18500, lr = 0.000611895
I1013 18:00:45.323824 15780 solver.cpp:228] Iteration 18600, loss = 1.41097
I1013 18:00:45.323871 15780 solver.cpp:244]     Train net output #0: loss = 1.41097 (* 1 = 1.41097 loss)
I1013 18:00:45.323880 15780 sgd_solver.cpp:106] Iteration 18600, lr = 0.000610706
I1013 18:00:51.603801 15780 solver.cpp:228] Iteration 18700, loss = 1.4308
I1013 18:00:51.603842 15780 solver.cpp:244]     Train net output #0: loss = 1.4308 (* 1 = 1.4308 loss)
I1013 18:00:51.603850 15780 sgd_solver.cpp:106] Iteration 18700, lr = 0.000609522
I1013 18:00:52.224623 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:00:56.023313 15780 solver.cpp:228] Iteration 18800, loss = 1.47052
I1013 18:00:56.023368 15780 solver.cpp:244]     Train net output #0: loss = 1.47052 (* 1 = 1.47052 loss)
I1013 18:00:56.023378 15780 sgd_solver.cpp:106] Iteration 18800, lr = 0.000608343
I1013 18:01:00.423339 15780 solver.cpp:228] Iteration 18900, loss = 1.32451
I1013 18:01:00.423390 15780 solver.cpp:244]     Train net output #0: loss = 1.32451 (* 1 = 1.32451 loss)
I1013 18:01:00.423398 15780 sgd_solver.cpp:106] Iteration 18900, lr = 0.00060717
I1013 18:01:04.775358 15780 solver.cpp:337] Iteration 19000, Testing net (#0)
I1013 18:01:09.498739 15780 solver.cpp:404]     Test net output #0: accuracy = 0.645875
I1013 18:01:09.498783 15780 solver.cpp:404]     Test net output #1: loss = 1.39366 (* 1 = 1.39366 loss)
I1013 18:01:09.514096 15780 solver.cpp:228] Iteration 19000, loss = 1.2304
I1013 18:01:09.514128 15780 solver.cpp:244]     Train net output #0: loss = 1.2304 (* 1 = 1.2304 loss)
I1013 18:01:09.514142 15780 sgd_solver.cpp:106] Iteration 19000, lr = 0.000606002
I1013 18:01:13.968556 15780 solver.cpp:228] Iteration 19100, loss = 1.31403
I1013 18:01:13.968613 15780 solver.cpp:244]     Train net output #0: loss = 1.31403 (* 1 = 1.31403 loss)
I1013 18:01:13.968621 15780 sgd_solver.cpp:106] Iteration 19100, lr = 0.000604839
I1013 18:01:18.393877 15780 solver.cpp:228] Iteration 19200, loss = 1.44198
I1013 18:01:18.393918 15780 solver.cpp:244]     Train net output #0: loss = 1.44198 (* 1 = 1.44198 loss)
I1013 18:01:18.393925 15780 sgd_solver.cpp:106] Iteration 19200, lr = 0.000603682
I1013 18:01:22.827250 15780 solver.cpp:228] Iteration 19300, loss = 1.171
I1013 18:01:22.827323 15780 solver.cpp:244]     Train net output #0: loss = 1.171 (* 1 = 1.171 loss)
I1013 18:01:22.827332 15780 sgd_solver.cpp:106] Iteration 19300, lr = 0.000602529
I1013 18:01:27.314672 15780 solver.cpp:228] Iteration 19400, loss = 1.50891
I1013 18:01:27.314743 15780 solver.cpp:244]     Train net output #0: loss = 1.50891 (* 1 = 1.50891 loss)
I1013 18:01:27.314752 15780 sgd_solver.cpp:106] Iteration 19400, lr = 0.000601382
I1013 18:01:31.738665 15780 solver.cpp:337] Iteration 19500, Testing net (#0)
I1013 18:01:36.473631 15780 solver.cpp:404]     Test net output #0: accuracy = 0.64275
I1013 18:01:36.473691 15780 solver.cpp:404]     Test net output #1: loss = 1.39678 (* 1 = 1.39678 loss)
I1013 18:01:36.489147 15780 solver.cpp:228] Iteration 19500, loss = 1.44356
I1013 18:01:36.489190 15780 solver.cpp:244]     Train net output #0: loss = 1.44356 (* 1 = 1.44356 loss)
I1013 18:01:36.489202 15780 sgd_solver.cpp:106] Iteration 19500, lr = 0.00060024
I1013 18:01:40.938958 15780 solver.cpp:228] Iteration 19600, loss = 1.52355
I1013 18:01:40.938998 15780 solver.cpp:244]     Train net output #0: loss = 1.52355 (* 1 = 1.52355 loss)
I1013 18:01:40.939004 15780 sgd_solver.cpp:106] Iteration 19600, lr = 0.000599102
I1013 18:01:45.414537 15780 solver.cpp:228] Iteration 19700, loss = 1.42257
I1013 18:01:45.414582 15780 solver.cpp:244]     Train net output #0: loss = 1.42257 (* 1 = 1.42257 loss)
I1013 18:01:45.414587 15780 sgd_solver.cpp:106] Iteration 19700, lr = 0.00059797
I1013 18:01:49.932909 15780 solver.cpp:228] Iteration 19800, loss = 1.21935
I1013 18:01:49.932958 15780 solver.cpp:244]     Train net output #0: loss = 1.21935 (* 1 = 1.21935 loss)
I1013 18:01:49.932970 15780 sgd_solver.cpp:106] Iteration 19800, lr = 0.000596843
I1013 18:01:54.423012 15780 solver.cpp:228] Iteration 19900, loss = 1.02665
I1013 18:01:54.423056 15780 solver.cpp:244]     Train net output #0: loss = 1.02665 (* 1 = 1.02665 loss)
I1013 18:01:54.423065 15780 sgd_solver.cpp:106] Iteration 19900, lr = 0.000595721
I1013 18:01:58.819651 15780 solver.cpp:454] Snapshotting to binary proto file models/21class_pascal_plus_pre_trained_alex_net/21class_pascal_plus_pre_trained_alex_net_lr_0.001_iter_20000.caffemodel
I1013 18:01:59.597084 15780 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/21class_pascal_plus_pre_trained_alex_net/21class_pascal_plus_pre_trained_alex_net_lr_0.001_iter_20000.solverstate
I1013 18:01:59.744765 15780 solver.cpp:337] Iteration 20000, Testing net (#0)
I1013 18:02:04.145604 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:02:04.556634 15780 solver.cpp:404]     Test net output #0: accuracy = 0.646042
I1013 18:02:04.556700 15780 solver.cpp:404]     Test net output #1: loss = 1.39518 (* 1 = 1.39518 loss)
I1013 18:02:04.572454 15780 solver.cpp:228] Iteration 20000, loss = 1.39524
I1013 18:02:04.572499 15780 solver.cpp:244]     Train net output #0: loss = 1.39524 (* 1 = 1.39524 loss)
I1013 18:02:04.572542 15780 sgd_solver.cpp:106] Iteration 20000, lr = 0.000594604
I1013 18:02:09.024904 15780 solver.cpp:228] Iteration 20100, loss = 1.43187
I1013 18:02:09.024942 15780 solver.cpp:244]     Train net output #0: loss = 1.43187 (* 1 = 1.43187 loss)
I1013 18:02:09.024948 15780 sgd_solver.cpp:106] Iteration 20100, lr = 0.000593491
I1013 18:02:13.473855 15780 solver.cpp:228] Iteration 20200, loss = 1.06629
I1013 18:02:13.473872 15780 solver.cpp:244]     Train net output #0: loss = 1.06629 (* 1 = 1.06629 loss)
I1013 18:02:13.473878 15780 sgd_solver.cpp:106] Iteration 20200, lr = 0.000592384
I1013 18:02:17.907498 15780 solver.cpp:228] Iteration 20300, loss = 1.62157
I1013 18:02:17.907521 15780 solver.cpp:244]     Train net output #0: loss = 1.62157 (* 1 = 1.62157 loss)
I1013 18:02:17.907527 15780 sgd_solver.cpp:106] Iteration 20300, lr = 0.000591281
I1013 18:02:22.424974 15780 solver.cpp:228] Iteration 20400, loss = 1.1803
I1013 18:02:22.425024 15780 solver.cpp:244]     Train net output #0: loss = 1.1803 (* 1 = 1.1803 loss)
I1013 18:02:22.425034 15780 sgd_solver.cpp:106] Iteration 20400, lr = 0.000590183
I1013 18:02:26.863350 15780 solver.cpp:337] Iteration 20500, Testing net (#0)
I1013 18:02:31.593377 15780 solver.cpp:404]     Test net output #0: accuracy = 0.644291
I1013 18:02:31.593420 15780 solver.cpp:404]     Test net output #1: loss = 1.39323 (* 1 = 1.39323 loss)
I1013 18:02:31.608670 15780 solver.cpp:228] Iteration 20500, loss = 1.51049
I1013 18:02:31.608698 15780 solver.cpp:244]     Train net output #0: loss = 1.51049 (* 1 = 1.51049 loss)
I1013 18:02:31.608726 15780 sgd_solver.cpp:106] Iteration 20500, lr = 0.000589089
I1013 18:02:36.122709 15780 solver.cpp:228] Iteration 20600, loss = 1.41111
I1013 18:02:36.122805 15780 solver.cpp:244]     Train net output #0: loss = 1.41111 (* 1 = 1.41111 loss)
I1013 18:02:36.122817 15780 sgd_solver.cpp:106] Iteration 20600, lr = 0.000588001
I1013 18:02:40.534926 15780 solver.cpp:228] Iteration 20700, loss = 1.62235
I1013 18:02:40.534960 15780 solver.cpp:244]     Train net output #0: loss = 1.62235 (* 1 = 1.62235 loss)
I1013 18:02:40.534966 15780 sgd_solver.cpp:106] Iteration 20700, lr = 0.000586917
I1013 18:02:44.928536 15780 solver.cpp:228] Iteration 20800, loss = 1.28414
I1013 18:02:44.928555 15780 solver.cpp:244]     Train net output #0: loss = 1.28414 (* 1 = 1.28414 loss)
I1013 18:02:44.928561 15780 sgd_solver.cpp:106] Iteration 20800, lr = 0.000585838
I1013 18:02:49.360821 15780 solver.cpp:228] Iteration 20900, loss = 1.06237
I1013 18:02:49.360862 15780 solver.cpp:244]     Train net output #0: loss = 1.06237 (* 1 = 1.06237 loss)
I1013 18:02:49.360869 15780 sgd_solver.cpp:106] Iteration 20900, lr = 0.000584763
I1013 18:02:53.759707 15780 solver.cpp:337] Iteration 21000, Testing net (#0)
I1013 18:02:58.571426 15780 solver.cpp:404]     Test net output #0: accuracy = 0.656
I1013 18:02:58.571470 15780 solver.cpp:404]     Test net output #1: loss = 1.3425 (* 1 = 1.3425 loss)
I1013 18:02:58.586801 15780 solver.cpp:228] Iteration 21000, loss = 1.30274
I1013 18:02:58.586833 15780 solver.cpp:244]     Train net output #0: loss = 1.30274 (* 1 = 1.30274 loss)
I1013 18:02:58.586848 15780 sgd_solver.cpp:106] Iteration 21000, lr = 0.000583693
I1013 18:03:03.085798 15780 solver.cpp:228] Iteration 21100, loss = 1.24554
I1013 18:03:03.085850 15780 solver.cpp:244]     Train net output #0: loss = 1.24554 (* 1 = 1.24554 loss)
I1013 18:03:03.085860 15780 sgd_solver.cpp:106] Iteration 21100, lr = 0.000582628
I1013 18:03:07.550995 15780 solver.cpp:228] Iteration 21200, loss = 1.20586
I1013 18:03:07.551030 15780 solver.cpp:244]     Train net output #0: loss = 1.20586 (* 1 = 1.20586 loss)
I1013 18:03:07.551038 15780 sgd_solver.cpp:106] Iteration 21200, lr = 0.000581567
I1013 18:03:11.977668 15780 solver.cpp:228] Iteration 21300, loss = 1.3819
I1013 18:03:11.977705 15780 solver.cpp:244]     Train net output #0: loss = 1.3819 (* 1 = 1.3819 loss)
I1013 18:03:11.977711 15780 sgd_solver.cpp:106] Iteration 21300, lr = 0.00058051
I1013 18:03:16.411736 15780 solver.cpp:228] Iteration 21400, loss = 1.23675
I1013 18:03:16.411773 15780 solver.cpp:244]     Train net output #0: loss = 1.23675 (* 1 = 1.23675 loss)
I1013 18:03:16.411782 15780 sgd_solver.cpp:106] Iteration 21400, lr = 0.000579458
I1013 18:03:20.850991 15780 solver.cpp:337] Iteration 21500, Testing net (#0)
I1013 18:03:21.906201 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:03:25.676645 15780 solver.cpp:404]     Test net output #0: accuracy = 0.657083
I1013 18:03:25.676671 15780 solver.cpp:404]     Test net output #1: loss = 1.33257 (* 1 = 1.33257 loss)
I1013 18:03:25.691825 15780 solver.cpp:228] Iteration 21500, loss = 1.10052
I1013 18:03:25.691865 15780 solver.cpp:244]     Train net output #0: loss = 1.10052 (* 1 = 1.10052 loss)
I1013 18:03:25.691879 15780 sgd_solver.cpp:106] Iteration 21500, lr = 0.000578411
I1013 18:03:30.123430 15780 solver.cpp:228] Iteration 21600, loss = 1.49957
I1013 18:03:30.123481 15780 solver.cpp:244]     Train net output #0: loss = 1.49957 (* 1 = 1.49957 loss)
I1013 18:03:30.123489 15780 sgd_solver.cpp:106] Iteration 21600, lr = 0.000577368
I1013 18:03:34.575497 15780 solver.cpp:228] Iteration 21700, loss = 1.17573
I1013 18:03:34.575536 15780 solver.cpp:244]     Train net output #0: loss = 1.17573 (* 1 = 1.17573 loss)
I1013 18:03:34.575542 15780 sgd_solver.cpp:106] Iteration 21700, lr = 0.000576329
I1013 18:03:39.005964 15780 solver.cpp:228] Iteration 21800, loss = 1.54276
I1013 18:03:39.005991 15780 solver.cpp:244]     Train net output #0: loss = 1.54276 (* 1 = 1.54276 loss)
I1013 18:03:39.006008 15780 sgd_solver.cpp:106] Iteration 21800, lr = 0.000575295
I1013 18:03:43.436312 15780 solver.cpp:228] Iteration 21900, loss = 1.14223
I1013 18:03:43.436334 15780 solver.cpp:244]     Train net output #0: loss = 1.14223 (* 1 = 1.14223 loss)
I1013 18:03:43.436341 15780 sgd_solver.cpp:106] Iteration 21900, lr = 0.000574265
I1013 18:03:47.804613 15780 solver.cpp:337] Iteration 22000, Testing net (#0)
I1013 18:03:52.746520 15780 solver.cpp:404]     Test net output #0: accuracy = 0.662375
I1013 18:03:52.746565 15780 solver.cpp:404]     Test net output #1: loss = 1.30534 (* 1 = 1.30534 loss)
I1013 18:03:52.761893 15780 solver.cpp:228] Iteration 22000, loss = 1.21254
I1013 18:03:52.761916 15780 solver.cpp:244]     Train net output #0: loss = 1.21254 (* 1 = 1.21254 loss)
I1013 18:03:52.761931 15780 sgd_solver.cpp:106] Iteration 22000, lr = 0.000573239
I1013 18:03:57.236454 15780 solver.cpp:228] Iteration 22100, loss = 1.19834
I1013 18:03:57.236490 15780 solver.cpp:244]     Train net output #0: loss = 1.19834 (* 1 = 1.19834 loss)
I1013 18:03:57.236497 15780 sgd_solver.cpp:106] Iteration 22100, lr = 0.000572217
I1013 18:04:01.665515 15780 solver.cpp:228] Iteration 22200, loss = 1.15154
I1013 18:04:01.665561 15780 solver.cpp:244]     Train net output #0: loss = 1.15154 (* 1 = 1.15154 loss)
I1013 18:04:01.665567 15780 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005712
I1013 18:04:06.133695 15780 solver.cpp:228] Iteration 22300, loss = 1.27413
I1013 18:04:06.133728 15780 solver.cpp:244]     Train net output #0: loss = 1.27413 (* 1 = 1.27413 loss)
I1013 18:04:06.133735 15780 sgd_solver.cpp:106] Iteration 22300, lr = 0.000570187
I1013 18:04:10.629169 15780 solver.cpp:228] Iteration 22400, loss = 1.31205
I1013 18:04:10.629202 15780 solver.cpp:244]     Train net output #0: loss = 1.31205 (* 1 = 1.31205 loss)
I1013 18:04:10.629209 15780 sgd_solver.cpp:106] Iteration 22400, lr = 0.000569178
I1013 18:04:15.053290 15780 solver.cpp:337] Iteration 22500, Testing net (#0)
I1013 18:04:17.733841 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:04:20.175549 15780 solver.cpp:404]     Test net output #0: accuracy = 0.658208
I1013 18:04:20.175612 15780 solver.cpp:404]     Test net output #1: loss = 1.3094 (* 1 = 1.3094 loss)
I1013 18:04:20.190943 15780 solver.cpp:228] Iteration 22500, loss = 1.25281
I1013 18:04:20.190973 15780 solver.cpp:244]     Train net output #0: loss = 1.25281 (* 1 = 1.25281 loss)
I1013 18:04:20.190987 15780 sgd_solver.cpp:106] Iteration 22500, lr = 0.000568173
I1013 18:04:24.674052 15780 solver.cpp:228] Iteration 22600, loss = 1.19387
I1013 18:04:24.674118 15780 solver.cpp:244]     Train net output #0: loss = 1.19387 (* 1 = 1.19387 loss)
I1013 18:04:24.674130 15780 sgd_solver.cpp:106] Iteration 22600, lr = 0.000567173
I1013 18:04:29.173404 15780 solver.cpp:228] Iteration 22700, loss = 1.32597
I1013 18:04:29.173460 15780 solver.cpp:244]     Train net output #0: loss = 1.32597 (* 1 = 1.32597 loss)
I1013 18:04:29.173471 15780 sgd_solver.cpp:106] Iteration 22700, lr = 0.000566176
I1013 18:04:33.670794 15780 solver.cpp:228] Iteration 22800, loss = 1.64193
I1013 18:04:33.670858 15780 solver.cpp:244]     Train net output #0: loss = 1.64193 (* 1 = 1.64193 loss)
I1013 18:04:33.670871 15780 sgd_solver.cpp:106] Iteration 22800, lr = 0.000565184
I1013 18:04:38.089790 15780 solver.cpp:228] Iteration 22900, loss = 1.18092
I1013 18:04:38.089838 15780 solver.cpp:244]     Train net output #0: loss = 1.18092 (* 1 = 1.18092 loss)
I1013 18:04:38.089846 15780 sgd_solver.cpp:106] Iteration 22900, lr = 0.000564195
I1013 18:04:42.470613 15780 solver.cpp:337] Iteration 23000, Testing net (#0)
I1013 18:04:47.286837 15780 solver.cpp:404]     Test net output #0: accuracy = 0.663042
I1013 18:04:47.286885 15780 solver.cpp:404]     Test net output #1: loss = 1.31816 (* 1 = 1.31816 loss)
I1013 18:04:47.302316 15780 solver.cpp:228] Iteration 23000, loss = 1.04013
I1013 18:04:47.302356 15780 solver.cpp:244]     Train net output #0: loss = 1.04013 (* 1 = 1.04013 loss)
I1013 18:04:47.302371 15780 sgd_solver.cpp:106] Iteration 23000, lr = 0.000563211
I1013 18:04:51.694366 15780 solver.cpp:228] Iteration 23100, loss = 1.07506
I1013 18:04:51.694468 15780 solver.cpp:244]     Train net output #0: loss = 1.07506 (* 1 = 1.07506 loss)
I1013 18:04:51.694480 15780 sgd_solver.cpp:106] Iteration 23100, lr = 0.000562231
I1013 18:04:56.189997 15780 solver.cpp:228] Iteration 23200, loss = 1.08636
I1013 18:04:56.190078 15780 solver.cpp:244]     Train net output #0: loss = 1.08636 (* 1 = 1.08636 loss)
I1013 18:04:56.190089 15780 sgd_solver.cpp:106] Iteration 23200, lr = 0.000561254
I1013 18:05:00.625715 15780 solver.cpp:228] Iteration 23300, loss = 1.1033
I1013 18:05:00.625756 15780 solver.cpp:244]     Train net output #0: loss = 1.1033 (* 1 = 1.1033 loss)
I1013 18:05:00.625761 15780 sgd_solver.cpp:106] Iteration 23300, lr = 0.000560282
I1013 18:05:05.031497 15780 solver.cpp:228] Iteration 23400, loss = 1.34954
I1013 18:05:05.031554 15780 solver.cpp:244]     Train net output #0: loss = 1.34954 (* 1 = 1.34954 loss)
I1013 18:05:05.031561 15780 sgd_solver.cpp:106] Iteration 23400, lr = 0.000559313
I1013 18:05:09.441876 15780 solver.cpp:337] Iteration 23500, Testing net (#0)
I1013 18:05:14.238641 15780 solver.cpp:404]     Test net output #0: accuracy = 0.663458
I1013 18:05:14.238679 15780 solver.cpp:404]     Test net output #1: loss = 1.28653 (* 1 = 1.28653 loss)
I1013 18:05:14.253883 15780 solver.cpp:228] Iteration 23500, loss = 0.952467
I1013 18:05:14.253917 15780 solver.cpp:244]     Train net output #0: loss = 0.952467 (* 1 = 0.952467 loss)
I1013 18:05:14.253931 15780 sgd_solver.cpp:106] Iteration 23500, lr = 0.000558349
I1013 18:05:18.726830 15780 solver.cpp:228] Iteration 23600, loss = 1.37318
I1013 18:05:18.726864 15780 solver.cpp:244]     Train net output #0: loss = 1.37318 (* 1 = 1.37318 loss)
I1013 18:05:18.726871 15780 sgd_solver.cpp:106] Iteration 23600, lr = 0.000557388
I1013 18:05:23.204546 15780 solver.cpp:228] Iteration 23700, loss = 1.19871
I1013 18:05:23.204605 15780 solver.cpp:244]     Train net output #0: loss = 1.19871 (* 1 = 1.19871 loss)
I1013 18:05:23.204615 15780 sgd_solver.cpp:106] Iteration 23700, lr = 0.000556431
I1013 18:05:27.694463 15780 solver.cpp:228] Iteration 23800, loss = 1.31062
I1013 18:05:27.694548 15780 solver.cpp:244]     Train net output #0: loss = 1.31062 (* 1 = 1.31062 loss)
I1013 18:05:27.694560 15780 sgd_solver.cpp:106] Iteration 23800, lr = 0.000555478
I1013 18:05:32.178809 15780 solver.cpp:228] Iteration 23900, loss = 1.19727
I1013 18:05:32.178845 15780 solver.cpp:244]     Train net output #0: loss = 1.19727 (* 1 = 1.19727 loss)
I1013 18:05:32.178851 15780 sgd_solver.cpp:106] Iteration 23900, lr = 0.000554529
I1013 18:05:36.607219 15780 solver.cpp:337] Iteration 24000, Testing net (#0)
I1013 18:05:39.973062 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:05:41.329493 15780 solver.cpp:404]     Test net output #0: accuracy = 0.657792
I1013 18:05:41.329546 15780 solver.cpp:404]     Test net output #1: loss = 1.31461 (* 1 = 1.31461 loss)
I1013 18:05:41.345263 15780 solver.cpp:228] Iteration 24000, loss = 1.14676
I1013 18:05:41.345314 15780 solver.cpp:244]     Train net output #0: loss = 1.14676 (* 1 = 1.14676 loss)
I1013 18:05:41.345326 15780 sgd_solver.cpp:106] Iteration 24000, lr = 0.000553583
I1013 18:05:45.802503 15780 solver.cpp:228] Iteration 24100, loss = 1.18633
I1013 18:05:45.802548 15780 solver.cpp:244]     Train net output #0: loss = 1.18633 (* 1 = 1.18633 loss)
I1013 18:05:45.802554 15780 sgd_solver.cpp:106] Iteration 24100, lr = 0.000552642
I1013 18:05:50.239708 15780 solver.cpp:228] Iteration 24200, loss = 1.15425
I1013 18:05:50.239743 15780 solver.cpp:244]     Train net output #0: loss = 1.15425 (* 1 = 1.15425 loss)
I1013 18:05:50.239750 15780 sgd_solver.cpp:106] Iteration 24200, lr = 0.000551704
I1013 18:05:54.681694 15780 solver.cpp:228] Iteration 24300, loss = 1.22184
I1013 18:05:54.681758 15780 solver.cpp:244]     Train net output #0: loss = 1.22184 (* 1 = 1.22184 loss)
I1013 18:05:54.681771 15780 sgd_solver.cpp:106] Iteration 24300, lr = 0.000550769
I1013 18:05:59.109972 15780 solver.cpp:228] Iteration 24400, loss = 1.20633
I1013 18:05:59.110007 15780 solver.cpp:244]     Train net output #0: loss = 1.20633 (* 1 = 1.20633 loss)
I1013 18:05:59.110018 15780 sgd_solver.cpp:106] Iteration 24400, lr = 0.000549839
I1013 18:06:03.505177 15780 solver.cpp:337] Iteration 24500, Testing net (#0)
I1013 18:06:08.521819 15780 solver.cpp:404]     Test net output #0: accuracy = 0.65
I1013 18:06:08.521878 15780 solver.cpp:404]     Test net output #1: loss = 1.34826 (* 1 = 1.34826 loss)
I1013 18:06:08.537919 15780 solver.cpp:228] Iteration 24500, loss = 1.15186
I1013 18:06:08.537973 15780 solver.cpp:244]     Train net output #0: loss = 1.15186 (* 1 = 1.15186 loss)
I1013 18:06:08.537998 15780 sgd_solver.cpp:106] Iteration 24500, lr = 0.000548912
I1013 18:06:13.037492 15780 solver.cpp:228] Iteration 24600, loss = 1.06617
I1013 18:06:13.037535 15780 solver.cpp:244]     Train net output #0: loss = 1.06617 (* 1 = 1.06617 loss)
I1013 18:06:13.037541 15780 sgd_solver.cpp:106] Iteration 24600, lr = 0.000547988
I1013 18:06:17.454931 15780 solver.cpp:228] Iteration 24700, loss = 1.21092
I1013 18:06:17.454952 15780 solver.cpp:244]     Train net output #0: loss = 1.21092 (* 1 = 1.21092 loss)
I1013 18:06:17.454958 15780 sgd_solver.cpp:106] Iteration 24700, lr = 0.000547069
I1013 18:06:21.899018 15780 solver.cpp:228] Iteration 24800, loss = 1.16844
I1013 18:06:21.899037 15780 solver.cpp:244]     Train net output #0: loss = 1.16844 (* 1 = 1.16844 loss)
I1013 18:06:21.899044 15780 sgd_solver.cpp:106] Iteration 24800, lr = 0.000546153
I1013 18:06:26.338433 15780 solver.cpp:228] Iteration 24900, loss = 1.30789
I1013 18:06:26.338480 15780 solver.cpp:244]     Train net output #0: loss = 1.30789 (* 1 = 1.30789 loss)
I1013 18:06:26.338487 15780 sgd_solver.cpp:106] Iteration 24900, lr = 0.00054524
I1013 18:06:30.741351 15780 solver.cpp:337] Iteration 25000, Testing net (#0)
I1013 18:06:35.872599 15780 solver.cpp:404]     Test net output #0: accuracy = 0.667125
I1013 18:06:35.872658 15780 solver.cpp:404]     Test net output #1: loss = 1.27067 (* 1 = 1.27067 loss)
I1013 18:06:35.888763 15780 solver.cpp:228] Iteration 25000, loss = 1.26288
I1013 18:06:35.888809 15780 solver.cpp:244]     Train net output #0: loss = 1.26288 (* 1 = 1.26288 loss)
I1013 18:06:35.888824 15780 sgd_solver.cpp:106] Iteration 25000, lr = 0.000544331
I1013 18:06:40.299182 15780 solver.cpp:228] Iteration 25100, loss = 1.13844
I1013 18:06:40.299237 15780 solver.cpp:244]     Train net output #0: loss = 1.13844 (* 1 = 1.13844 loss)
I1013 18:06:40.299244 15780 sgd_solver.cpp:106] Iteration 25100, lr = 0.000543426
I1013 18:06:44.689716 15780 solver.cpp:228] Iteration 25200, loss = 1.11135
I1013 18:06:44.689759 15780 solver.cpp:244]     Train net output #0: loss = 1.11135 (* 1 = 1.11135 loss)
I1013 18:06:44.689766 15780 sgd_solver.cpp:106] Iteration 25200, lr = 0.000542524
I1013 18:06:49.075892 15780 solver.cpp:228] Iteration 25300, loss = 1.34248
I1013 18:06:49.075937 15780 solver.cpp:244]     Train net output #0: loss = 1.34248 (* 1 = 1.34248 loss)
I1013 18:06:49.075944 15780 sgd_solver.cpp:106] Iteration 25300, lr = 0.000541625
I1013 18:06:53.468343 15780 solver.cpp:228] Iteration 25400, loss = 0.996283
I1013 18:06:53.468402 15780 solver.cpp:244]     Train net output #0: loss = 0.996283 (* 1 = 0.996283 loss)
I1013 18:06:53.468413 15780 sgd_solver.cpp:106] Iteration 25400, lr = 0.00054073
I1013 18:06:55.094136 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:06:57.819977 15780 solver.cpp:337] Iteration 25500, Testing net (#0)
I1013 18:07:02.716898 15780 solver.cpp:404]     Test net output #0: accuracy = 0.673042
I1013 18:07:02.716965 15780 solver.cpp:404]     Test net output #1: loss = 1.23543 (* 1 = 1.23543 loss)
I1013 18:07:02.733067 15780 solver.cpp:228] Iteration 25500, loss = 1.05742
I1013 18:07:02.733124 15780 solver.cpp:244]     Train net output #0: loss = 1.05742 (* 1 = 1.05742 loss)
I1013 18:07:02.733150 15780 sgd_solver.cpp:106] Iteration 25500, lr = 0.000539839
I1013 18:07:07.189771 15780 solver.cpp:228] Iteration 25600, loss = 1.13454
I1013 18:07:07.189827 15780 solver.cpp:244]     Train net output #0: loss = 1.13454 (* 1 = 1.13454 loss)
I1013 18:07:07.189834 15780 sgd_solver.cpp:106] Iteration 25600, lr = 0.00053895
I1013 18:07:11.588163 15780 solver.cpp:228] Iteration 25700, loss = 1.03808
I1013 18:07:11.588219 15780 solver.cpp:244]     Train net output #0: loss = 1.03808 (* 1 = 1.03808 loss)
I1013 18:07:11.588227 15780 sgd_solver.cpp:106] Iteration 25700, lr = 0.000538066
I1013 18:07:16.062669 15780 solver.cpp:228] Iteration 25800, loss = 1.071
I1013 18:07:16.062716 15780 solver.cpp:244]     Train net output #0: loss = 1.071 (* 1 = 1.071 loss)
I1013 18:07:16.062721 15780 sgd_solver.cpp:106] Iteration 25800, lr = 0.000537184
I1013 18:07:20.521852 15780 solver.cpp:228] Iteration 25900, loss = 1.15267
I1013 18:07:20.521908 15780 solver.cpp:244]     Train net output #0: loss = 1.15267 (* 1 = 1.15267 loss)
I1013 18:07:20.521917 15780 sgd_solver.cpp:106] Iteration 25900, lr = 0.000536306
I1013 18:07:24.916538 15780 solver.cpp:337] Iteration 26000, Testing net (#0)
I1013 18:07:29.838620 15780 solver.cpp:404]     Test net output #0: accuracy = 0.67375
I1013 18:07:29.838667 15780 solver.cpp:404]     Test net output #1: loss = 1.22712 (* 1 = 1.22712 loss)
I1013 18:07:29.853821 15780 solver.cpp:228] Iteration 26000, loss = 0.963921
I1013 18:07:29.853854 15780 solver.cpp:244]     Train net output #0: loss = 0.963921 (* 1 = 0.963921 loss)
I1013 18:07:29.853871 15780 sgd_solver.cpp:106] Iteration 26000, lr = 0.000535432
I1013 18:07:34.334841 15780 solver.cpp:228] Iteration 26100, loss = 1.12267
I1013 18:07:34.334890 15780 solver.cpp:244]     Train net output #0: loss = 1.12267 (* 1 = 1.12267 loss)
I1013 18:07:34.334897 15780 sgd_solver.cpp:106] Iteration 26100, lr = 0.00053456
I1013 18:07:38.743212 15780 solver.cpp:228] Iteration 26200, loss = 1.04508
I1013 18:07:38.743232 15780 solver.cpp:244]     Train net output #0: loss = 1.04508 (* 1 = 1.04508 loss)
I1013 18:07:38.743237 15780 sgd_solver.cpp:106] Iteration 26200, lr = 0.000533692
I1013 18:07:43.204013 15780 solver.cpp:228] Iteration 26300, loss = 1.00434
I1013 18:07:43.204058 15780 solver.cpp:244]     Train net output #0: loss = 1.00434 (* 1 = 1.00434 loss)
I1013 18:07:43.204068 15780 sgd_solver.cpp:106] Iteration 26300, lr = 0.000532828
I1013 18:07:47.684502 15780 solver.cpp:228] Iteration 26400, loss = 1.03767
I1013 18:07:47.684540 15780 solver.cpp:244]     Train net output #0: loss = 1.03767 (* 1 = 1.03767 loss)
I1013 18:07:47.684545 15780 sgd_solver.cpp:106] Iteration 26400, lr = 0.000531966
I1013 18:07:52.107841 15780 solver.cpp:337] Iteration 26500, Testing net (#0)
I1013 18:07:56.700760 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:07:57.104537 15780 solver.cpp:404]     Test net output #0: accuracy = 0.671958
I1013 18:07:57.104581 15780 solver.cpp:404]     Test net output #1: loss = 1.24224 (* 1 = 1.24224 loss)
I1013 18:07:57.119109 15780 solver.cpp:228] Iteration 26500, loss = 0.918956
I1013 18:07:57.119141 15780 solver.cpp:244]     Train net output #0: loss = 0.918956 (* 1 = 0.918956 loss)
I1013 18:07:57.119156 15780 sgd_solver.cpp:106] Iteration 26500, lr = 0.000531108
I1013 18:08:01.505384 15780 solver.cpp:228] Iteration 26600, loss = 1.0327
I1013 18:08:01.505439 15780 solver.cpp:244]     Train net output #0: loss = 1.0327 (* 1 = 1.0327 loss)
I1013 18:08:01.505445 15780 sgd_solver.cpp:106] Iteration 26600, lr = 0.000530253
I1013 18:08:05.952627 15780 solver.cpp:228] Iteration 26700, loss = 0.999576
I1013 18:08:05.952682 15780 solver.cpp:244]     Train net output #0: loss = 0.999576 (* 1 = 0.999576 loss)
I1013 18:08:05.952689 15780 sgd_solver.cpp:106] Iteration 26700, lr = 0.000529401
I1013 18:08:10.394275 15780 solver.cpp:228] Iteration 26800, loss = 1.13535
I1013 18:08:10.394328 15780 solver.cpp:244]     Train net output #0: loss = 1.13535 (* 1 = 1.13535 loss)
I1013 18:08:10.394335 15780 sgd_solver.cpp:106] Iteration 26800, lr = 0.000528553
I1013 18:08:14.833453 15780 solver.cpp:228] Iteration 26900, loss = 1.17774
I1013 18:08:14.833509 15780 solver.cpp:244]     Train net output #0: loss = 1.17774 (* 1 = 1.17774 loss)
I1013 18:08:14.833518 15780 sgd_solver.cpp:106] Iteration 26900, lr = 0.000527707
I1013 18:08:19.220552 15780 solver.cpp:337] Iteration 27000, Testing net (#0)
I1013 18:08:24.197916 15780 solver.cpp:404]     Test net output #0: accuracy = 0.677292
I1013 18:08:24.197978 15780 solver.cpp:404]     Test net output #1: loss = 1.2124 (* 1 = 1.2124 loss)
I1013 18:08:24.214141 15780 solver.cpp:228] Iteration 27000, loss = 1.22772
I1013 18:08:24.214191 15780 solver.cpp:244]     Train net output #0: loss = 1.22772 (* 1 = 1.22772 loss)
I1013 18:08:24.214206 15780 sgd_solver.cpp:106] Iteration 27000, lr = 0.000526865
I1013 18:08:28.706604 15780 solver.cpp:228] Iteration 27100, loss = 0.985932
I1013 18:08:28.706655 15780 solver.cpp:244]     Train net output #0: loss = 0.985932 (* 1 = 0.985932 loss)
I1013 18:08:28.706673 15780 sgd_solver.cpp:106] Iteration 27100, lr = 0.000526026
I1013 18:08:33.172137 15780 solver.cpp:228] Iteration 27200, loss = 1.03792
I1013 18:08:33.172168 15780 solver.cpp:244]     Train net output #0: loss = 1.03792 (* 1 = 1.03792 loss)
I1013 18:08:33.172173 15780 sgd_solver.cpp:106] Iteration 27200, lr = 0.000525189
I1013 18:08:37.655876 15780 solver.cpp:228] Iteration 27300, loss = 1.14006
I1013 18:08:37.655927 15780 solver.cpp:244]     Train net output #0: loss = 1.14006 (* 1 = 1.14006 loss)
I1013 18:08:37.655935 15780 sgd_solver.cpp:106] Iteration 27300, lr = 0.000524356
I1013 18:08:42.073190 15780 solver.cpp:228] Iteration 27400, loss = 1.10715
I1013 18:08:42.073236 15780 solver.cpp:244]     Train net output #0: loss = 1.10715 (* 1 = 1.10715 loss)
I1013 18:08:42.073246 15780 sgd_solver.cpp:106] Iteration 27400, lr = 0.000523527
I1013 18:08:46.510888 15780 solver.cpp:337] Iteration 27500, Testing net (#0)
I1013 18:08:51.434499 15780 solver.cpp:404]     Test net output #0: accuracy = 0.672833
I1013 18:08:51.434571 15780 solver.cpp:404]     Test net output #1: loss = 1.21885 (* 1 = 1.21885 loss)
I1013 18:08:51.450542 15780 solver.cpp:228] Iteration 27500, loss = 0.954177
I1013 18:08:51.450584 15780 solver.cpp:244]     Train net output #0: loss = 0.954177 (* 1 = 0.954177 loss)
I1013 18:08:51.450620 15780 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005227
I1013 18:08:55.939236 15780 solver.cpp:228] Iteration 27600, loss = 1.10653
I1013 18:08:55.939292 15780 solver.cpp:244]     Train net output #0: loss = 1.10653 (* 1 = 1.10653 loss)
I1013 18:08:55.939312 15780 sgd_solver.cpp:106] Iteration 27600, lr = 0.000521876
I1013 18:09:00.430625 15780 solver.cpp:228] Iteration 27700, loss = 0.931361
I1013 18:09:00.430660 15780 solver.cpp:244]     Train net output #0: loss = 0.931361 (* 1 = 0.931361 loss)
I1013 18:09:00.430665 15780 sgd_solver.cpp:106] Iteration 27700, lr = 0.000521055
I1013 18:09:04.882380 15780 solver.cpp:228] Iteration 27800, loss = 1.14244
I1013 18:09:04.882443 15780 solver.cpp:244]     Train net output #0: loss = 1.14244 (* 1 = 1.14244 loss)
I1013 18:09:04.882454 15780 sgd_solver.cpp:106] Iteration 27800, lr = 0.000520237
I1013 18:09:09.292042 15780 solver.cpp:228] Iteration 27900, loss = 0.938018
I1013 18:09:09.292098 15780 solver.cpp:244]     Train net output #0: loss = 0.938018 (* 1 = 0.938018 loss)
I1013 18:09:09.292145 15780 sgd_solver.cpp:106] Iteration 27900, lr = 0.000519423
I1013 18:09:13.656070 15780 solver.cpp:337] Iteration 28000, Testing net (#0)
I1013 18:09:17.775782 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:09:18.575333 15780 solver.cpp:404]     Test net output #0: accuracy = 0.679333
I1013 18:09:18.575381 15780 solver.cpp:404]     Test net output #1: loss = 1.1937 (* 1 = 1.1937 loss)
I1013 18:09:18.591243 15780 solver.cpp:228] Iteration 28000, loss = 1.15973
I1013 18:09:18.591266 15780 solver.cpp:244]     Train net output #0: loss = 1.15973 (* 1 = 1.15973 loss)
I1013 18:09:18.591281 15780 sgd_solver.cpp:106] Iteration 28000, lr = 0.000518611
I1013 18:09:23.068841 15780 solver.cpp:228] Iteration 28100, loss = 0.898709
I1013 18:09:23.068902 15780 solver.cpp:244]     Train net output #0: loss = 0.898709 (* 1 = 0.898709 loss)
I1013 18:09:23.068910 15780 sgd_solver.cpp:106] Iteration 28100, lr = 0.000517802
I1013 18:09:27.540920 15780 solver.cpp:228] Iteration 28200, loss = 0.964713
I1013 18:09:27.540946 15780 solver.cpp:244]     Train net output #0: loss = 0.964713 (* 1 = 0.964713 loss)
I1013 18:09:27.540953 15780 sgd_solver.cpp:106] Iteration 28200, lr = 0.000516996
I1013 18:09:32.028494 15780 solver.cpp:228] Iteration 28300, loss = 1.11551
I1013 18:09:32.028540 15780 solver.cpp:244]     Train net output #0: loss = 1.11551 (* 1 = 1.11551 loss)
I1013 18:09:32.028550 15780 sgd_solver.cpp:106] Iteration 28300, lr = 0.000516193
I1013 18:09:36.486331 15780 solver.cpp:228] Iteration 28400, loss = 0.983487
I1013 18:09:36.486380 15780 solver.cpp:244]     Train net output #0: loss = 0.983487 (* 1 = 0.983487 loss)
I1013 18:09:36.486387 15780 sgd_solver.cpp:106] Iteration 28400, lr = 0.000515393
I1013 18:09:40.903837 15780 solver.cpp:337] Iteration 28500, Testing net (#0)
I1013 18:09:45.878438 15780 solver.cpp:404]     Test net output #0: accuracy = 0.678875
I1013 18:09:45.878505 15780 solver.cpp:404]     Test net output #1: loss = 1.19174 (* 1 = 1.19174 loss)
I1013 18:09:45.892750 15780 solver.cpp:228] Iteration 28500, loss = 1.02536
I1013 18:09:45.892771 15780 solver.cpp:244]     Train net output #0: loss = 1.02536 (* 1 = 1.02536 loss)
I1013 18:09:45.892782 15780 sgd_solver.cpp:106] Iteration 28500, lr = 0.000514596
I1013 18:09:50.342803 15780 solver.cpp:228] Iteration 28600, loss = 0.977335
I1013 18:09:50.342836 15780 solver.cpp:244]     Train net output #0: loss = 0.977335 (* 1 = 0.977335 loss)
I1013 18:09:50.342842 15780 sgd_solver.cpp:106] Iteration 28600, lr = 0.000513801
I1013 18:09:54.769238 15780 solver.cpp:228] Iteration 28700, loss = 1.23327
I1013 18:09:54.769275 15780 solver.cpp:244]     Train net output #0: loss = 1.23327 (* 1 = 1.23327 loss)
I1013 18:09:54.769281 15780 sgd_solver.cpp:106] Iteration 28700, lr = 0.00051301
I1013 18:09:59.229727 15780 solver.cpp:228] Iteration 28800, loss = 1.03565
I1013 18:09:59.229758 15780 solver.cpp:244]     Train net output #0: loss = 1.03565 (* 1 = 1.03565 loss)
I1013 18:09:59.229765 15780 sgd_solver.cpp:106] Iteration 28800, lr = 0.000512221
I1013 18:10:03.717489 15780 solver.cpp:228] Iteration 28900, loss = 1.08367
I1013 18:10:03.717524 15780 solver.cpp:244]     Train net output #0: loss = 1.08367 (* 1 = 1.08367 loss)
I1013 18:10:03.717530 15780 sgd_solver.cpp:106] Iteration 28900, lr = 0.000511436
I1013 18:10:08.151885 15780 solver.cpp:337] Iteration 29000, Testing net (#0)
I1013 18:10:13.039727 15780 solver.cpp:404]     Test net output #0: accuracy = 0.680916
I1013 18:10:13.039769 15780 solver.cpp:404]     Test net output #1: loss = 1.1816 (* 1 = 1.1816 loss)
I1013 18:10:13.055552 15780 solver.cpp:228] Iteration 29000, loss = 0.71967
I1013 18:10:13.055575 15780 solver.cpp:244]     Train net output #0: loss = 0.71967 (* 1 = 0.71967 loss)
I1013 18:10:13.055589 15780 sgd_solver.cpp:106] Iteration 29000, lr = 0.000510653
I1013 18:10:17.514662 15780 solver.cpp:228] Iteration 29100, loss = 0.878121
I1013 18:10:17.514708 15780 solver.cpp:244]     Train net output #0: loss = 0.878121 (* 1 = 0.878121 loss)
I1013 18:10:17.514715 15780 sgd_solver.cpp:106] Iteration 29100, lr = 0.000509872
I1013 18:10:21.943208 15780 solver.cpp:228] Iteration 29200, loss = 1.04482
I1013 18:10:21.943265 15780 solver.cpp:244]     Train net output #0: loss = 1.04482 (* 1 = 1.04482 loss)
I1013 18:10:21.943274 15780 sgd_solver.cpp:106] Iteration 29200, lr = 0.000509095
I1013 18:10:26.360946 15780 solver.cpp:228] Iteration 29300, loss = 1.18714
I1013 18:10:26.360980 15780 solver.cpp:244]     Train net output #0: loss = 1.18714 (* 1 = 1.18714 loss)
I1013 18:10:26.360986 15780 sgd_solver.cpp:106] Iteration 29300, lr = 0.00050832
I1013 18:10:30.751195 15780 solver.cpp:228] Iteration 29400, loss = 1.05472
I1013 18:10:30.751214 15780 solver.cpp:244]     Train net output #0: loss = 1.05472 (* 1 = 1.05472 loss)
I1013 18:10:30.751219 15780 sgd_solver.cpp:106] Iteration 29400, lr = 0.000507548
I1013 18:10:35.127214 15780 solver.cpp:337] Iteration 29500, Testing net (#0)
I1013 18:10:35.982342 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:10:40.121631 15780 solver.cpp:404]     Test net output #0: accuracy = 0.677792
I1013 18:10:40.121682 15780 solver.cpp:404]     Test net output #1: loss = 1.21598 (* 1 = 1.21598 loss)
I1013 18:10:40.137405 15780 solver.cpp:228] Iteration 29500, loss = 0.944517
I1013 18:10:40.137428 15780 solver.cpp:244]     Train net output #0: loss = 0.944517 (* 1 = 0.944517 loss)
I1013 18:10:40.137440 15780 sgd_solver.cpp:106] Iteration 29500, lr = 0.000506779
I1013 18:10:44.589238 15780 solver.cpp:228] Iteration 29600, loss = 0.961194
I1013 18:10:44.589289 15780 solver.cpp:244]     Train net output #0: loss = 0.961194 (* 1 = 0.961194 loss)
I1013 18:10:44.589299 15780 sgd_solver.cpp:106] Iteration 29600, lr = 0.000506013
I1013 18:10:49.060158 15780 solver.cpp:228] Iteration 29700, loss = 0.775196
I1013 18:10:49.060220 15780 solver.cpp:244]     Train net output #0: loss = 0.775196 (* 1 = 0.775196 loss)
I1013 18:10:49.060230 15780 sgd_solver.cpp:106] Iteration 29700, lr = 0.000505249
I1013 18:10:53.479581 15780 solver.cpp:228] Iteration 29800, loss = 0.860123
I1013 18:10:53.479637 15780 solver.cpp:244]     Train net output #0: loss = 0.860123 (* 1 = 0.860123 loss)
I1013 18:10:53.479648 15780 sgd_solver.cpp:106] Iteration 29800, lr = 0.000504488
I1013 18:10:57.935878 15780 solver.cpp:228] Iteration 29900, loss = 0.964425
I1013 18:10:57.935914 15780 solver.cpp:244]     Train net output #0: loss = 0.964425 (* 1 = 0.964425 loss)
I1013 18:10:57.935921 15780 sgd_solver.cpp:106] Iteration 29900, lr = 0.000503729
I1013 18:11:02.352502 15780 solver.cpp:337] Iteration 30000, Testing net (#0)
I1013 18:11:07.594789 15780 solver.cpp:404]     Test net output #0: accuracy = 0.645458
I1013 18:11:07.594842 15780 solver.cpp:404]     Test net output #1: loss = 1.33995 (* 1 = 1.33995 loss)
I1013 18:11:07.610332 15780 solver.cpp:228] Iteration 30000, loss = 1.29211
I1013 18:11:07.610380 15780 solver.cpp:244]     Train net output #0: loss = 1.29211 (* 1 = 1.29211 loss)
I1013 18:11:07.610391 15780 sgd_solver.cpp:106] Iteration 30000, lr = 0.000502973
I1013 18:11:12.095943 15780 solver.cpp:228] Iteration 30100, loss = 1.03721
I1013 18:11:12.095993 15780 solver.cpp:244]     Train net output #0: loss = 1.03721 (* 1 = 1.03721 loss)
I1013 18:11:12.096001 15780 sgd_solver.cpp:106] Iteration 30100, lr = 0.00050222
I1013 18:11:16.582840 15780 solver.cpp:228] Iteration 30200, loss = 0.782859
I1013 18:11:16.582893 15780 solver.cpp:244]     Train net output #0: loss = 0.782859 (* 1 = 0.782859 loss)
I1013 18:11:16.582902 15780 sgd_solver.cpp:106] Iteration 30200, lr = 0.00050147
I1013 18:11:21.056654 15780 solver.cpp:228] Iteration 30300, loss = 1.08101
I1013 18:11:21.056697 15780 solver.cpp:244]     Train net output #0: loss = 1.08101 (* 1 = 1.08101 loss)
I1013 18:11:21.056707 15780 sgd_solver.cpp:106] Iteration 30300, lr = 0.000500722
I1013 18:11:25.529911 15780 solver.cpp:228] Iteration 30400, loss = 1.00996
I1013 18:11:25.529961 15780 solver.cpp:244]     Train net output #0: loss = 1.00996 (* 1 = 1.00996 loss)
I1013 18:11:25.529970 15780 sgd_solver.cpp:106] Iteration 30400, lr = 0.000499977
I1013 18:11:29.972576 15780 solver.cpp:337] Iteration 30500, Testing net (#0)
I1013 18:11:35.075086 15780 solver.cpp:404]     Test net output #0: accuracy = 0.676834
I1013 18:11:35.075145 15780 solver.cpp:404]     Test net output #1: loss = 1.20596 (* 1 = 1.20596 loss)
I1013 18:11:35.091426 15780 solver.cpp:228] Iteration 30500, loss = 0.743432
I1013 18:11:35.091471 15780 solver.cpp:244]     Train net output #0: loss = 0.743432 (* 1 = 0.743432 loss)
I1013 18:11:35.091488 15780 sgd_solver.cpp:106] Iteration 30500, lr = 0.000499234
I1013 18:11:39.566711 15780 solver.cpp:228] Iteration 30600, loss = 0.931783
I1013 18:11:39.566769 15780 solver.cpp:244]     Train net output #0: loss = 0.931783 (* 1 = 0.931783 loss)
I1013 18:11:39.566778 15780 sgd_solver.cpp:106] Iteration 30600, lr = 0.000498494
I1013 18:11:44.032079 15780 solver.cpp:228] Iteration 30700, loss = 0.677863
I1013 18:11:44.032131 15780 solver.cpp:244]     Train net output #0: loss = 0.677863 (* 1 = 0.677863 loss)
I1013 18:11:44.032140 15780 sgd_solver.cpp:106] Iteration 30700, lr = 0.000497756
I1013 18:11:48.508558 15780 solver.cpp:228] Iteration 30800, loss = 0.950396
I1013 18:11:48.508615 15780 solver.cpp:244]     Train net output #0: loss = 0.950396 (* 1 = 0.950396 loss)
I1013 18:11:48.508626 15780 sgd_solver.cpp:106] Iteration 30800, lr = 0.000497021
I1013 18:11:52.980335 15780 solver.cpp:228] Iteration 30900, loss = 1.0257
I1013 18:11:52.980371 15780 solver.cpp:244]     Train net output #0: loss = 1.0257 (* 1 = 1.0257 loss)
I1013 18:11:52.980378 15780 sgd_solver.cpp:106] Iteration 30900, lr = 0.000496288
I1013 18:11:57.384418 15780 solver.cpp:337] Iteration 31000, Testing net (#0)
I1013 18:11:57.912080 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:12:02.935523 15780 solver.cpp:404]     Test net output #0: accuracy = 0.681375
I1013 18:12:02.935575 15780 solver.cpp:404]     Test net output #1: loss = 1.23514 (* 1 = 1.23514 loss)
I1013 18:12:02.949916 15780 solver.cpp:228] Iteration 31000, loss = 0.903768
I1013 18:12:02.949964 15780 solver.cpp:244]     Train net output #0: loss = 0.903768 (* 1 = 0.903768 loss)
I1013 18:12:02.949975 15780 sgd_solver.cpp:106] Iteration 31000, lr = 0.000495558
I1013 18:12:07.409021 15780 solver.cpp:228] Iteration 31100, loss = 1.07142
I1013 18:12:07.409072 15780 solver.cpp:244]     Train net output #0: loss = 1.07142 (* 1 = 1.07142 loss)
I1013 18:12:07.409081 15780 sgd_solver.cpp:106] Iteration 31100, lr = 0.000494831
I1013 18:12:11.895064 15780 solver.cpp:228] Iteration 31200, loss = 0.91447
I1013 18:12:11.895129 15780 solver.cpp:244]     Train net output #0: loss = 0.91447 (* 1 = 0.91447 loss)
I1013 18:12:11.895149 15780 sgd_solver.cpp:106] Iteration 31200, lr = 0.000494106
I1013 18:12:16.303863 15780 solver.cpp:228] Iteration 31300, loss = 0.815713
I1013 18:12:16.303920 15780 solver.cpp:244]     Train net output #0: loss = 0.815713 (* 1 = 0.815713 loss)
I1013 18:12:16.303942 15780 sgd_solver.cpp:106] Iteration 31300, lr = 0.000493383
I1013 18:12:20.714673 15780 solver.cpp:228] Iteration 31400, loss = 1.13408
I1013 18:12:20.714720 15780 solver.cpp:244]     Train net output #0: loss = 1.13408 (* 1 = 1.13408 loss)
I1013 18:12:20.714727 15780 sgd_solver.cpp:106] Iteration 31400, lr = 0.000492663
I1013 18:12:25.122697 15780 solver.cpp:337] Iteration 31500, Testing net (#0)
I1013 18:12:30.670128 15780 solver.cpp:404]     Test net output #0: accuracy = 0.673167
I1013 18:12:30.670181 15780 solver.cpp:404]     Test net output #1: loss = 1.25798 (* 1 = 1.25798 loss)
I1013 18:12:30.686223 15780 solver.cpp:228] Iteration 31500, loss = 0.700368
I1013 18:12:30.686266 15780 solver.cpp:244]     Train net output #0: loss = 0.700368 (* 1 = 0.700368 loss)
I1013 18:12:30.686280 15780 sgd_solver.cpp:106] Iteration 31500, lr = 0.000491946
I1013 18:12:35.130419 15780 solver.cpp:228] Iteration 31600, loss = 0.892958
I1013 18:12:35.130465 15780 solver.cpp:244]     Train net output #0: loss = 0.892958 (* 1 = 0.892958 loss)
I1013 18:12:35.130471 15780 sgd_solver.cpp:106] Iteration 31600, lr = 0.00049123
I1013 18:12:39.598974 15780 solver.cpp:228] Iteration 31700, loss = 0.709492
I1013 18:12:39.599021 15780 solver.cpp:244]     Train net output #0: loss = 0.709492 (* 1 = 0.709492 loss)
I1013 18:12:39.599031 15780 sgd_solver.cpp:106] Iteration 31700, lr = 0.000490518
I1013 18:12:44.079725 15780 solver.cpp:228] Iteration 31800, loss = 0.923214
I1013 18:12:44.079762 15780 solver.cpp:244]     Train net output #0: loss = 0.923214 (* 1 = 0.923214 loss)
I1013 18:12:44.079771 15780 sgd_solver.cpp:106] Iteration 31800, lr = 0.000489807
I1013 18:12:48.567256 15780 solver.cpp:228] Iteration 31900, loss = 0.847254
I1013 18:12:48.567306 15780 solver.cpp:244]     Train net output #0: loss = 0.847254 (* 1 = 0.847254 loss)
I1013 18:12:48.567312 15780 sgd_solver.cpp:106] Iteration 31900, lr = 0.000489099
I1013 18:12:52.965893 15780 solver.cpp:337] Iteration 32000, Testing net (#0)
I1013 18:12:58.294100 15780 solver.cpp:404]     Test net output #0: accuracy = 0.67675
I1013 18:12:58.294149 15780 solver.cpp:404]     Test net output #1: loss = 1.25589 (* 1 = 1.25589 loss)
I1013 18:12:58.309324 15780 solver.cpp:228] Iteration 32000, loss = 0.902347
I1013 18:12:58.309363 15780 solver.cpp:244]     Train net output #0: loss = 0.902347 (* 1 = 0.902347 loss)
I1013 18:12:58.309376 15780 sgd_solver.cpp:106] Iteration 32000, lr = 0.000488394
I1013 18:13:02.796716 15780 solver.cpp:228] Iteration 32100, loss = 0.643437
I1013 18:13:02.796758 15780 solver.cpp:244]     Train net output #0: loss = 0.643437 (* 1 = 0.643437 loss)
I1013 18:13:02.796766 15780 sgd_solver.cpp:106] Iteration 32100, lr = 0.00048769
I1013 18:13:07.259821 15780 solver.cpp:228] Iteration 32200, loss = 0.998624
I1013 18:13:07.259866 15780 solver.cpp:244]     Train net output #0: loss = 0.998624 (* 1 = 0.998624 loss)
I1013 18:13:07.259876 15780 sgd_solver.cpp:106] Iteration 32200, lr = 0.00048699
I1013 18:13:11.670575 15780 solver.cpp:228] Iteration 32300, loss = 1.18466
I1013 18:13:11.670614 15780 solver.cpp:244]     Train net output #0: loss = 1.18466 (* 1 = 1.18466 loss)
I1013 18:13:11.670621 15780 sgd_solver.cpp:106] Iteration 32300, lr = 0.000486291
I1013 18:13:16.097412 15780 solver.cpp:228] Iteration 32400, loss = 1.19502
I1013 18:13:16.097453 15780 solver.cpp:244]     Train net output #0: loss = 1.19502 (* 1 = 1.19502 loss)
I1013 18:13:16.097461 15780 sgd_solver.cpp:106] Iteration 32400, lr = 0.000485595
I1013 18:13:20.539124 15780 solver.cpp:337] Iteration 32500, Testing net (#0)
I1013 18:13:22.788558 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:13:25.684746 15780 solver.cpp:404]     Test net output #0: accuracy = 0.668167
I1013 18:13:25.684818 15780 solver.cpp:404]     Test net output #1: loss = 1.31128 (* 1 = 1.31128 loss)
I1013 18:13:25.700371 15780 solver.cpp:228] Iteration 32500, loss = 0.937941
I1013 18:13:25.700415 15780 solver.cpp:244]     Train net output #0: loss = 0.937941 (* 1 = 0.937941 loss)
I1013 18:13:25.700429 15780 sgd_solver.cpp:106] Iteration 32500, lr = 0.000484901
I1013 18:13:30.167421 15780 solver.cpp:228] Iteration 32600, loss = 1.01126
I1013 18:13:30.167476 15780 solver.cpp:244]     Train net output #0: loss = 1.01126 (* 1 = 1.01126 loss)
I1013 18:13:30.167484 15780 sgd_solver.cpp:106] Iteration 32600, lr = 0.000484209
I1013 18:13:34.632169 15780 solver.cpp:228] Iteration 32700, loss = 0.843796
I1013 18:13:34.632215 15780 solver.cpp:244]     Train net output #0: loss = 0.843796 (* 1 = 0.843796 loss)
I1013 18:13:34.632225 15780 sgd_solver.cpp:106] Iteration 32700, lr = 0.00048352
I1013 18:13:39.101793 15780 solver.cpp:228] Iteration 32800, loss = 0.690479
I1013 18:13:39.101835 15780 solver.cpp:244]     Train net output #0: loss = 0.690479 (* 1 = 0.690479 loss)
I1013 18:13:39.101841 15780 sgd_solver.cpp:106] Iteration 32800, lr = 0.000482833
I1013 18:13:43.583645 15780 solver.cpp:228] Iteration 32900, loss = 0.847445
I1013 18:13:43.583667 15780 solver.cpp:244]     Train net output #0: loss = 0.847445 (* 1 = 0.847445 loss)
I1013 18:13:43.583673 15780 sgd_solver.cpp:106] Iteration 32900, lr = 0.000482148
I1013 18:13:48.024124 15780 solver.cpp:337] Iteration 33000, Testing net (#0)
I1013 18:13:53.005064 15780 solver.cpp:404]     Test net output #0: accuracy = 0.667333
I1013 18:13:53.005115 15780 solver.cpp:404]     Test net output #1: loss = 1.30858 (* 1 = 1.30858 loss)
I1013 18:13:53.021339 15780 solver.cpp:228] Iteration 33000, loss = 1.12477
I1013 18:13:53.021419 15780 solver.cpp:244]     Train net output #0: loss = 1.12477 (* 1 = 1.12477 loss)
I1013 18:13:53.021452 15780 sgd_solver.cpp:106] Iteration 33000, lr = 0.000481466
I1013 18:13:57.420684 15780 solver.cpp:228] Iteration 33100, loss = 0.916241
I1013 18:13:57.420729 15780 solver.cpp:244]     Train net output #0: loss = 0.916241 (* 1 = 0.916241 loss)
I1013 18:13:57.420737 15780 sgd_solver.cpp:106] Iteration 33100, lr = 0.000480786
I1013 18:14:01.845398 15780 solver.cpp:228] Iteration 33200, loss = 0.910767
I1013 18:14:01.845443 15780 solver.cpp:244]     Train net output #0: loss = 0.910767 (* 1 = 0.910767 loss)
I1013 18:14:01.845454 15780 sgd_solver.cpp:106] Iteration 33200, lr = 0.000480108
I1013 18:14:06.303767 15780 solver.cpp:228] Iteration 33300, loss = 0.688021
I1013 18:14:06.303808 15780 solver.cpp:244]     Train net output #0: loss = 0.688021 (* 1 = 0.688021 loss)
I1013 18:14:06.303817 15780 sgd_solver.cpp:106] Iteration 33300, lr = 0.000479432
I1013 18:14:10.765568 15780 solver.cpp:228] Iteration 33400, loss = 0.820307
I1013 18:14:10.765605 15780 solver.cpp:244]     Train net output #0: loss = 0.820307 (* 1 = 0.820307 loss)
I1013 18:14:10.765614 15780 sgd_solver.cpp:106] Iteration 33400, lr = 0.000478759
I1013 18:14:15.160717 15780 solver.cpp:337] Iteration 33500, Testing net (#0)
I1013 18:14:20.169932 15780 solver.cpp:404]     Test net output #0: accuracy = 0.687625
I1013 18:14:20.169977 15780 solver.cpp:404]     Test net output #1: loss = 1.22837 (* 1 = 1.22837 loss)
I1013 18:14:20.186717 15780 solver.cpp:228] Iteration 33500, loss = 0.763573
I1013 18:14:20.186765 15780 solver.cpp:244]     Train net output #0: loss = 0.763573 (* 1 = 0.763573 loss)
I1013 18:14:20.186781 15780 sgd_solver.cpp:106] Iteration 33500, lr = 0.000478087
I1013 18:14:24.647627 15780 solver.cpp:228] Iteration 33600, loss = 0.698693
I1013 18:14:24.647668 15780 solver.cpp:244]     Train net output #0: loss = 0.698693 (* 1 = 0.698693 loss)
I1013 18:14:24.647675 15780 sgd_solver.cpp:106] Iteration 33600, lr = 0.000477418
I1013 18:14:29.115664 15780 solver.cpp:228] Iteration 33700, loss = 0.895731
I1013 18:14:29.115716 15780 solver.cpp:244]     Train net output #0: loss = 0.895731 (* 1 = 0.895731 loss)
I1013 18:14:29.115726 15780 sgd_solver.cpp:106] Iteration 33700, lr = 0.000476751
I1013 18:14:33.613682 15780 solver.cpp:228] Iteration 33800, loss = 0.866458
I1013 18:14:33.613732 15780 solver.cpp:244]     Train net output #0: loss = 0.866458 (* 1 = 0.866458 loss)
I1013 18:14:33.613741 15780 sgd_solver.cpp:106] Iteration 33800, lr = 0.000476086
I1013 18:14:38.091305 15780 solver.cpp:228] Iteration 33900, loss = 0.991495
I1013 18:14:38.091358 15780 solver.cpp:244]     Train net output #0: loss = 0.991495 (* 1 = 0.991495 loss)
I1013 18:14:38.091367 15780 sgd_solver.cpp:106] Iteration 33900, lr = 0.000475424
I1013 18:14:42.532526 15780 solver.cpp:337] Iteration 34000, Testing net (#0)
I1013 18:14:46.682107 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:14:47.876991 15780 solver.cpp:404]     Test net output #0: accuracy = 0.641625
I1013 18:14:47.877039 15780 solver.cpp:404]     Test net output #1: loss = 1.63568 (* 1 = 1.63568 loss)
I1013 18:14:47.891394 15780 solver.cpp:228] Iteration 34000, loss = 1.06035
I1013 18:14:47.891436 15780 solver.cpp:244]     Train net output #0: loss = 1.06035 (* 1 = 1.06035 loss)
I1013 18:14:47.891451 15780 sgd_solver.cpp:106] Iteration 34000, lr = 0.000474763
I1013 18:14:52.368510 15780 solver.cpp:228] Iteration 34100, loss = 0.699439
I1013 18:14:52.368554 15780 solver.cpp:244]     Train net output #0: loss = 0.699439 (* 1 = 0.699439 loss)
I1013 18:14:52.368564 15780 sgd_solver.cpp:106] Iteration 34100, lr = 0.000474105
I1013 18:14:56.841199 15780 solver.cpp:228] Iteration 34200, loss = 0.914085
I1013 18:14:56.841243 15780 solver.cpp:244]     Train net output #0: loss = 0.914085 (* 1 = 0.914085 loss)
I1013 18:14:56.841253 15780 sgd_solver.cpp:106] Iteration 34200, lr = 0.000473449
I1013 18:15:01.321110 15780 solver.cpp:228] Iteration 34300, loss = 0.980315
I1013 18:15:01.321152 15780 solver.cpp:244]     Train net output #0: loss = 0.980315 (* 1 = 0.980315 loss)
I1013 18:15:01.321161 15780 sgd_solver.cpp:106] Iteration 34300, lr = 0.000472795
I1013 18:15:05.785537 15780 solver.cpp:228] Iteration 34400, loss = 0.920367
I1013 18:15:05.785593 15780 solver.cpp:244]     Train net output #0: loss = 0.920367 (* 1 = 0.920367 loss)
I1013 18:15:05.785603 15780 sgd_solver.cpp:106] Iteration 34400, lr = 0.000472143
I1013 18:15:10.220484 15780 solver.cpp:337] Iteration 34500, Testing net (#0)
I1013 18:15:15.616098 15780 solver.cpp:404]     Test net output #0: accuracy = 0.682125
I1013 18:15:15.616163 15780 solver.cpp:404]     Test net output #1: loss = 1.31147 (* 1 = 1.31147 loss)
I1013 18:15:15.630926 15780 solver.cpp:228] Iteration 34500, loss = 0.710493
I1013 18:15:15.630969 15780 solver.cpp:244]     Train net output #0: loss = 0.710493 (* 1 = 0.710493 loss)
I1013 18:15:15.630987 15780 sgd_solver.cpp:106] Iteration 34500, lr = 0.000471493
I1013 18:15:20.074075 15780 solver.cpp:228] Iteration 34600, loss = 0.926363
I1013 18:15:20.074128 15780 solver.cpp:244]     Train net output #0: loss = 0.926363 (* 1 = 0.926363 loss)
I1013 18:15:20.074136 15780 sgd_solver.cpp:106] Iteration 34600, lr = 0.000470845
I1013 18:15:24.525059 15780 solver.cpp:228] Iteration 34700, loss = 1.03455
I1013 18:15:24.525113 15780 solver.cpp:244]     Train net output #0: loss = 1.03455 (* 1 = 1.03455 loss)
I1013 18:15:24.525120 15780 sgd_solver.cpp:106] Iteration 34700, lr = 0.000470199
I1013 18:15:28.941329 15780 solver.cpp:228] Iteration 34800, loss = 0.761846
I1013 18:15:28.941380 15780 solver.cpp:244]     Train net output #0: loss = 0.761846 (* 1 = 0.761846 loss)
I1013 18:15:28.941387 15780 sgd_solver.cpp:106] Iteration 34800, lr = 0.000469556
I1013 18:15:33.380486 15780 solver.cpp:228] Iteration 34900, loss = 0.912898
I1013 18:15:33.380503 15780 solver.cpp:244]     Train net output #0: loss = 0.912898 (* 1 = 0.912898 loss)
I1013 18:15:33.380509 15780 sgd_solver.cpp:106] Iteration 34900, lr = 0.000468914
I1013 18:15:37.788785 15780 solver.cpp:337] Iteration 35000, Testing net (#0)
I1013 18:15:43.083753 15780 solver.cpp:404]     Test net output #0: accuracy = 0.668375
I1013 18:15:43.083830 15780 solver.cpp:404]     Test net output #1: loss = 1.33544 (* 1 = 1.33544 loss)
I1013 18:15:43.099779 15780 solver.cpp:228] Iteration 35000, loss = 0.900562
I1013 18:15:43.099843 15780 solver.cpp:244]     Train net output #0: loss = 0.900562 (* 1 = 0.900562 loss)
I1013 18:15:43.099859 15780 sgd_solver.cpp:106] Iteration 35000, lr = 0.000468274
I1013 18:15:47.552238 15780 solver.cpp:228] Iteration 35100, loss = 0.82481
I1013 18:15:47.552297 15780 solver.cpp:244]     Train net output #0: loss = 0.82481 (* 1 = 0.82481 loss)
I1013 18:15:47.552306 15780 sgd_solver.cpp:106] Iteration 35100, lr = 0.000467637
I1013 18:15:52.016809 15780 solver.cpp:228] Iteration 35200, loss = 0.578028
I1013 18:15:52.016854 15780 solver.cpp:244]     Train net output #0: loss = 0.578028 (* 1 = 0.578028 loss)
I1013 18:15:52.016860 15780 sgd_solver.cpp:106] Iteration 35200, lr = 0.000467001
I1013 18:15:56.452361 15780 solver.cpp:228] Iteration 35300, loss = 1.07646
I1013 18:15:56.452414 15780 solver.cpp:244]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I1013 18:15:56.452432 15780 sgd_solver.cpp:106] Iteration 35300, lr = 0.000466368
I1013 18:16:00.896674 15780 solver.cpp:228] Iteration 35400, loss = 0.56364
I1013 18:16:00.896724 15780 solver.cpp:244]     Train net output #0: loss = 0.56364 (* 1 = 0.56364 loss)
I1013 18:16:00.896742 15780 sgd_solver.cpp:106] Iteration 35400, lr = 0.000465736
I1013 18:16:05.318833 15780 solver.cpp:337] Iteration 35500, Testing net (#0)
I1013 18:16:10.326823 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:16:10.713872 15780 solver.cpp:404]     Test net output #0: accuracy = 0.652333
I1013 18:16:10.713935 15780 solver.cpp:404]     Test net output #1: loss = 1.52833 (* 1 = 1.52833 loss)
I1013 18:16:10.730135 15780 solver.cpp:228] Iteration 35500, loss = 0.892655
I1013 18:16:10.730177 15780 solver.cpp:244]     Train net output #0: loss = 0.892655 (* 1 = 0.892655 loss)
I1013 18:16:10.730192 15780 sgd_solver.cpp:106] Iteration 35500, lr = 0.000465107
I1013 18:16:15.189405 15780 solver.cpp:228] Iteration 35600, loss = 0.713393
I1013 18:16:15.189451 15780 solver.cpp:244]     Train net output #0: loss = 0.713393 (* 1 = 0.713393 loss)
I1013 18:16:15.189458 15780 sgd_solver.cpp:106] Iteration 35600, lr = 0.000464479
I1013 18:16:19.651739 15780 solver.cpp:228] Iteration 35700, loss = 0.929218
I1013 18:16:19.651770 15780 solver.cpp:244]     Train net output #0: loss = 0.929218 (* 1 = 0.929218 loss)
I1013 18:16:19.651778 15780 sgd_solver.cpp:106] Iteration 35700, lr = 0.000463854
I1013 18:16:24.130507 15780 solver.cpp:228] Iteration 35800, loss = 0.736543
I1013 18:16:24.130550 15780 solver.cpp:244]     Train net output #0: loss = 0.736543 (* 1 = 0.736543 loss)
I1013 18:16:24.130560 15780 sgd_solver.cpp:106] Iteration 35800, lr = 0.00046323
I1013 18:16:28.606103 15780 solver.cpp:228] Iteration 35900, loss = 0.665794
I1013 18:16:28.606151 15780 solver.cpp:244]     Train net output #0: loss = 0.665794 (* 1 = 0.665794 loss)
I1013 18:16:28.606159 15780 sgd_solver.cpp:106] Iteration 35900, lr = 0.000462609
I1013 18:16:33.003074 15780 solver.cpp:337] Iteration 36000, Testing net (#0)
I1013 18:16:38.473125 15780 solver.cpp:404]     Test net output #0: accuracy = 0.654292
I1013 18:16:38.473173 15780 solver.cpp:404]     Test net output #1: loss = 1.46168 (* 1 = 1.46168 loss)
I1013 18:16:38.490128 15780 solver.cpp:228] Iteration 36000, loss = 1.01071
I1013 18:16:38.490190 15780 solver.cpp:244]     Train net output #0: loss = 1.01071 (* 1 = 1.01071 loss)
I1013 18:16:38.490209 15780 sgd_solver.cpp:106] Iteration 36000, lr = 0.000461989
I1013 18:16:42.966302 15780 solver.cpp:228] Iteration 36100, loss = 0.637461
I1013 18:16:42.966354 15780 solver.cpp:244]     Train net output #0: loss = 0.637461 (* 1 = 0.637461 loss)
I1013 18:16:42.966363 15780 sgd_solver.cpp:106] Iteration 36100, lr = 0.000461371
I1013 18:16:47.422255 15780 solver.cpp:228] Iteration 36200, loss = 0.632617
I1013 18:16:47.422302 15780 solver.cpp:244]     Train net output #0: loss = 0.632617 (* 1 = 0.632617 loss)
I1013 18:16:47.422309 15780 sgd_solver.cpp:106] Iteration 36200, lr = 0.000460755
I1013 18:16:51.903921 15780 solver.cpp:228] Iteration 36300, loss = 0.582689
I1013 18:16:51.903975 15780 solver.cpp:244]     Train net output #0: loss = 0.582689 (* 1 = 0.582689 loss)
I1013 18:16:51.903985 15780 sgd_solver.cpp:106] Iteration 36300, lr = 0.000460141
I1013 18:16:56.382254 15780 solver.cpp:228] Iteration 36400, loss = 0.627905
I1013 18:16:56.382306 15780 solver.cpp:244]     Train net output #0: loss = 0.627905 (* 1 = 0.627905 loss)
I1013 18:16:56.382316 15780 sgd_solver.cpp:106] Iteration 36400, lr = 0.000459529
I1013 18:17:00.819473 15780 solver.cpp:337] Iteration 36500, Testing net (#0)
I1013 18:17:06.105691 15780 solver.cpp:404]     Test net output #0: accuracy = 0.683458
I1013 18:17:06.105736 15780 solver.cpp:404]     Test net output #1: loss = 1.40801 (* 1 = 1.40801 loss)
I1013 18:17:06.120322 15780 solver.cpp:228] Iteration 36500, loss = 0.678691
I1013 18:17:06.120368 15780 solver.cpp:244]     Train net output #0: loss = 0.678691 (* 1 = 0.678691 loss)
I1013 18:17:06.120385 15780 sgd_solver.cpp:106] Iteration 36500, lr = 0.000458919
I1013 18:17:10.604797 15780 solver.cpp:228] Iteration 36600, loss = 0.609251
I1013 18:17:10.604841 15780 solver.cpp:244]     Train net output #0: loss = 0.609251 (* 1 = 0.609251 loss)
I1013 18:17:10.604849 15780 sgd_solver.cpp:106] Iteration 36600, lr = 0.000458311
I1013 18:17:15.078125 15780 solver.cpp:228] Iteration 36700, loss = 0.535873
I1013 18:17:15.078172 15780 solver.cpp:244]     Train net output #0: loss = 0.535873 (* 1 = 0.535873 loss)
I1013 18:17:15.078182 15780 sgd_solver.cpp:106] Iteration 36700, lr = 0.000457705
I1013 18:17:19.562201 15780 solver.cpp:228] Iteration 36800, loss = 0.61043
I1013 18:17:19.562242 15780 solver.cpp:244]     Train net output #0: loss = 0.61043 (* 1 = 0.61043 loss)
I1013 18:17:19.562250 15780 sgd_solver.cpp:106] Iteration 36800, lr = 0.0004571
I1013 18:17:24.040926 15780 solver.cpp:228] Iteration 36900, loss = 0.652448
I1013 18:17:24.040968 15780 solver.cpp:244]     Train net output #0: loss = 0.652448 (* 1 = 0.652448 loss)
I1013 18:17:24.040980 15780 sgd_solver.cpp:106] Iteration 36900, lr = 0.000456497
I1013 18:17:28.483373 15780 solver.cpp:337] Iteration 37000, Testing net (#0)
I1013 18:17:33.788872 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:17:33.957892 15780 solver.cpp:404]     Test net output #0: accuracy = 0.674875
I1013 18:17:33.957943 15780 solver.cpp:404]     Test net output #1: loss = 1.47694 (* 1 = 1.47694 loss)
I1013 18:17:33.973381 15780 solver.cpp:228] Iteration 37000, loss = 0.602392
I1013 18:17:33.973428 15780 solver.cpp:244]     Train net output #0: loss = 0.602392 (* 1 = 0.602392 loss)
I1013 18:17:33.973441 15780 sgd_solver.cpp:106] Iteration 37000, lr = 0.000455897
I1013 18:17:38.443725 15780 solver.cpp:228] Iteration 37100, loss = 0.653683
I1013 18:17:38.443778 15780 solver.cpp:244]     Train net output #0: loss = 0.653683 (* 1 = 0.653683 loss)
I1013 18:17:38.443788 15780 sgd_solver.cpp:106] Iteration 37100, lr = 0.000455298
I1013 18:17:42.911027 15780 solver.cpp:228] Iteration 37200, loss = 0.670202
I1013 18:17:42.911082 15780 solver.cpp:244]     Train net output #0: loss = 0.670202 (* 1 = 0.670202 loss)
I1013 18:17:42.911090 15780 sgd_solver.cpp:106] Iteration 37200, lr = 0.000454701
I1013 18:17:47.376760 15780 solver.cpp:228] Iteration 37300, loss = 0.786947
I1013 18:17:47.376806 15780 solver.cpp:244]     Train net output #0: loss = 0.786947 (* 1 = 0.786947 loss)
I1013 18:17:47.376811 15780 sgd_solver.cpp:106] Iteration 37300, lr = 0.000454105
I1013 18:17:51.844813 15780 solver.cpp:228] Iteration 37400, loss = 0.731339
I1013 18:17:51.844873 15780 solver.cpp:244]     Train net output #0: loss = 0.731339 (* 1 = 0.731339 loss)
I1013 18:17:51.844880 15780 sgd_solver.cpp:106] Iteration 37400, lr = 0.000453512
I1013 18:17:56.262197 15780 solver.cpp:337] Iteration 37500, Testing net (#0)
I1013 18:18:01.667507 15780 solver.cpp:404]     Test net output #0: accuracy = 0.66025
I1013 18:18:01.667562 15780 solver.cpp:404]     Test net output #1: loss = 1.48523 (* 1 = 1.48523 loss)
I1013 18:18:01.683050 15780 solver.cpp:228] Iteration 37500, loss = 0.769154
I1013 18:18:01.683090 15780 solver.cpp:244]     Train net output #0: loss = 0.769154 (* 1 = 0.769154 loss)
I1013 18:18:01.683111 15780 sgd_solver.cpp:106] Iteration 37500, lr = 0.00045292
I1013 18:18:06.144389 15780 solver.cpp:228] Iteration 37600, loss = 0.564436
I1013 18:18:06.144448 15780 solver.cpp:244]     Train net output #0: loss = 0.564436 (* 1 = 0.564436 loss)
I1013 18:18:06.144476 15780 sgd_solver.cpp:106] Iteration 37600, lr = 0.00045233
I1013 18:18:10.607914 15780 solver.cpp:228] Iteration 37700, loss = 0.806672
I1013 18:18:10.607964 15780 solver.cpp:244]     Train net output #0: loss = 0.806672 (* 1 = 0.806672 loss)
I1013 18:18:10.607972 15780 sgd_solver.cpp:106] Iteration 37700, lr = 0.000451742
I1013 18:18:15.076652 15780 solver.cpp:228] Iteration 37800, loss = 0.828189
I1013 18:18:15.076702 15780 solver.cpp:244]     Train net output #0: loss = 0.828189 (* 1 = 0.828189 loss)
I1013 18:18:15.076711 15780 sgd_solver.cpp:106] Iteration 37800, lr = 0.000451156
I1013 18:18:19.550209 15780 solver.cpp:228] Iteration 37900, loss = 0.544387
I1013 18:18:19.550264 15780 solver.cpp:244]     Train net output #0: loss = 0.544387 (* 1 = 0.544387 loss)
I1013 18:18:19.550273 15780 sgd_solver.cpp:106] Iteration 37900, lr = 0.000450571
I1013 18:18:23.986855 15780 solver.cpp:337] Iteration 38000, Testing net (#0)
I1013 18:18:29.271724 15780 solver.cpp:404]     Test net output #0: accuracy = 0.676792
I1013 18:18:29.271791 15780 solver.cpp:404]     Test net output #1: loss = 1.37456 (* 1 = 1.37456 loss)
I1013 18:18:29.287683 15780 solver.cpp:228] Iteration 38000, loss = 0.712499
I1013 18:18:29.287714 15780 solver.cpp:244]     Train net output #0: loss = 0.712499 (* 1 = 0.712499 loss)
I1013 18:18:29.287729 15780 sgd_solver.cpp:106] Iteration 38000, lr = 0.000449989
I1013 18:18:33.756916 15780 solver.cpp:228] Iteration 38100, loss = 0.693187
I1013 18:18:33.756966 15780 solver.cpp:244]     Train net output #0: loss = 0.693187 (* 1 = 0.693187 loss)
I1013 18:18:33.756976 15780 sgd_solver.cpp:106] Iteration 38100, lr = 0.000449408
I1013 18:18:38.233343 15780 solver.cpp:228] Iteration 38200, loss = 0.537348
I1013 18:18:38.233384 15780 solver.cpp:244]     Train net output #0: loss = 0.537348 (* 1 = 0.537348 loss)
I1013 18:18:38.233392 15780 sgd_solver.cpp:106] Iteration 38200, lr = 0.000448828
I1013 18:18:42.713219 15780 solver.cpp:228] Iteration 38300, loss = 0.648416
I1013 18:18:42.713271 15780 solver.cpp:244]     Train net output #0: loss = 0.648416 (* 1 = 0.648416 loss)
I1013 18:18:42.713281 15780 sgd_solver.cpp:106] Iteration 38300, lr = 0.000448251
I1013 18:18:47.175161 15780 solver.cpp:228] Iteration 38400, loss = 0.839654
I1013 18:18:47.175214 15780 solver.cpp:244]     Train net output #0: loss = 0.839654 (* 1 = 0.839654 loss)
I1013 18:18:47.175223 15780 sgd_solver.cpp:106] Iteration 38400, lr = 0.000447675
I1013 18:18:51.596619 15780 solver.cpp:337] Iteration 38500, Testing net (#0)
I1013 18:18:55.830993 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:18:57.099138 15780 solver.cpp:404]     Test net output #0: accuracy = 0.638167
I1013 18:18:57.099201 15780 solver.cpp:404]     Test net output #1: loss = 1.65883 (* 1 = 1.65883 loss)
I1013 18:18:57.115224 15780 solver.cpp:228] Iteration 38500, loss = 0.695538
I1013 18:18:57.115248 15780 solver.cpp:244]     Train net output #0: loss = 0.695538 (* 1 = 0.695538 loss)
I1013 18:18:57.115262 15780 sgd_solver.cpp:106] Iteration 38500, lr = 0.000447101
I1013 18:19:01.573835 15780 solver.cpp:228] Iteration 38600, loss = 0.771604
I1013 18:19:01.573885 15780 solver.cpp:244]     Train net output #0: loss = 0.771604 (* 1 = 0.771604 loss)
I1013 18:19:01.573895 15780 sgd_solver.cpp:106] Iteration 38600, lr = 0.000446529
I1013 18:19:06.037392 15780 solver.cpp:228] Iteration 38700, loss = 1.02655
I1013 18:19:06.037439 15780 solver.cpp:244]     Train net output #0: loss = 1.02655 (* 1 = 1.02655 loss)
I1013 18:19:06.037446 15780 sgd_solver.cpp:106] Iteration 38700, lr = 0.000445958
I1013 18:19:10.502697 15780 solver.cpp:228] Iteration 38800, loss = 0.71175
I1013 18:19:10.502722 15780 solver.cpp:244]     Train net output #0: loss = 0.71175 (* 1 = 0.71175 loss)
I1013 18:19:10.502732 15780 sgd_solver.cpp:106] Iteration 38800, lr = 0.000445389
I1013 18:19:14.964943 15780 solver.cpp:228] Iteration 38900, loss = 0.832439
I1013 18:19:14.964993 15780 solver.cpp:244]     Train net output #0: loss = 0.832439 (* 1 = 0.832439 loss)
I1013 18:19:14.965003 15780 sgd_solver.cpp:106] Iteration 38900, lr = 0.000444822
I1013 18:19:19.401401 15780 solver.cpp:337] Iteration 39000, Testing net (#0)
I1013 18:19:24.596051 15780 solver.cpp:404]     Test net output #0: accuracy = 0.662708
I1013 18:19:24.596096 15780 solver.cpp:404]     Test net output #1: loss = 1.55718 (* 1 = 1.55718 loss)
I1013 18:19:24.611197 15780 solver.cpp:228] Iteration 39000, loss = 0.773368
I1013 18:19:24.611240 15780 solver.cpp:244]     Train net output #0: loss = 0.773368 (* 1 = 0.773368 loss)
I1013 18:19:24.611256 15780 sgd_solver.cpp:106] Iteration 39000, lr = 0.000444256
I1013 18:19:29.062111 15780 solver.cpp:228] Iteration 39100, loss = 0.636006
I1013 18:19:29.062157 15780 solver.cpp:244]     Train net output #0: loss = 0.636006 (* 1 = 0.636006 loss)
I1013 18:19:29.062165 15780 sgd_solver.cpp:106] Iteration 39100, lr = 0.000443692
I1013 18:19:33.501979 15780 solver.cpp:228] Iteration 39200, loss = 0.585618
I1013 18:19:33.502039 15780 solver.cpp:244]     Train net output #0: loss = 0.585618 (* 1 = 0.585618 loss)
I1013 18:19:33.502053 15780 sgd_solver.cpp:106] Iteration 39200, lr = 0.00044313
I1013 18:19:37.918704 15780 solver.cpp:228] Iteration 39300, loss = 0.637254
I1013 18:19:37.918756 15780 solver.cpp:244]     Train net output #0: loss = 0.637254 (* 1 = 0.637254 loss)
I1013 18:19:37.918766 15780 sgd_solver.cpp:106] Iteration 39300, lr = 0.00044257
I1013 18:19:42.383968 15780 solver.cpp:228] Iteration 39400, loss = 0.624462
I1013 18:19:42.384049 15780 solver.cpp:244]     Train net output #0: loss = 0.624462 (* 1 = 0.624462 loss)
I1013 18:19:42.384064 15780 sgd_solver.cpp:106] Iteration 39400, lr = 0.000442011
I1013 18:19:46.816515 15780 solver.cpp:337] Iteration 39500, Testing net (#0)
I1013 18:19:51.946207 15780 solver.cpp:404]     Test net output #0: accuracy = 0.662375
I1013 18:19:51.946252 15780 solver.cpp:404]     Test net output #1: loss = 1.5776 (* 1 = 1.5776 loss)
I1013 18:19:51.960947 15780 solver.cpp:228] Iteration 39500, loss = 0.567548
I1013 18:19:51.960968 15780 solver.cpp:244]     Train net output #0: loss = 0.567548 (* 1 = 0.567548 loss)
I1013 18:19:51.960979 15780 sgd_solver.cpp:106] Iteration 39500, lr = 0.000441453
I1013 18:19:56.396402 15780 solver.cpp:228] Iteration 39600, loss = 0.675982
I1013 18:19:56.396441 15780 solver.cpp:244]     Train net output #0: loss = 0.675982 (* 1 = 0.675982 loss)
I1013 18:19:56.396450 15780 sgd_solver.cpp:106] Iteration 39600, lr = 0.000440898
I1013 18:20:00.815832 15780 solver.cpp:228] Iteration 39700, loss = 0.446166
I1013 18:20:00.815884 15780 solver.cpp:244]     Train net output #0: loss = 0.446166 (* 1 = 0.446166 loss)
I1013 18:20:00.815893 15780 sgd_solver.cpp:106] Iteration 39700, lr = 0.000440344
I1013 18:20:05.235743 15780 solver.cpp:228] Iteration 39800, loss = 0.640095
I1013 18:20:05.235783 15780 solver.cpp:244]     Train net output #0: loss = 0.640095 (* 1 = 0.640095 loss)
I1013 18:20:05.235792 15780 sgd_solver.cpp:106] Iteration 39800, lr = 0.000439791
I1013 18:20:09.651228 15780 solver.cpp:228] Iteration 39900, loss = 0.745141
I1013 18:20:09.651279 15780 solver.cpp:244]     Train net output #0: loss = 0.745141 (* 1 = 0.745141 loss)
I1013 18:20:09.651288 15780 sgd_solver.cpp:106] Iteration 39900, lr = 0.000439241
I1013 18:20:14.025952 15780 solver.cpp:454] Snapshotting to binary proto file models/21class_pascal_plus_pre_trained_alex_net/21class_pascal_plus_pre_trained_alex_net_lr_0.001_iter_40000.caffemodel
I1013 18:20:14.443532 15780 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/21class_pascal_plus_pre_trained_alex_net/21class_pascal_plus_pre_trained_alex_net_lr_0.001_iter_40000.solverstate
I1013 18:20:14.580914 15780 solver.cpp:337] Iteration 40000, Testing net (#0)
I1013 18:20:19.538955 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:20:20.035396 15780 solver.cpp:404]     Test net output #0: accuracy = 0.651209
I1013 18:20:20.035454 15780 solver.cpp:404]     Test net output #1: loss = 1.72343 (* 1 = 1.72343 loss)
I1013 18:20:20.049931 15780 solver.cpp:228] Iteration 40000, loss = 0.446095
I1013 18:20:20.049978 15780 solver.cpp:244]     Train net output #0: loss = 0.446095 (* 1 = 0.446095 loss)
I1013 18:20:20.049991 15780 sgd_solver.cpp:106] Iteration 40000, lr = 0.000438691
I1013 18:20:24.509716 15780 solver.cpp:228] Iteration 40100, loss = 0.690754
I1013 18:20:24.509781 15780 solver.cpp:244]     Train net output #0: loss = 0.690754 (* 1 = 0.690754 loss)
I1013 18:20:24.509793 15780 sgd_solver.cpp:106] Iteration 40100, lr = 0.000438144
I1013 18:20:28.946694 15780 solver.cpp:228] Iteration 40200, loss = 0.565804
I1013 18:20:28.946735 15780 solver.cpp:244]     Train net output #0: loss = 0.565804 (* 1 = 0.565804 loss)
I1013 18:20:28.946745 15780 sgd_solver.cpp:106] Iteration 40200, lr = 0.000437598
I1013 18:20:33.407141 15780 solver.cpp:228] Iteration 40300, loss = 0.580915
I1013 18:20:33.407194 15780 solver.cpp:244]     Train net output #0: loss = 0.580915 (* 1 = 0.580915 loss)
I1013 18:20:33.407203 15780 sgd_solver.cpp:106] Iteration 40300, lr = 0.000437053
I1013 18:20:37.886565 15780 solver.cpp:228] Iteration 40400, loss = 0.780463
I1013 18:20:37.886617 15780 solver.cpp:244]     Train net output #0: loss = 0.780463 (* 1 = 0.780463 loss)
I1013 18:20:37.886626 15780 sgd_solver.cpp:106] Iteration 40400, lr = 0.000436511
I1013 18:20:42.318552 15780 solver.cpp:337] Iteration 40500, Testing net (#0)
I1013 18:20:47.663094 15780 solver.cpp:404]     Test net output #0: accuracy = 0.666458
I1013 18:20:47.663141 15780 solver.cpp:404]     Test net output #1: loss = 1.56612 (* 1 = 1.56612 loss)
I1013 18:20:47.678488 15780 solver.cpp:228] Iteration 40500, loss = 0.499099
I1013 18:20:47.678544 15780 solver.cpp:244]     Train net output #0: loss = 0.499099 (* 1 = 0.499099 loss)
I1013 18:20:47.678556 15780 sgd_solver.cpp:106] Iteration 40500, lr = 0.000435969
I1013 18:20:52.155380 15780 solver.cpp:228] Iteration 40600, loss = 0.796563
I1013 18:20:52.155427 15780 solver.cpp:244]     Train net output #0: loss = 0.796563 (* 1 = 0.796563 loss)
I1013 18:20:52.155434 15780 sgd_solver.cpp:106] Iteration 40600, lr = 0.00043543
I1013 18:20:56.594485 15780 solver.cpp:228] Iteration 40700, loss = 0.57963
I1013 18:20:56.594534 15780 solver.cpp:244]     Train net output #0: loss = 0.57963 (* 1 = 0.57963 loss)
I1013 18:20:56.594543 15780 sgd_solver.cpp:106] Iteration 40700, lr = 0.000434892
I1013 18:21:01.044318 15780 solver.cpp:228] Iteration 40800, loss = 0.930596
I1013 18:21:01.044369 15780 solver.cpp:244]     Train net output #0: loss = 0.930596 (* 1 = 0.930596 loss)
I1013 18:21:01.044379 15780 sgd_solver.cpp:106] Iteration 40800, lr = 0.000434355
I1013 18:21:05.469035 15780 solver.cpp:228] Iteration 40900, loss = 0.591595
I1013 18:21:05.469084 15780 solver.cpp:244]     Train net output #0: loss = 0.591595 (* 1 = 0.591595 loss)
I1013 18:21:05.469097 15780 sgd_solver.cpp:106] Iteration 40900, lr = 0.00043382
I1013 18:21:09.840291 15780 solver.cpp:337] Iteration 41000, Testing net (#0)
I1013 18:21:14.934722 15780 solver.cpp:404]     Test net output #0: accuracy = 0.611667
I1013 18:21:14.934772 15780 solver.cpp:404]     Test net output #1: loss = 2.01458 (* 1 = 2.01458 loss)
I1013 18:21:14.950268 15780 solver.cpp:228] Iteration 41000, loss = 0.962506
I1013 18:21:14.950300 15780 solver.cpp:244]     Train net output #0: loss = 0.962506 (* 1 = 0.962506 loss)
I1013 18:21:14.950311 15780 sgd_solver.cpp:106] Iteration 41000, lr = 0.000433286
I1013 18:21:19.424610 15780 solver.cpp:228] Iteration 41100, loss = 0.588767
I1013 18:21:19.424659 15780 solver.cpp:244]     Train net output #0: loss = 0.588767 (* 1 = 0.588767 loss)
I1013 18:21:19.424667 15780 sgd_solver.cpp:106] Iteration 41100, lr = 0.000432755
I1013 18:21:23.906610 15780 solver.cpp:228] Iteration 41200, loss = 1.01379
I1013 18:21:23.906659 15780 solver.cpp:244]     Train net output #0: loss = 1.01379 (* 1 = 1.01379 loss)
I1013 18:21:23.906669 15780 sgd_solver.cpp:106] Iteration 41200, lr = 0.000432224
I1013 18:21:28.395980 15780 solver.cpp:228] Iteration 41300, loss = 0.452298
I1013 18:21:28.396035 15780 solver.cpp:244]     Train net output #0: loss = 0.452298 (* 1 = 0.452298 loss)
I1013 18:21:28.396045 15780 sgd_solver.cpp:106] Iteration 41300, lr = 0.000431695
I1013 18:21:32.864048 15780 solver.cpp:228] Iteration 41400, loss = 0.749086
I1013 18:21:32.864099 15780 solver.cpp:244]     Train net output #0: loss = 0.749086 (* 1 = 0.749086 loss)
I1013 18:21:32.864118 15780 sgd_solver.cpp:106] Iteration 41400, lr = 0.000431168
I1013 18:21:37.272919 15780 solver.cpp:337] Iteration 41500, Testing net (#0)
I1013 18:21:41.845974 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:21:42.211964 15780 solver.cpp:404]     Test net output #0: accuracy = 0.650042
I1013 18:21:42.212013 15780 solver.cpp:404]     Test net output #1: loss = 1.73027 (* 1 = 1.73027 loss)
I1013 18:21:42.227900 15780 solver.cpp:228] Iteration 41500, loss = 0.851344
I1013 18:21:42.227943 15780 solver.cpp:244]     Train net output #0: loss = 0.851344 (* 1 = 0.851344 loss)
I1013 18:21:42.227968 15780 sgd_solver.cpp:106] Iteration 41500, lr = 0.000430642
I1013 18:21:46.656172 15780 solver.cpp:228] Iteration 41600, loss = 0.686032
I1013 18:21:46.656222 15780 solver.cpp:244]     Train net output #0: loss = 0.686032 (* 1 = 0.686032 loss)
I1013 18:21:46.656232 15780 sgd_solver.cpp:106] Iteration 41600, lr = 0.000430117
I1013 18:21:51.078063 15780 solver.cpp:228] Iteration 41700, loss = 0.754362
I1013 18:21:51.078109 15780 solver.cpp:244]     Train net output #0: loss = 0.754362 (* 1 = 0.754362 loss)
I1013 18:21:51.078117 15780 sgd_solver.cpp:106] Iteration 41700, lr = 0.000429594
I1013 18:21:55.540997 15780 solver.cpp:228] Iteration 41800, loss = 0.82717
I1013 18:21:55.541038 15780 solver.cpp:244]     Train net output #0: loss = 0.82717 (* 1 = 0.82717 loss)
I1013 18:21:55.541048 15780 sgd_solver.cpp:106] Iteration 41800, lr = 0.000429073
I1013 18:22:00.024983 15780 solver.cpp:228] Iteration 41900, loss = 0.624653
I1013 18:22:00.025027 15780 solver.cpp:244]     Train net output #0: loss = 0.624653 (* 1 = 0.624653 loss)
I1013 18:22:00.025037 15780 sgd_solver.cpp:106] Iteration 41900, lr = 0.000428553
I1013 18:22:04.456786 15780 solver.cpp:337] Iteration 42000, Testing net (#0)
I1013 18:22:09.752032 15780 solver.cpp:404]     Test net output #0: accuracy = 0.657375
I1013 18:22:09.752080 15780 solver.cpp:404]     Test net output #1: loss = 1.67528 (* 1 = 1.67528 loss)
I1013 18:22:09.766611 15780 solver.cpp:228] Iteration 42000, loss = 0.532285
I1013 18:22:09.766674 15780 solver.cpp:244]     Train net output #0: loss = 0.532285 (* 1 = 0.532285 loss)
I1013 18:22:09.766693 15780 sgd_solver.cpp:106] Iteration 42000, lr = 0.000428034
I1013 18:22:14.239807 15780 solver.cpp:228] Iteration 42100, loss = 0.553666
I1013 18:22:14.239855 15780 solver.cpp:244]     Train net output #0: loss = 0.553666 (* 1 = 0.553666 loss)
I1013 18:22:14.239873 15780 sgd_solver.cpp:106] Iteration 42100, lr = 0.000427517
I1013 18:22:18.682588 15780 solver.cpp:228] Iteration 42200, loss = 0.606346
I1013 18:22:18.682642 15780 solver.cpp:244]     Train net output #0: loss = 0.606346 (* 1 = 0.606346 loss)
I1013 18:22:18.682649 15780 sgd_solver.cpp:106] Iteration 42200, lr = 0.000427002
I1013 18:22:23.100301 15780 solver.cpp:228] Iteration 42300, loss = 0.71959
I1013 18:22:23.100347 15780 solver.cpp:244]     Train net output #0: loss = 0.71959 (* 1 = 0.71959 loss)
I1013 18:22:23.100356 15780 sgd_solver.cpp:106] Iteration 42300, lr = 0.000426488
I1013 18:22:27.500205 15780 solver.cpp:228] Iteration 42400, loss = 0.602835
I1013 18:22:27.500262 15780 solver.cpp:244]     Train net output #0: loss = 0.602835 (* 1 = 0.602835 loss)
I1013 18:22:27.500270 15780 sgd_solver.cpp:106] Iteration 42400, lr = 0.000425975
I1013 18:22:31.857544 15780 solver.cpp:337] Iteration 42500, Testing net (#0)
I1013 18:22:37.588141 15780 solver.cpp:404]     Test net output #0: accuracy = 0.655583
I1013 18:22:37.588213 15780 solver.cpp:404]     Test net output #1: loss = 1.78561 (* 1 = 1.78561 loss)
I1013 18:22:37.604430 15780 solver.cpp:228] Iteration 42500, loss = 0.663546
I1013 18:22:37.604492 15780 solver.cpp:244]     Train net output #0: loss = 0.663546 (* 1 = 0.663546 loss)
I1013 18:22:37.604509 15780 sgd_solver.cpp:106] Iteration 42500, lr = 0.000425464
I1013 18:22:42.060346 15780 solver.cpp:228] Iteration 42600, loss = 0.623537
I1013 18:22:42.060386 15780 solver.cpp:244]     Train net output #0: loss = 0.623537 (* 1 = 0.623537 loss)
I1013 18:22:42.060395 15780 sgd_solver.cpp:106] Iteration 42600, lr = 0.000424954
I1013 18:22:46.530472 15780 solver.cpp:228] Iteration 42700, loss = 0.688609
I1013 18:22:46.530511 15780 solver.cpp:244]     Train net output #0: loss = 0.688609 (* 1 = 0.688609 loss)
I1013 18:22:46.530520 15780 sgd_solver.cpp:106] Iteration 42700, lr = 0.000424445
I1013 18:22:50.999979 15780 solver.cpp:228] Iteration 42800, loss = 0.502323
I1013 18:22:51.000012 15780 solver.cpp:244]     Train net output #0: loss = 0.502323 (* 1 = 0.502323 loss)
I1013 18:22:51.000021 15780 sgd_solver.cpp:106] Iteration 42800, lr = 0.000423938
I1013 18:22:55.479859 15780 solver.cpp:228] Iteration 42900, loss = 0.611114
I1013 18:22:55.479902 15780 solver.cpp:244]     Train net output #0: loss = 0.611114 (* 1 = 0.611114 loss)
I1013 18:22:55.479913 15780 sgd_solver.cpp:106] Iteration 42900, lr = 0.000423433
I1013 18:22:59.920354 15780 solver.cpp:337] Iteration 43000, Testing net (#0)
I1013 18:23:04.887783 15780 solver.cpp:404]     Test net output #0: accuracy = 0.654042
I1013 18:23:04.887854 15780 solver.cpp:404]     Test net output #1: loss = 1.84687 (* 1 = 1.84687 loss)
I1013 18:23:04.903260 15780 solver.cpp:228] Iteration 43000, loss = 0.518902
I1013 18:23:04.903314 15780 solver.cpp:244]     Train net output #0: loss = 0.518902 (* 1 = 0.518902 loss)
I1013 18:23:04.903326 15780 sgd_solver.cpp:106] Iteration 43000, lr = 0.000422929
I1013 18:23:09.369885 15780 solver.cpp:228] Iteration 43100, loss = 0.545578
I1013 18:23:09.369940 15780 solver.cpp:244]     Train net output #0: loss = 0.545578 (* 1 = 0.545578 loss)
I1013 18:23:09.369949 15780 sgd_solver.cpp:106] Iteration 43100, lr = 0.000422426
I1013 18:23:11.158757 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:23:13.840735 15780 solver.cpp:228] Iteration 43200, loss = 0.60091
I1013 18:23:13.840788 15780 solver.cpp:244]     Train net output #0: loss = 0.60091 (* 1 = 0.60091 loss)
I1013 18:23:13.840797 15780 sgd_solver.cpp:106] Iteration 43200, lr = 0.000421924
I1013 18:23:18.318567 15780 solver.cpp:228] Iteration 43300, loss = 0.505807
I1013 18:23:18.318622 15780 solver.cpp:244]     Train net output #0: loss = 0.505807 (* 1 = 0.505807 loss)
I1013 18:23:18.318629 15780 sgd_solver.cpp:106] Iteration 43300, lr = 0.000421424
I1013 18:23:22.787374 15780 solver.cpp:228] Iteration 43400, loss = 0.388508
I1013 18:23:22.787430 15780 solver.cpp:244]     Train net output #0: loss = 0.388508 (* 1 = 0.388508 loss)
I1013 18:23:22.787437 15780 sgd_solver.cpp:106] Iteration 43400, lr = 0.000420926
I1013 18:23:27.245340 15780 solver.cpp:337] Iteration 43500, Testing net (#0)
I1013 18:23:32.253764 15780 solver.cpp:404]     Test net output #0: accuracy = 0.652917
I1013 18:23:32.253821 15780 solver.cpp:404]     Test net output #1: loss = 2.00207 (* 1 = 2.00207 loss)
I1013 18:23:32.269400 15780 solver.cpp:228] Iteration 43500, loss = 0.44927
I1013 18:23:32.269444 15780 solver.cpp:244]     Train net output #0: loss = 0.44927 (* 1 = 0.44927 loss)
I1013 18:23:32.269462 15780 sgd_solver.cpp:106] Iteration 43500, lr = 0.000420429
I1013 18:23:36.750393 15780 solver.cpp:228] Iteration 43600, loss = 0.53393
I1013 18:23:36.750443 15780 solver.cpp:244]     Train net output #0: loss = 0.53393 (* 1 = 0.53393 loss)
I1013 18:23:36.750452 15780 sgd_solver.cpp:106] Iteration 43600, lr = 0.000419933
I1013 18:23:41.222496 15780 solver.cpp:228] Iteration 43700, loss = 0.368886
I1013 18:23:41.222545 15780 solver.cpp:244]     Train net output #0: loss = 0.368886 (* 1 = 0.368886 loss)
I1013 18:23:41.222555 15780 sgd_solver.cpp:106] Iteration 43700, lr = 0.000419438
I1013 18:23:45.724411 15780 solver.cpp:228] Iteration 43800, loss = 0.283273
I1013 18:23:45.724458 15780 solver.cpp:244]     Train net output #0: loss = 0.283273 (* 1 = 0.283273 loss)
I1013 18:23:45.724468 15780 sgd_solver.cpp:106] Iteration 43800, lr = 0.000418945
I1013 18:23:50.237793 15780 solver.cpp:228] Iteration 43900, loss = 0.574825
I1013 18:23:50.237849 15780 solver.cpp:244]     Train net output #0: loss = 0.574825 (* 1 = 0.574825 loss)
I1013 18:23:50.237859 15780 sgd_solver.cpp:106] Iteration 43900, lr = 0.000418453
I1013 18:23:54.672188 15780 solver.cpp:337] Iteration 44000, Testing net (#0)
I1013 18:23:59.787133 15780 solver.cpp:404]     Test net output #0: accuracy = 0.651042
I1013 18:23:59.787191 15780 solver.cpp:404]     Test net output #1: loss = 2.04121 (* 1 = 2.04121 loss)
I1013 18:23:59.802696 15780 solver.cpp:228] Iteration 44000, loss = 0.366796
I1013 18:23:59.802726 15780 solver.cpp:244]     Train net output #0: loss = 0.366796 (* 1 = 0.366796 loss)
I1013 18:23:59.802739 15780 sgd_solver.cpp:106] Iteration 44000, lr = 0.000417963
I1013 18:24:04.287101 15780 solver.cpp:228] Iteration 44100, loss = 0.414737
I1013 18:24:04.287139 15780 solver.cpp:244]     Train net output #0: loss = 0.414737 (* 1 = 0.414737 loss)
I1013 18:24:04.287147 15780 sgd_solver.cpp:106] Iteration 44100, lr = 0.000417474
I1013 18:24:08.759958 15780 solver.cpp:228] Iteration 44200, loss = 0.429465
I1013 18:24:08.760010 15780 solver.cpp:244]     Train net output #0: loss = 0.429465 (* 1 = 0.429465 loss)
I1013 18:24:08.760017 15780 sgd_solver.cpp:106] Iteration 44200, lr = 0.000416986
I1013 18:24:13.232028 15780 solver.cpp:228] Iteration 44300, loss = 0.534147
I1013 18:24:13.232069 15780 solver.cpp:244]     Train net output #0: loss = 0.534147 (* 1 = 0.534147 loss)
I1013 18:24:13.232077 15780 sgd_solver.cpp:106] Iteration 44300, lr = 0.000416499
I1013 18:24:17.697892 15780 solver.cpp:228] Iteration 44400, loss = 0.423889
I1013 18:24:17.697943 15780 solver.cpp:244]     Train net output #0: loss = 0.423889 (* 1 = 0.423889 loss)
I1013 18:24:17.697952 15780 sgd_solver.cpp:106] Iteration 44400, lr = 0.000416014
I1013 18:24:22.122462 15780 solver.cpp:337] Iteration 44500, Testing net (#0)
I1013 18:24:27.797894 15780 solver.cpp:404]     Test net output #0: accuracy = 0.646375
I1013 18:24:27.797960 15780 solver.cpp:404]     Test net output #1: loss = 2.12798 (* 1 = 2.12798 loss)
I1013 18:24:27.814365 15780 solver.cpp:228] Iteration 44500, loss = 0.468699
I1013 18:24:27.814409 15780 solver.cpp:244]     Train net output #0: loss = 0.468699 (* 1 = 0.468699 loss)
I1013 18:24:27.814424 15780 sgd_solver.cpp:106] Iteration 44500, lr = 0.00041553
I1013 18:24:32.255457 15780 solver.cpp:228] Iteration 44600, loss = 0.428168
I1013 18:24:32.255520 15780 solver.cpp:244]     Train net output #0: loss = 0.428168 (* 1 = 0.428168 loss)
I1013 18:24:32.255534 15780 sgd_solver.cpp:106] Iteration 44600, lr = 0.000415048
I1013 18:24:36.732092 15780 solver.cpp:228] Iteration 44700, loss = 0.376066
I1013 18:24:36.732134 15780 solver.cpp:244]     Train net output #0: loss = 0.376066 (* 1 = 0.376066 loss)
I1013 18:24:36.732143 15780 sgd_solver.cpp:106] Iteration 44700, lr = 0.000414567
I1013 18:24:41.208469 15780 solver.cpp:228] Iteration 44800, loss = 0.486165
I1013 18:24:41.208518 15780 solver.cpp:244]     Train net output #0: loss = 0.486165 (* 1 = 0.486165 loss)
I1013 18:24:41.208526 15780 sgd_solver.cpp:106] Iteration 44800, lr = 0.000414087
I1013 18:24:45.693373 15780 solver.cpp:228] Iteration 44900, loss = 0.605892
I1013 18:24:45.693418 15780 solver.cpp:244]     Train net output #0: loss = 0.605892 (* 1 = 0.605892 loss)
I1013 18:24:45.693428 15780 sgd_solver.cpp:106] Iteration 44900, lr = 0.000413608
I1013 18:24:49.716928 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:24:50.122345 15780 solver.cpp:337] Iteration 45000, Testing net (#0)
I1013 18:24:55.593070 15780 solver.cpp:404]     Test net output #0: accuracy = 0.638708
I1013 18:24:55.593116 15780 solver.cpp:404]     Test net output #1: loss = 2.21279 (* 1 = 2.21279 loss)
I1013 18:24:55.607309 15780 solver.cpp:228] Iteration 45000, loss = 0.498447
I1013 18:24:55.607331 15780 solver.cpp:244]     Train net output #0: loss = 0.498447 (* 1 = 0.498447 loss)
I1013 18:24:55.607345 15780 sgd_solver.cpp:106] Iteration 45000, lr = 0.000413131
I1013 18:25:00.056797 15780 solver.cpp:228] Iteration 45100, loss = 0.46158
I1013 18:25:00.056852 15780 solver.cpp:244]     Train net output #0: loss = 0.46158 (* 1 = 0.46158 loss)
I1013 18:25:00.056859 15780 sgd_solver.cpp:106] Iteration 45100, lr = 0.000412655
I1013 18:25:04.499181 15780 solver.cpp:228] Iteration 45200, loss = 0.391191
I1013 18:25:04.499234 15780 solver.cpp:244]     Train net output #0: loss = 0.391191 (* 1 = 0.391191 loss)
I1013 18:25:04.499243 15780 sgd_solver.cpp:106] Iteration 45200, lr = 0.00041218
I1013 18:25:08.950487 15780 solver.cpp:228] Iteration 45300, loss = 0.393712
I1013 18:25:08.950532 15780 solver.cpp:244]     Train net output #0: loss = 0.393712 (* 1 = 0.393712 loss)
I1013 18:25:08.950539 15780 sgd_solver.cpp:106] Iteration 45300, lr = 0.000411706
I1013 18:25:13.396306 15780 solver.cpp:228] Iteration 45400, loss = 0.436868
I1013 18:25:13.396363 15780 solver.cpp:244]     Train net output #0: loss = 0.436868 (* 1 = 0.436868 loss)
I1013 18:25:13.396370 15780 sgd_solver.cpp:106] Iteration 45400, lr = 0.000411234
I1013 18:25:17.813547 15780 solver.cpp:337] Iteration 45500, Testing net (#0)
I1013 18:25:22.818748 15780 solver.cpp:404]     Test net output #0: accuracy = 0.672709
I1013 18:25:22.818792 15780 solver.cpp:404]     Test net output #1: loss = 1.9083 (* 1 = 1.9083 loss)
I1013 18:25:22.833212 15780 solver.cpp:228] Iteration 45500, loss = 0.287621
I1013 18:25:22.833266 15780 solver.cpp:244]     Train net output #0: loss = 0.287621 (* 1 = 0.287621 loss)
I1013 18:25:22.833281 15780 sgd_solver.cpp:106] Iteration 45500, lr = 0.000410763
I1013 18:25:27.273612 15780 solver.cpp:228] Iteration 45600, loss = 0.40186
I1013 18:25:27.273669 15780 solver.cpp:244]     Train net output #0: loss = 0.40186 (* 1 = 0.40186 loss)
I1013 18:25:27.273675 15780 sgd_solver.cpp:106] Iteration 45600, lr = 0.000410293
I1013 18:25:31.716477 15780 solver.cpp:228] Iteration 45700, loss = 0.397084
I1013 18:25:31.716517 15780 solver.cpp:244]     Train net output #0: loss = 0.397084 (* 1 = 0.397084 loss)
I1013 18:25:31.716523 15780 sgd_solver.cpp:106] Iteration 45700, lr = 0.000409825
I1013 18:25:36.118024 15780 solver.cpp:228] Iteration 45800, loss = 0.580157
I1013 18:25:36.118090 15780 solver.cpp:244]     Train net output #0: loss = 0.580157 (* 1 = 0.580157 loss)
I1013 18:25:36.118098 15780 sgd_solver.cpp:106] Iteration 45800, lr = 0.000409358
I1013 18:25:40.514839 15780 solver.cpp:228] Iteration 45900, loss = 0.465578
I1013 18:25:40.514896 15780 solver.cpp:244]     Train net output #0: loss = 0.465578 (* 1 = 0.465578 loss)
I1013 18:25:40.514904 15780 sgd_solver.cpp:106] Iteration 45900, lr = 0.000408892
I1013 18:25:44.929711 15780 solver.cpp:337] Iteration 46000, Testing net (#0)
I1013 18:25:49.776091 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:25:50.086393 15780 solver.cpp:404]     Test net output #0: accuracy = 0.616708
I1013 18:25:50.086438 15780 solver.cpp:404]     Test net output #1: loss = 2.34498 (* 1 = 2.34498 loss)
I1013 18:25:50.103546 15780 solver.cpp:228] Iteration 46000, loss = 0.602391
I1013 18:25:50.103621 15780 solver.cpp:244]     Train net output #0: loss = 0.602391 (* 1 = 0.602391 loss)
I1013 18:25:50.103647 15780 sgd_solver.cpp:106] Iteration 46000, lr = 0.000408427
I1013 18:25:54.553021 15780 solver.cpp:228] Iteration 46100, loss = 0.726881
I1013 18:25:54.553064 15780 solver.cpp:244]     Train net output #0: loss = 0.726881 (* 1 = 0.726881 loss)
I1013 18:25:54.553076 15780 sgd_solver.cpp:106] Iteration 46100, lr = 0.000407964
I1013 18:25:59.014323 15780 solver.cpp:228] Iteration 46200, loss = 0.462593
I1013 18:25:59.014377 15780 solver.cpp:244]     Train net output #0: loss = 0.462593 (* 1 = 0.462593 loss)
I1013 18:25:59.014384 15780 sgd_solver.cpp:106] Iteration 46200, lr = 0.000407501
I1013 18:26:03.435330 15780 solver.cpp:228] Iteration 46300, loss = 0.494134
I1013 18:26:03.435369 15780 solver.cpp:244]     Train net output #0: loss = 0.494134 (* 1 = 0.494134 loss)
I1013 18:26:03.435374 15780 sgd_solver.cpp:106] Iteration 46300, lr = 0.00040704
I1013 18:26:07.852689 15780 solver.cpp:228] Iteration 46400, loss = 0.454851
I1013 18:26:07.852741 15780 solver.cpp:244]     Train net output #0: loss = 0.454851 (* 1 = 0.454851 loss)
I1013 18:26:07.852749 15780 sgd_solver.cpp:106] Iteration 46400, lr = 0.00040658
I1013 18:26:12.235368 15780 solver.cpp:337] Iteration 46500, Testing net (#0)
I1013 18:26:18.002285 15780 solver.cpp:404]     Test net output #0: accuracy = 0.672208
I1013 18:26:18.002342 15780 solver.cpp:404]     Test net output #1: loss = 1.94276 (* 1 = 1.94276 loss)
I1013 18:26:18.018668 15780 solver.cpp:228] Iteration 46500, loss = 0.726285
I1013 18:26:18.018692 15780 solver.cpp:244]     Train net output #0: loss = 0.726285 (* 1 = 0.726285 loss)
I1013 18:26:18.018710 15780 sgd_solver.cpp:106] Iteration 46500, lr = 0.000406122
I1013 18:26:22.482728 15780 solver.cpp:228] Iteration 46600, loss = 0.35127
I1013 18:26:22.482794 15780 solver.cpp:244]     Train net output #0: loss = 0.35127 (* 1 = 0.35127 loss)
I1013 18:26:22.482802 15780 sgd_solver.cpp:106] Iteration 46600, lr = 0.000405664
I1013 18:26:26.925668 15780 solver.cpp:228] Iteration 46700, loss = 0.341241
I1013 18:26:26.925720 15780 solver.cpp:244]     Train net output #0: loss = 0.341241 (* 1 = 0.341241 loss)
I1013 18:26:26.925730 15780 sgd_solver.cpp:106] Iteration 46700, lr = 0.000405208
I1013 18:26:31.338815 15780 solver.cpp:228] Iteration 46800, loss = 0.458865
I1013 18:26:31.338862 15780 solver.cpp:244]     Train net output #0: loss = 0.458865 (* 1 = 0.458865 loss)
I1013 18:26:31.338871 15780 sgd_solver.cpp:106] Iteration 46800, lr = 0.000404753
I1013 18:26:35.808540 15780 solver.cpp:228] Iteration 46900, loss = 0.38134
I1013 18:26:35.808590 15780 solver.cpp:244]     Train net output #0: loss = 0.38134 (* 1 = 0.38134 loss)
I1013 18:26:35.808598 15780 sgd_solver.cpp:106] Iteration 46900, lr = 0.000404299
I1013 18:26:40.218909 15780 solver.cpp:337] Iteration 47000, Testing net (#0)
I1013 18:26:45.415726 15780 solver.cpp:404]     Test net output #0: accuracy = 0.637375
I1013 18:26:45.415778 15780 solver.cpp:404]     Test net output #1: loss = 2.30411 (* 1 = 2.30411 loss)
I1013 18:26:45.431933 15780 solver.cpp:228] Iteration 47000, loss = 0.504679
I1013 18:26:45.431953 15780 solver.cpp:244]     Train net output #0: loss = 0.504679 (* 1 = 0.504679 loss)
I1013 18:26:45.431964 15780 sgd_solver.cpp:106] Iteration 47000, lr = 0.000403847
I1013 18:26:49.908689 15780 solver.cpp:228] Iteration 47100, loss = 0.492294
I1013 18:26:49.908706 15780 solver.cpp:244]     Train net output #0: loss = 0.492294 (* 1 = 0.492294 loss)
I1013 18:26:49.908712 15780 sgd_solver.cpp:106] Iteration 47100, lr = 0.000403395
I1013 18:26:54.341995 15780 solver.cpp:228] Iteration 47200, loss = 0.355909
I1013 18:26:54.342054 15780 solver.cpp:244]     Train net output #0: loss = 0.355909 (* 1 = 0.355909 loss)
I1013 18:26:54.342064 15780 sgd_solver.cpp:106] Iteration 47200, lr = 0.000402945
I1013 18:26:58.748615 15780 solver.cpp:228] Iteration 47300, loss = 0.378248
I1013 18:26:58.748670 15780 solver.cpp:244]     Train net output #0: loss = 0.378248 (* 1 = 0.378248 loss)
I1013 18:26:58.748677 15780 sgd_solver.cpp:106] Iteration 47300, lr = 0.000402496
I1013 18:27:03.151052 15780 solver.cpp:228] Iteration 47400, loss = 0.370279
I1013 18:27:03.151106 15780 solver.cpp:244]     Train net output #0: loss = 0.370279 (* 1 = 0.370279 loss)
I1013 18:27:03.151113 15780 sgd_solver.cpp:106] Iteration 47400, lr = 0.000402048
I1013 18:27:07.523012 15780 solver.cpp:337] Iteration 47500, Testing net (#0)
I1013 18:27:12.154635 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:27:12.582587 15780 solver.cpp:404]     Test net output #0: accuracy = 0.664209
I1013 18:27:12.582628 15780 solver.cpp:404]     Test net output #1: loss = 2.05442 (* 1 = 2.05442 loss)
I1013 18:27:12.597170 15780 solver.cpp:228] Iteration 47500, loss = 0.360554
I1013 18:27:12.597249 15780 solver.cpp:244]     Train net output #0: loss = 0.360554 (* 1 = 0.360554 loss)
I1013 18:27:12.597260 15780 sgd_solver.cpp:106] Iteration 47500, lr = 0.000401601
I1013 18:27:17.066316 15780 solver.cpp:228] Iteration 47600, loss = 0.230864
I1013 18:27:17.066365 15780 solver.cpp:244]     Train net output #0: loss = 0.230864 (* 1 = 0.230864 loss)
I1013 18:27:17.066376 15780 sgd_solver.cpp:106] Iteration 47600, lr = 0.000401155
I1013 18:27:21.516989 15780 solver.cpp:228] Iteration 47700, loss = 0.445145
I1013 18:27:21.517031 15780 solver.cpp:244]     Train net output #0: loss = 0.445145 (* 1 = 0.445145 loss)
I1013 18:27:21.517038 15780 sgd_solver.cpp:106] Iteration 47700, lr = 0.000400711
I1013 18:27:25.961096 15780 solver.cpp:228] Iteration 47800, loss = 0.333499
I1013 18:27:25.961150 15780 solver.cpp:244]     Train net output #0: loss = 0.333499 (* 1 = 0.333499 loss)
I1013 18:27:25.961158 15780 sgd_solver.cpp:106] Iteration 47800, lr = 0.000400267
I1013 18:27:30.420454 15780 solver.cpp:228] Iteration 47900, loss = 0.469323
I1013 18:27:30.420497 15780 solver.cpp:244]     Train net output #0: loss = 0.469323 (* 1 = 0.469323 loss)
I1013 18:27:30.420505 15780 sgd_solver.cpp:106] Iteration 47900, lr = 0.000399825
I1013 18:27:34.842468 15780 solver.cpp:337] Iteration 48000, Testing net (#0)
I1013 18:27:40.287761 15780 solver.cpp:404]     Test net output #0: accuracy = 0.648667
I1013 18:27:40.287828 15780 solver.cpp:404]     Test net output #1: loss = 2.22294 (* 1 = 2.22294 loss)
I1013 18:27:40.304193 15780 solver.cpp:228] Iteration 48000, loss = 0.568012
I1013 18:27:40.304236 15780 solver.cpp:244]     Train net output #0: loss = 0.568012 (* 1 = 0.568012 loss)
I1013 18:27:40.304249 15780 sgd_solver.cpp:106] Iteration 48000, lr = 0.000399384
I1013 18:27:44.782021 15780 solver.cpp:228] Iteration 48100, loss = 0.456525
I1013 18:27:44.782074 15780 solver.cpp:244]     Train net output #0: loss = 0.456525 (* 1 = 0.456525 loss)
I1013 18:27:44.782081 15780 sgd_solver.cpp:106] Iteration 48100, lr = 0.000398944
I1013 18:27:49.242920 15780 solver.cpp:228] Iteration 48200, loss = 0.443264
I1013 18:27:49.242971 15780 solver.cpp:244]     Train net output #0: loss = 0.443264 (* 1 = 0.443264 loss)
I1013 18:27:49.242981 15780 sgd_solver.cpp:106] Iteration 48200, lr = 0.000398505
I1013 18:27:53.718335 15780 solver.cpp:228] Iteration 48300, loss = 0.574563
I1013 18:27:53.718394 15780 solver.cpp:244]     Train net output #0: loss = 0.574563 (* 1 = 0.574563 loss)
I1013 18:27:53.718427 15780 sgd_solver.cpp:106] Iteration 48300, lr = 0.000398068
I1013 18:27:58.178696 15780 solver.cpp:228] Iteration 48400, loss = 0.340823
I1013 18:27:58.178746 15780 solver.cpp:244]     Train net output #0: loss = 0.340823 (* 1 = 0.340823 loss)
I1013 18:27:58.178756 15780 sgd_solver.cpp:106] Iteration 48400, lr = 0.000397631
I1013 18:28:02.598489 15780 solver.cpp:337] Iteration 48500, Testing net (#0)
I1013 18:28:08.069893 15780 solver.cpp:404]     Test net output #0: accuracy = 0.660959
I1013 18:28:08.069954 15780 solver.cpp:404]     Test net output #1: loss = 2.05651 (* 1 = 2.05651 loss)
I1013 18:28:08.084183 15780 solver.cpp:228] Iteration 48500, loss = 0.333829
I1013 18:28:08.084214 15780 solver.cpp:244]     Train net output #0: loss = 0.333829 (* 1 = 0.333829 loss)
I1013 18:28:08.084228 15780 sgd_solver.cpp:106] Iteration 48500, lr = 0.000397196
I1013 18:28:12.559736 15780 solver.cpp:228] Iteration 48600, loss = 0.359379
I1013 18:28:12.559787 15780 solver.cpp:244]     Train net output #0: loss = 0.359379 (* 1 = 0.359379 loss)
I1013 18:28:12.559798 15780 sgd_solver.cpp:106] Iteration 48600, lr = 0.000396761
I1013 18:28:17.029708 15780 solver.cpp:228] Iteration 48700, loss = 0.38987
I1013 18:28:17.029762 15780 solver.cpp:244]     Train net output #0: loss = 0.38987 (* 1 = 0.38987 loss)
I1013 18:28:17.029770 15780 sgd_solver.cpp:106] Iteration 48700, lr = 0.000396328
I1013 18:28:21.496022 15780 solver.cpp:228] Iteration 48800, loss = 0.303702
I1013 18:28:21.496076 15780 solver.cpp:244]     Train net output #0: loss = 0.303702 (* 1 = 0.303702 loss)
I1013 18:28:21.496085 15780 sgd_solver.cpp:106] Iteration 48800, lr = 0.000395896
I1013 18:28:25.968201 15780 solver.cpp:228] Iteration 48900, loss = 0.342113
I1013 18:28:25.968253 15780 solver.cpp:244]     Train net output #0: loss = 0.342113 (* 1 = 0.342113 loss)
I1013 18:28:25.968263 15780 sgd_solver.cpp:106] Iteration 48900, lr = 0.000395465
I1013 18:28:30.392529 15780 solver.cpp:337] Iteration 49000, Testing net (#0)
I1013 18:28:34.340018 15780 blocking_queue.cpp:50] Data layer prefetch queue empty
I1013 18:28:35.602738 15780 solver.cpp:404]     Test net output #0: accuracy = 0.643291
I1013 18:28:35.602782 15780 solver.cpp:404]     Test net output #1: loss = 2.53703 (* 1 = 2.53703 loss)
I1013 18:28:35.618307 15780 solver.cpp:228] Iteration 49000, loss = 0.311309
I1013 18:28:35.618345 15780 solver.cpp:244]     Train net output #0: loss = 0.311309 (* 1 = 0.311309 loss)
I1013 18:28:35.618358 15780 sgd_solver.cpp:106] Iteration 49000, lr = 0.000395035
I1013 18:28:40.105218 15780 solver.cpp:228] Iteration 49100, loss = 0.496995
I1013 18:28:40.105271 15780 solver.cpp:244]     Train net output #0: loss = 0.496995 (* 1 = 0.496995 loss)
I1013 18:28:40.105283 15780 sgd_solver.cpp:106] Iteration 49100, lr = 0.000394606
I1013 18:28:44.581646 15780 solver.cpp:228] Iteration 49200, loss = 0.34537
I1013 18:28:44.581701 15780 solver.cpp:244]     Train net output #0: loss = 0.34537 (* 1 = 0.34537 loss)
I1013 18:28:44.581709 15780 sgd_solver.cpp:106] Iteration 49200, lr = 0.000394178
I1013 18:28:49.068182 15780 solver.cpp:228] Iteration 49300, loss = 0.429367
I1013 18:28:49.068218 15780 solver.cpp:244]     Train net output #0: loss = 0.429367 (* 1 = 0.429367 loss)
I1013 18:28:49.068224 15780 sgd_solver.cpp:106] Iteration 49300, lr = 0.000393752
I1013 18:28:53.543270 15780 solver.cpp:228] Iteration 49400, loss = 0.336865
I1013 18:28:53.543334 15780 solver.cpp:244]     Train net output #0: loss = 0.336865 (* 1 = 0.336865 loss)
I1013 18:28:53.543347 15780 sgd_solver.cpp:106] Iteration 49400, lr = 0.000393326
I1013 18:28:57.983137 15780 solver.cpp:337] Iteration 49500, Testing net (#0)
I1013 18:29:03.044407 15780 solver.cpp:404]     Test net output #0: accuracy = 0.65325
I1013 18:29:03.044452 15780 solver.cpp:404]     Test net output #1: loss = 2.23801 (* 1 = 2.23801 loss)
I1013 18:29:03.059900 15780 solver.cpp:228] Iteration 49500, loss = 0.318211
I1013 18:29:03.059937 15780 solver.cpp:244]     Train net output #0: loss = 0.318211 (* 1 = 0.318211 loss)
I1013 18:29:03.059952 15780 sgd_solver.cpp:106] Iteration 49500, lr = 0.000392902
I1013 18:29:07.490124 15780 solver.cpp:228] Iteration 49600, loss = 0.398855
I1013 18:29:07.490161 15780 solver.cpp:244]     Train net output #0: loss = 0.398855 (* 1 = 0.398855 loss)
I1013 18:29:07.490170 15780 sgd_solver.cpp:106] Iteration 49600, lr = 0.000392478
I1013 18:29:11.861044 15780 solver.cpp:228] Iteration 49700, loss = 0.419233
I1013 18:29:11.861101 15780 solver.cpp:244]     Train net output #0: loss = 0.419233 (* 1 = 0.419233 loss)
I1013 18:29:11.861107 15780 sgd_solver.cpp:106] Iteration 49700, lr = 0.000392056
I1013 18:29:16.240473 15780 solver.cpp:228] Iteration 49800, loss = 0.322375
I1013 18:29:16.240525 15780 solver.cpp:244]     Train net output #0: loss = 0.322375 (* 1 = 0.322375 loss)
I1013 18:29:16.240533 15780 sgd_solver.cpp:106] Iteration 49800, lr = 0.000391635
I1013 18:29:20.616600 15780 solver.cpp:228] Iteration 49900, loss = 0.564919
I1013 18:29:20.616648 15780 solver.cpp:244]     Train net output #0: loss = 0.564919 (* 1 = 0.564919 loss)
I1013 18:29:20.616655 15780 sgd_solver.cpp:106] Iteration 49900, lr = 0.000391214
I1013 18:29:24.957806 15780 solver.cpp:337] Iteration 50000, Testing net (#0)
I1013 18:29:29.920804 15780 solver.cpp:404]     Test net output #0: accuracy = 0.648792
I1013 18:29:29.920874 15780 solver.cpp:404]     Test net output #1: loss = 2.55319 (* 1 = 2.55319 loss)
I1013 18:29:29.936131 15780 solver.cpp:228] Iteration 50000, loss = 0.396523
I1013 18:29:29.936152 15780 solver.cpp:244]     Train net output #0: loss = 0.396523 (* 1 = 0.396523 loss)
I1013 18:29:29.936166 15780 sgd_solver.cpp:106] Iteration 50000, lr = 0.000390795
I1013 18:29:34.399565 15780 solver.cpp:228] Iteration 50100, loss = 0.250162
I1013 18:29:34.399588 15780 solver.cpp:244]     Train net output #0: loss = 0.250162 (* 1 = 0.250162 loss)
I1013 18:29:34.399595 15780 sgd_solver.cpp:106] Iteration 50100, lr = 0.000390377
I1013 18:29:38.851707 15780 solver.cpp:228] Iteration 50200, loss = 0.355393
I1013 18:29:38.851752 15780 solver.cpp:244]     Train net output #0: loss = 0.355393 (* 1 = 0.355393 loss)
I1013 18:29:38.851758 15780 sgd_solver.cpp:106] Iteration 50200, lr = 0.00038996
I1013 18:29:43.301761 15780 solver.cpp:228] Iteration 50300, loss = 0.446927
I1013 18:29:43.301792 15780 solver.cpp:244]     Train net output #0: loss = 0.446927 (* 1 = 0.446927 loss)
I1013 18:29:43.301798 15780 sgd_solver.cpp:106] Iteration 50300, lr = 0.000389544
