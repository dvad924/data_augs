WARNING: Logging before InitGoogleLogging() is written to STDERR
I0725 21:38:40.216939 22939 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 1e-05
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
snapshot: 5000
snapshot_prefix: "models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001"
solver_mode: GPU
net: "nets/person_vs_background_vs_random/trainval.prototxt"
I0725 21:38:40.217025 22939 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random/trainval.prototxt
I0725 21:38:40.217273 22939 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0725 21:38:40.217298 22939 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0725 21:38:40.217353 22939 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 96
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0725 21:38:40.217391 22939 layer_factory.hpp:77] Creating layer mnist
I0725 21:38:40.218103 22939 net.cpp:91] Creating Layer mnist
I0725 21:38:40.218116 22939 net.cpp:399] mnist -> data
I0725 21:38:40.218137 22939 net.cpp:399] mnist -> label
I0725 21:38:40.218150 22939 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0725 21:38:40.219588 22946 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0725 21:38:54.950357 22939 data_layer.cpp:41] output data size: 64,3,128,128
I0725 21:38:54.970520 22939 net.cpp:141] Setting up mnist
I0725 21:38:54.970572 22939 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0725 21:38:54.970578 22939 net.cpp:148] Top shape: 64 (64)
I0725 21:38:54.970582 22939 net.cpp:156] Memory required for data: 12583168
I0725 21:38:54.970590 22939 layer_factory.hpp:77] Creating layer conv1
I0725 21:38:54.970644 22939 net.cpp:91] Creating Layer conv1
I0725 21:38:54.970654 22939 net.cpp:425] conv1 <- data
I0725 21:38:54.970665 22939 net.cpp:399] conv1 -> conv1
I0725 21:38:55.085327 22939 net.cpp:141] Setting up conv1
I0725 21:38:55.085361 22939 net.cpp:148] Top shape: 64 96 124 124 (94470144)
I0725 21:38:55.085366 22939 net.cpp:156] Memory required for data: 390463744
I0725 21:38:55.085382 22939 layer_factory.hpp:77] Creating layer pool1
I0725 21:38:55.085394 22939 net.cpp:91] Creating Layer pool1
I0725 21:38:55.085398 22939 net.cpp:425] pool1 <- conv1
I0725 21:38:55.085403 22939 net.cpp:399] pool1 -> pool1
I0725 21:38:55.085448 22939 net.cpp:141] Setting up pool1
I0725 21:38:55.085459 22939 net.cpp:148] Top shape: 64 96 62 62 (23617536)
I0725 21:38:55.085464 22939 net.cpp:156] Memory required for data: 484933888
I0725 21:38:55.085467 22939 layer_factory.hpp:77] Creating layer conv2
I0725 21:38:55.085482 22939 net.cpp:91] Creating Layer conv2
I0725 21:38:55.085489 22939 net.cpp:425] conv2 <- pool1
I0725 21:38:55.085508 22939 net.cpp:399] conv2 -> conv2
I0725 21:38:55.087967 22939 net.cpp:141] Setting up conv2
I0725 21:38:55.087981 22939 net.cpp:148] Top shape: 64 50 58 58 (10764800)
I0725 21:38:55.087985 22939 net.cpp:156] Memory required for data: 527993088
I0725 21:38:55.087992 22939 layer_factory.hpp:77] Creating layer pool2
I0725 21:38:55.087999 22939 net.cpp:91] Creating Layer pool2
I0725 21:38:55.088002 22939 net.cpp:425] pool2 <- conv2
I0725 21:38:55.088006 22939 net.cpp:399] pool2 -> pool2
I0725 21:38:55.088040 22939 net.cpp:141] Setting up pool2
I0725 21:38:55.088049 22939 net.cpp:148] Top shape: 64 50 29 29 (2691200)
I0725 21:38:55.088064 22939 net.cpp:156] Memory required for data: 538757888
I0725 21:38:55.088069 22939 layer_factory.hpp:77] Creating layer ip1
I0725 21:38:55.088079 22939 net.cpp:91] Creating Layer ip1
I0725 21:38:55.088084 22939 net.cpp:425] ip1 <- pool2
I0725 21:38:55.088093 22939 net.cpp:399] ip1 -> ip1
I0725 21:38:55.235783 22939 net.cpp:141] Setting up ip1
I0725 21:38:55.235822 22939 net.cpp:148] Top shape: 64 500 (32000)
I0725 21:38:55.235826 22939 net.cpp:156] Memory required for data: 538885888
I0725 21:38:55.235841 22939 layer_factory.hpp:77] Creating layer relu1
I0725 21:38:55.235864 22939 net.cpp:91] Creating Layer relu1
I0725 21:38:55.235868 22939 net.cpp:425] relu1 <- ip1
I0725 21:38:55.235874 22939 net.cpp:386] relu1 -> ip1 (in-place)
I0725 21:38:55.236284 22939 net.cpp:141] Setting up relu1
I0725 21:38:55.236307 22939 net.cpp:148] Top shape: 64 500 (32000)
I0725 21:38:55.236310 22939 net.cpp:156] Memory required for data: 539013888
I0725 21:38:55.236315 22939 layer_factory.hpp:77] Creating layer ip2
I0725 21:38:55.236325 22939 net.cpp:91] Creating Layer ip2
I0725 21:38:55.236327 22939 net.cpp:425] ip2 <- ip1
I0725 21:38:55.236335 22939 net.cpp:399] ip2 -> ip2
I0725 21:38:55.236515 22939 net.cpp:141] Setting up ip2
I0725 21:38:55.236529 22939 net.cpp:148] Top shape: 64 3 (192)
I0725 21:38:55.236534 22939 net.cpp:156] Memory required for data: 539014656
I0725 21:38:55.236542 22939 layer_factory.hpp:77] Creating layer loss
I0725 21:38:55.236558 22939 net.cpp:91] Creating Layer loss
I0725 21:38:55.236564 22939 net.cpp:425] loss <- ip2
I0725 21:38:55.236569 22939 net.cpp:425] loss <- label
I0725 21:38:55.236577 22939 net.cpp:399] loss -> loss
I0725 21:38:55.236588 22939 layer_factory.hpp:77] Creating layer loss
I0725 21:38:55.236933 22939 net.cpp:141] Setting up loss
I0725 21:38:55.236948 22939 net.cpp:148] Top shape: (1)
I0725 21:38:55.236953 22939 net.cpp:151]     with loss weight 1
I0725 21:38:55.236979 22939 net.cpp:156] Memory required for data: 539014660
I0725 21:38:55.236985 22939 net.cpp:217] loss needs backward computation.
I0725 21:38:55.236990 22939 net.cpp:217] ip2 needs backward computation.
I0725 21:38:55.237006 22939 net.cpp:217] relu1 needs backward computation.
I0725 21:38:55.237011 22939 net.cpp:217] ip1 needs backward computation.
I0725 21:38:55.237015 22939 net.cpp:217] pool2 needs backward computation.
I0725 21:38:55.237017 22939 net.cpp:217] conv2 needs backward computation.
I0725 21:38:55.237020 22939 net.cpp:217] pool1 needs backward computation.
I0725 21:38:55.237023 22939 net.cpp:217] conv1 needs backward computation.
I0725 21:38:55.237027 22939 net.cpp:219] mnist does not need backward computation.
I0725 21:38:55.237030 22939 net.cpp:261] This network produces output loss
I0725 21:38:55.237037 22939 net.cpp:274] Network initialization done.
I0725 21:38:55.237479 22939 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random/trainval.prototxt
I0725 21:38:55.237540 22939 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0725 21:38:55.237705 22939 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 96
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0725 21:38:55.237789 22939 layer_factory.hpp:77] Creating layer mnist
I0725 21:38:55.237926 22939 net.cpp:91] Creating Layer mnist
I0725 21:38:55.237941 22939 net.cpp:399] mnist -> data
I0725 21:38:55.237951 22939 net.cpp:399] mnist -> label
I0725 21:38:55.237960 22939 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0725 21:38:55.239334 22949 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0725 21:38:55.239578 22939 data_layer.cpp:41] output data size: 100,3,128,128
I0725 21:38:55.272630 22939 net.cpp:141] Setting up mnist
I0725 21:38:55.272668 22939 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0725 21:38:55.272675 22939 net.cpp:148] Top shape: 100 (100)
I0725 21:38:55.272676 22939 net.cpp:156] Memory required for data: 19661200
I0725 21:38:55.272683 22939 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0725 21:38:55.272697 22939 net.cpp:91] Creating Layer label_mnist_1_split
I0725 21:38:55.272702 22939 net.cpp:425] label_mnist_1_split <- label
I0725 21:38:55.272708 22939 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0725 21:38:55.272718 22939 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0725 21:38:55.273026 22939 net.cpp:141] Setting up label_mnist_1_split
I0725 21:38:55.273041 22939 net.cpp:148] Top shape: 100 (100)
I0725 21:38:55.273047 22939 net.cpp:148] Top shape: 100 (100)
I0725 21:38:55.273051 22939 net.cpp:156] Memory required for data: 19662000
I0725 21:38:55.273056 22939 layer_factory.hpp:77] Creating layer conv1
I0725 21:38:55.273074 22939 net.cpp:91] Creating Layer conv1
I0725 21:38:55.273080 22939 net.cpp:425] conv1 <- data
I0725 21:38:55.273088 22939 net.cpp:399] conv1 -> conv1
I0725 21:38:55.277356 22939 net.cpp:141] Setting up conv1
I0725 21:38:55.277391 22939 net.cpp:148] Top shape: 100 96 124 124 (147609600)
I0725 21:38:55.277400 22939 net.cpp:156] Memory required for data: 610100400
I0725 21:38:55.277425 22939 layer_factory.hpp:77] Creating layer pool1
I0725 21:38:55.277441 22939 net.cpp:91] Creating Layer pool1
I0725 21:38:55.277456 22939 net.cpp:425] pool1 <- conv1
I0725 21:38:55.277475 22939 net.cpp:399] pool1 -> pool1
I0725 21:38:55.277612 22939 net.cpp:141] Setting up pool1
I0725 21:38:55.277624 22939 net.cpp:148] Top shape: 100 96 62 62 (36902400)
I0725 21:38:55.277629 22939 net.cpp:156] Memory required for data: 757710000
I0725 21:38:55.277634 22939 layer_factory.hpp:77] Creating layer conv2
I0725 21:38:55.277647 22939 net.cpp:91] Creating Layer conv2
I0725 21:38:55.277653 22939 net.cpp:425] conv2 <- pool1
I0725 21:38:55.277662 22939 net.cpp:399] conv2 -> conv2
I0725 21:38:55.279374 22939 net.cpp:141] Setting up conv2
I0725 21:38:55.279389 22939 net.cpp:148] Top shape: 100 50 58 58 (16820000)
I0725 21:38:55.279392 22939 net.cpp:156] Memory required for data: 824990000
I0725 21:38:55.279400 22939 layer_factory.hpp:77] Creating layer pool2
I0725 21:38:55.279424 22939 net.cpp:91] Creating Layer pool2
I0725 21:38:55.279429 22939 net.cpp:425] pool2 <- conv2
I0725 21:38:55.279433 22939 net.cpp:399] pool2 -> pool2
I0725 21:38:55.279485 22939 net.cpp:141] Setting up pool2
I0725 21:38:55.279498 22939 net.cpp:148] Top shape: 100 50 29 29 (4205000)
I0725 21:38:55.279505 22939 net.cpp:156] Memory required for data: 841810000
I0725 21:38:55.279510 22939 layer_factory.hpp:77] Creating layer ip1
I0725 21:38:55.279521 22939 net.cpp:91] Creating Layer ip1
I0725 21:38:55.279530 22939 net.cpp:425] ip1 <- pool2
I0725 21:38:55.279549 22939 net.cpp:399] ip1 -> ip1
I0725 21:38:55.427047 22939 net.cpp:141] Setting up ip1
I0725 21:38:55.427084 22939 net.cpp:148] Top shape: 100 500 (50000)
I0725 21:38:55.427088 22939 net.cpp:156] Memory required for data: 842010000
I0725 21:38:55.427103 22939 layer_factory.hpp:77] Creating layer relu1
I0725 21:38:55.427114 22939 net.cpp:91] Creating Layer relu1
I0725 21:38:55.427119 22939 net.cpp:425] relu1 <- ip1
I0725 21:38:55.427124 22939 net.cpp:386] relu1 -> ip1 (in-place)
I0725 21:38:55.427610 22939 net.cpp:141] Setting up relu1
I0725 21:38:55.427634 22939 net.cpp:148] Top shape: 100 500 (50000)
I0725 21:38:55.427637 22939 net.cpp:156] Memory required for data: 842210000
I0725 21:38:55.427641 22939 layer_factory.hpp:77] Creating layer ip2
I0725 21:38:55.427661 22939 net.cpp:91] Creating Layer ip2
I0725 21:38:55.427676 22939 net.cpp:425] ip2 <- ip1
I0725 21:38:55.427682 22939 net.cpp:399] ip2 -> ip2
I0725 21:38:55.427845 22939 net.cpp:141] Setting up ip2
I0725 21:38:55.427858 22939 net.cpp:148] Top shape: 100 3 (300)
I0725 21:38:55.427862 22939 net.cpp:156] Memory required for data: 842211200
I0725 21:38:55.427870 22939 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0725 21:38:55.427880 22939 net.cpp:91] Creating Layer ip2_ip2_0_split
I0725 21:38:55.427884 22939 net.cpp:425] ip2_ip2_0_split <- ip2
I0725 21:38:55.427891 22939 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0725 21:38:55.427899 22939 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0725 21:38:55.427942 22939 net.cpp:141] Setting up ip2_ip2_0_split
I0725 21:38:55.427953 22939 net.cpp:148] Top shape: 100 3 (300)
I0725 21:38:55.427958 22939 net.cpp:148] Top shape: 100 3 (300)
I0725 21:38:55.427963 22939 net.cpp:156] Memory required for data: 842213600
I0725 21:38:55.427966 22939 layer_factory.hpp:77] Creating layer accuracy
I0725 21:38:55.427975 22939 net.cpp:91] Creating Layer accuracy
I0725 21:38:55.427996 22939 net.cpp:425] accuracy <- ip2_ip2_0_split_0
I0725 21:38:55.428014 22939 net.cpp:425] accuracy <- label_mnist_1_split_0
I0725 21:38:55.428022 22939 net.cpp:399] accuracy -> accuracy
I0725 21:38:55.428035 22939 net.cpp:141] Setting up accuracy
I0725 21:38:55.428041 22939 net.cpp:148] Top shape: (1)
I0725 21:38:55.428046 22939 net.cpp:156] Memory required for data: 842213604
I0725 21:38:55.428050 22939 layer_factory.hpp:77] Creating layer loss
I0725 21:38:55.428069 22939 net.cpp:91] Creating Layer loss
I0725 21:38:55.428074 22939 net.cpp:425] loss <- ip2_ip2_0_split_1
I0725 21:38:55.428079 22939 net.cpp:425] loss <- label_mnist_1_split_1
I0725 21:38:55.428086 22939 net.cpp:399] loss -> loss
I0725 21:38:55.428097 22939 layer_factory.hpp:77] Creating layer loss
I0725 21:38:55.428460 22939 net.cpp:141] Setting up loss
I0725 21:38:55.428473 22939 net.cpp:148] Top shape: (1)
I0725 21:38:55.428478 22939 net.cpp:151]     with loss weight 1
I0725 21:38:55.428493 22939 net.cpp:156] Memory required for data: 842213608
I0725 21:38:55.428498 22939 net.cpp:217] loss needs backward computation.
I0725 21:38:55.428504 22939 net.cpp:219] accuracy does not need backward computation.
I0725 21:38:55.428509 22939 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0725 21:38:55.428514 22939 net.cpp:217] ip2 needs backward computation.
I0725 21:38:55.428519 22939 net.cpp:217] relu1 needs backward computation.
I0725 21:38:55.428524 22939 net.cpp:217] ip1 needs backward computation.
I0725 21:38:55.428529 22939 net.cpp:217] pool2 needs backward computation.
I0725 21:38:55.428532 22939 net.cpp:217] conv2 needs backward computation.
I0725 21:38:55.428539 22939 net.cpp:217] pool1 needs backward computation.
I0725 21:38:55.428544 22939 net.cpp:217] conv1 needs backward computation.
I0725 21:38:55.428549 22939 net.cpp:219] label_mnist_1_split does not need backward computation.
I0725 21:38:55.428553 22939 net.cpp:219] mnist does not need backward computation.
I0725 21:38:55.428557 22939 net.cpp:261] This network produces output accuracy
I0725 21:38:55.428562 22939 net.cpp:261] This network produces output loss
I0725 21:38:55.428588 22939 net.cpp:274] Network initialization done.
I0725 21:38:55.428689 22939 solver.cpp:60] Solver scaffolding done.
I0725 21:38:55.430467 22939 solver.cpp:337] Iteration 0, Testing net (#0)
I0725 21:38:56.708781 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 21:39:05.165277 22939 solver.cpp:404]     Test net output #0: accuracy = 0.552333
I0725 21:39:05.165331 22939 solver.cpp:404]     Test net output #1: loss = 1.0546 (* 1 = 1.0546 loss)
I0725 21:39:05.197823 22939 solver.cpp:228] Iteration 0, loss = 1.09255
I0725 21:39:05.197875 22939 solver.cpp:244]     Train net output #0: loss = 1.09255 (* 1 = 1.09255 loss)
I0725 21:39:05.197896 22939 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0725 21:39:13.606487 22939 solver.cpp:228] Iteration 100, loss = 1.04812
I0725 21:39:13.606544 22939 solver.cpp:244]     Train net output #0: loss = 1.04812 (* 1 = 1.04812 loss)
I0725 21:39:13.606554 22939 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-06
I0725 21:39:22.067677 22939 solver.cpp:228] Iteration 200, loss = 1.07191
I0725 21:39:22.067728 22939 solver.cpp:244]     Train net output #0: loss = 1.07191 (* 1 = 1.07191 loss)
I0725 21:39:22.067734 22939 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-06
I0725 21:39:30.586416 22939 solver.cpp:228] Iteration 300, loss = 1.00372
I0725 21:39:30.586851 22939 solver.cpp:244]     Train net output #0: loss = 1.00372 (* 1 = 1.00372 loss)
I0725 21:39:30.586858 22939 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-06
I0725 21:39:39.140784 22939 solver.cpp:228] Iteration 400, loss = 0.940574
I0725 21:39:39.140835 22939 solver.cpp:244]     Train net output #0: loss = 0.940574 (* 1 = 0.940574 loss)
I0725 21:39:39.140841 22939 sgd_solver.cpp:106] Iteration 400, lr = 9.85258e-06
I0725 21:39:47.875286 22939 solver.cpp:337] Iteration 500, Testing net (#0)
I0725 21:39:58.989883 22939 solver.cpp:404]     Test net output #0: accuracy = 0.551042
I0725 21:39:58.989939 22939 solver.cpp:404]     Test net output #1: loss = 0.941409 (* 1 = 0.941409 loss)
I0725 21:39:59.020046 22939 solver.cpp:228] Iteration 500, loss = 0.960649
I0725 21:39:59.020090 22939 solver.cpp:244]     Train net output #0: loss = 0.960649 (* 1 = 0.960649 loss)
I0725 21:39:59.020102 22939 sgd_solver.cpp:106] Iteration 500, lr = 9.81651e-06
I0725 21:40:08.360059 22939 solver.cpp:228] Iteration 600, loss = 1.00205
I0725 21:40:08.360126 22939 solver.cpp:244]     Train net output #0: loss = 1.00205 (* 1 = 1.00205 loss)
I0725 21:40:08.360131 22939 sgd_solver.cpp:106] Iteration 600, lr = 9.78075e-06
I0725 21:40:17.698369 22939 solver.cpp:228] Iteration 700, loss = 1.00456
I0725 21:40:17.698433 22939 solver.cpp:244]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0725 21:40:17.698441 22939 sgd_solver.cpp:106] Iteration 700, lr = 9.74529e-06
I0725 21:40:27.033821 22939 solver.cpp:228] Iteration 800, loss = 0.966074
I0725 21:40:27.033869 22939 solver.cpp:244]     Train net output #0: loss = 0.966074 (* 1 = 0.966074 loss)
I0725 21:40:27.033875 22939 sgd_solver.cpp:106] Iteration 800, lr = 9.71013e-06
I0725 21:40:36.369163 22939 solver.cpp:228] Iteration 900, loss = 1.01489
I0725 21:40:36.369211 22939 solver.cpp:244]     Train net output #0: loss = 1.01489 (* 1 = 1.01489 loss)
I0725 21:40:36.369217 22939 sgd_solver.cpp:106] Iteration 900, lr = 9.67526e-06
I0725 21:40:45.677990 22939 solver.cpp:337] Iteration 1000, Testing net (#0)
I0725 21:40:56.705845 22939 solver.cpp:404]     Test net output #0: accuracy = 0.561917
I0725 21:40:56.705899 22939 solver.cpp:404]     Test net output #1: loss = 0.925977 (* 1 = 0.925977 loss)
I0725 21:40:56.735471 22939 solver.cpp:228] Iteration 1000, loss = 1.01321
I0725 21:40:56.735491 22939 solver.cpp:244]     Train net output #0: loss = 1.01321 (* 1 = 1.01321 loss)
I0725 21:40:56.735510 22939 sgd_solver.cpp:106] Iteration 1000, lr = 9.64069e-06
I0725 21:41:06.141907 22939 solver.cpp:228] Iteration 1100, loss = 1.00904
I0725 21:41:06.141957 22939 solver.cpp:244]     Train net output #0: loss = 1.00904 (* 1 = 1.00904 loss)
I0725 21:41:06.141965 22939 sgd_solver.cpp:106] Iteration 1100, lr = 9.6064e-06
I0725 21:41:15.560094 22939 solver.cpp:228] Iteration 1200, loss = 0.96943
I0725 21:41:15.560147 22939 solver.cpp:244]     Train net output #0: loss = 0.96943 (* 1 = 0.96943 loss)
I0725 21:41:15.560153 22939 sgd_solver.cpp:106] Iteration 1200, lr = 9.5724e-06
I0725 21:41:24.980077 22939 solver.cpp:228] Iteration 1300, loss = 0.927634
I0725 21:41:24.980126 22939 solver.cpp:244]     Train net output #0: loss = 0.927634 (* 1 = 0.927634 loss)
I0725 21:41:24.980134 22939 sgd_solver.cpp:106] Iteration 1300, lr = 9.53867e-06
I0725 21:41:34.397950 22939 solver.cpp:228] Iteration 1400, loss = 0.981274
I0725 21:41:34.398000 22939 solver.cpp:244]     Train net output #0: loss = 0.981274 (* 1 = 0.981274 loss)
I0725 21:41:34.398007 22939 sgd_solver.cpp:106] Iteration 1400, lr = 9.50522e-06
I0725 21:41:43.731072 22939 solver.cpp:337] Iteration 1500, Testing net (#0)
I0725 21:41:54.866313 22939 solver.cpp:404]     Test net output #0: accuracy = 0.563166
I0725 21:41:54.866380 22939 solver.cpp:404]     Test net output #1: loss = 0.921804 (* 1 = 0.921804 loss)
I0725 21:41:54.898176 22939 solver.cpp:228] Iteration 1500, loss = 0.882388
I0725 21:41:54.898232 22939 solver.cpp:244]     Train net output #0: loss = 0.882388 (* 1 = 0.882388 loss)
I0725 21:41:54.898253 22939 sgd_solver.cpp:106] Iteration 1500, lr = 9.47204e-06
I0725 21:42:04.323078 22939 solver.cpp:228] Iteration 1600, loss = 0.967115
I0725 21:42:04.323124 22939 solver.cpp:244]     Train net output #0: loss = 0.967115 (* 1 = 0.967115 loss)
I0725 21:42:04.323132 22939 sgd_solver.cpp:106] Iteration 1600, lr = 9.43913e-06
I0725 21:42:13.898236 22939 solver.cpp:228] Iteration 1700, loss = 0.920022
I0725 21:42:13.898298 22939 solver.cpp:244]     Train net output #0: loss = 0.920022 (* 1 = 0.920022 loss)
I0725 21:42:13.898308 22939 sgd_solver.cpp:106] Iteration 1700, lr = 9.40649e-06
I0725 21:42:23.472618 22939 solver.cpp:228] Iteration 1800, loss = 0.998093
I0725 21:42:23.472671 22939 solver.cpp:244]     Train net output #0: loss = 0.998093 (* 1 = 0.998093 loss)
I0725 21:42:23.472681 22939 sgd_solver.cpp:106] Iteration 1800, lr = 9.37411e-06
I0725 21:42:32.888481 22939 solver.cpp:228] Iteration 1900, loss = 0.950133
I0725 21:42:32.888522 22939 solver.cpp:244]     Train net output #0: loss = 0.950133 (* 1 = 0.950133 loss)
I0725 21:42:32.888530 22939 sgd_solver.cpp:106] Iteration 1900, lr = 9.34199e-06
I0725 21:42:42.210928 22939 solver.cpp:337] Iteration 2000, Testing net (#0)
I0725 21:42:48.122776 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 21:42:53.315806 22939 solver.cpp:404]     Test net output #0: accuracy = 0.577583
I0725 21:42:53.315865 22939 solver.cpp:404]     Test net output #1: loss = 0.907106 (* 1 = 0.907106 loss)
I0725 21:42:53.342267 22939 solver.cpp:228] Iteration 2000, loss = 0.947323
I0725 21:42:53.342320 22939 solver.cpp:244]     Train net output #0: loss = 0.947323 (* 1 = 0.947323 loss)
I0725 21:42:53.342344 22939 sgd_solver.cpp:106] Iteration 2000, lr = 9.31012e-06
I0725 21:43:02.714912 22939 solver.cpp:228] Iteration 2100, loss = 0.93646
I0725 21:43:02.714951 22939 solver.cpp:244]     Train net output #0: loss = 0.93646 (* 1 = 0.93646 loss)
I0725 21:43:02.714957 22939 sgd_solver.cpp:106] Iteration 2100, lr = 9.27851e-06
I0725 21:43:12.214772 22939 solver.cpp:228] Iteration 2200, loss = 1.0009
I0725 21:43:12.214817 22939 solver.cpp:244]     Train net output #0: loss = 1.0009 (* 1 = 1.0009 loss)
I0725 21:43:12.214823 22939 sgd_solver.cpp:106] Iteration 2200, lr = 9.24715e-06
I0725 21:43:21.782699 22939 solver.cpp:228] Iteration 2300, loss = 0.910717
I0725 21:43:21.782745 22939 solver.cpp:244]     Train net output #0: loss = 0.910717 (* 1 = 0.910717 loss)
I0725 21:43:21.782752 22939 sgd_solver.cpp:106] Iteration 2300, lr = 9.21603e-06
I0725 21:43:31.354251 22939 solver.cpp:228] Iteration 2400, loss = 0.878521
I0725 21:43:31.354291 22939 solver.cpp:244]     Train net output #0: loss = 0.878521 (* 1 = 0.878521 loss)
I0725 21:43:31.354298 22939 sgd_solver.cpp:106] Iteration 2400, lr = 9.18515e-06
I0725 21:43:40.645723 22939 solver.cpp:337] Iteration 2500, Testing net (#0)
I0725 21:43:51.725764 22939 solver.cpp:404]     Test net output #0: accuracy = 0.583584
I0725 21:43:51.725826 22939 solver.cpp:404]     Test net output #1: loss = 0.900825 (* 1 = 0.900825 loss)
I0725 21:43:51.755877 22939 solver.cpp:228] Iteration 2500, loss = 0.901054
I0725 21:43:51.755936 22939 solver.cpp:244]     Train net output #0: loss = 0.901054 (* 1 = 0.901054 loss)
I0725 21:43:51.755954 22939 sgd_solver.cpp:106] Iteration 2500, lr = 9.15452e-06
I0725 21:44:01.166738 22939 solver.cpp:228] Iteration 2600, loss = 0.93474
I0725 21:44:01.166810 22939 solver.cpp:244]     Train net output #0: loss = 0.93474 (* 1 = 0.93474 loss)
I0725 21:44:01.166818 22939 sgd_solver.cpp:106] Iteration 2600, lr = 9.12412e-06
I0725 21:44:10.587254 22939 solver.cpp:228] Iteration 2700, loss = 0.929724
I0725 21:44:10.587296 22939 solver.cpp:244]     Train net output #0: loss = 0.929724 (* 1 = 0.929724 loss)
I0725 21:44:10.587302 22939 sgd_solver.cpp:106] Iteration 2700, lr = 9.09396e-06
I0725 21:44:20.004571 22939 solver.cpp:228] Iteration 2800, loss = 0.847878
I0725 21:44:20.004636 22939 solver.cpp:244]     Train net output #0: loss = 0.847878 (* 1 = 0.847878 loss)
I0725 21:44:20.004645 22939 sgd_solver.cpp:106] Iteration 2800, lr = 9.06403e-06
I0725 21:44:29.528096 22939 solver.cpp:228] Iteration 2900, loss = 0.898108
I0725 21:44:29.528141 22939 solver.cpp:244]     Train net output #0: loss = 0.898108 (* 1 = 0.898108 loss)
I0725 21:44:29.528147 22939 sgd_solver.cpp:106] Iteration 2900, lr = 9.03433e-06
I0725 21:44:39.020062 22939 solver.cpp:337] Iteration 3000, Testing net (#0)
I0725 21:44:50.060629 22939 solver.cpp:404]     Test net output #0: accuracy = 0.59525
I0725 21:44:50.060698 22939 solver.cpp:404]     Test net output #1: loss = 0.886441 (* 1 = 0.886441 loss)
I0725 21:44:50.090755 22939 solver.cpp:228] Iteration 3000, loss = 0.879118
I0725 21:44:50.090777 22939 solver.cpp:244]     Train net output #0: loss = 0.879118 (* 1 = 0.879118 loss)
I0725 21:44:50.090790 22939 sgd_solver.cpp:106] Iteration 3000, lr = 9.00485e-06
I0725 21:44:59.461231 22939 solver.cpp:228] Iteration 3100, loss = 0.861348
I0725 21:44:59.461292 22939 solver.cpp:244]     Train net output #0: loss = 0.861348 (* 1 = 0.861348 loss)
I0725 21:44:59.461298 22939 sgd_solver.cpp:106] Iteration 3100, lr = 8.9756e-06
I0725 21:45:08.879290 22939 solver.cpp:228] Iteration 3200, loss = 0.934751
I0725 21:45:08.879333 22939 solver.cpp:244]     Train net output #0: loss = 0.934751 (* 1 = 0.934751 loss)
I0725 21:45:08.879339 22939 sgd_solver.cpp:106] Iteration 3200, lr = 8.94657e-06
I0725 21:45:18.291937 22939 solver.cpp:228] Iteration 3300, loss = 0.869067
I0725 21:45:18.291990 22939 solver.cpp:244]     Train net output #0: loss = 0.869067 (* 1 = 0.869067 loss)
I0725 21:45:18.291999 22939 sgd_solver.cpp:106] Iteration 3300, lr = 8.91776e-06
I0725 21:45:27.704000 22939 solver.cpp:228] Iteration 3400, loss = 0.841359
I0725 21:45:27.704062 22939 solver.cpp:244]     Train net output #0: loss = 0.841359 (* 1 = 0.841359 loss)
I0725 21:45:27.704071 22939 sgd_solver.cpp:106] Iteration 3400, lr = 8.88916e-06
I0725 21:45:37.018921 22939 solver.cpp:337] Iteration 3500, Testing net (#0)
I0725 21:45:48.040117 22939 solver.cpp:404]     Test net output #0: accuracy = 0.603375
I0725 21:45:48.040165 22939 solver.cpp:404]     Test net output #1: loss = 0.878045 (* 1 = 0.878045 loss)
I0725 21:45:48.070463 22939 solver.cpp:228] Iteration 3500, loss = 0.867527
I0725 21:45:48.070498 22939 solver.cpp:244]     Train net output #0: loss = 0.867527 (* 1 = 0.867527 loss)
I0725 21:45:48.070519 22939 sgd_solver.cpp:106] Iteration 3500, lr = 8.86077e-06
I0725 21:45:57.474480 22939 solver.cpp:228] Iteration 3600, loss = 0.944273
I0725 21:45:57.474532 22939 solver.cpp:244]     Train net output #0: loss = 0.944273 (* 1 = 0.944273 loss)
I0725 21:45:57.474540 22939 sgd_solver.cpp:106] Iteration 3600, lr = 8.8326e-06
I0725 21:46:06.895346 22939 solver.cpp:228] Iteration 3700, loss = 0.871014
I0725 21:46:06.895401 22939 solver.cpp:244]     Train net output #0: loss = 0.871014 (* 1 = 0.871014 loss)
I0725 21:46:06.895416 22939 sgd_solver.cpp:106] Iteration 3700, lr = 8.80463e-06
I0725 21:46:16.316864 22939 solver.cpp:228] Iteration 3800, loss = 0.88239
I0725 21:46:16.316913 22939 solver.cpp:244]     Train net output #0: loss = 0.88239 (* 1 = 0.88239 loss)
I0725 21:46:16.316920 22939 sgd_solver.cpp:106] Iteration 3800, lr = 8.77687e-06
I0725 21:46:25.736796 22939 solver.cpp:228] Iteration 3900, loss = 0.869045
I0725 21:46:25.736857 22939 solver.cpp:244]     Train net output #0: loss = 0.869045 (* 1 = 0.869045 loss)
I0725 21:46:25.736866 22939 sgd_solver.cpp:106] Iteration 3900, lr = 8.74932e-06
I0725 21:46:35.054860 22939 solver.cpp:337] Iteration 4000, Testing net (#0)
I0725 21:46:39.655289 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 21:46:45.899891 22939 solver.cpp:404]     Test net output #0: accuracy = 0.613458
I0725 21:46:45.899950 22939 solver.cpp:404]     Test net output #1: loss = 0.864024 (* 1 = 0.864024 loss)
I0725 21:46:45.929031 22939 solver.cpp:228] Iteration 4000, loss = 0.81255
I0725 21:46:45.929061 22939 solver.cpp:244]     Train net output #0: loss = 0.81255 (* 1 = 0.81255 loss)
I0725 21:46:45.929071 22939 sgd_solver.cpp:106] Iteration 4000, lr = 8.72196e-06
I0725 21:46:55.370254 22939 solver.cpp:228] Iteration 4100, loss = 0.848435
I0725 21:46:55.370313 22939 solver.cpp:244]     Train net output #0: loss = 0.848435 (* 1 = 0.848435 loss)
I0725 21:46:55.370321 22939 sgd_solver.cpp:106] Iteration 4100, lr = 8.6948e-06
I0725 21:47:04.899914 22939 solver.cpp:228] Iteration 4200, loss = 0.823414
I0725 21:47:04.899984 22939 solver.cpp:244]     Train net output #0: loss = 0.823414 (* 1 = 0.823414 loss)
I0725 21:47:04.899993 22939 sgd_solver.cpp:106] Iteration 4200, lr = 8.66784e-06
I0725 21:47:14.322664 22939 solver.cpp:228] Iteration 4300, loss = 0.835133
I0725 21:47:14.322717 22939 solver.cpp:244]     Train net output #0: loss = 0.835133 (* 1 = 0.835133 loss)
I0725 21:47:14.322726 22939 sgd_solver.cpp:106] Iteration 4300, lr = 8.64107e-06
I0725 21:47:23.738911 22939 solver.cpp:228] Iteration 4400, loss = 0.807737
I0725 21:47:23.738950 22939 solver.cpp:244]     Train net output #0: loss = 0.807737 (* 1 = 0.807737 loss)
I0725 21:47:23.738955 22939 sgd_solver.cpp:106] Iteration 4400, lr = 8.6145e-06
I0725 21:47:33.069319 22939 solver.cpp:337] Iteration 4500, Testing net (#0)
I0725 21:47:44.036388 22939 solver.cpp:404]     Test net output #0: accuracy = 0.61775
I0725 21:47:44.036437 22939 solver.cpp:404]     Test net output #1: loss = 0.856188 (* 1 = 0.856188 loss)
I0725 21:47:44.063191 22939 solver.cpp:228] Iteration 4500, loss = 0.893505
I0725 21:47:44.063227 22939 solver.cpp:244]     Train net output #0: loss = 0.893505 (* 1 = 0.893505 loss)
I0725 21:47:44.063237 22939 sgd_solver.cpp:106] Iteration 4500, lr = 8.58812e-06
I0725 21:47:53.468189 22939 solver.cpp:228] Iteration 4600, loss = 0.792424
I0725 21:47:53.468233 22939 solver.cpp:244]     Train net output #0: loss = 0.792424 (* 1 = 0.792424 loss)
I0725 21:47:53.468240 22939 sgd_solver.cpp:106] Iteration 4600, lr = 8.56192e-06
I0725 21:48:02.877281 22939 solver.cpp:228] Iteration 4700, loss = 0.744904
I0725 21:48:02.877326 22939 solver.cpp:244]     Train net output #0: loss = 0.744904 (* 1 = 0.744904 loss)
I0725 21:48:02.877333 22939 sgd_solver.cpp:106] Iteration 4700, lr = 8.53591e-06
I0725 21:48:12.283345 22939 solver.cpp:228] Iteration 4800, loss = 0.886761
I0725 21:48:12.283391 22939 solver.cpp:244]     Train net output #0: loss = 0.886761 (* 1 = 0.886761 loss)
I0725 21:48:12.283397 22939 sgd_solver.cpp:106] Iteration 4800, lr = 8.51008e-06
I0725 21:48:21.690048 22939 solver.cpp:228] Iteration 4900, loss = 0.80097
I0725 21:48:21.690110 22939 solver.cpp:244]     Train net output #0: loss = 0.80097 (* 1 = 0.80097 loss)
I0725 21:48:21.690121 22939 sgd_solver.cpp:106] Iteration 4900, lr = 8.48444e-06
I0725 21:48:30.997501 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_5000.caffemodel
I0725 21:48:31.534409 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_5000.solverstate
I0725 21:48:31.736698 22939 solver.cpp:337] Iteration 5000, Testing net (#0)
I0725 21:48:42.289973 22939 solver.cpp:404]     Test net output #0: accuracy = 0.626875
I0725 21:48:42.290017 22939 solver.cpp:404]     Test net output #1: loss = 0.842947 (* 1 = 0.842947 loss)
I0725 21:48:42.319221 22939 solver.cpp:228] Iteration 5000, loss = 0.965439
I0725 21:48:42.319247 22939 solver.cpp:244]     Train net output #0: loss = 0.965439 (* 1 = 0.965439 loss)
I0725 21:48:42.319258 22939 sgd_solver.cpp:106] Iteration 5000, lr = 8.45897e-06
I0725 21:48:51.717120 22939 solver.cpp:228] Iteration 5100, loss = 0.78783
I0725 21:48:51.717195 22939 solver.cpp:244]     Train net output #0: loss = 0.78783 (* 1 = 0.78783 loss)
I0725 21:48:51.717201 22939 sgd_solver.cpp:106] Iteration 5100, lr = 8.43368e-06
I0725 21:49:01.131690 22939 solver.cpp:228] Iteration 5200, loss = 0.871384
I0725 21:49:01.131747 22939 solver.cpp:244]     Train net output #0: loss = 0.871384 (* 1 = 0.871384 loss)
I0725 21:49:01.131754 22939 sgd_solver.cpp:106] Iteration 5200, lr = 8.40857e-06
I0725 21:49:10.550601 22939 solver.cpp:228] Iteration 5300, loss = 0.843449
I0725 21:49:10.550659 22939 solver.cpp:244]     Train net output #0: loss = 0.843449 (* 1 = 0.843449 loss)
I0725 21:49:10.550668 22939 sgd_solver.cpp:106] Iteration 5300, lr = 8.38363e-06
I0725 21:49:19.969594 22939 solver.cpp:228] Iteration 5400, loss = 0.831236
I0725 21:49:19.969642 22939 solver.cpp:244]     Train net output #0: loss = 0.831236 (* 1 = 0.831236 loss)
I0725 21:49:19.969648 22939 sgd_solver.cpp:106] Iteration 5400, lr = 8.35886e-06
I0725 21:49:29.297994 22939 solver.cpp:337] Iteration 5500, Testing net (#0)
I0725 21:49:40.097164 22939 solver.cpp:404]     Test net output #0: accuracy = 0.630417
I0725 21:49:40.097225 22939 solver.cpp:404]     Test net output #1: loss = 0.836588 (* 1 = 0.836588 loss)
I0725 21:49:40.130156 22939 solver.cpp:228] Iteration 5500, loss = 0.752691
I0725 21:49:40.130208 22939 solver.cpp:244]     Train net output #0: loss = 0.752691 (* 1 = 0.752691 loss)
I0725 21:49:40.130230 22939 sgd_solver.cpp:106] Iteration 5500, lr = 8.33427e-06
I0725 21:49:49.542608 22939 solver.cpp:228] Iteration 5600, loss = 0.84064
I0725 21:49:49.542659 22939 solver.cpp:244]     Train net output #0: loss = 0.84064 (* 1 = 0.84064 loss)
I0725 21:49:49.542666 22939 sgd_solver.cpp:106] Iteration 5600, lr = 8.30984e-06
I0725 21:49:58.970497 22939 solver.cpp:228] Iteration 5700, loss = 0.951153
I0725 21:49:58.970562 22939 solver.cpp:244]     Train net output #0: loss = 0.951153 (* 1 = 0.951153 loss)
I0725 21:49:58.970568 22939 sgd_solver.cpp:106] Iteration 5700, lr = 8.28557e-06
I0725 21:50:08.396749 22939 solver.cpp:228] Iteration 5800, loss = 0.768499
I0725 21:50:08.396787 22939 solver.cpp:244]     Train net output #0: loss = 0.768499 (* 1 = 0.768499 loss)
I0725 21:50:08.396793 22939 sgd_solver.cpp:106] Iteration 5800, lr = 8.26148e-06
I0725 21:50:17.824203 22939 solver.cpp:228] Iteration 5900, loss = 0.860573
I0725 21:50:17.824265 22939 solver.cpp:244]     Train net output #0: loss = 0.860573 (* 1 = 0.860573 loss)
I0725 21:50:17.824272 22939 sgd_solver.cpp:106] Iteration 5900, lr = 8.23754e-06
I0725 21:50:27.160542 22939 solver.cpp:337] Iteration 6000, Testing net (#0)
I0725 21:50:30.700314 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 21:50:38.098274 22939 solver.cpp:404]     Test net output #0: accuracy = 0.638542
I0725 21:50:38.098333 22939 solver.cpp:404]     Test net output #1: loss = 0.82389 (* 1 = 0.82389 loss)
I0725 21:50:38.127696 22939 solver.cpp:228] Iteration 6000, loss = 0.851204
I0725 21:50:38.127725 22939 solver.cpp:244]     Train net output #0: loss = 0.851204 (* 1 = 0.851204 loss)
I0725 21:50:38.127735 22939 sgd_solver.cpp:106] Iteration 6000, lr = 8.21377e-06
I0725 21:50:47.479064 22939 solver.cpp:228] Iteration 6100, loss = 1.01504
I0725 21:50:47.479106 22939 solver.cpp:244]     Train net output #0: loss = 1.01504 (* 1 = 1.01504 loss)
I0725 21:50:47.479113 22939 sgd_solver.cpp:106] Iteration 6100, lr = 8.19015e-06
I0725 21:50:56.893565 22939 solver.cpp:228] Iteration 6200, loss = 0.878987
I0725 21:50:56.893613 22939 solver.cpp:244]     Train net output #0: loss = 0.878987 (* 1 = 0.878987 loss)
I0725 21:50:56.893620 22939 sgd_solver.cpp:106] Iteration 6200, lr = 8.1667e-06
I0725 21:51:06.303840 22939 solver.cpp:228] Iteration 6300, loss = 0.912621
I0725 21:51:06.303891 22939 solver.cpp:244]     Train net output #0: loss = 0.912621 (* 1 = 0.912621 loss)
I0725 21:51:06.303899 22939 sgd_solver.cpp:106] Iteration 6300, lr = 8.1434e-06
I0725 21:51:15.716409 22939 solver.cpp:228] Iteration 6400, loss = 0.750634
I0725 21:51:15.716449 22939 solver.cpp:244]     Train net output #0: loss = 0.750634 (* 1 = 0.750634 loss)
I0725 21:51:15.716455 22939 sgd_solver.cpp:106] Iteration 6400, lr = 8.12025e-06
I0725 21:51:25.038161 22939 solver.cpp:337] Iteration 6500, Testing net (#0)
I0725 21:51:35.935880 22939 solver.cpp:404]     Test net output #0: accuracy = 0.640833
I0725 21:51:35.935930 22939 solver.cpp:404]     Test net output #1: loss = 0.819105 (* 1 = 0.819105 loss)
I0725 21:51:35.964845 22939 solver.cpp:228] Iteration 6500, loss = 0.923355
I0725 21:51:35.964879 22939 solver.cpp:244]     Train net output #0: loss = 0.923355 (* 1 = 0.923355 loss)
I0725 21:51:35.964890 22939 sgd_solver.cpp:106] Iteration 6500, lr = 8.09726e-06
I0725 21:51:45.354207 22939 solver.cpp:228] Iteration 6600, loss = 0.841844
I0725 21:51:45.354266 22939 solver.cpp:244]     Train net output #0: loss = 0.841844 (* 1 = 0.841844 loss)
I0725 21:51:45.354274 22939 sgd_solver.cpp:106] Iteration 6600, lr = 8.07442e-06
I0725 21:51:54.771780 22939 solver.cpp:228] Iteration 6700, loss = 0.814459
I0725 21:51:54.771836 22939 solver.cpp:244]     Train net output #0: loss = 0.814459 (* 1 = 0.814459 loss)
I0725 21:51:54.771843 22939 sgd_solver.cpp:106] Iteration 6700, lr = 8.05173e-06
I0725 21:52:04.198941 22939 solver.cpp:228] Iteration 6800, loss = 0.859465
I0725 21:52:04.198992 22939 solver.cpp:244]     Train net output #0: loss = 0.859465 (* 1 = 0.859465 loss)
I0725 21:52:04.198998 22939 sgd_solver.cpp:106] Iteration 6800, lr = 8.02918e-06
I0725 21:52:13.616741 22939 solver.cpp:228] Iteration 6900, loss = 0.846503
I0725 21:52:13.616781 22939 solver.cpp:244]     Train net output #0: loss = 0.846503 (* 1 = 0.846503 loss)
I0725 21:52:13.616787 22939 sgd_solver.cpp:106] Iteration 6900, lr = 8.00679e-06
I0725 21:52:22.940886 22939 solver.cpp:337] Iteration 7000, Testing net (#0)
I0725 21:52:33.873369 22939 solver.cpp:404]     Test net output #0: accuracy = 0.646417
I0725 21:52:33.873420 22939 solver.cpp:404]     Test net output #1: loss = 0.807442 (* 1 = 0.807442 loss)
I0725 21:52:33.904877 22939 solver.cpp:228] Iteration 7000, loss = 0.717365
I0725 21:52:33.904903 22939 solver.cpp:244]     Train net output #0: loss = 0.717365 (* 1 = 0.717365 loss)
I0725 21:52:33.904924 22939 sgd_solver.cpp:106] Iteration 7000, lr = 7.98454e-06
I0725 21:52:43.255089 22939 solver.cpp:228] Iteration 7100, loss = 0.753924
I0725 21:52:43.255141 22939 solver.cpp:244]     Train net output #0: loss = 0.753924 (* 1 = 0.753924 loss)
I0725 21:52:43.255148 22939 sgd_solver.cpp:106] Iteration 7100, lr = 7.96243e-06
I0725 21:52:52.725067 22939 solver.cpp:228] Iteration 7200, loss = 0.808164
I0725 21:52:52.725119 22939 solver.cpp:244]     Train net output #0: loss = 0.808164 (* 1 = 0.808164 loss)
I0725 21:52:52.725126 22939 sgd_solver.cpp:106] Iteration 7200, lr = 7.94046e-06
I0725 21:53:02.306222 22939 solver.cpp:228] Iteration 7300, loss = 0.776649
I0725 21:53:02.306272 22939 solver.cpp:244]     Train net output #0: loss = 0.776649 (* 1 = 0.776649 loss)
I0725 21:53:02.306279 22939 sgd_solver.cpp:106] Iteration 7300, lr = 7.91864e-06
I0725 21:53:11.778972 22939 solver.cpp:228] Iteration 7400, loss = 0.770074
I0725 21:53:11.779042 22939 solver.cpp:244]     Train net output #0: loss = 0.770074 (* 1 = 0.770074 loss)
I0725 21:53:11.779049 22939 sgd_solver.cpp:106] Iteration 7400, lr = 7.89695e-06
I0725 21:53:21.105628 22939 solver.cpp:337] Iteration 7500, Testing net (#0)
I0725 21:53:31.961396 22939 solver.cpp:404]     Test net output #0: accuracy = 0.648542
I0725 21:53:31.961452 22939 solver.cpp:404]     Test net output #1: loss = 0.803052 (* 1 = 0.803052 loss)
I0725 21:53:31.991328 22939 solver.cpp:228] Iteration 7500, loss = 0.802939
I0725 21:53:31.991375 22939 solver.cpp:244]     Train net output #0: loss = 0.802939 (* 1 = 0.802939 loss)
I0725 21:53:31.991397 22939 sgd_solver.cpp:106] Iteration 7500, lr = 7.87541e-06
I0725 21:53:41.377171 22939 solver.cpp:228] Iteration 7600, loss = 0.773266
I0725 21:53:41.377224 22939 solver.cpp:244]     Train net output #0: loss = 0.773266 (* 1 = 0.773266 loss)
I0725 21:53:41.377233 22939 sgd_solver.cpp:106] Iteration 7600, lr = 7.854e-06
I0725 21:53:50.847329 22939 solver.cpp:228] Iteration 7700, loss = 0.75009
I0725 21:53:50.855574 22939 solver.cpp:244]     Train net output #0: loss = 0.75009 (* 1 = 0.75009 loss)
I0725 21:53:50.855588 22939 sgd_solver.cpp:106] Iteration 7700, lr = 7.83272e-06
I0725 21:54:00.428310 22939 solver.cpp:228] Iteration 7800, loss = 0.791446
I0725 21:54:00.428375 22939 solver.cpp:244]     Train net output #0: loss = 0.791446 (* 1 = 0.791446 loss)
I0725 21:54:00.428381 22939 sgd_solver.cpp:106] Iteration 7800, lr = 7.81158e-06
I0725 21:54:09.952036 22939 solver.cpp:228] Iteration 7900, loss = 0.914331
I0725 21:54:09.952088 22939 solver.cpp:244]     Train net output #0: loss = 0.914331 (* 1 = 0.914331 loss)
I0725 21:54:09.952098 22939 sgd_solver.cpp:106] Iteration 7900, lr = 7.79057e-06
I0725 21:54:19.212761 22939 solver.cpp:337] Iteration 8000, Testing net (#0)
I0725 21:54:30.146370 22939 solver.cpp:404]     Test net output #0: accuracy = 0.655083
I0725 21:54:30.146430 22939 solver.cpp:404]     Test net output #1: loss = 0.793136 (* 1 = 0.793136 loss)
I0725 21:54:30.175932 22939 solver.cpp:228] Iteration 8000, loss = 0.747248
I0725 21:54:30.175981 22939 solver.cpp:244]     Train net output #0: loss = 0.747248 (* 1 = 0.747248 loss)
I0725 21:54:30.175993 22939 sgd_solver.cpp:106] Iteration 8000, lr = 7.7697e-06
I0725 21:54:39.523324 22939 solver.cpp:228] Iteration 8100, loss = 0.795759
I0725 21:54:39.523367 22939 solver.cpp:244]     Train net output #0: loss = 0.795759 (* 1 = 0.795759 loss)
I0725 21:54:39.523375 22939 sgd_solver.cpp:106] Iteration 8100, lr = 7.74895e-06
I0725 21:54:49.054083 22939 solver.cpp:228] Iteration 8200, loss = 0.775389
I0725 21:54:49.054141 22939 solver.cpp:244]     Train net output #0: loss = 0.775389 (* 1 = 0.775389 loss)
I0725 21:54:49.054147 22939 sgd_solver.cpp:106] Iteration 8200, lr = 7.72833e-06
I0725 21:54:58.635437 22939 solver.cpp:228] Iteration 8300, loss = 0.776582
I0725 21:54:58.635496 22939 solver.cpp:244]     Train net output #0: loss = 0.776582 (* 1 = 0.776582 loss)
I0725 21:54:58.635504 22939 sgd_solver.cpp:106] Iteration 8300, lr = 7.70784e-06
I0725 21:55:08.085194 22939 solver.cpp:228] Iteration 8400, loss = 0.772837
I0725 21:55:08.085247 22939 solver.cpp:244]     Train net output #0: loss = 0.772837 (* 1 = 0.772837 loss)
I0725 21:55:08.085256 22939 sgd_solver.cpp:106] Iteration 8400, lr = 7.68748e-06
I0725 21:55:17.413508 22939 solver.cpp:337] Iteration 8500, Testing net (#0)
I0725 21:55:19.057744 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 21:55:28.364552 22939 solver.cpp:404]     Test net output #0: accuracy = 0.657542
I0725 21:55:28.364603 22939 solver.cpp:404]     Test net output #1: loss = 0.788745 (* 1 = 0.788745 loss)
I0725 21:55:28.394377 22939 solver.cpp:228] Iteration 8500, loss = 0.674763
I0725 21:55:28.394436 22939 solver.cpp:244]     Train net output #0: loss = 0.674763 (* 1 = 0.674763 loss)
I0725 21:55:28.394456 22939 sgd_solver.cpp:106] Iteration 8500, lr = 7.66724e-06
I0725 21:55:37.762728 22939 solver.cpp:228] Iteration 8600, loss = 0.762578
I0725 21:55:37.762778 22939 solver.cpp:244]     Train net output #0: loss = 0.762578 (* 1 = 0.762578 loss)
I0725 21:55:37.762784 22939 sgd_solver.cpp:106] Iteration 8600, lr = 7.64712e-06
I0725 21:55:47.182348 22939 solver.cpp:228] Iteration 8700, loss = 0.781065
I0725 21:55:47.182386 22939 solver.cpp:244]     Train net output #0: loss = 0.781065 (* 1 = 0.781065 loss)
I0725 21:55:47.182392 22939 sgd_solver.cpp:106] Iteration 8700, lr = 7.62713e-06
I0725 21:55:56.607662 22939 solver.cpp:228] Iteration 8800, loss = 0.861054
I0725 21:55:56.607709 22939 solver.cpp:244]     Train net output #0: loss = 0.861054 (* 1 = 0.861054 loss)
I0725 21:55:56.607715 22939 sgd_solver.cpp:106] Iteration 8800, lr = 7.60726e-06
I0725 21:56:06.034116 22939 solver.cpp:228] Iteration 8900, loss = 0.720567
I0725 21:56:06.034170 22939 solver.cpp:244]     Train net output #0: loss = 0.720567 (* 1 = 0.720567 loss)
I0725 21:56:06.034178 22939 sgd_solver.cpp:106] Iteration 8900, lr = 7.58751e-06
I0725 21:56:15.499335 22939 solver.cpp:337] Iteration 9000, Testing net (#0)
I0725 21:56:26.480552 22939 solver.cpp:404]     Test net output #0: accuracy = 0.662458
I0725 21:56:26.480602 22939 solver.cpp:404]     Test net output #1: loss = 0.780487 (* 1 = 0.780487 loss)
I0725 21:56:26.510088 22939 solver.cpp:228] Iteration 9000, loss = 0.626079
I0725 21:56:26.510136 22939 solver.cpp:244]     Train net output #0: loss = 0.626079 (* 1 = 0.626079 loss)
I0725 21:56:26.510161 22939 sgd_solver.cpp:106] Iteration 9000, lr = 7.56788e-06
I0725 21:56:35.838387 22939 solver.cpp:228] Iteration 9100, loss = 0.755656
I0725 21:56:35.838428 22939 solver.cpp:244]     Train net output #0: loss = 0.755656 (* 1 = 0.755656 loss)
I0725 21:56:35.838434 22939 sgd_solver.cpp:106] Iteration 9100, lr = 7.54836e-06
I0725 21:56:45.257892 22939 solver.cpp:228] Iteration 9200, loss = 0.717451
I0725 21:56:45.257947 22939 solver.cpp:244]     Train net output #0: loss = 0.717451 (* 1 = 0.717451 loss)
I0725 21:56:45.257954 22939 sgd_solver.cpp:106] Iteration 9200, lr = 7.52897e-06
I0725 21:56:54.674988 22939 solver.cpp:228] Iteration 9300, loss = 0.848569
I0725 21:56:54.675038 22939 solver.cpp:244]     Train net output #0: loss = 0.848569 (* 1 = 0.848569 loss)
I0725 21:56:54.675045 22939 sgd_solver.cpp:106] Iteration 9300, lr = 7.50969e-06
I0725 21:57:04.099781 22939 solver.cpp:228] Iteration 9400, loss = 0.720249
I0725 21:57:04.099834 22939 solver.cpp:244]     Train net output #0: loss = 0.720249 (* 1 = 0.720249 loss)
I0725 21:57:04.099840 22939 sgd_solver.cpp:106] Iteration 9400, lr = 7.49052e-06
I0725 21:57:13.422806 22939 solver.cpp:337] Iteration 9500, Testing net (#0)
I0725 21:57:24.394625 22939 solver.cpp:404]     Test net output #0: accuracy = 0.665792
I0725 21:57:24.394678 22939 solver.cpp:404]     Test net output #1: loss = 0.775582 (* 1 = 0.775582 loss)
I0725 21:57:24.424985 22939 solver.cpp:228] Iteration 9500, loss = 0.693507
I0725 21:57:24.425029 22939 solver.cpp:244]     Train net output #0: loss = 0.693507 (* 1 = 0.693507 loss)
I0725 21:57:24.425041 22939 sgd_solver.cpp:106] Iteration 9500, lr = 7.47147e-06
I0725 21:57:33.842954 22939 solver.cpp:228] Iteration 9600, loss = 0.819155
I0725 21:57:33.843009 22939 solver.cpp:244]     Train net output #0: loss = 0.819155 (* 1 = 0.819155 loss)
I0725 21:57:33.843029 22939 sgd_solver.cpp:106] Iteration 9600, lr = 7.45253e-06
I0725 21:57:43.266579 22939 solver.cpp:228] Iteration 9700, loss = 0.69525
I0725 21:57:43.266645 22939 solver.cpp:244]     Train net output #0: loss = 0.69525 (* 1 = 0.69525 loss)
I0725 21:57:43.266656 22939 sgd_solver.cpp:106] Iteration 9700, lr = 7.4337e-06
I0725 21:57:52.678400 22939 solver.cpp:228] Iteration 9800, loss = 0.683559
I0725 21:57:52.678453 22939 solver.cpp:244]     Train net output #0: loss = 0.683559 (* 1 = 0.683559 loss)
I0725 21:57:52.678460 22939 sgd_solver.cpp:106] Iteration 9800, lr = 7.41499e-06
I0725 21:58:02.093325 22939 solver.cpp:228] Iteration 9900, loss = 0.705444
I0725 21:58:02.093374 22939 solver.cpp:244]     Train net output #0: loss = 0.705444 (* 1 = 0.705444 loss)
I0725 21:58:02.093381 22939 sgd_solver.cpp:106] Iteration 9900, lr = 7.39638e-06
I0725 21:58:11.413494 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_10000.caffemodel
I0725 21:58:11.886909 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_10000.solverstate
I0725 21:58:12.091677 22939 solver.cpp:337] Iteration 10000, Testing net (#0)
I0725 21:58:22.811375 22939 solver.cpp:404]     Test net output #0: accuracy = 0.669208
I0725 21:58:22.811444 22939 solver.cpp:404]     Test net output #1: loss = 0.76935 (* 1 = 0.76935 loss)
I0725 21:58:22.841439 22939 solver.cpp:228] Iteration 10000, loss = 0.831321
I0725 21:58:22.841485 22939 solver.cpp:244]     Train net output #0: loss = 0.831321 (* 1 = 0.831321 loss)
I0725 21:58:22.841511 22939 sgd_solver.cpp:106] Iteration 10000, lr = 7.37788e-06
I0725 21:58:32.268314 22939 solver.cpp:228] Iteration 10100, loss = 0.72493
I0725 21:58:32.268369 22939 solver.cpp:244]     Train net output #0: loss = 0.72493 (* 1 = 0.72493 loss)
I0725 21:58:32.268378 22939 sgd_solver.cpp:106] Iteration 10100, lr = 7.35949e-06
I0725 21:58:41.839234 22939 solver.cpp:228] Iteration 10200, loss = 0.703862
I0725 21:58:41.839293 22939 solver.cpp:244]     Train net output #0: loss = 0.703862 (* 1 = 0.703862 loss)
I0725 21:58:41.839300 22939 sgd_solver.cpp:106] Iteration 10200, lr = 7.3412e-06
I0725 21:58:51.406745 22939 solver.cpp:228] Iteration 10300, loss = 0.836041
I0725 21:58:51.406795 22939 solver.cpp:244]     Train net output #0: loss = 0.836041 (* 1 = 0.836041 loss)
I0725 21:58:51.406801 22939 sgd_solver.cpp:106] Iteration 10300, lr = 7.32302e-06
I0725 21:59:00.901815 22939 solver.cpp:228] Iteration 10400, loss = 0.872794
I0725 21:59:00.901850 22939 solver.cpp:244]     Train net output #0: loss = 0.872794 (* 1 = 0.872794 loss)
I0725 21:59:00.901856 22939 sgd_solver.cpp:106] Iteration 10400, lr = 7.30495e-06
I0725 21:59:10.228431 22939 solver.cpp:337] Iteration 10500, Testing net (#0)
I0725 21:59:21.137207 22939 solver.cpp:404]     Test net output #0: accuracy = 0.671583
I0725 21:59:21.137260 22939 solver.cpp:404]     Test net output #1: loss = 0.764255 (* 1 = 0.764255 loss)
I0725 21:59:21.166517 22939 solver.cpp:228] Iteration 10500, loss = 0.806636
I0725 21:59:21.166545 22939 solver.cpp:244]     Train net output #0: loss = 0.806636 (* 1 = 0.806636 loss)
I0725 21:59:21.166556 22939 sgd_solver.cpp:106] Iteration 10500, lr = 7.28698e-06
I0725 21:59:30.509930 22939 solver.cpp:228] Iteration 10600, loss = 0.860236
I0725 21:59:30.509979 22939 solver.cpp:244]     Train net output #0: loss = 0.860236 (* 1 = 0.860236 loss)
I0725 21:59:30.509986 22939 sgd_solver.cpp:106] Iteration 10600, lr = 7.26911e-06
I0725 21:59:39.907917 22939 solver.cpp:228] Iteration 10700, loss = 0.599974
I0725 21:59:39.907960 22939 solver.cpp:244]     Train net output #0: loss = 0.599974 (* 1 = 0.599974 loss)
I0725 21:59:39.907968 22939 sgd_solver.cpp:106] Iteration 10700, lr = 7.25135e-06
I0725 21:59:49.464458 22939 solver.cpp:228] Iteration 10800, loss = 0.786617
I0725 21:59:49.464521 22939 solver.cpp:244]     Train net output #0: loss = 0.786617 (* 1 = 0.786617 loss)
I0725 21:59:49.464531 22939 sgd_solver.cpp:106] Iteration 10800, lr = 7.23368e-06
I0725 21:59:59.031234 22939 solver.cpp:228] Iteration 10900, loss = 0.831615
I0725 21:59:59.031275 22939 solver.cpp:244]     Train net output #0: loss = 0.831615 (* 1 = 0.831615 loss)
I0725 21:59:59.031280 22939 sgd_solver.cpp:106] Iteration 10900, lr = 7.21612e-06
I0725 22:00:08.500097 22939 solver.cpp:337] Iteration 11000, Testing net (#0)
I0725 22:00:10.833963 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:00:19.451326 22939 solver.cpp:404]     Test net output #0: accuracy = 0.676459
I0725 22:00:19.451386 22939 solver.cpp:404]     Test net output #1: loss = 0.757821 (* 1 = 0.757821 loss)
I0725 22:00:19.480412 22939 solver.cpp:228] Iteration 11000, loss = 0.7263
I0725 22:00:19.480463 22939 solver.cpp:244]     Train net output #0: loss = 0.7263 (* 1 = 0.7263 loss)
I0725 22:00:19.480480 22939 sgd_solver.cpp:106] Iteration 11000, lr = 7.19865e-06
I0725 22:00:28.855202 22939 solver.cpp:228] Iteration 11100, loss = 0.781038
I0725 22:00:28.855244 22939 solver.cpp:244]     Train net output #0: loss = 0.781038 (* 1 = 0.781038 loss)
I0725 22:00:28.855250 22939 sgd_solver.cpp:106] Iteration 11100, lr = 7.18129e-06
I0725 22:00:38.417551 22939 solver.cpp:228] Iteration 11200, loss = 0.750013
I0725 22:00:38.417600 22939 solver.cpp:244]     Train net output #0: loss = 0.750013 (* 1 = 0.750013 loss)
I0725 22:00:38.417606 22939 sgd_solver.cpp:106] Iteration 11200, lr = 7.16402e-06
I0725 22:00:47.937111 22939 solver.cpp:228] Iteration 11300, loss = 0.669586
I0725 22:00:47.937166 22939 solver.cpp:244]     Train net output #0: loss = 0.669586 (* 1 = 0.669586 loss)
I0725 22:00:47.937173 22939 sgd_solver.cpp:106] Iteration 11300, lr = 7.14684e-06
I0725 22:00:57.335947 22939 solver.cpp:228] Iteration 11400, loss = 0.729818
I0725 22:00:57.335994 22939 solver.cpp:244]     Train net output #0: loss = 0.729818 (* 1 = 0.729818 loss)
I0725 22:00:57.335999 22939 sgd_solver.cpp:106] Iteration 11400, lr = 7.12977e-06
I0725 22:01:06.643374 22939 solver.cpp:337] Iteration 11500, Testing net (#0)
I0725 22:01:17.512482 22939 solver.cpp:404]     Test net output #0: accuracy = 0.679041
I0725 22:01:17.512539 22939 solver.cpp:404]     Test net output #1: loss = 0.753299 (* 1 = 0.753299 loss)
I0725 22:01:17.541419 22939 solver.cpp:228] Iteration 11500, loss = 0.682655
I0725 22:01:17.541438 22939 solver.cpp:244]     Train net output #0: loss = 0.682655 (* 1 = 0.682655 loss)
I0725 22:01:17.541448 22939 sgd_solver.cpp:106] Iteration 11500, lr = 7.11278e-06
I0725 22:01:26.944301 22939 solver.cpp:228] Iteration 11600, loss = 0.714445
I0725 22:01:26.944344 22939 solver.cpp:244]     Train net output #0: loss = 0.714445 (* 1 = 0.714445 loss)
I0725 22:01:26.944350 22939 sgd_solver.cpp:106] Iteration 11600, lr = 7.09589e-06
I0725 22:01:36.344620 22939 solver.cpp:228] Iteration 11700, loss = 0.672734
I0725 22:01:36.344662 22939 solver.cpp:244]     Train net output #0: loss = 0.672734 (* 1 = 0.672734 loss)
I0725 22:01:36.344668 22939 sgd_solver.cpp:106] Iteration 11700, lr = 7.0791e-06
I0725 22:01:45.904784 22939 solver.cpp:228] Iteration 11800, loss = 0.793626
I0725 22:01:45.904840 22939 solver.cpp:244]     Train net output #0: loss = 0.793626 (* 1 = 0.793626 loss)
I0725 22:01:45.904847 22939 sgd_solver.cpp:106] Iteration 11800, lr = 7.0624e-06
I0725 22:01:55.473091 22939 solver.cpp:228] Iteration 11900, loss = 0.71088
I0725 22:01:55.473136 22939 solver.cpp:244]     Train net output #0: loss = 0.71088 (* 1 = 0.71088 loss)
I0725 22:01:55.473142 22939 sgd_solver.cpp:106] Iteration 11900, lr = 7.04579e-06
I0725 22:02:04.799195 22939 solver.cpp:337] Iteration 12000, Testing net (#0)
I0725 22:02:15.696307 22939 solver.cpp:404]     Test net output #0: accuracy = 0.681625
I0725 22:02:15.696363 22939 solver.cpp:404]     Test net output #1: loss = 0.748769 (* 1 = 0.748769 loss)
I0725 22:02:15.722959 22939 solver.cpp:228] Iteration 12000, loss = 0.769174
I0725 22:02:15.723003 22939 solver.cpp:244]     Train net output #0: loss = 0.769174 (* 1 = 0.769174 loss)
I0725 22:02:15.723018 22939 sgd_solver.cpp:106] Iteration 12000, lr = 7.02927e-06
I0725 22:02:25.079044 22939 solver.cpp:228] Iteration 12100, loss = 0.680384
I0725 22:02:25.079087 22939 solver.cpp:244]     Train net output #0: loss = 0.680384 (* 1 = 0.680384 loss)
I0725 22:02:25.079093 22939 sgd_solver.cpp:106] Iteration 12100, lr = 7.01284e-06
I0725 22:02:34.475469 22939 solver.cpp:228] Iteration 12200, loss = 0.772894
I0725 22:02:34.475512 22939 solver.cpp:244]     Train net output #0: loss = 0.772894 (* 1 = 0.772894 loss)
I0725 22:02:34.475518 22939 sgd_solver.cpp:106] Iteration 12200, lr = 6.9965e-06
I0725 22:02:43.971503 22939 solver.cpp:228] Iteration 12300, loss = 0.714349
I0725 22:02:43.971546 22939 solver.cpp:244]     Train net output #0: loss = 0.714349 (* 1 = 0.714349 loss)
I0725 22:02:43.971552 22939 sgd_solver.cpp:106] Iteration 12300, lr = 6.98024e-06
I0725 22:02:53.533012 22939 solver.cpp:228] Iteration 12400, loss = 0.734336
I0725 22:02:53.533054 22939 solver.cpp:244]     Train net output #0: loss = 0.734336 (* 1 = 0.734336 loss)
I0725 22:02:53.533061 22939 sgd_solver.cpp:106] Iteration 12400, lr = 6.96408e-06
I0725 22:03:02.899920 22939 solver.cpp:337] Iteration 12500, Testing net (#0)
I0725 22:03:13.805629 22939 solver.cpp:404]     Test net output #0: accuracy = 0.684333
I0725 22:03:13.805673 22939 solver.cpp:404]     Test net output #1: loss = 0.743943 (* 1 = 0.743943 loss)
I0725 22:03:13.835156 22939 solver.cpp:228] Iteration 12500, loss = 0.645484
I0725 22:03:13.835175 22939 solver.cpp:244]     Train net output #0: loss = 0.645484 (* 1 = 0.645484 loss)
I0725 22:03:13.835185 22939 sgd_solver.cpp:106] Iteration 12500, lr = 6.948e-06
I0725 22:03:23.235872 22939 solver.cpp:228] Iteration 12600, loss = 0.693425
I0725 22:03:23.235918 22939 solver.cpp:244]     Train net output #0: loss = 0.693425 (* 1 = 0.693425 loss)
I0725 22:03:23.235926 22939 sgd_solver.cpp:106] Iteration 12600, lr = 6.93201e-06
I0725 22:03:32.634050 22939 solver.cpp:228] Iteration 12700, loss = 0.717541
I0725 22:03:32.634093 22939 solver.cpp:244]     Train net output #0: loss = 0.717541 (* 1 = 0.717541 loss)
I0725 22:03:32.634099 22939 sgd_solver.cpp:106] Iteration 12700, lr = 6.91611e-06
I0725 22:03:42.036993 22939 solver.cpp:228] Iteration 12800, loss = 0.677919
I0725 22:03:42.037035 22939 solver.cpp:244]     Train net output #0: loss = 0.677919 (* 1 = 0.677919 loss)
I0725 22:03:42.037041 22939 sgd_solver.cpp:106] Iteration 12800, lr = 6.90029e-06
I0725 22:03:51.438602 22939 solver.cpp:228] Iteration 12900, loss = 0.749834
I0725 22:03:51.438650 22939 solver.cpp:244]     Train net output #0: loss = 0.749834 (* 1 = 0.749834 loss)
I0725 22:03:51.438657 22939 sgd_solver.cpp:106] Iteration 12900, lr = 6.88455e-06
I0725 22:04:00.750501 22939 solver.cpp:337] Iteration 13000, Testing net (#0)
I0725 22:04:04.876911 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:04:11.679721 22939 solver.cpp:404]     Test net output #0: accuracy = 0.685833
I0725 22:04:11.679778 22939 solver.cpp:404]     Test net output #1: loss = 0.740528 (* 1 = 0.740528 loss)
I0725 22:04:11.706420 22939 solver.cpp:228] Iteration 13000, loss = 0.729863
I0725 22:04:11.706444 22939 solver.cpp:244]     Train net output #0: loss = 0.729863 (* 1 = 0.729863 loss)
I0725 22:04:11.706454 22939 sgd_solver.cpp:106] Iteration 13000, lr = 6.8689e-06
I0725 22:04:21.242569 22939 solver.cpp:228] Iteration 13100, loss = 0.87242
I0725 22:04:21.242629 22939 solver.cpp:244]     Train net output #0: loss = 0.87242 (* 1 = 0.87242 loss)
I0725 22:04:21.242635 22939 sgd_solver.cpp:106] Iteration 13100, lr = 6.85333e-06
I0725 22:04:30.813045 22939 solver.cpp:228] Iteration 13200, loss = 0.599157
I0725 22:04:30.813099 22939 solver.cpp:244]     Train net output #0: loss = 0.599157 (* 1 = 0.599157 loss)
I0725 22:04:30.813107 22939 sgd_solver.cpp:106] Iteration 13200, lr = 6.83784e-06
I0725 22:04:40.287880 22939 solver.cpp:228] Iteration 13300, loss = 0.632776
I0725 22:04:40.287927 22939 solver.cpp:244]     Train net output #0: loss = 0.632776 (* 1 = 0.632776 loss)
I0725 22:04:40.287933 22939 sgd_solver.cpp:106] Iteration 13300, lr = 6.82243e-06
I0725 22:04:49.698446 22939 solver.cpp:228] Iteration 13400, loss = 0.709315
I0725 22:04:49.698500 22939 solver.cpp:244]     Train net output #0: loss = 0.709315 (* 1 = 0.709315 loss)
I0725 22:04:49.698508 22939 sgd_solver.cpp:106] Iteration 13400, lr = 6.80711e-06
I0725 22:04:59.011840 22939 solver.cpp:337] Iteration 13500, Testing net (#0)
I0725 22:05:09.975514 22939 solver.cpp:404]     Test net output #0: accuracy = 0.688125
I0725 22:05:09.975565 22939 solver.cpp:404]     Test net output #1: loss = 0.734298 (* 1 = 0.734298 loss)
I0725 22:05:10.002589 22939 solver.cpp:228] Iteration 13500, loss = 0.761651
I0725 22:05:10.002653 22939 solver.cpp:244]     Train net output #0: loss = 0.761651 (* 1 = 0.761651 loss)
I0725 22:05:10.002672 22939 sgd_solver.cpp:106] Iteration 13500, lr = 6.79186e-06
I0725 22:05:19.387472 22939 solver.cpp:228] Iteration 13600, loss = 0.617673
I0725 22:05:19.387516 22939 solver.cpp:244]     Train net output #0: loss = 0.617673 (* 1 = 0.617673 loss)
I0725 22:05:19.387523 22939 sgd_solver.cpp:106] Iteration 13600, lr = 6.7767e-06
I0725 22:05:28.785759 22939 solver.cpp:228] Iteration 13700, loss = 0.671762
I0725 22:05:28.785801 22939 solver.cpp:244]     Train net output #0: loss = 0.671762 (* 1 = 0.671762 loss)
I0725 22:05:28.785807 22939 sgd_solver.cpp:106] Iteration 13700, lr = 6.76161e-06
I0725 22:05:38.189777 22939 solver.cpp:228] Iteration 13800, loss = 0.704089
I0725 22:05:38.189826 22939 solver.cpp:244]     Train net output #0: loss = 0.704089 (* 1 = 0.704089 loss)
I0725 22:05:38.189831 22939 sgd_solver.cpp:106] Iteration 13800, lr = 6.7466e-06
I0725 22:05:47.590406 22939 solver.cpp:228] Iteration 13900, loss = 0.801041
I0725 22:05:47.590456 22939 solver.cpp:244]     Train net output #0: loss = 0.801041 (* 1 = 0.801041 loss)
I0725 22:05:47.590461 22939 sgd_solver.cpp:106] Iteration 13900, lr = 6.73167e-06
I0725 22:05:56.899121 22939 solver.cpp:337] Iteration 14000, Testing net (#0)
I0725 22:06:07.764475 22939 solver.cpp:404]     Test net output #0: accuracy = 0.688125
I0725 22:06:07.764518 22939 solver.cpp:404]     Test net output #1: loss = 0.733596 (* 1 = 0.733596 loss)
I0725 22:06:07.797731 22939 solver.cpp:228] Iteration 14000, loss = 0.648452
I0725 22:06:07.797776 22939 solver.cpp:244]     Train net output #0: loss = 0.648452 (* 1 = 0.648452 loss)
I0725 22:06:07.797797 22939 sgd_solver.cpp:106] Iteration 14000, lr = 6.71681e-06
I0725 22:06:17.200381 22939 solver.cpp:228] Iteration 14100, loss = 0.696147
I0725 22:06:17.200441 22939 solver.cpp:244]     Train net output #0: loss = 0.696147 (* 1 = 0.696147 loss)
I0725 22:06:17.200451 22939 sgd_solver.cpp:106] Iteration 14100, lr = 6.70204e-06
I0725 22:06:26.598285 22939 solver.cpp:228] Iteration 14200, loss = 0.709137
I0725 22:06:26.598345 22939 solver.cpp:244]     Train net output #0: loss = 0.709137 (* 1 = 0.709137 loss)
I0725 22:06:26.598351 22939 sgd_solver.cpp:106] Iteration 14200, lr = 6.68733e-06
I0725 22:06:35.999747 22939 solver.cpp:228] Iteration 14300, loss = 0.753778
I0725 22:06:35.999794 22939 solver.cpp:244]     Train net output #0: loss = 0.753778 (* 1 = 0.753778 loss)
I0725 22:06:35.999800 22939 sgd_solver.cpp:106] Iteration 14300, lr = 6.6727e-06
I0725 22:06:45.401422 22939 solver.cpp:228] Iteration 14400, loss = 0.669163
I0725 22:06:45.401466 22939 solver.cpp:244]     Train net output #0: loss = 0.669163 (* 1 = 0.669163 loss)
I0725 22:06:45.401471 22939 sgd_solver.cpp:106] Iteration 14400, lr = 6.65815e-06
I0725 22:06:54.702889 22939 solver.cpp:337] Iteration 14500, Testing net (#0)
I0725 22:07:05.623247 22939 solver.cpp:404]     Test net output #0: accuracy = 0.691708
I0725 22:07:05.623299 22939 solver.cpp:404]     Test net output #1: loss = 0.725238 (* 1 = 0.725238 loss)
I0725 22:07:05.655771 22939 solver.cpp:228] Iteration 14500, loss = 0.6853
I0725 22:07:05.655817 22939 solver.cpp:244]     Train net output #0: loss = 0.6853 (* 1 = 0.6853 loss)
I0725 22:07:05.655827 22939 sgd_solver.cpp:106] Iteration 14500, lr = 6.64367e-06
I0725 22:07:15.015126 22939 solver.cpp:228] Iteration 14600, loss = 0.763241
I0725 22:07:15.015172 22939 solver.cpp:244]     Train net output #0: loss = 0.763241 (* 1 = 0.763241 loss)
I0725 22:07:15.015179 22939 sgd_solver.cpp:106] Iteration 14600, lr = 6.62927e-06
I0725 22:07:24.420881 22939 solver.cpp:228] Iteration 14700, loss = 0.766395
I0725 22:07:24.420928 22939 solver.cpp:244]     Train net output #0: loss = 0.766395 (* 1 = 0.766395 loss)
I0725 22:07:24.420933 22939 sgd_solver.cpp:106] Iteration 14700, lr = 6.61493e-06
I0725 22:07:33.826891 22939 solver.cpp:228] Iteration 14800, loss = 0.809931
I0725 22:07:33.826937 22939 solver.cpp:244]     Train net output #0: loss = 0.809931 (* 1 = 0.809931 loss)
I0725 22:07:33.826943 22939 sgd_solver.cpp:106] Iteration 14800, lr = 6.60067e-06
I0725 22:07:43.232311 22939 solver.cpp:228] Iteration 14900, loss = 0.742106
I0725 22:07:43.232359 22939 solver.cpp:244]     Train net output #0: loss = 0.742106 (* 1 = 0.742106 loss)
I0725 22:07:43.232367 22939 sgd_solver.cpp:106] Iteration 14900, lr = 6.58648e-06
I0725 22:07:52.546885 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_15000.caffemodel
I0725 22:07:52.887737 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_15000.solverstate
I0725 22:07:52.995136 22939 solver.cpp:337] Iteration 15000, Testing net (#0)
I0725 22:07:55.370127 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:08:03.788152 22939 solver.cpp:404]     Test net output #0: accuracy = 0.690875
I0725 22:08:03.788208 22939 solver.cpp:404]     Test net output #1: loss = 0.726138 (* 1 = 0.726138 loss)
I0725 22:08:03.817782 22939 solver.cpp:228] Iteration 15000, loss = 0.639891
I0725 22:08:03.817814 22939 solver.cpp:244]     Train net output #0: loss = 0.639891 (* 1 = 0.639891 loss)
I0725 22:08:03.817826 22939 sgd_solver.cpp:106] Iteration 15000, lr = 6.57236e-06
I0725 22:08:13.214680 22939 solver.cpp:228] Iteration 15100, loss = 0.715197
I0725 22:08:13.214727 22939 solver.cpp:244]     Train net output #0: loss = 0.715197 (* 1 = 0.715197 loss)
I0725 22:08:13.214733 22939 sgd_solver.cpp:106] Iteration 15100, lr = 6.55831e-06
I0725 22:08:22.612625 22939 solver.cpp:228] Iteration 15200, loss = 0.82422
I0725 22:08:22.612668 22939 solver.cpp:244]     Train net output #0: loss = 0.82422 (* 1 = 0.82422 loss)
I0725 22:08:22.612674 22939 sgd_solver.cpp:106] Iteration 15200, lr = 6.54433e-06
I0725 22:08:32.011518 22939 solver.cpp:228] Iteration 15300, loss = 0.667291
I0725 22:08:32.011566 22939 solver.cpp:244]     Train net output #0: loss = 0.667291 (* 1 = 0.667291 loss)
I0725 22:08:32.011572 22939 sgd_solver.cpp:106] Iteration 15300, lr = 6.53043e-06
I0725 22:08:41.406664 22939 solver.cpp:228] Iteration 15400, loss = 0.73185
I0725 22:08:41.406723 22939 solver.cpp:244]     Train net output #0: loss = 0.73185 (* 1 = 0.73185 loss)
I0725 22:08:41.406730 22939 sgd_solver.cpp:106] Iteration 15400, lr = 6.51658e-06
I0725 22:08:50.706224 22939 solver.cpp:337] Iteration 15500, Testing net (#0)
I0725 22:09:01.596846 22939 solver.cpp:404]     Test net output #0: accuracy = 0.693458
I0725 22:09:01.596901 22939 solver.cpp:404]     Test net output #1: loss = 0.719583 (* 1 = 0.719583 loss)
I0725 22:09:01.630203 22939 solver.cpp:228] Iteration 15500, loss = 0.695712
I0725 22:09:01.630249 22939 solver.cpp:244]     Train net output #0: loss = 0.695712 (* 1 = 0.695712 loss)
I0725 22:09:01.630269 22939 sgd_solver.cpp:106] Iteration 15500, lr = 6.50281e-06
I0725 22:09:11.026744 22939 solver.cpp:228] Iteration 15600, loss = 0.680985
I0725 22:09:11.026801 22939 solver.cpp:244]     Train net output #0: loss = 0.680985 (* 1 = 0.680985 loss)
I0725 22:09:11.026808 22939 sgd_solver.cpp:106] Iteration 15600, lr = 6.48911e-06
I0725 22:09:20.429240 22939 solver.cpp:228] Iteration 15700, loss = 0.808601
I0725 22:09:20.429303 22939 solver.cpp:244]     Train net output #0: loss = 0.808601 (* 1 = 0.808601 loss)
I0725 22:09:20.429311 22939 sgd_solver.cpp:106] Iteration 15700, lr = 6.47547e-06
I0725 22:09:29.826800 22939 solver.cpp:228] Iteration 15800, loss = 0.611927
I0725 22:09:29.826844 22939 solver.cpp:244]     Train net output #0: loss = 0.611927 (* 1 = 0.611927 loss)
I0725 22:09:29.826850 22939 sgd_solver.cpp:106] Iteration 15800, lr = 6.4619e-06
I0725 22:09:39.222568 22939 solver.cpp:228] Iteration 15900, loss = 0.636354
I0725 22:09:39.222616 22939 solver.cpp:244]     Train net output #0: loss = 0.636354 (* 1 = 0.636354 loss)
I0725 22:09:39.222622 22939 sgd_solver.cpp:106] Iteration 15900, lr = 6.4484e-06
I0725 22:09:48.525365 22939 solver.cpp:337] Iteration 16000, Testing net (#0)
I0725 22:09:59.436650 22939 solver.cpp:404]     Test net output #0: accuracy = 0.693625
I0725 22:09:59.436714 22939 solver.cpp:404]     Test net output #1: loss = 0.719648 (* 1 = 0.719648 loss)
I0725 22:09:59.466670 22939 solver.cpp:228] Iteration 16000, loss = 0.667032
I0725 22:09:59.466732 22939 solver.cpp:244]     Train net output #0: loss = 0.667032 (* 1 = 0.667032 loss)
I0725 22:09:59.466752 22939 sgd_solver.cpp:106] Iteration 16000, lr = 6.43496e-06
I0725 22:10:08.861666 22939 solver.cpp:228] Iteration 16100, loss = 0.775669
I0725 22:10:08.861709 22939 solver.cpp:244]     Train net output #0: loss = 0.775669 (* 1 = 0.775669 loss)
I0725 22:10:08.861716 22939 sgd_solver.cpp:106] Iteration 16100, lr = 6.42158e-06
I0725 22:10:18.403385 22939 solver.cpp:228] Iteration 16200, loss = 0.691562
I0725 22:10:18.403447 22939 solver.cpp:244]     Train net output #0: loss = 0.691562 (* 1 = 0.691562 loss)
I0725 22:10:18.403455 22939 sgd_solver.cpp:106] Iteration 16200, lr = 6.40827e-06
I0725 22:10:27.967866 22939 solver.cpp:228] Iteration 16300, loss = 0.668911
I0725 22:10:27.967911 22939 solver.cpp:244]     Train net output #0: loss = 0.668911 (* 1 = 0.668911 loss)
I0725 22:10:27.967917 22939 sgd_solver.cpp:106] Iteration 16300, lr = 6.39503e-06
I0725 22:10:37.433992 22939 solver.cpp:228] Iteration 16400, loss = 0.781715
I0725 22:10:37.434046 22939 solver.cpp:244]     Train net output #0: loss = 0.781715 (* 1 = 0.781715 loss)
I0725 22:10:37.434054 22939 sgd_solver.cpp:106] Iteration 16400, lr = 6.38185e-06
I0725 22:10:46.746211 22939 solver.cpp:337] Iteration 16500, Testing net (#0)
I0725 22:10:57.609968 22939 solver.cpp:404]     Test net output #0: accuracy = 0.6965
I0725 22:10:57.610031 22939 solver.cpp:404]     Test net output #1: loss = 0.712602 (* 1 = 0.712602 loss)
I0725 22:10:57.642685 22939 solver.cpp:228] Iteration 16500, loss = 0.739671
I0725 22:10:57.642735 22939 solver.cpp:244]     Train net output #0: loss = 0.739671 (* 1 = 0.739671 loss)
I0725 22:10:57.642746 22939 sgd_solver.cpp:106] Iteration 16500, lr = 6.36873e-06
I0725 22:11:06.996443 22939 solver.cpp:228] Iteration 16600, loss = 0.671387
I0725 22:11:06.996500 22939 solver.cpp:244]     Train net output #0: loss = 0.671387 (* 1 = 0.671387 loss)
I0725 22:11:06.996507 22939 sgd_solver.cpp:106] Iteration 16600, lr = 6.35567e-06
I0725 22:11:13.571445 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:11:16.388100 22939 solver.cpp:228] Iteration 16700, loss = 0.685785
I0725 22:11:16.388152 22939 solver.cpp:244]     Train net output #0: loss = 0.685785 (* 1 = 0.685785 loss)
I0725 22:11:16.388159 22939 sgd_solver.cpp:106] Iteration 16700, lr = 6.34268e-06
I0725 22:11:25.832233 22939 solver.cpp:228] Iteration 16800, loss = 0.608977
I0725 22:11:25.832274 22939 solver.cpp:244]     Train net output #0: loss = 0.608977 (* 1 = 0.608977 loss)
I0725 22:11:25.832280 22939 sgd_solver.cpp:106] Iteration 16800, lr = 6.32975e-06
I0725 22:11:35.322573 22939 solver.cpp:228] Iteration 16900, loss = 0.621547
I0725 22:11:35.322610 22939 solver.cpp:244]     Train net output #0: loss = 0.621547 (* 1 = 0.621547 loss)
I0725 22:11:35.322615 22939 sgd_solver.cpp:106] Iteration 16900, lr = 6.31688e-06
I0725 22:11:44.618350 22939 solver.cpp:337] Iteration 17000, Testing net (#0)
I0725 22:11:55.523593 22939 solver.cpp:404]     Test net output #0: accuracy = 0.695125
I0725 22:11:55.523643 22939 solver.cpp:404]     Test net output #1: loss = 0.7146 (* 1 = 0.7146 loss)
I0725 22:11:55.552953 22939 solver.cpp:228] Iteration 17000, loss = 0.628723
I0725 22:11:55.552981 22939 solver.cpp:244]     Train net output #0: loss = 0.628723 (* 1 = 0.628723 loss)
I0725 22:11:55.552991 22939 sgd_solver.cpp:106] Iteration 17000, lr = 6.30407e-06
I0725 22:12:04.923583 22939 solver.cpp:228] Iteration 17100, loss = 0.603375
I0725 22:12:04.923632 22939 solver.cpp:244]     Train net output #0: loss = 0.603375 (* 1 = 0.603375 loss)
I0725 22:12:04.923640 22939 sgd_solver.cpp:106] Iteration 17100, lr = 6.29132e-06
I0725 22:12:14.320966 22939 solver.cpp:228] Iteration 17200, loss = 0.656839
I0725 22:12:14.321007 22939 solver.cpp:244]     Train net output #0: loss = 0.656839 (* 1 = 0.656839 loss)
I0725 22:12:14.321013 22939 sgd_solver.cpp:106] Iteration 17200, lr = 6.27864e-06
I0725 22:12:23.724828 22939 solver.cpp:228] Iteration 17300, loss = 0.69898
I0725 22:12:23.724876 22939 solver.cpp:244]     Train net output #0: loss = 0.69898 (* 1 = 0.69898 loss)
I0725 22:12:23.724884 22939 sgd_solver.cpp:106] Iteration 17300, lr = 6.26601e-06
I0725 22:12:33.117630 22939 solver.cpp:228] Iteration 17400, loss = 0.708451
I0725 22:12:33.117669 22939 solver.cpp:244]     Train net output #0: loss = 0.708451 (* 1 = 0.708451 loss)
I0725 22:12:33.117676 22939 sgd_solver.cpp:106] Iteration 17400, lr = 6.25344e-06
I0725 22:12:42.416702 22939 solver.cpp:337] Iteration 17500, Testing net (#0)
I0725 22:12:53.328662 22939 solver.cpp:404]     Test net output #0: accuracy = 0.699042
I0725 22:12:53.328702 22939 solver.cpp:404]     Test net output #1: loss = 0.706785 (* 1 = 0.706785 loss)
I0725 22:12:53.357942 22939 solver.cpp:228] Iteration 17500, loss = 0.605005
I0725 22:12:53.357959 22939 solver.cpp:244]     Train net output #0: loss = 0.605005 (* 1 = 0.605005 loss)
I0725 22:12:53.357969 22939 sgd_solver.cpp:106] Iteration 17500, lr = 6.24093e-06
I0725 22:13:02.743332 22939 solver.cpp:228] Iteration 17600, loss = 0.659681
I0725 22:13:02.743372 22939 solver.cpp:244]     Train net output #0: loss = 0.659681 (* 1 = 0.659681 loss)
I0725 22:13:02.743378 22939 sgd_solver.cpp:106] Iteration 17600, lr = 6.22847e-06
I0725 22:13:12.259239 22939 solver.cpp:228] Iteration 17700, loss = 0.694937
I0725 22:13:12.259289 22939 solver.cpp:244]     Train net output #0: loss = 0.694937 (* 1 = 0.694937 loss)
I0725 22:13:12.259294 22939 sgd_solver.cpp:106] Iteration 17700, lr = 6.21608e-06
I0725 22:13:21.820124 22939 solver.cpp:228] Iteration 17800, loss = 0.814556
I0725 22:13:21.820188 22939 solver.cpp:244]     Train net output #0: loss = 0.814556 (* 1 = 0.814556 loss)
I0725 22:13:21.820194 22939 sgd_solver.cpp:106] Iteration 17800, lr = 6.20374e-06
I0725 22:13:31.221882 22939 solver.cpp:228] Iteration 17900, loss = 0.559958
I0725 22:13:31.221920 22939 solver.cpp:244]     Train net output #0: loss = 0.559958 (* 1 = 0.559958 loss)
I0725 22:13:31.221925 22939 sgd_solver.cpp:106] Iteration 17900, lr = 6.19146e-06
I0725 22:13:40.530668 22939 solver.cpp:337] Iteration 18000, Testing net (#0)
I0725 22:13:51.404952 22939 solver.cpp:404]     Test net output #0: accuracy = 0.69925
I0725 22:13:51.404995 22939 solver.cpp:404]     Test net output #1: loss = 0.707483 (* 1 = 0.707483 loss)
I0725 22:13:51.434290 22939 solver.cpp:228] Iteration 18000, loss = 0.600103
I0725 22:13:51.434340 22939 solver.cpp:244]     Train net output #0: loss = 0.600103 (* 1 = 0.600103 loss)
I0725 22:13:51.434351 22939 sgd_solver.cpp:106] Iteration 18000, lr = 6.17924e-06
I0725 22:14:00.797125 22939 solver.cpp:228] Iteration 18100, loss = 0.726656
I0725 22:14:00.797174 22939 solver.cpp:244]     Train net output #0: loss = 0.726656 (* 1 = 0.726656 loss)
I0725 22:14:00.797180 22939 sgd_solver.cpp:106] Iteration 18100, lr = 6.16707e-06
I0725 22:14:10.349109 22939 solver.cpp:228] Iteration 18200, loss = 0.713063
I0725 22:14:10.349158 22939 solver.cpp:244]     Train net output #0: loss = 0.713063 (* 1 = 0.713063 loss)
I0725 22:14:10.349164 22939 sgd_solver.cpp:106] Iteration 18200, lr = 6.15496e-06
I0725 22:14:19.758844 22939 solver.cpp:228] Iteration 18300, loss = 0.572413
I0725 22:14:19.758883 22939 solver.cpp:244]     Train net output #0: loss = 0.572413 (* 1 = 0.572413 loss)
I0725 22:14:19.758889 22939 sgd_solver.cpp:106] Iteration 18300, lr = 6.1429e-06
I0725 22:14:29.145627 22939 solver.cpp:228] Iteration 18400, loss = 0.733539
I0725 22:14:29.145671 22939 solver.cpp:244]     Train net output #0: loss = 0.733539 (* 1 = 0.733539 loss)
I0725 22:14:29.145678 22939 sgd_solver.cpp:106] Iteration 18400, lr = 6.1309e-06
I0725 22:14:38.440398 22939 solver.cpp:337] Iteration 18500, Testing net (#0)
I0725 22:14:46.189750 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:14:49.315726 22939 solver.cpp:404]     Test net output #0: accuracy = 0.702042
I0725 22:14:49.315769 22939 solver.cpp:404]     Test net output #1: loss = 0.700642 (* 1 = 0.700642 loss)
I0725 22:14:49.348376 22939 solver.cpp:228] Iteration 18500, loss = 0.635955
I0725 22:14:49.348419 22939 solver.cpp:244]     Train net output #0: loss = 0.635955 (* 1 = 0.635955 loss)
I0725 22:14:49.348431 22939 sgd_solver.cpp:106] Iteration 18500, lr = 6.11895e-06
I0725 22:14:58.701174 22939 solver.cpp:228] Iteration 18600, loss = 0.754807
I0725 22:14:58.701228 22939 solver.cpp:244]     Train net output #0: loss = 0.754807 (* 1 = 0.754807 loss)
I0725 22:14:58.701234 22939 sgd_solver.cpp:106] Iteration 18600, lr = 6.10706e-06
I0725 22:15:08.097648 22939 solver.cpp:228] Iteration 18700, loss = 0.715087
I0725 22:15:08.097693 22939 solver.cpp:244]     Train net output #0: loss = 0.715087 (* 1 = 0.715087 loss)
I0725 22:15:08.097699 22939 sgd_solver.cpp:106] Iteration 18700, lr = 6.09522e-06
I0725 22:15:17.489125 22939 solver.cpp:228] Iteration 18800, loss = 0.697416
I0725 22:15:17.489166 22939 solver.cpp:244]     Train net output #0: loss = 0.697416 (* 1 = 0.697416 loss)
I0725 22:15:17.489172 22939 sgd_solver.cpp:106] Iteration 18800, lr = 6.08343e-06
I0725 22:15:26.883831 22939 solver.cpp:228] Iteration 18900, loss = 0.722204
I0725 22:15:26.883893 22939 solver.cpp:244]     Train net output #0: loss = 0.722204 (* 1 = 0.722204 loss)
I0725 22:15:26.883901 22939 sgd_solver.cpp:106] Iteration 18900, lr = 6.0717e-06
I0725 22:15:36.234360 22939 solver.cpp:337] Iteration 19000, Testing net (#0)
I0725 22:15:47.192339 22939 solver.cpp:404]     Test net output #0: accuracy = 0.702917
I0725 22:15:47.192384 22939 solver.cpp:404]     Test net output #1: loss = 0.700744 (* 1 = 0.700744 loss)
I0725 22:15:47.221897 22939 solver.cpp:228] Iteration 19000, loss = 0.736869
I0725 22:15:47.221915 22939 solver.cpp:244]     Train net output #0: loss = 0.736869 (* 1 = 0.736869 loss)
I0725 22:15:47.221925 22939 sgd_solver.cpp:106] Iteration 19000, lr = 6.06002e-06
I0725 22:15:56.579545 22939 solver.cpp:228] Iteration 19100, loss = 0.694732
I0725 22:15:56.579602 22939 solver.cpp:244]     Train net output #0: loss = 0.694732 (* 1 = 0.694732 loss)
I0725 22:15:56.579608 22939 sgd_solver.cpp:106] Iteration 19100, lr = 6.04839e-06
I0725 22:16:06.027778 22939 solver.cpp:228] Iteration 19200, loss = 0.647892
I0725 22:16:06.027818 22939 solver.cpp:244]     Train net output #0: loss = 0.647892 (* 1 = 0.647892 loss)
I0725 22:16:06.027824 22939 sgd_solver.cpp:106] Iteration 19200, lr = 6.03682e-06
I0725 22:16:15.591755 22939 solver.cpp:228] Iteration 19300, loss = 0.617714
I0725 22:16:15.591799 22939 solver.cpp:244]     Train net output #0: loss = 0.617714 (* 1 = 0.617714 loss)
I0725 22:16:15.591804 22939 sgd_solver.cpp:106] Iteration 19300, lr = 6.02529e-06
I0725 22:16:24.949939 22939 solver.cpp:228] Iteration 19400, loss = 0.71325
I0725 22:16:24.949990 22939 solver.cpp:244]     Train net output #0: loss = 0.71325 (* 1 = 0.71325 loss)
I0725 22:16:24.949995 22939 sgd_solver.cpp:106] Iteration 19400, lr = 6.01382e-06
I0725 22:16:34.236945 22939 solver.cpp:337] Iteration 19500, Testing net (#0)
I0725 22:16:45.173295 22939 solver.cpp:404]     Test net output #0: accuracy = 0.705625
I0725 22:16:45.173351 22939 solver.cpp:404]     Test net output #1: loss = 0.694337 (* 1 = 0.694337 loss)
I0725 22:16:45.203536 22939 solver.cpp:228] Iteration 19500, loss = 0.799252
I0725 22:16:45.203577 22939 solver.cpp:244]     Train net output #0: loss = 0.799252 (* 1 = 0.799252 loss)
I0725 22:16:45.203588 22939 sgd_solver.cpp:106] Iteration 19500, lr = 6.0024e-06
I0725 22:16:54.602073 22939 solver.cpp:228] Iteration 19600, loss = 0.793484
I0725 22:16:54.602115 22939 solver.cpp:244]     Train net output #0: loss = 0.793484 (* 1 = 0.793484 loss)
I0725 22:16:54.602121 22939 sgd_solver.cpp:106] Iteration 19600, lr = 5.99102e-06
I0725 22:17:03.997489 22939 solver.cpp:228] Iteration 19700, loss = 0.609662
I0725 22:17:03.997555 22939 solver.cpp:244]     Train net output #0: loss = 0.609662 (* 1 = 0.609662 loss)
I0725 22:17:03.997563 22939 sgd_solver.cpp:106] Iteration 19700, lr = 5.9797e-06
I0725 22:17:13.391944 22939 solver.cpp:228] Iteration 19800, loss = 0.706397
I0725 22:17:13.391990 22939 solver.cpp:244]     Train net output #0: loss = 0.706397 (* 1 = 0.706397 loss)
I0725 22:17:13.391998 22939 sgd_solver.cpp:106] Iteration 19800, lr = 5.96843e-06
I0725 22:17:22.780200 22939 solver.cpp:228] Iteration 19900, loss = 0.650246
I0725 22:17:22.780239 22939 solver.cpp:244]     Train net output #0: loss = 0.650246 (* 1 = 0.650246 loss)
I0725 22:17:22.780246 22939 sgd_solver.cpp:106] Iteration 19900, lr = 5.95721e-06
I0725 22:17:32.074053 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_20000.caffemodel
I0725 22:17:32.414316 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_20000.solverstate
I0725 22:17:32.521720 22939 solver.cpp:337] Iteration 20000, Testing net (#0)
I0725 22:17:43.273775 22939 solver.cpp:404]     Test net output #0: accuracy = 0.706708
I0725 22:17:43.273831 22939 solver.cpp:404]     Test net output #1: loss = 0.694592 (* 1 = 0.694592 loss)
I0725 22:17:43.303092 22939 solver.cpp:228] Iteration 20000, loss = 0.749022
I0725 22:17:43.303124 22939 solver.cpp:244]     Train net output #0: loss = 0.749022 (* 1 = 0.749022 loss)
I0725 22:17:43.303135 22939 sgd_solver.cpp:106] Iteration 20000, lr = 5.94604e-06
I0725 22:17:52.670361 22939 solver.cpp:228] Iteration 20100, loss = 0.592998
I0725 22:17:52.670399 22939 solver.cpp:244]     Train net output #0: loss = 0.592998 (* 1 = 0.592998 loss)
I0725 22:17:52.670404 22939 sgd_solver.cpp:106] Iteration 20100, lr = 5.93491e-06
I0725 22:18:02.067726 22939 solver.cpp:228] Iteration 20200, loss = 0.617616
I0725 22:18:02.067767 22939 solver.cpp:244]     Train net output #0: loss = 0.617616 (* 1 = 0.617616 loss)
I0725 22:18:02.067775 22939 sgd_solver.cpp:106] Iteration 20200, lr = 5.92384e-06
I0725 22:18:11.465361 22939 solver.cpp:228] Iteration 20300, loss = 0.718124
I0725 22:18:11.465406 22939 solver.cpp:244]     Train net output #0: loss = 0.718124 (* 1 = 0.718124 loss)
I0725 22:18:11.465412 22939 sgd_solver.cpp:106] Iteration 20300, lr = 5.91281e-06
I0725 22:18:20.862418 22939 solver.cpp:228] Iteration 20400, loss = 0.751585
I0725 22:18:20.862469 22939 solver.cpp:244]     Train net output #0: loss = 0.751585 (* 1 = 0.751585 loss)
I0725 22:18:20.862476 22939 sgd_solver.cpp:106] Iteration 20400, lr = 5.90183e-06
I0725 22:18:30.165720 22939 solver.cpp:337] Iteration 20500, Testing net (#0)
I0725 22:18:37.461772 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:18:41.055573 22939 solver.cpp:404]     Test net output #0: accuracy = 0.708833
I0725 22:18:41.055626 22939 solver.cpp:404]     Test net output #1: loss = 0.689154 (* 1 = 0.689154 loss)
I0725 22:18:41.088093 22939 solver.cpp:228] Iteration 20500, loss = 0.676449
I0725 22:18:41.088122 22939 solver.cpp:244]     Train net output #0: loss = 0.676449 (* 1 = 0.676449 loss)
I0725 22:18:41.088132 22939 sgd_solver.cpp:106] Iteration 20500, lr = 5.89089e-06
I0725 22:18:50.445994 22939 solver.cpp:228] Iteration 20600, loss = 0.604337
I0725 22:18:50.446049 22939 solver.cpp:244]     Train net output #0: loss = 0.604337 (* 1 = 0.604337 loss)
I0725 22:18:50.446055 22939 sgd_solver.cpp:106] Iteration 20600, lr = 5.88001e-06
I0725 22:18:59.846137 22939 solver.cpp:228] Iteration 20700, loss = 0.617726
I0725 22:18:59.846179 22939 solver.cpp:244]     Train net output #0: loss = 0.617726 (* 1 = 0.617726 loss)
I0725 22:18:59.846185 22939 sgd_solver.cpp:106] Iteration 20700, lr = 5.86917e-06
I0725 22:19:09.254264 22939 solver.cpp:228] Iteration 20800, loss = 0.724029
I0725 22:19:09.254315 22939 solver.cpp:244]     Train net output #0: loss = 0.724029 (* 1 = 0.724029 loss)
I0725 22:19:09.254323 22939 sgd_solver.cpp:106] Iteration 20800, lr = 5.85838e-06
I0725 22:19:18.658552 22939 solver.cpp:228] Iteration 20900, loss = 0.691798
I0725 22:19:18.658601 22939 solver.cpp:244]     Train net output #0: loss = 0.691798 (* 1 = 0.691798 loss)
I0725 22:19:18.658607 22939 sgd_solver.cpp:106] Iteration 20900, lr = 5.84763e-06
I0725 22:19:27.967588 22939 solver.cpp:337] Iteration 21000, Testing net (#0)
I0725 22:19:38.826477 22939 solver.cpp:404]     Test net output #0: accuracy = 0.709583
I0725 22:19:38.826534 22939 solver.cpp:404]     Test net output #1: loss = 0.689632 (* 1 = 0.689632 loss)
I0725 22:19:38.858345 22939 solver.cpp:228] Iteration 21000, loss = 0.653857
I0725 22:19:38.858409 22939 solver.cpp:244]     Train net output #0: loss = 0.653857 (* 1 = 0.653857 loss)
I0725 22:19:38.858428 22939 sgd_solver.cpp:106] Iteration 21000, lr = 5.83693e-06
I0725 22:19:48.205587 22939 solver.cpp:228] Iteration 21100, loss = 0.656839
I0725 22:19:48.205628 22939 solver.cpp:244]     Train net output #0: loss = 0.656839 (* 1 = 0.656839 loss)
I0725 22:19:48.205634 22939 sgd_solver.cpp:106] Iteration 21100, lr = 5.82628e-06
I0725 22:19:57.597704 22939 solver.cpp:228] Iteration 21200, loss = 0.609814
I0725 22:19:57.597748 22939 solver.cpp:244]     Train net output #0: loss = 0.609814 (* 1 = 0.609814 loss)
I0725 22:19:57.597754 22939 sgd_solver.cpp:106] Iteration 21200, lr = 5.81567e-06
I0725 22:20:06.990037 22939 solver.cpp:228] Iteration 21300, loss = 0.611558
I0725 22:20:06.990094 22939 solver.cpp:244]     Train net output #0: loss = 0.611558 (* 1 = 0.611558 loss)
I0725 22:20:06.990102 22939 sgd_solver.cpp:106] Iteration 21300, lr = 5.8051e-06
I0725 22:20:16.380743 22939 solver.cpp:228] Iteration 21400, loss = 0.555816
I0725 22:20:16.380792 22939 solver.cpp:244]     Train net output #0: loss = 0.555816 (* 1 = 0.555816 loss)
I0725 22:20:16.380798 22939 sgd_solver.cpp:106] Iteration 21400, lr = 5.79458e-06
I0725 22:20:25.680482 22939 solver.cpp:337] Iteration 21500, Testing net (#0)
I0725 22:20:36.607960 22939 solver.cpp:404]     Test net output #0: accuracy = 0.712708
I0725 22:20:36.608008 22939 solver.cpp:404]     Test net output #1: loss = 0.683156 (* 1 = 0.683156 loss)
I0725 22:20:36.637433 22939 solver.cpp:228] Iteration 21500, loss = 0.625054
I0725 22:20:36.637483 22939 solver.cpp:244]     Train net output #0: loss = 0.625054 (* 1 = 0.625054 loss)
I0725 22:20:36.637495 22939 sgd_solver.cpp:106] Iteration 21500, lr = 5.78411e-06
I0725 22:20:45.954609 22939 solver.cpp:228] Iteration 21600, loss = 0.696842
I0725 22:20:45.954649 22939 solver.cpp:244]     Train net output #0: loss = 0.696842 (* 1 = 0.696842 loss)
I0725 22:20:45.954655 22939 sgd_solver.cpp:106] Iteration 21600, lr = 5.77368e-06
I0725 22:20:55.328675 22939 solver.cpp:228] Iteration 21700, loss = 0.682903
I0725 22:20:55.328717 22939 solver.cpp:244]     Train net output #0: loss = 0.682903 (* 1 = 0.682903 loss)
I0725 22:20:55.328724 22939 sgd_solver.cpp:106] Iteration 21700, lr = 5.76329e-06
I0725 22:21:04.727885 22939 solver.cpp:228] Iteration 21800, loss = 0.59631
I0725 22:21:04.727921 22939 solver.cpp:244]     Train net output #0: loss = 0.59631 (* 1 = 0.59631 loss)
I0725 22:21:04.727927 22939 sgd_solver.cpp:106] Iteration 21800, lr = 5.75295e-06
I0725 22:21:14.125367 22939 solver.cpp:228] Iteration 21900, loss = 0.677537
I0725 22:21:14.125408 22939 solver.cpp:244]     Train net output #0: loss = 0.677537 (* 1 = 0.677537 loss)
I0725 22:21:14.125416 22939 sgd_solver.cpp:106] Iteration 21900, lr = 5.74265e-06
I0725 22:21:23.425914 22939 solver.cpp:337] Iteration 22000, Testing net (#0)
I0725 22:21:34.382411 22939 solver.cpp:404]     Test net output #0: accuracy = 0.709792
I0725 22:21:34.382452 22939 solver.cpp:404]     Test net output #1: loss = 0.687947 (* 1 = 0.687947 loss)
I0725 22:21:34.410164 22939 solver.cpp:228] Iteration 22000, loss = 0.621633
I0725 22:21:34.410197 22939 solver.cpp:244]     Train net output #0: loss = 0.621633 (* 1 = 0.621633 loss)
I0725 22:21:34.410209 22939 sgd_solver.cpp:106] Iteration 22000, lr = 5.73239e-06
I0725 22:21:43.778486 22939 solver.cpp:228] Iteration 22100, loss = 0.747977
I0725 22:21:43.778542 22939 solver.cpp:244]     Train net output #0: loss = 0.747977 (* 1 = 0.747977 loss)
I0725 22:21:43.778548 22939 sgd_solver.cpp:106] Iteration 22100, lr = 5.72217e-06
I0725 22:21:53.176450 22939 solver.cpp:228] Iteration 22200, loss = 0.622541
I0725 22:21:53.176491 22939 solver.cpp:244]     Train net output #0: loss = 0.622541 (* 1 = 0.622541 loss)
I0725 22:21:53.176498 22939 sgd_solver.cpp:106] Iteration 22200, lr = 5.712e-06
I0725 22:22:02.576530 22939 solver.cpp:228] Iteration 22300, loss = 0.631122
I0725 22:22:02.576580 22939 solver.cpp:244]     Train net output #0: loss = 0.631122 (* 1 = 0.631122 loss)
I0725 22:22:02.576586 22939 sgd_solver.cpp:106] Iteration 22300, lr = 5.70187e-06
I0725 22:22:07.464244 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:22:11.975309 22939 solver.cpp:228] Iteration 22400, loss = 0.728462
I0725 22:22:11.975337 22939 solver.cpp:244]     Train net output #0: loss = 0.728462 (* 1 = 0.728462 loss)
I0725 22:22:11.975344 22939 sgd_solver.cpp:106] Iteration 22400, lr = 5.69178e-06
I0725 22:22:21.280592 22939 solver.cpp:337] Iteration 22500, Testing net (#0)
I0725 22:22:32.138144 22939 solver.cpp:404]     Test net output #0: accuracy = 0.714917
I0725 22:22:32.138190 22939 solver.cpp:404]     Test net output #1: loss = 0.679789 (* 1 = 0.679789 loss)
I0725 22:22:32.168118 22939 solver.cpp:228] Iteration 22500, loss = 0.648588
I0725 22:22:32.168181 22939 solver.cpp:244]     Train net output #0: loss = 0.648588 (* 1 = 0.648588 loss)
I0725 22:22:32.168200 22939 sgd_solver.cpp:106] Iteration 22500, lr = 5.68173e-06
I0725 22:22:41.553241 22939 solver.cpp:228] Iteration 22600, loss = 0.545312
I0725 22:22:41.553279 22939 solver.cpp:244]     Train net output #0: loss = 0.545312 (* 1 = 0.545312 loss)
I0725 22:22:41.553287 22939 sgd_solver.cpp:106] Iteration 22600, lr = 5.67173e-06
I0725 22:22:50.944139 22939 solver.cpp:228] Iteration 22700, loss = 0.754724
I0725 22:22:50.944182 22939 solver.cpp:244]     Train net output #0: loss = 0.754724 (* 1 = 0.754724 loss)
I0725 22:22:50.944188 22939 sgd_solver.cpp:106] Iteration 22700, lr = 5.66176e-06
I0725 22:23:00.336024 22939 solver.cpp:228] Iteration 22800, loss = 0.585757
I0725 22:23:00.336066 22939 solver.cpp:244]     Train net output #0: loss = 0.585757 (* 1 = 0.585757 loss)
I0725 22:23:00.336071 22939 sgd_solver.cpp:106] Iteration 22800, lr = 5.65184e-06
I0725 22:23:09.731875 22939 solver.cpp:228] Iteration 22900, loss = 0.668739
I0725 22:23:09.731926 22939 solver.cpp:244]     Train net output #0: loss = 0.668739 (* 1 = 0.668739 loss)
I0725 22:23:09.731933 22939 sgd_solver.cpp:106] Iteration 22900, lr = 5.64195e-06
I0725 22:23:19.030635 22939 solver.cpp:337] Iteration 23000, Testing net (#0)
I0725 22:23:29.923753 22939 solver.cpp:404]     Test net output #0: accuracy = 0.711167
I0725 22:23:29.923802 22939 solver.cpp:404]     Test net output #1: loss = 0.685684 (* 1 = 0.685684 loss)
I0725 22:23:29.950469 22939 solver.cpp:228] Iteration 23000, loss = 0.795058
I0725 22:23:29.950530 22939 solver.cpp:244]     Train net output #0: loss = 0.795058 (* 1 = 0.795058 loss)
I0725 22:23:29.950549 22939 sgd_solver.cpp:106] Iteration 23000, lr = 5.63211e-06
I0725 22:23:39.276433 22939 solver.cpp:228] Iteration 23100, loss = 0.644288
I0725 22:23:39.276475 22939 solver.cpp:244]     Train net output #0: loss = 0.644288 (* 1 = 0.644288 loss)
I0725 22:23:39.276482 22939 sgd_solver.cpp:106] Iteration 23100, lr = 5.62231e-06
I0725 22:23:48.664896 22939 solver.cpp:228] Iteration 23200, loss = 0.714699
I0725 22:23:48.664935 22939 solver.cpp:244]     Train net output #0: loss = 0.714699 (* 1 = 0.714699 loss)
I0725 22:23:48.664942 22939 sgd_solver.cpp:106] Iteration 23200, lr = 5.61254e-06
I0725 22:23:58.057013 22939 solver.cpp:228] Iteration 23300, loss = 0.674512
I0725 22:23:58.057072 22939 solver.cpp:244]     Train net output #0: loss = 0.674512 (* 1 = 0.674512 loss)
I0725 22:23:58.057078 22939 sgd_solver.cpp:106] Iteration 23300, lr = 5.60282e-06
I0725 22:24:07.450076 22939 solver.cpp:228] Iteration 23400, loss = 0.637928
I0725 22:24:07.450119 22939 solver.cpp:244]     Train net output #0: loss = 0.637928 (* 1 = 0.637928 loss)
I0725 22:24:07.450125 22939 sgd_solver.cpp:106] Iteration 23400, lr = 5.59313e-06
I0725 22:24:16.749913 22939 solver.cpp:337] Iteration 23500, Testing net (#0)
I0725 22:24:27.689934 22939 solver.cpp:404]     Test net output #0: accuracy = 0.714208
I0725 22:24:27.689975 22939 solver.cpp:404]     Test net output #1: loss = 0.67983 (* 1 = 0.67983 loss)
I0725 22:24:27.719430 22939 solver.cpp:228] Iteration 23500, loss = 0.736215
I0725 22:24:27.719460 22939 solver.cpp:244]     Train net output #0: loss = 0.736215 (* 1 = 0.736215 loss)
I0725 22:24:27.719471 22939 sgd_solver.cpp:106] Iteration 23500, lr = 5.58349e-06
I0725 22:24:37.062633 22939 solver.cpp:228] Iteration 23600, loss = 0.521774
I0725 22:24:37.062675 22939 solver.cpp:244]     Train net output #0: loss = 0.521774 (* 1 = 0.521774 loss)
I0725 22:24:37.062681 22939 sgd_solver.cpp:106] Iteration 23600, lr = 5.57388e-06
I0725 22:24:46.462908 22939 solver.cpp:228] Iteration 23700, loss = 0.614717
I0725 22:24:46.462963 22939 solver.cpp:244]     Train net output #0: loss = 0.614717 (* 1 = 0.614717 loss)
I0725 22:24:46.462970 22939 sgd_solver.cpp:106] Iteration 23700, lr = 5.56431e-06
I0725 22:24:55.862010 22939 solver.cpp:228] Iteration 23800, loss = 0.622539
I0725 22:24:55.862049 22939 solver.cpp:244]     Train net output #0: loss = 0.622539 (* 1 = 0.622539 loss)
I0725 22:24:55.862056 22939 sgd_solver.cpp:106] Iteration 23800, lr = 5.55478e-06
I0725 22:25:05.264197 22939 solver.cpp:228] Iteration 23900, loss = 0.800074
I0725 22:25:05.264240 22939 solver.cpp:244]     Train net output #0: loss = 0.800074 (* 1 = 0.800074 loss)
I0725 22:25:05.264245 22939 sgd_solver.cpp:106] Iteration 23900, lr = 5.54529e-06
I0725 22:25:14.573029 22939 solver.cpp:337] Iteration 24000, Testing net (#0)
I0725 22:25:21.824939 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:25:25.478518 22939 solver.cpp:404]     Test net output #0: accuracy = 0.714375
I0725 22:25:25.478561 22939 solver.cpp:404]     Test net output #1: loss = 0.680491 (* 1 = 0.680491 loss)
I0725 22:25:25.508780 22939 solver.cpp:228] Iteration 24000, loss = 0.56585
I0725 22:25:25.508848 22939 solver.cpp:244]     Train net output #0: loss = 0.56585 (* 1 = 0.56585 loss)
I0725 22:25:25.508867 22939 sgd_solver.cpp:106] Iteration 24000, lr = 5.53583e-06
I0725 22:25:34.903957 22939 solver.cpp:228] Iteration 24100, loss = 0.635192
I0725 22:25:34.904016 22939 solver.cpp:244]     Train net output #0: loss = 0.635192 (* 1 = 0.635192 loss)
I0725 22:25:34.904023 22939 sgd_solver.cpp:106] Iteration 24100, lr = 5.52642e-06
I0725 22:25:44.296213 22939 solver.cpp:228] Iteration 24200, loss = 0.740562
I0725 22:25:44.296257 22939 solver.cpp:244]     Train net output #0: loss = 0.740562 (* 1 = 0.740562 loss)
I0725 22:25:44.296263 22939 sgd_solver.cpp:106] Iteration 24200, lr = 5.51704e-06
I0725 22:25:53.688918 22939 solver.cpp:228] Iteration 24300, loss = 0.653266
I0725 22:25:53.688958 22939 solver.cpp:244]     Train net output #0: loss = 0.653266 (* 1 = 0.653266 loss)
I0725 22:25:53.688964 22939 sgd_solver.cpp:106] Iteration 24300, lr = 5.50769e-06
I0725 22:26:03.083757 22939 solver.cpp:228] Iteration 24400, loss = 0.542241
I0725 22:26:03.083801 22939 solver.cpp:244]     Train net output #0: loss = 0.542241 (* 1 = 0.542241 loss)
I0725 22:26:03.083807 22939 sgd_solver.cpp:106] Iteration 24400, lr = 5.49839e-06
I0725 22:26:12.389528 22939 solver.cpp:337] Iteration 24500, Testing net (#0)
I0725 22:26:23.301023 22939 solver.cpp:404]     Test net output #0: accuracy = 0.715416
I0725 22:26:23.301067 22939 solver.cpp:404]     Test net output #1: loss = 0.677318 (* 1 = 0.677318 loss)
I0725 22:26:23.330430 22939 solver.cpp:228] Iteration 24500, loss = 0.639971
I0725 22:26:23.330446 22939 solver.cpp:244]     Train net output #0: loss = 0.639971 (* 1 = 0.639971 loss)
I0725 22:26:23.330456 22939 sgd_solver.cpp:106] Iteration 24500, lr = 5.48912e-06
I0725 22:26:32.665468 22939 solver.cpp:228] Iteration 24600, loss = 0.670576
I0725 22:26:32.665506 22939 solver.cpp:244]     Train net output #0: loss = 0.670576 (* 1 = 0.670576 loss)
I0725 22:26:32.665513 22939 sgd_solver.cpp:106] Iteration 24600, lr = 5.47988e-06
I0725 22:26:42.052435 22939 solver.cpp:228] Iteration 24700, loss = 0.664011
I0725 22:26:42.052479 22939 solver.cpp:244]     Train net output #0: loss = 0.664011 (* 1 = 0.664011 loss)
I0725 22:26:42.052484 22939 sgd_solver.cpp:106] Iteration 24700, lr = 5.47069e-06
I0725 22:26:51.447165 22939 solver.cpp:228] Iteration 24800, loss = 0.60815
I0725 22:26:51.447209 22939 solver.cpp:244]     Train net output #0: loss = 0.60815 (* 1 = 0.60815 loss)
I0725 22:26:51.447216 22939 sgd_solver.cpp:106] Iteration 24800, lr = 5.46153e-06
I0725 22:27:00.841712 22939 solver.cpp:228] Iteration 24900, loss = 0.746142
I0725 22:27:00.841752 22939 solver.cpp:244]     Train net output #0: loss = 0.746142 (* 1 = 0.746142 loss)
I0725 22:27:00.841758 22939 sgd_solver.cpp:106] Iteration 24900, lr = 5.4524e-06
I0725 22:27:10.141424 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_25000.caffemodel
I0725 22:27:10.485942 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_25000.solverstate
I0725 22:27:10.594118 22939 solver.cpp:337] Iteration 25000, Testing net (#0)
I0725 22:27:21.358434 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7155
I0725 22:27:21.358476 22939 solver.cpp:404]     Test net output #1: loss = 0.677267 (* 1 = 0.677267 loss)
I0725 22:27:21.387930 22939 solver.cpp:228] Iteration 25000, loss = 0.557368
I0725 22:27:21.387971 22939 solver.cpp:244]     Train net output #0: loss = 0.557368 (* 1 = 0.557368 loss)
I0725 22:27:21.387982 22939 sgd_solver.cpp:106] Iteration 25000, lr = 5.44331e-06
I0725 22:27:30.842366 22939 solver.cpp:228] Iteration 25100, loss = 0.647907
I0725 22:27:30.842418 22939 solver.cpp:244]     Train net output #0: loss = 0.647907 (* 1 = 0.647907 loss)
I0725 22:27:30.842425 22939 sgd_solver.cpp:106] Iteration 25100, lr = 5.43426e-06
I0725 22:27:40.345574 22939 solver.cpp:228] Iteration 25200, loss = 0.714359
I0725 22:27:40.345616 22939 solver.cpp:244]     Train net output #0: loss = 0.714359 (* 1 = 0.714359 loss)
I0725 22:27:40.345623 22939 sgd_solver.cpp:106] Iteration 25200, lr = 5.42524e-06
I0725 22:27:49.749655 22939 solver.cpp:228] Iteration 25300, loss = 0.634309
I0725 22:27:49.749704 22939 solver.cpp:244]     Train net output #0: loss = 0.634309 (* 1 = 0.634309 loss)
I0725 22:27:49.749711 22939 sgd_solver.cpp:106] Iteration 25300, lr = 5.41625e-06
I0725 22:27:59.151919 22939 solver.cpp:228] Iteration 25400, loss = 0.583555
I0725 22:27:59.151979 22939 solver.cpp:244]     Train net output #0: loss = 0.583555 (* 1 = 0.583555 loss)
I0725 22:27:59.151986 22939 sgd_solver.cpp:106] Iteration 25400, lr = 5.4073e-06
I0725 22:28:08.463346 22939 solver.cpp:337] Iteration 25500, Testing net (#0)
I0725 22:28:19.391460 22939 solver.cpp:404]     Test net output #0: accuracy = 0.717583
I0725 22:28:19.391515 22939 solver.cpp:404]     Test net output #1: loss = 0.673292 (* 1 = 0.673292 loss)
I0725 22:28:19.422852 22939 solver.cpp:228] Iteration 25500, loss = 0.71248
I0725 22:28:19.422881 22939 solver.cpp:244]     Train net output #0: loss = 0.71248 (* 1 = 0.71248 loss)
I0725 22:28:19.422894 22939 sgd_solver.cpp:106] Iteration 25500, lr = 5.39839e-06
I0725 22:28:28.765818 22939 solver.cpp:228] Iteration 25600, loss = 0.6203
I0725 22:28:28.765862 22939 solver.cpp:244]     Train net output #0: loss = 0.6203 (* 1 = 0.6203 loss)
I0725 22:28:28.765869 22939 sgd_solver.cpp:106] Iteration 25600, lr = 5.3895e-06
I0725 22:28:38.165632 22939 solver.cpp:228] Iteration 25700, loss = 0.656484
I0725 22:28:38.165678 22939 solver.cpp:244]     Train net output #0: loss = 0.656484 (* 1 = 0.656484 loss)
I0725 22:28:38.165684 22939 sgd_solver.cpp:106] Iteration 25700, lr = 5.38066e-06
I0725 22:28:47.644160 22939 solver.cpp:228] Iteration 25800, loss = 0.636121
I0725 22:28:47.644203 22939 solver.cpp:244]     Train net output #0: loss = 0.636121 (* 1 = 0.636121 loss)
I0725 22:28:47.644209 22939 sgd_solver.cpp:106] Iteration 25800, lr = 5.37184e-06
I0725 22:28:57.206460 22939 solver.cpp:228] Iteration 25900, loss = 0.814186
I0725 22:28:57.206508 22939 solver.cpp:244]     Train net output #0: loss = 0.814186 (* 1 = 0.814186 loss)
I0725 22:28:57.206514 22939 sgd_solver.cpp:106] Iteration 25900, lr = 5.36306e-06
I0725 22:29:06.551826 22939 solver.cpp:337] Iteration 26000, Testing net (#0)
I0725 22:29:06.834828 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:29:17.411420 22939 solver.cpp:404]     Test net output #0: accuracy = 0.716625
I0725 22:29:17.411464 22939 solver.cpp:404]     Test net output #1: loss = 0.676243 (* 1 = 0.676243 loss)
I0725 22:29:17.444258 22939 solver.cpp:228] Iteration 26000, loss = 0.690378
I0725 22:29:17.444320 22939 solver.cpp:244]     Train net output #0: loss = 0.690378 (* 1 = 0.690378 loss)
I0725 22:29:17.444339 22939 sgd_solver.cpp:106] Iteration 26000, lr = 5.35432e-06
I0725 22:29:26.758988 22939 solver.cpp:228] Iteration 26100, loss = 0.570336
I0725 22:29:26.759032 22939 solver.cpp:244]     Train net output #0: loss = 0.570336 (* 1 = 0.570336 loss)
I0725 22:29:26.759038 22939 sgd_solver.cpp:106] Iteration 26100, lr = 5.3456e-06
I0725 22:29:36.138190 22939 solver.cpp:228] Iteration 26200, loss = 0.573711
I0725 22:29:36.138236 22939 solver.cpp:244]     Train net output #0: loss = 0.573711 (* 1 = 0.573711 loss)
I0725 22:29:36.138242 22939 sgd_solver.cpp:106] Iteration 26200, lr = 5.33692e-06
I0725 22:29:45.628968 22939 solver.cpp:228] Iteration 26300, loss = 0.637571
I0725 22:29:45.629010 22939 solver.cpp:244]     Train net output #0: loss = 0.637571 (* 1 = 0.637571 loss)
I0725 22:29:45.629017 22939 sgd_solver.cpp:106] Iteration 26300, lr = 5.32828e-06
I0725 22:29:55.184542 22939 solver.cpp:228] Iteration 26400, loss = 0.569899
I0725 22:29:55.184582 22939 solver.cpp:244]     Train net output #0: loss = 0.569899 (* 1 = 0.569899 loss)
I0725 22:29:55.184588 22939 sgd_solver.cpp:106] Iteration 26400, lr = 5.31966e-06
I0725 22:30:04.525418 22939 solver.cpp:337] Iteration 26500, Testing net (#0)
I0725 22:30:15.444699 22939 solver.cpp:404]     Test net output #0: accuracy = 0.720125
I0725 22:30:15.444761 22939 solver.cpp:404]     Test net output #1: loss = 0.66831 (* 1 = 0.66831 loss)
I0725 22:30:15.474586 22939 solver.cpp:228] Iteration 26500, loss = 0.652457
I0725 22:30:15.474617 22939 solver.cpp:244]     Train net output #0: loss = 0.652457 (* 1 = 0.652457 loss)
I0725 22:30:15.474629 22939 sgd_solver.cpp:106] Iteration 26500, lr = 5.31108e-06
I0725 22:30:24.802680 22939 solver.cpp:228] Iteration 26600, loss = 0.599652
I0725 22:30:24.802722 22939 solver.cpp:244]     Train net output #0: loss = 0.599652 (* 1 = 0.599652 loss)
I0725 22:30:24.802729 22939 sgd_solver.cpp:106] Iteration 26600, lr = 5.30253e-06
I0725 22:30:34.194831 22939 solver.cpp:228] Iteration 26700, loss = 0.703725
I0725 22:30:34.194875 22939 solver.cpp:244]     Train net output #0: loss = 0.703725 (* 1 = 0.703725 loss)
I0725 22:30:34.194881 22939 sgd_solver.cpp:106] Iteration 26700, lr = 5.29401e-06
I0725 22:30:43.679846 22939 solver.cpp:228] Iteration 26800, loss = 0.644217
I0725 22:30:43.679893 22939 solver.cpp:244]     Train net output #0: loss = 0.644217 (* 1 = 0.644217 loss)
I0725 22:30:43.679899 22939 sgd_solver.cpp:106] Iteration 26800, lr = 5.28552e-06
I0725 22:30:53.244096 22939 solver.cpp:228] Iteration 26900, loss = 0.629468
I0725 22:30:53.244140 22939 solver.cpp:244]     Train net output #0: loss = 0.629468 (* 1 = 0.629468 loss)
I0725 22:30:53.244146 22939 sgd_solver.cpp:106] Iteration 26900, lr = 5.27707e-06
I0725 22:31:02.688910 22939 solver.cpp:337] Iteration 27000, Testing net (#0)
I0725 22:31:13.499234 22939 solver.cpp:404]     Test net output #0: accuracy = 0.717292
I0725 22:31:13.499279 22939 solver.cpp:404]     Test net output #1: loss = 0.672951 (* 1 = 0.672951 loss)
I0725 22:31:13.528607 22939 solver.cpp:228] Iteration 27000, loss = 0.654831
I0725 22:31:13.528635 22939 solver.cpp:244]     Train net output #0: loss = 0.654831 (* 1 = 0.654831 loss)
I0725 22:31:13.528646 22939 sgd_solver.cpp:106] Iteration 27000, lr = 5.26865e-06
I0725 22:31:22.863570 22939 solver.cpp:228] Iteration 27100, loss = 0.627234
I0725 22:31:22.863610 22939 solver.cpp:244]     Train net output #0: loss = 0.627234 (* 1 = 0.627234 loss)
I0725 22:31:22.863616 22939 sgd_solver.cpp:106] Iteration 27100, lr = 5.26025e-06
I0725 22:31:32.259377 22939 solver.cpp:228] Iteration 27200, loss = 0.579437
I0725 22:31:32.259424 22939 solver.cpp:244]     Train net output #0: loss = 0.579437 (* 1 = 0.579437 loss)
I0725 22:31:32.259431 22939 sgd_solver.cpp:106] Iteration 27200, lr = 5.25189e-06
I0725 22:31:41.657050 22939 solver.cpp:228] Iteration 27300, loss = 0.668241
I0725 22:31:41.657095 22939 solver.cpp:244]     Train net output #0: loss = 0.668241 (* 1 = 0.668241 loss)
I0725 22:31:41.657101 22939 sgd_solver.cpp:106] Iteration 27300, lr = 5.24356e-06
I0725 22:31:51.193159 22939 solver.cpp:228] Iteration 27400, loss = 0.58567
I0725 22:31:51.193202 22939 solver.cpp:244]     Train net output #0: loss = 0.58567 (* 1 = 0.58567 loss)
I0725 22:31:51.193207 22939 sgd_solver.cpp:106] Iteration 27400, lr = 5.23527e-06
I0725 22:32:00.655027 22939 solver.cpp:337] Iteration 27500, Testing net (#0)
I0725 22:32:11.520828 22939 solver.cpp:404]     Test net output #0: accuracy = 0.721667
I0725 22:32:11.520887 22939 solver.cpp:404]     Test net output #1: loss = 0.664693 (* 1 = 0.664693 loss)
I0725 22:32:11.553589 22939 solver.cpp:228] Iteration 27500, loss = 0.625172
I0725 22:32:11.553632 22939 solver.cpp:244]     Train net output #0: loss = 0.625172 (* 1 = 0.625172 loss)
I0725 22:32:11.553644 22939 sgd_solver.cpp:106] Iteration 27500, lr = 5.227e-06
I0725 22:32:20.868527 22939 solver.cpp:228] Iteration 27600, loss = 0.68787
I0725 22:32:20.868569 22939 solver.cpp:244]     Train net output #0: loss = 0.68787 (* 1 = 0.68787 loss)
I0725 22:32:20.868576 22939 sgd_solver.cpp:106] Iteration 27600, lr = 5.21876e-06
I0725 22:32:23.763391 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:32:30.244341 22939 solver.cpp:228] Iteration 27700, loss = 0.617355
I0725 22:32:30.244390 22939 solver.cpp:244]     Train net output #0: loss = 0.617355 (* 1 = 0.617355 loss)
I0725 22:32:30.244396 22939 sgd_solver.cpp:106] Iteration 27700, lr = 5.21055e-06
I0725 22:32:39.632302 22939 solver.cpp:228] Iteration 27800, loss = 0.691357
I0725 22:32:39.632350 22939 solver.cpp:244]     Train net output #0: loss = 0.691357 (* 1 = 0.691357 loss)
I0725 22:32:39.632357 22939 sgd_solver.cpp:106] Iteration 27800, lr = 5.20237e-06
I0725 22:32:49.104920 22939 solver.cpp:228] Iteration 27900, loss = 0.618282
I0725 22:32:49.104961 22939 solver.cpp:244]     Train net output #0: loss = 0.618282 (* 1 = 0.618282 loss)
I0725 22:32:49.104967 22939 sgd_solver.cpp:106] Iteration 27900, lr = 5.19423e-06
I0725 22:32:58.566227 22939 solver.cpp:337] Iteration 28000, Testing net (#0)
I0725 22:33:09.444497 22939 solver.cpp:404]     Test net output #0: accuracy = 0.719375
I0725 22:33:09.444540 22939 solver.cpp:404]     Test net output #1: loss = 0.668633 (* 1 = 0.668633 loss)
I0725 22:33:09.474527 22939 solver.cpp:228] Iteration 28000, loss = 0.536734
I0725 22:33:09.474555 22939 solver.cpp:244]     Train net output #0: loss = 0.536734 (* 1 = 0.536734 loss)
I0725 22:33:09.474565 22939 sgd_solver.cpp:106] Iteration 28000, lr = 5.18611e-06
I0725 22:33:18.875196 22939 solver.cpp:228] Iteration 28100, loss = 0.532206
I0725 22:33:18.875234 22939 solver.cpp:244]     Train net output #0: loss = 0.532206 (* 1 = 0.532206 loss)
I0725 22:33:18.875241 22939 sgd_solver.cpp:106] Iteration 28100, lr = 5.17802e-06
I0725 22:33:28.280120 22939 solver.cpp:228] Iteration 28200, loss = 0.746205
I0725 22:33:28.280161 22939 solver.cpp:244]     Train net output #0: loss = 0.746205 (* 1 = 0.746205 loss)
I0725 22:33:28.280169 22939 sgd_solver.cpp:106] Iteration 28200, lr = 5.16996e-06
I0725 22:33:37.679569 22939 solver.cpp:228] Iteration 28300, loss = 0.572561
I0725 22:33:37.679621 22939 solver.cpp:244]     Train net output #0: loss = 0.572561 (* 1 = 0.572561 loss)
I0725 22:33:37.679628 22939 sgd_solver.cpp:106] Iteration 28300, lr = 5.16193e-06
I0725 22:33:47.080271 22939 solver.cpp:228] Iteration 28400, loss = 0.614672
I0725 22:33:47.080329 22939 solver.cpp:244]     Train net output #0: loss = 0.614672 (* 1 = 0.614672 loss)
I0725 22:33:47.080335 22939 sgd_solver.cpp:106] Iteration 28400, lr = 5.15393e-06
I0725 22:33:56.388427 22939 solver.cpp:337] Iteration 28500, Testing net (#0)
I0725 22:34:07.314062 22939 solver.cpp:404]     Test net output #0: accuracy = 0.722083
I0725 22:34:07.314107 22939 solver.cpp:404]     Test net output #1: loss = 0.662764 (* 1 = 0.662764 loss)
I0725 22:34:07.343572 22939 solver.cpp:228] Iteration 28500, loss = 0.663
I0725 22:34:07.343627 22939 solver.cpp:244]     Train net output #0: loss = 0.663 (* 1 = 0.663 loss)
I0725 22:34:07.343647 22939 sgd_solver.cpp:106] Iteration 28500, lr = 5.14596e-06
I0725 22:34:16.729607 22939 solver.cpp:228] Iteration 28600, loss = 0.609411
I0725 22:34:16.729660 22939 solver.cpp:244]     Train net output #0: loss = 0.609411 (* 1 = 0.609411 loss)
I0725 22:34:16.729666 22939 sgd_solver.cpp:106] Iteration 28600, lr = 5.13801e-06
I0725 22:34:26.120769 22939 solver.cpp:228] Iteration 28700, loss = 0.555905
I0725 22:34:26.120815 22939 solver.cpp:244]     Train net output #0: loss = 0.555905 (* 1 = 0.555905 loss)
I0725 22:34:26.120820 22939 sgd_solver.cpp:106] Iteration 28700, lr = 5.1301e-06
I0725 22:34:35.511324 22939 solver.cpp:228] Iteration 28800, loss = 0.580568
I0725 22:34:35.511379 22939 solver.cpp:244]     Train net output #0: loss = 0.580568 (* 1 = 0.580568 loss)
I0725 22:34:35.511385 22939 sgd_solver.cpp:106] Iteration 28800, lr = 5.12221e-06
I0725 22:34:44.906803 22939 solver.cpp:228] Iteration 28900, loss = 0.657163
I0725 22:34:44.906847 22939 solver.cpp:244]     Train net output #0: loss = 0.657163 (* 1 = 0.657163 loss)
I0725 22:34:44.906853 22939 sgd_solver.cpp:106] Iteration 28900, lr = 5.11435e-06
I0725 22:34:54.206604 22939 solver.cpp:337] Iteration 29000, Testing net (#0)
I0725 22:35:05.160778 22939 solver.cpp:404]     Test net output #0: accuracy = 0.721584
I0725 22:35:05.160822 22939 solver.cpp:404]     Test net output #1: loss = 0.664469 (* 1 = 0.664469 loss)
I0725 22:35:05.190313 22939 solver.cpp:228] Iteration 29000, loss = 0.56258
I0725 22:35:05.190343 22939 solver.cpp:244]     Train net output #0: loss = 0.56258 (* 1 = 0.56258 loss)
I0725 22:35:05.190354 22939 sgd_solver.cpp:106] Iteration 29000, lr = 5.10652e-06
I0725 22:35:14.583847 22939 solver.cpp:228] Iteration 29100, loss = 0.549
I0725 22:35:14.583889 22939 solver.cpp:244]     Train net output #0: loss = 0.549 (* 1 = 0.549 loss)
I0725 22:35:14.583895 22939 sgd_solver.cpp:106] Iteration 29100, lr = 5.09872e-06
I0725 22:35:23.978067 22939 solver.cpp:228] Iteration 29200, loss = 0.690075
I0725 22:35:23.978109 22939 solver.cpp:244]     Train net output #0: loss = 0.690075 (* 1 = 0.690075 loss)
I0725 22:35:23.978116 22939 sgd_solver.cpp:106] Iteration 29200, lr = 5.09095e-06
I0725 22:35:33.372658 22939 solver.cpp:228] Iteration 29300, loss = 0.523014
I0725 22:35:33.372714 22939 solver.cpp:244]     Train net output #0: loss = 0.523014 (* 1 = 0.523014 loss)
I0725 22:35:33.372720 22939 sgd_solver.cpp:106] Iteration 29300, lr = 5.0832e-06
I0725 22:35:42.767138 22939 solver.cpp:228] Iteration 29400, loss = 0.583198
I0725 22:35:42.767197 22939 solver.cpp:244]     Train net output #0: loss = 0.583198 (* 1 = 0.583198 loss)
I0725 22:35:42.767204 22939 sgd_solver.cpp:106] Iteration 29400, lr = 5.07548e-06
I0725 22:35:52.070972 22939 solver.cpp:337] Iteration 29500, Testing net (#0)
I0725 22:35:58.984227 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:36:03.074933 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7215
I0725 22:36:03.074970 22939 solver.cpp:404]     Test net output #1: loss = 0.661947 (* 1 = 0.661947 loss)
I0725 22:36:03.103875 22939 solver.cpp:228] Iteration 29500, loss = 0.593187
I0725 22:36:03.103917 22939 solver.cpp:244]     Train net output #0: loss = 0.593187 (* 1 = 0.593187 loss)
I0725 22:36:03.103929 22939 sgd_solver.cpp:106] Iteration 29500, lr = 5.06779e-06
I0725 22:36:12.487781 22939 solver.cpp:228] Iteration 29600, loss = 0.563501
I0725 22:36:12.487823 22939 solver.cpp:244]     Train net output #0: loss = 0.563501 (* 1 = 0.563501 loss)
I0725 22:36:12.487830 22939 sgd_solver.cpp:106] Iteration 29600, lr = 5.06012e-06
I0725 22:36:21.890949 22939 solver.cpp:228] Iteration 29700, loss = 0.622289
I0725 22:36:21.890993 22939 solver.cpp:244]     Train net output #0: loss = 0.622289 (* 1 = 0.622289 loss)
I0725 22:36:21.891000 22939 sgd_solver.cpp:106] Iteration 29700, lr = 5.05249e-06
I0725 22:36:31.293310 22939 solver.cpp:228] Iteration 29800, loss = 0.570405
I0725 22:36:31.293370 22939 solver.cpp:244]     Train net output #0: loss = 0.570405 (* 1 = 0.570405 loss)
I0725 22:36:31.293376 22939 sgd_solver.cpp:106] Iteration 29800, lr = 5.04488e-06
I0725 22:36:40.698376 22939 solver.cpp:228] Iteration 29900, loss = 0.674384
I0725 22:36:40.698426 22939 solver.cpp:244]     Train net output #0: loss = 0.674384 (* 1 = 0.674384 loss)
I0725 22:36:40.698431 22939 sgd_solver.cpp:106] Iteration 29900, lr = 5.03729e-06
I0725 22:36:50.006613 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_30000.caffemodel
I0725 22:36:50.355144 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_30000.solverstate
I0725 22:36:50.463345 22939 solver.cpp:337] Iteration 30000, Testing net (#0)
I0725 22:37:01.244060 22939 solver.cpp:404]     Test net output #0: accuracy = 0.72325
I0725 22:37:01.244107 22939 solver.cpp:404]     Test net output #1: loss = 0.660237 (* 1 = 0.660237 loss)
I0725 22:37:01.277403 22939 solver.cpp:228] Iteration 30000, loss = 0.706433
I0725 22:37:01.277449 22939 solver.cpp:244]     Train net output #0: loss = 0.706433 (* 1 = 0.706433 loss)
I0725 22:37:01.277472 22939 sgd_solver.cpp:106] Iteration 30000, lr = 5.02973e-06
I0725 22:37:10.670493 22939 solver.cpp:228] Iteration 30100, loss = 0.605127
I0725 22:37:10.670542 22939 solver.cpp:244]     Train net output #0: loss = 0.605127 (* 1 = 0.605127 loss)
I0725 22:37:10.670547 22939 sgd_solver.cpp:106] Iteration 30100, lr = 5.0222e-06
I0725 22:37:20.056915 22939 solver.cpp:228] Iteration 30200, loss = 0.761757
I0725 22:37:20.056955 22939 solver.cpp:244]     Train net output #0: loss = 0.761757 (* 1 = 0.761757 loss)
I0725 22:37:20.056962 22939 sgd_solver.cpp:106] Iteration 30200, lr = 5.0147e-06
I0725 22:37:29.446429 22939 solver.cpp:228] Iteration 30300, loss = 0.539503
I0725 22:37:29.446476 22939 solver.cpp:244]     Train net output #0: loss = 0.539503 (* 1 = 0.539503 loss)
I0725 22:37:29.446482 22939 sgd_solver.cpp:106] Iteration 30300, lr = 5.00722e-06
I0725 22:37:38.837884 22939 solver.cpp:228] Iteration 30400, loss = 0.68513
I0725 22:37:38.837932 22939 solver.cpp:244]     Train net output #0: loss = 0.68513 (* 1 = 0.68513 loss)
I0725 22:37:38.837939 22939 sgd_solver.cpp:106] Iteration 30400, lr = 4.99976e-06
I0725 22:37:48.129544 22939 solver.cpp:337] Iteration 30500, Testing net (#0)
I0725 22:37:58.993805 22939 solver.cpp:404]     Test net output #0: accuracy = 0.723333
I0725 22:37:58.993861 22939 solver.cpp:404]     Test net output #1: loss = 0.658702 (* 1 = 0.658702 loss)
I0725 22:37:59.028292 22939 solver.cpp:228] Iteration 30500, loss = 0.56673
I0725 22:37:59.028339 22939 solver.cpp:244]     Train net output #0: loss = 0.56673 (* 1 = 0.56673 loss)
I0725 22:37:59.028360 22939 sgd_solver.cpp:106] Iteration 30500, lr = 4.99234e-06
I0725 22:38:08.422458 22939 solver.cpp:228] Iteration 30600, loss = 0.674259
I0725 22:38:08.422503 22939 solver.cpp:244]     Train net output #0: loss = 0.674259 (* 1 = 0.674259 loss)
I0725 22:38:08.422509 22939 sgd_solver.cpp:106] Iteration 30600, lr = 4.98494e-06
I0725 22:38:17.815273 22939 solver.cpp:228] Iteration 30700, loss = 0.573866
I0725 22:38:17.815322 22939 solver.cpp:244]     Train net output #0: loss = 0.573866 (* 1 = 0.573866 loss)
I0725 22:38:17.815330 22939 sgd_solver.cpp:106] Iteration 30700, lr = 4.97756e-06
I0725 22:38:27.207401 22939 solver.cpp:228] Iteration 30800, loss = 0.579173
I0725 22:38:27.207449 22939 solver.cpp:244]     Train net output #0: loss = 0.579173 (* 1 = 0.579173 loss)
I0725 22:38:27.207455 22939 sgd_solver.cpp:106] Iteration 30800, lr = 4.97021e-06
I0725 22:38:36.597046 22939 solver.cpp:228] Iteration 30900, loss = 0.594771
I0725 22:38:36.597091 22939 solver.cpp:244]     Train net output #0: loss = 0.594771 (* 1 = 0.594771 loss)
I0725 22:38:36.597097 22939 sgd_solver.cpp:106] Iteration 30900, lr = 4.96288e-06
I0725 22:38:45.896579 22939 solver.cpp:337] Iteration 31000, Testing net (#0)
I0725 22:38:56.794584 22939 solver.cpp:404]     Test net output #0: accuracy = 0.724458
I0725 22:38:56.794633 22939 solver.cpp:404]     Test net output #1: loss = 0.657502 (* 1 = 0.657502 loss)
I0725 22:38:56.824889 22939 solver.cpp:228] Iteration 31000, loss = 0.705069
I0725 22:38:56.824939 22939 solver.cpp:244]     Train net output #0: loss = 0.705069 (* 1 = 0.705069 loss)
I0725 22:38:56.824960 22939 sgd_solver.cpp:106] Iteration 31000, lr = 4.95558e-06
I0725 22:39:06.224797 22939 solver.cpp:228] Iteration 31100, loss = 0.69224
I0725 22:39:06.224841 22939 solver.cpp:244]     Train net output #0: loss = 0.69224 (* 1 = 0.69224 loss)
I0725 22:39:06.224848 22939 sgd_solver.cpp:106] Iteration 31100, lr = 4.94831e-06
I0725 22:39:15.621388 22939 solver.cpp:228] Iteration 31200, loss = 0.606298
I0725 22:39:15.621429 22939 solver.cpp:244]     Train net output #0: loss = 0.606298 (* 1 = 0.606298 loss)
I0725 22:39:15.621435 22939 sgd_solver.cpp:106] Iteration 31200, lr = 4.94106e-06
I0725 22:39:25.019747 22939 solver.cpp:228] Iteration 31300, loss = 0.532936
I0725 22:39:25.019790 22939 solver.cpp:244]     Train net output #0: loss = 0.532936 (* 1 = 0.532936 loss)
I0725 22:39:25.019796 22939 sgd_solver.cpp:106] Iteration 31300, lr = 4.93383e-06
I0725 22:39:34.419950 22939 solver.cpp:228] Iteration 31400, loss = 0.586628
I0725 22:39:34.419996 22939 solver.cpp:244]     Train net output #0: loss = 0.586628 (* 1 = 0.586628 loss)
I0725 22:39:34.420001 22939 sgd_solver.cpp:106] Iteration 31400, lr = 4.92663e-06
I0725 22:39:43.723340 22939 solver.cpp:337] Iteration 31500, Testing net (#0)
I0725 22:39:48.342620 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:39:54.662135 22939 solver.cpp:404]     Test net output #0: accuracy = 0.724875
I0725 22:39:54.662181 22939 solver.cpp:404]     Test net output #1: loss = 0.656216 (* 1 = 0.656216 loss)
I0725 22:39:54.689153 22939 solver.cpp:228] Iteration 31500, loss = 0.540222
I0725 22:39:54.689218 22939 solver.cpp:244]     Train net output #0: loss = 0.540222 (* 1 = 0.540222 loss)
I0725 22:39:54.689235 22939 sgd_solver.cpp:106] Iteration 31500, lr = 4.91946e-06
I0725 22:40:04.077796 22939 solver.cpp:228] Iteration 31600, loss = 0.597516
I0725 22:40:04.077844 22939 solver.cpp:244]     Train net output #0: loss = 0.597516 (* 1 = 0.597516 loss)
I0725 22:40:04.077852 22939 sgd_solver.cpp:106] Iteration 31600, lr = 4.9123e-06
I0725 22:40:13.468561 22939 solver.cpp:228] Iteration 31700, loss = 0.521652
I0725 22:40:13.468607 22939 solver.cpp:244]     Train net output #0: loss = 0.521652 (* 1 = 0.521652 loss)
I0725 22:40:13.468613 22939 sgd_solver.cpp:106] Iteration 31700, lr = 4.90518e-06
I0725 22:40:22.863317 22939 solver.cpp:228] Iteration 31800, loss = 0.598035
I0725 22:40:22.863371 22939 solver.cpp:244]     Train net output #0: loss = 0.598035 (* 1 = 0.598035 loss)
I0725 22:40:22.863379 22939 sgd_solver.cpp:106] Iteration 31800, lr = 4.89807e-06
I0725 22:40:32.253224 22939 solver.cpp:228] Iteration 31900, loss = 0.699147
I0725 22:40:32.253279 22939 solver.cpp:244]     Train net output #0: loss = 0.699147 (* 1 = 0.699147 loss)
I0725 22:40:32.253285 22939 sgd_solver.cpp:106] Iteration 31900, lr = 4.89099e-06
I0725 22:40:41.549036 22939 solver.cpp:337] Iteration 32000, Testing net (#0)
I0725 22:40:52.472167 22939 solver.cpp:404]     Test net output #0: accuracy = 0.725959
I0725 22:40:52.472210 22939 solver.cpp:404]     Test net output #1: loss = 0.654327 (* 1 = 0.654327 loss)
I0725 22:40:52.502063 22939 solver.cpp:228] Iteration 32000, loss = 0.538555
I0725 22:40:52.502122 22939 solver.cpp:244]     Train net output #0: loss = 0.538555 (* 1 = 0.538555 loss)
I0725 22:40:52.502140 22939 sgd_solver.cpp:106] Iteration 32000, lr = 4.88394e-06
I0725 22:41:01.894894 22939 solver.cpp:228] Iteration 32100, loss = 0.591387
I0725 22:41:01.894935 22939 solver.cpp:244]     Train net output #0: loss = 0.591387 (* 1 = 0.591387 loss)
I0725 22:41:01.894942 22939 sgd_solver.cpp:106] Iteration 32100, lr = 4.8769e-06
I0725 22:41:11.287472 22939 solver.cpp:228] Iteration 32200, loss = 0.716746
I0725 22:41:11.287511 22939 solver.cpp:244]     Train net output #0: loss = 0.716746 (* 1 = 0.716746 loss)
I0725 22:41:11.287518 22939 sgd_solver.cpp:106] Iteration 32200, lr = 4.86989e-06
I0725 22:41:20.680753 22939 solver.cpp:228] Iteration 32300, loss = 0.508419
I0725 22:41:20.680797 22939 solver.cpp:244]     Train net output #0: loss = 0.508419 (* 1 = 0.508419 loss)
I0725 22:41:20.680804 22939 sgd_solver.cpp:106] Iteration 32300, lr = 4.86291e-06
I0725 22:41:30.078368 22939 solver.cpp:228] Iteration 32400, loss = 0.510084
I0725 22:41:30.078408 22939 solver.cpp:244]     Train net output #0: loss = 0.510084 (* 1 = 0.510084 loss)
I0725 22:41:30.078414 22939 sgd_solver.cpp:106] Iteration 32400, lr = 4.85595e-06
I0725 22:41:39.380628 22939 solver.cpp:337] Iteration 32500, Testing net (#0)
I0725 22:41:50.251262 22939 solver.cpp:404]     Test net output #0: accuracy = 0.726167
I0725 22:41:50.251304 22939 solver.cpp:404]     Test net output #1: loss = 0.653223 (* 1 = 0.653223 loss)
I0725 22:41:50.280762 22939 solver.cpp:228] Iteration 32500, loss = 0.752492
I0725 22:41:50.280791 22939 solver.cpp:244]     Train net output #0: loss = 0.752492 (* 1 = 0.752492 loss)
I0725 22:41:50.280802 22939 sgd_solver.cpp:106] Iteration 32500, lr = 4.84901e-06
I0725 22:41:59.653928 22939 solver.cpp:228] Iteration 32600, loss = 0.684565
I0725 22:41:59.653978 22939 solver.cpp:244]     Train net output #0: loss = 0.684565 (* 1 = 0.684565 loss)
I0725 22:41:59.653985 22939 sgd_solver.cpp:106] Iteration 32600, lr = 4.84209e-06
I0725 22:42:09.052537 22939 solver.cpp:228] Iteration 32700, loss = 0.666065
I0725 22:42:09.052577 22939 solver.cpp:244]     Train net output #0: loss = 0.666065 (* 1 = 0.666065 loss)
I0725 22:42:09.052582 22939 sgd_solver.cpp:106] Iteration 32700, lr = 4.8352e-06
I0725 22:42:18.573276 22939 solver.cpp:228] Iteration 32800, loss = 0.607626
I0725 22:42:18.573314 22939 solver.cpp:244]     Train net output #0: loss = 0.607626 (* 1 = 0.607626 loss)
I0725 22:42:18.573320 22939 sgd_solver.cpp:106] Iteration 32800, lr = 4.82833e-06
I0725 22:42:28.048032 22939 solver.cpp:228] Iteration 32900, loss = 0.560643
I0725 22:42:28.048074 22939 solver.cpp:244]     Train net output #0: loss = 0.560643 (* 1 = 0.560643 loss)
I0725 22:42:28.048080 22939 sgd_solver.cpp:106] Iteration 32900, lr = 4.82148e-06
I0725 22:42:37.354269 22939 solver.cpp:337] Iteration 33000, Testing net (#0)
I0725 22:42:48.196104 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7265
I0725 22:42:48.196143 22939 solver.cpp:404]     Test net output #1: loss = 0.652648 (* 1 = 0.652648 loss)
I0725 22:42:48.230082 22939 solver.cpp:228] Iteration 33000, loss = 0.585136
I0725 22:42:48.230126 22939 solver.cpp:244]     Train net output #0: loss = 0.585136 (* 1 = 0.585136 loss)
I0725 22:42:48.230144 22939 sgd_solver.cpp:106] Iteration 33000, lr = 4.81466e-06
I0725 22:42:57.601752 22939 solver.cpp:228] Iteration 33100, loss = 0.551459
I0725 22:42:57.601802 22939 solver.cpp:244]     Train net output #0: loss = 0.551459 (* 1 = 0.551459 loss)
I0725 22:42:57.601809 22939 sgd_solver.cpp:106] Iteration 33100, lr = 4.80786e-06
I0725 22:43:07.000855 22939 solver.cpp:228] Iteration 33200, loss = 0.571322
I0725 22:43:07.000908 22939 solver.cpp:244]     Train net output #0: loss = 0.571322 (* 1 = 0.571322 loss)
I0725 22:43:07.000915 22939 sgd_solver.cpp:106] Iteration 33200, lr = 4.80108e-06
I0725 22:43:16.424020 22939 solver.cpp:228] Iteration 33300, loss = 0.576189
I0725 22:43:16.424075 22939 solver.cpp:244]     Train net output #0: loss = 0.576189 (* 1 = 0.576189 loss)
I0725 22:43:16.424082 22939 sgd_solver.cpp:106] Iteration 33300, lr = 4.79432e-06
I0725 22:43:25.978518 22939 solver.cpp:228] Iteration 33400, loss = 0.555663
I0725 22:43:25.978569 22939 solver.cpp:244]     Train net output #0: loss = 0.555663 (* 1 = 0.555663 loss)
I0725 22:43:25.978574 22939 sgd_solver.cpp:106] Iteration 33400, lr = 4.78759e-06
I0725 22:43:35.292732 22939 solver.cpp:337] Iteration 33500, Testing net (#0)
I0725 22:43:36.163544 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:43:46.175823 22939 solver.cpp:404]     Test net output #0: accuracy = 0.727
I0725 22:43:46.175866 22939 solver.cpp:404]     Test net output #1: loss = 0.651653 (* 1 = 0.651653 loss)
I0725 22:43:46.205193 22939 solver.cpp:228] Iteration 33500, loss = 0.648944
I0725 22:43:46.205219 22939 solver.cpp:244]     Train net output #0: loss = 0.648944 (* 1 = 0.648944 loss)
I0725 22:43:46.205231 22939 sgd_solver.cpp:106] Iteration 33500, lr = 4.78087e-06
I0725 22:43:55.568723 22939 solver.cpp:228] Iteration 33600, loss = 0.627483
I0725 22:43:55.568776 22939 solver.cpp:244]     Train net output #0: loss = 0.627483 (* 1 = 0.627483 loss)
I0725 22:43:55.568783 22939 sgd_solver.cpp:106] Iteration 33600, lr = 4.77418e-06
I0725 22:44:04.960422 22939 solver.cpp:228] Iteration 33700, loss = 0.663222
I0725 22:44:04.960466 22939 solver.cpp:244]     Train net output #0: loss = 0.663222 (* 1 = 0.663222 loss)
I0725 22:44:04.960472 22939 sgd_solver.cpp:106] Iteration 33700, lr = 4.76751e-06
I0725 22:44:14.354138 22939 solver.cpp:228] Iteration 33800, loss = 0.497694
I0725 22:44:14.354179 22939 solver.cpp:244]     Train net output #0: loss = 0.497694 (* 1 = 0.497694 loss)
I0725 22:44:14.354185 22939 sgd_solver.cpp:106] Iteration 33800, lr = 4.76086e-06
I0725 22:44:23.748075 22939 solver.cpp:228] Iteration 33900, loss = 0.567103
I0725 22:44:23.748124 22939 solver.cpp:244]     Train net output #0: loss = 0.567103 (* 1 = 0.567103 loss)
I0725 22:44:23.748131 22939 sgd_solver.cpp:106] Iteration 33900, lr = 4.75424e-06
I0725 22:44:33.051276 22939 solver.cpp:337] Iteration 34000, Testing net (#0)
I0725 22:44:43.941673 22939 solver.cpp:404]     Test net output #0: accuracy = 0.727708
I0725 22:44:43.941715 22939 solver.cpp:404]     Test net output #1: loss = 0.650681 (* 1 = 0.650681 loss)
I0725 22:44:43.971525 22939 solver.cpp:228] Iteration 34000, loss = 0.632688
I0725 22:44:43.971581 22939 solver.cpp:244]     Train net output #0: loss = 0.632688 (* 1 = 0.632688 loss)
I0725 22:44:43.971601 22939 sgd_solver.cpp:106] Iteration 34000, lr = 4.74763e-06
I0725 22:44:53.355731 22939 solver.cpp:228] Iteration 34100, loss = 0.613669
I0725 22:44:53.355773 22939 solver.cpp:244]     Train net output #0: loss = 0.613669 (* 1 = 0.613669 loss)
I0725 22:44:53.355780 22939 sgd_solver.cpp:106] Iteration 34100, lr = 4.74105e-06
I0725 22:45:02.761450 22939 solver.cpp:228] Iteration 34200, loss = 0.661179
I0725 22:45:02.761489 22939 solver.cpp:244]     Train net output #0: loss = 0.661179 (* 1 = 0.661179 loss)
I0725 22:45:02.761495 22939 sgd_solver.cpp:106] Iteration 34200, lr = 4.73449e-06
I0725 22:45:12.172273 22939 solver.cpp:228] Iteration 34300, loss = 0.65599
I0725 22:45:12.172322 22939 solver.cpp:244]     Train net output #0: loss = 0.65599 (* 1 = 0.65599 loss)
I0725 22:45:12.172327 22939 sgd_solver.cpp:106] Iteration 34300, lr = 4.72795e-06
I0725 22:45:21.576885 22939 solver.cpp:228] Iteration 34400, loss = 0.606109
I0725 22:45:21.576941 22939 solver.cpp:244]     Train net output #0: loss = 0.606109 (* 1 = 0.606109 loss)
I0725 22:45:21.576951 22939 sgd_solver.cpp:106] Iteration 34400, lr = 4.72143e-06
I0725 22:45:30.887070 22939 solver.cpp:337] Iteration 34500, Testing net (#0)
I0725 22:45:41.738762 22939 solver.cpp:404]     Test net output #0: accuracy = 0.727833
I0725 22:45:41.738801 22939 solver.cpp:404]     Test net output #1: loss = 0.650676 (* 1 = 0.650676 loss)
I0725 22:45:41.771988 22939 solver.cpp:228] Iteration 34500, loss = 0.741422
I0725 22:45:41.772033 22939 solver.cpp:244]     Train net output #0: loss = 0.741422 (* 1 = 0.741422 loss)
I0725 22:45:41.772053 22939 sgd_solver.cpp:106] Iteration 34500, lr = 4.71493e-06
I0725 22:45:51.165382 22939 solver.cpp:228] Iteration 34600, loss = 0.509856
I0725 22:45:51.165426 22939 solver.cpp:244]     Train net output #0: loss = 0.509856 (* 1 = 0.509856 loss)
I0725 22:45:51.165431 22939 sgd_solver.cpp:106] Iteration 34600, lr = 4.70845e-06
I0725 22:46:00.558986 22939 solver.cpp:228] Iteration 34700, loss = 0.724795
I0725 22:46:00.559039 22939 solver.cpp:244]     Train net output #0: loss = 0.724795 (* 1 = 0.724795 loss)
I0725 22:46:00.559046 22939 sgd_solver.cpp:106] Iteration 34700, lr = 4.70199e-06
I0725 22:46:09.950345 22939 solver.cpp:228] Iteration 34800, loss = 0.595259
I0725 22:46:09.950384 22939 solver.cpp:244]     Train net output #0: loss = 0.595259 (* 1 = 0.595259 loss)
I0725 22:46:09.950390 22939 sgd_solver.cpp:106] Iteration 34800, lr = 4.69556e-06
I0725 22:46:19.346170 22939 solver.cpp:228] Iteration 34900, loss = 0.637218
I0725 22:46:19.346211 22939 solver.cpp:244]     Train net output #0: loss = 0.637218 (* 1 = 0.637218 loss)
I0725 22:46:19.346217 22939 sgd_solver.cpp:106] Iteration 34900, lr = 4.68914e-06
I0725 22:46:28.645279 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_35000.caffemodel
I0725 22:46:28.992998 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_35000.solverstate
I0725 22:46:29.101104 22939 solver.cpp:337] Iteration 35000, Testing net (#0)
I0725 22:46:39.887125 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728042
I0725 22:46:39.887174 22939 solver.cpp:404]     Test net output #1: loss = 0.649704 (* 1 = 0.649704 loss)
I0725 22:46:39.919881 22939 solver.cpp:228] Iteration 35000, loss = 0.640412
I0725 22:46:39.919926 22939 solver.cpp:244]     Train net output #0: loss = 0.640412 (* 1 = 0.640412 loss)
I0725 22:46:39.919935 22939 sgd_solver.cpp:106] Iteration 35000, lr = 4.68274e-06
I0725 22:46:49.322235 22939 solver.cpp:228] Iteration 35100, loss = 0.538135
I0725 22:46:49.322283 22939 solver.cpp:244]     Train net output #0: loss = 0.538135 (* 1 = 0.538135 loss)
I0725 22:46:49.322289 22939 sgd_solver.cpp:106] Iteration 35100, lr = 4.67637e-06
I0725 22:46:58.873605 22939 solver.cpp:228] Iteration 35200, loss = 0.624065
I0725 22:46:58.873651 22939 solver.cpp:244]     Train net output #0: loss = 0.624065 (* 1 = 0.624065 loss)
I0725 22:46:58.873659 22939 sgd_solver.cpp:106] Iteration 35200, lr = 4.67001e-06
I0725 22:47:08.309389 22939 solver.cpp:228] Iteration 35300, loss = 0.589363
I0725 22:47:08.309430 22939 solver.cpp:244]     Train net output #0: loss = 0.589363 (* 1 = 0.589363 loss)
I0725 22:47:08.309437 22939 sgd_solver.cpp:106] Iteration 35300, lr = 4.66368e-06
I0725 22:47:10.846204 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:47:17.699396 22939 solver.cpp:228] Iteration 35400, loss = 0.70391
I0725 22:47:17.699441 22939 solver.cpp:244]     Train net output #0: loss = 0.70391 (* 1 = 0.70391 loss)
I0725 22:47:17.699447 22939 sgd_solver.cpp:106] Iteration 35400, lr = 4.65736e-06
I0725 22:47:26.999873 22939 solver.cpp:337] Iteration 35500, Testing net (#0)
I0725 22:47:37.839555 22939 solver.cpp:404]     Test net output #0: accuracy = 0.727334
I0725 22:47:37.839630 22939 solver.cpp:404]     Test net output #1: loss = 0.651083 (* 1 = 0.651083 loss)
I0725 22:47:37.866952 22939 solver.cpp:228] Iteration 35500, loss = 0.553002
I0725 22:47:37.867000 22939 solver.cpp:244]     Train net output #0: loss = 0.553002 (* 1 = 0.553002 loss)
I0725 22:47:37.867020 22939 sgd_solver.cpp:106] Iteration 35500, lr = 4.65107e-06
I0725 22:47:47.267716 22939 solver.cpp:228] Iteration 35600, loss = 0.572759
I0725 22:47:47.267770 22939 solver.cpp:244]     Train net output #0: loss = 0.572759 (* 1 = 0.572759 loss)
I0725 22:47:47.267776 22939 sgd_solver.cpp:106] Iteration 35600, lr = 4.64479e-06
I0725 22:47:56.666694 22939 solver.cpp:228] Iteration 35700, loss = 0.708842
I0725 22:47:56.666749 22939 solver.cpp:244]     Train net output #0: loss = 0.708842 (* 1 = 0.708842 loss)
I0725 22:47:56.666754 22939 sgd_solver.cpp:106] Iteration 35700, lr = 4.63854e-06
I0725 22:48:06.066481 22939 solver.cpp:228] Iteration 35800, loss = 0.553108
I0725 22:48:06.066537 22939 solver.cpp:244]     Train net output #0: loss = 0.553108 (* 1 = 0.553108 loss)
I0725 22:48:06.066545 22939 sgd_solver.cpp:106] Iteration 35800, lr = 4.6323e-06
I0725 22:48:15.464548 22939 solver.cpp:228] Iteration 35900, loss = 0.563837
I0725 22:48:15.464607 22939 solver.cpp:244]     Train net output #0: loss = 0.563837 (* 1 = 0.563837 loss)
I0725 22:48:15.464613 22939 sgd_solver.cpp:106] Iteration 35900, lr = 4.62609e-06
I0725 22:48:24.867658 22939 solver.cpp:337] Iteration 36000, Testing net (#0)
I0725 22:48:35.846256 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728459
I0725 22:48:35.846300 22939 solver.cpp:404]     Test net output #1: loss = 0.647745 (* 1 = 0.647745 loss)
I0725 22:48:35.877984 22939 solver.cpp:228] Iteration 36000, loss = 0.45257
I0725 22:48:35.878008 22939 solver.cpp:244]     Train net output #0: loss = 0.45257 (* 1 = 0.45257 loss)
I0725 22:48:35.878020 22939 sgd_solver.cpp:106] Iteration 36000, lr = 4.61989e-06
I0725 22:48:45.276185 22939 solver.cpp:228] Iteration 36100, loss = 0.523263
I0725 22:48:45.276226 22939 solver.cpp:244]     Train net output #0: loss = 0.523263 (* 1 = 0.523263 loss)
I0725 22:48:45.276232 22939 sgd_solver.cpp:106] Iteration 36100, lr = 4.61371e-06
I0725 22:48:54.667471 22939 solver.cpp:228] Iteration 36200, loss = 0.606311
I0725 22:48:54.667513 22939 solver.cpp:244]     Train net output #0: loss = 0.606311 (* 1 = 0.606311 loss)
I0725 22:48:54.667520 22939 sgd_solver.cpp:106] Iteration 36200, lr = 4.60755e-06
I0725 22:49:04.060560 22939 solver.cpp:228] Iteration 36300, loss = 0.627252
I0725 22:49:04.060622 22939 solver.cpp:244]     Train net output #0: loss = 0.627252 (* 1 = 0.627252 loss)
I0725 22:49:04.060629 22939 sgd_solver.cpp:106] Iteration 36300, lr = 4.60141e-06
I0725 22:49:13.450721 22939 solver.cpp:228] Iteration 36400, loss = 0.605064
I0725 22:49:13.450769 22939 solver.cpp:244]     Train net output #0: loss = 0.605064 (* 1 = 0.605064 loss)
I0725 22:49:13.450775 22939 sgd_solver.cpp:106] Iteration 36400, lr = 4.59529e-06
I0725 22:49:22.750620 22939 solver.cpp:337] Iteration 36500, Testing net (#0)
I0725 22:49:33.623443 22939 solver.cpp:404]     Test net output #0: accuracy = 0.727583
I0725 22:49:33.623486 22939 solver.cpp:404]     Test net output #1: loss = 0.650483 (* 1 = 0.650483 loss)
I0725 22:49:33.653337 22939 solver.cpp:228] Iteration 36500, loss = 0.581793
I0725 22:49:33.653383 22939 solver.cpp:244]     Train net output #0: loss = 0.581793 (* 1 = 0.581793 loss)
I0725 22:49:33.653408 22939 sgd_solver.cpp:106] Iteration 36500, lr = 4.58919e-06
I0725 22:49:43.039842 22939 solver.cpp:228] Iteration 36600, loss = 0.515834
I0725 22:49:43.039901 22939 solver.cpp:244]     Train net output #0: loss = 0.515834 (* 1 = 0.515834 loss)
I0725 22:49:43.039909 22939 sgd_solver.cpp:106] Iteration 36600, lr = 4.58311e-06
I0725 22:49:52.427271 22939 solver.cpp:228] Iteration 36700, loss = 0.534903
I0725 22:49:52.427331 22939 solver.cpp:244]     Train net output #0: loss = 0.534903 (* 1 = 0.534903 loss)
I0725 22:49:52.427338 22939 sgd_solver.cpp:106] Iteration 36700, lr = 4.57705e-06
I0725 22:50:01.818703 22939 solver.cpp:228] Iteration 36800, loss = 0.639408
I0725 22:50:01.818744 22939 solver.cpp:244]     Train net output #0: loss = 0.639408 (* 1 = 0.639408 loss)
I0725 22:50:01.818750 22939 sgd_solver.cpp:106] Iteration 36800, lr = 4.571e-06
I0725 22:50:11.315820 22939 solver.cpp:228] Iteration 36900, loss = 0.66636
I0725 22:50:11.315872 22939 solver.cpp:244]     Train net output #0: loss = 0.66636 (* 1 = 0.66636 loss)
I0725 22:50:11.315878 22939 sgd_solver.cpp:106] Iteration 36900, lr = 4.56497e-06
I0725 22:50:20.770521 22939 solver.cpp:337] Iteration 37000, Testing net (#0)
I0725 22:50:31.672488 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728875
I0725 22:50:31.672536 22939 solver.cpp:404]     Test net output #1: loss = 0.646629 (* 1 = 0.646629 loss)
I0725 22:50:31.700289 22939 solver.cpp:228] Iteration 37000, loss = 0.690633
I0725 22:50:31.700326 22939 solver.cpp:244]     Train net output #0: loss = 0.690633 (* 1 = 0.690633 loss)
I0725 22:50:31.700351 22939 sgd_solver.cpp:106] Iteration 37000, lr = 4.55897e-06
I0725 22:50:41.095851 22939 solver.cpp:228] Iteration 37100, loss = 0.474575
I0725 22:50:41.095893 22939 solver.cpp:244]     Train net output #0: loss = 0.474575 (* 1 = 0.474575 loss)
I0725 22:50:41.095902 22939 sgd_solver.cpp:106] Iteration 37100, lr = 4.55298e-06
I0725 22:50:50.495357 22939 solver.cpp:228] Iteration 37200, loss = 0.625852
I0725 22:50:50.495403 22939 solver.cpp:244]     Train net output #0: loss = 0.625852 (* 1 = 0.625852 loss)
I0725 22:50:50.495419 22939 sgd_solver.cpp:106] Iteration 37200, lr = 4.54701e-06
I0725 22:50:59.894352 22939 solver.cpp:228] Iteration 37300, loss = 0.647424
I0725 22:50:59.894397 22939 solver.cpp:244]     Train net output #0: loss = 0.647424 (* 1 = 0.647424 loss)
I0725 22:50:59.894407 22939 sgd_solver.cpp:106] Iteration 37300, lr = 4.54105e-06
I0725 22:51:09.295254 22939 solver.cpp:228] Iteration 37400, loss = 0.570259
I0725 22:51:09.295300 22939 solver.cpp:244]     Train net output #0: loss = 0.570259 (* 1 = 0.570259 loss)
I0725 22:51:09.295308 22939 sgd_solver.cpp:106] Iteration 37400, lr = 4.53512e-06
I0725 22:51:12.960492 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:51:18.600617 22939 solver.cpp:337] Iteration 37500, Testing net (#0)
I0725 22:51:29.511322 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728667
I0725 22:51:29.511374 22939 solver.cpp:404]     Test net output #1: loss = 0.649181 (* 1 = 0.649181 loss)
I0725 22:51:29.541286 22939 solver.cpp:228] Iteration 37500, loss = 0.586475
I0725 22:51:29.541345 22939 solver.cpp:244]     Train net output #0: loss = 0.586475 (* 1 = 0.586475 loss)
I0725 22:51:29.541365 22939 sgd_solver.cpp:106] Iteration 37500, lr = 4.5292e-06
I0725 22:51:38.929386 22939 solver.cpp:228] Iteration 37600, loss = 0.601438
I0725 22:51:38.929430 22939 solver.cpp:244]     Train net output #0: loss = 0.601438 (* 1 = 0.601438 loss)
I0725 22:51:38.929436 22939 sgd_solver.cpp:106] Iteration 37600, lr = 4.5233e-06
I0725 22:51:48.318111 22939 solver.cpp:228] Iteration 37700, loss = 0.519985
I0725 22:51:48.318155 22939 solver.cpp:244]     Train net output #0: loss = 0.519985 (* 1 = 0.519985 loss)
I0725 22:51:48.318161 22939 sgd_solver.cpp:106] Iteration 37700, lr = 4.51742e-06
I0725 22:51:57.703965 22939 solver.cpp:228] Iteration 37800, loss = 0.488744
I0725 22:51:57.704010 22939 solver.cpp:244]     Train net output #0: loss = 0.488744 (* 1 = 0.488744 loss)
I0725 22:51:57.704015 22939 sgd_solver.cpp:106] Iteration 37800, lr = 4.51156e-06
I0725 22:52:07.095813 22939 solver.cpp:228] Iteration 37900, loss = 0.660184
I0725 22:52:07.095867 22939 solver.cpp:244]     Train net output #0: loss = 0.660184 (* 1 = 0.660184 loss)
I0725 22:52:07.095875 22939 sgd_solver.cpp:106] Iteration 37900, lr = 4.50571e-06
I0725 22:52:16.391401 22939 solver.cpp:337] Iteration 38000, Testing net (#0)
I0725 22:52:27.291904 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728791
I0725 22:52:27.291946 22939 solver.cpp:404]     Test net output #1: loss = 0.645758 (* 1 = 0.645758 loss)
I0725 22:52:27.321538 22939 solver.cpp:228] Iteration 38000, loss = 0.662688
I0725 22:52:27.321557 22939 solver.cpp:244]     Train net output #0: loss = 0.662688 (* 1 = 0.662688 loss)
I0725 22:52:27.321566 22939 sgd_solver.cpp:106] Iteration 38000, lr = 4.49989e-06
I0725 22:52:36.794162 22939 solver.cpp:228] Iteration 38100, loss = 0.571595
I0725 22:52:36.794215 22939 solver.cpp:244]     Train net output #0: loss = 0.571595 (* 1 = 0.571595 loss)
I0725 22:52:36.794222 22939 sgd_solver.cpp:106] Iteration 38100, lr = 4.49408e-06
I0725 22:52:46.346292 22939 solver.cpp:228] Iteration 38200, loss = 0.592019
I0725 22:52:46.346338 22939 solver.cpp:244]     Train net output #0: loss = 0.592019 (* 1 = 0.592019 loss)
I0725 22:52:46.346344 22939 sgd_solver.cpp:106] Iteration 38200, lr = 4.48828e-06
I0725 22:52:55.736490 22939 solver.cpp:228] Iteration 38300, loss = 0.616695
I0725 22:52:55.736536 22939 solver.cpp:244]     Train net output #0: loss = 0.616695 (* 1 = 0.616695 loss)
I0725 22:52:55.736542 22939 sgd_solver.cpp:106] Iteration 38300, lr = 4.48251e-06
I0725 22:53:05.128764 22939 solver.cpp:228] Iteration 38400, loss = 0.543814
I0725 22:53:05.128803 22939 solver.cpp:244]     Train net output #0: loss = 0.543814 (* 1 = 0.543814 loss)
I0725 22:53:05.128808 22939 sgd_solver.cpp:106] Iteration 38400, lr = 4.47675e-06
I0725 22:53:14.428879 22939 solver.cpp:337] Iteration 38500, Testing net (#0)
I0725 22:53:25.264678 22939 solver.cpp:404]     Test net output #0: accuracy = 0.728792
I0725 22:53:25.264734 22939 solver.cpp:404]     Test net output #1: loss = 0.648667 (* 1 = 0.648667 loss)
I0725 22:53:25.291543 22939 solver.cpp:228] Iteration 38500, loss = 0.605267
I0725 22:53:25.291590 22939 solver.cpp:244]     Train net output #0: loss = 0.605267 (* 1 = 0.605267 loss)
I0725 22:53:25.291601 22939 sgd_solver.cpp:106] Iteration 38500, lr = 4.47101e-06
I0725 22:53:34.660387 22939 solver.cpp:228] Iteration 38600, loss = 0.60567
I0725 22:53:34.660441 22939 solver.cpp:244]     Train net output #0: loss = 0.60567 (* 1 = 0.60567 loss)
I0725 22:53:34.660449 22939 sgd_solver.cpp:106] Iteration 38600, lr = 4.46529e-06
I0725 22:53:44.059371 22939 solver.cpp:228] Iteration 38700, loss = 0.5869
I0725 22:53:44.059418 22939 solver.cpp:244]     Train net output #0: loss = 0.5869 (* 1 = 0.5869 loss)
I0725 22:53:44.059425 22939 sgd_solver.cpp:106] Iteration 38700, lr = 4.45958e-06
I0725 22:53:53.461016 22939 solver.cpp:228] Iteration 38800, loss = 0.620525
I0725 22:53:53.461066 22939 solver.cpp:244]     Train net output #0: loss = 0.620525 (* 1 = 0.620525 loss)
I0725 22:53:53.461071 22939 sgd_solver.cpp:106] Iteration 38800, lr = 4.45389e-06
I0725 22:54:02.861176 22939 solver.cpp:228] Iteration 38900, loss = 0.469281
I0725 22:54:02.861214 22939 solver.cpp:244]     Train net output #0: loss = 0.469281 (* 1 = 0.469281 loss)
I0725 22:54:02.861220 22939 sgd_solver.cpp:106] Iteration 38900, lr = 4.44822e-06
I0725 22:54:12.170224 22939 solver.cpp:337] Iteration 39000, Testing net (#0)
I0725 22:54:23.075273 22939 solver.cpp:404]     Test net output #0: accuracy = 0.729792
I0725 22:54:23.075332 22939 solver.cpp:404]     Test net output #1: loss = 0.6442 (* 1 = 0.6442 loss)
I0725 22:54:23.105659 22939 solver.cpp:228] Iteration 39000, loss = 0.576429
I0725 22:54:23.105718 22939 solver.cpp:244]     Train net output #0: loss = 0.576429 (* 1 = 0.576429 loss)
I0725 22:54:23.105744 22939 sgd_solver.cpp:106] Iteration 39000, lr = 4.44256e-06
I0725 22:54:32.499927 22939 solver.cpp:228] Iteration 39100, loss = 0.627605
I0725 22:54:32.499970 22939 solver.cpp:244]     Train net output #0: loss = 0.627605 (* 1 = 0.627605 loss)
I0725 22:54:32.499976 22939 sgd_solver.cpp:106] Iteration 39100, lr = 4.43692e-06
I0725 22:54:41.889755 22939 solver.cpp:228] Iteration 39200, loss = 0.605693
I0725 22:54:41.889798 22939 solver.cpp:244]     Train net output #0: loss = 0.605693 (* 1 = 0.605693 loss)
I0725 22:54:41.889804 22939 sgd_solver.cpp:106] Iteration 39200, lr = 4.4313e-06
I0725 22:54:51.284816 22939 solver.cpp:228] Iteration 39300, loss = 0.756199
I0725 22:54:51.284862 22939 solver.cpp:244]     Train net output #0: loss = 0.756199 (* 1 = 0.756199 loss)
I0725 22:54:51.284868 22939 sgd_solver.cpp:106] Iteration 39300, lr = 4.42569e-06
I0725 22:54:52.599833 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:55:00.681457 22939 solver.cpp:228] Iteration 39400, loss = 0.539391
I0725 22:55:00.681495 22939 solver.cpp:244]     Train net output #0: loss = 0.539391 (* 1 = 0.539391 loss)
I0725 22:55:00.681502 22939 sgd_solver.cpp:106] Iteration 39400, lr = 4.42011e-06
I0725 22:55:09.978480 22939 solver.cpp:337] Iteration 39500, Testing net (#0)
I0725 22:55:20.880183 22939 solver.cpp:404]     Test net output #0: accuracy = 0.730416
I0725 22:55:20.880225 22939 solver.cpp:404]     Test net output #1: loss = 0.644522 (* 1 = 0.644522 loss)
I0725 22:55:20.910181 22939 solver.cpp:228] Iteration 39500, loss = 0.600398
I0725 22:55:20.910241 22939 solver.cpp:244]     Train net output #0: loss = 0.600398 (* 1 = 0.600398 loss)
I0725 22:55:20.910260 22939 sgd_solver.cpp:106] Iteration 39500, lr = 4.41453e-06
I0725 22:55:30.303501 22939 solver.cpp:228] Iteration 39600, loss = 0.632963
I0725 22:55:30.303547 22939 solver.cpp:244]     Train net output #0: loss = 0.632963 (* 1 = 0.632963 loss)
I0725 22:55:30.303555 22939 sgd_solver.cpp:106] Iteration 39600, lr = 4.40898e-06
I0725 22:55:39.696120 22939 solver.cpp:228] Iteration 39700, loss = 0.686229
I0725 22:55:39.696173 22939 solver.cpp:244]     Train net output #0: loss = 0.686229 (* 1 = 0.686229 loss)
I0725 22:55:39.696179 22939 sgd_solver.cpp:106] Iteration 39700, lr = 4.40344e-06
I0725 22:55:49.088482 22939 solver.cpp:228] Iteration 39800, loss = 0.555243
I0725 22:55:49.088524 22939 solver.cpp:244]     Train net output #0: loss = 0.555243 (* 1 = 0.555243 loss)
I0725 22:55:49.088531 22939 sgd_solver.cpp:106] Iteration 39800, lr = 4.39791e-06
I0725 22:55:58.482930 22939 solver.cpp:228] Iteration 39900, loss = 0.54684
I0725 22:55:58.482988 22939 solver.cpp:244]     Train net output #0: loss = 0.54684 (* 1 = 0.54684 loss)
I0725 22:55:58.482995 22939 sgd_solver.cpp:106] Iteration 39900, lr = 4.39241e-06
I0725 22:56:07.788270 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_40000.caffemodel
I0725 22:56:08.134223 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_40000.solverstate
I0725 22:56:08.242048 22939 solver.cpp:337] Iteration 40000, Testing net (#0)
I0725 22:56:18.922250 22939 solver.cpp:404]     Test net output #0: accuracy = 0.730792
I0725 22:56:18.922291 22939 solver.cpp:404]     Test net output #1: loss = 0.641552 (* 1 = 0.641552 loss)
I0725 22:56:18.952070 22939 solver.cpp:228] Iteration 40000, loss = 0.732977
I0725 22:56:18.952127 22939 solver.cpp:244]     Train net output #0: loss = 0.732977 (* 1 = 0.732977 loss)
I0725 22:56:18.952152 22939 sgd_solver.cpp:106] Iteration 40000, lr = 4.38691e-06
I0725 22:56:28.424027 22939 solver.cpp:228] Iteration 40100, loss = 0.543884
I0725 22:56:28.424082 22939 solver.cpp:244]     Train net output #0: loss = 0.543884 (* 1 = 0.543884 loss)
I0725 22:56:28.424089 22939 sgd_solver.cpp:106] Iteration 40100, lr = 4.38144e-06
I0725 22:56:37.983736 22939 solver.cpp:228] Iteration 40200, loss = 0.598048
I0725 22:56:37.983777 22939 solver.cpp:244]     Train net output #0: loss = 0.598048 (* 1 = 0.598048 loss)
I0725 22:56:37.983783 22939 sgd_solver.cpp:106] Iteration 40200, lr = 4.37598e-06
I0725 22:56:47.486440 22939 solver.cpp:228] Iteration 40300, loss = 0.509214
I0725 22:56:47.486485 22939 solver.cpp:244]     Train net output #0: loss = 0.509214 (* 1 = 0.509214 loss)
I0725 22:56:47.486491 22939 sgd_solver.cpp:106] Iteration 40300, lr = 4.37053e-06
I0725 22:56:56.892978 22939 solver.cpp:228] Iteration 40400, loss = 0.66337
I0725 22:56:56.893021 22939 solver.cpp:244]     Train net output #0: loss = 0.66337 (* 1 = 0.66337 loss)
I0725 22:56:56.893028 22939 sgd_solver.cpp:106] Iteration 40400, lr = 4.36511e-06
I0725 22:57:06.201807 22939 solver.cpp:337] Iteration 40500, Testing net (#0)
I0725 22:57:17.108203 22939 solver.cpp:404]     Test net output #0: accuracy = 0.731875
I0725 22:57:17.108249 22939 solver.cpp:404]     Test net output #1: loss = 0.641712 (* 1 = 0.641712 loss)
I0725 22:57:17.140130 22939 solver.cpp:228] Iteration 40500, loss = 0.532181
I0725 22:57:17.140190 22939 solver.cpp:244]     Train net output #0: loss = 0.532181 (* 1 = 0.532181 loss)
I0725 22:57:17.140208 22939 sgd_solver.cpp:106] Iteration 40500, lr = 4.35969e-06
I0725 22:57:26.458626 22939 solver.cpp:228] Iteration 40600, loss = 0.627129
I0725 22:57:26.458669 22939 solver.cpp:244]     Train net output #0: loss = 0.627129 (* 1 = 0.627129 loss)
I0725 22:57:26.458678 22939 sgd_solver.cpp:106] Iteration 40600, lr = 4.3543e-06
I0725 22:57:35.854761 22939 solver.cpp:228] Iteration 40700, loss = 0.63397
I0725 22:57:35.854809 22939 solver.cpp:244]     Train net output #0: loss = 0.63397 (* 1 = 0.63397 loss)
I0725 22:57:35.854815 22939 sgd_solver.cpp:106] Iteration 40700, lr = 4.34892e-06
I0725 22:57:45.253726 22939 solver.cpp:228] Iteration 40800, loss = 0.541598
I0725 22:57:45.253772 22939 solver.cpp:244]     Train net output #0: loss = 0.541598 (* 1 = 0.541598 loss)
I0725 22:57:45.253778 22939 sgd_solver.cpp:106] Iteration 40800, lr = 4.34355e-06
I0725 22:57:54.679975 22939 solver.cpp:228] Iteration 40900, loss = 0.554595
I0725 22:57:54.680017 22939 solver.cpp:244]     Train net output #0: loss = 0.554595 (* 1 = 0.554595 loss)
I0725 22:57:54.680024 22939 sgd_solver.cpp:106] Iteration 40900, lr = 4.3382e-06
I0725 22:58:04.140287 22939 solver.cpp:337] Iteration 41000, Testing net (#0)
I0725 22:58:15.054985 22939 solver.cpp:404]     Test net output #0: accuracy = 0.731834
I0725 22:58:15.055042 22939 solver.cpp:404]     Test net output #1: loss = 0.638896 (* 1 = 0.638896 loss)
I0725 22:58:15.086105 22939 solver.cpp:228] Iteration 41000, loss = 0.479251
I0725 22:58:15.086134 22939 solver.cpp:244]     Train net output #0: loss = 0.479251 (* 1 = 0.479251 loss)
I0725 22:58:15.086144 22939 sgd_solver.cpp:106] Iteration 41000, lr = 4.33286e-06
I0725 22:58:24.443898 22939 solver.cpp:228] Iteration 41100, loss = 0.587828
I0725 22:58:24.443944 22939 solver.cpp:244]     Train net output #0: loss = 0.587828 (* 1 = 0.587828 loss)
I0725 22:58:24.443950 22939 sgd_solver.cpp:106] Iteration 41100, lr = 4.32754e-06
I0725 22:58:33.836585 22939 solver.cpp:228] Iteration 41200, loss = 0.546519
I0725 22:58:33.836632 22939 solver.cpp:244]     Train net output #0: loss = 0.546519 (* 1 = 0.546519 loss)
I0725 22:58:33.836637 22939 sgd_solver.cpp:106] Iteration 41200, lr = 4.32224e-06
I0725 22:58:43.254534 22939 solver.cpp:228] Iteration 41300, loss = 0.660217
I0725 22:58:43.254576 22939 solver.cpp:244]     Train net output #0: loss = 0.660217 (* 1 = 0.660217 loss)
I0725 22:58:43.254583 22939 sgd_solver.cpp:106] Iteration 41300, lr = 4.31695e-06
I0725 22:58:52.813845 22939 solver.cpp:228] Iteration 41400, loss = 0.519119
I0725 22:58:52.813906 22939 solver.cpp:244]     Train net output #0: loss = 0.519119 (* 1 = 0.519119 loss)
I0725 22:58:52.813915 22939 sgd_solver.cpp:106] Iteration 41400, lr = 4.31168e-06
I0725 22:58:57.867319 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 22:59:02.191825 22939 solver.cpp:337] Iteration 41500, Testing net (#0)
I0725 22:59:13.036655 22939 solver.cpp:404]     Test net output #0: accuracy = 0.731875
I0725 22:59:13.036700 22939 solver.cpp:404]     Test net output #1: loss = 0.63984 (* 1 = 0.63984 loss)
I0725 22:59:13.069481 22939 solver.cpp:228] Iteration 41500, loss = 0.634397
I0725 22:59:13.069499 22939 solver.cpp:244]     Train net output #0: loss = 0.634397 (* 1 = 0.634397 loss)
I0725 22:59:13.069506 22939 sgd_solver.cpp:106] Iteration 41500, lr = 4.30642e-06
I0725 22:59:22.471997 22939 solver.cpp:228] Iteration 41600, loss = 0.66106
I0725 22:59:22.472048 22939 solver.cpp:244]     Train net output #0: loss = 0.66106 (* 1 = 0.66106 loss)
I0725 22:59:22.472054 22939 sgd_solver.cpp:106] Iteration 41600, lr = 4.30117e-06
I0725 22:59:31.872277 22939 solver.cpp:228] Iteration 41700, loss = 0.673795
I0725 22:59:31.872326 22939 solver.cpp:244]     Train net output #0: loss = 0.673795 (* 1 = 0.673795 loss)
I0725 22:59:31.872333 22939 sgd_solver.cpp:106] Iteration 41700, lr = 4.29594e-06
I0725 22:59:41.273866 22939 solver.cpp:228] Iteration 41800, loss = 0.580923
I0725 22:59:41.273910 22939 solver.cpp:244]     Train net output #0: loss = 0.580923 (* 1 = 0.580923 loss)
I0725 22:59:41.273916 22939 sgd_solver.cpp:106] Iteration 41800, lr = 4.29073e-06
I0725 22:59:50.676687 22939 solver.cpp:228] Iteration 41900, loss = 0.57535
I0725 22:59:50.676740 22939 solver.cpp:244]     Train net output #0: loss = 0.57535 (* 1 = 0.57535 loss)
I0725 22:59:50.676746 22939 sgd_solver.cpp:106] Iteration 41900, lr = 4.28553e-06
I0725 22:59:59.982118 22939 solver.cpp:337] Iteration 42000, Testing net (#0)
I0725 23:00:10.882153 22939 solver.cpp:404]     Test net output #0: accuracy = 0.733458
I0725 23:00:10.882194 22939 solver.cpp:404]     Test net output #1: loss = 0.636399 (* 1 = 0.636399 loss)
I0725 23:00:10.909284 22939 solver.cpp:228] Iteration 42000, loss = 0.447757
I0725 23:00:10.909323 22939 solver.cpp:244]     Train net output #0: loss = 0.447757 (* 1 = 0.447757 loss)
I0725 23:00:10.909334 22939 sgd_solver.cpp:106] Iteration 42000, lr = 4.28034e-06
I0725 23:00:20.303578 22939 solver.cpp:228] Iteration 42100, loss = 0.552385
I0725 23:00:20.303634 22939 solver.cpp:244]     Train net output #0: loss = 0.552385 (* 1 = 0.552385 loss)
I0725 23:00:20.303642 22939 sgd_solver.cpp:106] Iteration 42100, lr = 4.27517e-06
I0725 23:00:29.700937 22939 solver.cpp:228] Iteration 42200, loss = 0.477108
I0725 23:00:29.700978 22939 solver.cpp:244]     Train net output #0: loss = 0.477108 (* 1 = 0.477108 loss)
I0725 23:00:29.700984 22939 sgd_solver.cpp:106] Iteration 42200, lr = 4.27002e-06
I0725 23:00:39.098551 22939 solver.cpp:228] Iteration 42300, loss = 0.613366
I0725 23:00:39.098593 22939 solver.cpp:244]     Train net output #0: loss = 0.613366 (* 1 = 0.613366 loss)
I0725 23:00:39.098599 22939 sgd_solver.cpp:106] Iteration 42300, lr = 4.26488e-06
I0725 23:00:48.499255 22939 solver.cpp:228] Iteration 42400, loss = 0.573772
I0725 23:00:48.499292 22939 solver.cpp:244]     Train net output #0: loss = 0.573772 (* 1 = 0.573772 loss)
I0725 23:00:48.499300 22939 sgd_solver.cpp:106] Iteration 42400, lr = 4.25975e-06
I0725 23:00:57.803521 22939 solver.cpp:337] Iteration 42500, Testing net (#0)
I0725 23:01:08.773540 22939 solver.cpp:404]     Test net output #0: accuracy = 0.733583
I0725 23:01:08.773581 22939 solver.cpp:404]     Test net output #1: loss = 0.638885 (* 1 = 0.638885 loss)
I0725 23:01:08.803186 22939 solver.cpp:228] Iteration 42500, loss = 0.582815
I0725 23:01:08.803222 22939 solver.cpp:244]     Train net output #0: loss = 0.582815 (* 1 = 0.582815 loss)
I0725 23:01:08.803233 22939 sgd_solver.cpp:106] Iteration 42500, lr = 4.25464e-06
I0725 23:01:18.196228 22939 solver.cpp:228] Iteration 42600, loss = 0.492871
I0725 23:01:18.196283 22939 solver.cpp:244]     Train net output #0: loss = 0.492871 (* 1 = 0.492871 loss)
I0725 23:01:18.196290 22939 sgd_solver.cpp:106] Iteration 42600, lr = 4.24954e-06
I0725 23:01:27.584475 22939 solver.cpp:228] Iteration 42700, loss = 0.486549
I0725 23:01:27.584520 22939 solver.cpp:244]     Train net output #0: loss = 0.486549 (* 1 = 0.486549 loss)
I0725 23:01:27.584527 22939 sgd_solver.cpp:106] Iteration 42700, lr = 4.24445e-06
I0725 23:01:36.974802 22939 solver.cpp:228] Iteration 42800, loss = 0.594084
I0725 23:01:36.974849 22939 solver.cpp:244]     Train net output #0: loss = 0.594084 (* 1 = 0.594084 loss)
I0725 23:01:36.974855 22939 sgd_solver.cpp:106] Iteration 42800, lr = 4.23938e-06
I0725 23:01:46.369308 22939 solver.cpp:228] Iteration 42900, loss = 0.603047
I0725 23:01:46.369364 22939 solver.cpp:244]     Train net output #0: loss = 0.603047 (* 1 = 0.603047 loss)
I0725 23:01:46.369369 22939 sgd_solver.cpp:106] Iteration 42900, lr = 4.23433e-06
I0725 23:01:55.671013 22939 solver.cpp:337] Iteration 43000, Testing net (#0)
I0725 23:02:06.422271 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:02:06.598368 22939 solver.cpp:404]     Test net output #0: accuracy = 0.734542
I0725 23:02:06.598395 22939 solver.cpp:404]     Test net output #1: loss = 0.634365 (* 1 = 0.634365 loss)
I0725 23:02:06.630882 22939 solver.cpp:228] Iteration 43000, loss = 0.493561
I0725 23:02:06.630946 22939 solver.cpp:244]     Train net output #0: loss = 0.493561 (* 1 = 0.493561 loss)
I0725 23:02:06.630965 22939 sgd_solver.cpp:106] Iteration 43000, lr = 4.22929e-06
I0725 23:02:16.004153 22939 solver.cpp:228] Iteration 43100, loss = 0.567907
I0725 23:02:16.004199 22939 solver.cpp:244]     Train net output #0: loss = 0.567907 (* 1 = 0.567907 loss)
I0725 23:02:16.004204 22939 sgd_solver.cpp:106] Iteration 43100, lr = 4.22426e-06
I0725 23:02:25.406571 22939 solver.cpp:228] Iteration 43200, loss = 0.635319
I0725 23:02:25.406612 22939 solver.cpp:244]     Train net output #0: loss = 0.635319 (* 1 = 0.635319 loss)
I0725 23:02:25.406618 22939 sgd_solver.cpp:106] Iteration 43200, lr = 4.21924e-06
I0725 23:02:34.809604 22939 solver.cpp:228] Iteration 43300, loss = 0.633344
I0725 23:02:34.809656 22939 solver.cpp:244]     Train net output #0: loss = 0.633344 (* 1 = 0.633344 loss)
I0725 23:02:34.809662 22939 sgd_solver.cpp:106] Iteration 43300, lr = 4.21424e-06
I0725 23:02:44.206424 22939 solver.cpp:228] Iteration 43400, loss = 0.565983
I0725 23:02:44.206485 22939 solver.cpp:244]     Train net output #0: loss = 0.565983 (* 1 = 0.565983 loss)
I0725 23:02:44.206490 22939 sgd_solver.cpp:106] Iteration 43400, lr = 4.20926e-06
I0725 23:02:53.512425 22939 solver.cpp:337] Iteration 43500, Testing net (#0)
I0725 23:03:04.408913 22939 solver.cpp:404]     Test net output #0: accuracy = 0.732333
I0725 23:03:04.408960 22939 solver.cpp:404]     Test net output #1: loss = 0.641186 (* 1 = 0.641186 loss)
I0725 23:03:04.442034 22939 solver.cpp:228] Iteration 43500, loss = 0.52958
I0725 23:03:04.442088 22939 solver.cpp:244]     Train net output #0: loss = 0.52958 (* 1 = 0.52958 loss)
I0725 23:03:04.442111 22939 sgd_solver.cpp:106] Iteration 43500, lr = 4.20429e-06
I0725 23:03:13.784781 22939 solver.cpp:228] Iteration 43600, loss = 0.681565
I0725 23:03:13.784832 22939 solver.cpp:244]     Train net output #0: loss = 0.681565 (* 1 = 0.681565 loss)
I0725 23:03:13.784838 22939 sgd_solver.cpp:106] Iteration 43600, lr = 4.19933e-06
I0725 23:03:23.173272 22939 solver.cpp:228] Iteration 43700, loss = 0.565894
I0725 23:03:23.173321 22939 solver.cpp:244]     Train net output #0: loss = 0.565894 (* 1 = 0.565894 loss)
I0725 23:03:23.173326 22939 sgd_solver.cpp:106] Iteration 43700, lr = 4.19438e-06
I0725 23:03:32.569454 22939 solver.cpp:228] Iteration 43800, loss = 0.56994
I0725 23:03:32.569501 22939 solver.cpp:244]     Train net output #0: loss = 0.56994 (* 1 = 0.56994 loss)
I0725 23:03:32.569507 22939 sgd_solver.cpp:106] Iteration 43800, lr = 4.18945e-06
I0725 23:03:41.999369 22939 solver.cpp:228] Iteration 43900, loss = 0.590454
I0725 23:03:41.999415 22939 solver.cpp:244]     Train net output #0: loss = 0.590454 (* 1 = 0.590454 loss)
I0725 23:03:41.999423 22939 sgd_solver.cpp:106] Iteration 43900, lr = 4.18453e-06
I0725 23:03:51.461807 22939 solver.cpp:337] Iteration 44000, Testing net (#0)
I0725 23:04:02.349936 22939 solver.cpp:404]     Test net output #0: accuracy = 0.734375
I0725 23:04:02.349988 22939 solver.cpp:404]     Test net output #1: loss = 0.636405 (* 1 = 0.636405 loss)
I0725 23:04:02.382509 22939 solver.cpp:228] Iteration 44000, loss = 0.620692
I0725 23:04:02.382530 22939 solver.cpp:244]     Train net output #0: loss = 0.620692 (* 1 = 0.620692 loss)
I0725 23:04:02.382541 22939 sgd_solver.cpp:106] Iteration 44000, lr = 4.17963e-06
I0725 23:04:11.744956 22939 solver.cpp:228] Iteration 44100, loss = 0.582399
I0725 23:04:11.745005 22939 solver.cpp:244]     Train net output #0: loss = 0.582399 (* 1 = 0.582399 loss)
I0725 23:04:11.745012 22939 sgd_solver.cpp:106] Iteration 44100, lr = 4.17474e-06
I0725 23:04:21.138212 22939 solver.cpp:228] Iteration 44200, loss = 0.52418
I0725 23:04:21.138254 22939 solver.cpp:244]     Train net output #0: loss = 0.52418 (* 1 = 0.52418 loss)
I0725 23:04:21.138260 22939 sgd_solver.cpp:106] Iteration 44200, lr = 4.16986e-06
I0725 23:04:30.528614 22939 solver.cpp:228] Iteration 44300, loss = 0.632822
I0725 23:04:30.528666 22939 solver.cpp:244]     Train net output #0: loss = 0.632822 (* 1 = 0.632822 loss)
I0725 23:04:30.528672 22939 sgd_solver.cpp:106] Iteration 44300, lr = 4.16499e-06
I0725 23:04:39.917111 22939 solver.cpp:228] Iteration 44400, loss = 0.470708
I0725 23:04:39.917152 22939 solver.cpp:244]     Train net output #0: loss = 0.470708 (* 1 = 0.470708 loss)
I0725 23:04:39.917158 22939 sgd_solver.cpp:106] Iteration 44400, lr = 4.16014e-06
I0725 23:04:49.212784 22939 solver.cpp:337] Iteration 44500, Testing net (#0)
I0725 23:05:00.108837 22939 solver.cpp:404]     Test net output #0: accuracy = 0.731792
I0725 23:05:00.108886 22939 solver.cpp:404]     Test net output #1: loss = 0.641421 (* 1 = 0.641421 loss)
I0725 23:05:00.138588 22939 solver.cpp:228] Iteration 44500, loss = 0.593343
I0725 23:05:00.138635 22939 solver.cpp:244]     Train net output #0: loss = 0.593343 (* 1 = 0.593343 loss)
I0725 23:05:00.138655 22939 sgd_solver.cpp:106] Iteration 44500, lr = 4.1553e-06
I0725 23:05:09.478332 22939 solver.cpp:228] Iteration 44600, loss = 0.545184
I0725 23:05:09.478374 22939 solver.cpp:244]     Train net output #0: loss = 0.545184 (* 1 = 0.545184 loss)
I0725 23:05:09.478379 22939 sgd_solver.cpp:106] Iteration 44600, lr = 4.15048e-06
I0725 23:05:18.877320 22939 solver.cpp:228] Iteration 44700, loss = 0.741135
I0725 23:05:18.877359 22939 solver.cpp:244]     Train net output #0: loss = 0.741135 (* 1 = 0.741135 loss)
I0725 23:05:18.877365 22939 sgd_solver.cpp:106] Iteration 44700, lr = 4.14567e-06
I0725 23:05:28.272820 22939 solver.cpp:228] Iteration 44800, loss = 0.511394
I0725 23:05:28.272867 22939 solver.cpp:244]     Train net output #0: loss = 0.511394 (* 1 = 0.511394 loss)
I0725 23:05:28.272874 22939 sgd_solver.cpp:106] Iteration 44800, lr = 4.14087e-06
I0725 23:05:37.674243 22939 solver.cpp:228] Iteration 44900, loss = 0.567551
I0725 23:05:37.674288 22939 solver.cpp:244]     Train net output #0: loss = 0.567551 (* 1 = 0.567551 loss)
I0725 23:05:37.674293 22939 sgd_solver.cpp:106] Iteration 44900, lr = 4.13608e-06
I0725 23:05:46.972705 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_45000.caffemodel
I0725 23:05:47.314869 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_45000.solverstate
I0725 23:05:47.422397 22939 solver.cpp:337] Iteration 45000, Testing net (#0)
I0725 23:05:58.104522 22939 solver.cpp:404]     Test net output #0: accuracy = 0.733625
I0725 23:05:58.104564 22939 solver.cpp:404]     Test net output #1: loss = 0.640122 (* 1 = 0.640122 loss)
I0725 23:05:58.131640 22939 solver.cpp:228] Iteration 45000, loss = 0.59909
I0725 23:05:58.131681 22939 solver.cpp:244]     Train net output #0: loss = 0.59909 (* 1 = 0.59909 loss)
I0725 23:05:58.131700 22939 sgd_solver.cpp:106] Iteration 45000, lr = 4.13131e-06
I0725 23:06:07.504166 22939 solver.cpp:228] Iteration 45100, loss = 0.532306
I0725 23:06:07.504209 22939 solver.cpp:244]     Train net output #0: loss = 0.532306 (* 1 = 0.532306 loss)
I0725 23:06:07.504216 22939 sgd_solver.cpp:106] Iteration 45100, lr = 4.12655e-06
I0725 23:06:12.481130 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:06:16.894497 22939 solver.cpp:228] Iteration 45200, loss = 0.696696
I0725 23:06:16.894546 22939 solver.cpp:244]     Train net output #0: loss = 0.696696 (* 1 = 0.696696 loss)
I0725 23:06:16.894552 22939 sgd_solver.cpp:106] Iteration 45200, lr = 4.1218e-06
I0725 23:06:26.348254 22939 solver.cpp:228] Iteration 45300, loss = 0.520697
I0725 23:06:26.348315 22939 solver.cpp:244]     Train net output #0: loss = 0.520697 (* 1 = 0.520697 loss)
I0725 23:06:26.348322 22939 sgd_solver.cpp:106] Iteration 45300, lr = 4.11706e-06
I0725 23:06:35.902423 22939 solver.cpp:228] Iteration 45400, loss = 0.505461
I0725 23:06:35.902467 22939 solver.cpp:244]     Train net output #0: loss = 0.505461 (* 1 = 0.505461 loss)
I0725 23:06:35.902473 22939 sgd_solver.cpp:106] Iteration 45400, lr = 4.11234e-06
I0725 23:06:45.198108 22939 solver.cpp:337] Iteration 45500, Testing net (#0)
I0725 23:06:56.114104 22939 solver.cpp:404]     Test net output #0: accuracy = 0.732416
I0725 23:06:56.114145 22939 solver.cpp:404]     Test net output #1: loss = 0.639517 (* 1 = 0.639517 loss)
I0725 23:06:56.143595 22939 solver.cpp:228] Iteration 45500, loss = 0.612574
I0725 23:06:56.143649 22939 solver.cpp:244]     Train net output #0: loss = 0.612574 (* 1 = 0.612574 loss)
I0725 23:06:56.143667 22939 sgd_solver.cpp:106] Iteration 45500, lr = 4.10763e-06
I0725 23:07:05.477337 22939 solver.cpp:228] Iteration 45600, loss = 0.68619
I0725 23:07:05.477380 22939 solver.cpp:244]     Train net output #0: loss = 0.68619 (* 1 = 0.68619 loss)
I0725 23:07:05.477385 22939 sgd_solver.cpp:106] Iteration 45600, lr = 4.10293e-06
I0725 23:07:14.866642 22939 solver.cpp:228] Iteration 45700, loss = 0.581153
I0725 23:07:14.866685 22939 solver.cpp:244]     Train net output #0: loss = 0.581153 (* 1 = 0.581153 loss)
I0725 23:07:14.866691 22939 sgd_solver.cpp:106] Iteration 45700, lr = 4.09825e-06
I0725 23:07:24.256572 22939 solver.cpp:228] Iteration 45800, loss = 0.50952
I0725 23:07:24.256613 22939 solver.cpp:244]     Train net output #0: loss = 0.50952 (* 1 = 0.50952 loss)
I0725 23:07:24.256619 22939 sgd_solver.cpp:106] Iteration 45800, lr = 4.09358e-06
I0725 23:07:33.644001 22939 solver.cpp:228] Iteration 45900, loss = 0.604523
I0725 23:07:33.644037 22939 solver.cpp:244]     Train net output #0: loss = 0.604523 (* 1 = 0.604523 loss)
I0725 23:07:33.644043 22939 sgd_solver.cpp:106] Iteration 45900, lr = 4.08892e-06
I0725 23:07:42.939352 22939 solver.cpp:337] Iteration 46000, Testing net (#0)
I0725 23:07:53.810919 22939 solver.cpp:404]     Test net output #0: accuracy = 0.734125
I0725 23:07:53.810976 22939 solver.cpp:404]     Test net output #1: loss = 0.64009 (* 1 = 0.64009 loss)
I0725 23:07:53.844091 22939 solver.cpp:228] Iteration 46000, loss = 0.570782
I0725 23:07:53.844151 22939 solver.cpp:244]     Train net output #0: loss = 0.570782 (* 1 = 0.570782 loss)
I0725 23:07:53.844168 22939 sgd_solver.cpp:106] Iteration 46000, lr = 4.08427e-06
I0725 23:08:03.218804 22939 solver.cpp:228] Iteration 46100, loss = 0.553801
I0725 23:08:03.218845 22939 solver.cpp:244]     Train net output #0: loss = 0.553801 (* 1 = 0.553801 loss)
I0725 23:08:03.218852 22939 sgd_solver.cpp:106] Iteration 46100, lr = 4.07964e-06
I0725 23:08:12.621927 22939 solver.cpp:228] Iteration 46200, loss = 0.531282
I0725 23:08:12.621970 22939 solver.cpp:244]     Train net output #0: loss = 0.531282 (* 1 = 0.531282 loss)
I0725 23:08:12.621976 22939 sgd_solver.cpp:106] Iteration 46200, lr = 4.07501e-06
I0725 23:08:22.023195 22939 solver.cpp:228] Iteration 46300, loss = 0.573839
I0725 23:08:22.023239 22939 solver.cpp:244]     Train net output #0: loss = 0.573839 (* 1 = 0.573839 loss)
I0725 23:08:22.023246 22939 sgd_solver.cpp:106] Iteration 46300, lr = 4.0704e-06
I0725 23:08:31.424304 22939 solver.cpp:228] Iteration 46400, loss = 0.685539
I0725 23:08:31.424355 22939 solver.cpp:244]     Train net output #0: loss = 0.685539 (* 1 = 0.685539 loss)
I0725 23:08:31.424360 22939 sgd_solver.cpp:106] Iteration 46400, lr = 4.0658e-06
I0725 23:08:40.725314 22939 solver.cpp:337] Iteration 46500, Testing net (#0)
I0725 23:08:51.572777 22939 solver.cpp:404]     Test net output #0: accuracy = 0.734167
I0725 23:08:51.572814 22939 solver.cpp:404]     Test net output #1: loss = 0.638231 (* 1 = 0.638231 loss)
I0725 23:08:51.605621 22939 solver.cpp:228] Iteration 46500, loss = 0.466754
I0725 23:08:51.605689 22939 solver.cpp:244]     Train net output #0: loss = 0.466754 (* 1 = 0.466754 loss)
I0725 23:08:51.605707 22939 sgd_solver.cpp:106] Iteration 46500, lr = 4.06122e-06
I0725 23:09:00.995093 22939 solver.cpp:228] Iteration 46600, loss = 0.628623
I0725 23:09:00.995134 22939 solver.cpp:244]     Train net output #0: loss = 0.628623 (* 1 = 0.628623 loss)
I0725 23:09:00.995141 22939 sgd_solver.cpp:106] Iteration 46600, lr = 4.05664e-06
I0725 23:09:10.461766 22939 solver.cpp:228] Iteration 46700, loss = 0.565387
I0725 23:09:10.461814 22939 solver.cpp:244]     Train net output #0: loss = 0.565387 (* 1 = 0.565387 loss)
I0725 23:09:10.461822 22939 sgd_solver.cpp:106] Iteration 46700, lr = 4.05208e-06
I0725 23:09:19.988629 22939 solver.cpp:228] Iteration 46800, loss = 0.680279
I0725 23:09:19.988677 22939 solver.cpp:244]     Train net output #0: loss = 0.680279 (* 1 = 0.680279 loss)
I0725 23:09:19.988683 22939 sgd_solver.cpp:106] Iteration 46800, lr = 4.04753e-06
I0725 23:09:29.382530 22939 solver.cpp:228] Iteration 46900, loss = 0.436128
I0725 23:09:29.382585 22939 solver.cpp:244]     Train net output #0: loss = 0.436128 (* 1 = 0.436128 loss)
I0725 23:09:29.382591 22939 sgd_solver.cpp:106] Iteration 46900, lr = 4.04299e-06
I0725 23:09:38.686108 22939 solver.cpp:337] Iteration 47000, Testing net (#0)
I0725 23:09:49.536773 22939 solver.cpp:404]     Test net output #0: accuracy = 0.735458
I0725 23:09:49.536828 22939 solver.cpp:404]     Test net output #1: loss = 0.636476 (* 1 = 0.636476 loss)
I0725 23:09:49.566247 22939 solver.cpp:228] Iteration 47000, loss = 0.561447
I0725 23:09:49.566277 22939 solver.cpp:244]     Train net output #0: loss = 0.561447 (* 1 = 0.561447 loss)
I0725 23:09:49.566298 22939 sgd_solver.cpp:106] Iteration 47000, lr = 4.03847e-06
I0725 23:09:58.889789 22939 solver.cpp:228] Iteration 47100, loss = 0.729123
I0725 23:09:58.889840 22939 solver.cpp:244]     Train net output #0: loss = 0.729123 (* 1 = 0.729123 loss)
I0725 23:09:58.889849 22939 sgd_solver.cpp:106] Iteration 47100, lr = 4.03395e-06
I0725 23:10:00.487988 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:10:08.351800 22939 solver.cpp:228] Iteration 47200, loss = 0.535405
I0725 23:10:08.351847 22939 solver.cpp:244]     Train net output #0: loss = 0.535405 (* 1 = 0.535405 loss)
I0725 23:10:08.351853 22939 sgd_solver.cpp:106] Iteration 47200, lr = 4.02945e-06
I0725 23:10:17.911223 22939 solver.cpp:228] Iteration 47300, loss = 0.461999
I0725 23:10:17.911278 22939 solver.cpp:244]     Train net output #0: loss = 0.461999 (* 1 = 0.461999 loss)
I0725 23:10:17.911284 22939 sgd_solver.cpp:106] Iteration 47300, lr = 4.02496e-06
I0725 23:10:27.336892 22939 solver.cpp:228] Iteration 47400, loss = 0.559431
I0725 23:10:27.336935 22939 solver.cpp:244]     Train net output #0: loss = 0.559431 (* 1 = 0.559431 loss)
I0725 23:10:27.336941 22939 sgd_solver.cpp:106] Iteration 47400, lr = 4.02048e-06
I0725 23:10:36.639358 22939 solver.cpp:337] Iteration 47500, Testing net (#0)
I0725 23:10:47.436997 22939 solver.cpp:404]     Test net output #0: accuracy = 0.732584
I0725 23:10:47.437038 22939 solver.cpp:404]     Test net output #1: loss = 0.640789 (* 1 = 0.640789 loss)
I0725 23:10:47.469990 22939 solver.cpp:228] Iteration 47500, loss = 0.544741
I0725 23:10:47.470054 22939 solver.cpp:244]     Train net output #0: loss = 0.544741 (* 1 = 0.544741 loss)
I0725 23:10:47.470074 22939 sgd_solver.cpp:106] Iteration 47500, lr = 4.01601e-06
I0725 23:10:56.847826 22939 solver.cpp:228] Iteration 47600, loss = 0.573994
I0725 23:10:56.847872 22939 solver.cpp:244]     Train net output #0: loss = 0.573994 (* 1 = 0.573994 loss)
I0725 23:10:56.847878 22939 sgd_solver.cpp:106] Iteration 47600, lr = 4.01155e-06
I0725 23:11:06.378347 22939 solver.cpp:228] Iteration 47700, loss = 0.508442
I0725 23:11:06.378399 22939 solver.cpp:244]     Train net output #0: loss = 0.508442 (* 1 = 0.508442 loss)
I0725 23:11:06.378406 22939 sgd_solver.cpp:106] Iteration 47700, lr = 4.00711e-06
I0725 23:11:15.868211 22939 solver.cpp:228] Iteration 47800, loss = 0.48768
I0725 23:11:15.868250 22939 solver.cpp:244]     Train net output #0: loss = 0.48768 (* 1 = 0.48768 loss)
I0725 23:11:15.868257 22939 sgd_solver.cpp:106] Iteration 47800, lr = 4.00267e-06
I0725 23:11:25.272590 22939 solver.cpp:228] Iteration 47900, loss = 0.537847
I0725 23:11:25.272629 22939 solver.cpp:244]     Train net output #0: loss = 0.537847 (* 1 = 0.537847 loss)
I0725 23:11:25.272634 22939 sgd_solver.cpp:106] Iteration 47900, lr = 3.99825e-06
I0725 23:11:34.577942 22939 solver.cpp:337] Iteration 48000, Testing net (#0)
I0725 23:11:45.429826 22939 solver.cpp:404]     Test net output #0: accuracy = 0.736291
I0725 23:11:45.429872 22939 solver.cpp:404]     Test net output #1: loss = 0.63368 (* 1 = 0.63368 loss)
I0725 23:11:45.459456 22939 solver.cpp:228] Iteration 48000, loss = 0.568827
I0725 23:11:45.459486 22939 solver.cpp:244]     Train net output #0: loss = 0.568827 (* 1 = 0.568827 loss)
I0725 23:11:45.459497 22939 sgd_solver.cpp:106] Iteration 48000, lr = 3.99384e-06
I0725 23:11:54.851701 22939 solver.cpp:228] Iteration 48100, loss = 0.539759
I0725 23:11:54.851745 22939 solver.cpp:244]     Train net output #0: loss = 0.539759 (* 1 = 0.539759 loss)
I0725 23:11:54.851752 22939 sgd_solver.cpp:106] Iteration 48100, lr = 3.98944e-06
I0725 23:12:04.248728 22939 solver.cpp:228] Iteration 48200, loss = 0.417064
I0725 23:12:04.248778 22939 solver.cpp:244]     Train net output #0: loss = 0.417064 (* 1 = 0.417064 loss)
I0725 23:12:04.248785 22939 sgd_solver.cpp:106] Iteration 48200, lr = 3.98505e-06
I0725 23:12:13.640768 22939 solver.cpp:228] Iteration 48300, loss = 0.500151
I0725 23:12:13.640808 22939 solver.cpp:244]     Train net output #0: loss = 0.500151 (* 1 = 0.500151 loss)
I0725 23:12:13.640815 22939 sgd_solver.cpp:106] Iteration 48300, lr = 3.98068e-06
I0725 23:12:23.036171 22939 solver.cpp:228] Iteration 48400, loss = 0.594537
I0725 23:12:23.036211 22939 solver.cpp:244]     Train net output #0: loss = 0.594537 (* 1 = 0.594537 loss)
I0725 23:12:23.036217 22939 sgd_solver.cpp:106] Iteration 48400, lr = 3.97631e-06
I0725 23:12:32.340500 22939 solver.cpp:337] Iteration 48500, Testing net (#0)
I0725 23:12:43.192791 22939 solver.cpp:404]     Test net output #0: accuracy = 0.733625
I0725 23:12:43.192847 22939 solver.cpp:404]     Test net output #1: loss = 0.638367 (* 1 = 0.638367 loss)
I0725 23:12:43.222741 22939 solver.cpp:228] Iteration 48500, loss = 0.519289
I0725 23:12:43.222772 22939 solver.cpp:244]     Train net output #0: loss = 0.519289 (* 1 = 0.519289 loss)
I0725 23:12:43.222784 22939 sgd_solver.cpp:106] Iteration 48500, lr = 3.97196e-06
I0725 23:12:52.581002 22939 solver.cpp:228] Iteration 48600, loss = 0.544621
I0725 23:12:52.581043 22939 solver.cpp:244]     Train net output #0: loss = 0.544621 (* 1 = 0.544621 loss)
I0725 23:12:52.581049 22939 sgd_solver.cpp:106] Iteration 48600, lr = 3.96761e-06
I0725 23:13:02.135601 22939 solver.cpp:228] Iteration 48700, loss = 0.526661
I0725 23:13:02.135643 22939 solver.cpp:244]     Train net output #0: loss = 0.526661 (* 1 = 0.526661 loss)
I0725 23:13:02.135650 22939 sgd_solver.cpp:106] Iteration 48700, lr = 3.96328e-06
I0725 23:13:11.688607 22939 solver.cpp:228] Iteration 48800, loss = 0.462607
I0725 23:13:11.688649 22939 solver.cpp:244]     Train net output #0: loss = 0.462607 (* 1 = 0.462607 loss)
I0725 23:13:11.688655 22939 sgd_solver.cpp:106] Iteration 48800, lr = 3.95896e-06
I0725 23:13:21.086477 22939 solver.cpp:228] Iteration 48900, loss = 0.669166
I0725 23:13:21.086521 22939 solver.cpp:244]     Train net output #0: loss = 0.669166 (* 1 = 0.669166 loss)
I0725 23:13:21.086527 22939 sgd_solver.cpp:106] Iteration 48900, lr = 3.95465e-06
I0725 23:13:30.386970 22939 solver.cpp:337] Iteration 49000, Testing net (#0)
I0725 23:13:41.296908 22939 solver.cpp:404]     Test net output #0: accuracy = 0.736875
I0725 23:13:41.296950 22939 solver.cpp:404]     Test net output #1: loss = 0.631465 (* 1 = 0.631465 loss)
I0725 23:13:41.326153 22939 solver.cpp:228] Iteration 49000, loss = 0.632525
I0725 23:13:41.326170 22939 solver.cpp:244]     Train net output #0: loss = 0.632525 (* 1 = 0.632525 loss)
I0725 23:13:41.326179 22939 sgd_solver.cpp:106] Iteration 49000, lr = 3.95035e-06
I0725 23:13:50.656350 22939 solver.cpp:228] Iteration 49100, loss = 0.444178
I0725 23:13:50.656401 22939 solver.cpp:244]     Train net output #0: loss = 0.444178 (* 1 = 0.444178 loss)
I0725 23:13:50.656407 22939 sgd_solver.cpp:106] Iteration 49100, lr = 3.94606e-06
I0725 23:14:00.053050 22939 solver.cpp:228] Iteration 49200, loss = 0.549817
I0725 23:14:00.053088 22939 solver.cpp:244]     Train net output #0: loss = 0.549817 (* 1 = 0.549817 loss)
I0725 23:14:00.053095 22939 sgd_solver.cpp:106] Iteration 49200, lr = 3.94178e-06
I0725 23:14:09.452639 22939 solver.cpp:228] Iteration 49300, loss = 0.605271
I0725 23:14:09.452687 22939 solver.cpp:244]     Train net output #0: loss = 0.605271 (* 1 = 0.605271 loss)
I0725 23:14:09.452693 22939 sgd_solver.cpp:106] Iteration 49300, lr = 3.93752e-06
I0725 23:14:18.948971 22939 solver.cpp:228] Iteration 49400, loss = 0.609852
I0725 23:14:18.949009 22939 solver.cpp:244]     Train net output #0: loss = 0.609852 (* 1 = 0.609852 loss)
I0725 23:14:18.949015 22939 sgd_solver.cpp:106] Iteration 49400, lr = 3.93326e-06
I0725 23:14:28.412279 22939 solver.cpp:337] Iteration 49500, Testing net (#0)
I0725 23:14:29.384449 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:14:39.294747 22939 solver.cpp:404]     Test net output #0: accuracy = 0.734417
I0725 23:14:39.294797 22939 solver.cpp:404]     Test net output #1: loss = 0.635645 (* 1 = 0.635645 loss)
I0725 23:14:39.321575 22939 solver.cpp:228] Iteration 49500, loss = 0.711989
I0725 23:14:39.321599 22939 solver.cpp:244]     Train net output #0: loss = 0.711989 (* 1 = 0.711989 loss)
I0725 23:14:39.321609 22939 sgd_solver.cpp:106] Iteration 49500, lr = 3.92902e-06
I0725 23:14:48.632735 22939 solver.cpp:228] Iteration 49600, loss = 0.490776
I0725 23:14:48.632776 22939 solver.cpp:244]     Train net output #0: loss = 0.490776 (* 1 = 0.490776 loss)
I0725 23:14:48.632781 22939 sgd_solver.cpp:106] Iteration 49600, lr = 3.92478e-06
I0725 23:14:58.009361 22939 solver.cpp:228] Iteration 49700, loss = 0.509998
I0725 23:14:58.009404 22939 solver.cpp:244]     Train net output #0: loss = 0.509998 (* 1 = 0.509998 loss)
I0725 23:14:58.009410 22939 sgd_solver.cpp:106] Iteration 49700, lr = 3.92056e-06
I0725 23:15:07.500813 22939 solver.cpp:228] Iteration 49800, loss = 0.467994
I0725 23:15:07.500854 22939 solver.cpp:244]     Train net output #0: loss = 0.467994 (* 1 = 0.467994 loss)
I0725 23:15:07.500859 22939 sgd_solver.cpp:106] Iteration 49800, lr = 3.91634e-06
I0725 23:15:17.050179 22939 solver.cpp:228] Iteration 49900, loss = 0.70445
I0725 23:15:17.050209 22939 solver.cpp:244]     Train net output #0: loss = 0.70445 (* 1 = 0.70445 loss)
I0725 23:15:17.050215 22939 sgd_solver.cpp:106] Iteration 49900, lr = 3.91214e-06
I0725 23:15:26.380630 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_50000.caffemodel
I0725 23:15:26.729321 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_50000.solverstate
I0725 23:15:26.837467 22939 solver.cpp:337] Iteration 50000, Testing net (#0)
I0725 23:15:37.514060 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7365
I0725 23:15:37.514114 22939 solver.cpp:404]     Test net output #1: loss = 0.63133 (* 1 = 0.63133 loss)
I0725 23:15:37.540776 22939 solver.cpp:228] Iteration 50000, loss = 0.522277
I0725 23:15:37.540829 22939 solver.cpp:244]     Train net output #0: loss = 0.522277 (* 1 = 0.522277 loss)
I0725 23:15:37.540839 22939 sgd_solver.cpp:106] Iteration 50000, lr = 3.90795e-06
I0725 23:15:46.984807 22939 solver.cpp:228] Iteration 50100, loss = 0.550516
I0725 23:15:46.984848 22939 solver.cpp:244]     Train net output #0: loss = 0.550516 (* 1 = 0.550516 loss)
I0725 23:15:46.984854 22939 sgd_solver.cpp:106] Iteration 50100, lr = 3.90377e-06
I0725 23:15:56.535682 22939 solver.cpp:228] Iteration 50200, loss = 0.482781
I0725 23:15:56.535737 22939 solver.cpp:244]     Train net output #0: loss = 0.482781 (* 1 = 0.482781 loss)
I0725 23:15:56.535743 22939 sgd_solver.cpp:106] Iteration 50200, lr = 3.8996e-06
I0725 23:16:06.004472 22939 solver.cpp:228] Iteration 50300, loss = 0.508602
I0725 23:16:06.004514 22939 solver.cpp:244]     Train net output #0: loss = 0.508602 (* 1 = 0.508602 loss)
I0725 23:16:06.004520 22939 sgd_solver.cpp:106] Iteration 50300, lr = 3.89544e-06
I0725 23:16:15.399355 22939 solver.cpp:228] Iteration 50400, loss = 0.609773
I0725 23:16:15.399399 22939 solver.cpp:244]     Train net output #0: loss = 0.609773 (* 1 = 0.609773 loss)
I0725 23:16:15.399412 22939 sgd_solver.cpp:106] Iteration 50400, lr = 3.89128e-06
I0725 23:16:24.694358 22939 solver.cpp:337] Iteration 50500, Testing net (#0)
I0725 23:16:35.545850 22939 solver.cpp:404]     Test net output #0: accuracy = 0.73625
I0725 23:16:35.545894 22939 solver.cpp:404]     Test net output #1: loss = 0.632969 (* 1 = 0.632969 loss)
I0725 23:16:35.572866 22939 solver.cpp:228] Iteration 50500, loss = 0.564467
I0725 23:16:35.572896 22939 solver.cpp:244]     Train net output #0: loss = 0.564467 (* 1 = 0.564467 loss)
I0725 23:16:35.572906 22939 sgd_solver.cpp:106] Iteration 50500, lr = 3.88714e-06
I0725 23:16:44.970537 22939 solver.cpp:228] Iteration 50600, loss = 0.614882
I0725 23:16:44.970579 22939 solver.cpp:244]     Train net output #0: loss = 0.614882 (* 1 = 0.614882 loss)
I0725 23:16:44.970587 22939 sgd_solver.cpp:106] Iteration 50600, lr = 3.88301e-06
I0725 23:16:54.365231 22939 solver.cpp:228] Iteration 50700, loss = 0.633986
I0725 23:16:54.365283 22939 solver.cpp:244]     Train net output #0: loss = 0.633986 (* 1 = 0.633986 loss)
I0725 23:16:54.365289 22939 sgd_solver.cpp:106] Iteration 50700, lr = 3.87889e-06
I0725 23:17:03.761622 22939 solver.cpp:228] Iteration 50800, loss = 0.519114
I0725 23:17:03.761679 22939 solver.cpp:244]     Train net output #0: loss = 0.519114 (* 1 = 0.519114 loss)
I0725 23:17:03.761687 22939 sgd_solver.cpp:106] Iteration 50800, lr = 3.87478e-06
I0725 23:17:13.163938 22939 solver.cpp:228] Iteration 50900, loss = 0.619285
I0725 23:17:13.164000 22939 solver.cpp:244]     Train net output #0: loss = 0.619285 (* 1 = 0.619285 loss)
I0725 23:17:13.164006 22939 sgd_solver.cpp:106] Iteration 50900, lr = 3.87068e-06
I0725 23:17:22.468682 22939 solver.cpp:337] Iteration 51000, Testing net (#0)
I0725 23:17:33.316241 22939 solver.cpp:404]     Test net output #0: accuracy = 0.735583
I0725 23:17:33.316282 22939 solver.cpp:404]     Test net output #1: loss = 0.632127 (* 1 = 0.632127 loss)
I0725 23:17:33.343456 22939 solver.cpp:228] Iteration 51000, loss = 0.582436
I0725 23:17:33.343520 22939 solver.cpp:244]     Train net output #0: loss = 0.582436 (* 1 = 0.582436 loss)
I0725 23:17:33.343581 22939 sgd_solver.cpp:106] Iteration 51000, lr = 3.8666e-06
I0725 23:17:42.734273 22939 solver.cpp:228] Iteration 51100, loss = 0.620242
I0725 23:17:42.734328 22939 solver.cpp:244]     Train net output #0: loss = 0.620242 (* 1 = 0.620242 loss)
I0725 23:17:42.734333 22939 sgd_solver.cpp:106] Iteration 51100, lr = 3.86252e-06
I0725 23:17:52.126392 22939 solver.cpp:228] Iteration 51200, loss = 0.652784
I0725 23:17:52.126432 22939 solver.cpp:244]     Train net output #0: loss = 0.652784 (* 1 = 0.652784 loss)
I0725 23:17:52.126438 22939 sgd_solver.cpp:106] Iteration 51200, lr = 3.85845e-06
I0725 23:18:01.514649 22939 solver.cpp:228] Iteration 51300, loss = 0.614817
I0725 23:18:01.514706 22939 solver.cpp:244]     Train net output #0: loss = 0.614817 (* 1 = 0.614817 loss)
I0725 23:18:01.514714 22939 sgd_solver.cpp:106] Iteration 51300, lr = 3.85439e-06
I0725 23:18:10.913214 22939 solver.cpp:228] Iteration 51400, loss = 0.72685
I0725 23:18:10.913259 22939 solver.cpp:244]     Train net output #0: loss = 0.72685 (* 1 = 0.72685 loss)
I0725 23:18:10.913265 22939 sgd_solver.cpp:106] Iteration 51400, lr = 3.85034e-06
I0725 23:18:20.341539 22939 solver.cpp:337] Iteration 51500, Testing net (#0)
I0725 23:18:25.439491 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:18:31.234401 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737875
I0725 23:18:31.234442 22939 solver.cpp:404]     Test net output #1: loss = 0.6302 (* 1 = 0.6302 loss)
I0725 23:18:31.263888 22939 solver.cpp:228] Iteration 51500, loss = 0.515423
I0725 23:18:31.263953 22939 solver.cpp:244]     Train net output #0: loss = 0.515423 (* 1 = 0.515423 loss)
I0725 23:18:31.263972 22939 sgd_solver.cpp:106] Iteration 51500, lr = 3.8463e-06
I0725 23:18:40.690804 22939 solver.cpp:228] Iteration 51600, loss = 0.473981
I0725 23:18:40.690843 22939 solver.cpp:244]     Train net output #0: loss = 0.473981 (* 1 = 0.473981 loss)
I0725 23:18:40.690850 22939 sgd_solver.cpp:106] Iteration 51600, lr = 3.84227e-06
I0725 23:18:50.242328 22939 solver.cpp:228] Iteration 51700, loss = 0.449906
I0725 23:18:50.242369 22939 solver.cpp:244]     Train net output #0: loss = 0.449906 (* 1 = 0.449906 loss)
I0725 23:18:50.242375 22939 sgd_solver.cpp:106] Iteration 51700, lr = 3.83825e-06
I0725 23:18:59.673472 22939 solver.cpp:228] Iteration 51800, loss = 0.488568
I0725 23:18:59.673516 22939 solver.cpp:244]     Train net output #0: loss = 0.488568 (* 1 = 0.488568 loss)
I0725 23:18:59.673521 22939 sgd_solver.cpp:106] Iteration 51800, lr = 3.83424e-06
I0725 23:19:09.028836 22939 solver.cpp:228] Iteration 51900, loss = 0.557664
I0725 23:19:09.028895 22939 solver.cpp:244]     Train net output #0: loss = 0.557664 (* 1 = 0.557664 loss)
I0725 23:19:09.028903 22939 sgd_solver.cpp:106] Iteration 51900, lr = 3.83024e-06
I0725 23:19:18.325558 22939 solver.cpp:337] Iteration 52000, Testing net (#0)
I0725 23:19:29.191844 22939 solver.cpp:404]     Test net output #0: accuracy = 0.735917
I0725 23:19:29.191900 22939 solver.cpp:404]     Test net output #1: loss = 0.631625 (* 1 = 0.631625 loss)
I0725 23:19:29.221614 22939 solver.cpp:228] Iteration 52000, loss = 0.439767
I0725 23:19:29.221643 22939 solver.cpp:244]     Train net output #0: loss = 0.439767 (* 1 = 0.439767 loss)
I0725 23:19:29.221653 22939 sgd_solver.cpp:106] Iteration 52000, lr = 3.82625e-06
I0725 23:19:38.622264 22939 solver.cpp:228] Iteration 52100, loss = 0.346155
I0725 23:19:38.622303 22939 solver.cpp:244]     Train net output #0: loss = 0.346155 (* 1 = 0.346155 loss)
I0725 23:19:38.622308 22939 sgd_solver.cpp:106] Iteration 52100, lr = 3.82227e-06
I0725 23:19:48.019541 22939 solver.cpp:228] Iteration 52200, loss = 0.522498
I0725 23:19:48.019562 22939 solver.cpp:244]     Train net output #0: loss = 0.522498 (* 1 = 0.522498 loss)
I0725 23:19:48.019568 22939 sgd_solver.cpp:106] Iteration 52200, lr = 3.8183e-06
I0725 23:19:57.418967 22939 solver.cpp:228] Iteration 52300, loss = 0.598407
I0725 23:19:57.419013 22939 solver.cpp:244]     Train net output #0: loss = 0.598407 (* 1 = 0.598407 loss)
I0725 23:19:57.419018 22939 sgd_solver.cpp:106] Iteration 52300, lr = 3.81433e-06
I0725 23:20:06.817317 22939 solver.cpp:228] Iteration 52400, loss = 0.628079
I0725 23:20:06.817364 22939 solver.cpp:244]     Train net output #0: loss = 0.628079 (* 1 = 0.628079 loss)
I0725 23:20:06.817370 22939 sgd_solver.cpp:106] Iteration 52400, lr = 3.81038e-06
I0725 23:20:16.123564 22939 solver.cpp:337] Iteration 52500, Testing net (#0)
I0725 23:20:26.958755 22939 solver.cpp:404]     Test net output #0: accuracy = 0.738584
I0725 23:20:26.958796 22939 solver.cpp:404]     Test net output #1: loss = 0.629555 (* 1 = 0.629555 loss)
I0725 23:20:26.990613 22939 solver.cpp:228] Iteration 52500, loss = 0.439744
I0725 23:20:26.990658 22939 solver.cpp:244]     Train net output #0: loss = 0.439744 (* 1 = 0.439744 loss)
I0725 23:20:26.990670 22939 sgd_solver.cpp:106] Iteration 52500, lr = 3.80644e-06
I0725 23:20:36.385829 22939 solver.cpp:228] Iteration 52600, loss = 0.465583
I0725 23:20:36.385867 22939 solver.cpp:244]     Train net output #0: loss = 0.465583 (* 1 = 0.465583 loss)
I0725 23:20:36.385874 22939 sgd_solver.cpp:106] Iteration 52600, lr = 3.80251e-06
I0725 23:20:45.775015 22939 solver.cpp:228] Iteration 52700, loss = 0.516482
I0725 23:20:45.775058 22939 solver.cpp:244]     Train net output #0: loss = 0.516482 (* 1 = 0.516482 loss)
I0725 23:20:45.775063 22939 sgd_solver.cpp:106] Iteration 52700, lr = 3.79858e-06
I0725 23:20:55.164624 22939 solver.cpp:228] Iteration 52800, loss = 0.494893
I0725 23:20:55.164669 22939 solver.cpp:244]     Train net output #0: loss = 0.494893 (* 1 = 0.494893 loss)
I0725 23:20:55.164676 22939 sgd_solver.cpp:106] Iteration 52800, lr = 3.79467e-06
I0725 23:21:04.554098 22939 solver.cpp:228] Iteration 52900, loss = 0.438934
I0725 23:21:04.554139 22939 solver.cpp:244]     Train net output #0: loss = 0.438934 (* 1 = 0.438934 loss)
I0725 23:21:04.554146 22939 sgd_solver.cpp:106] Iteration 52900, lr = 3.79076e-06
I0725 23:21:13.850152 22939 solver.cpp:337] Iteration 53000, Testing net (#0)
I0725 23:21:24.688550 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737083
I0725 23:21:24.688591 22939 solver.cpp:404]     Test net output #1: loss = 0.630272 (* 1 = 0.630272 loss)
I0725 23:21:24.718052 22939 solver.cpp:228] Iteration 53000, loss = 0.524555
I0725 23:21:24.718080 22939 solver.cpp:244]     Train net output #0: loss = 0.524555 (* 1 = 0.524555 loss)
I0725 23:21:24.718091 22939 sgd_solver.cpp:106] Iteration 53000, lr = 3.78687e-06
I0725 23:21:34.106717 22939 solver.cpp:228] Iteration 53100, loss = 0.437886
I0725 23:21:34.106760 22939 solver.cpp:244]     Train net output #0: loss = 0.437886 (* 1 = 0.437886 loss)
I0725 23:21:34.106767 22939 sgd_solver.cpp:106] Iteration 53100, lr = 3.78298e-06
I0725 23:21:43.494581 22939 solver.cpp:228] Iteration 53200, loss = 0.655996
I0725 23:21:43.494624 22939 solver.cpp:244]     Train net output #0: loss = 0.655996 (* 1 = 0.655996 loss)
I0725 23:21:43.494631 22939 sgd_solver.cpp:106] Iteration 53200, lr = 3.77911e-06
I0725 23:21:52.882297 22939 solver.cpp:228] Iteration 53300, loss = 0.541036
I0725 23:21:52.882351 22939 solver.cpp:244]     Train net output #0: loss = 0.541036 (* 1 = 0.541036 loss)
I0725 23:21:52.882359 22939 sgd_solver.cpp:106] Iteration 53300, lr = 3.77524e-06
I0725 23:22:02.269294 22939 solver.cpp:228] Iteration 53400, loss = 0.438852
I0725 23:22:02.269335 22939 solver.cpp:244]     Train net output #0: loss = 0.438852 (* 1 = 0.438852 loss)
I0725 23:22:02.269341 22939 sgd_solver.cpp:106] Iteration 53400, lr = 3.77138e-06
I0725 23:22:11.565091 22939 solver.cpp:337] Iteration 53500, Testing net (#0)
I0725 23:22:12.833441 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:22:22.472342 22939 solver.cpp:404]     Test net output #0: accuracy = 0.738667
I0725 23:22:22.472385 22939 solver.cpp:404]     Test net output #1: loss = 0.629003 (* 1 = 0.629003 loss)
I0725 23:22:22.502180 22939 solver.cpp:228] Iteration 53500, loss = 0.502407
I0725 23:22:22.502239 22939 solver.cpp:244]     Train net output #0: loss = 0.502407 (* 1 = 0.502407 loss)
I0725 23:22:22.502262 22939 sgd_solver.cpp:106] Iteration 53500, lr = 3.76753e-06
I0725 23:22:31.842787 22939 solver.cpp:228] Iteration 53600, loss = 0.65253
I0725 23:22:31.842828 22939 solver.cpp:244]     Train net output #0: loss = 0.65253 (* 1 = 0.65253 loss)
I0725 23:22:31.842835 22939 sgd_solver.cpp:106] Iteration 53600, lr = 3.76369e-06
I0725 23:22:41.243142 22939 solver.cpp:228] Iteration 53700, loss = 0.630218
I0725 23:22:41.243191 22939 solver.cpp:244]     Train net output #0: loss = 0.630218 (* 1 = 0.630218 loss)
I0725 23:22:41.243196 22939 sgd_solver.cpp:106] Iteration 53700, lr = 3.75986e-06
I0725 23:22:50.804481 22939 solver.cpp:228] Iteration 53800, loss = 0.504813
I0725 23:22:50.804535 22939 solver.cpp:244]     Train net output #0: loss = 0.504813 (* 1 = 0.504813 loss)
I0725 23:22:50.804541 22939 sgd_solver.cpp:106] Iteration 53800, lr = 3.75604e-06
I0725 23:23:00.342885 22939 solver.cpp:228] Iteration 53900, loss = 0.486893
I0725 23:23:00.342933 22939 solver.cpp:244]     Train net output #0: loss = 0.486893 (* 1 = 0.486893 loss)
I0725 23:23:00.342939 22939 sgd_solver.cpp:106] Iteration 53900, lr = 3.75223e-06
I0725 23:23:09.649106 22939 solver.cpp:337] Iteration 54000, Testing net (#0)
I0725 23:23:20.519531 22939 solver.cpp:404]     Test net output #0: accuracy = 0.738417
I0725 23:23:20.519573 22939 solver.cpp:404]     Test net output #1: loss = 0.628702 (* 1 = 0.628702 loss)
I0725 23:23:20.548900 22939 solver.cpp:228] Iteration 54000, loss = 0.490876
I0725 23:23:20.548949 22939 solver.cpp:244]     Train net output #0: loss = 0.490876 (* 1 = 0.490876 loss)
I0725 23:23:20.548969 22939 sgd_solver.cpp:106] Iteration 54000, lr = 3.74842e-06
I0725 23:23:29.883725 22939 solver.cpp:228] Iteration 54100, loss = 0.469274
I0725 23:23:29.883783 22939 solver.cpp:244]     Train net output #0: loss = 0.469274 (* 1 = 0.469274 loss)
I0725 23:23:29.883790 22939 sgd_solver.cpp:106] Iteration 54100, lr = 3.74463e-06
I0725 23:23:39.275624 22939 solver.cpp:228] Iteration 54200, loss = 0.639145
I0725 23:23:39.275666 22939 solver.cpp:244]     Train net output #0: loss = 0.639145 (* 1 = 0.639145 loss)
I0725 23:23:39.275673 22939 sgd_solver.cpp:106] Iteration 54200, lr = 3.74084e-06
I0725 23:23:48.667680 22939 solver.cpp:228] Iteration 54300, loss = 0.514536
I0725 23:23:48.667731 22939 solver.cpp:244]     Train net output #0: loss = 0.514536 (* 1 = 0.514536 loss)
I0725 23:23:48.667737 22939 sgd_solver.cpp:106] Iteration 54300, lr = 3.73707e-06
I0725 23:23:58.058835 22939 solver.cpp:228] Iteration 54400, loss = 0.560341
I0725 23:23:58.058866 22939 solver.cpp:244]     Train net output #0: loss = 0.560341 (* 1 = 0.560341 loss)
I0725 23:23:58.058872 22939 sgd_solver.cpp:106] Iteration 54400, lr = 3.7333e-06
I0725 23:24:07.359153 22939 solver.cpp:337] Iteration 54500, Testing net (#0)
I0725 23:24:18.246141 22939 solver.cpp:404]     Test net output #0: accuracy = 0.739125
I0725 23:24:18.246196 22939 solver.cpp:404]     Test net output #1: loss = 0.628348 (* 1 = 0.628348 loss)
I0725 23:24:18.273092 22939 solver.cpp:228] Iteration 54500, loss = 0.525832
I0725 23:24:18.273118 22939 solver.cpp:244]     Train net output #0: loss = 0.525832 (* 1 = 0.525832 loss)
I0725 23:24:18.273129 22939 sgd_solver.cpp:106] Iteration 54500, lr = 3.72954e-06
I0725 23:24:27.669735 22939 solver.cpp:228] Iteration 54600, loss = 0.553683
I0725 23:24:27.669787 22939 solver.cpp:244]     Train net output #0: loss = 0.553683 (* 1 = 0.553683 loss)
I0725 23:24:27.669795 22939 sgd_solver.cpp:106] Iteration 54600, lr = 3.72579e-06
I0725 23:24:37.058657 22939 solver.cpp:228] Iteration 54700, loss = 0.575127
I0725 23:24:37.058696 22939 solver.cpp:244]     Train net output #0: loss = 0.575127 (* 1 = 0.575127 loss)
I0725 23:24:37.058702 22939 sgd_solver.cpp:106] Iteration 54700, lr = 3.72205e-06
I0725 23:24:46.449252 22939 solver.cpp:228] Iteration 54800, loss = 0.540157
I0725 23:24:46.449273 22939 solver.cpp:244]     Train net output #0: loss = 0.540157 (* 1 = 0.540157 loss)
I0725 23:24:46.449280 22939 sgd_solver.cpp:106] Iteration 54800, lr = 3.71832e-06
I0725 23:24:55.837097 22939 solver.cpp:228] Iteration 54900, loss = 0.523553
I0725 23:24:55.837139 22939 solver.cpp:244]     Train net output #0: loss = 0.523553 (* 1 = 0.523553 loss)
I0725 23:24:55.837146 22939 sgd_solver.cpp:106] Iteration 54900, lr = 3.71459e-06
I0725 23:25:05.131055 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_55000.caffemodel
I0725 23:25:05.472806 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_55000.solverstate
I0725 23:25:05.580055 22939 solver.cpp:337] Iteration 55000, Testing net (#0)
I0725 23:25:16.333142 22939 solver.cpp:404]     Test net output #0: accuracy = 0.739167
I0725 23:25:16.333184 22939 solver.cpp:404]     Test net output #1: loss = 0.627846 (* 1 = 0.627846 loss)
I0725 23:25:16.366015 22939 solver.cpp:228] Iteration 55000, loss = 0.497192
I0725 23:25:16.366076 22939 solver.cpp:244]     Train net output #0: loss = 0.497192 (* 1 = 0.497192 loss)
I0725 23:25:16.366096 22939 sgd_solver.cpp:106] Iteration 55000, lr = 3.71088e-06
I0725 23:25:25.793083 22939 solver.cpp:228] Iteration 55100, loss = 0.53533
I0725 23:25:25.793123 22939 solver.cpp:244]     Train net output #0: loss = 0.53533 (* 1 = 0.53533 loss)
I0725 23:25:25.793129 22939 sgd_solver.cpp:106] Iteration 55100, lr = 3.70717e-06
I0725 23:25:35.357516 22939 solver.cpp:228] Iteration 55200, loss = 0.703067
I0725 23:25:35.357555 22939 solver.cpp:244]     Train net output #0: loss = 0.703067 (* 1 = 0.703067 loss)
I0725 23:25:35.357563 22939 sgd_solver.cpp:106] Iteration 55200, lr = 3.70347e-06
I0725 23:25:44.802718 22939 solver.cpp:228] Iteration 55300, loss = 0.477852
I0725 23:25:44.802743 22939 solver.cpp:244]     Train net output #0: loss = 0.477852 (* 1 = 0.477852 loss)
I0725 23:25:44.802748 22939 sgd_solver.cpp:106] Iteration 55300, lr = 3.69978e-06
I0725 23:25:54.203724 22939 solver.cpp:228] Iteration 55400, loss = 0.708612
I0725 23:25:54.203763 22939 solver.cpp:244]     Train net output #0: loss = 0.708612 (* 1 = 0.708612 loss)
I0725 23:25:54.203768 22939 sgd_solver.cpp:106] Iteration 55400, lr = 3.6961e-06
I0725 23:26:03.512321 22939 solver.cpp:337] Iteration 55500, Testing net (#0)
I0725 23:26:07.309330 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:26:14.361374 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737791
I0725 23:26:14.361420 22939 solver.cpp:404]     Test net output #1: loss = 0.628965 (* 1 = 0.628965 loss)
I0725 23:26:14.391271 22939 solver.cpp:228] Iteration 55500, loss = 0.727816
I0725 23:26:14.391306 22939 solver.cpp:244]     Train net output #0: loss = 0.727816 (* 1 = 0.727816 loss)
I0725 23:26:14.391320 22939 sgd_solver.cpp:106] Iteration 55500, lr = 3.69243e-06
I0725 23:26:23.787809 22939 solver.cpp:228] Iteration 55600, loss = 0.62463
I0725 23:26:23.787866 22939 solver.cpp:244]     Train net output #0: loss = 0.62463 (* 1 = 0.62463 loss)
I0725 23:26:23.787873 22939 sgd_solver.cpp:106] Iteration 55600, lr = 3.68877e-06
I0725 23:26:33.180778 22939 solver.cpp:228] Iteration 55700, loss = 0.556417
I0725 23:26:33.180820 22939 solver.cpp:244]     Train net output #0: loss = 0.556417 (* 1 = 0.556417 loss)
I0725 23:26:33.180827 22939 sgd_solver.cpp:106] Iteration 55700, lr = 3.68511e-06
I0725 23:26:42.576129 22939 solver.cpp:228] Iteration 55800, loss = 0.503161
I0725 23:26:42.576177 22939 solver.cpp:244]     Train net output #0: loss = 0.503161 (* 1 = 0.503161 loss)
I0725 23:26:42.576184 22939 sgd_solver.cpp:106] Iteration 55800, lr = 3.68146e-06
I0725 23:26:51.976148 22939 solver.cpp:228] Iteration 55900, loss = 0.50091
I0725 23:26:51.976193 22939 solver.cpp:244]     Train net output #0: loss = 0.50091 (* 1 = 0.50091 loss)
I0725 23:26:51.976199 22939 sgd_solver.cpp:106] Iteration 55900, lr = 3.67783e-06
I0725 23:27:01.279489 22939 solver.cpp:337] Iteration 56000, Testing net (#0)
I0725 23:27:12.127813 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737916
I0725 23:27:12.127856 22939 solver.cpp:404]     Test net output #1: loss = 0.63033 (* 1 = 0.63033 loss)
I0725 23:27:12.160665 22939 solver.cpp:228] Iteration 56000, loss = 0.47874
I0725 23:27:12.160733 22939 solver.cpp:244]     Train net output #0: loss = 0.47874 (* 1 = 0.47874 loss)
I0725 23:27:12.160753 22939 sgd_solver.cpp:106] Iteration 56000, lr = 3.6742e-06
I0725 23:27:21.519539 22939 solver.cpp:228] Iteration 56100, loss = 0.535783
I0725 23:27:21.519580 22939 solver.cpp:244]     Train net output #0: loss = 0.535783 (* 1 = 0.535783 loss)
I0725 23:27:21.519587 22939 sgd_solver.cpp:106] Iteration 56100, lr = 3.67057e-06
I0725 23:27:30.911185 22939 solver.cpp:228] Iteration 56200, loss = 0.514796
I0725 23:27:30.911231 22939 solver.cpp:244]     Train net output #0: loss = 0.514796 (* 1 = 0.514796 loss)
I0725 23:27:30.911238 22939 sgd_solver.cpp:106] Iteration 56200, lr = 3.66696e-06
I0725 23:27:40.296792 22939 solver.cpp:228] Iteration 56300, loss = 0.530846
I0725 23:27:40.296836 22939 solver.cpp:244]     Train net output #0: loss = 0.530846 (* 1 = 0.530846 loss)
I0725 23:27:40.296843 22939 sgd_solver.cpp:106] Iteration 56300, lr = 3.66336e-06
I0725 23:27:49.683598 22939 solver.cpp:228] Iteration 56400, loss = 0.391175
I0725 23:27:49.683640 22939 solver.cpp:244]     Train net output #0: loss = 0.391175 (* 1 = 0.391175 loss)
I0725 23:27:49.683646 22939 sgd_solver.cpp:106] Iteration 56400, lr = 3.65976e-06
I0725 23:27:58.983136 22939 solver.cpp:337] Iteration 56500, Testing net (#0)
I0725 23:28:09.911689 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7395
I0725 23:28:09.911733 22939 solver.cpp:404]     Test net output #1: loss = 0.626294 (* 1 = 0.626294 loss)
I0725 23:28:09.940882 22939 solver.cpp:228] Iteration 56500, loss = 0.481298
I0725 23:28:09.940901 22939 solver.cpp:244]     Train net output #0: loss = 0.481298 (* 1 = 0.481298 loss)
I0725 23:28:09.940910 22939 sgd_solver.cpp:106] Iteration 56500, lr = 3.65617e-06
I0725 23:28:19.304100 22939 solver.cpp:228] Iteration 56600, loss = 0.540156
I0725 23:28:19.304139 22939 solver.cpp:244]     Train net output #0: loss = 0.540156 (* 1 = 0.540156 loss)
I0725 23:28:19.304146 22939 sgd_solver.cpp:106] Iteration 56600, lr = 3.65259e-06
I0725 23:28:28.708884 22939 solver.cpp:228] Iteration 56700, loss = 0.597897
I0725 23:28:28.708923 22939 solver.cpp:244]     Train net output #0: loss = 0.597897 (* 1 = 0.597897 loss)
I0725 23:28:28.708930 22939 sgd_solver.cpp:106] Iteration 56700, lr = 3.64902e-06
I0725 23:28:38.112117 22939 solver.cpp:228] Iteration 56800, loss = 0.470445
I0725 23:28:38.112162 22939 solver.cpp:244]     Train net output #0: loss = 0.470445 (* 1 = 0.470445 loss)
I0725 23:28:38.112169 22939 sgd_solver.cpp:106] Iteration 56800, lr = 3.64545e-06
I0725 23:28:47.519659 22939 solver.cpp:228] Iteration 56900, loss = 0.41206
I0725 23:28:47.519706 22939 solver.cpp:244]     Train net output #0: loss = 0.41206 (* 1 = 0.41206 loss)
I0725 23:28:47.519711 22939 sgd_solver.cpp:106] Iteration 56900, lr = 3.6419e-06
I0725 23:28:56.830487 22939 solver.cpp:337] Iteration 57000, Testing net (#0)
I0725 23:29:07.743502 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737208
I0725 23:29:07.743547 22939 solver.cpp:404]     Test net output #1: loss = 0.631912 (* 1 = 0.631912 loss)
I0725 23:29:07.772979 22939 solver.cpp:228] Iteration 57000, loss = 0.439531
I0725 23:29:07.773028 22939 solver.cpp:244]     Train net output #0: loss = 0.439531 (* 1 = 0.439531 loss)
I0725 23:29:07.773049 22939 sgd_solver.cpp:106] Iteration 57000, lr = 3.63835e-06
I0725 23:29:17.104137 22939 solver.cpp:228] Iteration 57100, loss = 0.595442
I0725 23:29:17.104189 22939 solver.cpp:244]     Train net output #0: loss = 0.595442 (* 1 = 0.595442 loss)
I0725 23:29:17.104197 22939 sgd_solver.cpp:106] Iteration 57100, lr = 3.63481e-06
I0725 23:29:26.494637 22939 solver.cpp:228] Iteration 57200, loss = 0.418079
I0725 23:29:26.494698 22939 solver.cpp:244]     Train net output #0: loss = 0.418079 (* 1 = 0.418079 loss)
I0725 23:29:26.494704 22939 sgd_solver.cpp:106] Iteration 57200, lr = 3.63128e-06
I0725 23:29:35.886996 22939 solver.cpp:228] Iteration 57300, loss = 0.563533
I0725 23:29:35.887042 22939 solver.cpp:244]     Train net output #0: loss = 0.563533 (* 1 = 0.563533 loss)
I0725 23:29:35.887048 22939 sgd_solver.cpp:106] Iteration 57300, lr = 3.62775e-06
I0725 23:29:45.280848 22939 solver.cpp:228] Iteration 57400, loss = 0.470091
I0725 23:29:45.280869 22939 solver.cpp:244]     Train net output #0: loss = 0.470091 (* 1 = 0.470091 loss)
I0725 23:29:45.280874 22939 sgd_solver.cpp:106] Iteration 57400, lr = 3.62424e-06
I0725 23:29:54.583035 22939 solver.cpp:337] Iteration 57500, Testing net (#0)
I0725 23:30:03.183607 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:30:05.473731 22939 solver.cpp:404]     Test net output #0: accuracy = 0.739667
I0725 23:30:05.473781 22939 solver.cpp:404]     Test net output #1: loss = 0.626916 (* 1 = 0.626916 loss)
I0725 23:30:05.506750 22939 solver.cpp:228] Iteration 57500, loss = 0.578428
I0725 23:30:05.506798 22939 solver.cpp:244]     Train net output #0: loss = 0.578428 (* 1 = 0.578428 loss)
I0725 23:30:05.506821 22939 sgd_solver.cpp:106] Iteration 57500, lr = 3.62073e-06
I0725 23:30:14.889245 22939 solver.cpp:228] Iteration 57600, loss = 0.597702
I0725 23:30:14.889292 22939 solver.cpp:244]     Train net output #0: loss = 0.597702 (* 1 = 0.597702 loss)
I0725 23:30:14.889297 22939 sgd_solver.cpp:106] Iteration 57600, lr = 3.61723e-06
I0725 23:30:24.279734 22939 solver.cpp:228] Iteration 57700, loss = 0.573888
I0725 23:30:24.279783 22939 solver.cpp:244]     Train net output #0: loss = 0.573888 (* 1 = 0.573888 loss)
I0725 23:30:24.279788 22939 sgd_solver.cpp:106] Iteration 57700, lr = 3.61374e-06
I0725 23:30:33.670704 22939 solver.cpp:228] Iteration 57800, loss = 0.509797
I0725 23:30:33.670753 22939 solver.cpp:244]     Train net output #0: loss = 0.509797 (* 1 = 0.509797 loss)
I0725 23:30:33.670758 22939 sgd_solver.cpp:106] Iteration 57800, lr = 3.61025e-06
I0725 23:30:43.061708 22939 solver.cpp:228] Iteration 57900, loss = 0.693079
I0725 23:30:43.061758 22939 solver.cpp:244]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0725 23:30:43.061764 22939 sgd_solver.cpp:106] Iteration 57900, lr = 3.60678e-06
I0725 23:30:52.358355 22939 solver.cpp:337] Iteration 58000, Testing net (#0)
I0725 23:31:03.252285 22939 solver.cpp:404]     Test net output #0: accuracy = 0.73775
I0725 23:31:03.252322 22939 solver.cpp:404]     Test net output #1: loss = 0.631343 (* 1 = 0.631343 loss)
I0725 23:31:03.282507 22939 solver.cpp:228] Iteration 58000, loss = 0.693412
I0725 23:31:03.282562 22939 solver.cpp:244]     Train net output #0: loss = 0.693412 (* 1 = 0.693412 loss)
I0725 23:31:03.282582 22939 sgd_solver.cpp:106] Iteration 58000, lr = 3.60331e-06
I0725 23:31:12.614255 22939 solver.cpp:228] Iteration 58100, loss = 0.413608
I0725 23:31:12.614296 22939 solver.cpp:244]     Train net output #0: loss = 0.413608 (* 1 = 0.413608 loss)
I0725 23:31:12.614302 22939 sgd_solver.cpp:106] Iteration 58100, lr = 3.59985e-06
I0725 23:31:22.046651 22939 solver.cpp:228] Iteration 58200, loss = 0.672885
I0725 23:31:22.046705 22939 solver.cpp:244]     Train net output #0: loss = 0.672885 (* 1 = 0.672885 loss)
I0725 23:31:22.046711 22939 sgd_solver.cpp:106] Iteration 58200, lr = 3.5964e-06
I0725 23:31:31.612673 22939 solver.cpp:228] Iteration 58300, loss = 0.488064
I0725 23:31:31.612723 22939 solver.cpp:244]     Train net output #0: loss = 0.488064 (* 1 = 0.488064 loss)
I0725 23:31:31.612730 22939 sgd_solver.cpp:106] Iteration 58300, lr = 3.59295e-06
I0725 23:31:41.089794 22939 solver.cpp:228] Iteration 58400, loss = 0.53626
I0725 23:31:41.089814 22939 solver.cpp:244]     Train net output #0: loss = 0.53626 (* 1 = 0.53626 loss)
I0725 23:31:41.089820 22939 sgd_solver.cpp:106] Iteration 58400, lr = 3.58951e-06
I0725 23:31:50.399395 22939 solver.cpp:337] Iteration 58500, Testing net (#0)
I0725 23:32:01.241235 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737167
I0725 23:32:01.241295 22939 solver.cpp:404]     Test net output #1: loss = 0.629593 (* 1 = 0.629593 loss)
I0725 23:32:01.273876 22939 solver.cpp:228] Iteration 58500, loss = 0.465974
I0725 23:32:01.273905 22939 solver.cpp:244]     Train net output #0: loss = 0.465974 (* 1 = 0.465974 loss)
I0725 23:32:01.273926 22939 sgd_solver.cpp:106] Iteration 58500, lr = 3.58608e-06
I0725 23:32:10.620944 22939 solver.cpp:228] Iteration 58600, loss = 0.455524
I0725 23:32:10.620985 22939 solver.cpp:244]     Train net output #0: loss = 0.455524 (* 1 = 0.455524 loss)
I0725 23:32:10.620990 22939 sgd_solver.cpp:106] Iteration 58600, lr = 3.58266e-06
I0725 23:32:20.013134 22939 solver.cpp:228] Iteration 58700, loss = 0.558281
I0725 23:32:20.013175 22939 solver.cpp:244]     Train net output #0: loss = 0.558281 (* 1 = 0.558281 loss)
I0725 23:32:20.013181 22939 sgd_solver.cpp:106] Iteration 58700, lr = 3.57925e-06
I0725 23:32:29.406077 22939 solver.cpp:228] Iteration 58800, loss = 0.589736
I0725 23:32:29.406132 22939 solver.cpp:244]     Train net output #0: loss = 0.589736 (* 1 = 0.589736 loss)
I0725 23:32:29.406138 22939 sgd_solver.cpp:106] Iteration 58800, lr = 3.57584e-06
I0725 23:32:38.801218 22939 solver.cpp:228] Iteration 58900, loss = 0.562299
I0725 23:32:38.801272 22939 solver.cpp:244]     Train net output #0: loss = 0.562299 (* 1 = 0.562299 loss)
I0725 23:32:38.801280 22939 sgd_solver.cpp:106] Iteration 58900, lr = 3.57244e-06
I0725 23:32:48.107072 22939 solver.cpp:337] Iteration 59000, Testing net (#0)
I0725 23:32:58.969540 22939 solver.cpp:404]     Test net output #0: accuracy = 0.737417
I0725 23:32:58.969584 22939 solver.cpp:404]     Test net output #1: loss = 0.631286 (* 1 = 0.631286 loss)
I0725 23:32:59.002576 22939 solver.cpp:228] Iteration 59000, loss = 0.493041
I0725 23:32:59.002627 22939 solver.cpp:244]     Train net output #0: loss = 0.493041 (* 1 = 0.493041 loss)
I0725 23:32:59.002648 22939 sgd_solver.cpp:106] Iteration 59000, lr = 3.56905e-06
I0725 23:33:08.401414 22939 solver.cpp:228] Iteration 59100, loss = 0.551806
I0725 23:33:08.401461 22939 solver.cpp:244]     Train net output #0: loss = 0.551806 (* 1 = 0.551806 loss)
I0725 23:33:08.401466 22939 sgd_solver.cpp:106] Iteration 59100, lr = 3.56566e-06
I0725 23:33:17.795213 22939 solver.cpp:228] Iteration 59200, loss = 0.501356
I0725 23:33:17.795258 22939 solver.cpp:244]     Train net output #0: loss = 0.501356 (* 1 = 0.501356 loss)
I0725 23:33:17.795264 22939 sgd_solver.cpp:106] Iteration 59200, lr = 3.56228e-06
I0725 23:33:27.188539 22939 solver.cpp:228] Iteration 59300, loss = 0.614655
I0725 23:33:27.188586 22939 solver.cpp:244]     Train net output #0: loss = 0.614655 (* 1 = 0.614655 loss)
I0725 23:33:27.188592 22939 sgd_solver.cpp:106] Iteration 59300, lr = 3.55891e-06
I0725 23:33:36.575644 22939 solver.cpp:228] Iteration 59400, loss = 0.436484
I0725 23:33:36.575690 22939 solver.cpp:244]     Train net output #0: loss = 0.436484 (* 1 = 0.436484 loss)
I0725 23:33:36.575695 22939 sgd_solver.cpp:106] Iteration 59400, lr = 3.55555e-06
I0725 23:33:45.867617 22939 solver.cpp:337] Iteration 59500, Testing net (#0)
I0725 23:33:56.730069 22939 solver.cpp:404]     Test net output #0: accuracy = 0.738583
I0725 23:33:56.730111 22939 solver.cpp:404]     Test net output #1: loss = 0.628658 (* 1 = 0.628658 loss)
I0725 23:33:56.759896 22939 solver.cpp:228] Iteration 59500, loss = 0.664326
I0725 23:33:56.759940 22939 solver.cpp:244]     Train net output #0: loss = 0.664326 (* 1 = 0.664326 loss)
I0725 23:33:56.759961 22939 sgd_solver.cpp:106] Iteration 59500, lr = 3.5522e-06
I0725 23:34:06.144927 22939 solver.cpp:228] Iteration 59600, loss = 0.459411
I0725 23:34:06.144984 22939 solver.cpp:244]     Train net output #0: loss = 0.459411 (* 1 = 0.459411 loss)
I0725 23:34:06.144990 22939 sgd_solver.cpp:106] Iteration 59600, lr = 3.54885e-06
I0725 23:34:06.896632 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:34:15.543216 22939 solver.cpp:228] Iteration 59700, loss = 0.60084
I0725 23:34:15.543264 22939 solver.cpp:244]     Train net output #0: loss = 0.60084 (* 1 = 0.60084 loss)
I0725 23:34:15.543270 22939 sgd_solver.cpp:106] Iteration 59700, lr = 3.54551e-06
I0725 23:34:24.944018 22939 solver.cpp:228] Iteration 59800, loss = 0.546511
I0725 23:34:24.944077 22939 solver.cpp:244]     Train net output #0: loss = 0.546511 (* 1 = 0.546511 loss)
I0725 23:34:24.944084 22939 sgd_solver.cpp:106] Iteration 59800, lr = 3.54218e-06
I0725 23:34:34.343958 22939 solver.cpp:228] Iteration 59900, loss = 0.527564
I0725 23:34:34.344017 22939 solver.cpp:244]     Train net output #0: loss = 0.527564 (* 1 = 0.527564 loss)
I0725 23:34:34.344023 22939 sgd_solver.cpp:106] Iteration 59900, lr = 3.53885e-06
I0725 23:34:43.651185 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_60000.caffemodel
I0725 23:34:44.000017 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_60000.solverstate
I0725 23:34:44.108707 22939 solver.cpp:337] Iteration 60000, Testing net (#0)
I0725 23:34:54.760979 22939 solver.cpp:404]     Test net output #0: accuracy = 0.738292
I0725 23:34:54.761030 22939 solver.cpp:404]     Test net output #1: loss = 0.629091 (* 1 = 0.629091 loss)
I0725 23:34:54.790225 22939 solver.cpp:228] Iteration 60000, loss = 0.548637
I0725 23:34:54.790256 22939 solver.cpp:244]     Train net output #0: loss = 0.548637 (* 1 = 0.548637 loss)
I0725 23:34:54.790277 22939 sgd_solver.cpp:106] Iteration 60000, lr = 3.53553e-06
I0725 23:35:04.234261 22939 solver.cpp:228] Iteration 60100, loss = 0.462088
I0725 23:35:04.234302 22939 solver.cpp:244]     Train net output #0: loss = 0.462088 (* 1 = 0.462088 loss)
I0725 23:35:04.234308 22939 sgd_solver.cpp:106] Iteration 60100, lr = 3.53222e-06
I0725 23:35:13.786994 22939 solver.cpp:228] Iteration 60200, loss = 0.547984
I0725 23:35:13.787034 22939 solver.cpp:244]     Train net output #0: loss = 0.547984 (* 1 = 0.547984 loss)
I0725 23:35:13.787040 22939 sgd_solver.cpp:106] Iteration 60200, lr = 3.52892e-06
I0725 23:35:23.336447 22939 solver.cpp:228] Iteration 60300, loss = 0.50789
I0725 23:35:23.336500 22939 solver.cpp:244]     Train net output #0: loss = 0.50789 (* 1 = 0.50789 loss)
I0725 23:35:23.336508 22939 sgd_solver.cpp:106] Iteration 60300, lr = 3.52562e-06
I0725 23:35:32.802959 22939 solver.cpp:228] Iteration 60400, loss = 0.487274
I0725 23:35:32.803000 22939 solver.cpp:244]     Train net output #0: loss = 0.487274 (* 1 = 0.487274 loss)
I0725 23:35:32.803006 22939 sgd_solver.cpp:106] Iteration 60400, lr = 3.52233e-06
I0725 23:35:42.033434 22939 solver.cpp:337] Iteration 60500, Testing net (#0)
I0725 23:35:52.885288 22939 solver.cpp:404]     Test net output #0: accuracy = 0.739292
I0725 23:35:52.885339 22939 solver.cpp:404]     Test net output #1: loss = 0.627015 (* 1 = 0.627015 loss)
I0725 23:35:52.915235 22939 solver.cpp:228] Iteration 60500, loss = 0.519397
I0725 23:35:52.915294 22939 solver.cpp:244]     Train net output #0: loss = 0.519397 (* 1 = 0.519397 loss)
I0725 23:35:52.915313 22939 sgd_solver.cpp:106] Iteration 60500, lr = 3.51905e-06
I0725 23:36:02.312089 22939 solver.cpp:228] Iteration 60600, loss = 0.566987
I0725 23:36:02.312142 22939 solver.cpp:244]     Train net output #0: loss = 0.566987 (* 1 = 0.566987 loss)
I0725 23:36:02.312151 22939 sgd_solver.cpp:106] Iteration 60600, lr = 3.51578e-06
I0725 23:36:11.704545 22939 solver.cpp:228] Iteration 60700, loss = 0.543039
I0725 23:36:11.704594 22939 solver.cpp:244]     Train net output #0: loss = 0.543039 (* 1 = 0.543039 loss)
I0725 23:36:11.704601 22939 sgd_solver.cpp:106] Iteration 60700, lr = 3.51251e-06
I0725 23:36:21.094748 22939 solver.cpp:228] Iteration 60800, loss = 0.405365
I0725 23:36:21.094795 22939 solver.cpp:244]     Train net output #0: loss = 0.405365 (* 1 = 0.405365 loss)
I0725 23:36:21.094802 22939 sgd_solver.cpp:106] Iteration 60800, lr = 3.50925e-06
I0725 23:36:30.540846 22939 solver.cpp:228] Iteration 60900, loss = 0.386799
I0725 23:36:30.540899 22939 solver.cpp:244]     Train net output #0: loss = 0.386799 (* 1 = 0.386799 loss)
I0725 23:36:30.540906 22939 sgd_solver.cpp:106] Iteration 60900, lr = 3.50599e-06
I0725 23:36:39.995574 22939 solver.cpp:337] Iteration 61000, Testing net (#0)
I0725 23:36:50.933056 22939 solver.cpp:404]     Test net output #0: accuracy = 0.740292
I0725 23:36:50.933106 22939 solver.cpp:404]     Test net output #1: loss = 0.625639 (* 1 = 0.625639 loss)
I0725 23:36:50.960978 22939 solver.cpp:228] Iteration 61000, loss = 0.427531
I0725 23:36:50.961028 22939 solver.cpp:244]     Train net output #0: loss = 0.427531 (* 1 = 0.427531 loss)
I0725 23:36:50.961050 22939 sgd_solver.cpp:106] Iteration 61000, lr = 3.50275e-06
I0725 23:37:00.277933 22939 solver.cpp:228] Iteration 61100, loss = 0.451152
I0725 23:37:00.277983 22939 solver.cpp:244]     Train net output #0: loss = 0.451152 (* 1 = 0.451152 loss)
I0725 23:37:00.277990 22939 sgd_solver.cpp:106] Iteration 61100, lr = 3.49951e-06
I0725 23:37:09.670696 22939 solver.cpp:228] Iteration 61200, loss = 0.522027
I0725 23:37:09.670738 22939 solver.cpp:244]     Train net output #0: loss = 0.522027 (* 1 = 0.522027 loss)
I0725 23:37:09.670744 22939 sgd_solver.cpp:106] Iteration 61200, lr = 3.49627e-06
I0725 23:37:19.068596 22939 solver.cpp:228] Iteration 61300, loss = 0.455467
I0725 23:37:19.068639 22939 solver.cpp:244]     Train net output #0: loss = 0.455467 (* 1 = 0.455467 loss)
I0725 23:37:19.068645 22939 sgd_solver.cpp:106] Iteration 61300, lr = 3.49305e-06
I0725 23:37:28.524201 22939 solver.cpp:228] Iteration 61400, loss = 0.606056
I0725 23:37:28.524221 22939 solver.cpp:244]     Train net output #0: loss = 0.606056 (* 1 = 0.606056 loss)
I0725 23:37:28.524227 22939 sgd_solver.cpp:106] Iteration 61400, lr = 3.48983e-06
I0725 23:37:37.988457 22939 solver.cpp:337] Iteration 61500, Testing net (#0)
I0725 23:37:48.916604 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7395
I0725 23:37:48.916656 22939 solver.cpp:404]     Test net output #1: loss = 0.625295 (* 1 = 0.625295 loss)
I0725 23:37:48.945832 22939 solver.cpp:228] Iteration 61500, loss = 0.499436
I0725 23:37:48.945885 22939 solver.cpp:244]     Train net output #0: loss = 0.499436 (* 1 = 0.499436 loss)
I0725 23:37:48.945907 22939 sgd_solver.cpp:106] Iteration 61500, lr = 3.48662e-06
I0725 23:37:58.293579 22939 solver.cpp:228] Iteration 61600, loss = 0.514302
I0725 23:37:58.293622 22939 solver.cpp:244]     Train net output #0: loss = 0.514302 (* 1 = 0.514302 loss)
I0725 23:37:58.293627 22939 sgd_solver.cpp:106] Iteration 61600, lr = 3.48341e-06
I0725 23:38:07.684833 22939 solver.cpp:228] Iteration 61700, loss = 0.606788
I0725 23:38:07.684881 22939 solver.cpp:244]     Train net output #0: loss = 0.606788 (* 1 = 0.606788 loss)
I0725 23:38:07.684887 22939 sgd_solver.cpp:106] Iteration 61700, lr = 3.48021e-06
I0725 23:38:17.082618 22939 solver.cpp:228] Iteration 61800, loss = 0.501264
I0725 23:38:17.082679 22939 solver.cpp:244]     Train net output #0: loss = 0.501264 (* 1 = 0.501264 loss)
I0725 23:38:17.082684 22939 sgd_solver.cpp:106] Iteration 61800, lr = 3.47702e-06
I0725 23:38:26.476933 22939 solver.cpp:228] Iteration 61900, loss = 0.578766
I0725 23:38:26.476990 22939 solver.cpp:244]     Train net output #0: loss = 0.578766 (* 1 = 0.578766 loss)
I0725 23:38:26.476996 22939 sgd_solver.cpp:106] Iteration 61900, lr = 3.47384e-06
I0725 23:38:35.774878 22939 solver.cpp:337] Iteration 62000, Testing net (#0)
I0725 23:38:36.422646 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:38:46.671855 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74025
I0725 23:38:46.671900 22939 solver.cpp:404]     Test net output #1: loss = 0.624142 (* 1 = 0.624142 loss)
I0725 23:38:46.701561 22939 solver.cpp:228] Iteration 62000, loss = 0.617117
I0725 23:38:46.701591 22939 solver.cpp:244]     Train net output #0: loss = 0.617117 (* 1 = 0.617117 loss)
I0725 23:38:46.701602 22939 sgd_solver.cpp:106] Iteration 62000, lr = 3.47066e-06
I0725 23:38:56.042314 22939 solver.cpp:228] Iteration 62100, loss = 0.498055
I0725 23:38:56.042354 22939 solver.cpp:244]     Train net output #0: loss = 0.498055 (* 1 = 0.498055 loss)
I0725 23:38:56.042361 22939 sgd_solver.cpp:106] Iteration 62100, lr = 3.46749e-06
I0725 23:39:05.439223 22939 solver.cpp:228] Iteration 62200, loss = 0.607658
I0725 23:39:05.439262 22939 solver.cpp:244]     Train net output #0: loss = 0.607658 (* 1 = 0.607658 loss)
I0725 23:39:05.439268 22939 sgd_solver.cpp:106] Iteration 62200, lr = 3.46433e-06
I0725 23:39:14.838171 22939 solver.cpp:228] Iteration 62300, loss = 0.570819
I0725 23:39:14.838217 22939 solver.cpp:244]     Train net output #0: loss = 0.570819 (* 1 = 0.570819 loss)
I0725 23:39:14.838224 22939 sgd_solver.cpp:106] Iteration 62300, lr = 3.46117e-06
I0725 23:39:24.233729 22939 solver.cpp:228] Iteration 62400, loss = 0.519854
I0725 23:39:24.233770 22939 solver.cpp:244]     Train net output #0: loss = 0.519854 (* 1 = 0.519854 loss)
I0725 23:39:24.233777 22939 sgd_solver.cpp:106] Iteration 62400, lr = 3.45802e-06
I0725 23:39:33.558706 22939 solver.cpp:337] Iteration 62500, Testing net (#0)
I0725 23:39:44.598772 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74125
I0725 23:39:44.598826 22939 solver.cpp:404]     Test net output #1: loss = 0.623551 (* 1 = 0.623551 loss)
I0725 23:39:44.625741 22939 solver.cpp:228] Iteration 62500, loss = 0.751173
I0725 23:39:44.625808 22939 solver.cpp:244]     Train net output #0: loss = 0.751173 (* 1 = 0.751173 loss)
I0725 23:39:44.625828 22939 sgd_solver.cpp:106] Iteration 62500, lr = 3.45487e-06
I0725 23:39:53.950315 22939 solver.cpp:228] Iteration 62600, loss = 0.492506
I0725 23:39:53.950363 22939 solver.cpp:244]     Train net output #0: loss = 0.492506 (* 1 = 0.492506 loss)
I0725 23:39:53.950371 22939 sgd_solver.cpp:106] Iteration 62600, lr = 3.45173e-06
I0725 23:40:03.338271 22939 solver.cpp:228] Iteration 62700, loss = 0.537561
I0725 23:40:03.338316 22939 solver.cpp:244]     Train net output #0: loss = 0.537561 (* 1 = 0.537561 loss)
I0725 23:40:03.338323 22939 sgd_solver.cpp:106] Iteration 62700, lr = 3.4486e-06
I0725 23:40:12.739704 22939 solver.cpp:228] Iteration 62800, loss = 0.441714
I0725 23:40:12.739742 22939 solver.cpp:244]     Train net output #0: loss = 0.441714 (* 1 = 0.441714 loss)
I0725 23:40:12.739748 22939 sgd_solver.cpp:106] Iteration 62800, lr = 3.44548e-06
I0725 23:40:22.139595 22939 solver.cpp:228] Iteration 62900, loss = 0.401531
I0725 23:40:22.139642 22939 solver.cpp:244]     Train net output #0: loss = 0.401531 (* 1 = 0.401531 loss)
I0725 23:40:22.139647 22939 sgd_solver.cpp:106] Iteration 62900, lr = 3.44236e-06
I0725 23:40:31.454282 22939 solver.cpp:337] Iteration 63000, Testing net (#0)
I0725 23:40:42.290071 22939 solver.cpp:404]     Test net output #0: accuracy = 0.741375
I0725 23:40:42.290122 22939 solver.cpp:404]     Test net output #1: loss = 0.623138 (* 1 = 0.623138 loss)
I0725 23:40:42.321939 22939 solver.cpp:228] Iteration 63000, loss = 0.590382
I0725 23:40:42.321967 22939 solver.cpp:244]     Train net output #0: loss = 0.590382 (* 1 = 0.590382 loss)
I0725 23:40:42.321981 22939 sgd_solver.cpp:106] Iteration 63000, lr = 3.43925e-06
I0725 23:40:51.718293 22939 solver.cpp:228] Iteration 63100, loss = 0.602664
I0725 23:40:51.718338 22939 solver.cpp:244]     Train net output #0: loss = 0.602664 (* 1 = 0.602664 loss)
I0725 23:40:51.718343 22939 sgd_solver.cpp:106] Iteration 63100, lr = 3.43615e-06
I0725 23:41:01.114930 22939 solver.cpp:228] Iteration 63200, loss = 0.508147
I0725 23:41:01.114989 22939 solver.cpp:244]     Train net output #0: loss = 0.508147 (* 1 = 0.508147 loss)
I0725 23:41:01.114996 22939 sgd_solver.cpp:106] Iteration 63200, lr = 3.43305e-06
I0725 23:41:10.516156 22939 solver.cpp:228] Iteration 63300, loss = 0.399691
I0725 23:41:10.516202 22939 solver.cpp:244]     Train net output #0: loss = 0.399691 (* 1 = 0.399691 loss)
I0725 23:41:10.516208 22939 sgd_solver.cpp:106] Iteration 63300, lr = 3.42996e-06
I0725 23:41:19.914827 22939 solver.cpp:228] Iteration 63400, loss = 0.434625
I0725 23:41:19.914849 22939 solver.cpp:244]     Train net output #0: loss = 0.434625 (* 1 = 0.434625 loss)
I0725 23:41:19.914855 22939 sgd_solver.cpp:106] Iteration 63400, lr = 3.42687e-06
I0725 23:41:29.224117 22939 solver.cpp:337] Iteration 63500, Testing net (#0)
I0725 23:41:40.073212 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742875
I0725 23:41:40.073256 22939 solver.cpp:404]     Test net output #1: loss = 0.6214 (* 1 = 0.6214 loss)
I0725 23:41:40.103108 22939 solver.cpp:228] Iteration 63500, loss = 0.534318
I0725 23:41:40.103171 22939 solver.cpp:244]     Train net output #0: loss = 0.534318 (* 1 = 0.534318 loss)
I0725 23:41:40.103188 22939 sgd_solver.cpp:106] Iteration 63500, lr = 3.42379e-06
I0725 23:41:49.501260 22939 solver.cpp:228] Iteration 63600, loss = 0.664728
I0725 23:41:49.501302 22939 solver.cpp:244]     Train net output #0: loss = 0.664728 (* 1 = 0.664728 loss)
I0725 23:41:49.501307 22939 sgd_solver.cpp:106] Iteration 63600, lr = 3.42072e-06
I0725 23:41:58.898829 22939 solver.cpp:228] Iteration 63700, loss = 0.432595
I0725 23:41:58.898876 22939 solver.cpp:244]     Train net output #0: loss = 0.432595 (* 1 = 0.432595 loss)
I0725 23:41:58.898883 22939 sgd_solver.cpp:106] Iteration 63700, lr = 3.41766e-06
I0725 23:42:08.297117 22939 solver.cpp:228] Iteration 63800, loss = 0.617295
I0725 23:42:08.297161 22939 solver.cpp:244]     Train net output #0: loss = 0.617295 (* 1 = 0.617295 loss)
I0725 23:42:08.297168 22939 sgd_solver.cpp:106] Iteration 63800, lr = 3.4146e-06
I0725 23:42:17.696609 22939 solver.cpp:228] Iteration 63900, loss = 0.475355
I0725 23:42:17.696655 22939 solver.cpp:244]     Train net output #0: loss = 0.475355 (* 1 = 0.475355 loss)
I0725 23:42:17.696661 22939 sgd_solver.cpp:106] Iteration 63900, lr = 3.41154e-06
I0725 23:42:27.000308 22939 solver.cpp:337] Iteration 64000, Testing net (#0)
I0725 23:42:29.892628 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:42:37.922996 22939 solver.cpp:404]     Test net output #0: accuracy = 0.73925
I0725 23:42:37.923053 22939 solver.cpp:404]     Test net output #1: loss = 0.624899 (* 1 = 0.624899 loss)
I0725 23:42:37.952571 22939 solver.cpp:228] Iteration 64000, loss = 0.522852
I0725 23:42:37.952610 22939 solver.cpp:244]     Train net output #0: loss = 0.522852 (* 1 = 0.522852 loss)
I0725 23:42:37.952631 22939 sgd_solver.cpp:106] Iteration 64000, lr = 3.4085e-06
I0725 23:42:47.305557 22939 solver.cpp:228] Iteration 64100, loss = 0.53358
I0725 23:42:47.305595 22939 solver.cpp:244]     Train net output #0: loss = 0.53358 (* 1 = 0.53358 loss)
I0725 23:42:47.305603 22939 sgd_solver.cpp:106] Iteration 64100, lr = 3.40546e-06
I0725 23:42:56.709326 22939 solver.cpp:228] Iteration 64200, loss = 0.491526
I0725 23:42:56.709370 22939 solver.cpp:244]     Train net output #0: loss = 0.491526 (* 1 = 0.491526 loss)
I0725 23:42:56.709377 22939 sgd_solver.cpp:106] Iteration 64200, lr = 3.40242e-06
I0725 23:43:06.115752 22939 solver.cpp:228] Iteration 64300, loss = 0.52395
I0725 23:43:06.115813 22939 solver.cpp:244]     Train net output #0: loss = 0.52395 (* 1 = 0.52395 loss)
I0725 23:43:06.115818 22939 sgd_solver.cpp:106] Iteration 64300, lr = 3.3994e-06
I0725 23:43:15.517940 22939 solver.cpp:228] Iteration 64400, loss = 0.490262
I0725 23:43:15.517984 22939 solver.cpp:244]     Train net output #0: loss = 0.490262 (* 1 = 0.490262 loss)
I0725 23:43:15.517990 22939 sgd_solver.cpp:106] Iteration 64400, lr = 3.39637e-06
I0725 23:43:24.825678 22939 solver.cpp:337] Iteration 64500, Testing net (#0)
I0725 23:43:35.735481 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743125
I0725 23:43:35.735533 22939 solver.cpp:404]     Test net output #1: loss = 0.621538 (* 1 = 0.621538 loss)
I0725 23:43:35.768337 22939 solver.cpp:228] Iteration 64500, loss = 0.577279
I0725 23:43:35.768354 22939 solver.cpp:244]     Train net output #0: loss = 0.577279 (* 1 = 0.577279 loss)
I0725 23:43:35.768362 22939 sgd_solver.cpp:106] Iteration 64500, lr = 3.39336e-06
I0725 23:43:45.160375 22939 solver.cpp:228] Iteration 64600, loss = 0.459051
I0725 23:43:45.160399 22939 solver.cpp:244]     Train net output #0: loss = 0.459051 (* 1 = 0.459051 loss)
I0725 23:43:45.160406 22939 sgd_solver.cpp:106] Iteration 64600, lr = 3.39035e-06
I0725 23:43:54.555444 22939 solver.cpp:228] Iteration 64700, loss = 0.436066
I0725 23:43:54.555486 22939 solver.cpp:244]     Train net output #0: loss = 0.436066 (* 1 = 0.436066 loss)
I0725 23:43:54.555493 22939 sgd_solver.cpp:106] Iteration 64700, lr = 3.38735e-06
I0725 23:44:03.952421 22939 solver.cpp:228] Iteration 64800, loss = 0.559111
I0725 23:44:03.952461 22939 solver.cpp:244]     Train net output #0: loss = 0.559111 (* 1 = 0.559111 loss)
I0725 23:44:03.952466 22939 sgd_solver.cpp:106] Iteration 64800, lr = 3.38435e-06
I0725 23:44:13.347386 22939 solver.cpp:228] Iteration 64900, loss = 0.545072
I0725 23:44:13.347440 22939 solver.cpp:244]     Train net output #0: loss = 0.545072 (* 1 = 0.545072 loss)
I0725 23:44:13.347446 22939 sgd_solver.cpp:106] Iteration 64900, lr = 3.38136e-06
I0725 23:44:22.649376 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_65000.caffemodel
I0725 23:44:22.991029 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_65000.solverstate
I0725 23:44:23.098381 22939 solver.cpp:337] Iteration 65000, Testing net (#0)
I0725 23:44:33.745815 22939 solver.cpp:404]     Test net output #0: accuracy = 0.73875
I0725 23:44:33.745867 22939 solver.cpp:404]     Test net output #1: loss = 0.62838 (* 1 = 0.62838 loss)
I0725 23:44:33.779114 22939 solver.cpp:228] Iteration 65000, loss = 0.579643
I0725 23:44:33.779160 22939 solver.cpp:244]     Train net output #0: loss = 0.579643 (* 1 = 0.579643 loss)
I0725 23:44:33.779181 22939 sgd_solver.cpp:106] Iteration 65000, lr = 3.37838e-06
I0725 23:44:43.176398 22939 solver.cpp:228] Iteration 65100, loss = 0.591214
I0725 23:44:43.176440 22939 solver.cpp:244]     Train net output #0: loss = 0.591214 (* 1 = 0.591214 loss)
I0725 23:44:43.176446 22939 sgd_solver.cpp:106] Iteration 65100, lr = 3.3754e-06
I0725 23:44:52.573669 22939 solver.cpp:228] Iteration 65200, loss = 0.384528
I0725 23:44:52.573724 22939 solver.cpp:244]     Train net output #0: loss = 0.384528 (* 1 = 0.384528 loss)
I0725 23:44:52.573731 22939 sgd_solver.cpp:106] Iteration 65200, lr = 3.37243e-06
I0725 23:45:02.043365 22939 solver.cpp:228] Iteration 65300, loss = 0.530832
I0725 23:45:02.043417 22939 solver.cpp:244]     Train net output #0: loss = 0.530832 (* 1 = 0.530832 loss)
I0725 23:45:02.043436 22939 sgd_solver.cpp:106] Iteration 65300, lr = 3.36946e-06
I0725 23:45:11.560485 22939 solver.cpp:228] Iteration 65400, loss = 0.449069
I0725 23:45:11.560542 22939 solver.cpp:244]     Train net output #0: loss = 0.449069 (* 1 = 0.449069 loss)
I0725 23:45:11.560549 22939 sgd_solver.cpp:106] Iteration 65400, lr = 3.3665e-06
I0725 23:45:20.856792 22939 solver.cpp:337] Iteration 65500, Testing net (#0)
I0725 23:45:31.807023 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742333
I0725 23:45:31.807065 22939 solver.cpp:404]     Test net output #1: loss = 0.624256 (* 1 = 0.624256 loss)
I0725 23:45:31.836658 22939 solver.cpp:228] Iteration 65500, loss = 0.596166
I0725 23:45:31.836720 22939 solver.cpp:244]     Train net output #0: loss = 0.596166 (* 1 = 0.596166 loss)
I0725 23:45:31.836757 22939 sgd_solver.cpp:106] Iteration 65500, lr = 3.36355e-06
I0725 23:45:41.178398 22939 solver.cpp:228] Iteration 65600, loss = 0.447879
I0725 23:45:41.178444 22939 solver.cpp:244]     Train net output #0: loss = 0.447879 (* 1 = 0.447879 loss)
I0725 23:45:41.178450 22939 sgd_solver.cpp:106] Iteration 65600, lr = 3.3606e-06
I0725 23:45:50.578783 22939 solver.cpp:228] Iteration 65700, loss = 0.555799
I0725 23:45:50.578827 22939 solver.cpp:244]     Train net output #0: loss = 0.555799 (* 1 = 0.555799 loss)
I0725 23:45:50.578833 22939 sgd_solver.cpp:106] Iteration 65700, lr = 3.35766e-06
I0725 23:45:59.981603 22939 solver.cpp:228] Iteration 65800, loss = 0.498751
I0725 23:45:59.981643 22939 solver.cpp:244]     Train net output #0: loss = 0.498751 (* 1 = 0.498751 loss)
I0725 23:45:59.981652 22939 sgd_solver.cpp:106] Iteration 65800, lr = 3.35473e-06
I0725 23:46:09.383453 22939 solver.cpp:228] Iteration 65900, loss = 0.394416
I0725 23:46:09.383497 22939 solver.cpp:244]     Train net output #0: loss = 0.394416 (* 1 = 0.394416 loss)
I0725 23:46:09.383503 22939 sgd_solver.cpp:106] Iteration 65900, lr = 3.3518e-06
I0725 23:46:18.694038 22939 solver.cpp:337] Iteration 66000, Testing net (#0)
I0725 23:46:19.387313 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:46:29.602182 22939 solver.cpp:404]     Test net output #0: accuracy = 0.739917
I0725 23:46:29.602227 22939 solver.cpp:404]     Test net output #1: loss = 0.626465 (* 1 = 0.626465 loss)
I0725 23:46:29.629180 22939 solver.cpp:228] Iteration 66000, loss = 0.597826
I0725 23:46:29.629251 22939 solver.cpp:244]     Train net output #0: loss = 0.597826 (* 1 = 0.597826 loss)
I0725 23:46:29.629271 22939 sgd_solver.cpp:106] Iteration 66000, lr = 3.34887e-06
I0725 23:46:38.998025 22939 solver.cpp:228] Iteration 66100, loss = 0.434012
I0725 23:46:38.998072 22939 solver.cpp:244]     Train net output #0: loss = 0.434012 (* 1 = 0.434012 loss)
I0725 23:46:38.998078 22939 sgd_solver.cpp:106] Iteration 66100, lr = 3.34596e-06
I0725 23:46:48.392544 22939 solver.cpp:228] Iteration 66200, loss = 0.452177
I0725 23:46:48.392591 22939 solver.cpp:244]     Train net output #0: loss = 0.452177 (* 1 = 0.452177 loss)
I0725 23:46:48.392598 22939 sgd_solver.cpp:106] Iteration 66200, lr = 3.34304e-06
I0725 23:46:57.786555 22939 solver.cpp:228] Iteration 66300, loss = 0.579341
I0725 23:46:57.786609 22939 solver.cpp:244]     Train net output #0: loss = 0.579341 (* 1 = 0.579341 loss)
I0725 23:46:57.786617 22939 sgd_solver.cpp:106] Iteration 66300, lr = 3.34014e-06
I0725 23:47:07.187602 22939 solver.cpp:228] Iteration 66400, loss = 0.454015
I0725 23:47:07.187662 22939 solver.cpp:244]     Train net output #0: loss = 0.454015 (* 1 = 0.454015 loss)
I0725 23:47:07.187669 22939 sgd_solver.cpp:106] Iteration 66400, lr = 3.33724e-06
I0725 23:47:16.647611 22939 solver.cpp:337] Iteration 66500, Testing net (#0)
I0725 23:47:27.531618 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0725 23:47:27.531669 22939 solver.cpp:404]     Test net output #1: loss = 0.627026 (* 1 = 0.627026 loss)
I0725 23:47:27.561422 22939 solver.cpp:228] Iteration 66500, loss = 0.496971
I0725 23:47:27.561466 22939 solver.cpp:244]     Train net output #0: loss = 0.496971 (* 1 = 0.496971 loss)
I0725 23:47:27.561489 22939 sgd_solver.cpp:106] Iteration 66500, lr = 3.33434e-06
I0725 23:47:36.881916 22939 solver.cpp:228] Iteration 66600, loss = 0.595348
I0725 23:47:36.881958 22939 solver.cpp:244]     Train net output #0: loss = 0.595348 (* 1 = 0.595348 loss)
I0725 23:47:36.881965 22939 sgd_solver.cpp:106] Iteration 66600, lr = 3.33146e-06
I0725 23:47:46.328897 22939 solver.cpp:228] Iteration 66700, loss = 0.579144
I0725 23:47:46.328933 22939 solver.cpp:244]     Train net output #0: loss = 0.579144 (* 1 = 0.579144 loss)
I0725 23:47:46.328938 22939 sgd_solver.cpp:106] Iteration 66700, lr = 3.32857e-06
I0725 23:47:55.879973 22939 solver.cpp:228] Iteration 66800, loss = 0.535249
I0725 23:47:55.880012 22939 solver.cpp:244]     Train net output #0: loss = 0.535249 (* 1 = 0.535249 loss)
I0725 23:47:55.880017 22939 sgd_solver.cpp:106] Iteration 66800, lr = 3.3257e-06
I0725 23:48:05.290328 22939 solver.cpp:228] Iteration 66900, loss = 0.388385
I0725 23:48:05.290361 22939 solver.cpp:244]     Train net output #0: loss = 0.388385 (* 1 = 0.388385 loss)
I0725 23:48:05.290367 22939 sgd_solver.cpp:106] Iteration 66900, lr = 3.32283e-06
I0725 23:48:14.588237 22939 solver.cpp:337] Iteration 67000, Testing net (#0)
I0725 23:48:25.461208 22939 solver.cpp:404]     Test net output #0: accuracy = 0.741833
I0725 23:48:25.461248 22939 solver.cpp:404]     Test net output #1: loss = 0.625481 (* 1 = 0.625481 loss)
I0725 23:48:25.490778 22939 solver.cpp:228] Iteration 67000, loss = 0.456334
I0725 23:48:25.490829 22939 solver.cpp:244]     Train net output #0: loss = 0.456334 (* 1 = 0.456334 loss)
I0725 23:48:25.490845 22939 sgd_solver.cpp:106] Iteration 67000, lr = 3.31996e-06
I0725 23:48:34.860720 22939 solver.cpp:228] Iteration 67100, loss = 0.520156
I0725 23:48:34.860780 22939 solver.cpp:244]     Train net output #0: loss = 0.520156 (* 1 = 0.520156 loss)
I0725 23:48:34.860787 22939 sgd_solver.cpp:106] Iteration 67100, lr = 3.3171e-06
I0725 23:48:44.262161 22939 solver.cpp:228] Iteration 67200, loss = 0.393651
I0725 23:48:44.262199 22939 solver.cpp:244]     Train net output #0: loss = 0.393651 (* 1 = 0.393651 loss)
I0725 23:48:44.262205 22939 sgd_solver.cpp:106] Iteration 67200, lr = 3.31425e-06
I0725 23:48:53.658987 22939 solver.cpp:228] Iteration 67300, loss = 0.540438
I0725 23:48:53.659029 22939 solver.cpp:244]     Train net output #0: loss = 0.540438 (* 1 = 0.540438 loss)
I0725 23:48:53.659035 22939 sgd_solver.cpp:106] Iteration 67300, lr = 3.3114e-06
I0725 23:49:03.149667 22939 solver.cpp:228] Iteration 67400, loss = 0.563257
I0725 23:49:03.149725 22939 solver.cpp:244]     Train net output #0: loss = 0.563257 (* 1 = 0.563257 loss)
I0725 23:49:03.149732 22939 sgd_solver.cpp:106] Iteration 67400, lr = 3.30856e-06
I0725 23:49:12.500389 22939 solver.cpp:337] Iteration 67500, Testing net (#0)
I0725 23:49:23.359455 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743042
I0725 23:49:23.359515 22939 solver.cpp:404]     Test net output #1: loss = 0.626579 (* 1 = 0.626579 loss)
I0725 23:49:23.388994 22939 solver.cpp:228] Iteration 67500, loss = 0.582295
I0725 23:49:23.389025 22939 solver.cpp:244]     Train net output #0: loss = 0.582295 (* 1 = 0.582295 loss)
I0725 23:49:23.389036 22939 sgd_solver.cpp:106] Iteration 67500, lr = 3.30572e-06
I0725 23:49:32.732470 22939 solver.cpp:228] Iteration 67600, loss = 0.4701
I0725 23:49:32.732511 22939 solver.cpp:244]     Train net output #0: loss = 0.4701 (* 1 = 0.4701 loss)
I0725 23:49:32.732517 22939 sgd_solver.cpp:106] Iteration 67600, lr = 3.30289e-06
I0725 23:49:42.119122 22939 solver.cpp:228] Iteration 67700, loss = 0.464119
I0725 23:49:42.119176 22939 solver.cpp:244]     Train net output #0: loss = 0.464119 (* 1 = 0.464119 loss)
I0725 23:49:42.119182 22939 sgd_solver.cpp:106] Iteration 67700, lr = 3.30007e-06
I0725 23:49:51.509924 22939 solver.cpp:228] Iteration 67800, loss = 0.565675
I0725 23:49:51.509981 22939 solver.cpp:244]     Train net output #0: loss = 0.565675 (* 1 = 0.565675 loss)
I0725 23:49:51.509987 22939 sgd_solver.cpp:106] Iteration 67800, lr = 3.29725e-06
I0725 23:50:00.901747 22939 solver.cpp:228] Iteration 67900, loss = 0.624426
I0725 23:50:00.901805 22939 solver.cpp:244]     Train net output #0: loss = 0.624426 (* 1 = 0.624426 loss)
I0725 23:50:00.901813 22939 sgd_solver.cpp:106] Iteration 67900, lr = 3.29443e-06
I0725 23:50:10.200419 22939 solver.cpp:337] Iteration 68000, Testing net (#0)
I0725 23:50:18.277256 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:50:21.053061 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742083
I0725 23:50:21.053108 22939 solver.cpp:404]     Test net output #1: loss = 0.625762 (* 1 = 0.625762 loss)
I0725 23:50:21.081028 22939 solver.cpp:228] Iteration 68000, loss = 0.47286
I0725 23:50:21.081075 22939 solver.cpp:244]     Train net output #0: loss = 0.47286 (* 1 = 0.47286 loss)
I0725 23:50:21.081095 22939 sgd_solver.cpp:106] Iteration 68000, lr = 3.29163e-06
I0725 23:50:30.452894 22939 solver.cpp:228] Iteration 68100, loss = 0.624158
I0725 23:50:30.452936 22939 solver.cpp:244]     Train net output #0: loss = 0.624158 (* 1 = 0.624158 loss)
I0725 23:50:30.452942 22939 sgd_solver.cpp:106] Iteration 68100, lr = 3.28882e-06
I0725 23:50:39.850294 22939 solver.cpp:228] Iteration 68200, loss = 0.576415
I0725 23:50:39.850350 22939 solver.cpp:244]     Train net output #0: loss = 0.576415 (* 1 = 0.576415 loss)
I0725 23:50:39.850356 22939 sgd_solver.cpp:106] Iteration 68200, lr = 3.28603e-06
I0725 23:50:49.246300 22939 solver.cpp:228] Iteration 68300, loss = 0.412561
I0725 23:50:49.246340 22939 solver.cpp:244]     Train net output #0: loss = 0.412561 (* 1 = 0.412561 loss)
I0725 23:50:49.246346 22939 sgd_solver.cpp:106] Iteration 68300, lr = 3.28323e-06
I0725 23:50:58.637186 22939 solver.cpp:228] Iteration 68400, loss = 0.449221
I0725 23:50:58.637243 22939 solver.cpp:244]     Train net output #0: loss = 0.449221 (* 1 = 0.449221 loss)
I0725 23:50:58.637250 22939 sgd_solver.cpp:106] Iteration 68400, lr = 3.28045e-06
I0725 23:51:07.941854 22939 solver.cpp:337] Iteration 68500, Testing net (#0)
I0725 23:51:18.805321 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743833
I0725 23:51:18.805378 22939 solver.cpp:404]     Test net output #1: loss = 0.623402 (* 1 = 0.623402 loss)
I0725 23:51:18.834481 22939 solver.cpp:228] Iteration 68500, loss = 0.52385
I0725 23:51:18.834517 22939 solver.cpp:244]     Train net output #0: loss = 0.52385 (* 1 = 0.52385 loss)
I0725 23:51:18.834530 22939 sgd_solver.cpp:106] Iteration 68500, lr = 3.27767e-06
I0725 23:51:28.234944 22939 solver.cpp:228] Iteration 68600, loss = 0.518827
I0725 23:51:28.234984 22939 solver.cpp:244]     Train net output #0: loss = 0.518827 (* 1 = 0.518827 loss)
I0725 23:51:28.234992 22939 sgd_solver.cpp:106] Iteration 68600, lr = 3.27489e-06
I0725 23:51:37.640200 22939 solver.cpp:228] Iteration 68700, loss = 0.587087
I0725 23:51:37.640249 22939 solver.cpp:244]     Train net output #0: loss = 0.587087 (* 1 = 0.587087 loss)
I0725 23:51:37.640254 22939 sgd_solver.cpp:106] Iteration 68700, lr = 3.27212e-06
I0725 23:51:47.044883 22939 solver.cpp:228] Iteration 68800, loss = 0.565366
I0725 23:51:47.044931 22939 solver.cpp:244]     Train net output #0: loss = 0.565366 (* 1 = 0.565366 loss)
I0725 23:51:47.044939 22939 sgd_solver.cpp:106] Iteration 68800, lr = 3.26936e-06
I0725 23:51:56.448787 22939 solver.cpp:228] Iteration 68900, loss = 0.51211
I0725 23:51:56.448835 22939 solver.cpp:244]     Train net output #0: loss = 0.51211 (* 1 = 0.51211 loss)
I0725 23:51:56.448842 22939 sgd_solver.cpp:106] Iteration 68900, lr = 3.2666e-06
I0725 23:52:05.759217 22939 solver.cpp:337] Iteration 69000, Testing net (#0)
I0725 23:52:16.720110 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74175
I0725 23:52:16.720157 22939 solver.cpp:404]     Test net output #1: loss = 0.626929 (* 1 = 0.626929 loss)
I0725 23:52:16.747634 22939 solver.cpp:228] Iteration 69000, loss = 0.498061
I0725 23:52:16.747699 22939 solver.cpp:244]     Train net output #0: loss = 0.498061 (* 1 = 0.498061 loss)
I0725 23:52:16.747730 22939 sgd_solver.cpp:106] Iteration 69000, lr = 3.26385e-06
I0725 23:52:26.065534 22939 solver.cpp:228] Iteration 69100, loss = 0.606891
I0725 23:52:26.065577 22939 solver.cpp:244]     Train net output #0: loss = 0.606891 (* 1 = 0.606891 loss)
I0725 23:52:26.065583 22939 sgd_solver.cpp:106] Iteration 69100, lr = 3.2611e-06
I0725 23:52:35.462690 22939 solver.cpp:228] Iteration 69200, loss = 0.526961
I0725 23:52:35.462729 22939 solver.cpp:244]     Train net output #0: loss = 0.526961 (* 1 = 0.526961 loss)
I0725 23:52:35.462740 22939 sgd_solver.cpp:106] Iteration 69200, lr = 3.25836e-06
I0725 23:52:44.866892 22939 solver.cpp:228] Iteration 69300, loss = 0.558038
I0725 23:52:44.866932 22939 solver.cpp:244]     Train net output #0: loss = 0.558038 (* 1 = 0.558038 loss)
I0725 23:52:44.866940 22939 sgd_solver.cpp:106] Iteration 69300, lr = 3.25562e-06
I0725 23:52:54.361414 22939 solver.cpp:228] Iteration 69400, loss = 0.672444
I0725 23:52:54.361455 22939 solver.cpp:244]     Train net output #0: loss = 0.672444 (* 1 = 0.672444 loss)
I0725 23:52:54.361461 22939 sgd_solver.cpp:106] Iteration 69400, lr = 3.25289e-06
I0725 23:53:03.783480 22939 solver.cpp:337] Iteration 69500, Testing net (#0)
I0725 23:53:14.698089 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0725 23:53:14.698140 22939 solver.cpp:404]     Test net output #1: loss = 0.621615 (* 1 = 0.621615 loss)
I0725 23:53:14.726001 22939 solver.cpp:228] Iteration 69500, loss = 0.36996
I0725 23:53:14.726058 22939 solver.cpp:244]     Train net output #0: loss = 0.36996 (* 1 = 0.36996 loss)
I0725 23:53:14.726078 22939 sgd_solver.cpp:106] Iteration 69500, lr = 3.25016e-06
I0725 23:53:24.044363 22939 solver.cpp:228] Iteration 69600, loss = 0.501633
I0725 23:53:24.044404 22939 solver.cpp:244]     Train net output #0: loss = 0.501633 (* 1 = 0.501633 loss)
I0725 23:53:24.044411 22939 sgd_solver.cpp:106] Iteration 69600, lr = 3.24744e-06
I0725 23:53:33.573372 22939 solver.cpp:228] Iteration 69700, loss = 0.508643
I0725 23:53:33.573411 22939 solver.cpp:244]     Train net output #0: loss = 0.508643 (* 1 = 0.508643 loss)
I0725 23:53:33.573417 22939 sgd_solver.cpp:106] Iteration 69700, lr = 3.24473e-06
I0725 23:53:43.133299 22939 solver.cpp:228] Iteration 69800, loss = 0.595465
I0725 23:53:43.133322 22939 solver.cpp:244]     Train net output #0: loss = 0.595465 (* 1 = 0.595465 loss)
I0725 23:53:43.133328 22939 sgd_solver.cpp:106] Iteration 69800, lr = 3.24202e-06
I0725 23:53:52.453222 22939 solver.cpp:228] Iteration 69900, loss = 0.504536
I0725 23:53:52.453281 22939 solver.cpp:244]     Train net output #0: loss = 0.504536 (* 1 = 0.504536 loss)
I0725 23:53:52.453287 22939 sgd_solver.cpp:106] Iteration 69900, lr = 3.23931e-06
I0725 23:54:01.751446 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_70000.caffemodel
I0725 23:54:02.100165 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_70000.solverstate
I0725 23:54:02.208983 22939 solver.cpp:337] Iteration 70000, Testing net (#0)
I0725 23:54:12.881727 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742083
I0725 23:54:12.881777 22939 solver.cpp:404]     Test net output #1: loss = 0.625588 (* 1 = 0.625588 loss)
I0725 23:54:12.908748 22939 solver.cpp:228] Iteration 70000, loss = 0.483019
I0725 23:54:12.908807 22939 solver.cpp:244]     Train net output #0: loss = 0.483019 (* 1 = 0.483019 loss)
I0725 23:54:12.908826 22939 sgd_solver.cpp:106] Iteration 70000, lr = 3.23661e-06
I0725 23:54:22.453963 22939 solver.cpp:228] Iteration 70100, loss = 0.455616
I0725 23:54:22.454010 22939 solver.cpp:244]     Train net output #0: loss = 0.455616 (* 1 = 0.455616 loss)
I0725 23:54:22.454015 22939 sgd_solver.cpp:106] Iteration 70100, lr = 3.23392e-06
I0725 23:54:32.025877 22939 solver.cpp:228] Iteration 70200, loss = 0.439288
I0725 23:54:32.025919 22939 solver.cpp:244]     Train net output #0: loss = 0.439288 (* 1 = 0.439288 loss)
I0725 23:54:32.025926 22939 sgd_solver.cpp:106] Iteration 70200, lr = 3.23123e-06
I0725 23:54:41.449487 22939 solver.cpp:228] Iteration 70300, loss = 0.502757
I0725 23:54:41.449543 22939 solver.cpp:244]     Train net output #0: loss = 0.502757 (* 1 = 0.502757 loss)
I0725 23:54:41.449560 22939 sgd_solver.cpp:106] Iteration 70300, lr = 3.22854e-06
I0725 23:54:45.869617 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:54:50.853742 22939 solver.cpp:228] Iteration 70400, loss = 0.542333
I0725 23:54:50.853801 22939 solver.cpp:244]     Train net output #0: loss = 0.542333 (* 1 = 0.542333 loss)
I0725 23:54:50.853806 22939 sgd_solver.cpp:106] Iteration 70400, lr = 3.22586e-06
I0725 23:55:00.171339 22939 solver.cpp:337] Iteration 70500, Testing net (#0)
I0725 23:55:11.097730 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744209
I0725 23:55:11.097790 22939 solver.cpp:404]     Test net output #1: loss = 0.620985 (* 1 = 0.620985 loss)
I0725 23:55:11.130408 22939 solver.cpp:228] Iteration 70500, loss = 0.397842
I0725 23:55:11.130458 22939 solver.cpp:244]     Train net output #0: loss = 0.397842 (* 1 = 0.397842 loss)
I0725 23:55:11.130470 22939 sgd_solver.cpp:106] Iteration 70500, lr = 3.22319e-06
I0725 23:55:20.465240 22939 solver.cpp:228] Iteration 70600, loss = 0.54375
I0725 23:55:20.465276 22939 solver.cpp:244]     Train net output #0: loss = 0.54375 (* 1 = 0.54375 loss)
I0725 23:55:20.465281 22939 sgd_solver.cpp:106] Iteration 70600, lr = 3.22052e-06
I0725 23:55:29.856845 22939 solver.cpp:228] Iteration 70700, loss = 0.432032
I0725 23:55:29.856894 22939 solver.cpp:244]     Train net output #0: loss = 0.432032 (* 1 = 0.432032 loss)
I0725 23:55:29.856899 22939 sgd_solver.cpp:106] Iteration 70700, lr = 3.21786e-06
I0725 23:55:39.315229 22939 solver.cpp:228] Iteration 70800, loss = 0.462757
I0725 23:55:39.315273 22939 solver.cpp:244]     Train net output #0: loss = 0.462757 (* 1 = 0.462757 loss)
I0725 23:55:39.315279 22939 sgd_solver.cpp:106] Iteration 70800, lr = 3.2152e-06
I0725 23:55:48.870970 22939 solver.cpp:228] Iteration 70900, loss = 0.49159
I0725 23:55:48.871012 22939 solver.cpp:244]     Train net output #0: loss = 0.49159 (* 1 = 0.49159 loss)
I0725 23:55:48.871018 22939 sgd_solver.cpp:106] Iteration 70900, lr = 3.21255e-06
I0725 23:55:58.293532 22939 solver.cpp:337] Iteration 71000, Testing net (#0)
I0725 23:56:09.211431 22939 solver.cpp:404]     Test net output #0: accuracy = 0.741958
I0725 23:56:09.211477 22939 solver.cpp:404]     Test net output #1: loss = 0.623 (* 1 = 0.623 loss)
I0725 23:56:09.240557 22939 solver.cpp:228] Iteration 71000, loss = 0.658744
I0725 23:56:09.240597 22939 solver.cpp:244]     Train net output #0: loss = 0.658744 (* 1 = 0.658744 loss)
I0725 23:56:09.240608 22939 sgd_solver.cpp:106] Iteration 71000, lr = 3.2099e-06
I0725 23:56:18.610437 22939 solver.cpp:228] Iteration 71100, loss = 0.440869
I0725 23:56:18.610478 22939 solver.cpp:244]     Train net output #0: loss = 0.440869 (* 1 = 0.440869 loss)
I0725 23:56:18.610486 22939 sgd_solver.cpp:106] Iteration 71100, lr = 3.20726e-06
I0725 23:56:28.009179 22939 solver.cpp:228] Iteration 71200, loss = 0.344545
I0725 23:56:28.009219 22939 solver.cpp:244]     Train net output #0: loss = 0.344545 (* 1 = 0.344545 loss)
I0725 23:56:28.009227 22939 sgd_solver.cpp:106] Iteration 71200, lr = 3.20462e-06
I0725 23:56:37.406852 22939 solver.cpp:228] Iteration 71300, loss = 0.410374
I0725 23:56:37.406890 22939 solver.cpp:244]     Train net output #0: loss = 0.410374 (* 1 = 0.410374 loss)
I0725 23:56:37.406896 22939 sgd_solver.cpp:106] Iteration 71300, lr = 3.20199e-06
I0725 23:56:46.893108 22939 solver.cpp:228] Iteration 71400, loss = 0.498726
I0725 23:56:46.893149 22939 solver.cpp:244]     Train net output #0: loss = 0.498726 (* 1 = 0.498726 loss)
I0725 23:56:46.893156 22939 sgd_solver.cpp:106] Iteration 71400, lr = 3.19936e-06
I0725 23:56:56.351137 22939 solver.cpp:337] Iteration 71500, Testing net (#0)
I0725 23:57:07.271834 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743917
I0725 23:57:07.271888 22939 solver.cpp:404]     Test net output #1: loss = 0.621062 (* 1 = 0.621062 loss)
I0725 23:57:07.300966 22939 solver.cpp:228] Iteration 71500, loss = 0.455283
I0725 23:57:07.301007 22939 solver.cpp:244]     Train net output #0: loss = 0.455283 (* 1 = 0.455283 loss)
I0725 23:57:07.301017 22939 sgd_solver.cpp:106] Iteration 71500, lr = 3.19674e-06
I0725 23:57:16.643373 22939 solver.cpp:228] Iteration 71600, loss = 0.463689
I0725 23:57:16.643420 22939 solver.cpp:244]     Train net output #0: loss = 0.463689 (* 1 = 0.463689 loss)
I0725 23:57:16.643426 22939 sgd_solver.cpp:106] Iteration 71600, lr = 3.19412e-06
I0725 23:57:26.044896 22939 solver.cpp:228] Iteration 71700, loss = 0.46303
I0725 23:57:26.044955 22939 solver.cpp:244]     Train net output #0: loss = 0.46303 (* 1 = 0.46303 loss)
I0725 23:57:26.044961 22939 sgd_solver.cpp:106] Iteration 71700, lr = 3.1915e-06
I0725 23:57:35.446779 22939 solver.cpp:228] Iteration 71800, loss = 0.476615
I0725 23:57:35.446826 22939 solver.cpp:244]     Train net output #0: loss = 0.476615 (* 1 = 0.476615 loss)
I0725 23:57:35.446833 22939 sgd_solver.cpp:106] Iteration 71800, lr = 3.1889e-06
I0725 23:57:44.847206 22939 solver.cpp:228] Iteration 71900, loss = 0.482837
I0725 23:57:44.847244 22939 solver.cpp:244]     Train net output #0: loss = 0.482837 (* 1 = 0.482837 loss)
I0725 23:57:44.847250 22939 sgd_solver.cpp:106] Iteration 71900, lr = 3.18629e-06
I0725 23:57:54.274101 22939 solver.cpp:337] Iteration 72000, Testing net (#0)
I0725 23:58:03.606554 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 23:58:05.263427 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743417
I0725 23:58:05.263481 22939 solver.cpp:404]     Test net output #1: loss = 0.620832 (* 1 = 0.620832 loss)
I0725 23:58:05.293452 22939 solver.cpp:228] Iteration 72000, loss = 0.517298
I0725 23:58:05.293495 22939 solver.cpp:244]     Train net output #0: loss = 0.517298 (* 1 = 0.517298 loss)
I0725 23:58:05.293505 22939 sgd_solver.cpp:106] Iteration 72000, lr = 3.1837e-06
I0725 23:58:14.651820 22939 solver.cpp:228] Iteration 72100, loss = 0.559809
I0725 23:58:14.651876 22939 solver.cpp:244]     Train net output #0: loss = 0.559809 (* 1 = 0.559809 loss)
I0725 23:58:14.651882 22939 sgd_solver.cpp:106] Iteration 72100, lr = 3.1811e-06
I0725 23:58:24.036247 22939 solver.cpp:228] Iteration 72200, loss = 0.465028
I0725 23:58:24.036288 22939 solver.cpp:244]     Train net output #0: loss = 0.465028 (* 1 = 0.465028 loss)
I0725 23:58:24.036293 22939 sgd_solver.cpp:106] Iteration 72200, lr = 3.17852e-06
I0725 23:58:33.422930 22939 solver.cpp:228] Iteration 72300, loss = 0.45133
I0725 23:58:33.422971 22939 solver.cpp:244]     Train net output #0: loss = 0.45133 (* 1 = 0.45133 loss)
I0725 23:58:33.422976 22939 sgd_solver.cpp:106] Iteration 72300, lr = 3.17593e-06
I0725 23:58:42.815459 22939 solver.cpp:228] Iteration 72400, loss = 0.584117
I0725 23:58:42.815479 22939 solver.cpp:244]     Train net output #0: loss = 0.584117 (* 1 = 0.584117 loss)
I0725 23:58:42.815485 22939 sgd_solver.cpp:106] Iteration 72400, lr = 3.17335e-06
I0725 23:58:52.112520 22939 solver.cpp:337] Iteration 72500, Testing net (#0)
I0725 23:59:02.986245 22939 solver.cpp:404]     Test net output #0: accuracy = 0.742625
I0725 23:59:02.986282 22939 solver.cpp:404]     Test net output #1: loss = 0.622591 (* 1 = 0.622591 loss)
I0725 23:59:03.012974 22939 solver.cpp:228] Iteration 72500, loss = 0.531238
I0725 23:59:03.013003 22939 solver.cpp:244]     Train net output #0: loss = 0.531238 (* 1 = 0.531238 loss)
I0725 23:59:03.013011 22939 sgd_solver.cpp:106] Iteration 72500, lr = 3.17078e-06
I0725 23:59:12.403157 22939 solver.cpp:228] Iteration 72600, loss = 0.47873
I0725 23:59:12.403197 22939 solver.cpp:244]     Train net output #0: loss = 0.47873 (* 1 = 0.47873 loss)
I0725 23:59:12.403203 22939 sgd_solver.cpp:106] Iteration 72600, lr = 3.16821e-06
I0725 23:59:21.793603 22939 solver.cpp:228] Iteration 72700, loss = 0.348283
I0725 23:59:21.793645 22939 solver.cpp:244]     Train net output #0: loss = 0.348283 (* 1 = 0.348283 loss)
I0725 23:59:21.793651 22939 sgd_solver.cpp:106] Iteration 72700, lr = 3.16565e-06
I0725 23:59:31.185868 22939 solver.cpp:228] Iteration 72800, loss = 0.556057
I0725 23:59:31.185904 22939 solver.cpp:244]     Train net output #0: loss = 0.556057 (* 1 = 0.556057 loss)
I0725 23:59:31.185910 22939 sgd_solver.cpp:106] Iteration 72800, lr = 3.16309e-06
I0725 23:59:40.579426 22939 solver.cpp:228] Iteration 72900, loss = 0.518227
I0725 23:59:40.579466 22939 solver.cpp:244]     Train net output #0: loss = 0.518227 (* 1 = 0.518227 loss)
I0725 23:59:40.579473 22939 sgd_solver.cpp:106] Iteration 72900, lr = 3.16054e-06
I0725 23:59:49.876147 22939 solver.cpp:337] Iteration 73000, Testing net (#0)
I0726 00:00:00.799469 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744458
I0726 00:00:00.799520 22939 solver.cpp:404]     Test net output #1: loss = 0.618687 (* 1 = 0.618687 loss)
I0726 00:00:00.829040 22939 solver.cpp:228] Iteration 73000, loss = 0.51104
I0726 00:00:00.829088 22939 solver.cpp:244]     Train net output #0: loss = 0.51104 (* 1 = 0.51104 loss)
I0726 00:00:00.829100 22939 sgd_solver.cpp:106] Iteration 73000, lr = 3.15799e-06
I0726 00:00:10.195729 22939 solver.cpp:228] Iteration 73100, loss = 0.482896
I0726 00:00:10.195786 22939 solver.cpp:244]     Train net output #0: loss = 0.482896 (* 1 = 0.482896 loss)
I0726 00:00:10.195792 22939 sgd_solver.cpp:106] Iteration 73100, lr = 3.15544e-06
I0726 00:00:19.596130 22939 solver.cpp:228] Iteration 73200, loss = 0.533731
I0726 00:00:19.596177 22939 solver.cpp:244]     Train net output #0: loss = 0.533731 (* 1 = 0.533731 loss)
I0726 00:00:19.596184 22939 sgd_solver.cpp:106] Iteration 73200, lr = 3.1529e-06
I0726 00:00:28.995033 22939 solver.cpp:228] Iteration 73300, loss = 0.480218
I0726 00:00:28.995081 22939 solver.cpp:244]     Train net output #0: loss = 0.480218 (* 1 = 0.480218 loss)
I0726 00:00:28.995087 22939 sgd_solver.cpp:106] Iteration 73300, lr = 3.15037e-06
nets/person_vs_background_vs_random/solver.prototxt
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0I0726 00:00:38.394850 22939 solver.cpp:228] Iteration 73400, loss = 0.543311
I0726 00:00:38.394901 22939 solver.cpp:244]     Train net output #0: loss = 0.543311 (* 1 = 0.543311 loss)
I0726 00:00:38.394908 22939 sgd_solver.cpp:106] Iteration 73400, lr = 3.14784e-06
I0726 00:00:47.696049 22939 solver.cpp:337] Iteration 73500, Testing net (#0)
I0726 00:00:58.630038 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743042
I0726 00:00:58.630091 22939 solver.cpp:404]     Test net output #1: loss = 0.621623 (* 1 = 0.621623 loss)
I0726 00:00:58.656805 22939 solver.cpp:228] Iteration 73500, loss = 0.522493
I0726 00:00:58.656849 22939 solver.cpp:244]     Train net output #0: loss = 0.522493 (* 1 = 0.522493 loss)
I0726 00:00:58.656860 22939 sgd_solver.cpp:106] Iteration 73500, lr = 3.14531e-06
I0726 00:01:08.043356 22939 solver.cpp:228] Iteration 73600, loss = 0.538381
I0726 00:01:08.043401 22939 solver.cpp:244]     Train net output #0: loss = 0.538381 (* 1 = 0.538381 loss)
I0726 00:01:08.043413 22939 sgd_solver.cpp:106] Iteration 73600, lr = 3.14279e-06
I0726 00:01:17.430914 22939 solver.cpp:228] Iteration 73700, loss = 0.537373
I0726 00:01:17.430961 22939 solver.cpp:244]     Train net output #0: loss = 0.537373 (* 1 = 0.537373 loss)
I0726 00:01:17.430968 22939 sgd_solver.cpp:106] Iteration 73700, lr = 3.14028e-06
I0726 00:01:26.819010 22939 solver.cpp:228] Iteration 73800, loss = 0.478086
I0726 00:01:26.819051 22939 solver.cpp:244]     Train net output #0: loss = 0.478086 (* 1 = 0.478086 loss)
I0726 00:01:26.819057 22939 sgd_solver.cpp:106] Iteration 73800, lr = 3.13776e-06
I0726 00:01:36.204025 22939 solver.cpp:228] Iteration 73900, loss = 0.573938
I0726 00:01:36.204072 22939 solver.cpp:244]     Train net output #0: loss = 0.573938 (* 1 = 0.573938 loss)
I0726 00:01:36.204078 22939 sgd_solver.cpp:106] Iteration 73900, lr = 3.13526e-06
I0726 00:01:45.496215 22939 solver.cpp:337] Iteration 74000, Testing net (#0)
I0726 00:01:50.979720 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:01:56.372334 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74425
I0726 00:01:56.372390 22939 solver.cpp:404]     Test net output #1: loss = 0.619037 (* 1 = 0.619037 loss)
I0726 00:01:56.401713 22939 solver.cpp:228] Iteration 74000, loss = 0.528358
I0726 00:01:56.401763 22939 solver.cpp:244]     Train net output #0: loss = 0.528358 (* 1 = 0.528358 loss)
I0726 00:01:56.401774 22939 sgd_solver.cpp:106] Iteration 74000, lr = 3.13276e-06
I0726 00:02:05.778430 22939 solver.cpp:228] Iteration 74100, loss = 0.469381
I0726 00:02:05.778478 22939 solver.cpp:244]     Train net output #0: loss = 0.469381 (* 1 = 0.469381 loss)
I0726 00:02:05.778484 22939 sgd_solver.cpp:106] Iteration 74100, lr = 3.13026e-06
I0726 00:02:15.166182 22939 solver.cpp:228] Iteration 74200, loss = 0.426175
I0726 00:02:15.166231 22939 solver.cpp:244]     Train net output #0: loss = 0.426175 (* 1 = 0.426175 loss)
I0726 00:02:15.166237 22939 sgd_solver.cpp:106] Iteration 74200, lr = 3.12777e-06
I0726 00:02:24.555414 22939 solver.cpp:228] Iteration 74300, loss = 0.535816
I0726 00:02:24.555464 22939 solver.cpp:244]     Train net output #0: loss = 0.535816 (* 1 = 0.535816 loss)
I0726 00:02:24.555469 22939 sgd_solver.cpp:106] Iteration 74300, lr = 3.12528e-06
I0726 00:02:33.944464 22939 solver.cpp:228] Iteration 74400, loss = 0.442842
I0726 00:02:33.944505 22939 solver.cpp:244]     Train net output #0: loss = 0.442842 (* 1 = 0.442842 loss)
I0726 00:02:33.944511 22939 sgd_solver.cpp:106] Iteration 74400, lr = 3.1228e-06
I0726 00:02:43.242558 22939 solver.cpp:337] Iteration 74500, Testing net (#0)
I0726 00:02:54.091200 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744667
I0726 00:02:54.091255 22939 solver.cpp:404]     Test net output #1: loss = 0.619907 (* 1 = 0.619907 loss)
I0726 00:02:54.121098 22939 solver.cpp:228] Iteration 74500, loss = 0.393367
I0726 00:02:54.121156 22939 solver.cpp:244]     Train net output #0: loss = 0.393367 (* 1 = 0.393367 loss)
I0726 00:02:54.121175 22939 sgd_solver.cpp:106] Iteration 74500, lr = 3.12032e-06
I0726 00:03:03.527668 22939 solver.cpp:228] Iteration 74600, loss = 0.558687
I0726 00:03:03.527714 22939 solver.cpp:244]     Train net output #0: loss = 0.558687 (* 1 = 0.558687 loss)
I0726 00:03:03.527721 22939 sgd_solver.cpp:106] Iteration 74600, lr = 3.11784e-06
I0726 00:03:12.935854 22939 solver.cpp:228] Iteration 74700, loss = 0.554655
I0726 00:03:12.935899 22939 solver.cpp:244]     Train net output #0: loss = 0.554655 (* 1 = 0.554655 loss)
I0726 00:03:12.935904 22939 sgd_solver.cpp:106] Iteration 74700, lr = 3.11537e-06
I0726 00:03:22.334605 22939 solver.cpp:228] Iteration 74800, loss = 0.357073
I0726 00:03:22.334663 22939 solver.cpp:244]     Train net output #0: loss = 0.357073 (* 1 = 0.357073 loss)
I0726 00:03:22.334671 22939 sgd_solver.cpp:106] Iteration 74800, lr = 3.11291e-06
I0726 00:03:31.736244 22939 solver.cpp:228] Iteration 74900, loss = 0.48682
I0726 00:03:31.736294 22939 solver.cpp:244]     Train net output #0: loss = 0.48682 (* 1 = 0.48682 loss)
I0726 00:03:31.736299 22939 sgd_solver.cpp:106] Iteration 74900, lr = 3.11045e-06
I0726 00:03:41.043228 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_75000.caffemodel
I0726 00:03:41.392385 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_75000.solverstate
I0726 00:03:41.501102 22939 solver.cpp:337] Iteration 75000, Testing net (#0)
I0726 00:03:52.139655 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743292
I0726 00:03:52.139699 22939 solver.cpp:404]     Test net output #1: loss = 0.620617 (* 1 = 0.620617 loss)
I0726 00:03:52.166323 22939 solver.cpp:228] Iteration 75000, loss = 0.436982
I0726 00:03:52.166368 22939 solver.cpp:244]     Train net output #0: loss = 0.436982 (* 1 = 0.436982 loss)
I0726 00:03:52.166379 22939 sgd_solver.cpp:106] Iteration 75000, lr = 3.10799e-06
I0726 00:04:01.554194 22939 solver.cpp:228] Iteration 75100, loss = 0.415305
I0726 00:04:01.554240 22939 solver.cpp:244]     Train net output #0: loss = 0.415305 (* 1 = 0.415305 loss)
I0726 00:04:01.554247 22939 sgd_solver.cpp:106] Iteration 75100, lr = 3.10554e-06
I0726 00:04:10.943658 22939 solver.cpp:228] Iteration 75200, loss = 0.461619
I0726 00:04:10.943702 22939 solver.cpp:244]     Train net output #0: loss = 0.461619 (* 1 = 0.461619 loss)
I0726 00:04:10.943708 22939 sgd_solver.cpp:106] Iteration 75200, lr = 3.10309e-06
I0726 00:04:20.337069 22939 solver.cpp:228] Iteration 75300, loss = 0.515988
I0726 00:04:20.337117 22939 solver.cpp:244]     Train net output #0: loss = 0.515988 (* 1 = 0.515988 loss)
I0726 00:04:20.337123 22939 sgd_solver.cpp:106] Iteration 75300, lr = 3.10065e-06
I0726 00:04:29.728497 22939 solver.cpp:228] Iteration 75400, loss = 0.406353
I0726 00:04:29.728535 22939 solver.cpp:244]     Train net output #0: loss = 0.406353 (* 1 = 0.406353 loss)
I0726 00:04:29.728541 22939 sgd_solver.cpp:106] Iteration 75400, lr = 3.09821e-06
I0726 00:04:39.031385 22939 solver.cpp:337] Iteration 75500, Testing net (#0)
I0726 00:04:49.880111 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0726 00:04:49.880173 22939 solver.cpp:404]     Test net output #1: loss = 0.619008 (* 1 = 0.619008 loss)
I0726 00:04:49.912039 22939 solver.cpp:228] Iteration 75500, loss = 0.374842
I0726 00:04:49.912086 22939 solver.cpp:244]     Train net output #0: loss = 0.374842 (* 1 = 0.374842 loss)
I0726 00:04:49.912103 22939 sgd_solver.cpp:106] Iteration 75500, lr = 3.09578e-06
I0726 00:04:59.308959 22939 solver.cpp:228] Iteration 75600, loss = 0.467037
I0726 00:04:59.309010 22939 solver.cpp:244]     Train net output #0: loss = 0.467037 (* 1 = 0.467037 loss)
I0726 00:04:59.309016 22939 sgd_solver.cpp:106] Iteration 75600, lr = 3.09335e-06
I0726 00:05:08.707516 22939 solver.cpp:228] Iteration 75700, loss = 0.551805
I0726 00:05:08.707574 22939 solver.cpp:244]     Train net output #0: loss = 0.551805 (* 1 = 0.551805 loss)
I0726 00:05:08.707581 22939 sgd_solver.cpp:106] Iteration 75700, lr = 3.09093e-06
I0726 00:05:18.099588 22939 solver.cpp:228] Iteration 75800, loss = 0.454543
I0726 00:05:18.099635 22939 solver.cpp:244]     Train net output #0: loss = 0.454543 (* 1 = 0.454543 loss)
I0726 00:05:18.099642 22939 sgd_solver.cpp:106] Iteration 75800, lr = 3.08851e-06
I0726 00:05:27.489822 22939 solver.cpp:228] Iteration 75900, loss = 0.413601
I0726 00:05:27.489864 22939 solver.cpp:244]     Train net output #0: loss = 0.413601 (* 1 = 0.413601 loss)
I0726 00:05:27.489871 22939 sgd_solver.cpp:106] Iteration 75900, lr = 3.08609e-06
I0726 00:05:36.786792 22939 solver.cpp:337] Iteration 76000, Testing net (#0)
I0726 00:05:37.784798 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:05:47.754648 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744583
I0726 00:05:47.754700 22939 solver.cpp:404]     Test net output #1: loss = 0.619608 (* 1 = 0.619608 loss)
I0726 00:05:47.784238 22939 solver.cpp:228] Iteration 76000, loss = 0.430969
I0726 00:05:47.784266 22939 solver.cpp:244]     Train net output #0: loss = 0.430969 (* 1 = 0.430969 loss)
I0726 00:05:47.784277 22939 sgd_solver.cpp:106] Iteration 76000, lr = 3.08368e-06
I0726 00:05:57.183286 22939 solver.cpp:228] Iteration 76100, loss = 0.525708
I0726 00:05:57.183331 22939 solver.cpp:244]     Train net output #0: loss = 0.525708 (* 1 = 0.525708 loss)
I0726 00:05:57.183336 22939 sgd_solver.cpp:106] Iteration 76100, lr = 3.08127e-06
I0726 00:06:06.592789 22939 solver.cpp:228] Iteration 76200, loss = 0.506978
I0726 00:06:06.592859 22939 solver.cpp:244]     Train net output #0: loss = 0.506978 (* 1 = 0.506978 loss)
I0726 00:06:06.592869 22939 sgd_solver.cpp:106] Iteration 76200, lr = 3.07887e-06
I0726 00:06:15.996784 22939 solver.cpp:228] Iteration 76300, loss = 0.531676
I0726 00:06:15.996827 22939 solver.cpp:244]     Train net output #0: loss = 0.531676 (* 1 = 0.531676 loss)
I0726 00:06:15.996834 22939 sgd_solver.cpp:106] Iteration 76300, lr = 3.07647e-06
I0726 00:06:25.397882 22939 solver.cpp:228] Iteration 76400, loss = 0.499852
I0726 00:06:25.397927 22939 solver.cpp:244]     Train net output #0: loss = 0.499852 (* 1 = 0.499852 loss)
I0726 00:06:25.397933 22939 sgd_solver.cpp:106] Iteration 76400, lr = 3.07408e-06
I0726 00:06:34.702136 22939 solver.cpp:337] Iteration 76500, Testing net (#0)
I0726 00:06:45.598814 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745625
I0726 00:06:45.598852 22939 solver.cpp:404]     Test net output #1: loss = 0.619451 (* 1 = 0.619451 loss)
I0726 00:06:45.628324 22939 solver.cpp:228] Iteration 76500, loss = 0.36398
I0726 00:06:45.628366 22939 solver.cpp:244]     Train net output #0: loss = 0.36398 (* 1 = 0.36398 loss)
I0726 00:06:45.628376 22939 sgd_solver.cpp:106] Iteration 76500, lr = 3.07169e-06
I0726 00:06:55.018275 22939 solver.cpp:228] Iteration 76600, loss = 0.484221
I0726 00:06:55.018331 22939 solver.cpp:244]     Train net output #0: loss = 0.484221 (* 1 = 0.484221 loss)
I0726 00:06:55.018337 22939 sgd_solver.cpp:106] Iteration 76600, lr = 3.0693e-06
I0726 00:07:04.407567 22939 solver.cpp:228] Iteration 76700, loss = 0.455123
I0726 00:07:04.407605 22939 solver.cpp:244]     Train net output #0: loss = 0.455123 (* 1 = 0.455123 loss)
I0726 00:07:04.407611 22939 sgd_solver.cpp:106] Iteration 76700, lr = 3.06692e-06
I0726 00:07:13.797610 22939 solver.cpp:228] Iteration 76800, loss = 0.413714
I0726 00:07:13.797654 22939 solver.cpp:244]     Train net output #0: loss = 0.413714 (* 1 = 0.413714 loss)
I0726 00:07:13.797660 22939 sgd_solver.cpp:106] Iteration 76800, lr = 3.06454e-06
I0726 00:07:23.188293 22939 solver.cpp:228] Iteration 76900, loss = 0.541951
I0726 00:07:23.188340 22939 solver.cpp:244]     Train net output #0: loss = 0.541951 (* 1 = 0.541951 loss)
I0726 00:07:23.188346 22939 sgd_solver.cpp:106] Iteration 76900, lr = 3.06217e-06
I0726 00:07:32.486611 22939 solver.cpp:337] Iteration 77000, Testing net (#0)
I0726 00:07:43.333076 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745083
I0726 00:07:43.333127 22939 solver.cpp:404]     Test net output #1: loss = 0.618825 (* 1 = 0.618825 loss)
I0726 00:07:43.360023 22939 solver.cpp:228] Iteration 77000, loss = 0.330142
I0726 00:07:43.360075 22939 solver.cpp:244]     Train net output #0: loss = 0.330142 (* 1 = 0.330142 loss)
I0726 00:07:43.360087 22939 sgd_solver.cpp:106] Iteration 77000, lr = 3.0598e-06
I0726 00:07:52.753186 22939 solver.cpp:228] Iteration 77100, loss = 0.694929
I0726 00:07:52.753233 22939 solver.cpp:244]     Train net output #0: loss = 0.694929 (* 1 = 0.694929 loss)
I0726 00:07:52.753239 22939 sgd_solver.cpp:106] Iteration 77100, lr = 3.05744e-06
I0726 00:08:02.149515 22939 solver.cpp:228] Iteration 77200, loss = 0.496928
I0726 00:08:02.149556 22939 solver.cpp:244]     Train net output #0: loss = 0.496928 (* 1 = 0.496928 loss)
I0726 00:08:02.149562 22939 sgd_solver.cpp:106] Iteration 77200, lr = 3.05508e-06
I0726 00:08:11.540946 22939 solver.cpp:228] Iteration 77300, loss = 0.461997
I0726 00:08:11.540987 22939 solver.cpp:244]     Train net output #0: loss = 0.461997 (* 1 = 0.461997 loss)
I0726 00:08:11.540993 22939 sgd_solver.cpp:106] Iteration 77300, lr = 3.05273e-06
I0726 00:08:20.932428 22939 solver.cpp:228] Iteration 77400, loss = 0.439357
I0726 00:08:20.932466 22939 solver.cpp:244]     Train net output #0: loss = 0.439357 (* 1 = 0.439357 loss)
I0726 00:08:20.932471 22939 sgd_solver.cpp:106] Iteration 77400, lr = 3.05038e-06
I0726 00:08:30.228988 22939 solver.cpp:337] Iteration 77500, Testing net (#0)
I0726 00:08:41.207545 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743792
I0726 00:08:41.207590 22939 solver.cpp:404]     Test net output #1: loss = 0.622142 (* 1 = 0.622142 loss)
I0726 00:08:41.237064 22939 solver.cpp:228] Iteration 77500, loss = 0.508214
I0726 00:08:41.237097 22939 solver.cpp:244]     Train net output #0: loss = 0.508214 (* 1 = 0.508214 loss)
I0726 00:08:41.237112 22939 sgd_solver.cpp:106] Iteration 77500, lr = 3.04803e-06
I0726 00:08:50.605418 22939 solver.cpp:228] Iteration 77600, loss = 0.384937
I0726 00:08:50.605458 22939 solver.cpp:244]     Train net output #0: loss = 0.384937 (* 1 = 0.384937 loss)
I0726 00:08:50.605468 22939 sgd_solver.cpp:106] Iteration 77600, lr = 3.04569e-06
I0726 00:09:00.005368 22939 solver.cpp:228] Iteration 77700, loss = 0.488655
I0726 00:09:00.005411 22939 solver.cpp:244]     Train net output #0: loss = 0.488655 (* 1 = 0.488655 loss)
I0726 00:09:00.005420 22939 sgd_solver.cpp:106] Iteration 77700, lr = 3.04335e-06
I0726 00:09:09.409173 22939 solver.cpp:228] Iteration 77800, loss = 0.60042
I0726 00:09:09.409212 22939 solver.cpp:244]     Train net output #0: loss = 0.60042 (* 1 = 0.60042 loss)
I0726 00:09:09.409220 22939 sgd_solver.cpp:106] Iteration 77800, lr = 3.04101e-06
I0726 00:09:18.813159 22939 solver.cpp:228] Iteration 77900, loss = 0.431615
I0726 00:09:18.813202 22939 solver.cpp:244]     Train net output #0: loss = 0.431615 (* 1 = 0.431615 loss)
I0726 00:09:18.813211 22939 sgd_solver.cpp:106] Iteration 77900, lr = 3.03868e-06
I0726 00:09:28.119716 22939 solver.cpp:337] Iteration 78000, Testing net (#0)
I0726 00:09:28.448786 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:09:39.014379 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74475
I0726 00:09:39.014426 22939 solver.cpp:404]     Test net output #1: loss = 0.618972 (* 1 = 0.618972 loss)
I0726 00:09:39.041224 22939 solver.cpp:228] Iteration 78000, loss = 0.423598
I0726 00:09:39.041275 22939 solver.cpp:244]     Train net output #0: loss = 0.423598 (* 1 = 0.423598 loss)
I0726 00:09:39.041297 22939 sgd_solver.cpp:106] Iteration 78000, lr = 3.03636e-06
I0726 00:09:48.434110 22939 solver.cpp:228] Iteration 78100, loss = 0.610049
I0726 00:09:48.434155 22939 solver.cpp:244]     Train net output #0: loss = 0.610049 (* 1 = 0.610049 loss)
I0726 00:09:48.434161 22939 sgd_solver.cpp:106] Iteration 78100, lr = 3.03404e-06
I0726 00:09:57.822441 22939 solver.cpp:228] Iteration 78200, loss = 0.646036
I0726 00:09:57.822484 22939 solver.cpp:244]     Train net output #0: loss = 0.646036 (* 1 = 0.646036 loss)
I0726 00:09:57.822490 22939 sgd_solver.cpp:106] Iteration 78200, lr = 3.03172e-06
I0726 00:10:07.209106 22939 solver.cpp:228] Iteration 78300, loss = 0.594297
I0726 00:10:07.209161 22939 solver.cpp:244]     Train net output #0: loss = 0.594297 (* 1 = 0.594297 loss)
I0726 00:10:07.209168 22939 sgd_solver.cpp:106] Iteration 78300, lr = 3.0294e-06
I0726 00:10:16.599812 22939 solver.cpp:228] Iteration 78400, loss = 0.533256
I0726 00:10:16.599854 22939 solver.cpp:244]     Train net output #0: loss = 0.533256 (* 1 = 0.533256 loss)
I0726 00:10:16.599860 22939 sgd_solver.cpp:106] Iteration 78400, lr = 3.0271e-06
I0726 00:10:25.895869 22939 solver.cpp:337] Iteration 78500, Testing net (#0)
I0726 00:10:36.794910 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743042
I0726 00:10:36.794957 22939 solver.cpp:404]     Test net output #1: loss = 0.624515 (* 1 = 0.624515 loss)
I0726 00:10:36.824108 22939 solver.cpp:228] Iteration 78500, loss = 0.354073
I0726 00:10:36.824167 22939 solver.cpp:244]     Train net output #0: loss = 0.354073 (* 1 = 0.354073 loss)
I0726 00:10:36.824179 22939 sgd_solver.cpp:106] Iteration 78500, lr = 3.02479e-06
I0726 00:10:46.121443 22939 solver.cpp:228] Iteration 78600, loss = 0.479941
I0726 00:10:46.121487 22939 solver.cpp:244]     Train net output #0: loss = 0.479941 (* 1 = 0.479941 loss)
I0726 00:10:46.121493 22939 sgd_solver.cpp:106] Iteration 78600, lr = 3.02249e-06
I0726 00:10:55.515723 22939 solver.cpp:228] Iteration 78700, loss = 0.532787
I0726 00:10:55.515777 22939 solver.cpp:244]     Train net output #0: loss = 0.532787 (* 1 = 0.532787 loss)
I0726 00:10:55.515784 22939 sgd_solver.cpp:106] Iteration 78700, lr = 3.02019e-06
I0726 00:11:05.065170 22939 solver.cpp:228] Iteration 78800, loss = 0.420619
I0726 00:11:05.065207 22939 solver.cpp:244]     Train net output #0: loss = 0.420619 (* 1 = 0.420619 loss)
I0726 00:11:05.065213 22939 sgd_solver.cpp:106] Iteration 78800, lr = 3.0179e-06
I0726 00:11:14.580163 22939 solver.cpp:228] Iteration 78900, loss = 0.526047
I0726 00:11:14.580211 22939 solver.cpp:244]     Train net output #0: loss = 0.526047 (* 1 = 0.526047 loss)
I0726 00:11:14.580217 22939 sgd_solver.cpp:106] Iteration 78900, lr = 3.01561e-06
I0726 00:11:23.883307 22939 solver.cpp:337] Iteration 79000, Testing net (#0)
I0726 00:11:34.767130 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744833
I0726 00:11:34.767192 22939 solver.cpp:404]     Test net output #1: loss = 0.620287 (* 1 = 0.620287 loss)
I0726 00:11:34.800003 22939 solver.cpp:228] Iteration 79000, loss = 0.466027
I0726 00:11:34.800048 22939 solver.cpp:244]     Train net output #0: loss = 0.466027 (* 1 = 0.466027 loss)
I0726 00:11:34.800070 22939 sgd_solver.cpp:106] Iteration 79000, lr = 3.01333e-06
I0726 00:11:44.191275 22939 solver.cpp:228] Iteration 79100, loss = 0.344334
I0726 00:11:44.191318 22939 solver.cpp:244]     Train net output #0: loss = 0.344334 (* 1 = 0.344334 loss)
I0726 00:11:44.191324 22939 sgd_solver.cpp:106] Iteration 79100, lr = 3.01105e-06
I0726 00:11:53.588645 22939 solver.cpp:228] Iteration 79200, loss = 0.408142
I0726 00:11:53.588687 22939 solver.cpp:244]     Train net output #0: loss = 0.408142 (* 1 = 0.408142 loss)
I0726 00:11:53.588693 22939 sgd_solver.cpp:106] Iteration 79200, lr = 3.00877e-06
I0726 00:12:02.987699 22939 solver.cpp:228] Iteration 79300, loss = 0.490868
I0726 00:12:02.987736 22939 solver.cpp:244]     Train net output #0: loss = 0.490868 (* 1 = 0.490868 loss)
I0726 00:12:02.987742 22939 sgd_solver.cpp:106] Iteration 79300, lr = 3.0065e-06
I0726 00:12:12.388835 22939 solver.cpp:228] Iteration 79400, loss = 0.377347
I0726 00:12:12.388880 22939 solver.cpp:244]     Train net output #0: loss = 0.377347 (* 1 = 0.377347 loss)
I0726 00:12:12.388886 22939 sgd_solver.cpp:106] Iteration 79400, lr = 3.00423e-06
I0726 00:12:21.697690 22939 solver.cpp:337] Iteration 79500, Testing net (#0)
I0726 00:12:32.496520 22939 solver.cpp:404]     Test net output #0: accuracy = 0.7435
I0726 00:12:32.496568 22939 solver.cpp:404]     Test net output #1: loss = 0.623034 (* 1 = 0.623034 loss)
I0726 00:12:32.523365 22939 solver.cpp:228] Iteration 79500, loss = 0.485404
I0726 00:12:32.523432 22939 solver.cpp:244]     Train net output #0: loss = 0.485404 (* 1 = 0.485404 loss)
I0726 00:12:32.523457 22939 sgd_solver.cpp:106] Iteration 79500, lr = 3.00196e-06
I0726 00:12:40.690062 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:12:41.909996 22939 solver.cpp:228] Iteration 79600, loss = 0.518231
I0726 00:12:41.910025 22939 solver.cpp:244]     Train net output #0: loss = 0.518231 (* 1 = 0.518231 loss)
I0726 00:12:41.910032 22939 sgd_solver.cpp:106] Iteration 79600, lr = 2.9997e-06
I0726 00:12:51.326362 22939 solver.cpp:228] Iteration 79700, loss = 0.527071
I0726 00:12:51.326411 22939 solver.cpp:244]     Train net output #0: loss = 0.527071 (* 1 = 0.527071 loss)
I0726 00:12:51.326417 22939 sgd_solver.cpp:106] Iteration 79700, lr = 2.99744e-06
I0726 00:13:00.880513 22939 solver.cpp:228] Iteration 79800, loss = 0.456937
I0726 00:13:00.880555 22939 solver.cpp:244]     Train net output #0: loss = 0.456937 (* 1 = 0.456937 loss)
I0726 00:13:00.880561 22939 sgd_solver.cpp:106] Iteration 79800, lr = 2.99519e-06
I0726 00:13:10.403578 22939 solver.cpp:228] Iteration 79900, loss = 0.44821
I0726 00:13:10.403625 22939 solver.cpp:244]     Train net output #0: loss = 0.44821 (* 1 = 0.44821 loss)
I0726 00:13:10.403632 22939 sgd_solver.cpp:106] Iteration 79900, lr = 2.99294e-06
I0726 00:13:19.700626 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_80000.caffemodel
I0726 00:13:20.046883 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_80000.solverstate
I0726 00:13:20.154116 22939 solver.cpp:337] Iteration 80000, Testing net (#0)
I0726 00:13:30.791388 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74375
I0726 00:13:30.791447 22939 solver.cpp:404]     Test net output #1: loss = 0.62265 (* 1 = 0.62265 loss)
I0726 00:13:30.818096 22939 solver.cpp:228] Iteration 80000, loss = 0.549746
I0726 00:13:30.818141 22939 solver.cpp:244]     Train net output #0: loss = 0.549746 (* 1 = 0.549746 loss)
I0726 00:13:30.818163 22939 sgd_solver.cpp:106] Iteration 80000, lr = 2.9907e-06
I0726 00:13:40.190637 22939 solver.cpp:228] Iteration 80100, loss = 0.438907
I0726 00:13:40.190685 22939 solver.cpp:244]     Train net output #0: loss = 0.438907 (* 1 = 0.438907 loss)
I0726 00:13:40.190691 22939 sgd_solver.cpp:106] Iteration 80100, lr = 2.98846e-06
I0726 00:13:49.580446 22939 solver.cpp:228] Iteration 80200, loss = 0.437655
I0726 00:13:49.580487 22939 solver.cpp:244]     Train net output #0: loss = 0.437655 (* 1 = 0.437655 loss)
I0726 00:13:49.580492 22939 sgd_solver.cpp:106] Iteration 80200, lr = 2.98622e-06
I0726 00:13:58.966909 22939 solver.cpp:228] Iteration 80300, loss = 0.420086
I0726 00:13:58.966948 22939 solver.cpp:244]     Train net output #0: loss = 0.420086 (* 1 = 0.420086 loss)
I0726 00:13:58.966953 22939 sgd_solver.cpp:106] Iteration 80300, lr = 2.98399e-06
I0726 00:14:08.356768 22939 solver.cpp:228] Iteration 80400, loss = 0.51439
I0726 00:14:08.356809 22939 solver.cpp:244]     Train net output #0: loss = 0.51439 (* 1 = 0.51439 loss)
I0726 00:14:08.356815 22939 sgd_solver.cpp:106] Iteration 80400, lr = 2.98176e-06
I0726 00:14:17.653658 22939 solver.cpp:337] Iteration 80500, Testing net (#0)
I0726 00:14:28.522759 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743417
I0726 00:14:28.522806 22939 solver.cpp:404]     Test net output #1: loss = 0.623925 (* 1 = 0.623925 loss)
I0726 00:14:28.552181 22939 solver.cpp:228] Iteration 80500, loss = 0.516702
I0726 00:14:28.552234 22939 solver.cpp:244]     Train net output #0: loss = 0.516702 (* 1 = 0.516702 loss)
I0726 00:14:28.552245 22939 sgd_solver.cpp:106] Iteration 80500, lr = 2.97953e-06
I0726 00:14:37.944485 22939 solver.cpp:228] Iteration 80600, loss = 0.449889
I0726 00:14:37.944540 22939 solver.cpp:244]     Train net output #0: loss = 0.449889 (* 1 = 0.449889 loss)
I0726 00:14:37.944547 22939 sgd_solver.cpp:106] Iteration 80600, lr = 2.97731e-06
I0726 00:14:47.344501 22939 solver.cpp:228] Iteration 80700, loss = 0.45509
I0726 00:14:47.344542 22939 solver.cpp:244]     Train net output #0: loss = 0.45509 (* 1 = 0.45509 loss)
I0726 00:14:47.344547 22939 sgd_solver.cpp:106] Iteration 80700, lr = 2.97509e-06
I0726 00:14:56.741133 22939 solver.cpp:228] Iteration 80800, loss = 0.379461
I0726 00:14:56.741185 22939 solver.cpp:244]     Train net output #0: loss = 0.379461 (* 1 = 0.379461 loss)
I0726 00:14:56.741192 22939 sgd_solver.cpp:106] Iteration 80800, lr = 2.97288e-06
I0726 00:15:06.135222 22939 solver.cpp:228] Iteration 80900, loss = 0.544479
I0726 00:15:06.135259 22939 solver.cpp:244]     Train net output #0: loss = 0.544479 (* 1 = 0.544479 loss)
I0726 00:15:06.135265 22939 sgd_solver.cpp:106] Iteration 80900, lr = 2.97067e-06
I0726 00:15:15.437090 22939 solver.cpp:337] Iteration 81000, Testing net (#0)
I0726 00:15:26.374119 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744292
I0726 00:15:26.374171 22939 solver.cpp:404]     Test net output #1: loss = 0.622122 (* 1 = 0.622122 loss)
I0726 00:15:26.400741 22939 solver.cpp:228] Iteration 81000, loss = 0.43905
I0726 00:15:26.400784 22939 solver.cpp:244]     Train net output #0: loss = 0.43905 (* 1 = 0.43905 loss)
I0726 00:15:26.400794 22939 sgd_solver.cpp:106] Iteration 81000, lr = 2.96846e-06
I0726 00:15:35.759778 22939 solver.cpp:228] Iteration 81100, loss = 0.460558
I0726 00:15:35.759824 22939 solver.cpp:244]     Train net output #0: loss = 0.460558 (* 1 = 0.460558 loss)
I0726 00:15:35.759832 22939 sgd_solver.cpp:106] Iteration 81100, lr = 2.96626e-06
I0726 00:15:45.152231 22939 solver.cpp:228] Iteration 81200, loss = 0.505803
I0726 00:15:45.152287 22939 solver.cpp:244]     Train net output #0: loss = 0.505803 (* 1 = 0.505803 loss)
I0726 00:15:45.152294 22939 sgd_solver.cpp:106] Iteration 81200, lr = 2.96406e-06
I0726 00:15:54.542881 22939 solver.cpp:228] Iteration 81300, loss = 0.322308
I0726 00:15:54.542943 22939 solver.cpp:244]     Train net output #0: loss = 0.322308 (* 1 = 0.322308 loss)
I0726 00:15:54.542949 22939 sgd_solver.cpp:106] Iteration 81300, lr = 2.96187e-06
I0726 00:16:03.930594 22939 solver.cpp:228] Iteration 81400, loss = 0.558279
I0726 00:16:03.930646 22939 solver.cpp:244]     Train net output #0: loss = 0.558279 (* 1 = 0.558279 loss)
I0726 00:16:03.930654 22939 sgd_solver.cpp:106] Iteration 81400, lr = 2.95968e-06
I0726 00:16:13.222599 22939 solver.cpp:337] Iteration 81500, Testing net (#0)
I0726 00:16:22.594519 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:16:24.077116 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744333
I0726 00:16:24.077144 22939 solver.cpp:404]     Test net output #1: loss = 0.621823 (* 1 = 0.621823 loss)
I0726 00:16:24.106506 22939 solver.cpp:228] Iteration 81500, loss = 0.459773
I0726 00:16:24.106554 22939 solver.cpp:244]     Train net output #0: loss = 0.459773 (* 1 = 0.459773 loss)
I0726 00:16:24.106564 22939 sgd_solver.cpp:106] Iteration 81500, lr = 2.95749e-06
I0726 00:16:33.470865 22939 solver.cpp:228] Iteration 81600, loss = 0.419418
I0726 00:16:33.470916 22939 solver.cpp:244]     Train net output #0: loss = 0.419418 (* 1 = 0.419418 loss)
I0726 00:16:33.470922 22939 sgd_solver.cpp:106] Iteration 81600, lr = 2.9553e-06
I0726 00:16:43.004279 22939 solver.cpp:228] Iteration 81700, loss = 0.506457
I0726 00:16:43.004333 22939 solver.cpp:244]     Train net output #0: loss = 0.506457 (* 1 = 0.506457 loss)
I0726 00:16:43.004340 22939 sgd_solver.cpp:106] Iteration 81700, lr = 2.95312e-06
I0726 00:16:52.495991 22939 solver.cpp:228] Iteration 81800, loss = 0.404543
I0726 00:16:52.496042 22939 solver.cpp:244]     Train net output #0: loss = 0.404543 (* 1 = 0.404543 loss)
I0726 00:16:52.496048 22939 sgd_solver.cpp:106] Iteration 81800, lr = 2.95095e-06
I0726 00:17:01.883863 22939 solver.cpp:228] Iteration 81900, loss = 0.441885
I0726 00:17:01.883901 22939 solver.cpp:244]     Train net output #0: loss = 0.441885 (* 1 = 0.441885 loss)
I0726 00:17:01.883908 22939 sgd_solver.cpp:106] Iteration 81900, lr = 2.94878e-06
I0726 00:17:11.180595 22939 solver.cpp:337] Iteration 82000, Testing net (#0)
I0726 00:17:22.067242 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743833
I0726 00:17:22.067284 22939 solver.cpp:404]     Test net output #1: loss = 0.620501 (* 1 = 0.620501 loss)
I0726 00:17:22.095113 22939 solver.cpp:228] Iteration 82000, loss = 0.51729
I0726 00:17:22.095177 22939 solver.cpp:244]     Train net output #0: loss = 0.51729 (* 1 = 0.51729 loss)
I0726 00:17:22.095197 22939 sgd_solver.cpp:106] Iteration 82000, lr = 2.94661e-06
I0726 00:17:31.424762 22939 solver.cpp:228] Iteration 82100, loss = 0.55056
I0726 00:17:31.424801 22939 solver.cpp:244]     Train net output #0: loss = 0.55056 (* 1 = 0.55056 loss)
I0726 00:17:31.424808 22939 sgd_solver.cpp:106] Iteration 82100, lr = 2.94444e-06
I0726 00:17:40.827033 22939 solver.cpp:228] Iteration 82200, loss = 0.397275
I0726 00:17:40.827075 22939 solver.cpp:244]     Train net output #0: loss = 0.397275 (* 1 = 0.397275 loss)
I0726 00:17:40.827080 22939 sgd_solver.cpp:106] Iteration 82200, lr = 2.94228e-06
I0726 00:17:50.228633 22939 solver.cpp:228] Iteration 82300, loss = 0.411848
I0726 00:17:50.228680 22939 solver.cpp:244]     Train net output #0: loss = 0.411848 (* 1 = 0.411848 loss)
I0726 00:17:50.228688 22939 sgd_solver.cpp:106] Iteration 82300, lr = 2.94012e-06
I0726 00:17:59.628309 22939 solver.cpp:228] Iteration 82400, loss = 0.579702
I0726 00:17:59.628352 22939 solver.cpp:244]     Train net output #0: loss = 0.579702 (* 1 = 0.579702 loss)
I0726 00:17:59.628358 22939 sgd_solver.cpp:106] Iteration 82400, lr = 2.93797e-06
I0726 00:18:08.933181 22939 solver.cpp:337] Iteration 82500, Testing net (#0)
I0726 00:18:19.820122 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745625
I0726 00:18:19.820173 22939 solver.cpp:404]     Test net output #1: loss = 0.618803 (* 1 = 0.618803 loss)
I0726 00:18:19.849725 22939 solver.cpp:228] Iteration 82500, loss = 0.637927
I0726 00:18:19.849767 22939 solver.cpp:244]     Train net output #0: loss = 0.637927 (* 1 = 0.637927 loss)
I0726 00:18:19.849788 22939 sgd_solver.cpp:106] Iteration 82500, lr = 2.93582e-06
I0726 00:18:29.226475 22939 solver.cpp:228] Iteration 82600, loss = 0.492281
I0726 00:18:29.226517 22939 solver.cpp:244]     Train net output #0: loss = 0.492281 (* 1 = 0.492281 loss)
I0726 00:18:29.226523 22939 sgd_solver.cpp:106] Iteration 82600, lr = 2.93367e-06
I0726 00:18:38.615111 22939 solver.cpp:228] Iteration 82700, loss = 0.540435
I0726 00:18:38.615156 22939 solver.cpp:244]     Train net output #0: loss = 0.540435 (* 1 = 0.540435 loss)
I0726 00:18:38.615161 22939 sgd_solver.cpp:106] Iteration 82700, lr = 2.93153e-06
I0726 00:18:48.003515 22939 solver.cpp:228] Iteration 82800, loss = 0.298749
I0726 00:18:48.003561 22939 solver.cpp:244]     Train net output #0: loss = 0.298749 (* 1 = 0.298749 loss)
I0726 00:18:48.003567 22939 sgd_solver.cpp:106] Iteration 82800, lr = 2.92939e-06
I0726 00:18:57.393110 22939 solver.cpp:228] Iteration 82900, loss = 0.434844
I0726 00:18:57.393157 22939 solver.cpp:244]     Train net output #0: loss = 0.434844 (* 1 = 0.434844 loss)
I0726 00:18:57.393162 22939 sgd_solver.cpp:106] Iteration 82900, lr = 2.92726e-06
I0726 00:19:06.697638 22939 solver.cpp:337] Iteration 83000, Testing net (#0)
I0726 00:19:17.533619 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744583
I0726 00:19:17.533674 22939 solver.cpp:404]     Test net output #1: loss = 0.619045 (* 1 = 0.619045 loss)
I0726 00:19:17.563206 22939 solver.cpp:228] Iteration 83000, loss = 0.589054
I0726 00:19:17.563251 22939 solver.cpp:244]     Train net output #0: loss = 0.589054 (* 1 = 0.589054 loss)
I0726 00:19:17.563261 22939 sgd_solver.cpp:106] Iteration 83000, lr = 2.92513e-06
I0726 00:19:26.954177 22939 solver.cpp:228] Iteration 83100, loss = 0.46779
I0726 00:19:26.954226 22939 solver.cpp:244]     Train net output #0: loss = 0.46779 (* 1 = 0.46779 loss)
I0726 00:19:26.954232 22939 sgd_solver.cpp:106] Iteration 83100, lr = 2.923e-06
I0726 00:19:36.343564 22939 solver.cpp:228] Iteration 83200, loss = 0.496332
I0726 00:19:36.343623 22939 solver.cpp:244]     Train net output #0: loss = 0.496332 (* 1 = 0.496332 loss)
I0726 00:19:36.343631 22939 sgd_solver.cpp:106] Iteration 83200, lr = 2.92087e-06
I0726 00:19:45.734519 22939 solver.cpp:228] Iteration 83300, loss = 0.439509
I0726 00:19:45.734563 22939 solver.cpp:244]     Train net output #0: loss = 0.439509 (* 1 = 0.439509 loss)
I0726 00:19:45.734570 22939 sgd_solver.cpp:106] Iteration 83300, lr = 2.91875e-06
I0726 00:19:55.123558 22939 solver.cpp:228] Iteration 83400, loss = 0.370359
I0726 00:19:55.123601 22939 solver.cpp:244]     Train net output #0: loss = 0.370359 (* 1 = 0.370359 loss)
I0726 00:19:55.123607 22939 sgd_solver.cpp:106] Iteration 83400, lr = 2.91663e-06
I0726 00:20:04.424209 22939 solver.cpp:337] Iteration 83500, Testing net (#0)
I0726 00:20:09.615072 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:20:15.259994 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746875
I0726 00:20:15.260048 22939 solver.cpp:404]     Test net output #1: loss = 0.617032 (* 1 = 0.617032 loss)
I0726 00:20:15.286650 22939 solver.cpp:228] Iteration 83500, loss = 0.422093
I0726 00:20:15.286691 22939 solver.cpp:244]     Train net output #0: loss = 0.422093 (* 1 = 0.422093 loss)
I0726 00:20:15.286703 22939 sgd_solver.cpp:106] Iteration 83500, lr = 2.91452e-06
I0726 00:20:24.640332 22939 solver.cpp:228] Iteration 83600, loss = 0.440826
I0726 00:20:24.640374 22939 solver.cpp:244]     Train net output #0: loss = 0.440826 (* 1 = 0.440826 loss)
I0726 00:20:24.640380 22939 sgd_solver.cpp:106] Iteration 83600, lr = 2.91241e-06
I0726 00:20:34.195516 22939 solver.cpp:228] Iteration 83700, loss = 0.410866
I0726 00:20:34.195565 22939 solver.cpp:244]     Train net output #0: loss = 0.410866 (* 1 = 0.410866 loss)
I0726 00:20:34.195572 22939 sgd_solver.cpp:106] Iteration 83700, lr = 2.9103e-06
I0726 00:20:43.684103 22939 solver.cpp:228] Iteration 83800, loss = 0.502943
I0726 00:20:43.684149 22939 solver.cpp:244]     Train net output #0: loss = 0.502943 (* 1 = 0.502943 loss)
I0726 00:20:43.684155 22939 sgd_solver.cpp:106] Iteration 83800, lr = 2.9082e-06
I0726 00:20:53.020151 22939 solver.cpp:228] Iteration 83900, loss = 0.517779
I0726 00:20:53.020200 22939 solver.cpp:244]     Train net output #0: loss = 0.517779 (* 1 = 0.517779 loss)
I0726 00:20:53.020206 22939 sgd_solver.cpp:106] Iteration 83900, lr = 2.9061e-06
I0726 00:21:02.417603 22939 solver.cpp:337] Iteration 84000, Testing net (#0)
I0726 00:21:13.360765 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746208
I0726 00:21:13.360806 22939 solver.cpp:404]     Test net output #1: loss = 0.616252 (* 1 = 0.616252 loss)
I0726 00:21:13.390130 22939 solver.cpp:228] Iteration 84000, loss = 0.503568
I0726 00:21:13.390172 22939 solver.cpp:244]     Train net output #0: loss = 0.503568 (* 1 = 0.503568 loss)
I0726 00:21:13.390194 22939 sgd_solver.cpp:106] Iteration 84000, lr = 2.90401e-06
I0726 00:21:22.719584 22939 solver.cpp:228] Iteration 84100, loss = 0.514053
I0726 00:21:22.719627 22939 solver.cpp:244]     Train net output #0: loss = 0.514053 (* 1 = 0.514053 loss)
I0726 00:21:22.719633 22939 sgd_solver.cpp:106] Iteration 84100, lr = 2.90191e-06
I0726 00:21:32.108907 22939 solver.cpp:228] Iteration 84200, loss = 0.474838
I0726 00:21:32.108953 22939 solver.cpp:244]     Train net output #0: loss = 0.474838 (* 1 = 0.474838 loss)
I0726 00:21:32.108959 22939 sgd_solver.cpp:106] Iteration 84200, lr = 2.89982e-06
I0726 00:21:41.502753 22939 solver.cpp:228] Iteration 84300, loss = 0.570617
I0726 00:21:41.502807 22939 solver.cpp:244]     Train net output #0: loss = 0.570617 (* 1 = 0.570617 loss)
I0726 00:21:41.502815 22939 sgd_solver.cpp:106] Iteration 84300, lr = 2.89774e-06
I0726 00:21:50.895319 22939 solver.cpp:228] Iteration 84400, loss = 0.470084
I0726 00:21:50.895375 22939 solver.cpp:244]     Train net output #0: loss = 0.470084 (* 1 = 0.470084 loss)
I0726 00:21:50.895382 22939 sgd_solver.cpp:106] Iteration 84400, lr = 2.89566e-06
I0726 00:22:00.195212 22939 solver.cpp:337] Iteration 84500, Testing net (#0)
I0726 00:22:11.043488 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746334
I0726 00:22:11.043527 22939 solver.cpp:404]     Test net output #1: loss = 0.617664 (* 1 = 0.617664 loss)
I0726 00:22:11.072868 22939 solver.cpp:228] Iteration 84500, loss = 0.465795
I0726 00:22:11.072919 22939 solver.cpp:244]     Train net output #0: loss = 0.465795 (* 1 = 0.465795 loss)
I0726 00:22:11.072931 22939 sgd_solver.cpp:106] Iteration 84500, lr = 2.89358e-06
I0726 00:22:20.528262 22939 solver.cpp:228] Iteration 84600, loss = 0.346697
I0726 00:22:20.528307 22939 solver.cpp:244]     Train net output #0: loss = 0.346697 (* 1 = 0.346697 loss)
I0726 00:22:20.528313 22939 sgd_solver.cpp:106] Iteration 84600, lr = 2.8915e-06
I0726 00:22:30.084270 22939 solver.cpp:228] Iteration 84700, loss = 0.475616
I0726 00:22:30.084326 22939 solver.cpp:244]     Train net output #0: loss = 0.475616 (* 1 = 0.475616 loss)
I0726 00:22:30.084331 22939 sgd_solver.cpp:106] Iteration 84700, lr = 2.88943e-06
I0726 00:22:39.596704 22939 solver.cpp:228] Iteration 84800, loss = 0.393171
I0726 00:22:39.596750 22939 solver.cpp:244]     Train net output #0: loss = 0.393171 (* 1 = 0.393171 loss)
I0726 00:22:39.596755 22939 sgd_solver.cpp:106] Iteration 84800, lr = 2.88736e-06
I0726 00:22:48.983675 22939 solver.cpp:228] Iteration 84900, loss = 0.39742
I0726 00:22:48.983721 22939 solver.cpp:244]     Train net output #0: loss = 0.39742 (* 1 = 0.39742 loss)
I0726 00:22:48.983727 22939 sgd_solver.cpp:106] Iteration 84900, lr = 2.8853e-06
I0726 00:22:58.276768 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_85000.caffemodel
I0726 00:22:58.619380 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_85000.solverstate
I0726 00:22:58.727092 22939 solver.cpp:337] Iteration 85000, Testing net (#0)
I0726 00:23:09.354184 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746333
I0726 00:23:09.354225 22939 solver.cpp:404]     Test net output #1: loss = 0.615714 (* 1 = 0.615714 loss)
I0726 00:23:09.383646 22939 solver.cpp:228] Iteration 85000, loss = 0.475252
I0726 00:23:09.383688 22939 solver.cpp:244]     Train net output #0: loss = 0.475252 (* 1 = 0.475252 loss)
I0726 00:23:09.383699 22939 sgd_solver.cpp:106] Iteration 85000, lr = 2.88324e-06
I0726 00:23:18.766180 22939 solver.cpp:228] Iteration 85100, loss = 0.429359
I0726 00:23:18.766217 22939 solver.cpp:244]     Train net output #0: loss = 0.429359 (* 1 = 0.429359 loss)
I0726 00:23:18.766222 22939 sgd_solver.cpp:106] Iteration 85100, lr = 2.88118e-06
I0726 00:23:28.170539 22939 solver.cpp:228] Iteration 85200, loss = 0.543399
I0726 00:23:28.170579 22939 solver.cpp:244]     Train net output #0: loss = 0.543399 (* 1 = 0.543399 loss)
I0726 00:23:28.170585 22939 sgd_solver.cpp:106] Iteration 85200, lr = 2.87913e-06
I0726 00:23:37.665523 22939 solver.cpp:228] Iteration 85300, loss = 0.343802
I0726 00:23:37.665562 22939 solver.cpp:244]     Train net output #0: loss = 0.343802 (* 1 = 0.343802 loss)
I0726 00:23:37.665568 22939 sgd_solver.cpp:106] Iteration 85300, lr = 2.87708e-06
I0726 00:23:47.226241 22939 solver.cpp:228] Iteration 85400, loss = 0.434182
I0726 00:23:47.226295 22939 solver.cpp:244]     Train net output #0: loss = 0.434182 (* 1 = 0.434182 loss)
I0726 00:23:47.226301 22939 sgd_solver.cpp:106] Iteration 85400, lr = 2.87503e-06
I0726 00:23:56.530320 22939 solver.cpp:337] Iteration 85500, Testing net (#0)
I0726 00:24:05.832504 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:24:07.408440 22939 solver.cpp:404]     Test net output #0: accuracy = 0.744334
I0726 00:24:07.408502 22939 solver.cpp:404]     Test net output #1: loss = 0.620616 (* 1 = 0.620616 loss)
I0726 00:24:07.434836 22939 solver.cpp:228] Iteration 85500, loss = 0.433272
I0726 00:24:07.434888 22939 solver.cpp:244]     Train net output #0: loss = 0.433272 (* 1 = 0.433272 loss)
I0726 00:24:07.434900 22939 sgd_solver.cpp:106] Iteration 85500, lr = 2.87298e-06
I0726 00:24:16.734725 22939 solver.cpp:228] Iteration 85600, loss = 0.41346
I0726 00:24:16.734767 22939 solver.cpp:244]     Train net output #0: loss = 0.41346 (* 1 = 0.41346 loss)
I0726 00:24:16.734773 22939 sgd_solver.cpp:106] Iteration 85600, lr = 2.87094e-06
I0726 00:24:26.114114 22939 solver.cpp:228] Iteration 85700, loss = 0.340572
I0726 00:24:26.114169 22939 solver.cpp:244]     Train net output #0: loss = 0.340572 (* 1 = 0.340572 loss)
I0726 00:24:26.114176 22939 sgd_solver.cpp:106] Iteration 85700, lr = 2.86891e-06
I0726 00:24:35.497334 22939 solver.cpp:228] Iteration 85800, loss = 0.421655
I0726 00:24:35.497378 22939 solver.cpp:244]     Train net output #0: loss = 0.421655 (* 1 = 0.421655 loss)
I0726 00:24:35.497385 22939 sgd_solver.cpp:106] Iteration 85800, lr = 2.86687e-06
I0726 00:24:45.043962 22939 solver.cpp:228] Iteration 85900, loss = 0.41526
I0726 00:24:45.044008 22939 solver.cpp:244]     Train net output #0: loss = 0.41526 (* 1 = 0.41526 loss)
I0726 00:24:45.044013 22939 sgd_solver.cpp:106] Iteration 85900, lr = 2.86484e-06
I0726 00:24:54.495527 22939 solver.cpp:337] Iteration 86000, Testing net (#0)
I0726 00:25:05.345000 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747083
I0726 00:25:05.345043 22939 solver.cpp:404]     Test net output #1: loss = 0.616033 (* 1 = 0.616033 loss)
I0726 00:25:05.374683 22939 solver.cpp:228] Iteration 86000, loss = 0.577915
I0726 00:25:05.374744 22939 solver.cpp:244]     Train net output #0: loss = 0.577915 (* 1 = 0.577915 loss)
I0726 00:25:05.374765 22939 sgd_solver.cpp:106] Iteration 86000, lr = 2.86281e-06
I0726 00:25:14.703270 22939 solver.cpp:228] Iteration 86100, loss = 0.368071
I0726 00:25:14.703318 22939 solver.cpp:244]     Train net output #0: loss = 0.368071 (* 1 = 0.368071 loss)
I0726 00:25:14.703327 22939 sgd_solver.cpp:106] Iteration 86100, lr = 2.86079e-06
I0726 00:25:24.092725 22939 solver.cpp:228] Iteration 86200, loss = 0.45904
I0726 00:25:24.092764 22939 solver.cpp:244]     Train net output #0: loss = 0.45904 (* 1 = 0.45904 loss)
I0726 00:25:24.092772 22939 sgd_solver.cpp:106] Iteration 86200, lr = 2.85877e-06
I0726 00:25:33.485404 22939 solver.cpp:228] Iteration 86300, loss = 0.5134
I0726 00:25:33.485450 22939 solver.cpp:244]     Train net output #0: loss = 0.5134 (* 1 = 0.5134 loss)
I0726 00:25:33.485455 22939 sgd_solver.cpp:106] Iteration 86300, lr = 2.85675e-06
I0726 00:25:43.011044 22939 solver.cpp:228] Iteration 86400, loss = 0.496741
I0726 00:25:43.011090 22939 solver.cpp:244]     Train net output #0: loss = 0.496741 (* 1 = 0.496741 loss)
I0726 00:25:43.011096 22939 sgd_solver.cpp:106] Iteration 86400, lr = 2.85474e-06
I0726 00:25:52.458736 22939 solver.cpp:337] Iteration 86500, Testing net (#0)
I0726 00:26:03.386477 22939 solver.cpp:404]     Test net output #0: accuracy = 0.743459
I0726 00:26:03.386526 22939 solver.cpp:404]     Test net output #1: loss = 0.623158 (* 1 = 0.623158 loss)
I0726 00:26:03.416683 22939 solver.cpp:228] Iteration 86500, loss = 0.402017
I0726 00:26:03.416738 22939 solver.cpp:244]     Train net output #0: loss = 0.402017 (* 1 = 0.402017 loss)
I0726 00:26:03.416760 22939 sgd_solver.cpp:106] Iteration 86500, lr = 2.85273e-06
I0726 00:26:12.744793 22939 solver.cpp:228] Iteration 86600, loss = 0.462748
I0726 00:26:12.744840 22939 solver.cpp:244]     Train net output #0: loss = 0.462748 (* 1 = 0.462748 loss)
I0726 00:26:12.744846 22939 sgd_solver.cpp:106] Iteration 86600, lr = 2.85072e-06
I0726 00:26:22.102110 22939 solver.cpp:228] Iteration 86700, loss = 0.498515
I0726 00:26:22.102159 22939 solver.cpp:244]     Train net output #0: loss = 0.498515 (* 1 = 0.498515 loss)
I0726 00:26:22.102164 22939 sgd_solver.cpp:106] Iteration 86700, lr = 2.84872e-06
I0726 00:26:31.502645 22939 solver.cpp:228] Iteration 86800, loss = 0.55386
I0726 00:26:31.502691 22939 solver.cpp:244]     Train net output #0: loss = 0.55386 (* 1 = 0.55386 loss)
I0726 00:26:31.502697 22939 sgd_solver.cpp:106] Iteration 86800, lr = 2.84672e-06
I0726 00:26:41.024617 22939 solver.cpp:228] Iteration 86900, loss = 0.448297
I0726 00:26:41.024662 22939 solver.cpp:244]     Train net output #0: loss = 0.448297 (* 1 = 0.448297 loss)
I0726 00:26:41.024668 22939 sgd_solver.cpp:106] Iteration 86900, lr = 2.84472e-06
I0726 00:26:50.487300 22939 solver.cpp:337] Iteration 87000, Testing net (#0)
I0726 00:27:01.355898 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746167
I0726 00:27:01.355940 22939 solver.cpp:404]     Test net output #1: loss = 0.619649 (* 1 = 0.619649 loss)
I0726 00:27:01.385862 22939 solver.cpp:228] Iteration 87000, loss = 0.525428
I0726 00:27:01.385908 22939 solver.cpp:244]     Train net output #0: loss = 0.525428 (* 1 = 0.525428 loss)
I0726 00:27:01.385928 22939 sgd_solver.cpp:106] Iteration 87000, lr = 2.84272e-06
I0726 00:27:10.702165 22939 solver.cpp:228] Iteration 87100, loss = 0.37174
I0726 00:27:10.702206 22939 solver.cpp:244]     Train net output #0: loss = 0.37174 (* 1 = 0.37174 loss)
I0726 00:27:10.702213 22939 sgd_solver.cpp:106] Iteration 87100, lr = 2.84073e-06
I0726 00:27:20.088327 22939 solver.cpp:228] Iteration 87200, loss = 0.447596
I0726 00:27:20.088382 22939 solver.cpp:244]     Train net output #0: loss = 0.447596 (* 1 = 0.447596 loss)
I0726 00:27:20.088389 22939 sgd_solver.cpp:106] Iteration 87200, lr = 2.83875e-06
I0726 00:27:29.475663 22939 solver.cpp:228] Iteration 87300, loss = 0.61727
I0726 00:27:29.475711 22939 solver.cpp:244]     Train net output #0: loss = 0.61727 (* 1 = 0.61727 loss)
I0726 00:27:29.475718 22939 sgd_solver.cpp:106] Iteration 87300, lr = 2.83676e-06
I0726 00:27:38.864899 22939 solver.cpp:228] Iteration 87400, loss = 0.465213
I0726 00:27:38.864953 22939 solver.cpp:244]     Train net output #0: loss = 0.465213 (* 1 = 0.465213 loss)
I0726 00:27:38.864960 22939 sgd_solver.cpp:106] Iteration 87400, lr = 2.83478e-06
I0726 00:27:48.243727 22939 solver.cpp:337] Iteration 87500, Testing net (#0)
I0726 00:27:56.421238 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:27:59.212237 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745667
I0726 00:27:59.212282 22939 solver.cpp:404]     Test net output #1: loss = 0.620626 (* 1 = 0.620626 loss)
I0726 00:27:59.239017 22939 solver.cpp:228] Iteration 87500, loss = 0.515502
I0726 00:27:59.239064 22939 solver.cpp:244]     Train net output #0: loss = 0.515502 (* 1 = 0.515502 loss)
I0726 00:27:59.239075 22939 sgd_solver.cpp:106] Iteration 87500, lr = 2.8328e-06
I0726 00:28:08.630096 22939 solver.cpp:228] Iteration 87600, loss = 0.447568
I0726 00:28:08.630141 22939 solver.cpp:244]     Train net output #0: loss = 0.447568 (* 1 = 0.447568 loss)
I0726 00:28:08.630146 22939 sgd_solver.cpp:106] Iteration 87600, lr = 2.83083e-06
I0726 00:28:18.015395 22939 solver.cpp:228] Iteration 87700, loss = 0.340132
I0726 00:28:18.015446 22939 solver.cpp:244]     Train net output #0: loss = 0.340132 (* 1 = 0.340132 loss)
I0726 00:28:18.015452 22939 sgd_solver.cpp:106] Iteration 87700, lr = 2.82886e-06
I0726 00:28:27.408836 22939 solver.cpp:228] Iteration 87800, loss = 0.566921
I0726 00:28:27.408895 22939 solver.cpp:244]     Train net output #0: loss = 0.566921 (* 1 = 0.566921 loss)
I0726 00:28:27.408901 22939 sgd_solver.cpp:106] Iteration 87800, lr = 2.82689e-06
I0726 00:28:36.793659 22939 solver.cpp:228] Iteration 87900, loss = 0.409463
I0726 00:28:36.793702 22939 solver.cpp:244]     Train net output #0: loss = 0.409463 (* 1 = 0.409463 loss)
I0726 00:28:36.793709 22939 sgd_solver.cpp:106] Iteration 87900, lr = 2.82492e-06
I0726 00:28:46.083725 22939 solver.cpp:337] Iteration 88000, Testing net (#0)
I0726 00:28:57.115172 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746833
I0726 00:28:57.115221 22939 solver.cpp:404]     Test net output #1: loss = 0.621726 (* 1 = 0.621726 loss)
I0726 00:28:57.142433 22939 solver.cpp:228] Iteration 88000, loss = 0.424112
I0726 00:28:57.142494 22939 solver.cpp:244]     Train net output #0: loss = 0.424112 (* 1 = 0.424112 loss)
I0726 00:28:57.142513 22939 sgd_solver.cpp:106] Iteration 88000, lr = 2.82296e-06
I0726 00:29:06.533864 22939 solver.cpp:228] Iteration 88100, loss = 0.560794
I0726 00:29:06.533910 22939 solver.cpp:244]     Train net output #0: loss = 0.560794 (* 1 = 0.560794 loss)
I0726 00:29:06.533916 22939 sgd_solver.cpp:106] Iteration 88100, lr = 2.821e-06
I0726 00:29:15.930968 22939 solver.cpp:228] Iteration 88200, loss = 0.479196
I0726 00:29:15.931010 22939 solver.cpp:244]     Train net output #0: loss = 0.479196 (* 1 = 0.479196 loss)
I0726 00:29:15.931015 22939 sgd_solver.cpp:106] Iteration 88200, lr = 2.81905e-06
I0726 00:29:25.329834 22939 solver.cpp:228] Iteration 88300, loss = 0.441906
I0726 00:29:25.329891 22939 solver.cpp:244]     Train net output #0: loss = 0.441906 (* 1 = 0.441906 loss)
I0726 00:29:25.329897 22939 sgd_solver.cpp:106] Iteration 88300, lr = 2.81709e-06
I0726 00:29:34.730936 22939 solver.cpp:228] Iteration 88400, loss = 0.426537
I0726 00:29:34.730978 22939 solver.cpp:244]     Train net output #0: loss = 0.426537 (* 1 = 0.426537 loss)
I0726 00:29:34.730983 22939 sgd_solver.cpp:106] Iteration 88400, lr = 2.81514e-06
I0726 00:29:44.036609 22939 solver.cpp:337] Iteration 88500, Testing net (#0)
I0726 00:29:54.893476 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74625
I0726 00:29:54.893532 22939 solver.cpp:404]     Test net output #1: loss = 0.619393 (* 1 = 0.619393 loss)
I0726 00:29:54.923060 22939 solver.cpp:228] Iteration 88500, loss = 0.531323
I0726 00:29:54.923111 22939 solver.cpp:244]     Train net output #0: loss = 0.531323 (* 1 = 0.531323 loss)
I0726 00:29:54.923122 22939 sgd_solver.cpp:106] Iteration 88500, lr = 2.8132e-06
I0726 00:30:04.297510 22939 solver.cpp:228] Iteration 88600, loss = 0.508065
I0726 00:30:04.297566 22939 solver.cpp:244]     Train net output #0: loss = 0.508065 (* 1 = 0.508065 loss)
I0726 00:30:04.297574 22939 sgd_solver.cpp:106] Iteration 88600, lr = 2.81125e-06
I0726 00:30:13.686218 22939 solver.cpp:228] Iteration 88700, loss = 0.478248
I0726 00:30:13.686264 22939 solver.cpp:244]     Train net output #0: loss = 0.478248 (* 1 = 0.478248 loss)
I0726 00:30:13.686269 22939 sgd_solver.cpp:106] Iteration 88700, lr = 2.80931e-06
I0726 00:30:23.073694 22939 solver.cpp:228] Iteration 88800, loss = 0.464373
I0726 00:30:23.073743 22939 solver.cpp:244]     Train net output #0: loss = 0.464373 (* 1 = 0.464373 loss)
I0726 00:30:23.073750 22939 sgd_solver.cpp:106] Iteration 88800, lr = 2.80738e-06
I0726 00:30:32.458801 22939 solver.cpp:228] Iteration 88900, loss = 0.296247
I0726 00:30:32.458839 22939 solver.cpp:244]     Train net output #0: loss = 0.296247 (* 1 = 0.296247 loss)
I0726 00:30:32.458845 22939 sgd_solver.cpp:106] Iteration 88900, lr = 2.80544e-06
I0726 00:30:41.752117 22939 solver.cpp:337] Iteration 89000, Testing net (#0)
I0726 00:30:52.616708 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746458
I0726 00:30:52.616756 22939 solver.cpp:404]     Test net output #1: loss = 0.620854 (* 1 = 0.620854 loss)
I0726 00:30:52.648593 22939 solver.cpp:228] Iteration 89000, loss = 0.440296
I0726 00:30:52.648651 22939 solver.cpp:244]     Train net output #0: loss = 0.440296 (* 1 = 0.440296 loss)
I0726 00:30:52.648670 22939 sgd_solver.cpp:106] Iteration 89000, lr = 2.80351e-06
I0726 00:31:02.042892 22939 solver.cpp:228] Iteration 89100, loss = 0.360389
I0726 00:31:02.042933 22939 solver.cpp:244]     Train net output #0: loss = 0.360389 (* 1 = 0.360389 loss)
I0726 00:31:02.042939 22939 sgd_solver.cpp:106] Iteration 89100, lr = 2.80159e-06
I0726 00:31:11.439569 22939 solver.cpp:228] Iteration 89200, loss = 0.393462
I0726 00:31:11.439616 22939 solver.cpp:244]     Train net output #0: loss = 0.393462 (* 1 = 0.393462 loss)
I0726 00:31:11.439622 22939 sgd_solver.cpp:106] Iteration 89200, lr = 2.79966e-06
I0726 00:31:20.831836 22939 solver.cpp:228] Iteration 89300, loss = 0.4237
I0726 00:31:20.831878 22939 solver.cpp:244]     Train net output #0: loss = 0.4237 (* 1 = 0.4237 loss)
I0726 00:31:20.831884 22939 sgd_solver.cpp:106] Iteration 89300, lr = 2.79774e-06
I0726 00:31:30.221356 22939 solver.cpp:228] Iteration 89400, loss = 0.429294
I0726 00:31:30.221410 22939 solver.cpp:244]     Train net output #0: loss = 0.429294 (* 1 = 0.429294 loss)
I0726 00:31:30.221415 22939 sgd_solver.cpp:106] Iteration 89400, lr = 2.79582e-06
I0726 00:31:39.515832 22939 solver.cpp:337] Iteration 89500, Testing net (#0)
I0726 00:31:43.139087 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:31:50.486413 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745833
I0726 00:31:50.486460 22939 solver.cpp:404]     Test net output #1: loss = 0.620855 (* 1 = 0.620855 loss)
I0726 00:31:50.513353 22939 solver.cpp:228] Iteration 89500, loss = 0.460515
I0726 00:31:50.513414 22939 solver.cpp:244]     Train net output #0: loss = 0.460515 (* 1 = 0.460515 loss)
I0726 00:31:50.513423 22939 sgd_solver.cpp:106] Iteration 89500, lr = 2.79391e-06
I0726 00:31:59.913244 22939 solver.cpp:228] Iteration 89600, loss = 0.323275
I0726 00:31:59.913287 22939 solver.cpp:244]     Train net output #0: loss = 0.323275 (* 1 = 0.323275 loss)
I0726 00:31:59.913293 22939 sgd_solver.cpp:106] Iteration 89600, lr = 2.79199e-06
I0726 00:32:09.313303 22939 solver.cpp:228] Iteration 89700, loss = 0.431311
I0726 00:32:09.313336 22939 solver.cpp:244]     Train net output #0: loss = 0.431311 (* 1 = 0.431311 loss)
I0726 00:32:09.313343 22939 sgd_solver.cpp:106] Iteration 89700, lr = 2.79009e-06
I0726 00:32:18.708736 22939 solver.cpp:228] Iteration 89800, loss = 0.523006
I0726 00:32:18.708780 22939 solver.cpp:244]     Train net output #0: loss = 0.523006 (* 1 = 0.523006 loss)
I0726 00:32:18.708786 22939 sgd_solver.cpp:106] Iteration 89800, lr = 2.78818e-06
I0726 00:32:28.107772 22939 solver.cpp:228] Iteration 89900, loss = 0.597376
I0726 00:32:28.107810 22939 solver.cpp:244]     Train net output #0: loss = 0.597376 (* 1 = 0.597376 loss)
I0726 00:32:28.107815 22939 sgd_solver.cpp:106] Iteration 89900, lr = 2.78628e-06
I0726 00:32:37.416721 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_90000.caffemodel
I0726 00:32:37.758723 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_90000.solverstate
I0726 00:32:37.866055 22939 solver.cpp:337] Iteration 90000, Testing net (#0)
I0726 00:32:48.494426 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747292
I0726 00:32:48.494478 22939 solver.cpp:404]     Test net output #1: loss = 0.617657 (* 1 = 0.617657 loss)
I0726 00:32:48.521313 22939 solver.cpp:228] Iteration 90000, loss = 0.348791
I0726 00:32:48.521379 22939 solver.cpp:244]     Train net output #0: loss = 0.348791 (* 1 = 0.348791 loss)
I0726 00:32:48.521397 22939 sgd_solver.cpp:106] Iteration 90000, lr = 2.78438e-06
I0726 00:32:57.971609 22939 solver.cpp:228] Iteration 90100, loss = 0.354681
I0726 00:32:57.971649 22939 solver.cpp:244]     Train net output #0: loss = 0.354681 (* 1 = 0.354681 loss)
I0726 00:32:57.971655 22939 sgd_solver.cpp:106] Iteration 90100, lr = 2.78248e-06
I0726 00:33:07.409948 22939 solver.cpp:228] Iteration 90200, loss = 0.454242
I0726 00:33:07.409996 22939 solver.cpp:244]     Train net output #0: loss = 0.454242 (* 1 = 0.454242 loss)
I0726 00:33:07.410001 22939 sgd_solver.cpp:106] Iteration 90200, lr = 2.78059e-06
I0726 00:33:16.812374 22939 solver.cpp:228] Iteration 90300, loss = 0.476206
I0726 00:33:16.812417 22939 solver.cpp:244]     Train net output #0: loss = 0.476206 (* 1 = 0.476206 loss)
I0726 00:33:16.812422 22939 sgd_solver.cpp:106] Iteration 90300, lr = 2.77869e-06
I0726 00:33:26.207140 22939 solver.cpp:228] Iteration 90400, loss = 0.369184
I0726 00:33:26.207180 22939 solver.cpp:244]     Train net output #0: loss = 0.369184 (* 1 = 0.369184 loss)
I0726 00:33:26.207186 22939 sgd_solver.cpp:106] Iteration 90400, lr = 2.77681e-06
I0726 00:33:35.507386 22939 solver.cpp:337] Iteration 90500, Testing net (#0)
I0726 00:33:46.426897 22939 solver.cpp:404]     Test net output #0: accuracy = 0.745833
I0726 00:33:46.426952 22939 solver.cpp:404]     Test net output #1: loss = 0.621865 (* 1 = 0.621865 loss)
I0726 00:33:46.453524 22939 solver.cpp:228] Iteration 90500, loss = 0.542683
I0726 00:33:46.453574 22939 solver.cpp:244]     Train net output #0: loss = 0.542683 (* 1 = 0.542683 loss)
I0726 00:33:46.453583 22939 sgd_solver.cpp:106] Iteration 90500, lr = 2.77492e-06
I0726 00:33:55.797845 22939 solver.cpp:228] Iteration 90600, loss = 0.410355
I0726 00:33:55.797897 22939 solver.cpp:244]     Train net output #0: loss = 0.410355 (* 1 = 0.410355 loss)
I0726 00:33:55.797904 22939 sgd_solver.cpp:106] Iteration 90600, lr = 2.77304e-06
I0726 00:34:05.186702 22939 solver.cpp:228] Iteration 90700, loss = 0.510302
I0726 00:34:05.186745 22939 solver.cpp:244]     Train net output #0: loss = 0.510302 (* 1 = 0.510302 loss)
I0726 00:34:05.186751 22939 sgd_solver.cpp:106] Iteration 90700, lr = 2.77116e-06
I0726 00:34:14.578800 22939 solver.cpp:228] Iteration 90800, loss = 0.504601
I0726 00:34:14.578848 22939 solver.cpp:244]     Train net output #0: loss = 0.504601 (* 1 = 0.504601 loss)
I0726 00:34:14.578855 22939 sgd_solver.cpp:106] Iteration 90800, lr = 2.76929e-06
I0726 00:34:23.968533 22939 solver.cpp:228] Iteration 90900, loss = 0.501528
I0726 00:34:23.968581 22939 solver.cpp:244]     Train net output #0: loss = 0.501528 (* 1 = 0.501528 loss)
I0726 00:34:23.968587 22939 sgd_solver.cpp:106] Iteration 90900, lr = 2.76741e-06
I0726 00:34:33.262305 22939 solver.cpp:337] Iteration 91000, Testing net (#0)
I0726 00:34:44.153802 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747834
I0726 00:34:44.153856 22939 solver.cpp:404]     Test net output #1: loss = 0.616482 (* 1 = 0.616482 loss)
I0726 00:34:44.184391 22939 solver.cpp:228] Iteration 91000, loss = 0.519909
I0726 00:34:44.184463 22939 solver.cpp:244]     Train net output #0: loss = 0.519909 (* 1 = 0.519909 loss)
I0726 00:34:44.184486 22939 sgd_solver.cpp:106] Iteration 91000, lr = 2.76554e-06
I0726 00:34:53.521184 22939 solver.cpp:228] Iteration 91100, loss = 0.546208
I0726 00:34:53.521232 22939 solver.cpp:244]     Train net output #0: loss = 0.546208 (* 1 = 0.546208 loss)
I0726 00:34:53.521239 22939 sgd_solver.cpp:106] Iteration 91100, lr = 2.76367e-06
I0726 00:35:02.862308 22939 solver.cpp:228] Iteration 91200, loss = 0.420741
I0726 00:35:02.862362 22939 solver.cpp:244]     Train net output #0: loss = 0.420741 (* 1 = 0.420741 loss)
I0726 00:35:02.862368 22939 sgd_solver.cpp:106] Iteration 91200, lr = 2.76181e-06
I0726 00:35:12.393343 22939 solver.cpp:228] Iteration 91300, loss = 0.469543
I0726 00:35:12.393386 22939 solver.cpp:244]     Train net output #0: loss = 0.469543 (* 1 = 0.469543 loss)
I0726 00:35:12.393391 22939 sgd_solver.cpp:106] Iteration 91300, lr = 2.75995e-06
I0726 00:35:21.815680 22939 solver.cpp:228] Iteration 91400, loss = 0.394998
I0726 00:35:21.815722 22939 solver.cpp:244]     Train net output #0: loss = 0.394998 (* 1 = 0.394998 loss)
I0726 00:35:21.815728 22939 sgd_solver.cpp:106] Iteration 91400, lr = 2.75809e-06
I0726 00:35:31.125504 22939 solver.cpp:337] Iteration 91500, Testing net (#0)
I0726 00:35:37.329315 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:35:42.009209 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746042
I0726 00:35:42.009266 22939 solver.cpp:404]     Test net output #1: loss = 0.620253 (* 1 = 0.620253 loss)
I0726 00:35:42.038919 22939 solver.cpp:228] Iteration 91500, loss = 0.482981
I0726 00:35:42.038967 22939 solver.cpp:244]     Train net output #0: loss = 0.482981 (* 1 = 0.482981 loss)
I0726 00:35:42.038983 22939 sgd_solver.cpp:106] Iteration 91500, lr = 2.75624e-06
I0726 00:35:51.321702 22939 solver.cpp:228] Iteration 91600, loss = 0.662441
I0726 00:35:51.321749 22939 solver.cpp:244]     Train net output #0: loss = 0.662441 (* 1 = 0.662441 loss)
I0726 00:35:51.321770 22939 sgd_solver.cpp:106] Iteration 91600, lr = 2.75438e-06
I0726 00:36:00.666986 22939 solver.cpp:228] Iteration 91700, loss = 0.566011
I0726 00:36:00.667033 22939 solver.cpp:244]     Train net output #0: loss = 0.566011 (* 1 = 0.566011 loss)
I0726 00:36:00.667039 22939 sgd_solver.cpp:106] Iteration 91700, lr = 2.75253e-06
I0726 00:36:10.059402 22939 solver.cpp:228] Iteration 91800, loss = 0.378987
I0726 00:36:10.059465 22939 solver.cpp:244]     Train net output #0: loss = 0.378987 (* 1 = 0.378987 loss)
I0726 00:36:10.059471 22939 sgd_solver.cpp:106] Iteration 91800, lr = 2.75069e-06
I0726 00:36:19.558054 22939 solver.cpp:228] Iteration 91900, loss = 0.505891
I0726 00:36:19.558105 22939 solver.cpp:244]     Train net output #0: loss = 0.505891 (* 1 = 0.505891 loss)
I0726 00:36:19.558112 22939 sgd_solver.cpp:106] Iteration 91900, lr = 2.74884e-06
I0726 00:36:28.890163 22939 solver.cpp:337] Iteration 92000, Testing net (#0)
I0726 00:36:39.787761 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747042
I0726 00:36:39.787806 22939 solver.cpp:404]     Test net output #1: loss = 0.61739 (* 1 = 0.61739 loss)
I0726 00:36:39.816866 22939 solver.cpp:228] Iteration 92000, loss = 0.428672
I0726 00:36:39.816921 22939 solver.cpp:244]     Train net output #0: loss = 0.428672 (* 1 = 0.428672 loss)
I0726 00:36:39.816933 22939 sgd_solver.cpp:106] Iteration 92000, lr = 2.747e-06
I0726 00:36:49.149781 22939 solver.cpp:228] Iteration 92100, loss = 0.602925
I0726 00:36:49.149826 22939 solver.cpp:244]     Train net output #0: loss = 0.602925 (* 1 = 0.602925 loss)
I0726 00:36:49.149830 22939 sgd_solver.cpp:106] Iteration 92100, lr = 2.74516e-06
I0726 00:36:58.537981 22939 solver.cpp:228] Iteration 92200, loss = 0.425142
I0726 00:36:58.538030 22939 solver.cpp:244]     Train net output #0: loss = 0.425142 (* 1 = 0.425142 loss)
I0726 00:36:58.538036 22939 sgd_solver.cpp:106] Iteration 92200, lr = 2.74333e-06
I0726 00:37:07.928508 22939 solver.cpp:228] Iteration 92300, loss = 0.429799
I0726 00:37:07.928551 22939 solver.cpp:244]     Train net output #0: loss = 0.429799 (* 1 = 0.429799 loss)
I0726 00:37:07.928557 22939 sgd_solver.cpp:106] Iteration 92300, lr = 2.7415e-06
I0726 00:37:17.315665 22939 solver.cpp:228] Iteration 92400, loss = 0.501709
I0726 00:37:17.315702 22939 solver.cpp:244]     Train net output #0: loss = 0.501709 (* 1 = 0.501709 loss)
I0726 00:37:17.315708 22939 sgd_solver.cpp:106] Iteration 92400, lr = 2.73967e-06
I0726 00:37:26.609858 22939 solver.cpp:337] Iteration 92500, Testing net (#0)
I0726 00:37:37.447769 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746584
I0726 00:37:37.447821 22939 solver.cpp:404]     Test net output #1: loss = 0.619189 (* 1 = 0.619189 loss)
I0726 00:37:37.474444 22939 solver.cpp:228] Iteration 92500, loss = 0.43365
I0726 00:37:37.474503 22939 solver.cpp:244]     Train net output #0: loss = 0.43365 (* 1 = 0.43365 loss)
I0726 00:37:37.474515 22939 sgd_solver.cpp:106] Iteration 92500, lr = 2.73784e-06
I0726 00:37:46.799078 22939 solver.cpp:228] Iteration 92600, loss = 0.437466
I0726 00:37:46.799136 22939 solver.cpp:244]     Train net output #0: loss = 0.437466 (* 1 = 0.437466 loss)
I0726 00:37:46.799142 22939 sgd_solver.cpp:106] Iteration 92600, lr = 2.73602e-06
I0726 00:37:56.181754 22939 solver.cpp:228] Iteration 92700, loss = 0.394197
I0726 00:37:56.181802 22939 solver.cpp:244]     Train net output #0: loss = 0.394197 (* 1 = 0.394197 loss)
I0726 00:37:56.181807 22939 sgd_solver.cpp:106] Iteration 92700, lr = 2.7342e-06
I0726 00:38:05.582922 22939 solver.cpp:228] Iteration 92800, loss = 0.449481
I0726 00:38:05.582970 22939 solver.cpp:244]     Train net output #0: loss = 0.449481 (* 1 = 0.449481 loss)
I0726 00:38:05.582975 22939 sgd_solver.cpp:106] Iteration 92800, lr = 2.73238e-06
I0726 00:38:14.983876 22939 solver.cpp:228] Iteration 92900, loss = 0.435201
I0726 00:38:14.983923 22939 solver.cpp:244]     Train net output #0: loss = 0.435201 (* 1 = 0.435201 loss)
I0726 00:38:14.983929 22939 sgd_solver.cpp:106] Iteration 92900, lr = 2.73056e-06
I0726 00:38:24.290019 22939 solver.cpp:337] Iteration 93000, Testing net (#0)
I0726 00:38:35.171277 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747333
I0726 00:38:35.171331 22939 solver.cpp:404]     Test net output #1: loss = 0.617943 (* 1 = 0.617943 loss)
I0726 00:38:35.200716 22939 solver.cpp:228] Iteration 93000, loss = 0.496539
I0726 00:38:35.200765 22939 solver.cpp:244]     Train net output #0: loss = 0.496539 (* 1 = 0.496539 loss)
I0726 00:38:35.200778 22939 sgd_solver.cpp:106] Iteration 93000, lr = 2.72875e-06
I0726 00:38:44.516674 22939 solver.cpp:228] Iteration 93100, loss = 0.38649
I0726 00:38:44.516721 22939 solver.cpp:244]     Train net output #0: loss = 0.38649 (* 1 = 0.38649 loss)
I0726 00:38:44.516727 22939 sgd_solver.cpp:106] Iteration 93100, lr = 2.72694e-06
I0726 00:38:53.884286 22939 solver.cpp:228] Iteration 93200, loss = 0.333467
I0726 00:38:53.884330 22939 solver.cpp:244]     Train net output #0: loss = 0.333467 (* 1 = 0.333467 loss)
I0726 00:38:53.884335 22939 sgd_solver.cpp:106] Iteration 93200, lr = 2.72513e-06
I0726 00:39:03.273506 22939 solver.cpp:228] Iteration 93300, loss = 0.403412
I0726 00:39:03.273550 22939 solver.cpp:244]     Train net output #0: loss = 0.403412 (* 1 = 0.403412 loss)
I0726 00:39:03.273556 22939 sgd_solver.cpp:106] Iteration 93300, lr = 2.72333e-06
I0726 00:39:12.663079 22939 solver.cpp:228] Iteration 93400, loss = 0.37026
I0726 00:39:12.663116 22939 solver.cpp:244]     Train net output #0: loss = 0.37026 (* 1 = 0.37026 loss)
I0726 00:39:12.663122 22939 sgd_solver.cpp:106] Iteration 93400, lr = 2.72153e-06
I0726 00:39:21.959055 22939 solver.cpp:337] Iteration 93500, Testing net (#0)
I0726 00:39:26.600908 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:39:32.800977 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747917
I0726 00:39:32.801033 22939 solver.cpp:404]     Test net output #1: loss = 0.616036 (* 1 = 0.616036 loss)
I0726 00:39:32.827661 22939 solver.cpp:228] Iteration 93500, loss = 0.45366
I0726 00:39:32.827705 22939 solver.cpp:244]     Train net output #0: loss = 0.45366 (* 1 = 0.45366 loss)
I0726 00:39:32.827716 22939 sgd_solver.cpp:106] Iteration 93500, lr = 2.71973e-06
I0726 00:39:42.144954 22939 solver.cpp:228] Iteration 93600, loss = 0.449519
I0726 00:39:42.145014 22939 solver.cpp:244]     Train net output #0: loss = 0.449519 (* 1 = 0.449519 loss)
I0726 00:39:42.145020 22939 sgd_solver.cpp:106] Iteration 93600, lr = 2.71793e-06
I0726 00:39:51.517756 22939 solver.cpp:228] Iteration 93700, loss = 0.567857
I0726 00:39:51.517812 22939 solver.cpp:244]     Train net output #0: loss = 0.567857 (* 1 = 0.567857 loss)
I0726 00:39:51.517817 22939 sgd_solver.cpp:106] Iteration 93700, lr = 2.71614e-06
I0726 00:40:00.903301 22939 solver.cpp:228] Iteration 93800, loss = 0.489618
I0726 00:40:00.903347 22939 solver.cpp:244]     Train net output #0: loss = 0.489618 (* 1 = 0.489618 loss)
I0726 00:40:00.903353 22939 sgd_solver.cpp:106] Iteration 93800, lr = 2.71435e-06
I0726 00:40:10.288295 22939 solver.cpp:228] Iteration 93900, loss = 0.351694
I0726 00:40:10.288339 22939 solver.cpp:244]     Train net output #0: loss = 0.351694 (* 1 = 0.351694 loss)
I0726 00:40:10.288346 22939 sgd_solver.cpp:106] Iteration 93900, lr = 2.71256e-06
I0726 00:40:19.585630 22939 solver.cpp:337] Iteration 94000, Testing net (#0)
I0726 00:40:30.465299 22939 solver.cpp:404]     Test net output #0: accuracy = 0.746834
I0726 00:40:30.465338 22939 solver.cpp:404]     Test net output #1: loss = 0.618173 (* 1 = 0.618173 loss)
I0726 00:40:30.492395 22939 solver.cpp:228] Iteration 94000, loss = 0.462239
I0726 00:40:30.492454 22939 solver.cpp:244]     Train net output #0: loss = 0.462239 (* 1 = 0.462239 loss)
I0726 00:40:30.492472 22939 sgd_solver.cpp:106] Iteration 94000, lr = 2.71078e-06
I0726 00:40:39.827203 22939 solver.cpp:228] Iteration 94100, loss = 0.441522
I0726 00:40:39.827241 22939 solver.cpp:244]     Train net output #0: loss = 0.441522 (* 1 = 0.441522 loss)
I0726 00:40:39.827247 22939 sgd_solver.cpp:106] Iteration 94100, lr = 2.709e-06
I0726 00:40:49.230532 22939 solver.cpp:228] Iteration 94200, loss = 0.586254
I0726 00:40:49.230569 22939 solver.cpp:244]     Train net output #0: loss = 0.586254 (* 1 = 0.586254 loss)
I0726 00:40:49.230576 22939 sgd_solver.cpp:106] Iteration 94200, lr = 2.70722e-06
I0726 00:40:58.636730 22939 solver.cpp:228] Iteration 94300, loss = 0.399046
I0726 00:40:58.636771 22939 solver.cpp:244]     Train net output #0: loss = 0.399046 (* 1 = 0.399046 loss)
I0726 00:40:58.636777 22939 sgd_solver.cpp:106] Iteration 94300, lr = 2.70544e-06
I0726 00:41:08.038035 22939 solver.cpp:228] Iteration 94400, loss = 0.34096
I0726 00:41:08.038089 22939 solver.cpp:244]     Train net output #0: loss = 0.34096 (* 1 = 0.34096 loss)
I0726 00:41:08.038095 22939 sgd_solver.cpp:106] Iteration 94400, lr = 2.70367e-06
I0726 00:41:17.338632 22939 solver.cpp:337] Iteration 94500, Testing net (#0)
I0726 00:41:28.232106 22939 solver.cpp:404]     Test net output #0: accuracy = 0.748042
I0726 00:41:28.232146 22939 solver.cpp:404]     Test net output #1: loss = 0.615119 (* 1 = 0.615119 loss)
I0726 00:41:28.258679 22939 solver.cpp:228] Iteration 94500, loss = 0.476884
I0726 00:41:28.258739 22939 solver.cpp:244]     Train net output #0: loss = 0.476884 (* 1 = 0.476884 loss)
I0726 00:41:28.258759 22939 sgd_solver.cpp:106] Iteration 94500, lr = 2.70189e-06
I0726 00:41:37.553251 22939 solver.cpp:228] Iteration 94600, loss = 0.458335
I0726 00:41:37.553295 22939 solver.cpp:244]     Train net output #0: loss = 0.458335 (* 1 = 0.458335 loss)
I0726 00:41:37.553302 22939 sgd_solver.cpp:106] Iteration 94600, lr = 2.70013e-06
I0726 00:41:46.939237 22939 solver.cpp:228] Iteration 94700, loss = 0.342174
I0726 00:41:46.939286 22939 solver.cpp:244]     Train net output #0: loss = 0.342174 (* 1 = 0.342174 loss)
I0726 00:41:46.939291 22939 sgd_solver.cpp:106] Iteration 94700, lr = 2.69836e-06
I0726 00:41:56.324689 22939 solver.cpp:228] Iteration 94800, loss = 0.574464
I0726 00:41:56.324743 22939 solver.cpp:244]     Train net output #0: loss = 0.574464 (* 1 = 0.574464 loss)
I0726 00:41:56.324751 22939 sgd_solver.cpp:106] Iteration 94800, lr = 2.6966e-06
I0726 00:42:05.708783 22939 solver.cpp:228] Iteration 94900, loss = 0.431167
I0726 00:42:05.708844 22939 solver.cpp:244]     Train net output #0: loss = 0.431167 (* 1 = 0.431167 loss)
I0726 00:42:05.708850 22939 sgd_solver.cpp:106] Iteration 94900, lr = 2.69484e-06
I0726 00:42:15.000051 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_95000.caffemodel
I0726 00:42:15.349817 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_95000.solverstate
I0726 00:42:15.458040 22939 solver.cpp:337] Iteration 95000, Testing net (#0)
I0726 00:42:26.056529 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747083
I0726 00:42:26.056579 22939 solver.cpp:404]     Test net output #1: loss = 0.617631 (* 1 = 0.617631 loss)
I0726 00:42:26.086030 22939 solver.cpp:228] Iteration 95000, loss = 0.503351
I0726 00:42:26.086079 22939 solver.cpp:244]     Train net output #0: loss = 0.503351 (* 1 = 0.503351 loss)
I0726 00:42:26.086091 22939 sgd_solver.cpp:106] Iteration 95000, lr = 2.69308e-06
I0726 00:42:35.518501 22939 solver.cpp:228] Iteration 95100, loss = 0.560171
I0726 00:42:35.518556 22939 solver.cpp:244]     Train net output #0: loss = 0.560171 (* 1 = 0.560171 loss)
I0726 00:42:35.518563 22939 sgd_solver.cpp:106] Iteration 95100, lr = 2.69132e-06
I0726 00:42:45.067114 22939 solver.cpp:228] Iteration 95200, loss = 0.473874
I0726 00:42:45.067147 22939 solver.cpp:244]     Train net output #0: loss = 0.473874 (* 1 = 0.473874 loss)
I0726 00:42:45.067152 22939 sgd_solver.cpp:106] Iteration 95200, lr = 2.68957e-06
I0726 00:42:54.471688 22939 solver.cpp:228] Iteration 95300, loss = 0.45131
I0726 00:42:54.471740 22939 solver.cpp:244]     Train net output #0: loss = 0.45131 (* 1 = 0.45131 loss)
I0726 00:42:54.471745 22939 sgd_solver.cpp:106] Iteration 95300, lr = 2.68782e-06
I0726 00:43:03.859375 22939 solver.cpp:228] Iteration 95400, loss = 0.548651
I0726 00:43:03.859432 22939 solver.cpp:244]     Train net output #0: loss = 0.548651 (* 1 = 0.548651 loss)
I0726 00:43:03.859439 22939 sgd_solver.cpp:106] Iteration 95400, lr = 2.68608e-06
I0726 00:43:13.151144 22939 solver.cpp:337] Iteration 95500, Testing net (#0)
I0726 00:43:13.701774 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:43:24.001674 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74775
I0726 00:43:24.001713 22939 solver.cpp:404]     Test net output #1: loss = 0.615849 (* 1 = 0.615849 loss)
I0726 00:43:24.028287 22939 solver.cpp:228] Iteration 95500, loss = 0.49887
I0726 00:43:24.028332 22939 solver.cpp:244]     Train net output #0: loss = 0.49887 (* 1 = 0.49887 loss)
I0726 00:43:24.028342 22939 sgd_solver.cpp:106] Iteration 95500, lr = 2.68433e-06
I0726 00:43:33.356879 22939 solver.cpp:228] Iteration 95600, loss = 0.557149
I0726 00:43:33.356925 22939 solver.cpp:244]     Train net output #0: loss = 0.557149 (* 1 = 0.557149 loss)
I0726 00:43:33.356930 22939 sgd_solver.cpp:106] Iteration 95600, lr = 2.68259e-06
I0726 00:43:42.860919 22939 solver.cpp:228] Iteration 95700, loss = 0.334832
I0726 00:43:42.860967 22939 solver.cpp:244]     Train net output #0: loss = 0.334832 (* 1 = 0.334832 loss)
I0726 00:43:42.860975 22939 sgd_solver.cpp:106] Iteration 95700, lr = 2.68085e-06
I0726 00:43:52.404465 22939 solver.cpp:228] Iteration 95800, loss = 0.497298
I0726 00:43:52.404508 22939 solver.cpp:244]     Train net output #0: loss = 0.497298 (* 1 = 0.497298 loss)
I0726 00:43:52.404527 22939 sgd_solver.cpp:106] Iteration 95800, lr = 2.67911e-06
I0726 00:44:01.785843 22939 solver.cpp:228] Iteration 95900, loss = 0.494182
I0726 00:44:01.785902 22939 solver.cpp:244]     Train net output #0: loss = 0.494182 (* 1 = 0.494182 loss)
I0726 00:44:01.785908 22939 sgd_solver.cpp:106] Iteration 95900, lr = 2.67738e-06
I0726 00:44:11.036053 22939 solver.cpp:337] Iteration 96000, Testing net (#0)
I0726 00:44:21.884469 22939 solver.cpp:404]     Test net output #0: accuracy = 0.74825
I0726 00:44:21.884517 22939 solver.cpp:404]     Test net output #1: loss = 0.615897 (* 1 = 0.615897 loss)
I0726 00:44:21.913946 22939 solver.cpp:228] Iteration 96000, loss = 0.580012
I0726 00:44:21.913998 22939 solver.cpp:244]     Train net output #0: loss = 0.580012 (* 1 = 0.580012 loss)
I0726 00:44:21.914011 22939 sgd_solver.cpp:106] Iteration 96000, lr = 2.67565e-06
I0726 00:44:31.257129 22939 solver.cpp:228] Iteration 96100, loss = 0.381063
I0726 00:44:31.257174 22939 solver.cpp:244]     Train net output #0: loss = 0.381063 (* 1 = 0.381063 loss)
I0726 00:44:31.257181 22939 sgd_solver.cpp:106] Iteration 96100, lr = 2.67392e-06
I0726 00:44:40.644703 22939 solver.cpp:228] Iteration 96200, loss = 0.503298
I0726 00:44:40.644752 22939 solver.cpp:244]     Train net output #0: loss = 0.503298 (* 1 = 0.503298 loss)
I0726 00:44:40.644757 22939 sgd_solver.cpp:106] Iteration 96200, lr = 2.67219e-06
I0726 00:44:50.034458 22939 solver.cpp:228] Iteration 96300, loss = 0.486672
I0726 00:44:50.034502 22939 solver.cpp:244]     Train net output #0: loss = 0.486672 (* 1 = 0.486672 loss)
I0726 00:44:50.034509 22939 sgd_solver.cpp:106] Iteration 96300, lr = 2.67047e-06
I0726 00:44:59.426924 22939 solver.cpp:228] Iteration 96400, loss = 0.590234
I0726 00:44:59.426970 22939 solver.cpp:244]     Train net output #0: loss = 0.590234 (* 1 = 0.590234 loss)
I0726 00:44:59.426976 22939 sgd_solver.cpp:106] Iteration 96400, lr = 2.66875e-06
I0726 00:45:08.729096 22939 solver.cpp:337] Iteration 96500, Testing net (#0)
I0726 00:45:19.623972 22939 solver.cpp:404]     Test net output #0: accuracy = 0.748208
I0726 00:45:19.624028 22939 solver.cpp:404]     Test net output #1: loss = 0.616245 (* 1 = 0.616245 loss)
I0726 00:45:19.655342 22939 solver.cpp:228] Iteration 96500, loss = 0.363009
I0726 00:45:19.655382 22939 solver.cpp:244]     Train net output #0: loss = 0.363009 (* 1 = 0.363009 loss)
I0726 00:45:19.655393 22939 sgd_solver.cpp:106] Iteration 96500, lr = 2.66703e-06
I0726 00:45:28.977401 22939 solver.cpp:228] Iteration 96600, loss = 0.404434
I0726 00:45:28.977444 22939 solver.cpp:244]     Train net output #0: loss = 0.404434 (* 1 = 0.404434 loss)
I0726 00:45:28.977450 22939 sgd_solver.cpp:106] Iteration 96600, lr = 2.66532e-06
I0726 00:45:38.359575 22939 solver.cpp:228] Iteration 96700, loss = 0.519801
I0726 00:45:38.359622 22939 solver.cpp:244]     Train net output #0: loss = 0.519801 (* 1 = 0.519801 loss)
I0726 00:45:38.359628 22939 sgd_solver.cpp:106] Iteration 96700, lr = 2.6636e-06
I0726 00:45:47.753255 22939 solver.cpp:228] Iteration 96800, loss = 0.466265
I0726 00:45:47.753299 22939 solver.cpp:244]     Train net output #0: loss = 0.466265 (* 1 = 0.466265 loss)
I0726 00:45:47.753305 22939 sgd_solver.cpp:106] Iteration 96800, lr = 2.66189e-06
I0726 00:45:57.145331 22939 solver.cpp:228] Iteration 96900, loss = 0.446998
I0726 00:45:57.145380 22939 solver.cpp:244]     Train net output #0: loss = 0.446998 (* 1 = 0.446998 loss)
I0726 00:45:57.145385 22939 sgd_solver.cpp:106] Iteration 96900, lr = 2.66018e-06
I0726 00:46:06.441710 22939 solver.cpp:337] Iteration 97000, Testing net (#0)
I0726 00:46:15.260823 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:46:17.364877 22939 solver.cpp:404]     Test net output #0: accuracy = 0.749583
I0726 00:46:17.364934 22939 solver.cpp:404]     Test net output #1: loss = 0.615442 (* 1 = 0.615442 loss)
I0726 00:46:17.394225 22939 solver.cpp:228] Iteration 97000, loss = 0.434278
I0726 00:46:17.394276 22939 solver.cpp:244]     Train net output #0: loss = 0.434278 (* 1 = 0.434278 loss)
I0726 00:46:17.394289 22939 sgd_solver.cpp:106] Iteration 97000, lr = 2.65848e-06
I0726 00:46:26.779853 22939 solver.cpp:228] Iteration 97100, loss = 0.390531
I0726 00:46:26.779899 22939 solver.cpp:244]     Train net output #0: loss = 0.390531 (* 1 = 0.390531 loss)
I0726 00:46:26.779906 22939 sgd_solver.cpp:106] Iteration 97100, lr = 2.65678e-06
I0726 00:46:36.242189 22939 solver.cpp:228] Iteration 97200, loss = 0.481798
I0726 00:46:36.242238 22939 solver.cpp:244]     Train net output #0: loss = 0.481798 (* 1 = 0.481798 loss)
I0726 00:46:36.242244 22939 sgd_solver.cpp:106] Iteration 97200, lr = 2.65507e-06
I0726 00:46:45.640655 22939 solver.cpp:228] Iteration 97300, loss = 0.573688
I0726 00:46:45.640699 22939 solver.cpp:244]     Train net output #0: loss = 0.573688 (* 1 = 0.573688 loss)
I0726 00:46:45.640705 22939 sgd_solver.cpp:106] Iteration 97300, lr = 2.65338e-06
I0726 00:46:55.040164 22939 solver.cpp:228] Iteration 97400, loss = 0.403498
I0726 00:46:55.040223 22939 solver.cpp:244]     Train net output #0: loss = 0.403498 (* 1 = 0.403498 loss)
I0726 00:46:55.040230 22939 sgd_solver.cpp:106] Iteration 97400, lr = 2.65168e-06
I0726 00:47:04.346976 22939 solver.cpp:337] Iteration 97500, Testing net (#0)
I0726 00:47:15.271541 22939 solver.cpp:404]     Test net output #0: accuracy = 0.748584
I0726 00:47:15.271591 22939 solver.cpp:404]     Test net output #1: loss = 0.615655 (* 1 = 0.615655 loss)
I0726 00:47:15.300637 22939 solver.cpp:228] Iteration 97500, loss = 0.365078
I0726 00:47:15.300686 22939 solver.cpp:244]     Train net output #0: loss = 0.365078 (* 1 = 0.365078 loss)
I0726 00:47:15.300698 22939 sgd_solver.cpp:106] Iteration 97500, lr = 2.64999e-06
I0726 00:47:24.666616 22939 solver.cpp:228] Iteration 97600, loss = 0.450867
I0726 00:47:24.666659 22939 solver.cpp:244]     Train net output #0: loss = 0.450867 (* 1 = 0.450867 loss)
I0726 00:47:24.666666 22939 sgd_solver.cpp:106] Iteration 97600, lr = 2.6483e-06
I0726 00:47:34.060544 22939 solver.cpp:228] Iteration 97700, loss = 0.409075
I0726 00:47:34.060591 22939 solver.cpp:244]     Train net output #0: loss = 0.409075 (* 1 = 0.409075 loss)
I0726 00:47:34.060598 22939 sgd_solver.cpp:106] Iteration 97700, lr = 2.64661e-06
I0726 00:47:43.454669 22939 solver.cpp:228] Iteration 97800, loss = 0.409477
I0726 00:47:43.454718 22939 solver.cpp:244]     Train net output #0: loss = 0.409477 (* 1 = 0.409477 loss)
I0726 00:47:43.454725 22939 sgd_solver.cpp:106] Iteration 97800, lr = 2.64493e-06
I0726 00:47:52.848611 22939 solver.cpp:228] Iteration 97900, loss = 0.496801
I0726 00:47:52.848654 22939 solver.cpp:244]     Train net output #0: loss = 0.496801 (* 1 = 0.496801 loss)
I0726 00:47:52.848660 22939 sgd_solver.cpp:106] Iteration 97900, lr = 2.64324e-06
I0726 00:48:02.152469 22939 solver.cpp:337] Iteration 98000, Testing net (#0)
I0726 00:48:12.995976 22939 solver.cpp:404]     Test net output #0: accuracy = 0.749333
I0726 00:48:12.996021 22939 solver.cpp:404]     Test net output #1: loss = 0.616196 (* 1 = 0.616196 loss)
I0726 00:48:13.025820 22939 solver.cpp:228] Iteration 98000, loss = 0.583362
I0726 00:48:13.025887 22939 solver.cpp:244]     Train net output #0: loss = 0.583362 (* 1 = 0.583362 loss)
I0726 00:48:13.025909 22939 sgd_solver.cpp:106] Iteration 98000, lr = 2.64156e-06
I0726 00:48:22.404855 22939 solver.cpp:228] Iteration 98100, loss = 0.535969
I0726 00:48:22.404899 22939 solver.cpp:244]     Train net output #0: loss = 0.535969 (* 1 = 0.535969 loss)
I0726 00:48:22.404906 22939 sgd_solver.cpp:106] Iteration 98100, lr = 2.63989e-06
I0726 00:48:31.802819 22939 solver.cpp:228] Iteration 98200, loss = 0.363611
I0726 00:48:31.802861 22939 solver.cpp:244]     Train net output #0: loss = 0.363611 (* 1 = 0.363611 loss)
I0726 00:48:31.802870 22939 sgd_solver.cpp:106] Iteration 98200, lr = 2.63821e-06
I0726 00:48:41.191540 22939 solver.cpp:228] Iteration 98300, loss = 0.417373
I0726 00:48:41.191586 22939 solver.cpp:244]     Train net output #0: loss = 0.417373 (* 1 = 0.417373 loss)
I0726 00:48:41.191592 22939 sgd_solver.cpp:106] Iteration 98300, lr = 2.63654e-06
I0726 00:48:50.583530 22939 solver.cpp:228] Iteration 98400, loss = 0.432277
I0726 00:48:50.583573 22939 solver.cpp:244]     Train net output #0: loss = 0.432277 (* 1 = 0.432277 loss)
I0726 00:48:50.583580 22939 sgd_solver.cpp:106] Iteration 98400, lr = 2.63487e-06
I0726 00:48:59.882572 22939 solver.cpp:337] Iteration 98500, Testing net (#0)
I0726 00:49:10.669972 22939 solver.cpp:404]     Test net output #0: accuracy = 0.748834
I0726 00:49:10.670011 22939 solver.cpp:404]     Test net output #1: loss = 0.615616 (* 1 = 0.615616 loss)
I0726 00:49:10.701656 22939 solver.cpp:228] Iteration 98500, loss = 0.459852
I0726 00:49:10.701714 22939 solver.cpp:244]     Train net output #0: loss = 0.459852 (* 1 = 0.459852 loss)
I0726 00:49:10.701732 22939 sgd_solver.cpp:106] Iteration 98500, lr = 2.6332e-06
I0726 00:49:20.175808 22939 solver.cpp:228] Iteration 98600, loss = 0.525155
I0726 00:49:20.175854 22939 solver.cpp:244]     Train net output #0: loss = 0.525155 (* 1 = 0.525155 loss)
I0726 00:49:20.175860 22939 sgd_solver.cpp:106] Iteration 98600, lr = 2.63153e-06
I0726 00:49:29.732759 22939 solver.cpp:228] Iteration 98700, loss = 0.393576
I0726 00:49:29.732806 22939 solver.cpp:244]     Train net output #0: loss = 0.393576 (* 1 = 0.393576 loss)
I0726 00:49:29.732813 22939 sgd_solver.cpp:106] Iteration 98700, lr = 2.62987e-06
I0726 00:49:39.168886 22939 solver.cpp:228] Iteration 98800, loss = 0.499697
I0726 00:49:39.168946 22939 solver.cpp:244]     Train net output #0: loss = 0.499697 (* 1 = 0.499697 loss)
I0726 00:49:39.168951 22939 sgd_solver.cpp:106] Iteration 98800, lr = 2.62821e-06
I0726 00:49:48.567492 22939 solver.cpp:228] Iteration 98900, loss = 0.456388
I0726 00:49:48.567538 22939 solver.cpp:244]     Train net output #0: loss = 0.456388 (* 1 = 0.456388 loss)
I0726 00:49:48.567544 22939 sgd_solver.cpp:106] Iteration 98900, lr = 2.62655e-06
I0726 00:49:57.873451 22939 solver.cpp:337] Iteration 99000, Testing net (#0)
I0726 00:50:04.646224 22939 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 00:50:08.809905 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747542
I0726 00:50:08.809954 22939 solver.cpp:404]     Test net output #1: loss = 0.620053 (* 1 = 0.620053 loss)
I0726 00:50:08.839889 22939 solver.cpp:228] Iteration 99000, loss = 0.430572
I0726 00:50:08.839922 22939 solver.cpp:244]     Train net output #0: loss = 0.430572 (* 1 = 0.430572 loss)
I0726 00:50:08.839934 22939 sgd_solver.cpp:106] Iteration 99000, lr = 2.6249e-06
I0726 00:50:18.156301 22939 solver.cpp:228] Iteration 99100, loss = 0.419137
I0726 00:50:18.156342 22939 solver.cpp:244]     Train net output #0: loss = 0.419137 (* 1 = 0.419137 loss)
I0726 00:50:18.156348 22939 sgd_solver.cpp:106] Iteration 99100, lr = 2.62324e-06
I0726 00:50:27.548759 22939 solver.cpp:228] Iteration 99200, loss = 0.441589
I0726 00:50:27.548799 22939 solver.cpp:244]     Train net output #0: loss = 0.441589 (* 1 = 0.441589 loss)
I0726 00:50:27.548804 22939 sgd_solver.cpp:106] Iteration 99200, lr = 2.62159e-06
I0726 00:50:37.087524 22939 solver.cpp:228] Iteration 99300, loss = 0.410718
I0726 00:50:37.087566 22939 solver.cpp:244]     Train net output #0: loss = 0.410718 (* 1 = 0.410718 loss)
I0726 00:50:37.087573 22939 sgd_solver.cpp:106] Iteration 99300, lr = 2.61995e-06
I0726 00:50:46.639417 22939 solver.cpp:228] Iteration 99400, loss = 0.440865
I0726 00:50:46.639466 22939 solver.cpp:244]     Train net output #0: loss = 0.440865 (* 1 = 0.440865 loss)
I0726 00:50:46.639472 22939 sgd_solver.cpp:106] Iteration 99400, lr = 2.6183e-06
I0726 00:50:55.975527 22939 solver.cpp:337] Iteration 99500, Testing net (#0)
I0726 00:51:06.717456 22939 solver.cpp:404]     Test net output #0: accuracy = 0.748917
I0726 00:51:06.717509 22939 solver.cpp:404]     Test net output #1: loss = 0.615714 (* 1 = 0.615714 loss)
I0726 00:51:06.746891 22939 solver.cpp:228] Iteration 99500, loss = 0.426046
I0726 00:51:06.746959 22939 solver.cpp:244]     Train net output #0: loss = 0.426046 (* 1 = 0.426046 loss)
I0726 00:51:06.746980 22939 sgd_solver.cpp:106] Iteration 99500, lr = 2.61666e-06
I0726 00:51:16.128470 22939 solver.cpp:228] Iteration 99600, loss = 0.485955
I0726 00:51:16.128512 22939 solver.cpp:244]     Train net output #0: loss = 0.485955 (* 1 = 0.485955 loss)
I0726 00:51:16.128518 22939 sgd_solver.cpp:106] Iteration 99600, lr = 2.61501e-06
I0726 00:51:25.517086 22939 solver.cpp:228] Iteration 99700, loss = 0.506041
I0726 00:51:25.517165 22939 solver.cpp:244]     Train net output #0: loss = 0.506041 (* 1 = 0.506041 loss)
I0726 00:51:25.517180 22939 sgd_solver.cpp:106] Iteration 99700, lr = 2.61338e-06
I0726 00:51:34.906826 22939 solver.cpp:228] Iteration 99800, loss = 0.463082
I0726 00:51:34.906867 22939 solver.cpp:244]     Train net output #0: loss = 0.463082 (* 1 = 0.463082 loss)
I0726 00:51:34.906872 22939 sgd_solver.cpp:106] Iteration 99800, lr = 2.61174e-06
I0726 00:51:44.292062 22939 solver.cpp:228] Iteration 99900, loss = 0.486859
I0726 00:51:44.292105 22939 solver.cpp:244]     Train net output #0: loss = 0.486859 (* 1 = 0.486859 loss)
I0726 00:51:44.292111 22939 sgd_solver.cpp:106] Iteration 99900, lr = 2.61011e-06
I0726 00:51:53.583127 22939 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_100000.caffemodel
I0726 00:51:53.925220 22939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random/person_vs_background_vs_random_lr_0.00001_iter_100000.solverstate
I0726 00:51:54.033071 22939 solver.cpp:337] Iteration 100000, Testing net (#0)
I0726 00:52:04.678407 22939 solver.cpp:404]     Test net output #0: accuracy = 0.747292
I0726 00:52:04.678467 22939 solver.cpp:404]     Test net output #1: loss = 0.620878 (* 1 = 0.620878 loss)
I0726 00:52:04.707875 22939 solver.cpp:228] Iteration 100000, loss = 0.433885
I0726 00:52:04.707933 22939 solver.cpp:244]     Train net output #0: loss = 0.433885 (* 1 = 0.433885 loss)
I0726 00:52:04.707945 22939 sgd_solver.cpp:106] Iteration 100000, lr = 2.60847e-06
.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
