WARNING: Logging before InitGoogleLogging() is written to STDERR
I0811 14:25:46.249835  8383 solver.cpp:48] Initializing solver from parameters: 
test_iter: 310
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
snapshot: 5000
snapshot_prefix: "models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001"
solver_mode: GPU
net: "nets/person_background_and_random_alex_net/trainval.prototxt"
I0811 14:25:46.251404  8383 solver.cpp:91] Creating training net from net file: nets/person_background_and_random_alex_net/trainval.prototxt
I0811 14:25:46.251855  8383 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0811 14:25:46.251873  8383 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0811 14:25:46.252012  8383 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0811 14:25:46.252110  8383 layer_factory.hpp:77] Creating layer mnist
I0811 14:25:46.252877  8383 net.cpp:91] Creating Layer mnist
I0811 14:25:46.252892  8383 net.cpp:399] mnist -> data
I0811 14:25:46.252907  8383 net.cpp:399] mnist -> label
I0811 14:25:46.252957  8383 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0811 14:25:46.255049  8390 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_train_lmdb
I0811 14:25:53.044878  8383 data_layer.cpp:41] output data size: 64,3,128,128
I0811 14:25:53.065721  8383 net.cpp:141] Setting up mnist
I0811 14:25:53.065795  8383 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0811 14:25:53.065803  8383 net.cpp:148] Top shape: 64 (64)
I0811 14:25:53.065805  8383 net.cpp:156] Memory required for data: 12583168
I0811 14:25:53.065814  8383 layer_factory.hpp:77] Creating layer conv1
I0811 14:25:53.065871  8383 net.cpp:91] Creating Layer conv1
I0811 14:25:53.065877  8383 net.cpp:425] conv1 <- data
I0811 14:25:53.065886  8383 net.cpp:399] conv1 -> conv1
I0811 14:25:53.207324  8383 net.cpp:141] Setting up conv1
I0811 14:25:53.207370  8383 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0811 14:25:53.207373  8383 net.cpp:156] Memory required for data: 34701568
I0811 14:25:53.207392  8383 layer_factory.hpp:77] Creating layer relu1
I0811 14:25:53.207411  8383 net.cpp:91] Creating Layer relu1
I0811 14:25:53.207415  8383 net.cpp:425] relu1 <- conv1
I0811 14:25:53.207420  8383 net.cpp:386] relu1 -> conv1 (in-place)
I0811 14:25:53.207600  8383 net.cpp:141] Setting up relu1
I0811 14:25:53.207620  8383 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0811 14:25:53.207634  8383 net.cpp:156] Memory required for data: 56819968
I0811 14:25:53.207638  8383 layer_factory.hpp:77] Creating layer norm1
I0811 14:25:53.207658  8383 net.cpp:91] Creating Layer norm1
I0811 14:25:53.207660  8383 net.cpp:425] norm1 <- conv1
I0811 14:25:53.207665  8383 net.cpp:399] norm1 -> norm1
I0811 14:25:53.207978  8383 net.cpp:141] Setting up norm1
I0811 14:25:53.208000  8383 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0811 14:25:53.208003  8383 net.cpp:156] Memory required for data: 78938368
I0811 14:25:53.208009  8383 layer_factory.hpp:77] Creating layer pool1
I0811 14:25:53.208015  8383 net.cpp:91] Creating Layer pool1
I0811 14:25:53.208019  8383 net.cpp:425] pool1 <- norm1
I0811 14:25:53.208024  8383 net.cpp:399] pool1 -> pool1
I0811 14:25:53.208070  8383 net.cpp:141] Setting up pool1
I0811 14:25:53.208075  8383 net.cpp:148] Top shape: 64 96 15 15 (1382400)
I0811 14:25:53.208077  8383 net.cpp:156] Memory required for data: 84467968
I0811 14:25:53.208079  8383 layer_factory.hpp:77] Creating layer conv2
I0811 14:25:53.208093  8383 net.cpp:91] Creating Layer conv2
I0811 14:25:53.208096  8383 net.cpp:425] conv2 <- pool1
I0811 14:25:53.208101  8383 net.cpp:399] conv2 -> conv2
I0811 14:25:53.217533  8383 net.cpp:141] Setting up conv2
I0811 14:25:53.217547  8383 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0811 14:25:53.217562  8383 net.cpp:156] Memory required for data: 99213568
I0811 14:25:53.217571  8383 layer_factory.hpp:77] Creating layer relu2
I0811 14:25:53.217576  8383 net.cpp:91] Creating Layer relu2
I0811 14:25:53.217579  8383 net.cpp:425] relu2 <- conv2
I0811 14:25:53.217586  8383 net.cpp:386] relu2 -> conv2 (in-place)
I0811 14:25:53.217911  8383 net.cpp:141] Setting up relu2
I0811 14:25:53.217922  8383 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0811 14:25:53.217936  8383 net.cpp:156] Memory required for data: 113959168
I0811 14:25:53.217939  8383 layer_factory.hpp:77] Creating layer norm2
I0811 14:25:53.217958  8383 net.cpp:91] Creating Layer norm2
I0811 14:25:53.217962  8383 net.cpp:425] norm2 <- conv2
I0811 14:25:53.217965  8383 net.cpp:399] norm2 -> norm2
I0811 14:25:53.218188  8383 net.cpp:141] Setting up norm2
I0811 14:25:53.218197  8383 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0811 14:25:53.218210  8383 net.cpp:156] Memory required for data: 128704768
I0811 14:25:53.218214  8383 layer_factory.hpp:77] Creating layer pool2
I0811 14:25:53.218233  8383 net.cpp:91] Creating Layer pool2
I0811 14:25:53.218236  8383 net.cpp:425] pool2 <- norm2
I0811 14:25:53.218242  8383 net.cpp:399] pool2 -> pool2
I0811 14:25:53.218283  8383 net.cpp:141] Setting up pool2
I0811 14:25:53.218288  8383 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0811 14:25:53.218291  8383 net.cpp:156] Memory required for data: 131916032
I0811 14:25:53.218293  8383 layer_factory.hpp:77] Creating layer conv3
I0811 14:25:53.218302  8383 net.cpp:91] Creating Layer conv3
I0811 14:25:53.218305  8383 net.cpp:425] conv3 <- pool2
I0811 14:25:53.218312  8383 net.cpp:399] conv3 -> conv3
I0811 14:25:53.242517  8383 net.cpp:141] Setting up conv3
I0811 14:25:53.242532  8383 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0811 14:25:53.242547  8383 net.cpp:156] Memory required for data: 136732928
I0811 14:25:53.242555  8383 layer_factory.hpp:77] Creating layer relu3
I0811 14:25:53.242561  8383 net.cpp:91] Creating Layer relu3
I0811 14:25:53.242564  8383 net.cpp:425] relu3 <- conv3
I0811 14:25:53.242571  8383 net.cpp:386] relu3 -> conv3 (in-place)
I0811 14:25:53.242877  8383 net.cpp:141] Setting up relu3
I0811 14:25:53.242899  8383 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0811 14:25:53.242902  8383 net.cpp:156] Memory required for data: 141549824
I0811 14:25:53.242905  8383 layer_factory.hpp:77] Creating layer conv4
I0811 14:25:53.242915  8383 net.cpp:91] Creating Layer conv4
I0811 14:25:53.242918  8383 net.cpp:425] conv4 <- conv3
I0811 14:25:53.242925  8383 net.cpp:399] conv4 -> conv4
I0811 14:25:53.261770  8383 net.cpp:141] Setting up conv4
I0811 14:25:53.261795  8383 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0811 14:25:53.261798  8383 net.cpp:156] Memory required for data: 146366720
I0811 14:25:53.261804  8383 layer_factory.hpp:77] Creating layer relu4
I0811 14:25:53.261809  8383 net.cpp:91] Creating Layer relu4
I0811 14:25:53.261814  8383 net.cpp:425] relu4 <- conv4
I0811 14:25:53.261818  8383 net.cpp:386] relu4 -> conv4 (in-place)
I0811 14:25:53.262147  8383 net.cpp:141] Setting up relu4
I0811 14:25:53.262171  8383 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0811 14:25:53.262173  8383 net.cpp:156] Memory required for data: 151183616
I0811 14:25:53.262176  8383 layer_factory.hpp:77] Creating layer conv5
I0811 14:25:53.262188  8383 net.cpp:91] Creating Layer conv5
I0811 14:25:53.262193  8383 net.cpp:425] conv5 <- conv4
I0811 14:25:53.262210  8383 net.cpp:399] conv5 -> conv5
I0811 14:25:53.275404  8383 net.cpp:141] Setting up conv5
I0811 14:25:53.275429  8383 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0811 14:25:53.275431  8383 net.cpp:156] Memory required for data: 154394880
I0811 14:25:53.275441  8383 layer_factory.hpp:77] Creating layer relu5
I0811 14:25:53.275447  8383 net.cpp:91] Creating Layer relu5
I0811 14:25:53.275450  8383 net.cpp:425] relu5 <- conv5
I0811 14:25:53.275454  8383 net.cpp:386] relu5 -> conv5 (in-place)
I0811 14:25:53.275779  8383 net.cpp:141] Setting up relu5
I0811 14:25:53.275790  8383 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0811 14:25:53.275804  8383 net.cpp:156] Memory required for data: 157606144
I0811 14:25:53.275807  8383 layer_factory.hpp:77] Creating layer pool5
I0811 14:25:53.275815  8383 net.cpp:91] Creating Layer pool5
I0811 14:25:53.275818  8383 net.cpp:425] pool5 <- conv5
I0811 14:25:53.275823  8383 net.cpp:399] pool5 -> pool5
I0811 14:25:53.275863  8383 net.cpp:141] Setting up pool5
I0811 14:25:53.275869  8383 net.cpp:148] Top shape: 64 256 3 3 (147456)
I0811 14:25:53.275871  8383 net.cpp:156] Memory required for data: 158195968
I0811 14:25:53.275874  8383 layer_factory.hpp:77] Creating layer fc6
I0811 14:25:53.275885  8383 net.cpp:91] Creating Layer fc6
I0811 14:25:53.275888  8383 net.cpp:425] fc6 <- pool5
I0811 14:25:53.275892  8383 net.cpp:399] fc6 -> fc6
I0811 14:25:53.525298  8383 net.cpp:141] Setting up fc6
I0811 14:25:53.525346  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:53.525349  8383 net.cpp:156] Memory required for data: 159244544
I0811 14:25:53.525359  8383 layer_factory.hpp:77] Creating layer relu6
I0811 14:25:53.525372  8383 net.cpp:91] Creating Layer relu6
I0811 14:25:53.525377  8383 net.cpp:425] relu6 <- fc6
I0811 14:25:53.525383  8383 net.cpp:386] relu6 -> fc6 (in-place)
I0811 14:25:53.525645  8383 net.cpp:141] Setting up relu6
I0811 14:25:53.525666  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:53.525670  8383 net.cpp:156] Memory required for data: 160293120
I0811 14:25:53.525672  8383 layer_factory.hpp:77] Creating layer drop6
I0811 14:25:53.525691  8383 net.cpp:91] Creating Layer drop6
I0811 14:25:53.525693  8383 net.cpp:425] drop6 <- fc6
I0811 14:25:53.525708  8383 net.cpp:386] drop6 -> fc6 (in-place)
I0811 14:25:53.525734  8383 net.cpp:141] Setting up drop6
I0811 14:25:53.525739  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:53.525741  8383 net.cpp:156] Memory required for data: 161341696
I0811 14:25:53.525744  8383 layer_factory.hpp:77] Creating layer fc7
I0811 14:25:53.525753  8383 net.cpp:91] Creating Layer fc7
I0811 14:25:53.525756  8383 net.cpp:425] fc7 <- fc6
I0811 14:25:53.525761  8383 net.cpp:399] fc7 -> fc7
I0811 14:25:54.040619  8383 net.cpp:141] Setting up fc7
I0811 14:25:54.040663  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:54.040668  8383 net.cpp:156] Memory required for data: 162390272
I0811 14:25:54.040680  8383 layer_factory.hpp:77] Creating layer relu7
I0811 14:25:54.040695  8383 net.cpp:91] Creating Layer relu7
I0811 14:25:54.040700  8383 net.cpp:425] relu7 <- fc7
I0811 14:25:54.040709  8383 net.cpp:386] relu7 -> fc7 (in-place)
I0811 14:25:54.041223  8383 net.cpp:141] Setting up relu7
I0811 14:25:54.041239  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:54.041244  8383 net.cpp:156] Memory required for data: 163438848
I0811 14:25:54.041247  8383 layer_factory.hpp:77] Creating layer drop7
I0811 14:25:54.041261  8383 net.cpp:91] Creating Layer drop7
I0811 14:25:54.041265  8383 net.cpp:425] drop7 <- fc7
I0811 14:25:54.041271  8383 net.cpp:386] drop7 -> fc7 (in-place)
I0811 14:25:54.041308  8383 net.cpp:141] Setting up drop7
I0811 14:25:54.041316  8383 net.cpp:148] Top shape: 64 4096 (262144)
I0811 14:25:54.041319  8383 net.cpp:156] Memory required for data: 164487424
I0811 14:25:54.041322  8383 layer_factory.hpp:77] Creating layer fc8
I0811 14:25:54.041333  8383 net.cpp:91] Creating Layer fc8
I0811 14:25:54.041337  8383 net.cpp:425] fc8 <- fc7
I0811 14:25:54.041343  8383 net.cpp:399] fc8 -> fc8
I0811 14:25:54.042351  8383 net.cpp:141] Setting up fc8
I0811 14:25:54.042367  8383 net.cpp:148] Top shape: 64 2 (128)
I0811 14:25:54.042371  8383 net.cpp:156] Memory required for data: 164487936
I0811 14:25:54.042379  8383 layer_factory.hpp:77] Creating layer loss
I0811 14:25:54.042387  8383 net.cpp:91] Creating Layer loss
I0811 14:25:54.042390  8383 net.cpp:425] loss <- fc8
I0811 14:25:54.042397  8383 net.cpp:425] loss <- label
I0811 14:25:54.042402  8383 net.cpp:399] loss -> loss
I0811 14:25:54.042419  8383 layer_factory.hpp:77] Creating layer loss
I0811 14:25:54.042742  8383 net.cpp:141] Setting up loss
I0811 14:25:54.042754  8383 net.cpp:148] Top shape: (1)
I0811 14:25:54.042758  8383 net.cpp:151]     with loss weight 1
I0811 14:25:54.042784  8383 net.cpp:156] Memory required for data: 164487940
I0811 14:25:54.042788  8383 net.cpp:217] loss needs backward computation.
I0811 14:25:54.042793  8383 net.cpp:217] fc8 needs backward computation.
I0811 14:25:54.042798  8383 net.cpp:217] drop7 needs backward computation.
I0811 14:25:54.042800  8383 net.cpp:217] relu7 needs backward computation.
I0811 14:25:54.042804  8383 net.cpp:217] fc7 needs backward computation.
I0811 14:25:54.042807  8383 net.cpp:217] drop6 needs backward computation.
I0811 14:25:54.042810  8383 net.cpp:217] relu6 needs backward computation.
I0811 14:25:54.042814  8383 net.cpp:217] fc6 needs backward computation.
I0811 14:25:54.042819  8383 net.cpp:217] pool5 needs backward computation.
I0811 14:25:54.042824  8383 net.cpp:217] relu5 needs backward computation.
I0811 14:25:54.042826  8383 net.cpp:217] conv5 needs backward computation.
I0811 14:25:54.042832  8383 net.cpp:217] relu4 needs backward computation.
I0811 14:25:54.042836  8383 net.cpp:217] conv4 needs backward computation.
I0811 14:25:54.042840  8383 net.cpp:217] relu3 needs backward computation.
I0811 14:25:54.042843  8383 net.cpp:217] conv3 needs backward computation.
I0811 14:25:54.042847  8383 net.cpp:217] pool2 needs backward computation.
I0811 14:25:54.042851  8383 net.cpp:217] norm2 needs backward computation.
I0811 14:25:54.042855  8383 net.cpp:217] relu2 needs backward computation.
I0811 14:25:54.042860  8383 net.cpp:217] conv2 needs backward computation.
I0811 14:25:54.042863  8383 net.cpp:217] pool1 needs backward computation.
I0811 14:25:54.042867  8383 net.cpp:217] norm1 needs backward computation.
I0811 14:25:54.042870  8383 net.cpp:217] relu1 needs backward computation.
I0811 14:25:54.042875  8383 net.cpp:217] conv1 needs backward computation.
I0811 14:25:54.042878  8383 net.cpp:219] mnist does not need backward computation.
I0811 14:25:54.042882  8383 net.cpp:261] This network produces output loss
I0811 14:25:54.042899  8383 net.cpp:274] Network initialization done.
I0811 14:25:54.043642  8383 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_background_and_random_alex_net/trainval.prototxt
I0811 14:25:54.043694  8383 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0811 14:25:54.043901  8383 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0811 14:25:54.044025  8383 layer_factory.hpp:77] Creating layer mnist
I0811 14:25:54.044158  8383 net.cpp:91] Creating Layer mnist
I0811 14:25:54.044168  8383 net.cpp:399] mnist -> data
I0811 14:25:54.044178  8383 net.cpp:399] mnist -> label
I0811 14:25:54.044188  8383 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0811 14:25:54.047793  8392 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_test_lmdb
I0811 14:25:54.049439  8383 data_layer.cpp:41] output data size: 100,3,128,128
I0811 14:25:54.087852  8383 net.cpp:141] Setting up mnist
I0811 14:25:54.087895  8383 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0811 14:25:54.087903  8383 net.cpp:148] Top shape: 100 (100)
I0811 14:25:54.087905  8383 net.cpp:156] Memory required for data: 19661200
I0811 14:25:54.087913  8383 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0811 14:25:54.087929  8383 net.cpp:91] Creating Layer label_mnist_1_split
I0811 14:25:54.087934  8383 net.cpp:425] label_mnist_1_split <- label
I0811 14:25:54.087941  8383 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0811 14:25:54.087954  8383 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0811 14:25:54.088080  8383 net.cpp:141] Setting up label_mnist_1_split
I0811 14:25:54.088091  8383 net.cpp:148] Top shape: 100 (100)
I0811 14:25:54.088095  8383 net.cpp:148] Top shape: 100 (100)
I0811 14:25:54.088099  8383 net.cpp:156] Memory required for data: 19662000
I0811 14:25:54.088102  8383 layer_factory.hpp:77] Creating layer conv1
I0811 14:25:54.088116  8383 net.cpp:91] Creating Layer conv1
I0811 14:25:54.088120  8383 net.cpp:425] conv1 <- data
I0811 14:25:54.088126  8383 net.cpp:399] conv1 -> conv1
I0811 14:25:54.093731  8383 net.cpp:141] Setting up conv1
I0811 14:25:54.093767  8383 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0811 14:25:54.093772  8383 net.cpp:156] Memory required for data: 54222000
I0811 14:25:54.093787  8383 layer_factory.hpp:77] Creating layer relu1
I0811 14:25:54.093798  8383 net.cpp:91] Creating Layer relu1
I0811 14:25:54.093802  8383 net.cpp:425] relu1 <- conv1
I0811 14:25:54.093809  8383 net.cpp:386] relu1 -> conv1 (in-place)
I0811 14:25:54.094116  8383 net.cpp:141] Setting up relu1
I0811 14:25:54.094130  8383 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0811 14:25:54.094135  8383 net.cpp:156] Memory required for data: 88782000
I0811 14:25:54.094138  8383 layer_factory.hpp:77] Creating layer norm1
I0811 14:25:54.094148  8383 net.cpp:91] Creating Layer norm1
I0811 14:25:54.094152  8383 net.cpp:425] norm1 <- conv1
I0811 14:25:54.094159  8383 net.cpp:399] norm1 -> norm1
I0811 14:25:54.094377  8383 net.cpp:141] Setting up norm1
I0811 14:25:54.094388  8383 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0811 14:25:54.094393  8383 net.cpp:156] Memory required for data: 123342000
I0811 14:25:54.094395  8383 layer_factory.hpp:77] Creating layer pool1
I0811 14:25:54.094403  8383 net.cpp:91] Creating Layer pool1
I0811 14:25:54.094408  8383 net.cpp:425] pool1 <- norm1
I0811 14:25:54.094413  8383 net.cpp:399] pool1 -> pool1
I0811 14:25:54.094451  8383 net.cpp:141] Setting up pool1
I0811 14:25:54.094457  8383 net.cpp:148] Top shape: 100 96 15 15 (2160000)
I0811 14:25:54.094460  8383 net.cpp:156] Memory required for data: 131982000
I0811 14:25:54.094463  8383 layer_factory.hpp:77] Creating layer conv2
I0811 14:25:54.094475  8383 net.cpp:91] Creating Layer conv2
I0811 14:25:54.094477  8383 net.cpp:425] conv2 <- pool1
I0811 14:25:54.094485  8383 net.cpp:399] conv2 -> conv2
I0811 14:25:54.104632  8383 net.cpp:141] Setting up conv2
I0811 14:25:54.104660  8383 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0811 14:25:54.104665  8383 net.cpp:156] Memory required for data: 155022000
I0811 14:25:54.104676  8383 layer_factory.hpp:77] Creating layer relu2
I0811 14:25:54.104682  8383 net.cpp:91] Creating Layer relu2
I0811 14:25:54.104686  8383 net.cpp:425] relu2 <- conv2
I0811 14:25:54.104689  8383 net.cpp:386] relu2 -> conv2 (in-place)
I0811 14:25:54.104985  8383 net.cpp:141] Setting up relu2
I0811 14:25:54.104996  8383 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0811 14:25:54.105010  8383 net.cpp:156] Memory required for data: 178062000
I0811 14:25:54.105015  8383 layer_factory.hpp:77] Creating layer norm2
I0811 14:25:54.105022  8383 net.cpp:91] Creating Layer norm2
I0811 14:25:54.105026  8383 net.cpp:425] norm2 <- conv2
I0811 14:25:54.105031  8383 net.cpp:399] norm2 -> norm2
I0811 14:25:54.105248  8383 net.cpp:141] Setting up norm2
I0811 14:25:54.105258  8383 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0811 14:25:54.105271  8383 net.cpp:156] Memory required for data: 201102000
I0811 14:25:54.105274  8383 layer_factory.hpp:77] Creating layer pool2
I0811 14:25:54.105281  8383 net.cpp:91] Creating Layer pool2
I0811 14:25:54.105284  8383 net.cpp:425] pool2 <- norm2
I0811 14:25:54.105289  8383 net.cpp:399] pool2 -> pool2
I0811 14:25:54.105335  8383 net.cpp:141] Setting up pool2
I0811 14:25:54.105340  8383 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0811 14:25:54.105343  8383 net.cpp:156] Memory required for data: 206119600
I0811 14:25:54.105345  8383 layer_factory.hpp:77] Creating layer conv3
I0811 14:25:54.105356  8383 net.cpp:91] Creating Layer conv3
I0811 14:25:54.105361  8383 net.cpp:425] conv3 <- pool2
I0811 14:25:54.105368  8383 net.cpp:399] conv3 -> conv3
I0811 14:25:54.129660  8383 net.cpp:141] Setting up conv3
I0811 14:25:54.129689  8383 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0811 14:25:54.129698  8383 net.cpp:156] Memory required for data: 213646000
I0811 14:25:54.129708  8383 layer_factory.hpp:77] Creating layer relu3
I0811 14:25:54.129714  8383 net.cpp:91] Creating Layer relu3
I0811 14:25:54.129717  8383 net.cpp:425] relu3 <- conv3
I0811 14:25:54.129721  8383 net.cpp:386] relu3 -> conv3 (in-place)
I0811 14:25:54.129915  8383 net.cpp:141] Setting up relu3
I0811 14:25:54.129925  8383 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0811 14:25:54.129938  8383 net.cpp:156] Memory required for data: 221172400
I0811 14:25:54.129941  8383 layer_factory.hpp:77] Creating layer conv4
I0811 14:25:54.129951  8383 net.cpp:91] Creating Layer conv4
I0811 14:25:54.129953  8383 net.cpp:425] conv4 <- conv3
I0811 14:25:54.129961  8383 net.cpp:399] conv4 -> conv4
I0811 14:25:54.149127  8383 net.cpp:141] Setting up conv4
I0811 14:25:54.149157  8383 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0811 14:25:54.149159  8383 net.cpp:156] Memory required for data: 228698800
I0811 14:25:54.149168  8383 layer_factory.hpp:77] Creating layer relu4
I0811 14:25:54.149174  8383 net.cpp:91] Creating Layer relu4
I0811 14:25:54.149178  8383 net.cpp:425] relu4 <- conv4
I0811 14:25:54.149183  8383 net.cpp:386] relu4 -> conv4 (in-place)
I0811 14:25:54.149490  8383 net.cpp:141] Setting up relu4
I0811 14:25:54.149502  8383 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0811 14:25:54.149516  8383 net.cpp:156] Memory required for data: 236225200
I0811 14:25:54.149519  8383 layer_factory.hpp:77] Creating layer conv5
I0811 14:25:54.149529  8383 net.cpp:91] Creating Layer conv5
I0811 14:25:54.149534  8383 net.cpp:425] conv5 <- conv4
I0811 14:25:54.149539  8383 net.cpp:399] conv5 -> conv5
I0811 14:25:54.162675  8383 net.cpp:141] Setting up conv5
I0811 14:25:54.162701  8383 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0811 14:25:54.162705  8383 net.cpp:156] Memory required for data: 241242800
I0811 14:25:54.162714  8383 layer_factory.hpp:77] Creating layer relu5
I0811 14:25:54.162720  8383 net.cpp:91] Creating Layer relu5
I0811 14:25:54.162724  8383 net.cpp:425] relu5 <- conv5
I0811 14:25:54.162729  8383 net.cpp:386] relu5 -> conv5 (in-place)
I0811 14:25:54.163019  8383 net.cpp:141] Setting up relu5
I0811 14:25:54.163031  8383 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0811 14:25:54.163045  8383 net.cpp:156] Memory required for data: 246260400
I0811 14:25:54.163048  8383 layer_factory.hpp:77] Creating layer pool5
I0811 14:25:54.163058  8383 net.cpp:91] Creating Layer pool5
I0811 14:25:54.163061  8383 net.cpp:425] pool5 <- conv5
I0811 14:25:54.163065  8383 net.cpp:399] pool5 -> pool5
I0811 14:25:54.163120  8383 net.cpp:141] Setting up pool5
I0811 14:25:54.163127  8383 net.cpp:148] Top shape: 100 256 3 3 (230400)
I0811 14:25:54.163130  8383 net.cpp:156] Memory required for data: 247182000
I0811 14:25:54.163133  8383 layer_factory.hpp:77] Creating layer fc6
I0811 14:25:54.163139  8383 net.cpp:91] Creating Layer fc6
I0811 14:25:54.163142  8383 net.cpp:425] fc6 <- pool5
I0811 14:25:54.163148  8383 net.cpp:399] fc6 -> fc6
I0811 14:25:54.412401  8383 net.cpp:141] Setting up fc6
I0811 14:25:54.412442  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.412446  8383 net.cpp:156] Memory required for data: 248820400
I0811 14:25:54.412456  8383 layer_factory.hpp:77] Creating layer relu6
I0811 14:25:54.412467  8383 net.cpp:91] Creating Layer relu6
I0811 14:25:54.412472  8383 net.cpp:425] relu6 <- fc6
I0811 14:25:54.412485  8383 net.cpp:386] relu6 -> fc6 (in-place)
I0811 14:25:54.412766  8383 net.cpp:141] Setting up relu6
I0811 14:25:54.412791  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.412804  8383 net.cpp:156] Memory required for data: 250458800
I0811 14:25:54.412807  8383 layer_factory.hpp:77] Creating layer drop6
I0811 14:25:54.412814  8383 net.cpp:91] Creating Layer drop6
I0811 14:25:54.412817  8383 net.cpp:425] drop6 <- fc6
I0811 14:25:54.412820  8383 net.cpp:386] drop6 -> fc6 (in-place)
I0811 14:25:54.412861  8383 net.cpp:141] Setting up drop6
I0811 14:25:54.412866  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.412868  8383 net.cpp:156] Memory required for data: 252097200
I0811 14:25:54.412871  8383 layer_factory.hpp:77] Creating layer fc7
I0811 14:25:54.412879  8383 net.cpp:91] Creating Layer fc7
I0811 14:25:54.412883  8383 net.cpp:425] fc7 <- fc6
I0811 14:25:54.412886  8383 net.cpp:399] fc7 -> fc7
I0811 14:25:54.918041  8383 net.cpp:141] Setting up fc7
I0811 14:25:54.918088  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.918092  8383 net.cpp:156] Memory required for data: 253735600
I0811 14:25:54.918103  8383 layer_factory.hpp:77] Creating layer relu7
I0811 14:25:54.918113  8383 net.cpp:91] Creating Layer relu7
I0811 14:25:54.918118  8383 net.cpp:425] relu7 <- fc7
I0811 14:25:54.918124  8383 net.cpp:386] relu7 -> fc7 (in-place)
I0811 14:25:54.918613  8383 net.cpp:141] Setting up relu7
I0811 14:25:54.918624  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.918639  8383 net.cpp:156] Memory required for data: 255374000
I0811 14:25:54.918642  8383 layer_factory.hpp:77] Creating layer drop7
I0811 14:25:54.918649  8383 net.cpp:91] Creating Layer drop7
I0811 14:25:54.918653  8383 net.cpp:425] drop7 <- fc7
I0811 14:25:54.918658  8383 net.cpp:386] drop7 -> fc7 (in-place)
I0811 14:25:54.918699  8383 net.cpp:141] Setting up drop7
I0811 14:25:54.918702  8383 net.cpp:148] Top shape: 100 4096 (409600)
I0811 14:25:54.918705  8383 net.cpp:156] Memory required for data: 257012400
I0811 14:25:54.918709  8383 layer_factory.hpp:77] Creating layer fc8
I0811 14:25:54.918715  8383 net.cpp:91] Creating Layer fc8
I0811 14:25:54.918718  8383 net.cpp:425] fc8 <- fc7
I0811 14:25:54.918725  8383 net.cpp:399] fc8 -> fc8
I0811 14:25:54.919086  8383 net.cpp:141] Setting up fc8
I0811 14:25:54.919095  8383 net.cpp:148] Top shape: 100 2 (200)
I0811 14:25:54.919108  8383 net.cpp:156] Memory required for data: 257013200
I0811 14:25:54.919113  8383 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0811 14:25:54.919119  8383 net.cpp:91] Creating Layer fc8_fc8_0_split
I0811 14:25:54.919121  8383 net.cpp:425] fc8_fc8_0_split <- fc8
I0811 14:25:54.919127  8383 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0811 14:25:54.919132  8383 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0811 14:25:54.919176  8383 net.cpp:141] Setting up fc8_fc8_0_split
I0811 14:25:54.919181  8383 net.cpp:148] Top shape: 100 2 (200)
I0811 14:25:54.919184  8383 net.cpp:148] Top shape: 100 2 (200)
I0811 14:25:54.919188  8383 net.cpp:156] Memory required for data: 257014800
I0811 14:25:54.919190  8383 layer_factory.hpp:77] Creating layer accuracy
I0811 14:25:54.919198  8383 net.cpp:91] Creating Layer accuracy
I0811 14:25:54.919199  8383 net.cpp:425] accuracy <- fc8_fc8_0_split_0
I0811 14:25:54.919203  8383 net.cpp:425] accuracy <- label_mnist_1_split_0
I0811 14:25:54.919208  8383 net.cpp:399] accuracy -> accuracy
I0811 14:25:54.919214  8383 net.cpp:141] Setting up accuracy
I0811 14:25:54.919217  8383 net.cpp:148] Top shape: (1)
I0811 14:25:54.919220  8383 net.cpp:156] Memory required for data: 257014804
I0811 14:25:54.919222  8383 layer_factory.hpp:77] Creating layer loss
I0811 14:25:54.919229  8383 net.cpp:91] Creating Layer loss
I0811 14:25:54.919231  8383 net.cpp:425] loss <- fc8_fc8_0_split_1
I0811 14:25:54.919234  8383 net.cpp:425] loss <- label_mnist_1_split_1
I0811 14:25:54.919239  8383 net.cpp:399] loss -> loss
I0811 14:25:54.919245  8383 layer_factory.hpp:77] Creating layer loss
I0811 14:25:54.919517  8383 net.cpp:141] Setting up loss
I0811 14:25:54.919525  8383 net.cpp:148] Top shape: (1)
I0811 14:25:54.919540  8383 net.cpp:151]     with loss weight 1
I0811 14:25:54.919553  8383 net.cpp:156] Memory required for data: 257014808
I0811 14:25:54.919555  8383 net.cpp:217] loss needs backward computation.
I0811 14:25:54.919559  8383 net.cpp:219] accuracy does not need backward computation.
I0811 14:25:54.919561  8383 net.cpp:217] fc8_fc8_0_split needs backward computation.
I0811 14:25:54.919564  8383 net.cpp:217] fc8 needs backward computation.
I0811 14:25:54.919566  8383 net.cpp:217] drop7 needs backward computation.
I0811 14:25:54.919569  8383 net.cpp:217] relu7 needs backward computation.
I0811 14:25:54.919571  8383 net.cpp:217] fc7 needs backward computation.
I0811 14:25:54.919574  8383 net.cpp:217] drop6 needs backward computation.
I0811 14:25:54.919587  8383 net.cpp:217] relu6 needs backward computation.
I0811 14:25:54.919589  8383 net.cpp:217] fc6 needs backward computation.
I0811 14:25:54.919592  8383 net.cpp:217] pool5 needs backward computation.
I0811 14:25:54.919595  8383 net.cpp:217] relu5 needs backward computation.
I0811 14:25:54.919598  8383 net.cpp:217] conv5 needs backward computation.
I0811 14:25:54.919600  8383 net.cpp:217] relu4 needs backward computation.
I0811 14:25:54.919603  8383 net.cpp:217] conv4 needs backward computation.
I0811 14:25:54.919606  8383 net.cpp:217] relu3 needs backward computation.
I0811 14:25:54.919610  8383 net.cpp:217] conv3 needs backward computation.
I0811 14:25:54.919612  8383 net.cpp:217] pool2 needs backward computation.
I0811 14:25:54.919615  8383 net.cpp:217] norm2 needs backward computation.
I0811 14:25:54.919617  8383 net.cpp:217] relu2 needs backward computation.
I0811 14:25:54.919620  8383 net.cpp:217] conv2 needs backward computation.
I0811 14:25:54.919623  8383 net.cpp:217] pool1 needs backward computation.
I0811 14:25:54.919626  8383 net.cpp:217] norm1 needs backward computation.
I0811 14:25:54.919628  8383 net.cpp:217] relu1 needs backward computation.
I0811 14:25:54.919631  8383 net.cpp:217] conv1 needs backward computation.
I0811 14:25:54.919634  8383 net.cpp:219] label_mnist_1_split does not need backward computation.
I0811 14:25:54.919637  8383 net.cpp:219] mnist does not need backward computation.
I0811 14:25:54.919641  8383 net.cpp:261] This network produces output accuracy
I0811 14:25:54.919642  8383 net.cpp:261] This network produces output loss
I0811 14:25:54.919661  8383 net.cpp:274] Network initialization done.
I0811 14:25:54.919749  8383 solver.cpp:60] Solver scaffolding done.
I0811 14:25:54.921586  8383 solver.cpp:337] Iteration 0, Testing net (#0)
I0811 14:25:55.031852  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:26:01.584746  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117548
I0811 14:26:01.584820  8383 solver.cpp:404]     Test net output #1: loss = 0.711748 (* 1 = 0.711748 loss)
I0811 14:26:01.605386  8383 solver.cpp:228] Iteration 0, loss = 0.69101
I0811 14:26:01.605448  8383 solver.cpp:244]     Train net output #0: loss = 0.69101 (* 1 = 0.69101 loss)
I0811 14:26:01.605468  8383 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0811 14:26:04.660703  8383 solver.cpp:228] Iteration 100, loss = 0.693464
I0811 14:26:04.660754  8383 solver.cpp:244]     Train net output #0: loss = 0.693464 (* 1 = 0.693464 loss)
I0811 14:26:04.660761  8383 sgd_solver.cpp:106] Iteration 100, lr = 0.000996266
I0811 14:26:07.707901  8383 solver.cpp:228] Iteration 200, loss = 0.699557
I0811 14:26:07.707949  8383 solver.cpp:244]     Train net output #0: loss = 0.699557 (* 1 = 0.699557 loss)
I0811 14:26:07.707957  8383 sgd_solver.cpp:106] Iteration 200, lr = 0.000992565
I0811 14:26:10.752935  8383 solver.cpp:228] Iteration 300, loss = 0.699328
I0811 14:26:10.753001  8383 solver.cpp:244]     Train net output #0: loss = 0.699328 (* 1 = 0.699328 loss)
I0811 14:26:10.753015  8383 sgd_solver.cpp:106] Iteration 300, lr = 0.000988896
I0811 14:26:13.835126  8383 solver.cpp:228] Iteration 400, loss = 0.68736
I0811 14:26:13.835178  8383 solver.cpp:244]     Train net output #0: loss = 0.68736 (* 1 = 0.68736 loss)
I0811 14:26:13.835186  8383 sgd_solver.cpp:106] Iteration 400, lr = 0.000985258
I0811 14:26:16.860613  8383 solver.cpp:337] Iteration 500, Testing net (#0)
I0811 14:26:23.430408  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882581
I0811 14:26:23.430451  8383 solver.cpp:404]     Test net output #1: loss = 0.679606 (* 1 = 0.679606 loss)
I0811 14:26:23.443413  8383 solver.cpp:228] Iteration 500, loss = 0.696837
I0811 14:26:23.443485  8383 solver.cpp:244]     Train net output #0: loss = 0.696837 (* 1 = 0.696837 loss)
I0811 14:26:23.443511  8383 sgd_solver.cpp:106] Iteration 500, lr = 0.000981651
I0811 14:26:26.507598  8383 solver.cpp:228] Iteration 600, loss = 0.691478
I0811 14:26:26.507665  8383 solver.cpp:244]     Train net output #0: loss = 0.691478 (* 1 = 0.691478 loss)
I0811 14:26:26.507673  8383 sgd_solver.cpp:106] Iteration 600, lr = 0.000978075
I0811 14:26:29.594936  8383 solver.cpp:228] Iteration 700, loss = 0.698833
I0811 14:26:29.594995  8383 solver.cpp:244]     Train net output #0: loss = 0.698833 (* 1 = 0.698833 loss)
I0811 14:26:29.595012  8383 sgd_solver.cpp:106] Iteration 700, lr = 0.000974529
I0811 14:26:32.716588  8383 solver.cpp:228] Iteration 800, loss = 0.687693
I0811 14:26:32.716663  8383 solver.cpp:244]     Train net output #0: loss = 0.687693 (* 1 = 0.687693 loss)
I0811 14:26:32.716673  8383 sgd_solver.cpp:106] Iteration 800, lr = 0.000971013
I0811 14:26:35.802362  8383 solver.cpp:228] Iteration 900, loss = 0.685277
I0811 14:26:35.802415  8383 solver.cpp:244]     Train net output #0: loss = 0.685277 (* 1 = 0.685277 loss)
I0811 14:26:35.802423  8383 sgd_solver.cpp:106] Iteration 900, lr = 0.000967526
I0811 14:26:38.859683  8383 solver.cpp:337] Iteration 1000, Testing net (#0)
I0811 14:26:45.716734  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882581
I0811 14:26:45.716787  8383 solver.cpp:404]     Test net output #1: loss = 0.630378 (* 1 = 0.630378 loss)
I0811 14:26:45.729056  8383 solver.cpp:228] Iteration 1000, loss = 0.701053
I0811 14:26:45.729087  8383 solver.cpp:244]     Train net output #0: loss = 0.701053 (* 1 = 0.701053 loss)
I0811 14:26:45.729109  8383 sgd_solver.cpp:106] Iteration 1000, lr = 0.000964069
I0811 14:26:47.833493  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:26:48.815093  8383 solver.cpp:228] Iteration 1100, loss = 0.689323
I0811 14:26:48.815124  8383 solver.cpp:244]     Train net output #0: loss = 0.689323 (* 1 = 0.689323 loss)
I0811 14:26:48.815130  8383 sgd_solver.cpp:106] Iteration 1100, lr = 0.00096064
I0811 14:26:51.924450  8383 solver.cpp:228] Iteration 1200, loss = 0.695221
I0811 14:26:51.924513  8383 solver.cpp:244]     Train net output #0: loss = 0.695221 (* 1 = 0.695221 loss)
I0811 14:26:51.924521  8383 sgd_solver.cpp:106] Iteration 1200, lr = 0.00095724
I0811 14:26:55.054569  8383 solver.cpp:228] Iteration 1300, loss = 0.691399
I0811 14:26:55.054618  8383 solver.cpp:244]     Train net output #0: loss = 0.691399 (* 1 = 0.691399 loss)
I0811 14:26:55.054625  8383 sgd_solver.cpp:106] Iteration 1300, lr = 0.000953867
I0811 14:26:58.202530  8383 solver.cpp:228] Iteration 1400, loss = 0.715638
I0811 14:26:58.202579  8383 solver.cpp:244]     Train net output #0: loss = 0.715638 (* 1 = 0.715638 loss)
I0811 14:26:58.202585  8383 sgd_solver.cpp:106] Iteration 1400, lr = 0.000950522
I0811 14:27:01.277823  8383 solver.cpp:337] Iteration 1500, Testing net (#0)
I0811 14:27:07.703685  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117484
I0811 14:27:07.703745  8383 solver.cpp:404]     Test net output #1: loss = 0.719184 (* 1 = 0.719184 loss)
I0811 14:27:07.716783  8383 solver.cpp:228] Iteration 1500, loss = 0.693017
I0811 14:27:07.716807  8383 solver.cpp:244]     Train net output #0: loss = 0.693017 (* 1 = 0.693017 loss)
I0811 14:27:07.716830  8383 sgd_solver.cpp:106] Iteration 1500, lr = 0.000947204
I0811 14:27:10.962088  8383 solver.cpp:228] Iteration 1600, loss = 0.702065
I0811 14:27:10.962146  8383 solver.cpp:244]     Train net output #0: loss = 0.702065 (* 1 = 0.702065 loss)
I0811 14:27:10.962157  8383 sgd_solver.cpp:106] Iteration 1600, lr = 0.000943913
I0811 14:27:14.325923  8383 solver.cpp:228] Iteration 1700, loss = 0.685733
I0811 14:27:14.325970  8383 solver.cpp:244]     Train net output #0: loss = 0.685733 (* 1 = 0.685733 loss)
I0811 14:27:14.325978  8383 sgd_solver.cpp:106] Iteration 1700, lr = 0.000940649
I0811 14:27:17.712323  8383 solver.cpp:228] Iteration 1800, loss = 0.696622
I0811 14:27:17.712381  8383 solver.cpp:244]     Train net output #0: loss = 0.696622 (* 1 = 0.696622 loss)
I0811 14:27:17.712389  8383 sgd_solver.cpp:106] Iteration 1800, lr = 0.000937411
I0811 14:27:21.101850  8383 solver.cpp:228] Iteration 1900, loss = 0.688032
I0811 14:27:21.101891  8383 solver.cpp:244]     Train net output #0: loss = 0.688032 (* 1 = 0.688032 loss)
I0811 14:27:21.101897  8383 sgd_solver.cpp:106] Iteration 1900, lr = 0.000934199
I0811 14:27:24.422648  8383 solver.cpp:337] Iteration 2000, Testing net (#0)
I0811 14:27:30.880960  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117387
I0811 14:27:30.881059  8383 solver.cpp:404]     Test net output #1: loss = 0.725305 (* 1 = 0.725305 loss)
I0811 14:27:30.892745  8383 solver.cpp:228] Iteration 2000, loss = 0.708152
I0811 14:27:30.892794  8383 solver.cpp:244]     Train net output #0: loss = 0.708152 (* 1 = 0.708152 loss)
I0811 14:27:30.892810  8383 sgd_solver.cpp:106] Iteration 2000, lr = 0.000931013
I0811 14:27:34.141804  8383 solver.cpp:228] Iteration 2100, loss = 0.692463
I0811 14:27:34.141862  8383 solver.cpp:244]     Train net output #0: loss = 0.692463 (* 1 = 0.692463 loss)
I0811 14:27:34.141870  8383 sgd_solver.cpp:106] Iteration 2100, lr = 0.000927851
I0811 14:27:37.377032  8383 solver.cpp:228] Iteration 2200, loss = 0.696725
I0811 14:27:37.377079  8383 solver.cpp:244]     Train net output #0: loss = 0.696725 (* 1 = 0.696725 loss)
I0811 14:27:37.377084  8383 sgd_solver.cpp:106] Iteration 2200, lr = 0.000924715
I0811 14:27:40.615926  8383 solver.cpp:228] Iteration 2300, loss = 0.69174
I0811 14:27:40.615978  8383 solver.cpp:244]     Train net output #0: loss = 0.69174 (* 1 = 0.69174 loss)
I0811 14:27:40.615984  8383 sgd_solver.cpp:106] Iteration 2300, lr = 0.000921603
I0811 14:27:43.854547  8383 solver.cpp:228] Iteration 2400, loss = 0.69045
I0811 14:27:43.854589  8383 solver.cpp:244]     Train net output #0: loss = 0.69045 (* 1 = 0.69045 loss)
I0811 14:27:43.854595  8383 sgd_solver.cpp:106] Iteration 2400, lr = 0.000918516
I0811 14:27:47.068142  8383 solver.cpp:337] Iteration 2500, Testing net (#0)
I0811 14:27:50.833830  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:27:54.107815  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117323
I0811 14:27:54.107872  8383 solver.cpp:404]     Test net output #1: loss = 0.749037 (* 1 = 0.749037 loss)
I0811 14:27:54.121279  8383 solver.cpp:228] Iteration 2500, loss = 0.706046
I0811 14:27:54.121347  8383 solver.cpp:244]     Train net output #0: loss = 0.706046 (* 1 = 0.706046 loss)
I0811 14:27:54.121372  8383 sgd_solver.cpp:106] Iteration 2500, lr = 0.000915452
I0811 14:27:57.342524  8383 solver.cpp:228] Iteration 2600, loss = 0.707512
I0811 14:27:57.342567  8383 solver.cpp:244]     Train net output #0: loss = 0.707512 (* 1 = 0.707512 loss)
I0811 14:27:57.342574  8383 sgd_solver.cpp:106] Iteration 2600, lr = 0.000912412
I0811 14:28:00.645421  8383 solver.cpp:228] Iteration 2700, loss = 0.699073
I0811 14:28:00.645465  8383 solver.cpp:244]     Train net output #0: loss = 0.699073 (* 1 = 0.699073 loss)
I0811 14:28:00.645473  8383 sgd_solver.cpp:106] Iteration 2700, lr = 0.000909396
I0811 14:28:03.985606  8383 solver.cpp:228] Iteration 2800, loss = 0.707697
I0811 14:28:03.985661  8383 solver.cpp:244]     Train net output #0: loss = 0.707697 (* 1 = 0.707697 loss)
I0811 14:28:03.985671  8383 sgd_solver.cpp:106] Iteration 2800, lr = 0.000906403
I0811 14:28:07.254366  8383 solver.cpp:228] Iteration 2900, loss = 0.70595
I0811 14:28:07.254420  8383 solver.cpp:244]     Train net output #0: loss = 0.70595 (* 1 = 0.70595 loss)
I0811 14:28:07.254426  8383 sgd_solver.cpp:106] Iteration 2900, lr = 0.000903433
I0811 14:28:10.471896  8383 solver.cpp:337] Iteration 3000, Testing net (#0)
I0811 14:28:17.014680  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882452
I0811 14:28:17.014750  8383 solver.cpp:404]     Test net output #1: loss = 0.631305 (* 1 = 0.631305 loss)
I0811 14:28:17.028028  8383 solver.cpp:228] Iteration 3000, loss = 0.694786
I0811 14:28:17.028059  8383 solver.cpp:244]     Train net output #0: loss = 0.694786 (* 1 = 0.694786 loss)
I0811 14:28:17.028084  8383 sgd_solver.cpp:106] Iteration 3000, lr = 0.000900485
I0811 14:28:20.266584  8383 solver.cpp:228] Iteration 3100, loss = 0.684384
I0811 14:28:20.266634  8383 solver.cpp:244]     Train net output #0: loss = 0.684384 (* 1 = 0.684384 loss)
I0811 14:28:20.266640  8383 sgd_solver.cpp:106] Iteration 3100, lr = 0.00089756
I0811 14:28:23.575800  8383 solver.cpp:228] Iteration 3200, loss = 0.687293
I0811 14:28:23.575845  8383 solver.cpp:244]     Train net output #0: loss = 0.687293 (* 1 = 0.687293 loss)
I0811 14:28:23.575852  8383 sgd_solver.cpp:106] Iteration 3200, lr = 0.000894657
I0811 14:28:26.868641  8383 solver.cpp:228] Iteration 3300, loss = 0.697181
I0811 14:28:26.868679  8383 solver.cpp:244]     Train net output #0: loss = 0.697181 (* 1 = 0.697181 loss)
I0811 14:28:26.868685  8383 sgd_solver.cpp:106] Iteration 3300, lr = 0.000891776
I0811 14:28:30.165385  8383 solver.cpp:228] Iteration 3400, loss = 0.698445
I0811 14:28:30.165447  8383 solver.cpp:244]     Train net output #0: loss = 0.698445 (* 1 = 0.698445 loss)
I0811 14:28:30.165454  8383 sgd_solver.cpp:106] Iteration 3400, lr = 0.000888916
I0811 14:28:33.446841  8383 solver.cpp:337] Iteration 3500, Testing net (#0)
I0811 14:28:39.906106  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0811 14:28:39.906168  8383 solver.cpp:404]     Test net output #1: loss = 0.636342 (* 1 = 0.636342 loss)
I0811 14:28:39.917302  8383 solver.cpp:228] Iteration 3500, loss = 0.697839
I0811 14:28:39.917363  8383 solver.cpp:244]     Train net output #0: loss = 0.697839 (* 1 = 0.697839 loss)
I0811 14:28:39.917387  8383 sgd_solver.cpp:106] Iteration 3500, lr = 0.000886077
I0811 14:28:43.169260  8383 solver.cpp:228] Iteration 3600, loss = 0.717916
I0811 14:28:43.169308  8383 solver.cpp:244]     Train net output #0: loss = 0.717916 (* 1 = 0.717916 loss)
I0811 14:28:43.169315  8383 sgd_solver.cpp:106] Iteration 3600, lr = 0.00088326
I0811 14:28:46.441407  8383 solver.cpp:228] Iteration 3700, loss = 0.704556
I0811 14:28:46.441453  8383 solver.cpp:244]     Train net output #0: loss = 0.704556 (* 1 = 0.704556 loss)
I0811 14:28:46.441459  8383 sgd_solver.cpp:106] Iteration 3700, lr = 0.000880463
I0811 14:28:49.725811  8383 solver.cpp:228] Iteration 3800, loss = 0.697458
I0811 14:28:49.725849  8383 solver.cpp:244]     Train net output #0: loss = 0.697458 (* 1 = 0.697458 loss)
I0811 14:28:49.725857  8383 sgd_solver.cpp:106] Iteration 3800, lr = 0.000877687
I0811 14:28:53.007648  8383 solver.cpp:228] Iteration 3900, loss = 0.688093
I0811 14:28:53.007685  8383 solver.cpp:244]     Train net output #0: loss = 0.688093 (* 1 = 0.688093 loss)
I0811 14:28:53.007691  8383 sgd_solver.cpp:106] Iteration 3900, lr = 0.000874932
I0811 14:28:56.276302  8383 solver.cpp:337] Iteration 4000, Testing net (#0)
I0811 14:28:59.070935  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:29:02.785876  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0811 14:29:02.785953  8383 solver.cpp:404]     Test net output #1: loss = 0.658976 (* 1 = 0.658976 loss)
I0811 14:29:02.796581  8383 solver.cpp:228] Iteration 4000, loss = 0.683712
I0811 14:29:02.796599  8383 solver.cpp:244]     Train net output #0: loss = 0.683712 (* 1 = 0.683712 loss)
I0811 14:29:02.796612  8383 sgd_solver.cpp:106] Iteration 4000, lr = 0.000872196
I0811 14:29:06.045166  8383 solver.cpp:228] Iteration 4100, loss = 0.694877
I0811 14:29:06.045219  8383 solver.cpp:244]     Train net output #0: loss = 0.694877 (* 1 = 0.694877 loss)
I0811 14:29:06.045225  8383 sgd_solver.cpp:106] Iteration 4100, lr = 0.00086948
I0811 14:29:09.361075  8383 solver.cpp:228] Iteration 4200, loss = 0.691455
I0811 14:29:09.361120  8383 solver.cpp:244]     Train net output #0: loss = 0.691455 (* 1 = 0.691455 loss)
I0811 14:29:09.361127  8383 sgd_solver.cpp:106] Iteration 4200, lr = 0.000866784
I0811 14:29:12.683795  8383 solver.cpp:228] Iteration 4300, loss = 0.702423
I0811 14:29:12.683842  8383 solver.cpp:244]     Train net output #0: loss = 0.702423 (* 1 = 0.702423 loss)
I0811 14:29:12.683848  8383 sgd_solver.cpp:106] Iteration 4300, lr = 0.000864108
I0811 14:29:15.982821  8383 solver.cpp:228] Iteration 4400, loss = 0.707278
I0811 14:29:15.982874  8383 solver.cpp:244]     Train net output #0: loss = 0.707278 (* 1 = 0.707278 loss)
I0811 14:29:15.982882  8383 sgd_solver.cpp:106] Iteration 4400, lr = 0.00086145
I0811 14:29:19.285187  8383 solver.cpp:337] Iteration 4500, Testing net (#0)
I0811 14:29:25.757740  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0811 14:29:25.757786  8383 solver.cpp:404]     Test net output #1: loss = 0.68197 (* 1 = 0.68197 loss)
I0811 14:29:25.770673  8383 solver.cpp:228] Iteration 4500, loss = 0.697766
I0811 14:29:25.770702  8383 solver.cpp:244]     Train net output #0: loss = 0.697766 (* 1 = 0.697766 loss)
I0811 14:29:25.770712  8383 sgd_solver.cpp:106] Iteration 4500, lr = 0.000858812
I0811 14:29:29.039391  8383 solver.cpp:228] Iteration 4600, loss = 0.692588
I0811 14:29:29.039427  8383 solver.cpp:244]     Train net output #0: loss = 0.692588 (* 1 = 0.692588 loss)
I0811 14:29:29.039433  8383 sgd_solver.cpp:106] Iteration 4600, lr = 0.000856192
I0811 14:29:32.364809  8383 solver.cpp:228] Iteration 4700, loss = 0.689605
I0811 14:29:32.364863  8383 solver.cpp:244]     Train net output #0: loss = 0.689605 (* 1 = 0.689605 loss)
I0811 14:29:32.364871  8383 sgd_solver.cpp:106] Iteration 4700, lr = 0.000853591
I0811 14:29:35.698001  8383 solver.cpp:228] Iteration 4800, loss = 0.687211
I0811 14:29:35.698053  8383 solver.cpp:244]     Train net output #0: loss = 0.687211 (* 1 = 0.687211 loss)
I0811 14:29:35.698060  8383 sgd_solver.cpp:106] Iteration 4800, lr = 0.000851008
I0811 14:29:39.049585  8383 solver.cpp:228] Iteration 4900, loss = 0.695339
I0811 14:29:39.049628  8383 solver.cpp:244]     Train net output #0: loss = 0.695339 (* 1 = 0.695339 loss)
I0811 14:29:39.049635  8383 sgd_solver.cpp:106] Iteration 4900, lr = 0.000848444
I0811 14:29:42.315564  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_5000.caffemodel
I0811 14:29:42.732803  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_5000.solverstate
I0811 14:29:42.868279  8383 solver.cpp:337] Iteration 5000, Testing net (#0)
I0811 14:29:49.275413  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117387
I0811 14:29:49.275478  8383 solver.cpp:404]     Test net output #1: loss = 0.720692 (* 1 = 0.720692 loss)
I0811 14:29:49.288573  8383 solver.cpp:228] Iteration 5000, loss = 0.689227
I0811 14:29:49.288606  8383 solver.cpp:244]     Train net output #0: loss = 0.689227 (* 1 = 0.689227 loss)
I0811 14:29:49.288628  8383 sgd_solver.cpp:106] Iteration 5000, lr = 0.000845897
I0811 14:29:52.564651  8383 solver.cpp:228] Iteration 5100, loss = 0.686884
I0811 14:29:52.564688  8383 solver.cpp:244]     Train net output #0: loss = 0.686884 (* 1 = 0.686884 loss)
I0811 14:29:52.564695  8383 sgd_solver.cpp:106] Iteration 5100, lr = 0.000843368
I0811 14:29:55.904814  8383 solver.cpp:228] Iteration 5200, loss = 0.704977
I0811 14:29:55.904855  8383 solver.cpp:244]     Train net output #0: loss = 0.704977 (* 1 = 0.704977 loss)
I0811 14:29:55.904862  8383 sgd_solver.cpp:106] Iteration 5200, lr = 0.000840857
I0811 14:29:59.272303  8383 solver.cpp:228] Iteration 5300, loss = 0.690902
I0811 14:29:59.272344  8383 solver.cpp:244]     Train net output #0: loss = 0.690902 (* 1 = 0.690902 loss)
I0811 14:29:59.272351  8383 sgd_solver.cpp:106] Iteration 5300, lr = 0.000838363
I0811 14:30:02.683666  8383 solver.cpp:228] Iteration 5400, loss = 0.68953
I0811 14:30:02.683708  8383 solver.cpp:244]     Train net output #0: loss = 0.68953 (* 1 = 0.68953 loss)
I0811 14:30:02.683715  8383 sgd_solver.cpp:106] Iteration 5400, lr = 0.000835886
I0811 14:30:05.990993  8383 solver.cpp:337] Iteration 5500, Testing net (#0)
I0811 14:30:08.377276  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:30:12.425207  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0811 14:30:12.425276  8383 solver.cpp:404]     Test net output #1: loss = 0.663997 (* 1 = 0.663997 loss)
I0811 14:30:12.435492  8383 solver.cpp:228] Iteration 5500, loss = 0.695687
I0811 14:30:12.435523  8383 solver.cpp:244]     Train net output #0: loss = 0.695687 (* 1 = 0.695687 loss)
I0811 14:30:12.435536  8383 sgd_solver.cpp:106] Iteration 5500, lr = 0.000833427
I0811 14:30:15.707345  8383 solver.cpp:228] Iteration 5600, loss = 0.698651
I0811 14:30:15.707381  8383 solver.cpp:244]     Train net output #0: loss = 0.698651 (* 1 = 0.698651 loss)
I0811 14:30:15.707387  8383 sgd_solver.cpp:106] Iteration 5600, lr = 0.000830984
I0811 14:30:19.031275  8383 solver.cpp:228] Iteration 5700, loss = 0.687168
I0811 14:30:19.031313  8383 solver.cpp:244]     Train net output #0: loss = 0.687168 (* 1 = 0.687168 loss)
I0811 14:30:19.031321  8383 sgd_solver.cpp:106] Iteration 5700, lr = 0.000828558
I0811 14:30:22.384749  8383 solver.cpp:228] Iteration 5800, loss = 0.696721
I0811 14:30:22.384789  8383 solver.cpp:244]     Train net output #0: loss = 0.696721 (* 1 = 0.696721 loss)
I0811 14:30:22.384798  8383 sgd_solver.cpp:106] Iteration 5800, lr = 0.000826148
I0811 14:30:25.663103  8383 solver.cpp:228] Iteration 5900, loss = 0.68154
I0811 14:30:25.663154  8383 solver.cpp:244]     Train net output #0: loss = 0.68154 (* 1 = 0.68154 loss)
I0811 14:30:25.663161  8383 sgd_solver.cpp:106] Iteration 5900, lr = 0.000823754
I0811 14:30:28.928093  8383 solver.cpp:337] Iteration 6000, Testing net (#0)
I0811 14:30:35.489944  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882419
I0811 14:30:35.490001  8383 solver.cpp:404]     Test net output #1: loss = 0.684491 (* 1 = 0.684491 loss)
I0811 14:30:35.503015  8383 solver.cpp:228] Iteration 6000, loss = 0.685234
I0811 14:30:35.503041  8383 solver.cpp:244]     Train net output #0: loss = 0.685234 (* 1 = 0.685234 loss)
I0811 14:30:35.503054  8383 sgd_solver.cpp:106] Iteration 6000, lr = 0.000821377
I0811 14:30:38.768352  8383 solver.cpp:228] Iteration 6100, loss = 0.6976
I0811 14:30:38.768393  8383 solver.cpp:244]     Train net output #0: loss = 0.6976 (* 1 = 0.6976 loss)
I0811 14:30:38.768399  8383 sgd_solver.cpp:106] Iteration 6100, lr = 0.000819015
I0811 14:30:42.054404  8383 solver.cpp:228] Iteration 6200, loss = 0.691077
I0811 14:30:42.054455  8383 solver.cpp:244]     Train net output #0: loss = 0.691077 (* 1 = 0.691077 loss)
I0811 14:30:42.054462  8383 sgd_solver.cpp:106] Iteration 6200, lr = 0.00081667
I0811 14:30:45.336416  8383 solver.cpp:228] Iteration 6300, loss = 0.682615
I0811 14:30:45.336468  8383 solver.cpp:244]     Train net output #0: loss = 0.682615 (* 1 = 0.682615 loss)
I0811 14:30:45.336478  8383 sgd_solver.cpp:106] Iteration 6300, lr = 0.00081434
I0811 14:30:48.672122  8383 solver.cpp:228] Iteration 6400, loss = 0.686457
I0811 14:30:48.672157  8383 solver.cpp:244]     Train net output #0: loss = 0.686457 (* 1 = 0.686457 loss)
I0811 14:30:48.672163  8383 sgd_solver.cpp:106] Iteration 6400, lr = 0.000812025
I0811 14:30:51.992285  8383 solver.cpp:337] Iteration 6500, Testing net (#0)
I0811 14:30:58.518462  8383 solver.cpp:404]     Test net output #0: accuracy = 0.11729
I0811 14:30:58.518522  8383 solver.cpp:404]     Test net output #1: loss = 0.710732 (* 1 = 0.710732 loss)
I0811 14:30:58.531641  8383 solver.cpp:228] Iteration 6500, loss = 0.691638
I0811 14:30:58.531680  8383 solver.cpp:244]     Train net output #0: loss = 0.691638 (* 1 = 0.691638 loss)
I0811 14:30:58.531705  8383 sgd_solver.cpp:106] Iteration 6500, lr = 0.000809726
I0811 14:31:01.859057  8383 solver.cpp:228] Iteration 6600, loss = 0.699839
I0811 14:31:01.859093  8383 solver.cpp:244]     Train net output #0: loss = 0.699839 (* 1 = 0.699839 loss)
I0811 14:31:01.859100  8383 sgd_solver.cpp:106] Iteration 6600, lr = 0.000807442
I0811 14:31:05.134181  8383 solver.cpp:228] Iteration 6700, loss = 0.694849
I0811 14:31:05.134220  8383 solver.cpp:244]     Train net output #0: loss = 0.694849 (* 1 = 0.694849 loss)
I0811 14:31:05.134227  8383 sgd_solver.cpp:106] Iteration 6700, lr = 0.000805173
I0811 14:31:08.477649  8383 solver.cpp:228] Iteration 6800, loss = 0.69266
I0811 14:31:08.477694  8383 solver.cpp:244]     Train net output #0: loss = 0.69266 (* 1 = 0.69266 loss)
I0811 14:31:08.477701  8383 sgd_solver.cpp:106] Iteration 6800, lr = 0.000802918
I0811 14:31:11.813578  8383 solver.cpp:228] Iteration 6900, loss = 0.692899
I0811 14:31:11.813612  8383 solver.cpp:244]     Train net output #0: loss = 0.692899 (* 1 = 0.692899 loss)
I0811 14:31:11.813618  8383 sgd_solver.cpp:106] Iteration 6900, lr = 0.000800679
I0811 14:31:15.155364  8383 solver.cpp:337] Iteration 7000, Testing net (#0)
I0811 14:31:17.345163  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:31:22.104058  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117516
I0811 14:31:22.104127  8383 solver.cpp:404]     Test net output #1: loss = 0.761973 (* 1 = 0.761973 loss)
I0811 14:31:22.116719  8383 solver.cpp:228] Iteration 7000, loss = 0.695117
I0811 14:31:22.116751  8383 solver.cpp:244]     Train net output #0: loss = 0.695117 (* 1 = 0.695117 loss)
I0811 14:31:22.116765  8383 sgd_solver.cpp:106] Iteration 7000, lr = 0.000798454
I0811 14:31:25.355286  8383 solver.cpp:228] Iteration 7100, loss = 0.685919
I0811 14:31:25.355326  8383 solver.cpp:244]     Train net output #0: loss = 0.685919 (* 1 = 0.685919 loss)
I0811 14:31:25.355334  8383 sgd_solver.cpp:106] Iteration 7100, lr = 0.000796243
I0811 14:31:28.642379  8383 solver.cpp:228] Iteration 7200, loss = 0.690895
I0811 14:31:28.642418  8383 solver.cpp:244]     Train net output #0: loss = 0.690895 (* 1 = 0.690895 loss)
I0811 14:31:28.642426  8383 sgd_solver.cpp:106] Iteration 7200, lr = 0.000794046
I0811 14:31:31.933410  8383 solver.cpp:228] Iteration 7300, loss = 0.703589
I0811 14:31:31.933462  8383 solver.cpp:244]     Train net output #0: loss = 0.703589 (* 1 = 0.703589 loss)
I0811 14:31:31.933471  8383 sgd_solver.cpp:106] Iteration 7300, lr = 0.000791864
I0811 14:31:35.250411  8383 solver.cpp:228] Iteration 7400, loss = 0.689116
I0811 14:31:35.250464  8383 solver.cpp:244]     Train net output #0: loss = 0.689116 (* 1 = 0.689116 loss)
I0811 14:31:35.250473  8383 sgd_solver.cpp:106] Iteration 7400, lr = 0.000789695
I0811 14:31:38.507645  8383 solver.cpp:337] Iteration 7500, Testing net (#0)
I0811 14:31:45.005177  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0811 14:31:45.005250  8383 solver.cpp:404]     Test net output #1: loss = 0.69204 (* 1 = 0.69204 loss)
I0811 14:31:45.018776  8383 solver.cpp:228] Iteration 7500, loss = 0.703131
I0811 14:31:45.018822  8383 solver.cpp:244]     Train net output #0: loss = 0.703131 (* 1 = 0.703131 loss)
I0811 14:31:45.018848  8383 sgd_solver.cpp:106] Iteration 7500, lr = 0.000787541
I0811 14:31:48.337278  8383 solver.cpp:228] Iteration 7600, loss = 0.691096
I0811 14:31:48.337313  8383 solver.cpp:244]     Train net output #0: loss = 0.691096 (* 1 = 0.691096 loss)
I0811 14:31:48.337321  8383 sgd_solver.cpp:106] Iteration 7600, lr = 0.0007854
I0811 14:31:51.642148  8383 solver.cpp:228] Iteration 7700, loss = 0.694075
I0811 14:31:51.642190  8383 solver.cpp:244]     Train net output #0: loss = 0.694075 (* 1 = 0.694075 loss)
I0811 14:31:51.642197  8383 sgd_solver.cpp:106] Iteration 7700, lr = 0.000783272
I0811 14:31:54.912081  8383 solver.cpp:228] Iteration 7800, loss = 0.694871
I0811 14:31:54.912123  8383 solver.cpp:244]     Train net output #0: loss = 0.694871 (* 1 = 0.694871 loss)
I0811 14:31:54.912132  8383 sgd_solver.cpp:106] Iteration 7800, lr = 0.000781158
I0811 14:31:58.174636  8383 solver.cpp:228] Iteration 7900, loss = 0.683279
I0811 14:31:58.174671  8383 solver.cpp:244]     Train net output #0: loss = 0.683279 (* 1 = 0.683279 loss)
I0811 14:31:58.174677  8383 sgd_solver.cpp:106] Iteration 7900, lr = 0.000779057
I0811 14:32:01.464577  8383 solver.cpp:337] Iteration 8000, Testing net (#0)
I0811 14:32:07.902108  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117484
I0811 14:32:07.902173  8383 solver.cpp:404]     Test net output #1: loss = 0.693589 (* 1 = 0.693589 loss)
I0811 14:32:07.915225  8383 solver.cpp:228] Iteration 8000, loss = 0.693719
I0811 14:32:07.915251  8383 solver.cpp:244]     Train net output #0: loss = 0.693719 (* 1 = 0.693719 loss)
I0811 14:32:07.915263  8383 sgd_solver.cpp:106] Iteration 8000, lr = 0.00077697
I0811 14:32:11.227457  8383 solver.cpp:228] Iteration 8100, loss = 0.67735
I0811 14:32:11.227491  8383 solver.cpp:244]     Train net output #0: loss = 0.67735 (* 1 = 0.67735 loss)
I0811 14:32:11.227497  8383 sgd_solver.cpp:106] Iteration 8100, lr = 0.000774895
I0811 14:32:14.493284  8383 solver.cpp:228] Iteration 8200, loss = 0.691924
I0811 14:32:14.493327  8383 solver.cpp:244]     Train net output #0: loss = 0.691924 (* 1 = 0.691924 loss)
I0811 14:32:14.493337  8383 sgd_solver.cpp:106] Iteration 8200, lr = 0.000772833
I0811 14:32:17.758707  8383 solver.cpp:228] Iteration 8300, loss = 0.694375
I0811 14:32:17.758746  8383 solver.cpp:244]     Train net output #0: loss = 0.694375 (* 1 = 0.694375 loss)
I0811 14:32:17.758754  8383 sgd_solver.cpp:106] Iteration 8300, lr = 0.000770784
I0811 14:32:21.024951  8383 solver.cpp:228] Iteration 8400, loss = 0.700633
I0811 14:32:21.024984  8383 solver.cpp:244]     Train net output #0: loss = 0.700633 (* 1 = 0.700633 loss)
I0811 14:32:21.024989  8383 sgd_solver.cpp:106] Iteration 8400, lr = 0.000768748
I0811 14:32:24.281397  8383 solver.cpp:337] Iteration 8500, Testing net (#0)
I0811 14:32:27.598152  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:32:31.111201  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0811 14:32:31.111259  8383 solver.cpp:404]     Test net output #1: loss = 0.657394 (* 1 = 0.657394 loss)
I0811 14:32:31.121623  8383 solver.cpp:228] Iteration 8500, loss = 0.6996
I0811 14:32:31.121656  8383 solver.cpp:244]     Train net output #0: loss = 0.6996 (* 1 = 0.6996 loss)
I0811 14:32:31.121668  8383 sgd_solver.cpp:106] Iteration 8500, lr = 0.000766724
I0811 14:32:34.345679  8383 solver.cpp:228] Iteration 8600, loss = 0.689681
I0811 14:32:34.345715  8383 solver.cpp:244]     Train net output #0: loss = 0.689681 (* 1 = 0.689681 loss)
I0811 14:32:34.345722  8383 sgd_solver.cpp:106] Iteration 8600, lr = 0.000764712
I0811 14:32:37.640923  8383 solver.cpp:228] Iteration 8700, loss = 0.6887
I0811 14:32:37.640969  8383 solver.cpp:244]     Train net output #0: loss = 0.6887 (* 1 = 0.6887 loss)
I0811 14:32:37.640975  8383 sgd_solver.cpp:106] Iteration 8700, lr = 0.000762713
I0811 14:32:40.981200  8383 solver.cpp:228] Iteration 8800, loss = 0.688028
I0811 14:32:40.981247  8383 solver.cpp:244]     Train net output #0: loss = 0.688028 (* 1 = 0.688028 loss)
I0811 14:32:40.981256  8383 sgd_solver.cpp:106] Iteration 8800, lr = 0.000760726
I0811 14:32:44.295845  8383 solver.cpp:228] Iteration 8900, loss = 0.696621
I0811 14:32:44.295881  8383 solver.cpp:244]     Train net output #0: loss = 0.696621 (* 1 = 0.696621 loss)
I0811 14:32:44.295887  8383 sgd_solver.cpp:106] Iteration 8900, lr = 0.000758751
I0811 14:32:47.602334  8383 solver.cpp:337] Iteration 9000, Testing net (#0)
I0811 14:32:54.450902  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117613
I0811 14:32:54.450970  8383 solver.cpp:404]     Test net output #1: loss = 0.733312 (* 1 = 0.733312 loss)
I0811 14:32:54.462041  8383 solver.cpp:228] Iteration 9000, loss = 0.692374
I0811 14:32:54.462107  8383 solver.cpp:244]     Train net output #0: loss = 0.692374 (* 1 = 0.692374 loss)
I0811 14:32:54.462132  8383 sgd_solver.cpp:106] Iteration 9000, lr = 0.000756788
I0811 14:32:57.707468  8383 solver.cpp:228] Iteration 9100, loss = 0.684424
I0811 14:32:57.707504  8383 solver.cpp:244]     Train net output #0: loss = 0.684424 (* 1 = 0.684424 loss)
I0811 14:32:57.707510  8383 sgd_solver.cpp:106] Iteration 9100, lr = 0.000754836
I0811 14:33:01.055347  8383 solver.cpp:228] Iteration 9200, loss = 0.679012
I0811 14:33:01.055394  8383 solver.cpp:244]     Train net output #0: loss = 0.679012 (* 1 = 0.679012 loss)
I0811 14:33:01.055402  8383 sgd_solver.cpp:106] Iteration 9200, lr = 0.000752897
I0811 14:33:04.397621  8383 solver.cpp:228] Iteration 9300, loss = 0.695637
I0811 14:33:04.397675  8383 solver.cpp:244]     Train net output #0: loss = 0.695637 (* 1 = 0.695637 loss)
I0811 14:33:04.397683  8383 sgd_solver.cpp:106] Iteration 9300, lr = 0.000750969
I0811 14:33:07.725261  8383 solver.cpp:228] Iteration 9400, loss = 0.703501
I0811 14:33:07.725296  8383 solver.cpp:244]     Train net output #0: loss = 0.703501 (* 1 = 0.703501 loss)
I0811 14:33:07.725301  8383 sgd_solver.cpp:106] Iteration 9400, lr = 0.000749052
I0811 14:33:11.025183  8383 solver.cpp:337] Iteration 9500, Testing net (#0)
I0811 14:33:17.938813  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117677
I0811 14:33:17.938869  8383 solver.cpp:404]     Test net output #1: loss = 0.713801 (* 1 = 0.713801 loss)
I0811 14:33:17.952078  8383 solver.cpp:228] Iteration 9500, loss = 0.694808
I0811 14:33:17.952157  8383 solver.cpp:244]     Train net output #0: loss = 0.694808 (* 1 = 0.694808 loss)
I0811 14:33:17.952180  8383 sgd_solver.cpp:106] Iteration 9500, lr = 0.000747147
I0811 14:33:21.230556  8383 solver.cpp:228] Iteration 9600, loss = 0.688482
I0811 14:33:21.230612  8383 solver.cpp:244]     Train net output #0: loss = 0.688482 (* 1 = 0.688482 loss)
I0811 14:33:21.230619  8383 sgd_solver.cpp:106] Iteration 9600, lr = 0.000745253
I0811 14:33:24.557767  8383 solver.cpp:228] Iteration 9700, loss = 0.696122
I0811 14:33:24.557814  8383 solver.cpp:244]     Train net output #0: loss = 0.696122 (* 1 = 0.696122 loss)
I0811 14:33:24.557824  8383 sgd_solver.cpp:106] Iteration 9700, lr = 0.00074337
I0811 14:33:27.466383  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:33:27.822688  8383 solver.cpp:228] Iteration 9800, loss = 0.692059
I0811 14:33:27.822712  8383 solver.cpp:244]     Train net output #0: loss = 0.692059 (* 1 = 0.692059 loss)
I0811 14:33:27.822718  8383 sgd_solver.cpp:106] Iteration 9800, lr = 0.000741499
I0811 14:33:31.111480  8383 solver.cpp:228] Iteration 9900, loss = 0.700933
I0811 14:33:31.111541  8383 solver.cpp:244]     Train net output #0: loss = 0.700933 (* 1 = 0.700933 loss)
I0811 14:33:31.111548  8383 sgd_solver.cpp:106] Iteration 9900, lr = 0.000739638
I0811 14:33:34.368881  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_10000.caffemodel
I0811 14:33:34.745200  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_10000.solverstate
I0811 14:33:34.880620  8383 solver.cpp:337] Iteration 10000, Testing net (#0)
I0811 14:33:41.546875  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117581
I0811 14:33:41.546947  8383 solver.cpp:404]     Test net output #1: loss = 0.734067 (* 1 = 0.734067 loss)
I0811 14:33:41.560155  8383 solver.cpp:228] Iteration 10000, loss = 0.694884
I0811 14:33:41.560220  8383 solver.cpp:244]     Train net output #0: loss = 0.694884 (* 1 = 0.694884 loss)
I0811 14:33:41.560243  8383 sgd_solver.cpp:106] Iteration 10000, lr = 0.000737788
I0811 14:33:44.796847  8383 solver.cpp:228] Iteration 10100, loss = 0.669377
I0811 14:33:44.796896  8383 solver.cpp:244]     Train net output #0: loss = 0.669377 (* 1 = 0.669377 loss)
I0811 14:33:44.796903  8383 sgd_solver.cpp:106] Iteration 10100, lr = 0.000735949
I0811 14:33:48.087821  8383 solver.cpp:228] Iteration 10200, loss = 0.690948
I0811 14:33:48.087863  8383 solver.cpp:244]     Train net output #0: loss = 0.690948 (* 1 = 0.690948 loss)
I0811 14:33:48.087870  8383 sgd_solver.cpp:106] Iteration 10200, lr = 0.00073412
I0811 14:33:51.378963  8383 solver.cpp:228] Iteration 10300, loss = 0.699982
I0811 14:33:51.379004  8383 solver.cpp:244]     Train net output #0: loss = 0.699982 (* 1 = 0.699982 loss)
I0811 14:33:51.379010  8383 sgd_solver.cpp:106] Iteration 10300, lr = 0.000732303
I0811 14:33:54.693867  8383 solver.cpp:228] Iteration 10400, loss = 0.685894
I0811 14:33:54.693903  8383 solver.cpp:244]     Train net output #0: loss = 0.685894 (* 1 = 0.685894 loss)
I0811 14:33:54.693909  8383 sgd_solver.cpp:106] Iteration 10400, lr = 0.000730495
I0811 14:33:58.004993  8383 solver.cpp:337] Iteration 10500, Testing net (#0)
I0811 14:34:04.647157  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0811 14:34:04.647229  8383 solver.cpp:404]     Test net output #1: loss = 0.638031 (* 1 = 0.638031 loss)
I0811 14:34:04.660723  8383 solver.cpp:228] Iteration 10500, loss = 0.706931
I0811 14:34:04.660787  8383 solver.cpp:244]     Train net output #0: loss = 0.706931 (* 1 = 0.706931 loss)
I0811 14:34:04.660817  8383 sgd_solver.cpp:106] Iteration 10500, lr = 0.000728698
I0811 14:34:07.878015  8383 solver.cpp:228] Iteration 10600, loss = 0.705645
I0811 14:34:07.878059  8383 solver.cpp:244]     Train net output #0: loss = 0.705645 (* 1 = 0.705645 loss)
I0811 14:34:07.878065  8383 sgd_solver.cpp:106] Iteration 10600, lr = 0.000726911
I0811 14:34:11.146353  8383 solver.cpp:228] Iteration 10700, loss = 0.69423
I0811 14:34:11.146409  8383 solver.cpp:244]     Train net output #0: loss = 0.69423 (* 1 = 0.69423 loss)
I0811 14:34:11.146416  8383 sgd_solver.cpp:106] Iteration 10700, lr = 0.000725135
I0811 14:34:14.440978  8383 solver.cpp:228] Iteration 10800, loss = 0.692383
I0811 14:34:14.441017  8383 solver.cpp:244]     Train net output #0: loss = 0.692383 (* 1 = 0.692383 loss)
I0811 14:34:14.441025  8383 sgd_solver.cpp:106] Iteration 10800, lr = 0.000723368
I0811 14:34:17.715340  8383 solver.cpp:228] Iteration 10900, loss = 0.697768
I0811 14:34:17.715394  8383 solver.cpp:244]     Train net output #0: loss = 0.697768 (* 1 = 0.697768 loss)
I0811 14:34:17.715400  8383 sgd_solver.cpp:106] Iteration 10900, lr = 0.000721612
I0811 14:34:21.002838  8383 solver.cpp:337] Iteration 11000, Testing net (#0)
I0811 14:34:27.552930  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882323
I0811 14:34:27.553014  8383 solver.cpp:404]     Test net output #1: loss = 0.654862 (* 1 = 0.654862 loss)
I0811 14:34:27.569025  8383 solver.cpp:228] Iteration 11000, loss = 0.69637
I0811 14:34:27.569072  8383 solver.cpp:244]     Train net output #0: loss = 0.69637 (* 1 = 0.69637 loss)
I0811 14:34:27.569094  8383 sgd_solver.cpp:106] Iteration 11000, lr = 0.000719865
I0811 14:34:30.875195  8383 solver.cpp:228] Iteration 11100, loss = 0.68834
I0811 14:34:30.875232  8383 solver.cpp:244]     Train net output #0: loss = 0.68834 (* 1 = 0.68834 loss)
I0811 14:34:30.875238  8383 sgd_solver.cpp:106] Iteration 11100, lr = 0.000718129
I0811 14:34:32.543287  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:34:34.154100  8383 solver.cpp:228] Iteration 11200, loss = 0.71043
I0811 14:34:34.154142  8383 solver.cpp:244]     Train net output #0: loss = 0.71043 (* 1 = 0.71043 loss)
I0811 14:34:34.154150  8383 sgd_solver.cpp:106] Iteration 11200, lr = 0.000716402
I0811 14:34:37.434854  8383 solver.cpp:228] Iteration 11300, loss = 0.69482
I0811 14:34:37.434898  8383 solver.cpp:244]     Train net output #0: loss = 0.69482 (* 1 = 0.69482 loss)
I0811 14:34:37.434906  8383 sgd_solver.cpp:106] Iteration 11300, lr = 0.000714684
I0811 14:34:40.774379  8383 solver.cpp:228] Iteration 11400, loss = 0.695715
I0811 14:34:40.774421  8383 solver.cpp:244]     Train net output #0: loss = 0.695715 (* 1 = 0.695715 loss)
I0811 14:34:40.774428  8383 sgd_solver.cpp:106] Iteration 11400, lr = 0.000712977
I0811 14:34:44.018512  8383 solver.cpp:337] Iteration 11500, Testing net (#0)
I0811 14:34:50.562846  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0811 14:34:50.562933  8383 solver.cpp:404]     Test net output #1: loss = 0.666497 (* 1 = 0.666497 loss)
I0811 14:34:50.574434  8383 solver.cpp:228] Iteration 11500, loss = 0.700604
I0811 14:34:50.574493  8383 solver.cpp:244]     Train net output #0: loss = 0.700604 (* 1 = 0.700604 loss)
I0811 14:34:50.574522  8383 sgd_solver.cpp:106] Iteration 11500, lr = 0.000711278
I0811 14:34:53.847822  8383 solver.cpp:228] Iteration 11600, loss = 0.689416
I0811 14:34:53.847861  8383 solver.cpp:244]     Train net output #0: loss = 0.689416 (* 1 = 0.689416 loss)
I0811 14:34:53.847867  8383 sgd_solver.cpp:106] Iteration 11600, lr = 0.00070959
I0811 14:34:57.117048  8383 solver.cpp:228] Iteration 11700, loss = 0.696627
I0811 14:34:57.117110  8383 solver.cpp:244]     Train net output #0: loss = 0.696627 (* 1 = 0.696627 loss)
I0811 14:34:57.117118  8383 sgd_solver.cpp:106] Iteration 11700, lr = 0.00070791
I0811 14:35:00.373703  8383 solver.cpp:228] Iteration 11800, loss = 0.694346
I0811 14:35:00.373755  8383 solver.cpp:244]     Train net output #0: loss = 0.694346 (* 1 = 0.694346 loss)
I0811 14:35:00.373764  8383 sgd_solver.cpp:106] Iteration 11800, lr = 0.00070624
I0811 14:35:03.638695  8383 solver.cpp:228] Iteration 11900, loss = 0.695984
I0811 14:35:03.638734  8383 solver.cpp:244]     Train net output #0: loss = 0.695984 (* 1 = 0.695984 loss)
I0811 14:35:03.638741  8383 sgd_solver.cpp:106] Iteration 11900, lr = 0.000704579
I0811 14:35:06.939730  8383 solver.cpp:337] Iteration 12000, Testing net (#0)
I0811 14:35:13.686028  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117613
I0811 14:35:13.686085  8383 solver.cpp:404]     Test net output #1: loss = 0.696467 (* 1 = 0.696467 loss)
I0811 14:35:13.699357  8383 solver.cpp:228] Iteration 12000, loss = 0.701502
I0811 14:35:13.699390  8383 solver.cpp:244]     Train net output #0: loss = 0.701502 (* 1 = 0.701502 loss)
I0811 14:35:13.699403  8383 sgd_solver.cpp:106] Iteration 12000, lr = 0.000702927
I0811 14:35:16.952962  8383 solver.cpp:228] Iteration 12100, loss = 0.69401
I0811 14:35:16.953006  8383 solver.cpp:244]     Train net output #0: loss = 0.69401 (* 1 = 0.69401 loss)
I0811 14:35:16.953013  8383 sgd_solver.cpp:106] Iteration 12100, lr = 0.000701284
I0811 14:35:20.318253  8383 solver.cpp:228] Iteration 12200, loss = 0.693437
I0811 14:35:20.318308  8383 solver.cpp:244]     Train net output #0: loss = 0.693437 (* 1 = 0.693437 loss)
I0811 14:35:20.318316  8383 sgd_solver.cpp:106] Iteration 12200, lr = 0.00069965
I0811 14:35:23.634572  8383 solver.cpp:228] Iteration 12300, loss = 0.689399
I0811 14:35:23.634716  8383 solver.cpp:244]     Train net output #0: loss = 0.689399 (* 1 = 0.689399 loss)
I0811 14:35:23.634726  8383 sgd_solver.cpp:106] Iteration 12300, lr = 0.000698024
I0811 14:35:26.966778  8383 solver.cpp:228] Iteration 12400, loss = 0.693904
I0811 14:35:26.966820  8383 solver.cpp:244]     Train net output #0: loss = 0.693904 (* 1 = 0.693904 loss)
I0811 14:35:26.966826  8383 sgd_solver.cpp:106] Iteration 12400, lr = 0.000696408
I0811 14:35:30.247429  8383 solver.cpp:337] Iteration 12500, Testing net (#0)
I0811 14:35:35.098160  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:35:36.949795  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117452
I0811 14:35:36.949890  8383 solver.cpp:404]     Test net output #1: loss = 0.696523 (* 1 = 0.696523 loss)
I0811 14:35:36.963395  8383 solver.cpp:228] Iteration 12500, loss = 0.694061
I0811 14:35:36.963462  8383 solver.cpp:244]     Train net output #0: loss = 0.694061 (* 1 = 0.694061 loss)
I0811 14:35:36.963488  8383 sgd_solver.cpp:106] Iteration 12500, lr = 0.0006948
I0811 14:35:40.198632  8383 solver.cpp:228] Iteration 12600, loss = 0.691353
I0811 14:35:40.198681  8383 solver.cpp:244]     Train net output #0: loss = 0.691353 (* 1 = 0.691353 loss)
I0811 14:35:40.198688  8383 sgd_solver.cpp:106] Iteration 12600, lr = 0.000693201
I0811 14:35:43.464226  8383 solver.cpp:228] Iteration 12700, loss = 0.696448
I0811 14:35:43.464277  8383 solver.cpp:244]     Train net output #0: loss = 0.696448 (* 1 = 0.696448 loss)
I0811 14:35:43.464285  8383 sgd_solver.cpp:106] Iteration 12700, lr = 0.000691611
I0811 14:35:46.776118  8383 solver.cpp:228] Iteration 12800, loss = 0.69635
I0811 14:35:46.776172  8383 solver.cpp:244]     Train net output #0: loss = 0.69635 (* 1 = 0.69635 loss)
I0811 14:35:46.776182  8383 sgd_solver.cpp:106] Iteration 12800, lr = 0.000690029
I0811 14:35:50.077309  8383 solver.cpp:228] Iteration 12900, loss = 0.692523
I0811 14:35:50.077354  8383 solver.cpp:244]     Train net output #0: loss = 0.692523 (* 1 = 0.692523 loss)
I0811 14:35:50.077361  8383 sgd_solver.cpp:106] Iteration 12900, lr = 0.000688455
I0811 14:35:53.320547  8383 solver.cpp:337] Iteration 13000, Testing net (#0)
I0811 14:35:59.970296  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0811 14:35:59.970366  8383 solver.cpp:404]     Test net output #1: loss = 0.656521 (* 1 = 0.656521 loss)
I0811 14:35:59.980432  8383 solver.cpp:228] Iteration 13000, loss = 0.69189
I0811 14:35:59.980463  8383 solver.cpp:244]     Train net output #0: loss = 0.69189 (* 1 = 0.69189 loss)
I0811 14:35:59.980474  8383 sgd_solver.cpp:106] Iteration 13000, lr = 0.00068689
I0811 14:36:03.246759  8383 solver.cpp:228] Iteration 13100, loss = 0.698882
I0811 14:36:03.246795  8383 solver.cpp:244]     Train net output #0: loss = 0.698882 (* 1 = 0.698882 loss)
I0811 14:36:03.246801  8383 sgd_solver.cpp:106] Iteration 13100, lr = 0.000685333
I0811 14:36:06.577869  8383 solver.cpp:228] Iteration 13200, loss = 0.699804
I0811 14:36:06.577986  8383 solver.cpp:244]     Train net output #0: loss = 0.699804 (* 1 = 0.699804 loss)
I0811 14:36:06.578016  8383 sgd_solver.cpp:106] Iteration 13200, lr = 0.000683784
I0811 14:36:09.858764  8383 solver.cpp:228] Iteration 13300, loss = 0.694617
I0811 14:36:09.858844  8383 solver.cpp:244]     Train net output #0: loss = 0.694617 (* 1 = 0.694617 loss)
I0811 14:36:09.858853  8383 sgd_solver.cpp:106] Iteration 13300, lr = 0.000682243
I0811 14:36:13.133627  8383 solver.cpp:228] Iteration 13400, loss = 0.70484
I0811 14:36:13.133663  8383 solver.cpp:244]     Train net output #0: loss = 0.70484 (* 1 = 0.70484 loss)
I0811 14:36:13.133671  8383 sgd_solver.cpp:106] Iteration 13400, lr = 0.000680711
I0811 14:36:16.400599  8383 solver.cpp:337] Iteration 13500, Testing net (#0)
I0811 14:36:23.291515  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882194
I0811 14:36:23.291577  8383 solver.cpp:404]     Test net output #1: loss = 0.679204 (* 1 = 0.679204 loss)
I0811 14:36:23.303128  8383 solver.cpp:228] Iteration 13500, loss = 0.688714
I0811 14:36:23.303205  8383 solver.cpp:244]     Train net output #0: loss = 0.688714 (* 1 = 0.688714 loss)
I0811 14:36:23.303231  8383 sgd_solver.cpp:106] Iteration 13500, lr = 0.000679186
I0811 14:36:26.525358  8383 solver.cpp:228] Iteration 13600, loss = 0.700621
I0811 14:36:26.525406  8383 solver.cpp:244]     Train net output #0: loss = 0.700621 (* 1 = 0.700621 loss)
I0811 14:36:26.525413  8383 sgd_solver.cpp:106] Iteration 13600, lr = 0.00067767
I0811 14:36:29.787021  8383 solver.cpp:228] Iteration 13700, loss = 0.688476
I0811 14:36:29.787070  8383 solver.cpp:244]     Train net output #0: loss = 0.688476 (* 1 = 0.688476 loss)
I0811 14:36:29.787096  8383 sgd_solver.cpp:106] Iteration 13700, lr = 0.000676161
I0811 14:36:33.069461  8383 solver.cpp:228] Iteration 13800, loss = 0.693143
I0811 14:36:33.069543  8383 solver.cpp:244]     Train net output #0: loss = 0.693143 (* 1 = 0.693143 loss)
I0811 14:36:33.069551  8383 sgd_solver.cpp:106] Iteration 13800, lr = 0.00067466
I0811 14:36:36.334625  8383 solver.cpp:228] Iteration 13900, loss = 0.69676
I0811 14:36:36.334664  8383 solver.cpp:244]     Train net output #0: loss = 0.69676 (* 1 = 0.69676 loss)
I0811 14:36:36.334671  8383 sgd_solver.cpp:106] Iteration 13900, lr = 0.000673167
I0811 14:36:39.611156  8383 solver.cpp:337] Iteration 14000, Testing net (#0)
I0811 14:36:40.787132  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:36:46.682062  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117355
I0811 14:36:46.682106  8383 solver.cpp:404]     Test net output #1: loss = 0.709157 (* 1 = 0.709157 loss)
I0811 14:36:46.694761  8383 solver.cpp:228] Iteration 14000, loss = 0.691096
I0811 14:36:46.694804  8383 solver.cpp:244]     Train net output #0: loss = 0.691096 (* 1 = 0.691096 loss)
I0811 14:36:46.694818  8383 sgd_solver.cpp:106] Iteration 14000, lr = 0.000671681
I0811 14:36:49.918006  8383 solver.cpp:228] Iteration 14100, loss = 0.687427
I0811 14:36:49.918057  8383 solver.cpp:244]     Train net output #0: loss = 0.687427 (* 1 = 0.687427 loss)
I0811 14:36:49.918063  8383 sgd_solver.cpp:106] Iteration 14100, lr = 0.000670204
I0811 14:36:53.216794  8383 solver.cpp:228] Iteration 14200, loss = 0.698807
I0811 14:36:53.216838  8383 solver.cpp:244]     Train net output #0: loss = 0.698807 (* 1 = 0.698807 loss)
I0811 14:36:53.216845  8383 sgd_solver.cpp:106] Iteration 14200, lr = 0.000668733
I0811 14:36:56.501591  8383 solver.cpp:228] Iteration 14300, loss = 0.695459
I0811 14:36:56.501644  8383 solver.cpp:244]     Train net output #0: loss = 0.695459 (* 1 = 0.695459 loss)
I0811 14:36:56.501652  8383 sgd_solver.cpp:106] Iteration 14300, lr = 0.000667271
I0811 14:36:59.777787  8383 solver.cpp:228] Iteration 14400, loss = 0.687938
I0811 14:36:59.777832  8383 solver.cpp:244]     Train net output #0: loss = 0.687938 (* 1 = 0.687938 loss)
I0811 14:36:59.777838  8383 sgd_solver.cpp:106] Iteration 14400, lr = 0.000665815
I0811 14:37:03.034669  8383 solver.cpp:337] Iteration 14500, Testing net (#0)
I0811 14:37:09.574021  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117452
I0811 14:37:09.574081  8383 solver.cpp:404]     Test net output #1: loss = 0.750837 (* 1 = 0.750837 loss)
I0811 14:37:09.586819  8383 solver.cpp:228] Iteration 14500, loss = 0.683179
I0811 14:37:09.586849  8383 solver.cpp:244]     Train net output #0: loss = 0.683179 (* 1 = 0.683179 loss)
I0811 14:37:09.586874  8383 sgd_solver.cpp:106] Iteration 14500, lr = 0.000664367
I0811 14:37:12.809191  8383 solver.cpp:228] Iteration 14600, loss = 0.69012
I0811 14:37:12.809248  8383 solver.cpp:244]     Train net output #0: loss = 0.69012 (* 1 = 0.69012 loss)
I0811 14:37:12.809257  8383 sgd_solver.cpp:106] Iteration 14600, lr = 0.000662927
I0811 14:37:16.105603  8383 solver.cpp:228] Iteration 14700, loss = 0.692134
I0811 14:37:16.105672  8383 solver.cpp:244]     Train net output #0: loss = 0.692134 (* 1 = 0.692134 loss)
I0811 14:37:16.105681  8383 sgd_solver.cpp:106] Iteration 14700, lr = 0.000661493
I0811 14:37:19.376323  8383 solver.cpp:228] Iteration 14800, loss = 0.690515
I0811 14:37:19.376364  8383 solver.cpp:244]     Train net output #0: loss = 0.690515 (* 1 = 0.690515 loss)
I0811 14:37:19.376370  8383 sgd_solver.cpp:106] Iteration 14800, lr = 0.000660067
I0811 14:37:22.695171  8383 solver.cpp:228] Iteration 14900, loss = 0.687148
I0811 14:37:22.695212  8383 solver.cpp:244]     Train net output #0: loss = 0.687148 (* 1 = 0.687148 loss)
I0811 14:37:22.695219  8383 sgd_solver.cpp:106] Iteration 14900, lr = 0.000658648
I0811 14:37:25.947103  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_15000.caffemodel
I0811 14:37:26.323925  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_15000.solverstate
I0811 14:37:26.459239  8383 solver.cpp:337] Iteration 15000, Testing net (#0)
I0811 14:37:33.150213  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0811 14:37:33.150272  8383 solver.cpp:404]     Test net output #1: loss = 0.677402 (* 1 = 0.677402 loss)
I0811 14:37:33.162796  8383 solver.cpp:228] Iteration 15000, loss = 0.700213
I0811 14:37:33.162827  8383 solver.cpp:244]     Train net output #0: loss = 0.700213 (* 1 = 0.700213 loss)
I0811 14:37:33.162852  8383 sgd_solver.cpp:106] Iteration 15000, lr = 0.000657236
I0811 14:37:36.387336  8383 solver.cpp:228] Iteration 15100, loss = 0.697235
I0811 14:37:36.387392  8383 solver.cpp:244]     Train net output #0: loss = 0.697235 (* 1 = 0.697235 loss)
I0811 14:37:36.387398  8383 sgd_solver.cpp:106] Iteration 15100, lr = 0.000655831
I0811 14:37:36.738775  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:37:39.668583  8383 solver.cpp:228] Iteration 15200, loss = 0.705682
I0811 14:37:39.668629  8383 solver.cpp:244]     Train net output #0: loss = 0.705682 (* 1 = 0.705682 loss)
I0811 14:37:39.668637  8383 sgd_solver.cpp:106] Iteration 15200, lr = 0.000654434
I0811 14:37:42.961222  8383 solver.cpp:228] Iteration 15300, loss = 0.709411
I0811 14:37:42.961273  8383 solver.cpp:244]     Train net output #0: loss = 0.709411 (* 1 = 0.709411 loss)
I0811 14:37:42.961284  8383 sgd_solver.cpp:106] Iteration 15300, lr = 0.000653043
I0811 14:37:46.241650  8383 solver.cpp:228] Iteration 15400, loss = 0.695006
I0811 14:37:46.241694  8383 solver.cpp:244]     Train net output #0: loss = 0.695006 (* 1 = 0.695006 loss)
I0811 14:37:46.241700  8383 sgd_solver.cpp:106] Iteration 15400, lr = 0.000651659
I0811 14:37:49.489761  8383 solver.cpp:337] Iteration 15500, Testing net (#0)
I0811 14:37:56.337988  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0811 14:37:56.338054  8383 solver.cpp:404]     Test net output #1: loss = 0.688494 (* 1 = 0.688494 loss)
I0811 14:37:56.351234  8383 solver.cpp:228] Iteration 15500, loss = 0.694387
I0811 14:37:56.351270  8383 solver.cpp:244]     Train net output #0: loss = 0.694387 (* 1 = 0.694387 loss)
I0811 14:37:56.351284  8383 sgd_solver.cpp:106] Iteration 15500, lr = 0.000650281
I0811 14:37:59.583266  8383 solver.cpp:228] Iteration 15600, loss = 0.703395
I0811 14:37:59.583307  8383 solver.cpp:244]     Train net output #0: loss = 0.703395 (* 1 = 0.703395 loss)
I0811 14:37:59.583313  8383 sgd_solver.cpp:106] Iteration 15600, lr = 0.000648911
I0811 14:38:02.849443  8383 solver.cpp:228] Iteration 15700, loss = 0.698897
I0811 14:38:02.849481  8383 solver.cpp:244]     Train net output #0: loss = 0.698897 (* 1 = 0.698897 loss)
I0811 14:38:02.849488  8383 sgd_solver.cpp:106] Iteration 15700, lr = 0.000647547
I0811 14:38:06.124209  8383 solver.cpp:228] Iteration 15800, loss = 0.683429
I0811 14:38:06.124260  8383 solver.cpp:244]     Train net output #0: loss = 0.683429 (* 1 = 0.683429 loss)
I0811 14:38:06.124269  8383 sgd_solver.cpp:106] Iteration 15800, lr = 0.00064619
I0811 14:38:09.433933  8383 solver.cpp:228] Iteration 15900, loss = 0.689468
I0811 14:38:09.433974  8383 solver.cpp:244]     Train net output #0: loss = 0.689468 (* 1 = 0.689468 loss)
I0811 14:38:09.433979  8383 sgd_solver.cpp:106] Iteration 15900, lr = 0.00064484
I0811 14:38:12.688561  8383 solver.cpp:337] Iteration 16000, Testing net (#0)
I0811 14:38:19.098305  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882483
I0811 14:38:19.098377  8383 solver.cpp:404]     Test net output #1: loss = 0.666621 (* 1 = 0.666621 loss)
I0811 14:38:19.111611  8383 solver.cpp:228] Iteration 16000, loss = 0.690856
I0811 14:38:19.111647  8383 solver.cpp:244]     Train net output #0: loss = 0.690856 (* 1 = 0.690856 loss)
I0811 14:38:19.111675  8383 sgd_solver.cpp:106] Iteration 16000, lr = 0.000643496
I0811 14:38:22.374549  8383 solver.cpp:228] Iteration 16100, loss = 0.692466
I0811 14:38:22.374585  8383 solver.cpp:244]     Train net output #0: loss = 0.692466 (* 1 = 0.692466 loss)
I0811 14:38:22.374591  8383 sgd_solver.cpp:106] Iteration 16100, lr = 0.000642158
I0811 14:38:25.630779  8383 solver.cpp:228] Iteration 16200, loss = 0.687852
I0811 14:38:25.630820  8383 solver.cpp:244]     Train net output #0: loss = 0.687852 (* 1 = 0.687852 loss)
I0811 14:38:25.630827  8383 sgd_solver.cpp:106] Iteration 16200, lr = 0.000640827
I0811 14:38:28.900166  8383 solver.cpp:228] Iteration 16300, loss = 0.702879
I0811 14:38:28.900208  8383 solver.cpp:244]     Train net output #0: loss = 0.702879 (* 1 = 0.702879 loss)
I0811 14:38:28.900218  8383 sgd_solver.cpp:106] Iteration 16300, lr = 0.000639503
I0811 14:38:32.169756  8383 solver.cpp:228] Iteration 16400, loss = 0.702368
I0811 14:38:32.169792  8383 solver.cpp:244]     Train net output #0: loss = 0.702368 (* 1 = 0.702368 loss)
I0811 14:38:32.169800  8383 sgd_solver.cpp:106] Iteration 16400, lr = 0.000638185
I0811 14:38:35.428869  8383 solver.cpp:337] Iteration 16500, Testing net (#0)
I0811 14:38:41.563480  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:38:41.934900  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117516
I0811 14:38:41.935232  8383 solver.cpp:404]     Test net output #1: loss = 0.736586 (* 1 = 0.736586 loss)
I0811 14:38:41.949091  8383 solver.cpp:228] Iteration 16500, loss = 0.703111
I0811 14:38:41.949173  8383 solver.cpp:244]     Train net output #0: loss = 0.703111 (* 1 = 0.703111 loss)
I0811 14:38:41.949199  8383 sgd_solver.cpp:106] Iteration 16500, lr = 0.000636873
I0811 14:38:45.201848  8383 solver.cpp:228] Iteration 16600, loss = 0.685548
I0811 14:38:45.201885  8383 solver.cpp:244]     Train net output #0: loss = 0.685548 (* 1 = 0.685548 loss)
I0811 14:38:45.201891  8383 sgd_solver.cpp:106] Iteration 16600, lr = 0.000635568
I0811 14:38:48.445560  8383 solver.cpp:228] Iteration 16700, loss = 0.694571
I0811 14:38:48.445598  8383 solver.cpp:244]     Train net output #0: loss = 0.694571 (* 1 = 0.694571 loss)
I0811 14:38:48.445605  8383 sgd_solver.cpp:106] Iteration 16700, lr = 0.000634268
I0811 14:38:51.725874  8383 solver.cpp:228] Iteration 16800, loss = 0.688413
I0811 14:38:51.725915  8383 solver.cpp:244]     Train net output #0: loss = 0.688413 (* 1 = 0.688413 loss)
I0811 14:38:51.725924  8383 sgd_solver.cpp:106] Iteration 16800, lr = 0.000632975
I0811 14:38:55.082273  8383 solver.cpp:228] Iteration 16900, loss = 0.681372
I0811 14:38:55.082325  8383 solver.cpp:244]     Train net output #0: loss = 0.681372 (* 1 = 0.681372 loss)
I0811 14:38:55.082332  8383 sgd_solver.cpp:106] Iteration 16900, lr = 0.000631688
I0811 14:38:58.309046  8383 solver.cpp:337] Iteration 17000, Testing net (#0)
I0811 14:39:05.182348  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117548
I0811 14:39:05.182420  8383 solver.cpp:404]     Test net output #1: loss = 0.700759 (* 1 = 0.700759 loss)
I0811 14:39:05.195623  8383 solver.cpp:228] Iteration 17000, loss = 0.685004
I0811 14:39:05.195652  8383 solver.cpp:244]     Train net output #0: loss = 0.685004 (* 1 = 0.685004 loss)
I0811 14:39:05.195667  8383 sgd_solver.cpp:106] Iteration 17000, lr = 0.000630407
I0811 14:39:08.406692  8383 solver.cpp:228] Iteration 17100, loss = 0.694738
I0811 14:39:08.406734  8383 solver.cpp:244]     Train net output #0: loss = 0.694738 (* 1 = 0.694738 loss)
I0811 14:39:08.406743  8383 sgd_solver.cpp:106] Iteration 17100, lr = 0.000629132
I0811 14:39:11.647349  8383 solver.cpp:228] Iteration 17200, loss = 0.693911
I0811 14:39:11.647416  8383 solver.cpp:244]     Train net output #0: loss = 0.693911 (* 1 = 0.693911 loss)
I0811 14:39:11.647431  8383 sgd_solver.cpp:106] Iteration 17200, lr = 0.000627864
I0811 14:39:14.920163  8383 solver.cpp:228] Iteration 17300, loss = 0.687451
I0811 14:39:14.920213  8383 solver.cpp:244]     Train net output #0: loss = 0.687451 (* 1 = 0.687451 loss)
I0811 14:39:14.920220  8383 sgd_solver.cpp:106] Iteration 17300, lr = 0.000626601
I0811 14:39:18.200760  8383 solver.cpp:228] Iteration 17400, loss = 0.693509
I0811 14:39:18.200817  8383 solver.cpp:244]     Train net output #0: loss = 0.693509 (* 1 = 0.693509 loss)
I0811 14:39:18.200824  8383 sgd_solver.cpp:106] Iteration 17400, lr = 0.000625344
I0811 14:39:21.462656  8383 solver.cpp:337] Iteration 17500, Testing net (#0)
I0811 14:39:28.047715  8383 solver.cpp:404]     Test net output #0: accuracy = 0.117355
I0811 14:39:28.047796  8383 solver.cpp:404]     Test net output #1: loss = 0.723857 (* 1 = 0.723857 loss)
I0811 14:39:28.058769  8383 solver.cpp:228] Iteration 17500, loss = 0.690812
I0811 14:39:28.058843  8383 solver.cpp:244]     Train net output #0: loss = 0.690812 (* 1 = 0.690812 loss)
I0811 14:39:28.058868  8383 sgd_solver.cpp:106] Iteration 17500, lr = 0.000624093
I0811 14:39:31.308611  8383 solver.cpp:228] Iteration 17600, loss = 0.69785
I0811 14:39:31.308660  8383 solver.cpp:244]     Train net output #0: loss = 0.69785 (* 1 = 0.69785 loss)
I0811 14:39:31.308665  8383 sgd_solver.cpp:106] Iteration 17600, lr = 0.000622847
I0811 14:39:34.585002  8383 solver.cpp:228] Iteration 17700, loss = 0.690486
I0811 14:39:34.585058  8383 solver.cpp:244]     Train net output #0: loss = 0.690486 (* 1 = 0.690486 loss)
I0811 14:39:34.585067  8383 sgd_solver.cpp:106] Iteration 17700, lr = 0.000621608
I0811 14:39:37.855104  8383 solver.cpp:228] Iteration 17800, loss = 0.691005
I0811 14:39:37.855157  8383 solver.cpp:244]     Train net output #0: loss = 0.691005 (* 1 = 0.691005 loss)
I0811 14:39:37.855166  8383 sgd_solver.cpp:106] Iteration 17800, lr = 0.000620374
I0811 14:39:41.178158  8383 solver.cpp:228] Iteration 17900, loss = 0.692411
I0811 14:39:41.178191  8383 solver.cpp:244]     Train net output #0: loss = 0.692411 (* 1 = 0.692411 loss)
I0811 14:39:41.178197  8383 sgd_solver.cpp:106] Iteration 17900, lr = 0.000619146
I0811 14:39:44.430620  8383 solver.cpp:337] Iteration 18000, Testing net (#0)
I0811 14:39:50.782068  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0811 14:39:50.782126  8383 solver.cpp:404]     Test net output #1: loss = 0.647345 (* 1 = 0.647345 loss)
I0811 14:39:50.795045  8383 solver.cpp:228] Iteration 18000, loss = 0.69544
I0811 14:39:50.795078  8383 solver.cpp:244]     Train net output #0: loss = 0.69544 (* 1 = 0.69544 loss)
I0811 14:39:50.795090  8383 sgd_solver.cpp:106] Iteration 18000, lr = 0.000617924
I0811 14:39:54.020647  8383 solver.cpp:228] Iteration 18100, loss = 0.690329
I0811 14:39:54.020689  8383 solver.cpp:244]     Train net output #0: loss = 0.690329 (* 1 = 0.690329 loss)
I0811 14:39:54.020696  8383 sgd_solver.cpp:106] Iteration 18100, lr = 0.000616707
I0811 14:39:56.324347  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:39:57.296020  8383 solver.cpp:228] Iteration 18200, loss = 0.68895
I0811 14:39:57.296046  8383 solver.cpp:244]     Train net output #0: loss = 0.68895 (* 1 = 0.68895 loss)
I0811 14:39:57.296053  8383 sgd_solver.cpp:106] Iteration 18200, lr = 0.000615496
I0811 14:40:00.566788  8383 solver.cpp:228] Iteration 18300, loss = 0.685903
I0811 14:40:00.566831  8383 solver.cpp:244]     Train net output #0: loss = 0.685903 (* 1 = 0.685903 loss)
I0811 14:40:00.566838  8383 sgd_solver.cpp:106] Iteration 18300, lr = 0.00061429
I0811 14:40:03.877135  8383 solver.cpp:228] Iteration 18400, loss = 0.686313
I0811 14:40:03.877203  8383 solver.cpp:244]     Train net output #0: loss = 0.686313 (* 1 = 0.686313 loss)
I0811 14:40:03.877210  8383 sgd_solver.cpp:106] Iteration 18400, lr = 0.00061309
I0811 14:40:07.122772  8383 solver.cpp:337] Iteration 18500, Testing net (#0)
I0811 14:40:13.792798  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0811 14:40:13.792852  8383 solver.cpp:404]     Test net output #1: loss = 0.669217 (* 1 = 0.669217 loss)
I0811 14:40:13.806105  8383 solver.cpp:228] Iteration 18500, loss = 0.68935
I0811 14:40:13.806172  8383 solver.cpp:244]     Train net output #0: loss = 0.68935 (* 1 = 0.68935 loss)
I0811 14:40:13.806197  8383 sgd_solver.cpp:106] Iteration 18500, lr = 0.000611895
I0811 14:40:17.006294  8383 solver.cpp:228] Iteration 18600, loss = 0.690587
I0811 14:40:17.006337  8383 solver.cpp:244]     Train net output #0: loss = 0.690587 (* 1 = 0.690587 loss)
I0811 14:40:17.006343  8383 sgd_solver.cpp:106] Iteration 18600, lr = 0.000610706
I0811 14:40:20.272966  8383 solver.cpp:228] Iteration 18700, loss = 0.699454
I0811 14:40:20.273005  8383 solver.cpp:244]     Train net output #0: loss = 0.699454 (* 1 = 0.699454 loss)
I0811 14:40:20.273013  8383 sgd_solver.cpp:106] Iteration 18700, lr = 0.000609522
I0811 14:40:23.549901  8383 solver.cpp:228] Iteration 18800, loss = 0.685618
I0811 14:40:23.549942  8383 solver.cpp:244]     Train net output #0: loss = 0.685618 (* 1 = 0.685618 loss)
I0811 14:40:23.549949  8383 sgd_solver.cpp:106] Iteration 18800, lr = 0.000608343
I0811 14:40:26.865826  8383 solver.cpp:228] Iteration 18900, loss = 0.681848
I0811 14:40:26.865859  8383 solver.cpp:244]     Train net output #0: loss = 0.681848 (* 1 = 0.681848 loss)
I0811 14:40:26.865865  8383 sgd_solver.cpp:106] Iteration 18900, lr = 0.00060717
I0811 14:40:30.126394  8383 solver.cpp:337] Iteration 19000, Testing net (#0)
I0811 14:40:36.662423  8383 solver.cpp:404]     Test net output #0: accuracy = 0.665709
I0811 14:40:36.662502  8383 solver.cpp:404]     Test net output #1: loss = 0.665604 (* 1 = 0.665604 loss)
I0811 14:40:36.675732  8383 solver.cpp:228] Iteration 19000, loss = 0.683816
I0811 14:40:36.675757  8383 solver.cpp:244]     Train net output #0: loss = 0.683816 (* 1 = 0.683816 loss)
I0811 14:40:36.675779  8383 sgd_solver.cpp:106] Iteration 19000, lr = 0.000606002
I0811 14:40:39.972993  8383 solver.cpp:228] Iteration 19100, loss = 0.682455
I0811 14:40:39.973031  8383 solver.cpp:244]     Train net output #0: loss = 0.682455 (* 1 = 0.682455 loss)
I0811 14:40:39.973037  8383 sgd_solver.cpp:106] Iteration 19100, lr = 0.000604839
I0811 14:40:43.257251  8383 solver.cpp:228] Iteration 19200, loss = 0.671629
I0811 14:40:43.257294  8383 solver.cpp:244]     Train net output #0: loss = 0.671629 (* 1 = 0.671629 loss)
I0811 14:40:43.257303  8383 sgd_solver.cpp:106] Iteration 19200, lr = 0.000603682
I0811 14:40:46.517405  8383 solver.cpp:228] Iteration 19300, loss = 0.688445
I0811 14:40:46.517451  8383 solver.cpp:244]     Train net output #0: loss = 0.688445 (* 1 = 0.688445 loss)
I0811 14:40:46.517458  8383 sgd_solver.cpp:106] Iteration 19300, lr = 0.000602529
I0811 14:40:49.821794  8383 solver.cpp:228] Iteration 19400, loss = 0.652938
I0811 14:40:49.821848  8383 solver.cpp:244]     Train net output #0: loss = 0.652938 (* 1 = 0.652938 loss)
I0811 14:40:49.821856  8383 sgd_solver.cpp:106] Iteration 19400, lr = 0.000601382
I0811 14:40:53.101893  8383 solver.cpp:337] Iteration 19500, Testing net (#0)
I0811 14:40:57.710136  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:40:59.702126  8383 solver.cpp:404]     Test net output #0: accuracy = 0.542677
I0811 14:40:59.702195  8383 solver.cpp:404]     Test net output #1: loss = 0.662598 (* 1 = 0.662598 loss)
I0811 14:40:59.714834  8383 solver.cpp:228] Iteration 19500, loss = 0.660808
I0811 14:40:59.714870  8383 solver.cpp:244]     Train net output #0: loss = 0.660808 (* 1 = 0.660808 loss)
I0811 14:40:59.714884  8383 sgd_solver.cpp:106] Iteration 19500, lr = 0.00060024
I0811 14:41:02.965742  8383 solver.cpp:228] Iteration 19600, loss = 0.626737
I0811 14:41:02.965781  8383 solver.cpp:244]     Train net output #0: loss = 0.626737 (* 1 = 0.626737 loss)
I0811 14:41:02.965787  8383 sgd_solver.cpp:106] Iteration 19600, lr = 0.000599102
I0811 14:41:06.253712  8383 solver.cpp:228] Iteration 19700, loss = 0.64164
I0811 14:41:06.253762  8383 solver.cpp:244]     Train net output #0: loss = 0.64164 (* 1 = 0.64164 loss)
I0811 14:41:06.253772  8383 sgd_solver.cpp:106] Iteration 19700, lr = 0.00059797
I0811 14:41:09.518412  8383 solver.cpp:228] Iteration 19800, loss = 0.565768
I0811 14:41:09.518476  8383 solver.cpp:244]     Train net output #0: loss = 0.565768 (* 1 = 0.565768 loss)
I0811 14:41:09.518484  8383 sgd_solver.cpp:106] Iteration 19800, lr = 0.000596843
I0811 14:41:12.799564  8383 solver.cpp:228] Iteration 19900, loss = 0.591786
I0811 14:41:12.799600  8383 solver.cpp:244]     Train net output #0: loss = 0.591786 (* 1 = 0.591786 loss)
I0811 14:41:12.799607  8383 sgd_solver.cpp:106] Iteration 19900, lr = 0.000595721
I0811 14:41:16.048713  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_20000.caffemodel
I0811 14:41:16.420876  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_20000.solverstate
I0811 14:41:16.552898  8383 solver.cpp:337] Iteration 20000, Testing net (#0)
I0811 14:41:23.095929  8383 solver.cpp:404]     Test net output #0: accuracy = 0.482839
I0811 14:41:23.096001  8383 solver.cpp:404]     Test net output #1: loss = 0.708506 (* 1 = 0.708506 loss)
I0811 14:41:23.109433  8383 solver.cpp:228] Iteration 20000, loss = 0.644051
I0811 14:41:23.109513  8383 solver.cpp:244]     Train net output #0: loss = 0.644051 (* 1 = 0.644051 loss)
I0811 14:41:23.109539  8383 sgd_solver.cpp:106] Iteration 20000, lr = 0.000594604
I0811 14:41:26.356672  8383 solver.cpp:228] Iteration 20100, loss = 0.68975
I0811 14:41:26.356710  8383 solver.cpp:244]     Train net output #0: loss = 0.68975 (* 1 = 0.68975 loss)
I0811 14:41:26.356716  8383 sgd_solver.cpp:106] Iteration 20100, lr = 0.000593491
I0811 14:41:29.626709  8383 solver.cpp:228] Iteration 20200, loss = 0.641088
I0811 14:41:29.626752  8383 solver.cpp:244]     Train net output #0: loss = 0.641088 (* 1 = 0.641088 loss)
I0811 14:41:29.626760  8383 sgd_solver.cpp:106] Iteration 20200, lr = 0.000592384
I0811 14:41:32.924087  8383 solver.cpp:228] Iteration 20300, loss = 0.61765
I0811 14:41:32.924129  8383 solver.cpp:244]     Train net output #0: loss = 0.61765 (* 1 = 0.61765 loss)
I0811 14:41:32.924135  8383 sgd_solver.cpp:106] Iteration 20300, lr = 0.000591281
I0811 14:41:36.256183  8383 solver.cpp:228] Iteration 20400, loss = 0.680028
I0811 14:41:36.256238  8383 solver.cpp:244]     Train net output #0: loss = 0.680028 (* 1 = 0.680028 loss)
I0811 14:41:36.256249  8383 sgd_solver.cpp:106] Iteration 20400, lr = 0.000590183
I0811 14:41:39.519295  8383 solver.cpp:337] Iteration 20500, Testing net (#0)
I0811 14:41:46.039492  8383 solver.cpp:404]     Test net output #0: accuracy = 0.517097
I0811 14:41:46.039547  8383 solver.cpp:404]     Test net output #1: loss = 0.643589 (* 1 = 0.643589 loss)
I0811 14:41:46.052605  8383 solver.cpp:228] Iteration 20500, loss = 0.608933
I0811 14:41:46.052625  8383 solver.cpp:244]     Train net output #0: loss = 0.608933 (* 1 = 0.608933 loss)
I0811 14:41:46.052639  8383 sgd_solver.cpp:106] Iteration 20500, lr = 0.000589089
I0811 14:41:49.286731  8383 solver.cpp:228] Iteration 20600, loss = 0.634205
I0811 14:41:49.286778  8383 solver.cpp:244]     Train net output #0: loss = 0.634205 (* 1 = 0.634205 loss)
I0811 14:41:49.286785  8383 sgd_solver.cpp:106] Iteration 20600, lr = 0.000588001
I0811 14:41:52.548861  8383 solver.cpp:228] Iteration 20700, loss = 0.628715
I0811 14:41:52.548900  8383 solver.cpp:244]     Train net output #0: loss = 0.628715 (* 1 = 0.628715 loss)
I0811 14:41:52.548907  8383 sgd_solver.cpp:106] Iteration 20700, lr = 0.000586917
I0811 14:41:55.835877  8383 solver.cpp:228] Iteration 20800, loss = 0.610601
I0811 14:41:55.835918  8383 solver.cpp:244]     Train net output #0: loss = 0.610601 (* 1 = 0.610601 loss)
I0811 14:41:55.835927  8383 sgd_solver.cpp:106] Iteration 20800, lr = 0.000585838
I0811 14:41:59.088063  8383 solver.cpp:228] Iteration 20900, loss = 0.620598
I0811 14:41:59.088098  8383 solver.cpp:244]     Train net output #0: loss = 0.620598 (* 1 = 0.620598 loss)
I0811 14:41:59.088104  8383 sgd_solver.cpp:106] Iteration 20900, lr = 0.000584763
I0811 14:42:02.405730  8383 solver.cpp:337] Iteration 21000, Testing net (#0)
I0811 14:42:05.977597  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:42:08.843889  8383 solver.cpp:404]     Test net output #0: accuracy = 0.625548
I0811 14:42:08.843963  8383 solver.cpp:404]     Test net output #1: loss = 0.581153 (* 1 = 0.581153 loss)
I0811 14:42:08.854094  8383 solver.cpp:228] Iteration 21000, loss = 0.604051
I0811 14:42:08.854115  8383 solver.cpp:244]     Train net output #0: loss = 0.604051 (* 1 = 0.604051 loss)
I0811 14:42:08.854128  8383 sgd_solver.cpp:106] Iteration 21000, lr = 0.000583693
I0811 14:42:12.107100  8383 solver.cpp:228] Iteration 21100, loss = 0.550375
I0811 14:42:12.107134  8383 solver.cpp:244]     Train net output #0: loss = 0.550375 (* 1 = 0.550375 loss)
I0811 14:42:12.107141  8383 sgd_solver.cpp:106] Iteration 21100, lr = 0.000582628
I0811 14:42:15.352802  8383 solver.cpp:228] Iteration 21200, loss = 0.513514
I0811 14:42:15.352843  8383 solver.cpp:244]     Train net output #0: loss = 0.513514 (* 1 = 0.513514 loss)
I0811 14:42:15.352849  8383 sgd_solver.cpp:106] Iteration 21200, lr = 0.000581567
I0811 14:42:18.634902  8383 solver.cpp:228] Iteration 21300, loss = 0.565303
I0811 14:42:18.634950  8383 solver.cpp:244]     Train net output #0: loss = 0.565303 (* 1 = 0.565303 loss)
I0811 14:42:18.634958  8383 sgd_solver.cpp:106] Iteration 21300, lr = 0.00058051
I0811 14:42:21.937227  8383 solver.cpp:228] Iteration 21400, loss = 0.413091
I0811 14:42:21.937264  8383 solver.cpp:244]     Train net output #0: loss = 0.413091 (* 1 = 0.413091 loss)
I0811 14:42:21.937270  8383 sgd_solver.cpp:106] Iteration 21400, lr = 0.000579458
I0811 14:42:25.171963  8383 solver.cpp:337] Iteration 21500, Testing net (#0)
I0811 14:42:31.899493  8383 solver.cpp:404]     Test net output #0: accuracy = 0.732677
I0811 14:42:31.899562  8383 solver.cpp:404]     Test net output #1: loss = 0.517999 (* 1 = 0.517999 loss)
I0811 14:42:31.912580  8383 solver.cpp:228] Iteration 21500, loss = 0.445227
I0811 14:42:31.912611  8383 solver.cpp:244]     Train net output #0: loss = 0.445227 (* 1 = 0.445227 loss)
I0811 14:42:31.912647  8383 sgd_solver.cpp:106] Iteration 21500, lr = 0.000578411
I0811 14:42:35.156502  8383 solver.cpp:228] Iteration 21600, loss = 0.44636
I0811 14:42:35.156548  8383 solver.cpp:244]     Train net output #0: loss = 0.44636 (* 1 = 0.44636 loss)
I0811 14:42:35.156556  8383 sgd_solver.cpp:106] Iteration 21600, lr = 0.000577368
I0811 14:42:38.435766  8383 solver.cpp:228] Iteration 21700, loss = 0.515786
I0811 14:42:38.435812  8383 solver.cpp:244]     Train net output #0: loss = 0.515786 (* 1 = 0.515786 loss)
I0811 14:42:38.435820  8383 sgd_solver.cpp:106] Iteration 21700, lr = 0.000576329
I0811 14:42:41.691396  8383 solver.cpp:228] Iteration 21800, loss = 0.490232
I0811 14:42:41.691452  8383 solver.cpp:244]     Train net output #0: loss = 0.490232 (* 1 = 0.490232 loss)
I0811 14:42:41.691463  8383 sgd_solver.cpp:106] Iteration 21800, lr = 0.000575295
I0811 14:42:44.953846  8383 solver.cpp:228] Iteration 21900, loss = 0.508308
I0811 14:42:44.953893  8383 solver.cpp:244]     Train net output #0: loss = 0.508308 (* 1 = 0.508308 loss)
I0811 14:42:44.953902  8383 sgd_solver.cpp:106] Iteration 21900, lr = 0.000574265
I0811 14:42:48.181385  8383 solver.cpp:337] Iteration 22000, Testing net (#0)
I0811 14:42:54.860805  8383 solver.cpp:404]     Test net output #0: accuracy = 0.738549
I0811 14:42:54.860874  8383 solver.cpp:404]     Test net output #1: loss = 0.505075 (* 1 = 0.505075 loss)
I0811 14:42:54.874316  8383 solver.cpp:228] Iteration 22000, loss = 0.418971
I0811 14:42:54.874383  8383 solver.cpp:244]     Train net output #0: loss = 0.418971 (* 1 = 0.418971 loss)
I0811 14:42:54.874409  8383 sgd_solver.cpp:106] Iteration 22000, lr = 0.000573239
I0811 14:42:58.128545  8383 solver.cpp:228] Iteration 22100, loss = 0.469478
I0811 14:42:58.128595  8383 solver.cpp:244]     Train net output #0: loss = 0.469478 (* 1 = 0.469478 loss)
I0811 14:42:58.128602  8383 sgd_solver.cpp:106] Iteration 22100, lr = 0.000572217
I0811 14:43:01.443038  8383 solver.cpp:228] Iteration 22200, loss = 0.42831
I0811 14:43:01.443104  8383 solver.cpp:244]     Train net output #0: loss = 0.42831 (* 1 = 0.42831 loss)
I0811 14:43:01.443120  8383 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005712
I0811 14:43:04.708917  8383 solver.cpp:228] Iteration 22300, loss = 0.566926
I0811 14:43:04.708961  8383 solver.cpp:244]     Train net output #0: loss = 0.566926 (* 1 = 0.566926 loss)
I0811 14:43:04.708967  8383 sgd_solver.cpp:106] Iteration 22300, lr = 0.000570187
I0811 14:43:07.985919  8383 solver.cpp:228] Iteration 22400, loss = 0.550267
I0811 14:43:07.985970  8383 solver.cpp:244]     Train net output #0: loss = 0.550267 (* 1 = 0.550267 loss)
I0811 14:43:07.985977  8383 sgd_solver.cpp:106] Iteration 22400, lr = 0.000569178
I0811 14:43:11.257560  8383 solver.cpp:337] Iteration 22500, Testing net (#0)
I0811 14:43:14.869707  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:43:17.989401  8383 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0811 14:43:17.989462  8383 solver.cpp:404]     Test net output #1: loss = 0.458042 (* 1 = 0.458042 loss)
I0811 14:43:18.000315  8383 solver.cpp:228] Iteration 22500, loss = 0.498855
I0811 14:43:18.000377  8383 solver.cpp:244]     Train net output #0: loss = 0.498855 (* 1 = 0.498855 loss)
I0811 14:43:18.000401  8383 sgd_solver.cpp:106] Iteration 22500, lr = 0.000568173
I0811 14:43:21.245036  8383 solver.cpp:228] Iteration 22600, loss = 0.374191
I0811 14:43:21.245084  8383 solver.cpp:244]     Train net output #0: loss = 0.374191 (* 1 = 0.374191 loss)
I0811 14:43:21.245091  8383 sgd_solver.cpp:106] Iteration 22600, lr = 0.000567173
I0811 14:43:24.521134  8383 solver.cpp:228] Iteration 22700, loss = 0.437187
I0811 14:43:24.521178  8383 solver.cpp:244]     Train net output #0: loss = 0.437187 (* 1 = 0.437187 loss)
I0811 14:43:24.521185  8383 sgd_solver.cpp:106] Iteration 22700, lr = 0.000566176
I0811 14:43:27.810191  8383 solver.cpp:228] Iteration 22800, loss = 0.347421
I0811 14:43:27.810237  8383 solver.cpp:244]     Train net output #0: loss = 0.347421 (* 1 = 0.347421 loss)
I0811 14:43:27.810243  8383 sgd_solver.cpp:106] Iteration 22800, lr = 0.000565184
I0811 14:43:31.143465  8383 solver.cpp:228] Iteration 22900, loss = 0.378288
I0811 14:43:31.143506  8383 solver.cpp:244]     Train net output #0: loss = 0.378288 (* 1 = 0.378288 loss)
I0811 14:43:31.143513  8383 sgd_solver.cpp:106] Iteration 22900, lr = 0.000564195
I0811 14:43:34.430868  8383 solver.cpp:337] Iteration 23000, Testing net (#0)
I0811 14:43:41.114888  8383 solver.cpp:404]     Test net output #0: accuracy = 0.769774
I0811 14:43:41.114949  8383 solver.cpp:404]     Test net output #1: loss = 0.496623 (* 1 = 0.496623 loss)
I0811 14:43:41.127737  8383 solver.cpp:228] Iteration 23000, loss = 0.338637
I0811 14:43:41.127760  8383 solver.cpp:244]     Train net output #0: loss = 0.338637 (* 1 = 0.338637 loss)
I0811 14:43:41.127774  8383 sgd_solver.cpp:106] Iteration 23000, lr = 0.000563211
I0811 14:43:44.409111  8383 solver.cpp:228] Iteration 23100, loss = 0.401969
I0811 14:43:44.409147  8383 solver.cpp:244]     Train net output #0: loss = 0.401969 (* 1 = 0.401969 loss)
I0811 14:43:44.409153  8383 sgd_solver.cpp:106] Iteration 23100, lr = 0.000562231
I0811 14:43:47.703299  8383 solver.cpp:228] Iteration 23200, loss = 0.341326
I0811 14:43:47.703338  8383 solver.cpp:244]     Train net output #0: loss = 0.341326 (* 1 = 0.341326 loss)
I0811 14:43:47.703346  8383 sgd_solver.cpp:106] Iteration 23200, lr = 0.000561254
I0811 14:43:51.031682  8383 solver.cpp:228] Iteration 23300, loss = 0.292954
I0811 14:43:51.031723  8383 solver.cpp:244]     Train net output #0: loss = 0.292954 (* 1 = 0.292954 loss)
I0811 14:43:51.031730  8383 sgd_solver.cpp:106] Iteration 23300, lr = 0.000560282
I0811 14:43:54.330919  8383 solver.cpp:228] Iteration 23400, loss = 0.454677
I0811 14:43:54.330952  8383 solver.cpp:244]     Train net output #0: loss = 0.454677 (* 1 = 0.454677 loss)
I0811 14:43:54.330960  8383 sgd_solver.cpp:106] Iteration 23400, lr = 0.000559313
I0811 14:43:57.594789  8383 solver.cpp:337] Iteration 23500, Testing net (#0)
I0811 14:44:04.160970  8383 solver.cpp:404]     Test net output #0: accuracy = 0.848484
I0811 14:44:04.161043  8383 solver.cpp:404]     Test net output #1: loss = 0.33644 (* 1 = 0.33644 loss)
I0811 14:44:04.177467  8383 solver.cpp:228] Iteration 23500, loss = 0.361326
I0811 14:44:04.177541  8383 solver.cpp:244]     Train net output #0: loss = 0.361326 (* 1 = 0.361326 loss)
I0811 14:44:04.177566  8383 sgd_solver.cpp:106] Iteration 23500, lr = 0.000558349
I0811 14:44:07.407408  8383 solver.cpp:228] Iteration 23600, loss = 0.37696
I0811 14:44:07.407452  8383 solver.cpp:244]     Train net output #0: loss = 0.37696 (* 1 = 0.37696 loss)
I0811 14:44:07.407459  8383 sgd_solver.cpp:106] Iteration 23600, lr = 0.000557388
I0811 14:44:10.680179  8383 solver.cpp:228] Iteration 23700, loss = 0.386208
I0811 14:44:10.680223  8383 solver.cpp:244]     Train net output #0: loss = 0.386208 (* 1 = 0.386208 loss)
I0811 14:44:10.680232  8383 sgd_solver.cpp:106] Iteration 23700, lr = 0.000556431
I0811 14:44:13.947242  8383 solver.cpp:228] Iteration 23800, loss = 0.348462
I0811 14:44:13.947283  8383 solver.cpp:244]     Train net output #0: loss = 0.348462 (* 1 = 0.348462 loss)
I0811 14:44:13.947291  8383 sgd_solver.cpp:106] Iteration 23800, lr = 0.000555478
I0811 14:44:17.240969  8383 solver.cpp:228] Iteration 23900, loss = 0.369697
I0811 14:44:17.241005  8383 solver.cpp:244]     Train net output #0: loss = 0.369697 (* 1 = 0.369697 loss)
I0811 14:44:17.241011  8383 sgd_solver.cpp:106] Iteration 23900, lr = 0.000554529
I0811 14:44:20.499420  8383 solver.cpp:337] Iteration 24000, Testing net (#0)
I0811 14:44:22.259524  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:44:26.906147  8383 solver.cpp:404]     Test net output #0: accuracy = 0.813162
I0811 14:44:26.906209  8383 solver.cpp:404]     Test net output #1: loss = 0.393773 (* 1 = 0.393773 loss)
I0811 14:44:26.919344  8383 solver.cpp:228] Iteration 24000, loss = 0.429917
I0811 14:44:26.919371  8383 solver.cpp:244]     Train net output #0: loss = 0.429917 (* 1 = 0.429917 loss)
I0811 14:44:26.919387  8383 sgd_solver.cpp:106] Iteration 24000, lr = 0.000553583
I0811 14:44:30.168869  8383 solver.cpp:228] Iteration 24100, loss = 0.421374
I0811 14:44:30.168927  8383 solver.cpp:244]     Train net output #0: loss = 0.421374 (* 1 = 0.421374 loss)
I0811 14:44:30.168943  8383 sgd_solver.cpp:106] Iteration 24100, lr = 0.000552642
I0811 14:44:33.462061  8383 solver.cpp:228] Iteration 24200, loss = 0.363565
I0811 14:44:33.462103  8383 solver.cpp:244]     Train net output #0: loss = 0.363565 (* 1 = 0.363565 loss)
I0811 14:44:33.462110  8383 sgd_solver.cpp:106] Iteration 24200, lr = 0.000551704
I0811 14:44:36.752570  8383 solver.cpp:228] Iteration 24300, loss = 0.377254
I0811 14:44:36.752625  8383 solver.cpp:244]     Train net output #0: loss = 0.377254 (* 1 = 0.377254 loss)
I0811 14:44:36.752632  8383 sgd_solver.cpp:106] Iteration 24300, lr = 0.000550769
I0811 14:44:40.021564  8383 solver.cpp:228] Iteration 24400, loss = 0.5006
I0811 14:44:40.021603  8383 solver.cpp:244]     Train net output #0: loss = 0.5006 (* 1 = 0.5006 loss)
I0811 14:44:40.021610  8383 sgd_solver.cpp:106] Iteration 24400, lr = 0.000549839
I0811 14:44:43.265559  8383 solver.cpp:337] Iteration 24500, Testing net (#0)
I0811 14:44:49.653941  8383 solver.cpp:404]     Test net output #0: accuracy = 0.838839
I0811 14:44:49.654009  8383 solver.cpp:404]     Test net output #1: loss = 0.3587 (* 1 = 0.3587 loss)
I0811 14:44:49.667815  8383 solver.cpp:228] Iteration 24500, loss = 0.385153
I0811 14:44:49.667899  8383 solver.cpp:244]     Train net output #0: loss = 0.385153 (* 1 = 0.385153 loss)
I0811 14:44:49.667925  8383 sgd_solver.cpp:106] Iteration 24500, lr = 0.000548912
I0811 14:44:52.920014  8383 solver.cpp:228] Iteration 24600, loss = 0.419092
I0811 14:44:52.920068  8383 solver.cpp:244]     Train net output #0: loss = 0.419092 (* 1 = 0.419092 loss)
I0811 14:44:52.920074  8383 sgd_solver.cpp:106] Iteration 24600, lr = 0.000547988
I0811 14:44:56.172957  8383 solver.cpp:228] Iteration 24700, loss = 0.336151
I0811 14:44:56.173002  8383 solver.cpp:244]     Train net output #0: loss = 0.336151 (* 1 = 0.336151 loss)
I0811 14:44:56.173008  8383 sgd_solver.cpp:106] Iteration 24700, lr = 0.000547069
I0811 14:44:59.439467  8383 solver.cpp:228] Iteration 24800, loss = 0.403565
I0811 14:44:59.439520  8383 solver.cpp:244]     Train net output #0: loss = 0.403565 (* 1 = 0.403565 loss)
I0811 14:44:59.439528  8383 sgd_solver.cpp:106] Iteration 24800, lr = 0.000546153
I0811 14:45:02.726037  8383 solver.cpp:228] Iteration 24900, loss = 0.403531
I0811 14:45:02.726089  8383 solver.cpp:244]     Train net output #0: loss = 0.403531 (* 1 = 0.403531 loss)
I0811 14:45:02.726094  8383 sgd_solver.cpp:106] Iteration 24900, lr = 0.00054524
I0811 14:45:05.972892  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_25000.caffemodel
I0811 14:45:06.340919  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_25000.solverstate
I0811 14:45:06.474563  8383 solver.cpp:337] Iteration 25000, Testing net (#0)
I0811 14:45:12.963165  8383 solver.cpp:404]     Test net output #0: accuracy = 0.857033
I0811 14:45:12.963246  8383 solver.cpp:404]     Test net output #1: loss = 0.315013 (* 1 = 0.315013 loss)
I0811 14:45:12.973721  8383 solver.cpp:228] Iteration 25000, loss = 0.393615
I0811 14:45:12.973742  8383 solver.cpp:244]     Train net output #0: loss = 0.393615 (* 1 = 0.393615 loss)
I0811 14:45:12.973755  8383 sgd_solver.cpp:106] Iteration 25000, lr = 0.000544331
I0811 14:45:16.202507  8383 solver.cpp:228] Iteration 25100, loss = 0.343488
I0811 14:45:16.202544  8383 solver.cpp:244]     Train net output #0: loss = 0.343488 (* 1 = 0.343488 loss)
I0811 14:45:16.202555  8383 sgd_solver.cpp:106] Iteration 25100, lr = 0.000543426
I0811 14:45:19.490605  8383 solver.cpp:228] Iteration 25200, loss = 0.370783
I0811 14:45:19.490643  8383 solver.cpp:244]     Train net output #0: loss = 0.370783 (* 1 = 0.370783 loss)
I0811 14:45:19.490650  8383 sgd_solver.cpp:106] Iteration 25200, lr = 0.000542524
I0811 14:45:22.811666  8383 solver.cpp:228] Iteration 25300, loss = 0.465175
I0811 14:45:22.811708  8383 solver.cpp:244]     Train net output #0: loss = 0.465175 (* 1 = 0.465175 loss)
I0811 14:45:22.811715  8383 sgd_solver.cpp:106] Iteration 25300, lr = 0.000541625
I0811 14:45:26.092753  8383 solver.cpp:228] Iteration 25400, loss = 0.420452
I0811 14:45:26.092795  8383 solver.cpp:244]     Train net output #0: loss = 0.420452 (* 1 = 0.420452 loss)
I0811 14:45:26.092802  8383 sgd_solver.cpp:106] Iteration 25400, lr = 0.00054073
I0811 14:45:29.355062  8383 solver.cpp:337] Iteration 25500, Testing net (#0)
I0811 14:45:29.660449  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:45:36.397526  8383 solver.cpp:404]     Test net output #0: accuracy = 0.900871
I0811 14:45:36.397615  8383 solver.cpp:404]     Test net output #1: loss = 0.225646 (* 1 = 0.225646 loss)
I0811 14:45:36.410888  8383 solver.cpp:228] Iteration 25500, loss = 0.37522
I0811 14:45:36.410955  8383 solver.cpp:244]     Train net output #0: loss = 0.37522 (* 1 = 0.37522 loss)
I0811 14:45:36.410979  8383 sgd_solver.cpp:106] Iteration 25500, lr = 0.000539839
I0811 14:45:39.720392  8383 solver.cpp:228] Iteration 25600, loss = 0.260878
I0811 14:45:39.720432  8383 solver.cpp:244]     Train net output #0: loss = 0.260878 (* 1 = 0.260878 loss)
I0811 14:45:39.720443  8383 sgd_solver.cpp:106] Iteration 25600, lr = 0.00053895
I0811 14:45:42.989902  8383 solver.cpp:228] Iteration 25700, loss = 0.440525
I0811 14:45:42.989945  8383 solver.cpp:244]     Train net output #0: loss = 0.440525 (* 1 = 0.440525 loss)
I0811 14:45:42.989953  8383 sgd_solver.cpp:106] Iteration 25700, lr = 0.000538066
I0811 14:45:46.249122  8383 solver.cpp:228] Iteration 25800, loss = 0.308693
I0811 14:45:46.249162  8383 solver.cpp:244]     Train net output #0: loss = 0.308693 (* 1 = 0.308693 loss)
I0811 14:45:46.249169  8383 sgd_solver.cpp:106] Iteration 25800, lr = 0.000537184
I0811 14:45:49.527076  8383 solver.cpp:228] Iteration 25900, loss = 0.280807
I0811 14:45:49.527137  8383 solver.cpp:244]     Train net output #0: loss = 0.280807 (* 1 = 0.280807 loss)
I0811 14:45:49.527150  8383 sgd_solver.cpp:106] Iteration 25900, lr = 0.000536306
I0811 14:45:52.778892  8383 solver.cpp:337] Iteration 26000, Testing net (#0)
I0811 14:45:59.256156  8383 solver.cpp:404]     Test net output #0: accuracy = 0.834387
I0811 14:45:59.256214  8383 solver.cpp:404]     Test net output #1: loss = 0.360305 (* 1 = 0.360305 loss)
I0811 14:45:59.267148  8383 solver.cpp:228] Iteration 26000, loss = 0.501096
I0811 14:45:59.267211  8383 solver.cpp:244]     Train net output #0: loss = 0.501096 (* 1 = 0.501096 loss)
I0811 14:45:59.267235  8383 sgd_solver.cpp:106] Iteration 26000, lr = 0.000535432
I0811 14:46:02.535490  8383 solver.cpp:228] Iteration 26100, loss = 0.435379
I0811 14:46:02.535540  8383 solver.cpp:244]     Train net output #0: loss = 0.435379 (* 1 = 0.435379 loss)
I0811 14:46:02.535547  8383 sgd_solver.cpp:106] Iteration 26100, lr = 0.00053456
I0811 14:46:05.815948  8383 solver.cpp:228] Iteration 26200, loss = 0.287416
I0811 14:46:05.815997  8383 solver.cpp:244]     Train net output #0: loss = 0.287416 (* 1 = 0.287416 loss)
I0811 14:46:05.816005  8383 sgd_solver.cpp:106] Iteration 26200, lr = 0.000533692
I0811 14:46:09.058429  8383 solver.cpp:228] Iteration 26300, loss = 0.280295
I0811 14:46:09.058470  8383 solver.cpp:244]     Train net output #0: loss = 0.280295 (* 1 = 0.280295 loss)
I0811 14:46:09.058477  8383 sgd_solver.cpp:106] Iteration 26300, lr = 0.000532828
I0811 14:46:12.342037  8383 solver.cpp:228] Iteration 26400, loss = 0.475219
I0811 14:46:12.342072  8383 solver.cpp:244]     Train net output #0: loss = 0.475219 (* 1 = 0.475219 loss)
I0811 14:46:12.342077  8383 sgd_solver.cpp:106] Iteration 26400, lr = 0.000531966
I0811 14:46:15.610045  8383 solver.cpp:337] Iteration 26500, Testing net (#0)
I0811 14:46:22.118582  8383 solver.cpp:404]     Test net output #0: accuracy = 0.799871
I0811 14:46:22.118648  8383 solver.cpp:404]     Test net output #1: loss = 0.442034 (* 1 = 0.442034 loss)
I0811 14:46:22.131836  8383 solver.cpp:228] Iteration 26500, loss = 0.36499
I0811 14:46:22.131871  8383 solver.cpp:244]     Train net output #0: loss = 0.36499 (* 1 = 0.36499 loss)
I0811 14:46:22.131887  8383 sgd_solver.cpp:106] Iteration 26500, lr = 0.000531108
I0811 14:46:25.373788  8383 solver.cpp:228] Iteration 26600, loss = 0.360911
I0811 14:46:25.373831  8383 solver.cpp:244]     Train net output #0: loss = 0.360911 (* 1 = 0.360911 loss)
I0811 14:46:25.373839  8383 sgd_solver.cpp:106] Iteration 26600, lr = 0.000530253
I0811 14:46:28.691480  8383 solver.cpp:228] Iteration 26700, loss = 0.271034
I0811 14:46:28.691540  8383 solver.cpp:244]     Train net output #0: loss = 0.271034 (* 1 = 0.271034 loss)
I0811 14:46:28.691552  8383 sgd_solver.cpp:106] Iteration 26700, lr = 0.000529401
I0811 14:46:30.713058  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:46:31.969794  8383 solver.cpp:228] Iteration 26800, loss = 0.310888
I0811 14:46:31.969833  8383 solver.cpp:244]     Train net output #0: loss = 0.310888 (* 1 = 0.310888 loss)
I0811 14:46:31.969841  8383 sgd_solver.cpp:106] Iteration 26800, lr = 0.000528553
I0811 14:46:35.232635  8383 solver.cpp:228] Iteration 26900, loss = 0.341968
I0811 14:46:35.232671  8383 solver.cpp:244]     Train net output #0: loss = 0.341968 (* 1 = 0.341968 loss)
I0811 14:46:35.232678  8383 sgd_solver.cpp:106] Iteration 26900, lr = 0.000527707
I0811 14:46:38.480909  8383 solver.cpp:337] Iteration 27000, Testing net (#0)
I0811 14:46:45.107756  8383 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0811 14:46:45.107821  8383 solver.cpp:404]     Test net output #1: loss = 0.272506 (* 1 = 0.272506 loss)
I0811 14:46:45.119042  8383 solver.cpp:228] Iteration 27000, loss = 0.304038
I0811 14:46:45.119115  8383 solver.cpp:244]     Train net output #0: loss = 0.304038 (* 1 = 0.304038 loss)
I0811 14:46:45.119140  8383 sgd_solver.cpp:106] Iteration 27000, lr = 0.000526865
I0811 14:46:48.341972  8383 solver.cpp:228] Iteration 27100, loss = 0.246387
I0811 14:46:48.342011  8383 solver.cpp:244]     Train net output #0: loss = 0.246387 (* 1 = 0.246387 loss)
I0811 14:46:48.342018  8383 sgd_solver.cpp:106] Iteration 27100, lr = 0.000526026
I0811 14:46:51.612812  8383 solver.cpp:228] Iteration 27200, loss = 0.264985
I0811 14:46:51.612851  8383 solver.cpp:244]     Train net output #0: loss = 0.264985 (* 1 = 0.264985 loss)
I0811 14:46:51.612859  8383 sgd_solver.cpp:106] Iteration 27200, lr = 0.000525189
I0811 14:46:54.935751  8383 solver.cpp:228] Iteration 27300, loss = 0.235426
I0811 14:46:54.935786  8383 solver.cpp:244]     Train net output #0: loss = 0.235426 (* 1 = 0.235426 loss)
I0811 14:46:54.935793  8383 sgd_solver.cpp:106] Iteration 27300, lr = 0.000524356
I0811 14:46:58.231720  8383 solver.cpp:228] Iteration 27400, loss = 0.312692
I0811 14:46:58.231775  8383 solver.cpp:244]     Train net output #0: loss = 0.312692 (* 1 = 0.312692 loss)
I0811 14:46:58.231782  8383 sgd_solver.cpp:106] Iteration 27400, lr = 0.000523527
I0811 14:47:01.487140  8383 solver.cpp:337] Iteration 27500, Testing net (#0)
I0811 14:47:08.217591  8383 solver.cpp:404]     Test net output #0: accuracy = 0.753064
I0811 14:47:08.217650  8383 solver.cpp:404]     Test net output #1: loss = 0.543957 (* 1 = 0.543957 loss)
I0811 14:47:08.228755  8383 solver.cpp:228] Iteration 27500, loss = 0.433035
I0811 14:47:08.228816  8383 solver.cpp:244]     Train net output #0: loss = 0.433035 (* 1 = 0.433035 loss)
I0811 14:47:08.228839  8383 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005227
I0811 14:47:11.473990  8383 solver.cpp:228] Iteration 27600, loss = 0.273775
I0811 14:47:11.474030  8383 solver.cpp:244]     Train net output #0: loss = 0.273775 (* 1 = 0.273775 loss)
I0811 14:47:11.474038  8383 sgd_solver.cpp:106] Iteration 27600, lr = 0.000521876
I0811 14:47:14.755972  8383 solver.cpp:228] Iteration 27700, loss = 0.483549
I0811 14:47:14.756016  8383 solver.cpp:244]     Train net output #0: loss = 0.483549 (* 1 = 0.483549 loss)
I0811 14:47:14.756022  8383 sgd_solver.cpp:106] Iteration 27700, lr = 0.000521055
I0811 14:47:18.029935  8383 solver.cpp:228] Iteration 27800, loss = 0.343908
I0811 14:47:18.029974  8383 solver.cpp:244]     Train net output #0: loss = 0.343908 (* 1 = 0.343908 loss)
I0811 14:47:18.029980  8383 sgd_solver.cpp:106] Iteration 27800, lr = 0.000520237
I0811 14:47:21.375036  8383 solver.cpp:228] Iteration 27900, loss = 0.368696
I0811 14:47:21.375079  8383 solver.cpp:244]     Train net output #0: loss = 0.368696 (* 1 = 0.368696 loss)
I0811 14:47:21.375087  8383 sgd_solver.cpp:106] Iteration 27900, lr = 0.000519423
I0811 14:47:24.618610  8383 solver.cpp:337] Iteration 28000, Testing net (#0)
I0811 14:47:29.331851  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:47:31.131539  8383 solver.cpp:404]     Test net output #0: accuracy = 0.875613
I0811 14:47:31.131620  8383 solver.cpp:404]     Test net output #1: loss = 0.280806 (* 1 = 0.280806 loss)
I0811 14:47:31.146947  8383 solver.cpp:228] Iteration 28000, loss = 0.324726
I0811 14:47:31.146998  8383 solver.cpp:244]     Train net output #0: loss = 0.324726 (* 1 = 0.324726 loss)
I0811 14:47:31.147016  8383 sgd_solver.cpp:106] Iteration 28000, lr = 0.000518611
I0811 14:47:34.414134  8383 solver.cpp:228] Iteration 28100, loss = 0.262677
I0811 14:47:34.414175  8383 solver.cpp:244]     Train net output #0: loss = 0.262677 (* 1 = 0.262677 loss)
I0811 14:47:34.414181  8383 sgd_solver.cpp:106] Iteration 28100, lr = 0.000517802
I0811 14:47:37.720401  8383 solver.cpp:228] Iteration 28200, loss = 0.34223
I0811 14:47:37.720441  8383 solver.cpp:244]     Train net output #0: loss = 0.34223 (* 1 = 0.34223 loss)
I0811 14:47:37.720448  8383 sgd_solver.cpp:106] Iteration 28200, lr = 0.000516996
I0811 14:47:41.006062  8383 solver.cpp:228] Iteration 28300, loss = 0.244737
I0811 14:47:41.006131  8383 solver.cpp:244]     Train net output #0: loss = 0.244737 (* 1 = 0.244737 loss)
I0811 14:47:41.006140  8383 sgd_solver.cpp:106] Iteration 28300, lr = 0.000516193
I0811 14:47:44.281777  8383 solver.cpp:228] Iteration 28400, loss = 0.268428
I0811 14:47:44.281824  8383 solver.cpp:244]     Train net output #0: loss = 0.268428 (* 1 = 0.268428 loss)
I0811 14:47:44.281832  8383 sgd_solver.cpp:106] Iteration 28400, lr = 0.000515393
I0811 14:47:47.537282  8383 solver.cpp:337] Iteration 28500, Testing net (#0)
I0811 14:47:54.150100  8383 solver.cpp:404]     Test net output #0: accuracy = 0.891677
I0811 14:47:54.150180  8383 solver.cpp:404]     Test net output #1: loss = 0.247248 (* 1 = 0.247248 loss)
I0811 14:47:54.163837  8383 solver.cpp:228] Iteration 28500, loss = 0.354299
I0811 14:47:54.163887  8383 solver.cpp:244]     Train net output #0: loss = 0.354299 (* 1 = 0.354299 loss)
I0811 14:47:54.163915  8383 sgd_solver.cpp:106] Iteration 28500, lr = 0.000514596
I0811 14:47:57.394363  8383 solver.cpp:228] Iteration 28600, loss = 0.302217
I0811 14:47:57.394428  8383 solver.cpp:244]     Train net output #0: loss = 0.302217 (* 1 = 0.302217 loss)
I0811 14:47:57.394436  8383 sgd_solver.cpp:106] Iteration 28600, lr = 0.000513801
I0811 14:48:00.690449  8383 solver.cpp:228] Iteration 28700, loss = 0.25264
I0811 14:48:00.690490  8383 solver.cpp:244]     Train net output #0: loss = 0.25264 (* 1 = 0.25264 loss)
I0811 14:48:00.690496  8383 sgd_solver.cpp:106] Iteration 28700, lr = 0.00051301
I0811 14:48:03.975455  8383 solver.cpp:228] Iteration 28800, loss = 0.336963
I0811 14:48:03.975494  8383 solver.cpp:244]     Train net output #0: loss = 0.336963 (* 1 = 0.336963 loss)
I0811 14:48:03.975502  8383 sgd_solver.cpp:106] Iteration 28800, lr = 0.000512221
I0811 14:48:07.230834  8383 solver.cpp:228] Iteration 28900, loss = 0.426384
I0811 14:48:07.230868  8383 solver.cpp:244]     Train net output #0: loss = 0.426384 (* 1 = 0.426384 loss)
I0811 14:48:07.230875  8383 sgd_solver.cpp:106] Iteration 28900, lr = 0.000511436
I0811 14:48:10.449887  8383 solver.cpp:337] Iteration 29000, Testing net (#0)
I0811 14:48:16.915680  8383 solver.cpp:404]     Test net output #0: accuracy = 0.87871
I0811 14:48:16.915757  8383 solver.cpp:404]     Test net output #1: loss = 0.27716 (* 1 = 0.27716 loss)
I0811 14:48:16.929134  8383 solver.cpp:228] Iteration 29000, loss = 0.164838
I0811 14:48:16.929193  8383 solver.cpp:244]     Train net output #0: loss = 0.164838 (* 1 = 0.164838 loss)
I0811 14:48:16.929216  8383 sgd_solver.cpp:106] Iteration 29000, lr = 0.000510653
I0811 14:48:20.169508  8383 solver.cpp:228] Iteration 29100, loss = 0.318152
I0811 14:48:20.169581  8383 solver.cpp:244]     Train net output #0: loss = 0.318152 (* 1 = 0.318152 loss)
I0811 14:48:20.169589  8383 sgd_solver.cpp:106] Iteration 29100, lr = 0.000509872
I0811 14:48:23.446379  8383 solver.cpp:228] Iteration 29200, loss = 0.28821
I0811 14:48:23.446424  8383 solver.cpp:244]     Train net output #0: loss = 0.28821 (* 1 = 0.28821 loss)
I0811 14:48:23.446431  8383 sgd_solver.cpp:106] Iteration 29200, lr = 0.000509095
I0811 14:48:26.745100  8383 solver.cpp:228] Iteration 29300, loss = 0.178068
I0811 14:48:26.745137  8383 solver.cpp:244]     Train net output #0: loss = 0.178068 (* 1 = 0.178068 loss)
I0811 14:48:26.745144  8383 sgd_solver.cpp:106] Iteration 29300, lr = 0.00050832
I0811 14:48:30.101347  8383 solver.cpp:228] Iteration 29400, loss = 0.271879
I0811 14:48:30.101397  8383 solver.cpp:244]     Train net output #0: loss = 0.271879 (* 1 = 0.271879 loss)
I0811 14:48:30.101403  8383 sgd_solver.cpp:106] Iteration 29400, lr = 0.000507548
I0811 14:48:33.376881  8383 solver.cpp:337] Iteration 29500, Testing net (#0)
I0811 14:48:37.432909  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:48:39.920917  8383 solver.cpp:404]     Test net output #0: accuracy = 0.881129
I0811 14:48:39.921017  8383 solver.cpp:404]     Test net output #1: loss = 0.26909 (* 1 = 0.26909 loss)
I0811 14:48:39.934530  8383 solver.cpp:228] Iteration 29500, loss = 0.235925
I0811 14:48:39.934566  8383 solver.cpp:244]     Train net output #0: loss = 0.235925 (* 1 = 0.235925 loss)
I0811 14:48:39.934583  8383 sgd_solver.cpp:106] Iteration 29500, lr = 0.000506779
I0811 14:48:43.206156  8383 solver.cpp:228] Iteration 29600, loss = 0.282085
I0811 14:48:43.206197  8383 solver.cpp:244]     Train net output #0: loss = 0.282085 (* 1 = 0.282085 loss)
I0811 14:48:43.206204  8383 sgd_solver.cpp:106] Iteration 29600, lr = 0.000506013
I0811 14:48:46.459537  8383 solver.cpp:228] Iteration 29700, loss = 0.316121
I0811 14:48:46.459597  8383 solver.cpp:244]     Train net output #0: loss = 0.316121 (* 1 = 0.316121 loss)
I0811 14:48:46.459605  8383 sgd_solver.cpp:106] Iteration 29700, lr = 0.000505249
I0811 14:48:49.709977  8383 solver.cpp:228] Iteration 29800, loss = 0.226422
I0811 14:48:49.710016  8383 solver.cpp:244]     Train net output #0: loss = 0.226422 (* 1 = 0.226422 loss)
I0811 14:48:49.710023  8383 sgd_solver.cpp:106] Iteration 29800, lr = 0.000504488
I0811 14:48:52.989493  8383 solver.cpp:228] Iteration 29900, loss = 0.529726
I0811 14:48:52.989547  8383 solver.cpp:244]     Train net output #0: loss = 0.529726 (* 1 = 0.529726 loss)
I0811 14:48:52.989557  8383 sgd_solver.cpp:106] Iteration 29900, lr = 0.000503729
I0811 14:48:56.241433  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_30000.caffemodel
I0811 14:48:56.623528  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_30000.solverstate
I0811 14:48:56.759202  8383 solver.cpp:337] Iteration 30000, Testing net (#0)
I0811 14:49:03.518582  8383 solver.cpp:404]     Test net output #0: accuracy = 0.864871
I0811 14:49:03.518640  8383 solver.cpp:404]     Test net output #1: loss = 0.310869 (* 1 = 0.310869 loss)
I0811 14:49:03.530549  8383 solver.cpp:228] Iteration 30000, loss = 0.47703
I0811 14:49:03.530597  8383 solver.cpp:244]     Train net output #0: loss = 0.47703 (* 1 = 0.47703 loss)
I0811 14:49:03.530614  8383 sgd_solver.cpp:106] Iteration 30000, lr = 0.000502973
I0811 14:49:06.770828  8383 solver.cpp:228] Iteration 30100, loss = 0.186035
I0811 14:49:06.770864  8383 solver.cpp:244]     Train net output #0: loss = 0.186035 (* 1 = 0.186035 loss)
I0811 14:49:06.770870  8383 sgd_solver.cpp:106] Iteration 30100, lr = 0.00050222
I0811 14:49:10.036284  8383 solver.cpp:228] Iteration 30200, loss = 0.185572
I0811 14:49:10.036336  8383 solver.cpp:244]     Train net output #0: loss = 0.185572 (* 1 = 0.185572 loss)
I0811 14:49:10.036345  8383 sgd_solver.cpp:106] Iteration 30200, lr = 0.00050147
I0811 14:49:13.335722  8383 solver.cpp:228] Iteration 30300, loss = 0.44216
I0811 14:49:13.335775  8383 solver.cpp:244]     Train net output #0: loss = 0.44216 (* 1 = 0.44216 loss)
I0811 14:49:13.335783  8383 sgd_solver.cpp:106] Iteration 30300, lr = 0.000500722
I0811 14:49:16.641058  8383 solver.cpp:228] Iteration 30400, loss = 0.338091
I0811 14:49:16.641108  8383 solver.cpp:244]     Train net output #0: loss = 0.338091 (* 1 = 0.338091 loss)
I0811 14:49:16.641115  8383 sgd_solver.cpp:106] Iteration 30400, lr = 0.000499977
I0811 14:49:19.939632  8383 solver.cpp:337] Iteration 30500, Testing net (#0)
I0811 14:49:26.717322  8383 solver.cpp:404]     Test net output #0: accuracy = 0.826742
I0811 14:49:26.717397  8383 solver.cpp:404]     Test net output #1: loss = 0.395985 (* 1 = 0.395985 loss)
I0811 14:49:26.728220  8383 solver.cpp:228] Iteration 30500, loss = 0.348071
I0811 14:49:26.728286  8383 solver.cpp:244]     Train net output #0: loss = 0.348071 (* 1 = 0.348071 loss)
I0811 14:49:26.728308  8383 sgd_solver.cpp:106] Iteration 30500, lr = 0.000499234
I0811 14:49:30.007308  8383 solver.cpp:228] Iteration 30600, loss = 0.224164
I0811 14:49:30.007359  8383 solver.cpp:244]     Train net output #0: loss = 0.224164 (* 1 = 0.224164 loss)
I0811 14:49:30.007369  8383 sgd_solver.cpp:106] Iteration 30600, lr = 0.000498494
I0811 14:49:33.297643  8383 solver.cpp:228] Iteration 30700, loss = 0.360334
I0811 14:49:33.297698  8383 solver.cpp:244]     Train net output #0: loss = 0.360334 (* 1 = 0.360334 loss)
I0811 14:49:33.297705  8383 sgd_solver.cpp:106] Iteration 30700, lr = 0.000497756
I0811 14:49:36.586109  8383 solver.cpp:228] Iteration 30800, loss = 0.213566
I0811 14:49:36.586138  8383 solver.cpp:244]     Train net output #0: loss = 0.213566 (* 1 = 0.213566 loss)
I0811 14:49:36.586144  8383 sgd_solver.cpp:106] Iteration 30800, lr = 0.000497021
I0811 14:49:39.863179  8383 solver.cpp:228] Iteration 30900, loss = 0.202513
I0811 14:49:39.863219  8383 solver.cpp:244]     Train net output #0: loss = 0.202513 (* 1 = 0.202513 loss)
I0811 14:49:39.863224  8383 sgd_solver.cpp:106] Iteration 30900, lr = 0.000496288
I0811 14:49:42.613190  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:49:43.142312  8383 solver.cpp:337] Iteration 31000, Testing net (#0)
I0811 14:49:49.807073  8383 solver.cpp:404]     Test net output #0: accuracy = 0.921484
I0811 14:49:49.807143  8383 solver.cpp:404]     Test net output #1: loss = 0.185792 (* 1 = 0.185792 loss)
I0811 14:49:49.818074  8383 solver.cpp:228] Iteration 31000, loss = 0.388546
I0811 14:49:49.818147  8383 solver.cpp:244]     Train net output #0: loss = 0.388546 (* 1 = 0.388546 loss)
I0811 14:49:49.818171  8383 sgd_solver.cpp:106] Iteration 31000, lr = 0.000495558
I0811 14:49:53.043175  8383 solver.cpp:228] Iteration 31100, loss = 0.245859
I0811 14:49:53.043233  8383 solver.cpp:244]     Train net output #0: loss = 0.245859 (* 1 = 0.245859 loss)
I0811 14:49:53.043243  8383 sgd_solver.cpp:106] Iteration 31100, lr = 0.000494831
I0811 14:49:56.272557  8383 solver.cpp:228] Iteration 31200, loss = 0.181522
I0811 14:49:56.272624  8383 solver.cpp:244]     Train net output #0: loss = 0.181522 (* 1 = 0.181522 loss)
I0811 14:49:56.272631  8383 sgd_solver.cpp:106] Iteration 31200, lr = 0.000494106
I0811 14:49:59.553649  8383 solver.cpp:228] Iteration 31300, loss = 0.190041
I0811 14:49:59.553700  8383 solver.cpp:244]     Train net output #0: loss = 0.190041 (* 1 = 0.190041 loss)
I0811 14:49:59.553711  8383 sgd_solver.cpp:106] Iteration 31300, lr = 0.000493383
I0811 14:50:02.905555  8383 solver.cpp:228] Iteration 31400, loss = 0.328621
I0811 14:50:02.905601  8383 solver.cpp:244]     Train net output #0: loss = 0.328621 (* 1 = 0.328621 loss)
I0811 14:50:02.905607  8383 sgd_solver.cpp:106] Iteration 31400, lr = 0.000492663
I0811 14:50:06.154526  8383 solver.cpp:337] Iteration 31500, Testing net (#0)
I0811 14:50:12.791254  8383 solver.cpp:404]     Test net output #0: accuracy = 0.911742
I0811 14:50:12.791321  8383 solver.cpp:404]     Test net output #1: loss = 0.206187 (* 1 = 0.206187 loss)
I0811 14:50:12.801550  8383 solver.cpp:228] Iteration 31500, loss = 0.239623
I0811 14:50:12.801580  8383 solver.cpp:244]     Train net output #0: loss = 0.239623 (* 1 = 0.239623 loss)
I0811 14:50:12.801596  8383 sgd_solver.cpp:106] Iteration 31500, lr = 0.000491946
I0811 14:50:16.010813  8383 solver.cpp:228] Iteration 31600, loss = 0.144705
I0811 14:50:16.010848  8383 solver.cpp:244]     Train net output #0: loss = 0.144705 (* 1 = 0.144705 loss)
I0811 14:50:16.010855  8383 sgd_solver.cpp:106] Iteration 31600, lr = 0.00049123
I0811 14:50:19.310689  8383 solver.cpp:228] Iteration 31700, loss = 0.240038
I0811 14:50:19.310729  8383 solver.cpp:244]     Train net output #0: loss = 0.240038 (* 1 = 0.240038 loss)
I0811 14:50:19.310735  8383 sgd_solver.cpp:106] Iteration 31700, lr = 0.000490518
I0811 14:50:22.583065  8383 solver.cpp:228] Iteration 31800, loss = 0.213533
I0811 14:50:22.583102  8383 solver.cpp:244]     Train net output #0: loss = 0.213533 (* 1 = 0.213533 loss)
I0811 14:50:22.583108  8383 sgd_solver.cpp:106] Iteration 31800, lr = 0.000489807
I0811 14:50:25.854991  8383 solver.cpp:228] Iteration 31900, loss = 0.241754
I0811 14:50:25.855027  8383 solver.cpp:244]     Train net output #0: loss = 0.241754 (* 1 = 0.241754 loss)
I0811 14:50:25.855033  8383 sgd_solver.cpp:106] Iteration 31900, lr = 0.000489099
I0811 14:50:29.177530  8383 solver.cpp:337] Iteration 32000, Testing net (#0)
I0811 14:50:35.561661  8383 solver.cpp:404]     Test net output #0: accuracy = 0.848806
I0811 14:50:35.561724  8383 solver.cpp:404]     Test net output #1: loss = 0.364659 (* 1 = 0.364659 loss)
I0811 14:50:35.574661  8383 solver.cpp:228] Iteration 32000, loss = 0.193527
I0811 14:50:35.574693  8383 solver.cpp:244]     Train net output #0: loss = 0.193527 (* 1 = 0.193527 loss)
I0811 14:50:35.574708  8383 sgd_solver.cpp:106] Iteration 32000, lr = 0.000488394
I0811 14:50:38.823935  8383 solver.cpp:228] Iteration 32100, loss = 0.238154
I0811 14:50:38.823977  8383 solver.cpp:244]     Train net output #0: loss = 0.238154 (* 1 = 0.238154 loss)
I0811 14:50:38.823984  8383 sgd_solver.cpp:106] Iteration 32100, lr = 0.00048769
I0811 14:50:42.114409  8383 solver.cpp:228] Iteration 32200, loss = 0.186143
I0811 14:50:42.114462  8383 solver.cpp:244]     Train net output #0: loss = 0.186143 (* 1 = 0.186143 loss)
I0811 14:50:42.114473  8383 sgd_solver.cpp:106] Iteration 32200, lr = 0.00048699
I0811 14:50:45.385116  8383 solver.cpp:228] Iteration 32300, loss = 0.304699
I0811 14:50:45.385159  8383 solver.cpp:244]     Train net output #0: loss = 0.304699 (* 1 = 0.304699 loss)
I0811 14:50:45.385165  8383 sgd_solver.cpp:106] Iteration 32300, lr = 0.000486291
I0811 14:50:48.657927  8383 solver.cpp:228] Iteration 32400, loss = 0.303254
I0811 14:50:48.657970  8383 solver.cpp:244]     Train net output #0: loss = 0.303254 (* 1 = 0.303254 loss)
I0811 14:50:48.657976  8383 sgd_solver.cpp:106] Iteration 32400, lr = 0.000485595
I0811 14:50:51.943100  8383 solver.cpp:337] Iteration 32500, Testing net (#0)
I0811 14:50:53.698334  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:50:58.351006  8383 solver.cpp:404]     Test net output #0: accuracy = 0.888839
I0811 14:50:58.351079  8383 solver.cpp:404]     Test net output #1: loss = 0.265252 (* 1 = 0.265252 loss)
I0811 14:50:58.364069  8383 solver.cpp:228] Iteration 32500, loss = 0.165341
I0811 14:50:58.364125  8383 solver.cpp:244]     Train net output #0: loss = 0.165341 (* 1 = 0.165341 loss)
I0811 14:50:58.364140  8383 sgd_solver.cpp:106] Iteration 32500, lr = 0.000484901
I0811 14:51:01.636055  8383 solver.cpp:228] Iteration 32600, loss = 0.209377
I0811 14:51:01.636096  8383 solver.cpp:244]     Train net output #0: loss = 0.209377 (* 1 = 0.209377 loss)
I0811 14:51:01.636117  8383 sgd_solver.cpp:106] Iteration 32600, lr = 0.000484209
I0811 14:51:04.902704  8383 solver.cpp:228] Iteration 32700, loss = 0.182277
I0811 14:51:04.902743  8383 solver.cpp:244]     Train net output #0: loss = 0.182277 (* 1 = 0.182277 loss)
I0811 14:51:04.902750  8383 sgd_solver.cpp:106] Iteration 32700, lr = 0.00048352
I0811 14:51:08.198894  8383 solver.cpp:228] Iteration 32800, loss = 0.166973
I0811 14:51:08.198931  8383 solver.cpp:244]     Train net output #0: loss = 0.166973 (* 1 = 0.166973 loss)
I0811 14:51:08.198937  8383 sgd_solver.cpp:106] Iteration 32800, lr = 0.000482833
I0811 14:51:11.452092  8383 solver.cpp:228] Iteration 32900, loss = 0.236282
I0811 14:51:11.452143  8383 solver.cpp:244]     Train net output #0: loss = 0.236282 (* 1 = 0.236282 loss)
I0811 14:51:11.452149  8383 sgd_solver.cpp:106] Iteration 32900, lr = 0.000482148
I0811 14:51:14.711205  8383 solver.cpp:337] Iteration 33000, Testing net (#0)
I0811 14:51:21.340378  8383 solver.cpp:404]     Test net output #0: accuracy = 0.867742
I0811 14:51:21.340458  8383 solver.cpp:404]     Test net output #1: loss = 0.324407 (* 1 = 0.324407 loss)
I0811 14:51:21.353710  8383 solver.cpp:228] Iteration 33000, loss = 0.170847
I0811 14:51:21.353745  8383 solver.cpp:244]     Train net output #0: loss = 0.170847 (* 1 = 0.170847 loss)
I0811 14:51:21.353763  8383 sgd_solver.cpp:106] Iteration 33000, lr = 0.000481466
I0811 14:51:24.607017  8383 solver.cpp:228] Iteration 33100, loss = 0.124932
I0811 14:51:24.607053  8383 solver.cpp:244]     Train net output #0: loss = 0.124932 (* 1 = 0.124932 loss)
I0811 14:51:24.607059  8383 sgd_solver.cpp:106] Iteration 33100, lr = 0.000480786
I0811 14:51:27.882570  8383 solver.cpp:228] Iteration 33200, loss = 0.175376
I0811 14:51:27.882632  8383 solver.cpp:244]     Train net output #0: loss = 0.175376 (* 1 = 0.175376 loss)
I0811 14:51:27.882640  8383 sgd_solver.cpp:106] Iteration 33200, lr = 0.000480108
I0811 14:51:31.141608  8383 solver.cpp:228] Iteration 33300, loss = 0.122996
I0811 14:51:31.141651  8383 solver.cpp:244]     Train net output #0: loss = 0.122996 (* 1 = 0.122996 loss)
I0811 14:51:31.141657  8383 sgd_solver.cpp:106] Iteration 33300, lr = 0.000479432
I0811 14:51:34.406368  8383 solver.cpp:228] Iteration 33400, loss = 0.264441
I0811 14:51:34.406404  8383 solver.cpp:244]     Train net output #0: loss = 0.264441 (* 1 = 0.264441 loss)
I0811 14:51:34.406412  8383 sgd_solver.cpp:106] Iteration 33400, lr = 0.000478759
I0811 14:51:37.655879  8383 solver.cpp:337] Iteration 33500, Testing net (#0)
I0811 14:51:44.214275  8383 solver.cpp:404]     Test net output #0: accuracy = 0.92058
I0811 14:51:44.214323  8383 solver.cpp:404]     Test net output #1: loss = 0.193091 (* 1 = 0.193091 loss)
I0811 14:51:44.227483  8383 solver.cpp:228] Iteration 33500, loss = 0.210827
I0811 14:51:44.227550  8383 solver.cpp:244]     Train net output #0: loss = 0.210827 (* 1 = 0.210827 loss)
I0811 14:51:44.227577  8383 sgd_solver.cpp:106] Iteration 33500, lr = 0.000478087
I0811 14:51:47.480099  8383 solver.cpp:228] Iteration 33600, loss = 0.187434
I0811 14:51:47.480136  8383 solver.cpp:244]     Train net output #0: loss = 0.187434 (* 1 = 0.187434 loss)
I0811 14:51:47.480142  8383 sgd_solver.cpp:106] Iteration 33600, lr = 0.000477418
I0811 14:51:50.612283  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:51:50.773885  8383 solver.cpp:228] Iteration 33700, loss = 0.214299
I0811 14:51:50.773936  8383 solver.cpp:244]     Train net output #0: loss = 0.214299 (* 1 = 0.214299 loss)
I0811 14:51:50.773943  8383 sgd_solver.cpp:106] Iteration 33700, lr = 0.000476751
I0811 14:51:54.061442  8383 solver.cpp:228] Iteration 33800, loss = 0.192221
I0811 14:51:54.061482  8383 solver.cpp:244]     Train net output #0: loss = 0.192221 (* 1 = 0.192221 loss)
I0811 14:51:54.061488  8383 sgd_solver.cpp:106] Iteration 33800, lr = 0.000476086
I0811 14:51:57.417480  8383 solver.cpp:228] Iteration 33900, loss = 0.184672
I0811 14:51:57.417517  8383 solver.cpp:244]     Train net output #0: loss = 0.184672 (* 1 = 0.184672 loss)
I0811 14:51:57.417524  8383 sgd_solver.cpp:106] Iteration 33900, lr = 0.000475424
I0811 14:52:00.663118  8383 solver.cpp:337] Iteration 34000, Testing net (#0)
I0811 14:52:07.221822  8383 solver.cpp:404]     Test net output #0: accuracy = 0.886935
I0811 14:52:07.221891  8383 solver.cpp:404]     Test net output #1: loss = 0.280481 (* 1 = 0.280481 loss)
I0811 14:52:07.234902  8383 solver.cpp:228] Iteration 34000, loss = 0.348943
I0811 14:52:07.234932  8383 solver.cpp:244]     Train net output #0: loss = 0.348943 (* 1 = 0.348943 loss)
I0811 14:52:07.234946  8383 sgd_solver.cpp:106] Iteration 34000, lr = 0.000474763
I0811 14:52:10.509138  8383 solver.cpp:228] Iteration 34100, loss = 0.136642
I0811 14:52:10.509178  8383 solver.cpp:244]     Train net output #0: loss = 0.136642 (* 1 = 0.136642 loss)
I0811 14:52:10.509184  8383 sgd_solver.cpp:106] Iteration 34100, lr = 0.000474105
I0811 14:52:13.795413  8383 solver.cpp:228] Iteration 34200, loss = 0.152325
I0811 14:52:13.795454  8383 solver.cpp:244]     Train net output #0: loss = 0.152325 (* 1 = 0.152325 loss)
I0811 14:52:13.795461  8383 sgd_solver.cpp:106] Iteration 34200, lr = 0.000473449
I0811 14:52:17.113811  8383 solver.cpp:228] Iteration 34300, loss = 0.375606
I0811 14:52:17.113847  8383 solver.cpp:244]     Train net output #0: loss = 0.375606 (* 1 = 0.375606 loss)
I0811 14:52:17.113852  8383 sgd_solver.cpp:106] Iteration 34300, lr = 0.000472795
I0811 14:52:20.393738  8383 solver.cpp:228] Iteration 34400, loss = 0.140782
I0811 14:52:20.393800  8383 solver.cpp:244]     Train net output #0: loss = 0.140782 (* 1 = 0.140782 loss)
I0811 14:52:20.393807  8383 sgd_solver.cpp:106] Iteration 34400, lr = 0.000472143
I0811 14:52:23.603420  8383 solver.cpp:337] Iteration 34500, Testing net (#0)
I0811 14:52:30.580902  8383 solver.cpp:404]     Test net output #0: accuracy = 0.899355
I0811 14:52:30.580971  8383 solver.cpp:404]     Test net output #1: loss = 0.251658 (* 1 = 0.251658 loss)
I0811 14:52:30.591696  8383 solver.cpp:228] Iteration 34500, loss = 0.285035
I0811 14:52:30.591758  8383 solver.cpp:244]     Train net output #0: loss = 0.285035 (* 1 = 0.285035 loss)
I0811 14:52:30.591780  8383 sgd_solver.cpp:106] Iteration 34500, lr = 0.000471493
I0811 14:52:33.832252  8383 solver.cpp:228] Iteration 34600, loss = 0.200044
I0811 14:52:33.832300  8383 solver.cpp:244]     Train net output #0: loss = 0.200044 (* 1 = 0.200044 loss)
I0811 14:52:33.832307  8383 sgd_solver.cpp:106] Iteration 34600, lr = 0.000470845
I0811 14:52:37.117908  8383 solver.cpp:228] Iteration 34700, loss = 0.162714
I0811 14:52:37.117955  8383 solver.cpp:244]     Train net output #0: loss = 0.162714 (* 1 = 0.162714 loss)
I0811 14:52:37.117962  8383 sgd_solver.cpp:106] Iteration 34700, lr = 0.000470199
I0811 14:52:40.380115  8383 solver.cpp:228] Iteration 34800, loss = 0.266501
I0811 14:52:40.380152  8383 solver.cpp:244]     Train net output #0: loss = 0.266501 (* 1 = 0.266501 loss)
I0811 14:52:40.380159  8383 sgd_solver.cpp:106] Iteration 34800, lr = 0.000469556
I0811 14:52:43.676375  8383 solver.cpp:228] Iteration 34900, loss = 0.243569
I0811 14:52:43.676394  8383 solver.cpp:244]     Train net output #0: loss = 0.243569 (* 1 = 0.243569 loss)
I0811 14:52:43.676400  8383 sgd_solver.cpp:106] Iteration 34900, lr = 0.000468914
I0811 14:52:46.954704  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_35000.caffemodel
I0811 14:52:47.340024  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_35000.solverstate
I0811 14:52:47.474920  8383 solver.cpp:337] Iteration 35000, Testing net (#0)
I0811 14:52:50.854794  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:52:53.929970  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896258
I0811 14:52:53.930066  8383 solver.cpp:404]     Test net output #1: loss = 0.258021 (* 1 = 0.258021 loss)
I0811 14:52:53.940831  8383 solver.cpp:228] Iteration 35000, loss = 0.102685
I0811 14:52:53.940897  8383 solver.cpp:244]     Train net output #0: loss = 0.102685 (* 1 = 0.102685 loss)
I0811 14:52:53.940915  8383 sgd_solver.cpp:106] Iteration 35000, lr = 0.000468274
I0811 14:52:57.172454  8383 solver.cpp:228] Iteration 35100, loss = 0.162125
I0811 14:52:57.172494  8383 solver.cpp:244]     Train net output #0: loss = 0.162125 (* 1 = 0.162125 loss)
I0811 14:52:57.172502  8383 sgd_solver.cpp:106] Iteration 35100, lr = 0.000467637
I0811 14:53:00.502195  8383 solver.cpp:228] Iteration 35200, loss = 0.265587
I0811 14:53:00.502244  8383 solver.cpp:244]     Train net output #0: loss = 0.265587 (* 1 = 0.265587 loss)
I0811 14:53:00.502254  8383 sgd_solver.cpp:106] Iteration 35200, lr = 0.000467001
I0811 14:53:03.782307  8383 solver.cpp:228] Iteration 35300, loss = 0.277123
I0811 14:53:03.782362  8383 solver.cpp:244]     Train net output #0: loss = 0.277123 (* 1 = 0.277123 loss)
I0811 14:53:03.782369  8383 sgd_solver.cpp:106] Iteration 35300, lr = 0.000466368
I0811 14:53:07.036310  8383 solver.cpp:228] Iteration 35400, loss = 0.131588
I0811 14:53:07.036347  8383 solver.cpp:244]     Train net output #0: loss = 0.131588 (* 1 = 0.131588 loss)
I0811 14:53:07.036353  8383 sgd_solver.cpp:106] Iteration 35400, lr = 0.000465736
I0811 14:53:10.339836  8383 solver.cpp:337] Iteration 35500, Testing net (#0)
I0811 14:53:16.778861  8383 solver.cpp:404]     Test net output #0: accuracy = 0.855581
I0811 14:53:16.778939  8383 solver.cpp:404]     Test net output #1: loss = 0.376256 (* 1 = 0.376256 loss)
I0811 14:53:16.791998  8383 solver.cpp:228] Iteration 35500, loss = 0.240357
I0811 14:53:16.792037  8383 solver.cpp:244]     Train net output #0: loss = 0.240357 (* 1 = 0.240357 loss)
I0811 14:53:16.792055  8383 sgd_solver.cpp:106] Iteration 35500, lr = 0.000465107
I0811 14:53:20.018533  8383 solver.cpp:228] Iteration 35600, loss = 0.158571
I0811 14:53:20.018584  8383 solver.cpp:244]     Train net output #0: loss = 0.158571 (* 1 = 0.158571 loss)
I0811 14:53:20.018590  8383 sgd_solver.cpp:106] Iteration 35600, lr = 0.000464479
I0811 14:53:23.266783  8383 solver.cpp:228] Iteration 35700, loss = 0.112601
I0811 14:53:23.266825  8383 solver.cpp:244]     Train net output #0: loss = 0.112601 (* 1 = 0.112601 loss)
I0811 14:53:23.266832  8383 sgd_solver.cpp:106] Iteration 35700, lr = 0.000463854
I0811 14:53:26.564702  8383 solver.cpp:228] Iteration 35800, loss = 0.179078
I0811 14:53:26.564738  8383 solver.cpp:244]     Train net output #0: loss = 0.179078 (* 1 = 0.179078 loss)
I0811 14:53:26.564743  8383 sgd_solver.cpp:106] Iteration 35800, lr = 0.00046323
I0811 14:53:29.822157  8383 solver.cpp:228] Iteration 35900, loss = 0.173632
I0811 14:53:29.822194  8383 solver.cpp:244]     Train net output #0: loss = 0.173632 (* 1 = 0.173632 loss)
I0811 14:53:29.822201  8383 sgd_solver.cpp:106] Iteration 35900, lr = 0.000462609
I0811 14:53:33.058621  8383 solver.cpp:337] Iteration 36000, Testing net (#0)
I0811 14:53:39.855466  8383 solver.cpp:404]     Test net output #0: accuracy = 0.928677
I0811 14:53:39.855545  8383 solver.cpp:404]     Test net output #1: loss = 0.181357 (* 1 = 0.181357 loss)
I0811 14:53:39.869117  8383 solver.cpp:228] Iteration 36000, loss = 0.183622
I0811 14:53:39.869182  8383 solver.cpp:244]     Train net output #0: loss = 0.183622 (* 1 = 0.183622 loss)
I0811 14:53:39.869206  8383 sgd_solver.cpp:106] Iteration 36000, lr = 0.000461989
I0811 14:53:43.083729  8383 solver.cpp:228] Iteration 36100, loss = 0.168887
I0811 14:53:43.083767  8383 solver.cpp:244]     Train net output #0: loss = 0.168887 (* 1 = 0.168887 loss)
I0811 14:53:43.083775  8383 sgd_solver.cpp:106] Iteration 36100, lr = 0.000461371
I0811 14:53:46.362386  8383 solver.cpp:228] Iteration 36200, loss = 0.0693351
I0811 14:53:46.362435  8383 solver.cpp:244]     Train net output #0: loss = 0.0693351 (* 1 = 0.0693351 loss)
I0811 14:53:46.362444  8383 sgd_solver.cpp:106] Iteration 36200, lr = 0.000460755
I0811 14:53:49.630110  8383 solver.cpp:228] Iteration 36300, loss = 0.165502
I0811 14:53:49.630154  8383 solver.cpp:244]     Train net output #0: loss = 0.165502 (* 1 = 0.165502 loss)
I0811 14:53:49.630162  8383 sgd_solver.cpp:106] Iteration 36300, lr = 0.000460141
I0811 14:53:52.927183  8383 solver.cpp:228] Iteration 36400, loss = 0.0928161
I0811 14:53:52.927222  8383 solver.cpp:244]     Train net output #0: loss = 0.0928161 (* 1 = 0.0928161 loss)
I0811 14:53:52.927228  8383 sgd_solver.cpp:106] Iteration 36400, lr = 0.000459529
I0811 14:53:56.140694  8383 solver.cpp:337] Iteration 36500, Testing net (#0)
I0811 14:53:58.163009  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:54:02.536814  8383 solver.cpp:404]     Test net output #0: accuracy = 0.887517
I0811 14:54:02.536885  8383 solver.cpp:404]     Test net output #1: loss = 0.28766 (* 1 = 0.28766 loss)
I0811 14:54:02.550451  8383 solver.cpp:228] Iteration 36500, loss = 0.178244
I0811 14:54:02.550475  8383 solver.cpp:244]     Train net output #0: loss = 0.178244 (* 1 = 0.178244 loss)
I0811 14:54:02.550489  8383 sgd_solver.cpp:106] Iteration 36500, lr = 0.000458919
I0811 14:54:05.780472  8383 solver.cpp:228] Iteration 36600, loss = 0.20454
I0811 14:54:05.780513  8383 solver.cpp:244]     Train net output #0: loss = 0.20454 (* 1 = 0.20454 loss)
I0811 14:54:05.780519  8383 sgd_solver.cpp:106] Iteration 36600, lr = 0.000458311
I0811 14:54:09.056463  8383 solver.cpp:228] Iteration 36700, loss = 0.168909
I0811 14:54:09.056509  8383 solver.cpp:244]     Train net output #0: loss = 0.168909 (* 1 = 0.168909 loss)
I0811 14:54:09.056514  8383 sgd_solver.cpp:106] Iteration 36700, lr = 0.000457705
I0811 14:54:12.325682  8383 solver.cpp:228] Iteration 36800, loss = 0.130843
I0811 14:54:12.325721  8383 solver.cpp:244]     Train net output #0: loss = 0.130843 (* 1 = 0.130843 loss)
I0811 14:54:12.325726  8383 sgd_solver.cpp:106] Iteration 36800, lr = 0.0004571
I0811 14:54:15.602005  8383 solver.cpp:228] Iteration 36900, loss = 0.134919
I0811 14:54:15.602025  8383 solver.cpp:244]     Train net output #0: loss = 0.134919 (* 1 = 0.134919 loss)
I0811 14:54:15.602030  8383 sgd_solver.cpp:106] Iteration 36900, lr = 0.000456497
I0811 14:54:18.813194  8383 solver.cpp:337] Iteration 37000, Testing net (#0)
I0811 14:54:25.366264  8383 solver.cpp:404]     Test net output #0: accuracy = 0.909903
I0811 14:54:25.366338  8383 solver.cpp:404]     Test net output #1: loss = 0.234349 (* 1 = 0.234349 loss)
I0811 14:54:25.378703  8383 solver.cpp:228] Iteration 37000, loss = 0.10834
I0811 14:54:25.378760  8383 solver.cpp:244]     Train net output #0: loss = 0.10834 (* 1 = 0.10834 loss)
I0811 14:54:25.378784  8383 sgd_solver.cpp:106] Iteration 37000, lr = 0.000455897
I0811 14:54:28.621269  8383 solver.cpp:228] Iteration 37100, loss = 0.166487
I0811 14:54:28.621312  8383 solver.cpp:244]     Train net output #0: loss = 0.166487 (* 1 = 0.166487 loss)
I0811 14:54:28.621318  8383 sgd_solver.cpp:106] Iteration 37100, lr = 0.000455298
I0811 14:54:31.894225  8383 solver.cpp:228] Iteration 37200, loss = 0.137718
I0811 14:54:31.894286  8383 solver.cpp:244]     Train net output #0: loss = 0.137718 (* 1 = 0.137718 loss)
I0811 14:54:31.894294  8383 sgd_solver.cpp:106] Iteration 37200, lr = 0.000454701
I0811 14:54:35.152061  8383 solver.cpp:228] Iteration 37300, loss = 0.089598
I0811 14:54:35.152117  8383 solver.cpp:244]     Train net output #0: loss = 0.089598 (* 1 = 0.089598 loss)
I0811 14:54:35.152133  8383 sgd_solver.cpp:106] Iteration 37300, lr = 0.000454105
I0811 14:54:38.441457  8383 solver.cpp:228] Iteration 37400, loss = 0.262811
I0811 14:54:38.441507  8383 solver.cpp:244]     Train net output #0: loss = 0.262811 (* 1 = 0.262811 loss)
I0811 14:54:38.441516  8383 sgd_solver.cpp:106] Iteration 37400, lr = 0.000453512
I0811 14:54:41.686846  8383 solver.cpp:337] Iteration 37500, Testing net (#0)
I0811 14:54:48.120249  8383 solver.cpp:404]     Test net output #0: accuracy = 0.918516
I0811 14:54:48.120307  8383 solver.cpp:404]     Test net output #1: loss = 0.215336 (* 1 = 0.215336 loss)
I0811 14:54:48.130445  8383 solver.cpp:228] Iteration 37500, loss = 0.240139
I0811 14:54:48.130470  8383 solver.cpp:244]     Train net output #0: loss = 0.240139 (* 1 = 0.240139 loss)
I0811 14:54:48.130484  8383 sgd_solver.cpp:106] Iteration 37500, lr = 0.00045292
I0811 14:54:51.365381  8383 solver.cpp:228] Iteration 37600, loss = 0.102382
I0811 14:54:51.365427  8383 solver.cpp:244]     Train net output #0: loss = 0.102382 (* 1 = 0.102382 loss)
I0811 14:54:51.365434  8383 sgd_solver.cpp:106] Iteration 37600, lr = 0.00045233
I0811 14:54:54.635771  8383 solver.cpp:228] Iteration 37700, loss = 0.242391
I0811 14:54:54.635813  8383 solver.cpp:244]     Train net output #0: loss = 0.242391 (* 1 = 0.242391 loss)
I0811 14:54:54.635819  8383 sgd_solver.cpp:106] Iteration 37700, lr = 0.000451742
I0811 14:54:57.896720  8383 solver.cpp:228] Iteration 37800, loss = 0.208357
I0811 14:54:57.896771  8383 solver.cpp:244]     Train net output #0: loss = 0.208357 (* 1 = 0.208357 loss)
I0811 14:54:57.896778  8383 sgd_solver.cpp:106] Iteration 37800, lr = 0.000451156
I0811 14:55:01.180788  8383 solver.cpp:228] Iteration 37900, loss = 0.174034
I0811 14:55:01.180845  8383 solver.cpp:244]     Train net output #0: loss = 0.174034 (* 1 = 0.174034 loss)
I0811 14:55:01.180851  8383 sgd_solver.cpp:106] Iteration 37900, lr = 0.000450571
I0811 14:55:04.395035  8383 solver.cpp:337] Iteration 38000, Testing net (#0)
I0811 14:55:06.628782  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:55:10.947618  8383 solver.cpp:404]     Test net output #0: accuracy = 0.920097
I0811 14:55:10.947679  8383 solver.cpp:404]     Test net output #1: loss = 0.204313 (* 1 = 0.204313 loss)
I0811 14:55:10.961634  8383 solver.cpp:228] Iteration 38000, loss = 0.265081
I0811 14:55:10.961701  8383 solver.cpp:244]     Train net output #0: loss = 0.265081 (* 1 = 0.265081 loss)
I0811 14:55:10.961725  8383 sgd_solver.cpp:106] Iteration 38000, lr = 0.000449989
I0811 14:55:14.195181  8383 solver.cpp:228] Iteration 38100, loss = 0.10238
I0811 14:55:14.195224  8383 solver.cpp:244]     Train net output #0: loss = 0.10238 (* 1 = 0.10238 loss)
I0811 14:55:14.195230  8383 sgd_solver.cpp:106] Iteration 38100, lr = 0.000449408
I0811 14:55:17.439050  8383 solver.cpp:228] Iteration 38200, loss = 0.199961
I0811 14:55:17.439101  8383 solver.cpp:244]     Train net output #0: loss = 0.199961 (* 1 = 0.199961 loss)
I0811 14:55:17.439108  8383 sgd_solver.cpp:106] Iteration 38200, lr = 0.000448828
I0811 14:55:20.706857  8383 solver.cpp:228] Iteration 38300, loss = 0.152618
I0811 14:55:20.706894  8383 solver.cpp:244]     Train net output #0: loss = 0.152618 (* 1 = 0.152618 loss)
I0811 14:55:20.706900  8383 sgd_solver.cpp:106] Iteration 38300, lr = 0.000448251
I0811 14:55:23.994308  8383 solver.cpp:228] Iteration 38400, loss = 0.191496
I0811 14:55:23.994349  8383 solver.cpp:244]     Train net output #0: loss = 0.191496 (* 1 = 0.191496 loss)
I0811 14:55:23.994356  8383 sgd_solver.cpp:106] Iteration 38400, lr = 0.000447675
I0811 14:55:27.219980  8383 solver.cpp:337] Iteration 38500, Testing net (#0)
I0811 14:55:33.747467  8383 solver.cpp:404]     Test net output #0: accuracy = 0.92929
I0811 14:55:33.747537  8383 solver.cpp:404]     Test net output #1: loss = 0.188062 (* 1 = 0.188062 loss)
I0811 14:55:33.760562  8383 solver.cpp:228] Iteration 38500, loss = 0.123505
I0811 14:55:33.760597  8383 solver.cpp:244]     Train net output #0: loss = 0.123505 (* 1 = 0.123505 loss)
I0811 14:55:33.760613  8383 sgd_solver.cpp:106] Iteration 38500, lr = 0.000447101
I0811 14:55:37.043933  8383 solver.cpp:228] Iteration 38600, loss = 0.229617
I0811 14:55:37.043973  8383 solver.cpp:244]     Train net output #0: loss = 0.229617 (* 1 = 0.229617 loss)
I0811 14:55:37.043980  8383 sgd_solver.cpp:106] Iteration 38600, lr = 0.000446529
I0811 14:55:40.314430  8383 solver.cpp:228] Iteration 38700, loss = 0.175562
I0811 14:55:40.314484  8383 solver.cpp:244]     Train net output #0: loss = 0.175562 (* 1 = 0.175562 loss)
I0811 14:55:40.314497  8383 sgd_solver.cpp:106] Iteration 38700, lr = 0.000445958
I0811 14:55:43.585566  8383 solver.cpp:228] Iteration 38800, loss = 0.0874286
I0811 14:55:43.585618  8383 solver.cpp:244]     Train net output #0: loss = 0.0874286 (* 1 = 0.0874286 loss)
I0811 14:55:43.585625  8383 sgd_solver.cpp:106] Iteration 38800, lr = 0.000445389
I0811 14:55:46.842532  8383 solver.cpp:228] Iteration 38900, loss = 0.173625
I0811 14:55:46.842561  8383 solver.cpp:244]     Train net output #0: loss = 0.173625 (* 1 = 0.173625 loss)
I0811 14:55:46.842566  8383 sgd_solver.cpp:106] Iteration 38900, lr = 0.000444822
I0811 14:55:50.093051  8383 solver.cpp:337] Iteration 39000, Testing net (#0)
I0811 14:55:56.613476  8383 solver.cpp:404]     Test net output #0: accuracy = 0.918097
I0811 14:55:56.613557  8383 solver.cpp:404]     Test net output #1: loss = 0.219033 (* 1 = 0.219033 loss)
I0811 14:55:56.626719  8383 solver.cpp:228] Iteration 39000, loss = 0.0968766
I0811 14:55:56.626782  8383 solver.cpp:244]     Train net output #0: loss = 0.0968766 (* 1 = 0.0968766 loss)
I0811 14:55:56.626806  8383 sgd_solver.cpp:106] Iteration 39000, lr = 0.000444256
I0811 14:55:59.860296  8383 solver.cpp:228] Iteration 39100, loss = 0.212934
I0811 14:55:59.860352  8383 solver.cpp:244]     Train net output #0: loss = 0.212934 (* 1 = 0.212934 loss)
I0811 14:55:59.860358  8383 sgd_solver.cpp:106] Iteration 39100, lr = 0.000443692
I0811 14:56:03.113368  8383 solver.cpp:228] Iteration 39200, loss = 0.152083
I0811 14:56:03.113430  8383 solver.cpp:244]     Train net output #0: loss = 0.152083 (* 1 = 0.152083 loss)
I0811 14:56:03.113436  8383 sgd_solver.cpp:106] Iteration 39200, lr = 0.00044313
I0811 14:56:06.388156  8383 solver.cpp:228] Iteration 39300, loss = 0.150103
I0811 14:56:06.388201  8383 solver.cpp:244]     Train net output #0: loss = 0.150103 (* 1 = 0.150103 loss)
I0811 14:56:06.388209  8383 sgd_solver.cpp:106] Iteration 39300, lr = 0.00044257
I0811 14:56:09.633146  8383 solver.cpp:228] Iteration 39400, loss = 0.224419
I0811 14:56:09.633191  8383 solver.cpp:244]     Train net output #0: loss = 0.224419 (* 1 = 0.224419 loss)
I0811 14:56:09.633198  8383 sgd_solver.cpp:106] Iteration 39400, lr = 0.000442011
I0811 14:56:11.160930  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:56:12.882437  8383 solver.cpp:337] Iteration 39500, Testing net (#0)
I0811 14:56:19.770045  8383 solver.cpp:404]     Test net output #0: accuracy = 0.871935
I0811 14:56:19.770125  8383 solver.cpp:404]     Test net output #1: loss = 0.378899 (* 1 = 0.378899 loss)
I0811 14:56:19.780252  8383 solver.cpp:228] Iteration 39500, loss = 0.0848037
I0811 14:56:19.780277  8383 solver.cpp:244]     Train net output #0: loss = 0.0848037 (* 1 = 0.0848037 loss)
I0811 14:56:19.780292  8383 sgd_solver.cpp:106] Iteration 39500, lr = 0.000441453
I0811 14:56:22.964006  8383 solver.cpp:228] Iteration 39600, loss = 0.266949
I0811 14:56:22.964047  8383 solver.cpp:244]     Train net output #0: loss = 0.266949 (* 1 = 0.266949 loss)
I0811 14:56:22.964054  8383 sgd_solver.cpp:106] Iteration 39600, lr = 0.000440898
I0811 14:56:26.224361  8383 solver.cpp:228] Iteration 39700, loss = 0.0906986
I0811 14:56:26.224406  8383 solver.cpp:244]     Train net output #0: loss = 0.0906986 (* 1 = 0.0906986 loss)
I0811 14:56:26.224411  8383 sgd_solver.cpp:106] Iteration 39700, lr = 0.000440344
I0811 14:56:29.491830  8383 solver.cpp:228] Iteration 39800, loss = 0.130297
I0811 14:56:29.491869  8383 solver.cpp:244]     Train net output #0: loss = 0.130297 (* 1 = 0.130297 loss)
I0811 14:56:29.491876  8383 sgd_solver.cpp:106] Iteration 39800, lr = 0.000439791
I0811 14:56:32.752904  8383 solver.cpp:228] Iteration 39900, loss = 0.151734
I0811 14:56:32.752959  8383 solver.cpp:244]     Train net output #0: loss = 0.151734 (* 1 = 0.151734 loss)
I0811 14:56:32.752966  8383 sgd_solver.cpp:106] Iteration 39900, lr = 0.000439241
I0811 14:56:35.971338  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_40000.caffemodel
I0811 14:56:36.340131  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_40000.solverstate
I0811 14:56:36.472218  8383 solver.cpp:337] Iteration 40000, Testing net (#0)
I0811 14:56:42.924592  8383 solver.cpp:404]     Test net output #0: accuracy = 0.879097
I0811 14:56:42.924671  8383 solver.cpp:404]     Test net output #1: loss = 0.350741 (* 1 = 0.350741 loss)
I0811 14:56:42.938601  8383 solver.cpp:228] Iteration 40000, loss = 0.120907
I0811 14:56:42.938668  8383 solver.cpp:244]     Train net output #0: loss = 0.120907 (* 1 = 0.120907 loss)
I0811 14:56:42.938694  8383 sgd_solver.cpp:106] Iteration 40000, lr = 0.000438691
I0811 14:56:46.157331  8383 solver.cpp:228] Iteration 40100, loss = 0.240606
I0811 14:56:46.157371  8383 solver.cpp:244]     Train net output #0: loss = 0.240606 (* 1 = 0.240606 loss)
I0811 14:56:46.157377  8383 sgd_solver.cpp:106] Iteration 40100, lr = 0.000438144
I0811 14:56:49.440961  8383 solver.cpp:228] Iteration 40200, loss = 0.104015
I0811 14:56:49.441004  8383 solver.cpp:244]     Train net output #0: loss = 0.104015 (* 1 = 0.104015 loss)
I0811 14:56:49.441009  8383 sgd_solver.cpp:106] Iteration 40200, lr = 0.000437598
I0811 14:56:52.725708  8383 solver.cpp:228] Iteration 40300, loss = 0.0968119
I0811 14:56:52.725759  8383 solver.cpp:244]     Train net output #0: loss = 0.0968119 (* 1 = 0.0968119 loss)
I0811 14:56:52.725767  8383 sgd_solver.cpp:106] Iteration 40300, lr = 0.000437053
I0811 14:56:55.974328  8383 solver.cpp:228] Iteration 40400, loss = 0.131978
I0811 14:56:55.974366  8383 solver.cpp:244]     Train net output #0: loss = 0.131978 (* 1 = 0.131978 loss)
I0811 14:56:55.974372  8383 sgd_solver.cpp:106] Iteration 40400, lr = 0.000436511
I0811 14:56:59.242982  8383 solver.cpp:337] Iteration 40500, Testing net (#0)
I0811 14:57:05.014048  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:57:06.018895  8383 solver.cpp:404]     Test net output #0: accuracy = 0.887291
I0811 14:57:06.018968  8383 solver.cpp:404]     Test net output #1: loss = 0.30253 (* 1 = 0.30253 loss)
I0811 14:57:06.031646  8383 solver.cpp:228] Iteration 40500, loss = 0.157495
I0811 14:57:06.031672  8383 solver.cpp:244]     Train net output #0: loss = 0.157495 (* 1 = 0.157495 loss)
I0811 14:57:06.031685  8383 sgd_solver.cpp:106] Iteration 40500, lr = 0.000435969
I0811 14:57:09.261020  8383 solver.cpp:228] Iteration 40600, loss = 0.0928069
I0811 14:57:09.261064  8383 solver.cpp:244]     Train net output #0: loss = 0.0928069 (* 1 = 0.0928069 loss)
I0811 14:57:09.261070  8383 sgd_solver.cpp:106] Iteration 40600, lr = 0.00043543
I0811 14:57:12.525617  8383 solver.cpp:228] Iteration 40700, loss = 0.244677
I0811 14:57:12.525665  8383 solver.cpp:244]     Train net output #0: loss = 0.244677 (* 1 = 0.244677 loss)
I0811 14:57:12.525672  8383 sgd_solver.cpp:106] Iteration 40700, lr = 0.000434892
I0811 14:57:15.764696  8383 solver.cpp:228] Iteration 40800, loss = 0.0946894
I0811 14:57:15.764739  8383 solver.cpp:244]     Train net output #0: loss = 0.0946894 (* 1 = 0.0946894 loss)
I0811 14:57:15.764745  8383 sgd_solver.cpp:106] Iteration 40800, lr = 0.000434355
I0811 14:57:19.010722  8383 solver.cpp:228] Iteration 40900, loss = 0.356272
I0811 14:57:19.010761  8383 solver.cpp:244]     Train net output #0: loss = 0.356272 (* 1 = 0.356272 loss)
I0811 14:57:19.010766  8383 sgd_solver.cpp:106] Iteration 40900, lr = 0.00043382
I0811 14:57:22.256587  8383 solver.cpp:337] Iteration 41000, Testing net (#0)
I0811 14:57:28.757781  8383 solver.cpp:404]     Test net output #0: accuracy = 0.902903
I0811 14:57:28.757848  8383 solver.cpp:404]     Test net output #1: loss = 0.274165 (* 1 = 0.274165 loss)
I0811 14:57:28.769016  8383 solver.cpp:228] Iteration 41000, loss = 0.0594734
I0811 14:57:28.769083  8383 solver.cpp:244]     Train net output #0: loss = 0.0594734 (* 1 = 0.0594734 loss)
I0811 14:57:28.769107  8383 sgd_solver.cpp:106] Iteration 41000, lr = 0.000433286
I0811 14:57:31.992907  8383 solver.cpp:228] Iteration 41100, loss = 0.266037
I0811 14:57:31.992949  8383 solver.cpp:244]     Train net output #0: loss = 0.266037 (* 1 = 0.266037 loss)
I0811 14:57:31.992956  8383 sgd_solver.cpp:106] Iteration 41100, lr = 0.000432755
I0811 14:57:35.241755  8383 solver.cpp:228] Iteration 41200, loss = 0.0855493
I0811 14:57:35.241797  8383 solver.cpp:244]     Train net output #0: loss = 0.0855493 (* 1 = 0.0855493 loss)
I0811 14:57:35.241804  8383 sgd_solver.cpp:106] Iteration 41200, lr = 0.000432224
I0811 14:57:38.487756  8383 solver.cpp:228] Iteration 41300, loss = 0.105653
I0811 14:57:38.487797  8383 solver.cpp:244]     Train net output #0: loss = 0.105653 (* 1 = 0.105653 loss)
I0811 14:57:38.487804  8383 sgd_solver.cpp:106] Iteration 41300, lr = 0.000431695
I0811 14:57:41.772496  8383 solver.cpp:228] Iteration 41400, loss = 0.0640892
I0811 14:57:41.772536  8383 solver.cpp:244]     Train net output #0: loss = 0.0640892 (* 1 = 0.0640892 loss)
I0811 14:57:41.772543  8383 sgd_solver.cpp:106] Iteration 41400, lr = 0.000431168
I0811 14:57:44.998167  8383 solver.cpp:337] Iteration 41500, Testing net (#0)
I0811 14:57:51.416779  8383 solver.cpp:404]     Test net output #0: accuracy = 0.890613
I0811 14:57:51.416833  8383 solver.cpp:404]     Test net output #1: loss = 0.328546 (* 1 = 0.328546 loss)
I0811 14:57:51.427072  8383 solver.cpp:228] Iteration 41500, loss = 0.225091
I0811 14:57:51.427098  8383 solver.cpp:244]     Train net output #0: loss = 0.225091 (* 1 = 0.225091 loss)
I0811 14:57:51.427111  8383 sgd_solver.cpp:106] Iteration 41500, lr = 0.000430642
I0811 14:57:54.650892  8383 solver.cpp:228] Iteration 41600, loss = 0.381512
I0811 14:57:54.650930  8383 solver.cpp:244]     Train net output #0: loss = 0.381512 (* 1 = 0.381512 loss)
I0811 14:57:54.650936  8383 sgd_solver.cpp:106] Iteration 41600, lr = 0.000430117
I0811 14:57:57.954555  8383 solver.cpp:228] Iteration 41700, loss = 0.0434393
I0811 14:57:57.954596  8383 solver.cpp:244]     Train net output #0: loss = 0.0434393 (* 1 = 0.0434393 loss)
I0811 14:57:57.954602  8383 sgd_solver.cpp:106] Iteration 41700, lr = 0.000429594
I0811 14:58:01.233546  8383 solver.cpp:228] Iteration 41800, loss = 0.119127
I0811 14:58:01.233595  8383 solver.cpp:244]     Train net output #0: loss = 0.119127 (* 1 = 0.119127 loss)
I0811 14:58:01.233603  8383 sgd_solver.cpp:106] Iteration 41800, lr = 0.000429073
I0811 14:58:04.483180  8383 solver.cpp:228] Iteration 41900, loss = 0.173005
I0811 14:58:04.483216  8383 solver.cpp:244]     Train net output #0: loss = 0.173005 (* 1 = 0.173005 loss)
I0811 14:58:04.483222  8383 sgd_solver.cpp:106] Iteration 41900, lr = 0.000428553
I0811 14:58:07.712203  8383 solver.cpp:337] Iteration 42000, Testing net (#0)
I0811 14:58:13.337883  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:58:14.088572  8383 solver.cpp:404]     Test net output #0: accuracy = 0.92371
I0811 14:58:14.088639  8383 solver.cpp:404]     Test net output #1: loss = 0.206241 (* 1 = 0.206241 loss)
I0811 14:58:14.098969  8383 solver.cpp:228] Iteration 42000, loss = 0.187922
I0811 14:58:14.099002  8383 solver.cpp:244]     Train net output #0: loss = 0.187922 (* 1 = 0.187922 loss)
I0811 14:58:14.099014  8383 sgd_solver.cpp:106] Iteration 42000, lr = 0.000428034
I0811 14:58:17.333416  8383 solver.cpp:228] Iteration 42100, loss = 0.0372487
I0811 14:58:17.333451  8383 solver.cpp:244]     Train net output #0: loss = 0.0372487 (* 1 = 0.0372487 loss)
I0811 14:58:17.333457  8383 sgd_solver.cpp:106] Iteration 42100, lr = 0.000427517
I0811 14:58:20.559937  8383 solver.cpp:228] Iteration 42200, loss = 0.150433
I0811 14:58:20.559980  8383 solver.cpp:244]     Train net output #0: loss = 0.150433 (* 1 = 0.150433 loss)
I0811 14:58:20.559988  8383 sgd_solver.cpp:106] Iteration 42200, lr = 0.000427002
I0811 14:58:23.855255  8383 solver.cpp:228] Iteration 42300, loss = 0.0738265
I0811 14:58:23.855303  8383 solver.cpp:244]     Train net output #0: loss = 0.0738265 (* 1 = 0.0738265 loss)
I0811 14:58:23.855311  8383 sgd_solver.cpp:106] Iteration 42300, lr = 0.000426488
I0811 14:58:27.152034  8383 solver.cpp:228] Iteration 42400, loss = 0.0797455
I0811 14:58:27.152086  8383 solver.cpp:244]     Train net output #0: loss = 0.0797455 (* 1 = 0.0797455 loss)
I0811 14:58:27.152093  8383 sgd_solver.cpp:106] Iteration 42400, lr = 0.000425975
I0811 14:58:30.412749  8383 solver.cpp:337] Iteration 42500, Testing net (#0)
I0811 14:58:36.990839  8383 solver.cpp:404]     Test net output #0: accuracy = 0.875548
I0811 14:58:36.990900  8383 solver.cpp:404]     Test net output #1: loss = 0.360398 (* 1 = 0.360398 loss)
I0811 14:58:37.001771  8383 solver.cpp:228] Iteration 42500, loss = 0.0437851
I0811 14:58:37.001837  8383 solver.cpp:244]     Train net output #0: loss = 0.0437851 (* 1 = 0.0437851 loss)
I0811 14:58:37.001859  8383 sgd_solver.cpp:106] Iteration 42500, lr = 0.000425464
I0811 14:58:40.238082  8383 solver.cpp:228] Iteration 42600, loss = 0.294116
I0811 14:58:40.238134  8383 solver.cpp:244]     Train net output #0: loss = 0.294116 (* 1 = 0.294116 loss)
I0811 14:58:40.238142  8383 sgd_solver.cpp:106] Iteration 42600, lr = 0.000424954
I0811 14:58:43.493033  8383 solver.cpp:228] Iteration 42700, loss = 0.0372686
I0811 14:58:43.493075  8383 solver.cpp:244]     Train net output #0: loss = 0.0372686 (* 1 = 0.0372686 loss)
I0811 14:58:43.493082  8383 sgd_solver.cpp:106] Iteration 42700, lr = 0.000424445
I0811 14:58:46.733546  8383 solver.cpp:228] Iteration 42800, loss = 0.164212
I0811 14:58:46.733583  8383 solver.cpp:244]     Train net output #0: loss = 0.164212 (* 1 = 0.164212 loss)
I0811 14:58:46.733590  8383 sgd_solver.cpp:106] Iteration 42800, lr = 0.000423938
I0811 14:58:49.992096  8383 solver.cpp:228] Iteration 42900, loss = 0.0541575
I0811 14:58:49.992138  8383 solver.cpp:244]     Train net output #0: loss = 0.0541575 (* 1 = 0.0541575 loss)
I0811 14:58:49.992146  8383 sgd_solver.cpp:106] Iteration 42900, lr = 0.000423433
I0811 14:58:53.227824  8383 solver.cpp:337] Iteration 43000, Testing net (#0)
I0811 14:58:59.762138  8383 solver.cpp:404]     Test net output #0: accuracy = 0.918032
I0811 14:58:59.762207  8383 solver.cpp:404]     Test net output #1: loss = 0.23774 (* 1 = 0.23774 loss)
I0811 14:58:59.777093  8383 solver.cpp:228] Iteration 43000, loss = 0.118216
I0811 14:58:59.777158  8383 solver.cpp:244]     Train net output #0: loss = 0.118216 (* 1 = 0.118216 loss)
I0811 14:58:59.777179  8383 sgd_solver.cpp:106] Iteration 43000, lr = 0.000422929
I0811 14:59:03.014279  8383 solver.cpp:228] Iteration 43100, loss = 0.1328
I0811 14:59:03.014367  8383 solver.cpp:244]     Train net output #0: loss = 0.1328 (* 1 = 0.1328 loss)
I0811 14:59:03.014387  8383 sgd_solver.cpp:106] Iteration 43100, lr = 0.000422426
I0811 14:59:06.255532  8383 solver.cpp:228] Iteration 43200, loss = 0.0855865
I0811 14:59:06.255573  8383 solver.cpp:244]     Train net output #0: loss = 0.0855865 (* 1 = 0.0855865 loss)
I0811 14:59:06.255579  8383 sgd_solver.cpp:106] Iteration 43200, lr = 0.000421924
I0811 14:59:09.550967  8383 solver.cpp:228] Iteration 43300, loss = 0.0682015
I0811 14:59:09.551030  8383 solver.cpp:244]     Train net output #0: loss = 0.0682015 (* 1 = 0.0682015 loss)
I0811 14:59:09.551041  8383 sgd_solver.cpp:106] Iteration 43300, lr = 0.000421424
I0811 14:59:12.813385  8383 solver.cpp:228] Iteration 43400, loss = 0.100393
I0811 14:59:12.813427  8383 solver.cpp:244]     Train net output #0: loss = 0.100393 (* 1 = 0.100393 loss)
I0811 14:59:12.813433  8383 sgd_solver.cpp:106] Iteration 43400, lr = 0.000420926
I0811 14:59:16.053058  8383 solver.cpp:337] Iteration 43500, Testing net (#0)
I0811 14:59:19.868374  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 14:59:22.388802  8383 solver.cpp:404]     Test net output #0: accuracy = 0.923225
I0811 14:59:22.388866  8383 solver.cpp:404]     Test net output #1: loss = 0.219272 (* 1 = 0.219272 loss)
I0811 14:59:22.402081  8383 solver.cpp:228] Iteration 43500, loss = 0.0703184
I0811 14:59:22.402118  8383 solver.cpp:244]     Train net output #0: loss = 0.0703184 (* 1 = 0.0703184 loss)
I0811 14:59:22.402132  8383 sgd_solver.cpp:106] Iteration 43500, lr = 0.000420429
I0811 14:59:25.642627  8383 solver.cpp:228] Iteration 43600, loss = 0.24308
I0811 14:59:25.642663  8383 solver.cpp:244]     Train net output #0: loss = 0.24308 (* 1 = 0.24308 loss)
I0811 14:59:25.642668  8383 sgd_solver.cpp:106] Iteration 43600, lr = 0.000419933
I0811 14:59:28.878566  8383 solver.cpp:228] Iteration 43700, loss = 0.139756
I0811 14:59:28.878607  8383 solver.cpp:244]     Train net output #0: loss = 0.139756 (* 1 = 0.139756 loss)
I0811 14:59:28.878612  8383 sgd_solver.cpp:106] Iteration 43700, lr = 0.000419438
I0811 14:59:32.121017  8383 solver.cpp:228] Iteration 43800, loss = 0.109601
I0811 14:59:32.121059  8383 solver.cpp:244]     Train net output #0: loss = 0.109601 (* 1 = 0.109601 loss)
I0811 14:59:32.121065  8383 sgd_solver.cpp:106] Iteration 43800, lr = 0.000418945
I0811 14:59:35.368481  8383 solver.cpp:228] Iteration 43900, loss = 0.0807426
I0811 14:59:35.368523  8383 solver.cpp:244]     Train net output #0: loss = 0.0807426 (* 1 = 0.0807426 loss)
I0811 14:59:35.368530  8383 sgd_solver.cpp:106] Iteration 43900, lr = 0.000418453
I0811 14:59:38.581140  8383 solver.cpp:337] Iteration 44000, Testing net (#0)
I0811 14:59:45.352095  8383 solver.cpp:404]     Test net output #0: accuracy = 0.928742
I0811 14:59:45.352166  8383 solver.cpp:404]     Test net output #1: loss = 0.224721 (* 1 = 0.224721 loss)
I0811 14:59:45.362843  8383 solver.cpp:228] Iteration 44000, loss = 0.0771486
I0811 14:59:45.362895  8383 solver.cpp:244]     Train net output #0: loss = 0.0771486 (* 1 = 0.0771486 loss)
I0811 14:59:45.362913  8383 sgd_solver.cpp:106] Iteration 44000, lr = 0.000417963
I0811 14:59:48.599009  8383 solver.cpp:228] Iteration 44100, loss = 0.0778712
I0811 14:59:48.599067  8383 solver.cpp:244]     Train net output #0: loss = 0.0778712 (* 1 = 0.0778712 loss)
I0811 14:59:48.599074  8383 sgd_solver.cpp:106] Iteration 44100, lr = 0.000417474
I0811 14:59:51.865595  8383 solver.cpp:228] Iteration 44200, loss = 0.0528388
I0811 14:59:51.865650  8383 solver.cpp:244]     Train net output #0: loss = 0.0528388 (* 1 = 0.0528388 loss)
I0811 14:59:51.865658  8383 sgd_solver.cpp:106] Iteration 44200, lr = 0.000416986
I0811 14:59:55.140038  8383 solver.cpp:228] Iteration 44300, loss = 0.0736875
I0811 14:59:55.140077  8383 solver.cpp:244]     Train net output #0: loss = 0.0736875 (* 1 = 0.0736875 loss)
I0811 14:59:55.140084  8383 sgd_solver.cpp:106] Iteration 44300, lr = 0.000416499
I0811 14:59:58.418728  8383 solver.cpp:228] Iteration 44400, loss = 0.135725
I0811 14:59:58.418763  8383 solver.cpp:244]     Train net output #0: loss = 0.135725 (* 1 = 0.135725 loss)
I0811 14:59:58.418769  8383 sgd_solver.cpp:106] Iteration 44400, lr = 0.000416014
I0811 15:00:01.661315  8383 solver.cpp:337] Iteration 44500, Testing net (#0)
I0811 15:00:08.190742  8383 solver.cpp:404]     Test net output #0: accuracy = 0.932129
I0811 15:00:08.190801  8383 solver.cpp:404]     Test net output #1: loss = 0.221968 (* 1 = 0.221968 loss)
I0811 15:00:08.201702  8383 solver.cpp:228] Iteration 44500, loss = 0.135682
I0811 15:00:08.201767  8383 solver.cpp:244]     Train net output #0: loss = 0.135682 (* 1 = 0.135682 loss)
I0811 15:00:08.201789  8383 sgd_solver.cpp:106] Iteration 44500, lr = 0.00041553
I0811 15:00:11.442934  8383 solver.cpp:228] Iteration 44600, loss = 0.0595378
I0811 15:00:11.442972  8383 solver.cpp:244]     Train net output #0: loss = 0.0595378 (* 1 = 0.0595378 loss)
I0811 15:00:11.442980  8383 sgd_solver.cpp:106] Iteration 44600, lr = 0.000415048
I0811 15:00:14.682165  8383 solver.cpp:228] Iteration 44700, loss = 0.284754
I0811 15:00:14.682205  8383 solver.cpp:244]     Train net output #0: loss = 0.284754 (* 1 = 0.284754 loss)
I0811 15:00:14.682211  8383 sgd_solver.cpp:106] Iteration 44700, lr = 0.000414567
I0811 15:00:17.965911  8383 solver.cpp:228] Iteration 44800, loss = 0.125757
I0811 15:00:17.965961  8383 solver.cpp:244]     Train net output #0: loss = 0.125757 (* 1 = 0.125757 loss)
I0811 15:00:17.965970  8383 sgd_solver.cpp:106] Iteration 44800, lr = 0.000414087
I0811 15:00:21.238955  8383 solver.cpp:228] Iteration 44900, loss = 0.179221
I0811 15:00:21.238998  8383 solver.cpp:244]     Train net output #0: loss = 0.179221 (* 1 = 0.179221 loss)
I0811 15:00:21.239006  8383 sgd_solver.cpp:106] Iteration 44900, lr = 0.000413608
I0811 15:00:24.474016  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_45000.caffemodel
I0811 15:00:24.863363  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_45000.solverstate
I0811 15:00:25.005802  8383 solver.cpp:337] Iteration 45000, Testing net (#0)
I0811 15:00:26.845962  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:00:31.648133  8383 solver.cpp:404]     Test net output #0: accuracy = 0.919129
I0811 15:00:31.648238  8383 solver.cpp:404]     Test net output #1: loss = 0.239626 (* 1 = 0.239626 loss)
I0811 15:00:31.660681  8383 solver.cpp:228] Iteration 45000, loss = 0.0899128
I0811 15:00:31.660712  8383 solver.cpp:244]     Train net output #0: loss = 0.0899128 (* 1 = 0.0899128 loss)
I0811 15:00:31.660723  8383 sgd_solver.cpp:106] Iteration 45000, lr = 0.000413131
I0811 15:00:34.897629  8383 solver.cpp:228] Iteration 45100, loss = 0.110221
I0811 15:00:34.897663  8383 solver.cpp:244]     Train net output #0: loss = 0.110221 (* 1 = 0.110221 loss)
I0811 15:00:34.897670  8383 sgd_solver.cpp:106] Iteration 45100, lr = 0.000412655
I0811 15:00:38.141928  8383 solver.cpp:228] Iteration 45200, loss = 0.122323
I0811 15:00:38.141969  8383 solver.cpp:244]     Train net output #0: loss = 0.122323 (* 1 = 0.122323 loss)
I0811 15:00:38.141976  8383 sgd_solver.cpp:106] Iteration 45200, lr = 0.00041218
I0811 15:00:41.469290  8383 solver.cpp:228] Iteration 45300, loss = 0.121672
I0811 15:00:41.469332  8383 solver.cpp:244]     Train net output #0: loss = 0.121672 (* 1 = 0.121672 loss)
I0811 15:00:41.469338  8383 sgd_solver.cpp:106] Iteration 45300, lr = 0.000411706
I0811 15:00:44.724198  8383 solver.cpp:228] Iteration 45400, loss = 0.0331778
I0811 15:00:44.724247  8383 solver.cpp:244]     Train net output #0: loss = 0.0331778 (* 1 = 0.0331778 loss)
I0811 15:00:44.724254  8383 sgd_solver.cpp:106] Iteration 45400, lr = 0.000411234
I0811 15:00:47.951501  8383 solver.cpp:337] Iteration 45500, Testing net (#0)
I0811 15:00:54.391547  8383 solver.cpp:404]     Test net output #0: accuracy = 0.891839
I0811 15:00:54.391613  8383 solver.cpp:404]     Test net output #1: loss = 0.334943 (* 1 = 0.334943 loss)
I0811 15:00:54.404994  8383 solver.cpp:228] Iteration 45500, loss = 0.0469578
I0811 15:00:54.405030  8383 solver.cpp:244]     Train net output #0: loss = 0.0469578 (* 1 = 0.0469578 loss)
I0811 15:00:54.405047  8383 sgd_solver.cpp:106] Iteration 45500, lr = 0.000410763
I0811 15:00:57.626021  8383 solver.cpp:228] Iteration 45600, loss = 0.0198077
I0811 15:00:57.626058  8383 solver.cpp:244]     Train net output #0: loss = 0.0198077 (* 1 = 0.0198077 loss)
I0811 15:00:57.626065  8383 sgd_solver.cpp:106] Iteration 45600, lr = 0.000410293
I0811 15:01:00.909381  8383 solver.cpp:228] Iteration 45700, loss = 0.0149747
I0811 15:01:00.909435  8383 solver.cpp:244]     Train net output #0: loss = 0.0149747 (* 1 = 0.0149747 loss)
I0811 15:01:00.909441  8383 sgd_solver.cpp:106] Iteration 45700, lr = 0.000409825
I0811 15:01:04.161887  8383 solver.cpp:228] Iteration 45800, loss = 0.0211044
I0811 15:01:04.161931  8383 solver.cpp:244]     Train net output #0: loss = 0.0211044 (* 1 = 0.0211044 loss)
I0811 15:01:04.161937  8383 sgd_solver.cpp:106] Iteration 45800, lr = 0.000409358
I0811 15:01:07.448189  8383 solver.cpp:228] Iteration 45900, loss = 0.0178538
I0811 15:01:07.448230  8383 solver.cpp:244]     Train net output #0: loss = 0.0178538 (* 1 = 0.0178538 loss)
I0811 15:01:07.448235  8383 sgd_solver.cpp:106] Iteration 45900, lr = 0.000408892
I0811 15:01:10.696023  8383 solver.cpp:337] Iteration 46000, Testing net (#0)
I0811 15:01:17.356135  8383 solver.cpp:404]     Test net output #0: accuracy = 0.876484
I0811 15:01:17.356196  8383 solver.cpp:404]     Test net output #1: loss = 0.451113 (* 1 = 0.451113 loss)
I0811 15:01:17.369014  8383 solver.cpp:228] Iteration 46000, loss = 0.0231858
I0811 15:01:17.369047  8383 solver.cpp:244]     Train net output #0: loss = 0.0231858 (* 1 = 0.0231858 loss)
I0811 15:01:17.369060  8383 sgd_solver.cpp:106] Iteration 46000, lr = 0.000408427
I0811 15:01:20.609334  8383 solver.cpp:228] Iteration 46100, loss = 0.0321835
I0811 15:01:20.609375  8383 solver.cpp:244]     Train net output #0: loss = 0.0321835 (* 1 = 0.0321835 loss)
I0811 15:01:20.609381  8383 sgd_solver.cpp:106] Iteration 46100, lr = 0.000407964
I0811 15:01:23.849912  8383 solver.cpp:228] Iteration 46200, loss = 0.023026
I0811 15:01:23.849951  8383 solver.cpp:244]     Train net output #0: loss = 0.023026 (* 1 = 0.023026 loss)
I0811 15:01:23.849957  8383 sgd_solver.cpp:106] Iteration 46200, lr = 0.000407501
I0811 15:01:27.109159  8383 solver.cpp:228] Iteration 46300, loss = 0.118419
I0811 15:01:27.109207  8383 solver.cpp:244]     Train net output #0: loss = 0.118419 (* 1 = 0.118419 loss)
I0811 15:01:27.109216  8383 sgd_solver.cpp:106] Iteration 46300, lr = 0.00040704
I0811 15:01:30.374779  8383 solver.cpp:228] Iteration 46400, loss = 0.0981291
I0811 15:01:30.374819  8383 solver.cpp:244]     Train net output #0: loss = 0.0981291 (* 1 = 0.0981291 loss)
I0811 15:01:30.374825  8383 sgd_solver.cpp:106] Iteration 46400, lr = 0.00040658
I0811 15:01:33.585002  8383 solver.cpp:337] Iteration 46500, Testing net (#0)
I0811 15:01:34.407740  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:01:39.997262  8383 solver.cpp:404]     Test net output #0: accuracy = 0.932968
I0811 15:01:39.997339  8383 solver.cpp:404]     Test net output #1: loss = 0.25891 (* 1 = 0.25891 loss)
I0811 15:01:40.009963  8383 solver.cpp:228] Iteration 46500, loss = 0.0442216
I0811 15:01:40.010005  8383 solver.cpp:244]     Train net output #0: loss = 0.0442216 (* 1 = 0.0442216 loss)
I0811 15:01:40.010023  8383 sgd_solver.cpp:106] Iteration 46500, lr = 0.000406122
I0811 15:01:43.241720  8383 solver.cpp:228] Iteration 46600, loss = 0.029997
I0811 15:01:43.241761  8383 solver.cpp:244]     Train net output #0: loss = 0.029997 (* 1 = 0.029997 loss)
I0811 15:01:43.241767  8383 sgd_solver.cpp:106] Iteration 46600, lr = 0.000405664
I0811 15:01:46.501103  8383 solver.cpp:228] Iteration 46700, loss = 0.00774325
I0811 15:01:46.501142  8383 solver.cpp:244]     Train net output #0: loss = 0.00774325 (* 1 = 0.00774325 loss)
I0811 15:01:46.501149  8383 sgd_solver.cpp:106] Iteration 46700, lr = 0.000405208
I0811 15:01:49.754475  8383 solver.cpp:228] Iteration 46800, loss = 0.0148875
I0811 15:01:49.754513  8383 solver.cpp:244]     Train net output #0: loss = 0.0148875 (* 1 = 0.0148875 loss)
I0811 15:01:49.754519  8383 sgd_solver.cpp:106] Iteration 46800, lr = 0.000404753
I0811 15:01:52.999995  8383 solver.cpp:228] Iteration 46900, loss = 0.0322757
I0811 15:01:53.000036  8383 solver.cpp:244]     Train net output #0: loss = 0.0322757 (* 1 = 0.0322757 loss)
I0811 15:01:53.000041  8383 sgd_solver.cpp:106] Iteration 46900, lr = 0.000404299
I0811 15:01:56.262584  8383 solver.cpp:337] Iteration 47000, Testing net (#0)
I0811 15:02:02.900868  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898774
I0811 15:02:02.900949  8383 solver.cpp:404]     Test net output #1: loss = 0.418354 (* 1 = 0.418354 loss)
I0811 15:02:02.913671  8383 solver.cpp:228] Iteration 47000, loss = 0.0354006
I0811 15:02:02.913705  8383 solver.cpp:244]     Train net output #0: loss = 0.0354006 (* 1 = 0.0354006 loss)
I0811 15:02:02.913723  8383 sgd_solver.cpp:106] Iteration 47000, lr = 0.000403847
I0811 15:02:06.099349  8383 solver.cpp:228] Iteration 47100, loss = 0.00912712
I0811 15:02:06.099390  8383 solver.cpp:244]     Train net output #0: loss = 0.00912712 (* 1 = 0.00912712 loss)
I0811 15:02:06.099397  8383 sgd_solver.cpp:106] Iteration 47100, lr = 0.000403395
I0811 15:02:09.370261  8383 solver.cpp:228] Iteration 47200, loss = 0.0522252
I0811 15:02:09.370304  8383 solver.cpp:244]     Train net output #0: loss = 0.0522252 (* 1 = 0.0522252 loss)
I0811 15:02:09.370311  8383 sgd_solver.cpp:106] Iteration 47200, lr = 0.000402945
I0811 15:02:12.668738  8383 solver.cpp:228] Iteration 47300, loss = 0.018652
I0811 15:02:12.668773  8383 solver.cpp:244]     Train net output #0: loss = 0.018652 (* 1 = 0.018652 loss)
I0811 15:02:12.668779  8383 sgd_solver.cpp:106] Iteration 47300, lr = 0.000402496
I0811 15:02:15.960044  8383 solver.cpp:228] Iteration 47400, loss = 0.0190203
I0811 15:02:15.960094  8383 solver.cpp:244]     Train net output #0: loss = 0.0190203 (* 1 = 0.0190203 loss)
I0811 15:02:15.960100  8383 sgd_solver.cpp:106] Iteration 47400, lr = 0.000402048
I0811 15:02:19.199857  8383 solver.cpp:337] Iteration 47500, Testing net (#0)
I0811 15:02:25.610975  8383 solver.cpp:404]     Test net output #0: accuracy = 0.867419
I0811 15:02:25.611040  8383 solver.cpp:404]     Test net output #1: loss = 0.559944 (* 1 = 0.559944 loss)
I0811 15:02:25.621845  8383 solver.cpp:228] Iteration 47500, loss = 0.00423296
I0811 15:02:25.621914  8383 solver.cpp:244]     Train net output #0: loss = 0.00423296 (* 1 = 0.00423296 loss)
I0811 15:02:25.621937  8383 sgd_solver.cpp:106] Iteration 47500, lr = 0.000401601
I0811 15:02:28.862792  8383 solver.cpp:228] Iteration 47600, loss = 0.0177492
I0811 15:02:28.862834  8383 solver.cpp:244]     Train net output #0: loss = 0.0177492 (* 1 = 0.0177492 loss)
I0811 15:02:28.862840  8383 sgd_solver.cpp:106] Iteration 47600, lr = 0.000401155
I0811 15:02:32.121608  8383 solver.cpp:228] Iteration 47700, loss = 0.0146313
I0811 15:02:32.121651  8383 solver.cpp:244]     Train net output #0: loss = 0.0146313 (* 1 = 0.0146313 loss)
I0811 15:02:32.121657  8383 sgd_solver.cpp:106] Iteration 47700, lr = 0.000400711
I0811 15:02:35.383026  8383 solver.cpp:228] Iteration 47800, loss = 0.00308207
I0811 15:02:35.383070  8383 solver.cpp:244]     Train net output #0: loss = 0.00308207 (* 1 = 0.00308207 loss)
I0811 15:02:35.383076  8383 sgd_solver.cpp:106] Iteration 47800, lr = 0.000400267
I0811 15:02:38.655113  8383 solver.cpp:228] Iteration 47900, loss = 0.0114782
I0811 15:02:38.655148  8383 solver.cpp:244]     Train net output #0: loss = 0.0114782 (* 1 = 0.0114782 loss)
I0811 15:02:38.655154  8383 sgd_solver.cpp:106] Iteration 47900, lr = 0.000399825
I0811 15:02:41.891299  8383 solver.cpp:337] Iteration 48000, Testing net (#0)
I0811 15:02:42.896078  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:02:48.677726  8383 solver.cpp:404]     Test net output #0: accuracy = 0.930516
I0811 15:02:48.677795  8383 solver.cpp:404]     Test net output #1: loss = 0.290331 (* 1 = 0.290331 loss)
I0811 15:02:48.688026  8383 solver.cpp:228] Iteration 48000, loss = 0.00400473
I0811 15:02:48.688078  8383 solver.cpp:244]     Train net output #0: loss = 0.00400473 (* 1 = 0.00400473 loss)
I0811 15:02:48.688092  8383 sgd_solver.cpp:106] Iteration 48000, lr = 0.000399384
I0811 15:02:51.905081  8383 solver.cpp:228] Iteration 48100, loss = 0.106356
I0811 15:02:51.905122  8383 solver.cpp:244]     Train net output #0: loss = 0.106356 (* 1 = 0.106356 loss)
I0811 15:02:51.905128  8383 sgd_solver.cpp:106] Iteration 48100, lr = 0.000398944
I0811 15:02:55.199899  8383 solver.cpp:228] Iteration 48200, loss = 0.00329383
I0811 15:02:55.199955  8383 solver.cpp:244]     Train net output #0: loss = 0.00329383 (* 1 = 0.00329383 loss)
I0811 15:02:55.199965  8383 sgd_solver.cpp:106] Iteration 48200, lr = 0.000398505
I0811 15:02:58.481549  8383 solver.cpp:228] Iteration 48300, loss = 0.0439778
I0811 15:02:58.481602  8383 solver.cpp:244]     Train net output #0: loss = 0.0439778 (* 1 = 0.0439778 loss)
I0811 15:02:58.481611  8383 sgd_solver.cpp:106] Iteration 48300, lr = 0.000398068
I0811 15:03:01.746657  8383 solver.cpp:228] Iteration 48400, loss = 0.0119625
I0811 15:03:01.746680  8383 solver.cpp:244]     Train net output #0: loss = 0.0119625 (* 1 = 0.0119625 loss)
I0811 15:03:01.746685  8383 sgd_solver.cpp:106] Iteration 48400, lr = 0.000397631
I0811 15:03:04.988819  8383 solver.cpp:337] Iteration 48500, Testing net (#0)
I0811 15:03:11.643687  8383 solver.cpp:404]     Test net output #0: accuracy = 0.919225
I0811 15:03:11.643760  8383 solver.cpp:404]     Test net output #1: loss = 0.323801 (* 1 = 0.323801 loss)
I0811 15:03:11.656415  8383 solver.cpp:228] Iteration 48500, loss = 0.0453639
I0811 15:03:11.656446  8383 solver.cpp:244]     Train net output #0: loss = 0.0453639 (* 1 = 0.0453639 loss)
I0811 15:03:11.656458  8383 sgd_solver.cpp:106] Iteration 48500, lr = 0.000397196
I0811 15:03:14.924034  8383 solver.cpp:228] Iteration 48600, loss = 0.036421
I0811 15:03:14.924074  8383 solver.cpp:244]     Train net output #0: loss = 0.036421 (* 1 = 0.036421 loss)
I0811 15:03:14.924080  8383 sgd_solver.cpp:106] Iteration 48600, lr = 0.000396761
I0811 15:03:18.204993  8383 solver.cpp:228] Iteration 48700, loss = 0.0099809
I0811 15:03:18.205039  8383 solver.cpp:244]     Train net output #0: loss = 0.0099809 (* 1 = 0.0099809 loss)
I0811 15:03:18.205045  8383 sgd_solver.cpp:106] Iteration 48700, lr = 0.000396328
I0811 15:03:21.462515  8383 solver.cpp:228] Iteration 48800, loss = 0.0822261
I0811 15:03:21.462551  8383 solver.cpp:244]     Train net output #0: loss = 0.0822261 (* 1 = 0.0822261 loss)
I0811 15:03:21.462558  8383 sgd_solver.cpp:106] Iteration 48800, lr = 0.000395896
I0811 15:03:24.750017  8383 solver.cpp:228] Iteration 48900, loss = 0.0128311
I0811 15:03:24.750062  8383 solver.cpp:244]     Train net output #0: loss = 0.0128311 (* 1 = 0.0128311 loss)
I0811 15:03:24.750068  8383 sgd_solver.cpp:106] Iteration 48900, lr = 0.000395465
I0811 15:03:27.977340  8383 solver.cpp:337] Iteration 49000, Testing net (#0)
I0811 15:03:34.472892  8383 solver.cpp:404]     Test net output #0: accuracy = 0.934613
I0811 15:03:34.472970  8383 solver.cpp:404]     Test net output #1: loss = 0.265851 (* 1 = 0.265851 loss)
I0811 15:03:34.483319  8383 solver.cpp:228] Iteration 49000, loss = 0.137629
I0811 15:03:34.483363  8383 solver.cpp:244]     Train net output #0: loss = 0.137629 (* 1 = 0.137629 loss)
I0811 15:03:34.483376  8383 sgd_solver.cpp:106] Iteration 49000, lr = 0.000395035
I0811 15:03:37.693827  8383 solver.cpp:228] Iteration 49100, loss = 0.0727492
I0811 15:03:37.693867  8383 solver.cpp:244]     Train net output #0: loss = 0.0727492 (* 1 = 0.0727492 loss)
I0811 15:03:37.693874  8383 sgd_solver.cpp:106] Iteration 49100, lr = 0.000394606
I0811 15:03:40.968176  8383 solver.cpp:228] Iteration 49200, loss = 0.0474649
I0811 15:03:40.968215  8383 solver.cpp:244]     Train net output #0: loss = 0.0474649 (* 1 = 0.0474649 loss)
I0811 15:03:40.968221  8383 sgd_solver.cpp:106] Iteration 49200, lr = 0.000394178
I0811 15:03:44.232834  8383 solver.cpp:228] Iteration 49300, loss = 0.0134137
I0811 15:03:44.232874  8383 solver.cpp:244]     Train net output #0: loss = 0.0134137 (* 1 = 0.0134137 loss)
I0811 15:03:44.232882  8383 sgd_solver.cpp:106] Iteration 49300, lr = 0.000393752
I0811 15:03:44.590713  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:03:47.476929  8383 solver.cpp:228] Iteration 49400, loss = 0.0328596
I0811 15:03:47.476969  8383 solver.cpp:244]     Train net output #0: loss = 0.0328596 (* 1 = 0.0328596 loss)
I0811 15:03:47.476974  8383 sgd_solver.cpp:106] Iteration 49400, lr = 0.000393326
I0811 15:03:50.710079  8383 solver.cpp:337] Iteration 49500, Testing net (#0)
I0811 15:03:57.455752  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896193
I0811 15:03:57.455816  8383 solver.cpp:404]     Test net output #1: loss = 0.394003 (* 1 = 0.394003 loss)
I0811 15:03:57.466742  8383 solver.cpp:228] Iteration 49500, loss = 0.00663849
I0811 15:03:57.466802  8383 solver.cpp:244]     Train net output #0: loss = 0.00663849 (* 1 = 0.00663849 loss)
I0811 15:03:57.466825  8383 sgd_solver.cpp:106] Iteration 49500, lr = 0.000392902
I0811 15:04:00.742377  8383 solver.cpp:228] Iteration 49600, loss = 0.031246
I0811 15:04:00.742415  8383 solver.cpp:244]     Train net output #0: loss = 0.031246 (* 1 = 0.031246 loss)
I0811 15:04:00.742421  8383 sgd_solver.cpp:106] Iteration 49600, lr = 0.000392478
I0811 15:04:04.023787  8383 solver.cpp:228] Iteration 49700, loss = 0.0367642
I0811 15:04:04.023849  8383 solver.cpp:244]     Train net output #0: loss = 0.0367642 (* 1 = 0.0367642 loss)
I0811 15:04:04.023855  8383 sgd_solver.cpp:106] Iteration 49700, lr = 0.000392056
I0811 15:04:07.303962  8383 solver.cpp:228] Iteration 49800, loss = 0.0666261
I0811 15:04:07.303997  8383 solver.cpp:244]     Train net output #0: loss = 0.0666261 (* 1 = 0.0666261 loss)
I0811 15:04:07.304003  8383 sgd_solver.cpp:106] Iteration 49800, lr = 0.000391635
I0811 15:04:10.576750  8383 solver.cpp:228] Iteration 49900, loss = 0.0306839
I0811 15:04:10.576788  8383 solver.cpp:244]     Train net output #0: loss = 0.0306839 (* 1 = 0.0306839 loss)
I0811 15:04:10.576794  8383 sgd_solver.cpp:106] Iteration 49900, lr = 0.000391214
I0811 15:04:13.836498  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_50000.caffemodel
I0811 15:04:14.205736  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_50000.solverstate
I0811 15:04:14.340023  8383 solver.cpp:337] Iteration 50000, Testing net (#0)
I0811 15:04:20.767171  8383 solver.cpp:404]     Test net output #0: accuracy = 0.84571
I0811 15:04:20.767216  8383 solver.cpp:404]     Test net output #1: loss = 0.624996 (* 1 = 0.624996 loss)
I0811 15:04:20.779510  8383 solver.cpp:228] Iteration 50000, loss = 0.0489884
I0811 15:04:20.779539  8383 solver.cpp:244]     Train net output #0: loss = 0.0489884 (* 1 = 0.0489884 loss)
I0811 15:04:20.779551  8383 sgd_solver.cpp:106] Iteration 50000, lr = 0.000390795
I0811 15:04:24.012951  8383 solver.cpp:228] Iteration 50100, loss = 0.0221102
I0811 15:04:24.012990  8383 solver.cpp:244]     Train net output #0: loss = 0.0221102 (* 1 = 0.0221102 loss)
I0811 15:04:24.012996  8383 sgd_solver.cpp:106] Iteration 50100, lr = 0.000390377
I0811 15:04:27.262990  8383 solver.cpp:228] Iteration 50200, loss = 0.0274798
I0811 15:04:27.263030  8383 solver.cpp:244]     Train net output #0: loss = 0.0274798 (* 1 = 0.0274798 loss)
I0811 15:04:27.263036  8383 sgd_solver.cpp:106] Iteration 50200, lr = 0.00038996
I0811 15:04:30.532362  8383 solver.cpp:228] Iteration 50300, loss = 0.112734
I0811 15:04:30.532414  8383 solver.cpp:244]     Train net output #0: loss = 0.112734 (* 1 = 0.112734 loss)
I0811 15:04:30.532421  8383 sgd_solver.cpp:106] Iteration 50300, lr = 0.000389544
I0811 15:04:33.796608  8383 solver.cpp:228] Iteration 50400, loss = 0.0116553
I0811 15:04:33.796648  8383 solver.cpp:244]     Train net output #0: loss = 0.0116553 (* 1 = 0.0116553 loss)
I0811 15:04:33.796654  8383 sgd_solver.cpp:106] Iteration 50400, lr = 0.000389128
I0811 15:04:37.049540  8383 solver.cpp:337] Iteration 50500, Testing net (#0)
I0811 15:04:42.091069  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:04:43.923969  8383 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0811 15:04:43.924020  8383 solver.cpp:404]     Test net output #1: loss = 0.491948 (* 1 = 0.491948 loss)
I0811 15:04:43.936980  8383 solver.cpp:228] Iteration 50500, loss = 0.0847862
I0811 15:04:43.937011  8383 solver.cpp:244]     Train net output #0: loss = 0.0847862 (* 1 = 0.0847862 loss)
I0811 15:04:43.937022  8383 sgd_solver.cpp:106] Iteration 50500, lr = 0.000388714
I0811 15:04:47.188834  8383 solver.cpp:228] Iteration 50600, loss = 0.0220975
I0811 15:04:47.188873  8383 solver.cpp:244]     Train net output #0: loss = 0.0220975 (* 1 = 0.0220975 loss)
I0811 15:04:47.188879  8383 sgd_solver.cpp:106] Iteration 50600, lr = 0.000388301
I0811 15:04:50.496147  8383 solver.cpp:228] Iteration 50700, loss = 0.00426177
I0811 15:04:50.496201  8383 solver.cpp:244]     Train net output #0: loss = 0.00426177 (* 1 = 0.00426177 loss)
I0811 15:04:50.496212  8383 sgd_solver.cpp:106] Iteration 50700, lr = 0.000387889
I0811 15:04:53.743978  8383 solver.cpp:228] Iteration 50800, loss = 0.102266
I0811 15:04:53.744040  8383 solver.cpp:244]     Train net output #0: loss = 0.102266 (* 1 = 0.102266 loss)
I0811 15:04:53.744048  8383 sgd_solver.cpp:106] Iteration 50800, lr = 0.000387478
I0811 15:04:57.029945  8383 solver.cpp:228] Iteration 50900, loss = 0.00418218
I0811 15:04:57.029989  8383 solver.cpp:244]     Train net output #0: loss = 0.00418218 (* 1 = 0.00418218 loss)
I0811 15:04:57.029995  8383 sgd_solver.cpp:106] Iteration 50900, lr = 0.000387069
I0811 15:05:00.252007  8383 solver.cpp:337] Iteration 51000, Testing net (#0)
I0811 15:05:06.750249  8383 solver.cpp:404]     Test net output #0: accuracy = 0.872033
I0811 15:05:06.750309  8383 solver.cpp:404]     Test net output #1: loss = 0.522058 (* 1 = 0.522058 loss)
I0811 15:05:06.760421  8383 solver.cpp:228] Iteration 51000, loss = 0.0981093
I0811 15:05:06.760450  8383 solver.cpp:244]     Train net output #0: loss = 0.0981093 (* 1 = 0.0981093 loss)
I0811 15:05:06.760462  8383 sgd_solver.cpp:106] Iteration 51000, lr = 0.00038666
I0811 15:05:10.001646  8383 solver.cpp:228] Iteration 51100, loss = 0.0155581
I0811 15:05:10.001691  8383 solver.cpp:244]     Train net output #0: loss = 0.0155581 (* 1 = 0.0155581 loss)
I0811 15:05:10.001698  8383 sgd_solver.cpp:106] Iteration 51100, lr = 0.000386252
I0811 15:05:13.227690  8383 solver.cpp:228] Iteration 51200, loss = 0.0157983
I0811 15:05:13.227730  8383 solver.cpp:244]     Train net output #0: loss = 0.0157983 (* 1 = 0.0157983 loss)
I0811 15:05:13.227737  8383 sgd_solver.cpp:106] Iteration 51200, lr = 0.000385845
I0811 15:05:16.537194  8383 solver.cpp:228] Iteration 51300, loss = 0.00762913
I0811 15:05:16.537235  8383 solver.cpp:244]     Train net output #0: loss = 0.00762913 (* 1 = 0.00762913 loss)
I0811 15:05:16.537241  8383 sgd_solver.cpp:106] Iteration 51300, lr = 0.000385439
I0811 15:05:19.792839  8383 solver.cpp:228] Iteration 51400, loss = 0.0120386
I0811 15:05:19.792870  8383 solver.cpp:244]     Train net output #0: loss = 0.0120386 (* 1 = 0.0120386 loss)
I0811 15:05:19.792876  8383 sgd_solver.cpp:106] Iteration 51400, lr = 0.000385034
I0811 15:05:23.033236  8383 solver.cpp:337] Iteration 51500, Testing net (#0)
I0811 15:05:29.396833  8383 solver.cpp:404]     Test net output #0: accuracy = 0.920419
I0811 15:05:29.396894  8383 solver.cpp:404]     Test net output #1: loss = 0.339982 (* 1 = 0.339982 loss)
I0811 15:05:29.416450  8383 solver.cpp:228] Iteration 51500, loss = 0.0212832
I0811 15:05:29.416517  8383 solver.cpp:244]     Train net output #0: loss = 0.0212832 (* 1 = 0.0212832 loss)
I0811 15:05:29.416549  8383 sgd_solver.cpp:106] Iteration 51500, lr = 0.00038463
I0811 15:05:32.658326  8383 solver.cpp:228] Iteration 51600, loss = 0.00437544
I0811 15:05:32.658372  8383 solver.cpp:244]     Train net output #0: loss = 0.00437544 (* 1 = 0.00437544 loss)
I0811 15:05:32.658381  8383 sgd_solver.cpp:106] Iteration 51600, lr = 0.000384227
I0811 15:05:35.910792  8383 solver.cpp:228] Iteration 51700, loss = 0.00486484
I0811 15:05:35.910847  8383 solver.cpp:244]     Train net output #0: loss = 0.00486484 (* 1 = 0.00486484 loss)
I0811 15:05:35.910854  8383 sgd_solver.cpp:106] Iteration 51700, lr = 0.000383825
I0811 15:05:39.138756  8383 solver.cpp:228] Iteration 51800, loss = 0.00415011
I0811 15:05:39.138808  8383 solver.cpp:244]     Train net output #0: loss = 0.00415011 (* 1 = 0.00415011 loss)
I0811 15:05:39.138813  8383 sgd_solver.cpp:106] Iteration 51800, lr = 0.000383424
I0811 15:05:42.404458  8383 solver.cpp:228] Iteration 51900, loss = 0.0554545
I0811 15:05:42.404525  8383 solver.cpp:244]     Train net output #0: loss = 0.0554545 (* 1 = 0.0554545 loss)
I0811 15:05:42.404531  8383 sgd_solver.cpp:106] Iteration 51900, lr = 0.000383024
I0811 15:05:45.652386  8383 solver.cpp:337] Iteration 52000, Testing net (#0)
I0811 15:05:49.814949  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:05:52.133703  8383 solver.cpp:404]     Test net output #0: accuracy = 0.925452
I0811 15:05:52.133749  8383 solver.cpp:404]     Test net output #1: loss = 0.339555 (* 1 = 0.339555 loss)
I0811 15:05:52.147428  8383 solver.cpp:228] Iteration 52000, loss = 0.0088034
I0811 15:05:52.147460  8383 solver.cpp:244]     Train net output #0: loss = 0.0088034 (* 1 = 0.0088034 loss)
I0811 15:05:52.147472  8383 sgd_solver.cpp:106] Iteration 52000, lr = 0.000382625
I0811 15:05:55.364090  8383 solver.cpp:228] Iteration 52100, loss = 0.00267836
I0811 15:05:55.364126  8383 solver.cpp:244]     Train net output #0: loss = 0.00267836 (* 1 = 0.00267836 loss)
I0811 15:05:55.364132  8383 sgd_solver.cpp:106] Iteration 52100, lr = 0.000382227
I0811 15:05:58.627796  8383 solver.cpp:228] Iteration 52200, loss = 0.172624
I0811 15:05:58.627835  8383 solver.cpp:244]     Train net output #0: loss = 0.172624 (* 1 = 0.172624 loss)
I0811 15:05:58.627842  8383 sgd_solver.cpp:106] Iteration 52200, lr = 0.00038183
I0811 15:06:01.888955  8383 solver.cpp:228] Iteration 52300, loss = 0.0353955
I0811 15:06:01.889011  8383 solver.cpp:244]     Train net output #0: loss = 0.0353955 (* 1 = 0.0353955 loss)
I0811 15:06:01.889020  8383 sgd_solver.cpp:106] Iteration 52300, lr = 0.000381433
I0811 15:06:05.151043  8383 solver.cpp:228] Iteration 52400, loss = 0.0170425
I0811 15:06:05.151063  8383 solver.cpp:244]     Train net output #0: loss = 0.0170425 (* 1 = 0.0170425 loss)
I0811 15:06:05.151069  8383 sgd_solver.cpp:106] Iteration 52400, lr = 0.000381038
I0811 15:06:08.404659  8383 solver.cpp:337] Iteration 52500, Testing net (#0)
I0811 15:06:15.141269  8383 solver.cpp:404]     Test net output #0: accuracy = 0.928291
I0811 15:06:15.141351  8383 solver.cpp:404]     Test net output #1: loss = 0.337655 (* 1 = 0.337655 loss)
I0811 15:06:15.151564  8383 solver.cpp:228] Iteration 52500, loss = 0.0410535
I0811 15:06:15.151598  8383 solver.cpp:244]     Train net output #0: loss = 0.0410535 (* 1 = 0.0410535 loss)
I0811 15:06:15.151621  8383 sgd_solver.cpp:106] Iteration 52500, lr = 0.000380644
I0811 15:06:18.376940  8383 solver.cpp:228] Iteration 52600, loss = 0.00172001
I0811 15:06:18.376979  8383 solver.cpp:244]     Train net output #0: loss = 0.00172001 (* 1 = 0.00172001 loss)
I0811 15:06:18.376986  8383 sgd_solver.cpp:106] Iteration 52600, lr = 0.000380251
I0811 15:06:21.648780  8383 solver.cpp:228] Iteration 52700, loss = 0.00424211
I0811 15:06:21.648820  8383 solver.cpp:244]     Train net output #0: loss = 0.00424211 (* 1 = 0.00424211 loss)
I0811 15:06:21.648828  8383 sgd_solver.cpp:106] Iteration 52700, lr = 0.000379858
I0811 15:06:24.903892  8383 solver.cpp:228] Iteration 52800, loss = 0.000759156
I0811 15:06:24.903939  8383 solver.cpp:244]     Train net output #0: loss = 0.000759156 (* 1 = 0.000759156 loss)
I0811 15:06:24.903949  8383 sgd_solver.cpp:106] Iteration 52800, lr = 0.000379467
I0811 15:06:28.168006  8383 solver.cpp:228] Iteration 52900, loss = 0.00272408
I0811 15:06:28.168050  8383 solver.cpp:244]     Train net output #0: loss = 0.00272408 (* 1 = 0.00272408 loss)
I0811 15:06:28.168058  8383 sgd_solver.cpp:106] Iteration 52900, lr = 0.000379077
I0811 15:06:31.381479  8383 solver.cpp:337] Iteration 53000, Testing net (#0)
I0811 15:06:38.035413  8383 solver.cpp:404]     Test net output #0: accuracy = 0.787258
I0811 15:06:38.035472  8383 solver.cpp:404]     Test net output #1: loss = 1.12585 (* 1 = 1.12585 loss)
I0811 15:06:38.045640  8383 solver.cpp:228] Iteration 53000, loss = 0.0274061
I0811 15:06:38.045665  8383 solver.cpp:244]     Train net output #0: loss = 0.0274061 (* 1 = 0.0274061 loss)
I0811 15:06:38.045678  8383 sgd_solver.cpp:106] Iteration 53000, lr = 0.000378687
I0811 15:06:41.259428  8383 solver.cpp:228] Iteration 53100, loss = 0.0597015
I0811 15:06:41.259465  8383 solver.cpp:244]     Train net output #0: loss = 0.0597015 (* 1 = 0.0597015 loss)
I0811 15:06:41.259471  8383 sgd_solver.cpp:106] Iteration 53100, lr = 0.000378298
I0811 15:06:44.540113  8383 solver.cpp:228] Iteration 53200, loss = 0.00734718
I0811 15:06:44.540155  8383 solver.cpp:244]     Train net output #0: loss = 0.00734718 (* 1 = 0.00734718 loss)
I0811 15:06:44.540161  8383 sgd_solver.cpp:106] Iteration 53200, lr = 0.000377911
I0811 15:06:47.830736  8383 solver.cpp:228] Iteration 53300, loss = 0.00180837
I0811 15:06:47.830788  8383 solver.cpp:244]     Train net output #0: loss = 0.00180837 (* 1 = 0.00180837 loss)
I0811 15:06:47.830795  8383 sgd_solver.cpp:106] Iteration 53300, lr = 0.000377524
I0811 15:06:51.101655  8383 solver.cpp:228] Iteration 53400, loss = 0.0365674
I0811 15:06:51.101696  8383 solver.cpp:244]     Train net output #0: loss = 0.0365674 (* 1 = 0.0365674 loss)
I0811 15:06:51.101701  8383 sgd_solver.cpp:106] Iteration 53400, lr = 0.000377138
I0811 15:06:54.330453  8383 solver.cpp:337] Iteration 53500, Testing net (#0)
I0811 15:06:57.336696  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:07:00.891106  8383 solver.cpp:404]     Test net output #0: accuracy = 0.919129
I0811 15:07:00.891178  8383 solver.cpp:404]     Test net output #1: loss = 0.408703 (* 1 = 0.408703 loss)
I0811 15:07:00.902032  8383 solver.cpp:228] Iteration 53500, loss = 0.00711176
I0811 15:07:00.902094  8383 solver.cpp:244]     Train net output #0: loss = 0.00711176 (* 1 = 0.00711176 loss)
I0811 15:07:00.902117  8383 sgd_solver.cpp:106] Iteration 53500, lr = 0.000376753
I0811 15:07:04.098696  8383 solver.cpp:228] Iteration 53600, loss = 0.0210466
I0811 15:07:04.098731  8383 solver.cpp:244]     Train net output #0: loss = 0.0210466 (* 1 = 0.0210466 loss)
I0811 15:07:04.098737  8383 sgd_solver.cpp:106] Iteration 53600, lr = 0.000376369
I0811 15:07:07.349993  8383 solver.cpp:228] Iteration 53700, loss = 0.0027547
I0811 15:07:07.350033  8383 solver.cpp:244]     Train net output #0: loss = 0.0027547 (* 1 = 0.0027547 loss)
I0811 15:07:07.350040  8383 sgd_solver.cpp:106] Iteration 53700, lr = 0.000375986
I0811 15:07:10.644680  8383 solver.cpp:228] Iteration 53800, loss = 0.028087
I0811 15:07:10.644724  8383 solver.cpp:244]     Train net output #0: loss = 0.028087 (* 1 = 0.028087 loss)
I0811 15:07:10.644734  8383 sgd_solver.cpp:106] Iteration 53800, lr = 0.000375604
I0811 15:07:13.962980  8383 solver.cpp:228] Iteration 53900, loss = 0.021651
I0811 15:07:13.963032  8383 solver.cpp:244]     Train net output #0: loss = 0.021651 (* 1 = 0.021651 loss)
I0811 15:07:13.963039  8383 sgd_solver.cpp:106] Iteration 53900, lr = 0.000375223
I0811 15:07:17.201380  8383 solver.cpp:337] Iteration 54000, Testing net (#0)
I0811 15:07:23.721920  8383 solver.cpp:404]     Test net output #0: accuracy = 0.908936
I0811 15:07:23.721985  8383 solver.cpp:404]     Test net output #1: loss = 0.456058 (* 1 = 0.456058 loss)
I0811 15:07:23.735859  8383 solver.cpp:228] Iteration 54000, loss = 0.00231664
I0811 15:07:23.735924  8383 solver.cpp:244]     Train net output #0: loss = 0.00231664 (* 1 = 0.00231664 loss)
I0811 15:07:23.735950  8383 sgd_solver.cpp:106] Iteration 54000, lr = 0.000374842
I0811 15:07:26.987095  8383 solver.cpp:228] Iteration 54100, loss = 0.00625274
I0811 15:07:26.987138  8383 solver.cpp:244]     Train net output #0: loss = 0.00625274 (* 1 = 0.00625274 loss)
I0811 15:07:26.987144  8383 sgd_solver.cpp:106] Iteration 54100, lr = 0.000374463
I0811 15:07:30.191251  8383 solver.cpp:228] Iteration 54200, loss = 0.00112751
I0811 15:07:30.191296  8383 solver.cpp:244]     Train net output #0: loss = 0.00112751 (* 1 = 0.00112751 loss)
I0811 15:07:30.191303  8383 sgd_solver.cpp:106] Iteration 54200, lr = 0.000374084
I0811 15:07:33.437988  8383 solver.cpp:228] Iteration 54300, loss = 0.00296088
I0811 15:07:33.438031  8383 solver.cpp:244]     Train net output #0: loss = 0.00296088 (* 1 = 0.00296088 loss)
I0811 15:07:33.438038  8383 sgd_solver.cpp:106] Iteration 54300, lr = 0.000373707
I0811 15:07:36.707852  8383 solver.cpp:228] Iteration 54400, loss = 0.00374169
I0811 15:07:36.707885  8383 solver.cpp:244]     Train net output #0: loss = 0.00374169 (* 1 = 0.00374169 loss)
I0811 15:07:36.707892  8383 sgd_solver.cpp:106] Iteration 54400, lr = 0.00037333
I0811 15:07:39.931058  8383 solver.cpp:337] Iteration 54500, Testing net (#0)
I0811 15:07:46.323861  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897742
I0811 15:07:46.323927  8383 solver.cpp:404]     Test net output #1: loss = 0.546493 (* 1 = 0.546493 loss)
I0811 15:07:46.336709  8383 solver.cpp:228] Iteration 54500, loss = 0.000649999
I0811 15:07:46.336740  8383 solver.cpp:244]     Train net output #0: loss = 0.000649999 (* 1 = 0.000649999 loss)
I0811 15:07:46.336751  8383 sgd_solver.cpp:106] Iteration 54500, lr = 0.000372954
I0811 15:07:49.560777  8383 solver.cpp:228] Iteration 54600, loss = 0.000237375
I0811 15:07:49.560817  8383 solver.cpp:244]     Train net output #0: loss = 0.000237375 (* 1 = 0.000237375 loss)
I0811 15:07:49.560824  8383 sgd_solver.cpp:106] Iteration 54600, lr = 0.000372579
I0811 15:07:52.812880  8383 solver.cpp:228] Iteration 54700, loss = 0.000904035
I0811 15:07:52.812921  8383 solver.cpp:244]     Train net output #0: loss = 0.000904035 (* 1 = 0.000904035 loss)
I0811 15:07:52.812927  8383 sgd_solver.cpp:106] Iteration 54700, lr = 0.000372205
I0811 15:07:56.066712  8383 solver.cpp:228] Iteration 54800, loss = 0.00123629
I0811 15:07:56.066751  8383 solver.cpp:244]     Train net output #0: loss = 0.00123629 (* 1 = 0.00123629 loss)
I0811 15:07:56.066756  8383 sgd_solver.cpp:106] Iteration 54800, lr = 0.000371832
I0811 15:07:59.339618  8383 solver.cpp:228] Iteration 54900, loss = 0.00101568
I0811 15:07:59.339658  8383 solver.cpp:244]     Train net output #0: loss = 0.00101568 (* 1 = 0.00101568 loss)
I0811 15:07:59.339664  8383 sgd_solver.cpp:106] Iteration 54900, lr = 0.000371459
I0811 15:08:02.621635  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_55000.caffemodel
I0811 15:08:03.000095  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_55000.solverstate
I0811 15:08:03.132776  8383 solver.cpp:337] Iteration 55000, Testing net (#0)
I0811 15:08:04.545591  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:08:09.547948  8383 solver.cpp:404]     Test net output #0: accuracy = 0.907419
I0811 15:08:09.548013  8383 solver.cpp:404]     Test net output #1: loss = 0.497123 (* 1 = 0.497123 loss)
I0811 15:08:09.561133  8383 solver.cpp:228] Iteration 55000, loss = 0.00035542
I0811 15:08:09.561208  8383 solver.cpp:244]     Train net output #0: loss = 0.00035542 (* 1 = 0.00035542 loss)
I0811 15:08:09.561231  8383 sgd_solver.cpp:106] Iteration 55000, lr = 0.000371088
I0811 15:08:12.777956  8383 solver.cpp:228] Iteration 55100, loss = 0.000722169
I0811 15:08:12.777997  8383 solver.cpp:244]     Train net output #0: loss = 0.000722169 (* 1 = 0.000722169 loss)
I0811 15:08:12.778005  8383 sgd_solver.cpp:106] Iteration 55100, lr = 0.000370717
I0811 15:08:16.106034  8383 solver.cpp:228] Iteration 55200, loss = 0.00062367
I0811 15:08:16.106072  8383 solver.cpp:244]     Train net output #0: loss = 0.00062367 (* 1 = 0.00062367 loss)
I0811 15:08:16.106078  8383 sgd_solver.cpp:106] Iteration 55200, lr = 0.000370347
I0811 15:08:19.420090  8383 solver.cpp:228] Iteration 55300, loss = 0.00065492
I0811 15:08:19.420130  8383 solver.cpp:244]     Train net output #0: loss = 0.00065492 (* 1 = 0.00065492 loss)
I0811 15:08:19.420137  8383 sgd_solver.cpp:106] Iteration 55300, lr = 0.000369978
I0811 15:08:22.726238  8383 solver.cpp:228] Iteration 55400, loss = 0.000698424
I0811 15:08:22.726284  8383 solver.cpp:244]     Train net output #0: loss = 0.000698424 (* 1 = 0.000698424 loss)
I0811 15:08:22.726292  8383 sgd_solver.cpp:106] Iteration 55400, lr = 0.00036961
I0811 15:08:25.972229  8383 solver.cpp:337] Iteration 55500, Testing net (#0)
I0811 15:08:32.440722  8383 solver.cpp:404]     Test net output #0: accuracy = 0.915839
I0811 15:08:32.440790  8383 solver.cpp:404]     Test net output #1: loss = 0.46477 (* 1 = 0.46477 loss)
I0811 15:08:32.454164  8383 solver.cpp:228] Iteration 55500, loss = 0.0043935
I0811 15:08:32.454231  8383 solver.cpp:244]     Train net output #0: loss = 0.0043935 (* 1 = 0.0043935 loss)
I0811 15:08:32.454249  8383 sgd_solver.cpp:106] Iteration 55500, lr = 0.000369243
I0811 15:08:35.700259  8383 solver.cpp:228] Iteration 55600, loss = 0.000454164
I0811 15:08:35.700307  8383 solver.cpp:244]     Train net output #0: loss = 0.000454164 (* 1 = 0.000454164 loss)
I0811 15:08:35.700320  8383 sgd_solver.cpp:106] Iteration 55600, lr = 0.000368877
I0811 15:08:39.037264  8383 solver.cpp:228] Iteration 55700, loss = 0.00222671
I0811 15:08:39.037307  8383 solver.cpp:244]     Train net output #0: loss = 0.00222671 (* 1 = 0.00222671 loss)
I0811 15:08:39.037312  8383 sgd_solver.cpp:106] Iteration 55700, lr = 0.000368511
I0811 15:08:42.269004  8383 solver.cpp:228] Iteration 55800, loss = 0.000764805
I0811 15:08:42.269062  8383 solver.cpp:244]     Train net output #0: loss = 0.000764805 (* 1 = 0.000764805 loss)
I0811 15:08:42.269069  8383 sgd_solver.cpp:106] Iteration 55800, lr = 0.000368146
I0811 15:08:45.560484  8383 solver.cpp:228] Iteration 55900, loss = 0.000599575
I0811 15:08:45.560540  8383 solver.cpp:244]     Train net output #0: loss = 0.000599575 (* 1 = 0.000599575 loss)
I0811 15:08:45.560557  8383 sgd_solver.cpp:106] Iteration 55900, lr = 0.000367783
I0811 15:08:48.825554  8383 solver.cpp:337] Iteration 56000, Testing net (#0)
I0811 15:08:55.460230  8383 solver.cpp:404]     Test net output #0: accuracy = 0.916742
I0811 15:08:55.460300  8383 solver.cpp:404]     Test net output #1: loss = 0.463435 (* 1 = 0.463435 loss)
I0811 15:08:55.474681  8383 solver.cpp:228] Iteration 56000, loss = 0.000480394
I0811 15:08:55.474756  8383 solver.cpp:244]     Train net output #0: loss = 0.000480394 (* 1 = 0.000480394 loss)
I0811 15:08:55.474777  8383 sgd_solver.cpp:106] Iteration 56000, lr = 0.00036742
I0811 15:08:56.178623  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:08:58.680706  8383 solver.cpp:228] Iteration 56100, loss = 0.000664145
I0811 15:08:58.680779  8383 solver.cpp:244]     Train net output #0: loss = 0.000664145 (* 1 = 0.000664145 loss)
I0811 15:08:58.680786  8383 sgd_solver.cpp:106] Iteration 56100, lr = 0.000367057
I0811 15:09:01.902410  8383 solver.cpp:228] Iteration 56200, loss = 0.00146069
I0811 15:09:01.902448  8383 solver.cpp:244]     Train net output #0: loss = 0.00146069 (* 1 = 0.00146069 loss)
I0811 15:09:01.902454  8383 sgd_solver.cpp:106] Iteration 56200, lr = 0.000366696
I0811 15:09:05.173656  8383 solver.cpp:228] Iteration 56300, loss = 0.0004525
I0811 15:09:05.173693  8383 solver.cpp:244]     Train net output #0: loss = 0.0004525 (* 1 = 0.0004525 loss)
I0811 15:09:05.173699  8383 sgd_solver.cpp:106] Iteration 56300, lr = 0.000366336
I0811 15:09:08.452922  8383 solver.cpp:228] Iteration 56400, loss = 0.000194314
I0811 15:09:08.452942  8383 solver.cpp:244]     Train net output #0: loss = 0.000194314 (* 1 = 0.000194314 loss)
I0811 15:09:08.452947  8383 sgd_solver.cpp:106] Iteration 56400, lr = 0.000365976
I0811 15:09:11.673373  8383 solver.cpp:337] Iteration 56500, Testing net (#0)
I0811 15:09:18.308831  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896484
I0811 15:09:18.308888  8383 solver.cpp:404]     Test net output #1: loss = 0.587895 (* 1 = 0.587895 loss)
I0811 15:09:18.319501  8383 solver.cpp:228] Iteration 56500, loss = 0.000227878
I0811 15:09:18.319568  8383 solver.cpp:244]     Train net output #0: loss = 0.000227878 (* 1 = 0.000227878 loss)
I0811 15:09:18.319592  8383 sgd_solver.cpp:106] Iteration 56500, lr = 0.000365617
I0811 15:09:21.557731  8383 solver.cpp:228] Iteration 56600, loss = 0.000401411
I0811 15:09:21.557767  8383 solver.cpp:244]     Train net output #0: loss = 0.000401411 (* 1 = 0.000401411 loss)
I0811 15:09:21.557773  8383 sgd_solver.cpp:106] Iteration 56600, lr = 0.000365259
I0811 15:09:24.845500  8383 solver.cpp:228] Iteration 56700, loss = 0.00017651
I0811 15:09:24.845540  8383 solver.cpp:244]     Train net output #0: loss = 0.00017651 (* 1 = 0.00017651 loss)
I0811 15:09:24.845546  8383 sgd_solver.cpp:106] Iteration 56700, lr = 0.000364902
I0811 15:09:28.111409  8383 solver.cpp:228] Iteration 56800, loss = 0.000634136
I0811 15:09:28.111450  8383 solver.cpp:244]     Train net output #0: loss = 0.000634136 (* 1 = 0.000634136 loss)
I0811 15:09:28.111457  8383 sgd_solver.cpp:106] Iteration 56800, lr = 0.000364545
I0811 15:09:31.383788  8383 solver.cpp:228] Iteration 56900, loss = 0.000421635
I0811 15:09:31.383834  8383 solver.cpp:244]     Train net output #0: loss = 0.000421635 (* 1 = 0.000421635 loss)
I0811 15:09:31.383841  8383 sgd_solver.cpp:106] Iteration 56900, lr = 0.00036419
I0811 15:09:34.634747  8383 solver.cpp:337] Iteration 57000, Testing net (#0)
I0811 15:09:41.078805  8383 solver.cpp:404]     Test net output #0: accuracy = 0.902225
I0811 15:09:41.078860  8383 solver.cpp:404]     Test net output #1: loss = 0.560764 (* 1 = 0.560764 loss)
I0811 15:09:41.089025  8383 solver.cpp:228] Iteration 57000, loss = 0.00107907
I0811 15:09:41.089046  8383 solver.cpp:244]     Train net output #0: loss = 0.00107907 (* 1 = 0.00107907 loss)
I0811 15:09:41.089058  8383 sgd_solver.cpp:106] Iteration 57000, lr = 0.000363835
I0811 15:09:44.320519  8383 solver.cpp:228] Iteration 57100, loss = 0.000344252
I0811 15:09:44.320555  8383 solver.cpp:244]     Train net output #0: loss = 0.000344252 (* 1 = 0.000344252 loss)
I0811 15:09:44.320561  8383 sgd_solver.cpp:106] Iteration 57100, lr = 0.000363481
I0811 15:09:47.582537  8383 solver.cpp:228] Iteration 57200, loss = 0.00115496
I0811 15:09:47.582578  8383 solver.cpp:244]     Train net output #0: loss = 0.00115496 (* 1 = 0.00115496 loss)
I0811 15:09:47.582586  8383 sgd_solver.cpp:106] Iteration 57200, lr = 0.000363128
I0811 15:09:50.920953  8383 solver.cpp:228] Iteration 57300, loss = 0.000623417
I0811 15:09:50.920999  8383 solver.cpp:244]     Train net output #0: loss = 0.000623417 (* 1 = 0.000623417 loss)
I0811 15:09:50.921006  8383 sgd_solver.cpp:106] Iteration 57300, lr = 0.000362775
I0811 15:09:54.160022  8383 solver.cpp:228] Iteration 57400, loss = 0.00100114
I0811 15:09:54.160055  8383 solver.cpp:244]     Train net output #0: loss = 0.00100114 (* 1 = 0.00100114 loss)
I0811 15:09:54.160061  8383 sgd_solver.cpp:106] Iteration 57400, lr = 0.000362424
I0811 15:09:57.396409  8383 solver.cpp:337] Iteration 57500, Testing net (#0)
I0811 15:10:03.774638  8383 solver.cpp:404]     Test net output #0: accuracy = 0.894742
I0811 15:10:03.774693  8383 solver.cpp:404]     Test net output #1: loss = 0.611339 (* 1 = 0.611339 loss)
I0811 15:10:03.785282  8383 solver.cpp:228] Iteration 57500, loss = 0.00134626
I0811 15:10:03.785377  8383 solver.cpp:244]     Train net output #0: loss = 0.00134626 (* 1 = 0.00134626 loss)
I0811 15:10:03.785414  8383 sgd_solver.cpp:106] Iteration 57500, lr = 0.000362073
I0811 15:10:05.833755  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:10:07.056077  8383 solver.cpp:228] Iteration 57600, loss = 0.000386489
I0811 15:10:07.056107  8383 solver.cpp:244]     Train net output #0: loss = 0.000386489 (* 1 = 0.000386489 loss)
I0811 15:10:07.056113  8383 sgd_solver.cpp:106] Iteration 57600, lr = 0.000361723
I0811 15:10:10.334513  8383 solver.cpp:228] Iteration 57700, loss = 0.000144685
I0811 15:10:10.334565  8383 solver.cpp:244]     Train net output #0: loss = 0.000144685 (* 1 = 0.000144685 loss)
I0811 15:10:10.334573  8383 sgd_solver.cpp:106] Iteration 57700, lr = 0.000361374
I0811 15:10:13.561574  8383 solver.cpp:228] Iteration 57800, loss = 0.000767673
I0811 15:10:13.561641  8383 solver.cpp:244]     Train net output #0: loss = 0.000767673 (* 1 = 0.000767673 loss)
I0811 15:10:13.561661  8383 sgd_solver.cpp:106] Iteration 57800, lr = 0.000361025
I0811 15:10:16.874837  8383 solver.cpp:228] Iteration 57900, loss = 0.000877114
I0811 15:10:16.874876  8383 solver.cpp:244]     Train net output #0: loss = 0.000877114 (* 1 = 0.000877114 loss)
I0811 15:10:16.874881  8383 sgd_solver.cpp:106] Iteration 57900, lr = 0.000360678
I0811 15:10:20.116130  8383 solver.cpp:337] Iteration 58000, Testing net (#0)
I0811 15:10:26.542884  8383 solver.cpp:404]     Test net output #0: accuracy = 0.911936
I0811 15:10:26.542942  8383 solver.cpp:404]     Test net output #1: loss = 0.516183 (* 1 = 0.516183 loss)
I0811 15:10:26.556190  8383 solver.cpp:228] Iteration 58000, loss = 0.000229429
I0811 15:10:26.556232  8383 solver.cpp:244]     Train net output #0: loss = 0.000229429 (* 1 = 0.000229429 loss)
I0811 15:10:26.556248  8383 sgd_solver.cpp:106] Iteration 58000, lr = 0.000360331
I0811 15:10:29.788626  8383 solver.cpp:228] Iteration 58100, loss = 0.000384413
I0811 15:10:29.788666  8383 solver.cpp:244]     Train net output #0: loss = 0.000384413 (* 1 = 0.000384413 loss)
I0811 15:10:29.788672  8383 sgd_solver.cpp:106] Iteration 58100, lr = 0.000359985
I0811 15:10:33.074090  8383 solver.cpp:228] Iteration 58200, loss = 0.000554154
I0811 15:10:33.074139  8383 solver.cpp:244]     Train net output #0: loss = 0.000554154 (* 1 = 0.000554154 loss)
I0811 15:10:33.074146  8383 sgd_solver.cpp:106] Iteration 58200, lr = 0.00035964
I0811 15:10:36.377812  8383 solver.cpp:228] Iteration 58300, loss = 0.00058994
I0811 15:10:36.377849  8383 solver.cpp:244]     Train net output #0: loss = 0.00058994 (* 1 = 0.00058994 loss)
I0811 15:10:36.377856  8383 sgd_solver.cpp:106] Iteration 58300, lr = 0.000359295
I0811 15:10:39.635907  8383 solver.cpp:228] Iteration 58400, loss = 0.00141646
I0811 15:10:39.635951  8383 solver.cpp:244]     Train net output #0: loss = 0.00141646 (* 1 = 0.00141646 loss)
I0811 15:10:39.635957  8383 sgd_solver.cpp:106] Iteration 58400, lr = 0.000358951
I0811 15:10:42.858305  8383 solver.cpp:337] Iteration 58500, Testing net (#0)
I0811 15:10:49.476186  8383 solver.cpp:404]     Test net output #0: accuracy = 0.893225
I0811 15:10:49.476251  8383 solver.cpp:404]     Test net output #1: loss = 0.638805 (* 1 = 0.638805 loss)
I0811 15:10:49.489711  8383 solver.cpp:228] Iteration 58500, loss = 0.000102987
I0811 15:10:49.489776  8383 solver.cpp:244]     Train net output #0: loss = 0.000102987 (* 1 = 0.000102987 loss)
I0811 15:10:49.489799  8383 sgd_solver.cpp:106] Iteration 58500, lr = 0.000358608
I0811 15:10:52.705835  8383 solver.cpp:228] Iteration 58600, loss = 0.00240326
I0811 15:10:52.705876  8383 solver.cpp:244]     Train net output #0: loss = 0.00240326 (* 1 = 0.00240326 loss)
I0811 15:10:52.705883  8383 sgd_solver.cpp:106] Iteration 58600, lr = 0.000358266
I0811 15:10:55.986960  8383 solver.cpp:228] Iteration 58700, loss = 0.000780665
I0811 15:10:55.987005  8383 solver.cpp:244]     Train net output #0: loss = 0.000780665 (* 1 = 0.000780665 loss)
I0811 15:10:55.987012  8383 sgd_solver.cpp:106] Iteration 58700, lr = 0.000357925
I0811 15:10:59.238395  8383 solver.cpp:228] Iteration 58800, loss = 0.000221733
I0811 15:10:59.238435  8383 solver.cpp:244]     Train net output #0: loss = 0.000221733 (* 1 = 0.000221733 loss)
I0811 15:10:59.238442  8383 sgd_solver.cpp:106] Iteration 58800, lr = 0.000357584
I0811 15:11:02.521972  8383 solver.cpp:228] Iteration 58900, loss = 0.000160644
I0811 15:11:02.522006  8383 solver.cpp:244]     Train net output #0: loss = 0.000160644 (* 1 = 0.000160644 loss)
I0811 15:11:02.522011  8383 sgd_solver.cpp:106] Iteration 58900, lr = 0.000357244
I0811 15:11:05.766325  8383 solver.cpp:337] Iteration 59000, Testing net (#0)
I0811 15:11:11.819896  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:11:12.413575  8383 solver.cpp:404]     Test net output #0: accuracy = 0.894516
I0811 15:11:12.413604  8383 solver.cpp:404]     Test net output #1: loss = 0.631209 (* 1 = 0.631209 loss)
I0811 15:11:12.426640  8383 solver.cpp:228] Iteration 59000, loss = 0.000446159
I0811 15:11:12.426658  8383 solver.cpp:244]     Train net output #0: loss = 0.000446159 (* 1 = 0.000446159 loss)
I0811 15:11:12.426681  8383 sgd_solver.cpp:106] Iteration 59000, lr = 0.000356905
I0811 15:11:15.658841  8383 solver.cpp:228] Iteration 59100, loss = 0.000202864
I0811 15:11:15.658884  8383 solver.cpp:244]     Train net output #0: loss = 0.000202864 (* 1 = 0.000202864 loss)
I0811 15:11:15.658890  8383 sgd_solver.cpp:106] Iteration 59100, lr = 0.000356566
I0811 15:11:18.910373  8383 solver.cpp:228] Iteration 59200, loss = 0.00012056
I0811 15:11:18.910425  8383 solver.cpp:244]     Train net output #0: loss = 0.00012056 (* 1 = 0.00012056 loss)
I0811 15:11:18.910431  8383 sgd_solver.cpp:106] Iteration 59200, lr = 0.000356228
I0811 15:11:22.193596  8383 solver.cpp:228] Iteration 59300, loss = 0.000677806
I0811 15:11:22.193634  8383 solver.cpp:244]     Train net output #0: loss = 0.000677806 (* 1 = 0.000677806 loss)
I0811 15:11:22.193641  8383 sgd_solver.cpp:106] Iteration 59300, lr = 0.000355892
I0811 15:11:25.481695  8383 solver.cpp:228] Iteration 59400, loss = 8.00732e-05
I0811 15:11:25.481714  8383 solver.cpp:244]     Train net output #0: loss = 8.00732e-05 (* 1 = 8.00732e-05 loss)
I0811 15:11:25.481720  8383 sgd_solver.cpp:106] Iteration 59400, lr = 0.000355555
I0811 15:11:28.708041  8383 solver.cpp:337] Iteration 59500, Testing net (#0)
I0811 15:11:35.277541  8383 solver.cpp:404]     Test net output #0: accuracy = 0.891226
I0811 15:11:35.277626  8383 solver.cpp:404]     Test net output #1: loss = 0.65702 (* 1 = 0.65702 loss)
I0811 15:11:35.290851  8383 solver.cpp:228] Iteration 59500, loss = 0.000530627
I0811 15:11:35.290879  8383 solver.cpp:244]     Train net output #0: loss = 0.000530627 (* 1 = 0.000530627 loss)
I0811 15:11:35.290904  8383 sgd_solver.cpp:106] Iteration 59500, lr = 0.00035522
I0811 15:11:38.499202  8383 solver.cpp:228] Iteration 59600, loss = 0.00297046
I0811 15:11:38.499243  8383 solver.cpp:244]     Train net output #0: loss = 0.00297046 (* 1 = 0.00297046 loss)
I0811 15:11:38.499249  8383 sgd_solver.cpp:106] Iteration 59600, lr = 0.000354885
I0811 15:11:41.749104  8383 solver.cpp:228] Iteration 59700, loss = 0.000154285
I0811 15:11:41.749145  8383 solver.cpp:244]     Train net output #0: loss = 0.000154285 (* 1 = 0.000154285 loss)
I0811 15:11:41.749150  8383 sgd_solver.cpp:106] Iteration 59700, lr = 0.000354551
I0811 15:11:45.012511  8383 solver.cpp:228] Iteration 59800, loss = 0.000348042
I0811 15:11:45.012550  8383 solver.cpp:244]     Train net output #0: loss = 0.000348042 (* 1 = 0.000348042 loss)
I0811 15:11:45.012557  8383 sgd_solver.cpp:106] Iteration 59800, lr = 0.000354218
I0811 15:11:48.284538  8383 solver.cpp:228] Iteration 59900, loss = 0.000154199
I0811 15:11:48.284574  8383 solver.cpp:244]     Train net output #0: loss = 0.000154199 (* 1 = 0.000154199 loss)
I0811 15:11:48.284580  8383 sgd_solver.cpp:106] Iteration 59900, lr = 0.000353885
I0811 15:11:51.512342  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_60000.caffemodel
I0811 15:11:51.885692  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_60000.solverstate
I0811 15:11:52.018043  8383 solver.cpp:337] Iteration 60000, Testing net (#0)
I0811 15:11:58.394542  8383 solver.cpp:404]     Test net output #0: accuracy = 0.907387
I0811 15:11:58.394603  8383 solver.cpp:404]     Test net output #1: loss = 0.561637 (* 1 = 0.561637 loss)
I0811 15:11:58.404816  8383 solver.cpp:228] Iteration 60000, loss = 0.000148529
I0811 15:11:58.404840  8383 solver.cpp:244]     Train net output #0: loss = 0.000148529 (* 1 = 0.000148529 loss)
I0811 15:11:58.404853  8383 sgd_solver.cpp:106] Iteration 60000, lr = 0.000353553
I0811 15:12:01.627722  8383 solver.cpp:228] Iteration 60100, loss = 0.000239452
I0811 15:12:01.627794  8383 solver.cpp:244]     Train net output #0: loss = 0.000239452 (* 1 = 0.000239452 loss)
I0811 15:12:01.627812  8383 sgd_solver.cpp:106] Iteration 60100, lr = 0.000353222
I0811 15:12:04.902437  8383 solver.cpp:228] Iteration 60200, loss = 0.000224457
I0811 15:12:04.902490  8383 solver.cpp:244]     Train net output #0: loss = 0.000224457 (* 1 = 0.000224457 loss)
I0811 15:12:04.902498  8383 sgd_solver.cpp:106] Iteration 60200, lr = 0.000352892
I0811 15:12:08.173519  8383 solver.cpp:228] Iteration 60300, loss = 0.000196918
I0811 15:12:08.173568  8383 solver.cpp:244]     Train net output #0: loss = 0.000196918 (* 1 = 0.000196918 loss)
I0811 15:12:08.173575  8383 sgd_solver.cpp:106] Iteration 60300, lr = 0.000352562
I0811 15:12:11.433981  8383 solver.cpp:228] Iteration 60400, loss = 0.000793371
I0811 15:12:11.434015  8383 solver.cpp:244]     Train net output #0: loss = 0.000793371 (* 1 = 0.000793371 loss)
I0811 15:12:11.434020  8383 sgd_solver.cpp:106] Iteration 60400, lr = 0.000352233
I0811 15:12:14.700764  8383 solver.cpp:337] Iteration 60500, Testing net (#0)
I0811 15:12:19.382542  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:12:21.241042  8383 solver.cpp:404]     Test net output #0: accuracy = 0.887903
I0811 15:12:21.241150  8383 solver.cpp:404]     Test net output #1: loss = 0.687573 (* 1 = 0.687573 loss)
I0811 15:12:21.251772  8383 solver.cpp:228] Iteration 60500, loss = 0.000266445
I0811 15:12:21.251817  8383 solver.cpp:244]     Train net output #0: loss = 0.000266445 (* 1 = 0.000266445 loss)
I0811 15:12:21.251832  8383 sgd_solver.cpp:106] Iteration 60500, lr = 0.000351905
I0811 15:12:24.470132  8383 solver.cpp:228] Iteration 60600, loss = 0.000244123
I0811 15:12:24.470161  8383 solver.cpp:244]     Train net output #0: loss = 0.000244123 (* 1 = 0.000244123 loss)
I0811 15:12:24.470167  8383 sgd_solver.cpp:106] Iteration 60600, lr = 0.000351578
I0811 15:12:27.705972  8383 solver.cpp:228] Iteration 60700, loss = 0.00025718
I0811 15:12:27.706013  8383 solver.cpp:244]     Train net output #0: loss = 0.00025718 (* 1 = 0.00025718 loss)
I0811 15:12:27.706018  8383 sgd_solver.cpp:106] Iteration 60700, lr = 0.000351251
I0811 15:12:30.946738  8383 solver.cpp:228] Iteration 60800, loss = 0.000472428
I0811 15:12:30.946774  8383 solver.cpp:244]     Train net output #0: loss = 0.000472428 (* 1 = 0.000472428 loss)
I0811 15:12:30.946779  8383 sgd_solver.cpp:106] Iteration 60800, lr = 0.000350925
I0811 15:12:34.273618  8383 solver.cpp:228] Iteration 60900, loss = 0.000202816
I0811 15:12:34.273672  8383 solver.cpp:244]     Train net output #0: loss = 0.000202816 (* 1 = 0.000202816 loss)
I0811 15:12:34.273679  8383 sgd_solver.cpp:106] Iteration 60900, lr = 0.000350599
I0811 15:12:37.493291  8383 solver.cpp:337] Iteration 61000, Testing net (#0)
I0811 15:12:44.438700  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896742
I0811 15:12:44.438760  8383 solver.cpp:404]     Test net output #1: loss = 0.637679 (* 1 = 0.637679 loss)
I0811 15:12:44.451701  8383 solver.cpp:228] Iteration 61000, loss = 0.000218596
I0811 15:12:44.451761  8383 solver.cpp:244]     Train net output #0: loss = 0.000218596 (* 1 = 0.000218596 loss)
I0811 15:12:44.451786  8383 sgd_solver.cpp:106] Iteration 61000, lr = 0.000350275
I0811 15:12:47.661281  8383 solver.cpp:228] Iteration 61100, loss = 0.000218026
I0811 15:12:47.661321  8383 solver.cpp:244]     Train net output #0: loss = 0.000218026 (* 1 = 0.000218026 loss)
I0811 15:12:47.661329  8383 sgd_solver.cpp:106] Iteration 61100, lr = 0.000349951
I0811 15:12:50.943366  8383 solver.cpp:228] Iteration 61200, loss = 0.00024164
I0811 15:12:50.943404  8383 solver.cpp:244]     Train net output #0: loss = 0.00024164 (* 1 = 0.00024164 loss)
I0811 15:12:50.943410  8383 sgd_solver.cpp:106] Iteration 61200, lr = 0.000349627
I0811 15:12:54.230948  8383 solver.cpp:228] Iteration 61300, loss = 0.000248427
I0811 15:12:54.230995  8383 solver.cpp:244]     Train net output #0: loss = 0.000248427 (* 1 = 0.000248427 loss)
I0811 15:12:54.231003  8383 sgd_solver.cpp:106] Iteration 61300, lr = 0.000349305
I0811 15:12:57.498062  8383 solver.cpp:228] Iteration 61400, loss = 0.000272657
I0811 15:12:57.498109  8383 solver.cpp:244]     Train net output #0: loss = 0.000272657 (* 1 = 0.000272657 loss)
I0811 15:12:57.498116  8383 sgd_solver.cpp:106] Iteration 61400, lr = 0.000348983
I0811 15:13:00.749481  8383 solver.cpp:337] Iteration 61500, Testing net (#0)
I0811 15:13:07.927880  8383 solver.cpp:404]     Test net output #0: accuracy = 0.892064
I0811 15:13:07.927932  8383 solver.cpp:404]     Test net output #1: loss = 0.668852 (* 1 = 0.668852 loss)
I0811 15:13:07.938043  8383 solver.cpp:228] Iteration 61500, loss = 0.000297597
I0811 15:13:07.938074  8383 solver.cpp:244]     Train net output #0: loss = 0.000297597 (* 1 = 0.000297597 loss)
I0811 15:13:07.938086  8383 sgd_solver.cpp:106] Iteration 61500, lr = 0.000348662
I0811 15:13:11.126380  8383 solver.cpp:228] Iteration 61600, loss = 8.87501e-05
I0811 15:13:11.126415  8383 solver.cpp:244]     Train net output #0: loss = 8.87501e-05 (* 1 = 8.87501e-05 loss)
I0811 15:13:11.126422  8383 sgd_solver.cpp:106] Iteration 61600, lr = 0.000348341
I0811 15:13:14.365711  8383 solver.cpp:228] Iteration 61700, loss = 6.2458e-05
I0811 15:13:14.365770  8383 solver.cpp:244]     Train net output #0: loss = 6.2458e-05 (* 1 = 6.2458e-05 loss)
I0811 15:13:14.365777  8383 sgd_solver.cpp:106] Iteration 61700, lr = 0.000348021
I0811 15:13:17.652012  8383 solver.cpp:228] Iteration 61800, loss = 0.00099692
I0811 15:13:17.652050  8383 solver.cpp:244]     Train net output #0: loss = 0.00099692 (* 1 = 0.00099692 loss)
I0811 15:13:17.652056  8383 sgd_solver.cpp:106] Iteration 61800, lr = 0.000347702
I0811 15:13:20.930847  8383 solver.cpp:228] Iteration 61900, loss = 0.000914088
I0811 15:13:20.930891  8383 solver.cpp:244]     Train net output #0: loss = 0.000914088 (* 1 = 0.000914088 loss)
I0811 15:13:20.930897  8383 sgd_solver.cpp:106] Iteration 61900, lr = 0.000347384
I0811 15:13:24.209499  8383 solver.cpp:337] Iteration 62000, Testing net (#0)
I0811 15:13:24.897624  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:13:30.631856  8383 solver.cpp:404]     Test net output #0: accuracy = 0.904968
I0811 15:13:30.631927  8383 solver.cpp:404]     Test net output #1: loss = 0.587304 (* 1 = 0.587304 loss)
I0811 15:13:30.645120  8383 solver.cpp:228] Iteration 62000, loss = 0.000160161
I0811 15:13:30.645197  8383 solver.cpp:244]     Train net output #0: loss = 0.000160161 (* 1 = 0.000160161 loss)
I0811 15:13:30.645221  8383 sgd_solver.cpp:106] Iteration 62000, lr = 0.000347066
I0811 15:13:33.884052  8383 solver.cpp:228] Iteration 62100, loss = 0.000162211
I0811 15:13:33.884089  8383 solver.cpp:244]     Train net output #0: loss = 0.000162211 (* 1 = 0.000162211 loss)
I0811 15:13:33.884096  8383 sgd_solver.cpp:106] Iteration 62100, lr = 0.000346749
I0811 15:13:37.133644  8383 solver.cpp:228] Iteration 62200, loss = 0.000231122
I0811 15:13:37.133682  8383 solver.cpp:244]     Train net output #0: loss = 0.000231122 (* 1 = 0.000231122 loss)
I0811 15:13:37.133688  8383 sgd_solver.cpp:106] Iteration 62200, lr = 0.000346433
I0811 15:13:40.441748  8383 solver.cpp:228] Iteration 62300, loss = 0.000977246
I0811 15:13:40.441788  8383 solver.cpp:244]     Train net output #0: loss = 0.000977246 (* 1 = 0.000977246 loss)
I0811 15:13:40.441795  8383 sgd_solver.cpp:106] Iteration 62300, lr = 0.000346117
I0811 15:13:43.703637  8383 solver.cpp:228] Iteration 62400, loss = 0.000192757
I0811 15:13:43.703671  8383 solver.cpp:244]     Train net output #0: loss = 0.000192757 (* 1 = 0.000192757 loss)
I0811 15:13:43.703677  8383 sgd_solver.cpp:106] Iteration 62400, lr = 0.000345802
I0811 15:13:46.936842  8383 solver.cpp:337] Iteration 62500, Testing net (#0)
I0811 15:13:53.836565  8383 solver.cpp:404]     Test net output #0: accuracy = 0.893516
I0811 15:13:53.836623  8383 solver.cpp:404]     Test net output #1: loss = 0.670765 (* 1 = 0.670765 loss)
I0811 15:13:53.848821  8383 solver.cpp:228] Iteration 62500, loss = 0.000175121
I0811 15:13:53.848845  8383 solver.cpp:244]     Train net output #0: loss = 0.000175121 (* 1 = 0.000175121 loss)
I0811 15:13:53.848857  8383 sgd_solver.cpp:106] Iteration 62500, lr = 0.000345487
I0811 15:13:57.057642  8383 solver.cpp:228] Iteration 62600, loss = 0.000548908
I0811 15:13:57.057678  8383 solver.cpp:244]     Train net output #0: loss = 0.000548908 (* 1 = 0.000548908 loss)
I0811 15:13:57.057685  8383 sgd_solver.cpp:106] Iteration 62600, lr = 0.000345174
I0811 15:14:00.343294  8383 solver.cpp:228] Iteration 62700, loss = 0.00019136
I0811 15:14:00.343345  8383 solver.cpp:244]     Train net output #0: loss = 0.00019136 (* 1 = 0.00019136 loss)
I0811 15:14:00.343353  8383 sgd_solver.cpp:106] Iteration 62700, lr = 0.00034486
I0811 15:14:03.611564  8383 solver.cpp:228] Iteration 62800, loss = 0.000234479
I0811 15:14:03.611600  8383 solver.cpp:244]     Train net output #0: loss = 0.000234479 (* 1 = 0.000234479 loss)
I0811 15:14:03.611606  8383 sgd_solver.cpp:106] Iteration 62800, lr = 0.000344548
I0811 15:14:06.900373  8383 solver.cpp:228] Iteration 62900, loss = 0.000428142
I0811 15:14:06.900413  8383 solver.cpp:244]     Train net output #0: loss = 0.000428142 (* 1 = 0.000428142 loss)
I0811 15:14:06.900419  8383 sgd_solver.cpp:106] Iteration 62900, lr = 0.000344236
I0811 15:14:10.134049  8383 solver.cpp:337] Iteration 63000, Testing net (#0)
I0811 15:14:16.657379  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898354
I0811 15:14:16.657444  8383 solver.cpp:404]     Test net output #1: loss = 0.639383 (* 1 = 0.639383 loss)
I0811 15:14:16.667603  8383 solver.cpp:228] Iteration 63000, loss = 0.000211435
I0811 15:14:16.667636  8383 solver.cpp:244]     Train net output #0: loss = 0.000211435 (* 1 = 0.000211435 loss)
I0811 15:14:16.667649  8383 sgd_solver.cpp:106] Iteration 63000, lr = 0.000343925
I0811 15:14:19.908555  8383 solver.cpp:228] Iteration 63100, loss = 9.5851e-05
I0811 15:14:19.908610  8383 solver.cpp:244]     Train net output #0: loss = 9.5851e-05 (* 1 = 9.5851e-05 loss)
I0811 15:14:19.908617  8383 sgd_solver.cpp:106] Iteration 63100, lr = 0.000343615
I0811 15:14:23.159082  8383 solver.cpp:228] Iteration 63200, loss = 0.000267134
I0811 15:14:23.159133  8383 solver.cpp:244]     Train net output #0: loss = 0.000267134 (* 1 = 0.000267134 loss)
I0811 15:14:23.159142  8383 sgd_solver.cpp:106] Iteration 63200, lr = 0.000343305
I0811 15:14:23.835441  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:14:26.420851  8383 solver.cpp:228] Iteration 63300, loss = 0.000558392
I0811 15:14:26.420894  8383 solver.cpp:244]     Train net output #0: loss = 0.000558392 (* 1 = 0.000558392 loss)
I0811 15:14:26.420902  8383 sgd_solver.cpp:106] Iteration 63300, lr = 0.000342996
I0811 15:14:29.710602  8383 solver.cpp:228] Iteration 63400, loss = 0.000180388
I0811 15:14:29.710642  8383 solver.cpp:244]     Train net output #0: loss = 0.000180388 (* 1 = 0.000180388 loss)
I0811 15:14:29.710649  8383 sgd_solver.cpp:106] Iteration 63400, lr = 0.000342687
I0811 15:14:32.968933  8383 solver.cpp:337] Iteration 63500, Testing net (#0)
I0811 15:14:39.587134  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89729
I0811 15:14:39.587185  8383 solver.cpp:404]     Test net output #1: loss = 0.64948 (* 1 = 0.64948 loss)
I0811 15:14:39.599653  8383 solver.cpp:228] Iteration 63500, loss = 0.000170294
I0811 15:14:39.599689  8383 solver.cpp:244]     Train net output #0: loss = 0.000170294 (* 1 = 0.000170294 loss)
I0811 15:14:39.599701  8383 sgd_solver.cpp:106] Iteration 63500, lr = 0.000342379
I0811 15:14:42.790271  8383 solver.cpp:228] Iteration 63600, loss = 0.00021885
I0811 15:14:42.790313  8383 solver.cpp:244]     Train net output #0: loss = 0.00021885 (* 1 = 0.00021885 loss)
I0811 15:14:42.790320  8383 sgd_solver.cpp:106] Iteration 63600, lr = 0.000342072
I0811 15:14:46.080108  8383 solver.cpp:228] Iteration 63700, loss = 0.000110577
I0811 15:14:46.080148  8383 solver.cpp:244]     Train net output #0: loss = 0.000110577 (* 1 = 0.000110577 loss)
I0811 15:14:46.080154  8383 sgd_solver.cpp:106] Iteration 63700, lr = 0.000341766
I0811 15:14:49.329011  8383 solver.cpp:228] Iteration 63800, loss = 0.000151621
I0811 15:14:49.329063  8383 solver.cpp:244]     Train net output #0: loss = 0.000151621 (* 1 = 0.000151621 loss)
I0811 15:14:49.329071  8383 sgd_solver.cpp:106] Iteration 63800, lr = 0.00034146
I0811 15:14:52.613373  8383 solver.cpp:228] Iteration 63900, loss = 0.000242157
I0811 15:14:52.613409  8383 solver.cpp:244]     Train net output #0: loss = 0.000242157 (* 1 = 0.000242157 loss)
I0811 15:14:52.613415  8383 sgd_solver.cpp:106] Iteration 63900, lr = 0.000341154
I0811 15:14:55.809698  8383 solver.cpp:337] Iteration 64000, Testing net (#0)
I0811 15:15:02.277734  8383 solver.cpp:404]     Test net output #0: accuracy = 0.903807
I0811 15:15:02.277808  8383 solver.cpp:404]     Test net output #1: loss = 0.607607 (* 1 = 0.607607 loss)
I0811 15:15:02.289861  8383 solver.cpp:228] Iteration 64000, loss = 0.000261392
I0811 15:15:02.290060  8383 solver.cpp:244]     Train net output #0: loss = 0.000261392 (* 1 = 0.000261392 loss)
I0811 15:15:02.290132  8383 sgd_solver.cpp:106] Iteration 64000, lr = 0.00034085
I0811 15:15:05.532579  8383 solver.cpp:228] Iteration 64100, loss = 0.000223768
I0811 15:15:05.532623  8383 solver.cpp:244]     Train net output #0: loss = 0.000223768 (* 1 = 0.000223768 loss)
I0811 15:15:05.532629  8383 sgd_solver.cpp:106] Iteration 64100, lr = 0.000340546
I0811 15:15:08.777957  8383 solver.cpp:228] Iteration 64200, loss = 0.000100827
I0811 15:15:08.778009  8383 solver.cpp:244]     Train net output #0: loss = 0.000100827 (* 1 = 0.000100827 loss)
I0811 15:15:08.778017  8383 sgd_solver.cpp:106] Iteration 64200, lr = 0.000340242
I0811 15:15:12.052691  8383 solver.cpp:228] Iteration 64300, loss = 0.000402691
I0811 15:15:12.052747  8383 solver.cpp:244]     Train net output #0: loss = 0.000402691 (* 1 = 0.000402691 loss)
I0811 15:15:12.052757  8383 sgd_solver.cpp:106] Iteration 64300, lr = 0.00033994
I0811 15:15:15.409009  8383 solver.cpp:228] Iteration 64400, loss = 0.000298124
I0811 15:15:15.409065  8383 solver.cpp:244]     Train net output #0: loss = 0.000298124 (* 1 = 0.000298124 loss)
I0811 15:15:15.409071  8383 sgd_solver.cpp:106] Iteration 64400, lr = 0.000339638
I0811 15:15:18.663503  8383 solver.cpp:337] Iteration 64500, Testing net (#0)
I0811 15:15:23.256060  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:15:25.408546  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895484
I0811 15:15:25.408612  8383 solver.cpp:404]     Test net output #1: loss = 0.668952 (* 1 = 0.668952 loss)
I0811 15:15:25.418792  8383 solver.cpp:228] Iteration 64500, loss = 0.000191533
I0811 15:15:25.418819  8383 solver.cpp:244]     Train net output #0: loss = 0.000191533 (* 1 = 0.000191533 loss)
I0811 15:15:25.418838  8383 sgd_solver.cpp:106] Iteration 64500, lr = 0.000339336
I0811 15:15:28.640630  8383 solver.cpp:228] Iteration 64600, loss = 0.000142483
I0811 15:15:28.640674  8383 solver.cpp:244]     Train net output #0: loss = 0.000142483 (* 1 = 0.000142483 loss)
I0811 15:15:28.640681  8383 sgd_solver.cpp:106] Iteration 64600, lr = 0.000339035
I0811 15:15:31.905897  8383 solver.cpp:228] Iteration 64700, loss = 0.000192515
I0811 15:15:31.905937  8383 solver.cpp:244]     Train net output #0: loss = 0.000192515 (* 1 = 0.000192515 loss)
I0811 15:15:31.905943  8383 sgd_solver.cpp:106] Iteration 64700, lr = 0.000338735
I0811 15:15:35.191663  8383 solver.cpp:228] Iteration 64800, loss = 0.00026425
I0811 15:15:35.191702  8383 solver.cpp:244]     Train net output #0: loss = 0.00026425 (* 1 = 0.00026425 loss)
I0811 15:15:35.191709  8383 sgd_solver.cpp:106] Iteration 64800, lr = 0.000338435
I0811 15:15:38.480554  8383 solver.cpp:228] Iteration 64900, loss = 0.000109101
I0811 15:15:38.480604  8383 solver.cpp:244]     Train net output #0: loss = 0.000109101 (* 1 = 0.000109101 loss)
I0811 15:15:38.480612  8383 sgd_solver.cpp:106] Iteration 64900, lr = 0.000338136
I0811 15:15:41.727296  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_65000.caffemodel
I0811 15:15:42.103487  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_65000.solverstate
I0811 15:15:42.238534  8383 solver.cpp:337] Iteration 65000, Testing net (#0)
I0811 15:15:48.843921  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895709
I0811 15:15:48.843986  8383 solver.cpp:404]     Test net output #1: loss = 0.670198 (* 1 = 0.670198 loss)
I0811 15:15:48.856758  8383 solver.cpp:228] Iteration 65000, loss = 0.000120603
I0811 15:15:48.856813  8383 solver.cpp:244]     Train net output #0: loss = 0.000120603 (* 1 = 0.000120603 loss)
I0811 15:15:48.856832  8383 sgd_solver.cpp:106] Iteration 65000, lr = 0.000337838
I0811 15:15:52.092113  8383 solver.cpp:228] Iteration 65100, loss = 0.000182977
I0811 15:15:52.092149  8383 solver.cpp:244]     Train net output #0: loss = 0.000182977 (* 1 = 0.000182977 loss)
I0811 15:15:52.092155  8383 sgd_solver.cpp:106] Iteration 65100, lr = 0.00033754
I0811 15:15:55.384258  8383 solver.cpp:228] Iteration 65200, loss = 0.000115938
I0811 15:15:55.384294  8383 solver.cpp:244]     Train net output #0: loss = 0.000115938 (* 1 = 0.000115938 loss)
I0811 15:15:55.384301  8383 sgd_solver.cpp:106] Iteration 65200, lr = 0.000337243
I0811 15:15:58.688385  8383 solver.cpp:228] Iteration 65300, loss = 5.17848e-05
I0811 15:15:58.688426  8383 solver.cpp:244]     Train net output #0: loss = 5.17848e-05 (* 1 = 5.17848e-05 loss)
I0811 15:15:58.688433  8383 sgd_solver.cpp:106] Iteration 65300, lr = 0.000336946
I0811 15:16:01.947175  8383 solver.cpp:228] Iteration 65400, loss = 0.000262019
I0811 15:16:01.947208  8383 solver.cpp:244]     Train net output #0: loss = 0.000262019 (* 1 = 0.000262019 loss)
I0811 15:16:01.947214  8383 sgd_solver.cpp:106] Iteration 65400, lr = 0.00033665
I0811 15:16:05.187918  8383 solver.cpp:337] Iteration 65500, Testing net (#0)
I0811 15:16:11.611117  8383 solver.cpp:404]     Test net output #0: accuracy = 0.900355
I0811 15:16:11.611178  8383 solver.cpp:404]     Test net output #1: loss = 0.64097 (* 1 = 0.64097 loss)
I0811 15:16:11.621948  8383 solver.cpp:228] Iteration 65500, loss = 0.000108943
I0811 15:16:11.622012  8383 solver.cpp:244]     Train net output #0: loss = 0.000108943 (* 1 = 0.000108943 loss)
I0811 15:16:11.622036  8383 sgd_solver.cpp:106] Iteration 65500, lr = 0.000336355
I0811 15:16:14.867254  8383 solver.cpp:228] Iteration 65600, loss = 0.00015463
I0811 15:16:14.867300  8383 solver.cpp:244]     Train net output #0: loss = 0.00015463 (* 1 = 0.00015463 loss)
I0811 15:16:14.867305  8383 sgd_solver.cpp:106] Iteration 65600, lr = 0.00033606
I0811 15:16:18.167582  8383 solver.cpp:228] Iteration 65700, loss = 4.29621e-05
I0811 15:16:18.167634  8383 solver.cpp:244]     Train net output #0: loss = 4.29621e-05 (* 1 = 4.29621e-05 loss)
I0811 15:16:18.167642  8383 sgd_solver.cpp:106] Iteration 65700, lr = 0.000335766
I0811 15:16:21.473172  8383 solver.cpp:228] Iteration 65800, loss = 6.71363e-05
I0811 15:16:21.473220  8383 solver.cpp:244]     Train net output #0: loss = 6.71363e-05 (* 1 = 6.71363e-05 loss)
I0811 15:16:21.473232  8383 sgd_solver.cpp:106] Iteration 65800, lr = 0.000335473
I0811 15:16:24.725358  8383 solver.cpp:228] Iteration 65900, loss = 7.75547e-05
I0811 15:16:24.725397  8383 solver.cpp:244]     Train net output #0: loss = 7.75547e-05 (* 1 = 7.75547e-05 loss)
I0811 15:16:24.725404  8383 sgd_solver.cpp:106] Iteration 65900, lr = 0.00033518
I0811 15:16:27.994333  8383 solver.cpp:337] Iteration 66000, Testing net (#0)
I0811 15:16:28.384131  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:16:34.448225  8383 solver.cpp:404]     Test net output #0: accuracy = 0.901387
I0811 15:16:34.448310  8383 solver.cpp:404]     Test net output #1: loss = 0.634581 (* 1 = 0.634581 loss)
I0811 15:16:34.460681  8383 solver.cpp:228] Iteration 66000, loss = 8.80129e-05
I0811 15:16:34.460742  8383 solver.cpp:244]     Train net output #0: loss = 8.80129e-05 (* 1 = 8.80129e-05 loss)
I0811 15:16:34.460768  8383 sgd_solver.cpp:106] Iteration 66000, lr = 0.000334887
I0811 15:16:37.679545  8383 solver.cpp:228] Iteration 66100, loss = 0.000155814
I0811 15:16:37.679586  8383 solver.cpp:244]     Train net output #0: loss = 0.000155814 (* 1 = 0.000155814 loss)
I0811 15:16:37.679592  8383 sgd_solver.cpp:106] Iteration 66100, lr = 0.000334596
I0811 15:16:40.906581  8383 solver.cpp:228] Iteration 66200, loss = 0.000152792
I0811 15:16:40.906635  8383 solver.cpp:244]     Train net output #0: loss = 0.000152792 (* 1 = 0.000152792 loss)
I0811 15:16:40.906641  8383 sgd_solver.cpp:106] Iteration 66200, lr = 0.000334304
I0811 15:16:44.149389  8383 solver.cpp:228] Iteration 66300, loss = 5.80312e-05
I0811 15:16:44.149426  8383 solver.cpp:244]     Train net output #0: loss = 5.80312e-05 (* 1 = 5.80312e-05 loss)
I0811 15:16:44.149432  8383 sgd_solver.cpp:106] Iteration 66300, lr = 0.000334014
I0811 15:16:47.424641  8383 solver.cpp:228] Iteration 66400, loss = 4.76518e-05
I0811 15:16:47.424680  8383 solver.cpp:244]     Train net output #0: loss = 4.76518e-05 (* 1 = 4.76518e-05 loss)
I0811 15:16:47.424686  8383 sgd_solver.cpp:106] Iteration 66400, lr = 0.000333724
I0811 15:16:50.682142  8383 solver.cpp:337] Iteration 66500, Testing net (#0)
I0811 15:16:57.165380  8383 solver.cpp:404]     Test net output #0: accuracy = 0.894161
I0811 15:16:57.165439  8383 solver.cpp:404]     Test net output #1: loss = 0.688564 (* 1 = 0.688564 loss)
I0811 15:16:57.179169  8383 solver.cpp:228] Iteration 66500, loss = 0.000227037
I0811 15:16:57.179203  8383 solver.cpp:244]     Train net output #0: loss = 0.000227037 (* 1 = 0.000227037 loss)
I0811 15:16:57.179217  8383 sgd_solver.cpp:106] Iteration 66500, lr = 0.000333434
I0811 15:17:00.404841  8383 solver.cpp:228] Iteration 66600, loss = 0.000123753
I0811 15:17:00.404883  8383 solver.cpp:244]     Train net output #0: loss = 0.000123753 (* 1 = 0.000123753 loss)
I0811 15:17:00.404891  8383 sgd_solver.cpp:106] Iteration 66600, lr = 0.000333146
I0811 15:17:03.690029  8383 solver.cpp:228] Iteration 66700, loss = 0.000562763
I0811 15:17:03.690068  8383 solver.cpp:244]     Train net output #0: loss = 0.000562763 (* 1 = 0.000562763 loss)
I0811 15:17:03.690074  8383 sgd_solver.cpp:106] Iteration 66700, lr = 0.000332857
I0811 15:17:06.938886  8383 solver.cpp:228] Iteration 66800, loss = 0.000166118
I0811 15:17:06.938926  8383 solver.cpp:244]     Train net output #0: loss = 0.000166118 (* 1 = 0.000166118 loss)
I0811 15:17:06.938933  8383 sgd_solver.cpp:106] Iteration 66800, lr = 0.00033257
I0811 15:17:10.204296  8383 solver.cpp:228] Iteration 66900, loss = 6.45985e-05
I0811 15:17:10.204331  8383 solver.cpp:244]     Train net output #0: loss = 6.45985e-05 (* 1 = 6.45985e-05 loss)
I0811 15:17:10.204339  8383 sgd_solver.cpp:106] Iteration 66900, lr = 0.000332283
I0811 15:17:13.461808  8383 solver.cpp:337] Iteration 67000, Testing net (#0)
I0811 15:17:19.833962  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895322
I0811 15:17:19.834022  8383 solver.cpp:404]     Test net output #1: loss = 0.685308 (* 1 = 0.685308 loss)
I0811 15:17:19.844476  8383 solver.cpp:228] Iteration 67000, loss = 0.000517791
I0811 15:17:19.844574  8383 solver.cpp:244]     Train net output #0: loss = 0.000517791 (* 1 = 0.000517791 loss)
I0811 15:17:19.844604  8383 sgd_solver.cpp:106] Iteration 67000, lr = 0.000331996
I0811 15:17:23.068260  8383 solver.cpp:228] Iteration 67100, loss = 0.00038894
I0811 15:17:23.068300  8383 solver.cpp:244]     Train net output #0: loss = 0.00038894 (* 1 = 0.00038894 loss)
I0811 15:17:23.068307  8383 sgd_solver.cpp:106] Iteration 67100, lr = 0.00033171
I0811 15:17:26.307660  8383 solver.cpp:228] Iteration 67200, loss = 6.43921e-05
I0811 15:17:26.307699  8383 solver.cpp:244]     Train net output #0: loss = 6.43921e-05 (* 1 = 6.43921e-05 loss)
I0811 15:17:26.307706  8383 sgd_solver.cpp:106] Iteration 67200, lr = 0.000331425
I0811 15:17:29.564666  8383 solver.cpp:228] Iteration 67300, loss = 0.000438422
I0811 15:17:29.564714  8383 solver.cpp:244]     Train net output #0: loss = 0.000438422 (* 1 = 0.000438422 loss)
I0811 15:17:29.564721  8383 sgd_solver.cpp:106] Iteration 67300, lr = 0.00033114
I0811 15:17:29.824347  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:17:32.841472  8383 solver.cpp:228] Iteration 67400, loss = 0.000109192
I0811 15:17:32.841512  8383 solver.cpp:244]     Train net output #0: loss = 0.000109192 (* 1 = 0.000109192 loss)
I0811 15:17:32.841518  8383 sgd_solver.cpp:106] Iteration 67400, lr = 0.000330856
I0811 15:17:36.113935  8383 solver.cpp:337] Iteration 67500, Testing net (#0)
I0811 15:17:42.774396  8383 solver.cpp:404]     Test net output #0: accuracy = 0.90229
I0811 15:17:42.774474  8383 solver.cpp:404]     Test net output #1: loss = 0.633323 (* 1 = 0.633323 loss)
I0811 15:17:42.787745  8383 solver.cpp:228] Iteration 67500, loss = 6.07567e-05
I0811 15:17:42.787781  8383 solver.cpp:244]     Train net output #0: loss = 6.07567e-05 (* 1 = 6.07567e-05 loss)
I0811 15:17:42.787798  8383 sgd_solver.cpp:106] Iteration 67500, lr = 0.000330572
I0811 15:17:46.005831  8383 solver.cpp:228] Iteration 67600, loss = 8.68104e-05
I0811 15:17:46.005905  8383 solver.cpp:244]     Train net output #0: loss = 8.68104e-05 (* 1 = 8.68104e-05 loss)
I0811 15:17:46.005920  8383 sgd_solver.cpp:106] Iteration 67600, lr = 0.000330289
I0811 15:17:49.265252  8383 solver.cpp:228] Iteration 67700, loss = 0.000121061
I0811 15:17:49.265292  8383 solver.cpp:244]     Train net output #0: loss = 0.000121061 (* 1 = 0.000121061 loss)
I0811 15:17:49.265300  8383 sgd_solver.cpp:106] Iteration 67700, lr = 0.000330007
I0811 15:17:52.543440  8383 solver.cpp:228] Iteration 67800, loss = 0.000192966
I0811 15:17:52.543480  8383 solver.cpp:244]     Train net output #0: loss = 0.000192966 (* 1 = 0.000192966 loss)
I0811 15:17:52.543488  8383 sgd_solver.cpp:106] Iteration 67800, lr = 0.000329725
I0811 15:17:55.815274  8383 solver.cpp:228] Iteration 67900, loss = 0.000221485
I0811 15:17:55.815325  8383 solver.cpp:244]     Train net output #0: loss = 0.000221485 (* 1 = 0.000221485 loss)
I0811 15:17:55.815331  8383 sgd_solver.cpp:106] Iteration 67900, lr = 0.000329443
I0811 15:17:59.027371  8383 solver.cpp:337] Iteration 68000, Testing net (#0)
I0811 15:18:05.900643  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898516
I0811 15:18:05.900724  8383 solver.cpp:404]     Test net output #1: loss = 0.663724 (* 1 = 0.663724 loss)
I0811 15:18:05.911156  8383 solver.cpp:228] Iteration 68000, loss = 4.86252e-05
I0811 15:18:05.911193  8383 solver.cpp:244]     Train net output #0: loss = 4.86252e-05 (* 1 = 4.86252e-05 loss)
I0811 15:18:05.911217  8383 sgd_solver.cpp:106] Iteration 68000, lr = 0.000329163
I0811 15:18:09.110152  8383 solver.cpp:228] Iteration 68100, loss = 0.000446482
I0811 15:18:09.110198  8383 solver.cpp:244]     Train net output #0: loss = 0.000446482 (* 1 = 0.000446482 loss)
I0811 15:18:09.110204  8383 sgd_solver.cpp:106] Iteration 68100, lr = 0.000328882
I0811 15:18:12.350780  8383 solver.cpp:228] Iteration 68200, loss = 7.63029e-05
I0811 15:18:12.350822  8383 solver.cpp:244]     Train net output #0: loss = 7.63029e-05 (* 1 = 7.63029e-05 loss)
I0811 15:18:12.350828  8383 sgd_solver.cpp:106] Iteration 68200, lr = 0.000328603
I0811 15:18:15.672976  8383 solver.cpp:228] Iteration 68300, loss = 0.000103091
I0811 15:18:15.673024  8383 solver.cpp:244]     Train net output #0: loss = 0.000103091 (* 1 = 0.000103091 loss)
I0811 15:18:15.673034  8383 sgd_solver.cpp:106] Iteration 68300, lr = 0.000328324
I0811 15:18:18.981549  8383 solver.cpp:228] Iteration 68400, loss = 0.00015216
I0811 15:18:18.981590  8383 solver.cpp:244]     Train net output #0: loss = 0.00015216 (* 1 = 0.00015216 loss)
I0811 15:18:18.981596  8383 sgd_solver.cpp:106] Iteration 68400, lr = 0.000328045
I0811 15:18:22.236724  8383 solver.cpp:337] Iteration 68500, Testing net (#0)
I0811 15:18:25.861398  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:18:28.669549  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896355
I0811 15:18:28.669618  8383 solver.cpp:404]     Test net output #1: loss = 0.684006 (* 1 = 0.684006 loss)
I0811 15:18:28.682864  8383 solver.cpp:228] Iteration 68500, loss = 0.000163592
I0811 15:18:28.682934  8383 solver.cpp:244]     Train net output #0: loss = 0.000163592 (* 1 = 0.000163592 loss)
I0811 15:18:28.682957  8383 sgd_solver.cpp:106] Iteration 68500, lr = 0.000327767
I0811 15:18:31.922266  8383 solver.cpp:228] Iteration 68600, loss = 3.36544e-05
I0811 15:18:31.922302  8383 solver.cpp:244]     Train net output #0: loss = 3.36544e-05 (* 1 = 3.36544e-05 loss)
I0811 15:18:31.922309  8383 sgd_solver.cpp:106] Iteration 68600, lr = 0.000327489
I0811 15:18:35.186444  8383 solver.cpp:228] Iteration 68700, loss = 7.45795e-05
I0811 15:18:35.186492  8383 solver.cpp:244]     Train net output #0: loss = 7.45795e-05 (* 1 = 7.45795e-05 loss)
I0811 15:18:35.186498  8383 sgd_solver.cpp:106] Iteration 68700, lr = 0.000327212
I0811 15:18:38.482005  8383 solver.cpp:228] Iteration 68800, loss = 5.18747e-05
I0811 15:18:38.482045  8383 solver.cpp:244]     Train net output #0: loss = 5.18747e-05 (* 1 = 5.18747e-05 loss)
I0811 15:18:38.482051  8383 sgd_solver.cpp:106] Iteration 68800, lr = 0.000326936
I0811 15:18:41.766247  8383 solver.cpp:228] Iteration 68900, loss = 0.000211111
I0811 15:18:41.766265  8383 solver.cpp:244]     Train net output #0: loss = 0.000211111 (* 1 = 0.000211111 loss)
I0811 15:18:41.766271  8383 sgd_solver.cpp:106] Iteration 68900, lr = 0.00032666
I0811 15:18:44.977278  8383 solver.cpp:337] Iteration 69000, Testing net (#0)
I0811 15:18:52.235182  8383 solver.cpp:404]     Test net output #0: accuracy = 0.894677
I0811 15:18:52.235232  8383 solver.cpp:404]     Test net output #1: loss = 0.69739 (* 1 = 0.69739 loss)
I0811 15:18:52.247557  8383 solver.cpp:228] Iteration 69000, loss = 0.000181821
I0811 15:18:52.247591  8383 solver.cpp:244]     Train net output #0: loss = 0.000181821 (* 1 = 0.000181821 loss)
I0811 15:18:52.247602  8383 sgd_solver.cpp:106] Iteration 69000, lr = 0.000326385
I0811 15:18:55.422837  8383 solver.cpp:228] Iteration 69100, loss = 9.37745e-05
I0811 15:18:55.422874  8383 solver.cpp:244]     Train net output #0: loss = 9.37745e-05 (* 1 = 9.37745e-05 loss)
I0811 15:18:55.422881  8383 sgd_solver.cpp:106] Iteration 69100, lr = 0.00032611
I0811 15:18:58.689442  8383 solver.cpp:228] Iteration 69200, loss = 0.000171317
I0811 15:18:58.689492  8383 solver.cpp:244]     Train net output #0: loss = 0.000171317 (* 1 = 0.000171317 loss)
I0811 15:18:58.689502  8383 sgd_solver.cpp:106] Iteration 69200, lr = 0.000325836
I0811 15:19:01.937579  8383 solver.cpp:228] Iteration 69300, loss = 7.36699e-05
I0811 15:19:01.937620  8383 solver.cpp:244]     Train net output #0: loss = 7.36699e-05 (* 1 = 7.36699e-05 loss)
I0811 15:19:01.937626  8383 sgd_solver.cpp:106] Iteration 69300, lr = 0.000325562
I0811 15:19:05.212179  8383 solver.cpp:228] Iteration 69400, loss = 8.28279e-05
I0811 15:19:05.212211  8383 solver.cpp:244]     Train net output #0: loss = 8.28279e-05 (* 1 = 8.28279e-05 loss)
I0811 15:19:05.212218  8383 sgd_solver.cpp:106] Iteration 69400, lr = 0.000325289
I0811 15:19:08.461778  8383 solver.cpp:337] Iteration 69500, Testing net (#0)
I0811 15:19:15.276057  8383 solver.cpp:404]     Test net output #0: accuracy = 0.900613
I0811 15:19:15.276103  8383 solver.cpp:404]     Test net output #1: loss = 0.65502 (* 1 = 0.65502 loss)
I0811 15:19:15.288553  8383 solver.cpp:228] Iteration 69500, loss = 0.000226171
I0811 15:19:15.288584  8383 solver.cpp:244]     Train net output #0: loss = 0.000226171 (* 1 = 0.000226171 loss)
I0811 15:19:15.288597  8383 sgd_solver.cpp:106] Iteration 69500, lr = 0.000325016
I0811 15:19:18.500527  8383 solver.cpp:228] Iteration 69600, loss = 9.97321e-05
I0811 15:19:18.500561  8383 solver.cpp:244]     Train net output #0: loss = 9.97321e-05 (* 1 = 9.97321e-05 loss)
I0811 15:19:18.500568  8383 sgd_solver.cpp:106] Iteration 69600, lr = 0.000324744
I0811 15:19:21.727226  8383 solver.cpp:228] Iteration 69700, loss = 4.26691e-05
I0811 15:19:21.727277  8383 solver.cpp:244]     Train net output #0: loss = 4.26691e-05 (* 1 = 4.26691e-05 loss)
I0811 15:19:21.727288  8383 sgd_solver.cpp:106] Iteration 69700, lr = 0.000324473
I0811 15:19:25.041901  8383 solver.cpp:228] Iteration 69800, loss = 0.000204722
I0811 15:19:25.041949  8383 solver.cpp:244]     Train net output #0: loss = 0.000204722 (* 1 = 0.000204722 loss)
I0811 15:19:25.041955  8383 sgd_solver.cpp:106] Iteration 69800, lr = 0.000324202
I0811 15:19:28.311283  8383 solver.cpp:228] Iteration 69900, loss = 6.5411e-05
I0811 15:19:28.311321  8383 solver.cpp:244]     Train net output #0: loss = 6.5411e-05 (* 1 = 6.5411e-05 loss)
I0811 15:19:28.311328  8383 sgd_solver.cpp:106] Iteration 69900, lr = 0.000323931
I0811 15:19:31.537294  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_70000.caffemodel
I0811 15:19:31.911097  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_70000.solverstate
I0811 15:19:32.043355  8383 solver.cpp:337] Iteration 70000, Testing net (#0)
I0811 15:19:33.420133  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:19:38.788836  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897
I0811 15:19:38.788902  8383 solver.cpp:404]     Test net output #1: loss = 0.681739 (* 1 = 0.681739 loss)
I0811 15:19:38.801765  8383 solver.cpp:228] Iteration 70000, loss = 0.000102263
I0811 15:19:38.801790  8383 solver.cpp:244]     Train net output #0: loss = 0.000102263 (* 1 = 0.000102263 loss)
I0811 15:19:38.801803  8383 sgd_solver.cpp:106] Iteration 70000, lr = 0.000323661
I0811 15:19:42.036265  8383 solver.cpp:228] Iteration 70100, loss = 5.68092e-05
I0811 15:19:42.036311  8383 solver.cpp:244]     Train net output #0: loss = 5.68092e-05 (* 1 = 5.68092e-05 loss)
I0811 15:19:42.036317  8383 sgd_solver.cpp:106] Iteration 70100, lr = 0.000323392
I0811 15:19:45.322726  8383 solver.cpp:228] Iteration 70200, loss = 0.000102026
I0811 15:19:45.322764  8383 solver.cpp:244]     Train net output #0: loss = 0.000102026 (* 1 = 0.000102026 loss)
I0811 15:19:45.322772  8383 sgd_solver.cpp:106] Iteration 70200, lr = 0.000323123
I0811 15:19:48.585489  8383 solver.cpp:228] Iteration 70300, loss = 5.54997e-05
I0811 15:19:48.585530  8383 solver.cpp:244]     Train net output #0: loss = 5.54997e-05 (* 1 = 5.54997e-05 loss)
I0811 15:19:48.585536  8383 sgd_solver.cpp:106] Iteration 70300, lr = 0.000322854
I0811 15:19:51.868116  8383 solver.cpp:228] Iteration 70400, loss = 5.85734e-05
I0811 15:19:51.868166  8383 solver.cpp:244]     Train net output #0: loss = 5.85734e-05 (* 1 = 5.85734e-05 loss)
I0811 15:19:51.868176  8383 sgd_solver.cpp:106] Iteration 70400, lr = 0.000322587
I0811 15:19:55.100810  8383 solver.cpp:337] Iteration 70500, Testing net (#0)
I0811 15:20:02.026180  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897032
I0811 15:20:02.026257  8383 solver.cpp:404]     Test net output #1: loss = 0.684438 (* 1 = 0.684438 loss)
I0811 15:20:02.039388  8383 solver.cpp:228] Iteration 70500, loss = 0.000325969
I0811 15:20:02.039422  8383 solver.cpp:244]     Train net output #0: loss = 0.000325969 (* 1 = 0.000325969 loss)
I0811 15:20:02.039441  8383 sgd_solver.cpp:106] Iteration 70500, lr = 0.000322319
I0811 15:20:05.261869  8383 solver.cpp:228] Iteration 70600, loss = 5.51069e-05
I0811 15:20:05.261909  8383 solver.cpp:244]     Train net output #0: loss = 5.51069e-05 (* 1 = 5.51069e-05 loss)
I0811 15:20:05.261915  8383 sgd_solver.cpp:106] Iteration 70600, lr = 0.000322052
I0811 15:20:08.515501  8383 solver.cpp:228] Iteration 70700, loss = 0.0001263
I0811 15:20:08.515539  8383 solver.cpp:244]     Train net output #0: loss = 0.0001263 (* 1 = 0.0001263 loss)
I0811 15:20:08.515545  8383 sgd_solver.cpp:106] Iteration 70700, lr = 0.000321786
I0811 15:20:11.766314  8383 solver.cpp:228] Iteration 70800, loss = 5.95936e-05
I0811 15:20:11.766362  8383 solver.cpp:244]     Train net output #0: loss = 5.95936e-05 (* 1 = 5.95936e-05 loss)
I0811 15:20:11.766371  8383 sgd_solver.cpp:106] Iteration 70800, lr = 0.00032152
I0811 15:20:15.062515  8383 solver.cpp:228] Iteration 70900, loss = 0.000137325
I0811 15:20:15.062554  8383 solver.cpp:244]     Train net output #0: loss = 0.000137325 (* 1 = 0.000137325 loss)
I0811 15:20:15.062561  8383 sgd_solver.cpp:106] Iteration 70900, lr = 0.000321255
I0811 15:20:18.292529  8383 solver.cpp:337] Iteration 71000, Testing net (#0)
I0811 15:20:24.691673  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:20:25.039666  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89629
I0811 15:20:25.039768  8383 solver.cpp:404]     Test net output #1: loss = 0.693382 (* 1 = 0.693382 loss)
I0811 15:20:25.054162  8383 solver.cpp:228] Iteration 71000, loss = 0.000148929
I0811 15:20:25.054203  8383 solver.cpp:244]     Train net output #0: loss = 0.000148929 (* 1 = 0.000148929 loss)
I0811 15:20:25.054214  8383 sgd_solver.cpp:106] Iteration 71000, lr = 0.00032099
I0811 15:20:28.267585  8383 solver.cpp:228] Iteration 71100, loss = 9.14886e-05
I0811 15:20:28.267624  8383 solver.cpp:244]     Train net output #0: loss = 9.14886e-05 (* 1 = 9.14886e-05 loss)
I0811 15:20:28.267632  8383 sgd_solver.cpp:106] Iteration 71100, lr = 0.000320726
I0811 15:20:31.547783  8383 solver.cpp:228] Iteration 71200, loss = 0.000640279
I0811 15:20:31.547821  8383 solver.cpp:244]     Train net output #0: loss = 0.000640279 (* 1 = 0.000640279 loss)
I0811 15:20:31.547828  8383 sgd_solver.cpp:106] Iteration 71200, lr = 0.000320462
I0811 15:20:34.775135  8383 solver.cpp:228] Iteration 71300, loss = 0.000103568
I0811 15:20:34.775189  8383 solver.cpp:244]     Train net output #0: loss = 0.000103568 (* 1 = 0.000103568 loss)
I0811 15:20:34.775199  8383 sgd_solver.cpp:106] Iteration 71300, lr = 0.000320199
I0811 15:20:38.036104  8383 solver.cpp:228] Iteration 71400, loss = 5.51502e-05
I0811 15:20:38.036146  8383 solver.cpp:244]     Train net output #0: loss = 5.51502e-05 (* 1 = 5.51502e-05 loss)
I0811 15:20:38.036152  8383 sgd_solver.cpp:106] Iteration 71400, lr = 0.000319936
I0811 15:20:41.257112  8383 solver.cpp:337] Iteration 71500, Testing net (#0)
I0811 15:20:48.315199  8383 solver.cpp:404]     Test net output #0: accuracy = 0.901129
I0811 15:20:48.315244  8383 solver.cpp:404]     Test net output #1: loss = 0.656108 (* 1 = 0.656108 loss)
I0811 15:20:48.327617  8383 solver.cpp:228] Iteration 71500, loss = 9.71065e-05
I0811 15:20:48.327649  8383 solver.cpp:244]     Train net output #0: loss = 9.71065e-05 (* 1 = 9.71065e-05 loss)
I0811 15:20:48.327662  8383 sgd_solver.cpp:106] Iteration 71500, lr = 0.000319674
I0811 15:20:51.520606  8383 solver.cpp:228] Iteration 71600, loss = 0.000846166
I0811 15:20:51.520647  8383 solver.cpp:244]     Train net output #0: loss = 0.000846166 (* 1 = 0.000846166 loss)
I0811 15:20:51.520653  8383 sgd_solver.cpp:106] Iteration 71600, lr = 0.000319412
I0811 15:20:54.789023  8383 solver.cpp:228] Iteration 71700, loss = 6.84306e-05
I0811 15:20:54.789078  8383 solver.cpp:244]     Train net output #0: loss = 6.84306e-05 (* 1 = 6.84306e-05 loss)
I0811 15:20:54.789084  8383 sgd_solver.cpp:106] Iteration 71700, lr = 0.00031915
I0811 15:20:58.097980  8383 solver.cpp:228] Iteration 71800, loss = 5.0393e-05
I0811 15:20:58.098018  8383 solver.cpp:244]     Train net output #0: loss = 5.0393e-05 (* 1 = 5.0393e-05 loss)
I0811 15:20:58.098026  8383 sgd_solver.cpp:106] Iteration 71800, lr = 0.00031889
I0811 15:21:01.403044  8383 solver.cpp:228] Iteration 71900, loss = 0.00025932
I0811 15:21:01.403084  8383 solver.cpp:244]     Train net output #0: loss = 0.00025932 (* 1 = 0.00025932 loss)
I0811 15:21:01.403090  8383 sgd_solver.cpp:106] Iteration 71900, lr = 0.000318629
I0811 15:21:04.648933  8383 solver.cpp:337] Iteration 72000, Testing net (#0)
I0811 15:21:11.329695  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896903
I0811 15:21:11.329749  8383 solver.cpp:404]     Test net output #1: loss = 0.692247 (* 1 = 0.692247 loss)
I0811 15:21:11.339879  8383 solver.cpp:228] Iteration 72000, loss = 6.91942e-05
I0811 15:21:11.339905  8383 solver.cpp:244]     Train net output #0: loss = 6.91942e-05 (* 1 = 6.91942e-05 loss)
I0811 15:21:11.339918  8383 sgd_solver.cpp:106] Iteration 72000, lr = 0.00031837
I0811 15:21:14.549383  8383 solver.cpp:228] Iteration 72100, loss = 0.000221766
I0811 15:21:14.549418  8383 solver.cpp:244]     Train net output #0: loss = 0.000221766 (* 1 = 0.000221766 loss)
I0811 15:21:14.549424  8383 sgd_solver.cpp:106] Iteration 72100, lr = 0.00031811
I0811 15:21:17.833282  8383 solver.cpp:228] Iteration 72200, loss = 4.68491e-05
I0811 15:21:17.833326  8383 solver.cpp:244]     Train net output #0: loss = 4.68491e-05 (* 1 = 4.68491e-05 loss)
I0811 15:21:17.833333  8383 sgd_solver.cpp:106] Iteration 72200, lr = 0.000317852
I0811 15:21:21.078470  8383 solver.cpp:228] Iteration 72300, loss = 8.04228e-05
I0811 15:21:21.078521  8383 solver.cpp:244]     Train net output #0: loss = 8.04228e-05 (* 1 = 8.04228e-05 loss)
I0811 15:21:21.078528  8383 sgd_solver.cpp:106] Iteration 72300, lr = 0.000317593
I0811 15:21:24.335814  8383 solver.cpp:228] Iteration 72400, loss = 3.8213e-05
I0811 15:21:24.335850  8383 solver.cpp:244]     Train net output #0: loss = 3.8213e-05 (* 1 = 3.8213e-05 loss)
I0811 15:21:24.335855  8383 sgd_solver.cpp:106] Iteration 72400, lr = 0.000317335
I0811 15:21:27.577891  8383 solver.cpp:337] Iteration 72500, Testing net (#0)
I0811 15:21:32.115880  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:21:34.043035  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896097
I0811 15:21:34.043112  8383 solver.cpp:404]     Test net output #1: loss = 0.699317 (* 1 = 0.699317 loss)
I0811 15:21:34.056340  8383 solver.cpp:228] Iteration 72500, loss = 0.00014748
I0811 15:21:34.056406  8383 solver.cpp:244]     Train net output #0: loss = 0.00014748 (* 1 = 0.00014748 loss)
I0811 15:21:34.056429  8383 sgd_solver.cpp:106] Iteration 72500, lr = 0.000317078
I0811 15:21:37.307705  8383 solver.cpp:228] Iteration 72600, loss = 0.000228195
I0811 15:21:37.307745  8383 solver.cpp:244]     Train net output #0: loss = 0.000228195 (* 1 = 0.000228195 loss)
I0811 15:21:37.307752  8383 sgd_solver.cpp:106] Iteration 72600, lr = 0.000316821
I0811 15:21:40.565033  8383 solver.cpp:228] Iteration 72700, loss = 7.7754e-05
I0811 15:21:40.565080  8383 solver.cpp:244]     Train net output #0: loss = 7.7754e-05 (* 1 = 7.7754e-05 loss)
I0811 15:21:40.565088  8383 sgd_solver.cpp:106] Iteration 72700, lr = 0.000316565
I0811 15:21:43.831748  8383 solver.cpp:228] Iteration 72800, loss = 7.63282e-05
I0811 15:21:43.831786  8383 solver.cpp:244]     Train net output #0: loss = 7.63282e-05 (* 1 = 7.63282e-05 loss)
I0811 15:21:43.831794  8383 sgd_solver.cpp:106] Iteration 72800, lr = 0.000316309
I0811 15:21:47.060174  8383 solver.cpp:228] Iteration 72900, loss = 6.18974e-05
I0811 15:21:47.060223  8383 solver.cpp:244]     Train net output #0: loss = 6.18974e-05 (* 1 = 6.18974e-05 loss)
I0811 15:21:47.060230  8383 sgd_solver.cpp:106] Iteration 72900, lr = 0.000316054
I0811 15:21:50.325572  8383 solver.cpp:337] Iteration 73000, Testing net (#0)
I0811 15:21:56.907905  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898129
I0811 15:21:56.907968  8383 solver.cpp:404]     Test net output #1: loss = 0.684614 (* 1 = 0.684614 loss)
I0811 15:21:56.920275  8383 solver.cpp:228] Iteration 73000, loss = 0.000131989
I0811 15:21:56.920312  8383 solver.cpp:244]     Train net output #0: loss = 0.000131989 (* 1 = 0.000131989 loss)
I0811 15:21:56.920336  8383 sgd_solver.cpp:106] Iteration 73000, lr = 0.000315799
I0811 15:22:00.139750  8383 solver.cpp:228] Iteration 73100, loss = 0.000298658
I0811 15:22:00.139799  8383 solver.cpp:244]     Train net output #0: loss = 0.000298658 (* 1 = 0.000298658 loss)
I0811 15:22:00.139806  8383 sgd_solver.cpp:106] Iteration 73100, lr = 0.000315544
I0811 15:22:03.396832  8383 solver.cpp:228] Iteration 73200, loss = 7.29586e-05
I0811 15:22:03.396875  8383 solver.cpp:244]     Train net output #0: loss = 7.29586e-05 (* 1 = 7.29586e-05 loss)
I0811 15:22:03.396888  8383 sgd_solver.cpp:106] Iteration 73200, lr = 0.00031529
I0811 15:22:06.674376  8383 solver.cpp:228] Iteration 73300, loss = 0.000269016
I0811 15:22:06.674396  8383 solver.cpp:244]     Train net output #0: loss = 0.000269016 (* 1 = 0.000269016 loss)
I0811 15:22:06.674402  8383 sgd_solver.cpp:106] Iteration 73300, lr = 0.000315037
I0811 15:22:09.956485  8383 solver.cpp:228] Iteration 73400, loss = 0.000110208
I0811 15:22:09.956559  8383 solver.cpp:244]     Train net output #0: loss = 0.000110208 (* 1 = 0.000110208 loss)
I0811 15:22:09.956574  8383 sgd_solver.cpp:106] Iteration 73400, lr = 0.000314784
I0811 15:22:13.244089  8383 solver.cpp:337] Iteration 73500, Testing net (#0)
I0811 15:22:19.820756  8383 solver.cpp:404]     Test net output #0: accuracy = 0.90071
I0811 15:22:19.820804  8383 solver.cpp:404]     Test net output #1: loss = 0.669931 (* 1 = 0.669931 loss)
I0811 15:22:19.830901  8383 solver.cpp:228] Iteration 73500, loss = 3.49577e-05
I0811 15:22:19.830934  8383 solver.cpp:244]     Train net output #0: loss = 3.49577e-05 (* 1 = 3.49577e-05 loss)
I0811 15:22:19.830945  8383 sgd_solver.cpp:106] Iteration 73500, lr = 0.000314531
I0811 15:22:23.062338  8383 solver.cpp:228] Iteration 73600, loss = 0.000121309
I0811 15:22:23.062387  8383 solver.cpp:244]     Train net output #0: loss = 0.000121309 (* 1 = 0.000121309 loss)
I0811 15:22:23.062397  8383 sgd_solver.cpp:106] Iteration 73600, lr = 0.000314279
I0811 15:22:26.313709  8383 solver.cpp:228] Iteration 73700, loss = 0.000187241
I0811 15:22:26.313760  8383 solver.cpp:244]     Train net output #0: loss = 0.000187241 (* 1 = 0.000187241 loss)
I0811 15:22:26.313766  8383 sgd_solver.cpp:106] Iteration 73700, lr = 0.000314028
I0811 15:22:29.592913  8383 solver.cpp:228] Iteration 73800, loss = 5.51595e-05
I0811 15:22:29.592934  8383 solver.cpp:244]     Train net output #0: loss = 5.51595e-05 (* 1 = 5.51595e-05 loss)
I0811 15:22:29.592941  8383 sgd_solver.cpp:106] Iteration 73800, lr = 0.000313777
I0811 15:22:32.888766  8383 solver.cpp:228] Iteration 73900, loss = 2.86785e-05
I0811 15:22:32.888800  8383 solver.cpp:244]     Train net output #0: loss = 2.86785e-05 (* 1 = 2.86785e-05 loss)
I0811 15:22:32.888806  8383 sgd_solver.cpp:106] Iteration 73900, lr = 0.000313526
I0811 15:22:36.152711  8383 solver.cpp:337] Iteration 74000, Testing net (#0)
I0811 15:22:39.033571  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:22:42.640823  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896548
I0811 15:22:42.640887  8383 solver.cpp:404]     Test net output #1: loss = 0.70155 (* 1 = 0.70155 loss)
I0811 15:22:42.651033  8383 solver.cpp:228] Iteration 74000, loss = 6.61624e-05
I0811 15:22:42.651067  8383 solver.cpp:244]     Train net output #0: loss = 6.61624e-05 (* 1 = 6.61624e-05 loss)
I0811 15:22:42.651078  8383 sgd_solver.cpp:106] Iteration 74000, lr = 0.000313276
I0811 15:22:45.876524  8383 solver.cpp:228] Iteration 74100, loss = 3.01987e-05
I0811 15:22:45.876559  8383 solver.cpp:244]     Train net output #0: loss = 3.01987e-05 (* 1 = 3.01987e-05 loss)
I0811 15:22:45.876565  8383 sgd_solver.cpp:106] Iteration 74100, lr = 0.000313026
I0811 15:22:49.163152  8383 solver.cpp:228] Iteration 74200, loss = 0.000104564
I0811 15:22:49.163194  8383 solver.cpp:244]     Train net output #0: loss = 0.000104564 (* 1 = 0.000104564 loss)
I0811 15:22:49.163202  8383 sgd_solver.cpp:106] Iteration 74200, lr = 0.000312777
I0811 15:22:52.442600  8383 solver.cpp:228] Iteration 74300, loss = 4.81207e-05
I0811 15:22:52.442638  8383 solver.cpp:244]     Train net output #0: loss = 4.81207e-05 (* 1 = 4.81207e-05 loss)
I0811 15:22:52.442646  8383 sgd_solver.cpp:106] Iteration 74300, lr = 0.000312528
I0811 15:22:55.711319  8383 solver.cpp:228] Iteration 74400, loss = 3.83779e-05
I0811 15:22:55.711361  8383 solver.cpp:244]     Train net output #0: loss = 3.83779e-05 (* 1 = 3.83779e-05 loss)
I0811 15:22:55.711369  8383 sgd_solver.cpp:106] Iteration 74400, lr = 0.00031228
I0811 15:22:58.959457  8383 solver.cpp:337] Iteration 74500, Testing net (#0)
I0811 15:23:05.443965  8383 solver.cpp:404]     Test net output #0: accuracy = 0.894612
I0811 15:23:05.444031  8383 solver.cpp:404]     Test net output #1: loss = 0.713795 (* 1 = 0.713795 loss)
I0811 15:23:05.454242  8383 solver.cpp:228] Iteration 74500, loss = 0.00014583
I0811 15:23:05.454274  8383 solver.cpp:244]     Train net output #0: loss = 0.00014583 (* 1 = 0.00014583 loss)
I0811 15:23:05.454288  8383 sgd_solver.cpp:106] Iteration 74500, lr = 0.000312032
I0811 15:23:08.673805  8383 solver.cpp:228] Iteration 74600, loss = 3.58564e-05
I0811 15:23:08.673859  8383 solver.cpp:244]     Train net output #0: loss = 3.58564e-05 (* 1 = 3.58564e-05 loss)
I0811 15:23:08.673866  8383 sgd_solver.cpp:106] Iteration 74600, lr = 0.000311784
I0811 15:23:11.936297  8383 solver.cpp:228] Iteration 74700, loss = 7.14521e-05
I0811 15:23:11.936336  8383 solver.cpp:244]     Train net output #0: loss = 7.14521e-05 (* 1 = 7.14521e-05 loss)
I0811 15:23:11.936342  8383 sgd_solver.cpp:106] Iteration 74700, lr = 0.000311537
I0811 15:23:15.211845  8383 solver.cpp:228] Iteration 74800, loss = 0.000103252
I0811 15:23:15.211894  8383 solver.cpp:244]     Train net output #0: loss = 0.000103252 (* 1 = 0.000103252 loss)
I0811 15:23:15.211905  8383 sgd_solver.cpp:106] Iteration 74800, lr = 0.000311291
I0811 15:23:18.474781  8383 solver.cpp:228] Iteration 74900, loss = 0.000203153
I0811 15:23:18.474828  8383 solver.cpp:244]     Train net output #0: loss = 0.000203153 (* 1 = 0.000203153 loss)
I0811 15:23:18.474835  8383 sgd_solver.cpp:106] Iteration 74900, lr = 0.000311045
I0811 15:23:21.715126  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_75000.caffemodel
I0811 15:23:22.177891  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_75000.solverstate
I0811 15:23:22.317683  8383 solver.cpp:337] Iteration 75000, Testing net (#0)
I0811 15:23:29.132668  8383 solver.cpp:404]     Test net output #0: accuracy = 0.899387
I0811 15:23:29.132730  8383 solver.cpp:404]     Test net output #1: loss = 0.682941 (* 1 = 0.682941 loss)
I0811 15:23:29.145229  8383 solver.cpp:228] Iteration 75000, loss = 5.08889e-05
I0811 15:23:29.145259  8383 solver.cpp:244]     Train net output #0: loss = 5.08889e-05 (* 1 = 5.08889e-05 loss)
I0811 15:23:29.145274  8383 sgd_solver.cpp:106] Iteration 75000, lr = 0.000310799
I0811 15:23:32.333200  8383 solver.cpp:228] Iteration 75100, loss = 4.57054e-05
I0811 15:23:32.333243  8383 solver.cpp:244]     Train net output #0: loss = 4.57054e-05 (* 1 = 4.57054e-05 loss)
I0811 15:23:32.333250  8383 sgd_solver.cpp:106] Iteration 75100, lr = 0.000310554
I0811 15:23:35.602102  8383 solver.cpp:228] Iteration 75200, loss = 0.000309402
I0811 15:23:35.602170  8383 solver.cpp:244]     Train net output #0: loss = 0.000309402 (* 1 = 0.000309402 loss)
I0811 15:23:35.602176  8383 sgd_solver.cpp:106] Iteration 75200, lr = 0.000310309
I0811 15:23:38.855132  8383 solver.cpp:228] Iteration 75300, loss = 0.000496547
I0811 15:23:38.855178  8383 solver.cpp:244]     Train net output #0: loss = 0.000496547 (* 1 = 0.000496547 loss)
I0811 15:23:38.855185  8383 sgd_solver.cpp:106] Iteration 75300, lr = 0.000310065
I0811 15:23:42.122207  8383 solver.cpp:228] Iteration 75400, loss = 4.25948e-05
I0811 15:23:42.122462  8383 solver.cpp:244]     Train net output #0: loss = 4.25948e-05 (* 1 = 4.25948e-05 loss)
I0811 15:23:42.122468  8383 sgd_solver.cpp:106] Iteration 75400, lr = 0.000309821
I0811 15:23:45.358117  8383 solver.cpp:337] Iteration 75500, Testing net (#0)
I0811 15:23:46.980527  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:23:52.551702  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898645
I0811 15:23:52.551753  8383 solver.cpp:404]     Test net output #1: loss = 0.690783 (* 1 = 0.690783 loss)
I0811 15:23:52.564919  8383 solver.cpp:228] Iteration 75500, loss = 4.48232e-05
I0811 15:23:52.564949  8383 solver.cpp:244]     Train net output #0: loss = 4.48232e-05 (* 1 = 4.48232e-05 loss)
I0811 15:23:52.564976  8383 sgd_solver.cpp:106] Iteration 75500, lr = 0.000309578
I0811 15:23:55.770057  8383 solver.cpp:228] Iteration 75600, loss = 8.07741e-05
I0811 15:23:55.770117  8383 solver.cpp:244]     Train net output #0: loss = 8.07741e-05 (* 1 = 8.07741e-05 loss)
I0811 15:23:55.770125  8383 sgd_solver.cpp:106] Iteration 75600, lr = 0.000309335
I0811 15:23:59.010426  8383 solver.cpp:228] Iteration 75700, loss = 8.2713e-05
I0811 15:23:59.010465  8383 solver.cpp:244]     Train net output #0: loss = 8.2713e-05 (* 1 = 8.2713e-05 loss)
I0811 15:23:59.010471  8383 sgd_solver.cpp:106] Iteration 75700, lr = 0.000309093
I0811 15:24:02.303434  8383 solver.cpp:228] Iteration 75800, loss = 8.4871e-05
I0811 15:24:02.303493  8383 solver.cpp:244]     Train net output #0: loss = 8.4871e-05 (* 1 = 8.4871e-05 loss)
I0811 15:24:02.303499  8383 sgd_solver.cpp:106] Iteration 75800, lr = 0.000308851
I0811 15:24:05.564973  8383 solver.cpp:228] Iteration 75900, loss = 0.000115983
I0811 15:24:05.565042  8383 solver.cpp:244]     Train net output #0: loss = 0.000115983 (* 1 = 0.000115983 loss)
I0811 15:24:05.565049  8383 sgd_solver.cpp:106] Iteration 75900, lr = 0.000308609
I0811 15:24:08.804083  8383 solver.cpp:337] Iteration 76000, Testing net (#0)
I0811 15:24:15.942821  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896323
I0811 15:24:15.942883  8383 solver.cpp:404]     Test net output #1: loss = 0.707589 (* 1 = 0.707589 loss)
I0811 15:24:15.953596  8383 solver.cpp:228] Iteration 76000, loss = 4.3964e-05
I0811 15:24:15.953658  8383 solver.cpp:244]     Train net output #0: loss = 4.3964e-05 (* 1 = 4.3964e-05 loss)
I0811 15:24:15.953680  8383 sgd_solver.cpp:106] Iteration 76000, lr = 0.000308368
I0811 15:24:19.168676  8383 solver.cpp:228] Iteration 76100, loss = 8.54327e-05
I0811 15:24:19.168735  8383 solver.cpp:244]     Train net output #0: loss = 8.54327e-05 (* 1 = 8.54327e-05 loss)
I0811 15:24:19.168751  8383 sgd_solver.cpp:106] Iteration 76100, lr = 0.000308127
I0811 15:24:22.427359  8383 solver.cpp:228] Iteration 76200, loss = 4.7158e-05
I0811 15:24:22.427404  8383 solver.cpp:244]     Train net output #0: loss = 4.7158e-05 (* 1 = 4.7158e-05 loss)
I0811 15:24:22.427410  8383 sgd_solver.cpp:106] Iteration 76200, lr = 0.000307887
I0811 15:24:25.697296  8383 solver.cpp:228] Iteration 76300, loss = 0.00013923
I0811 15:24:25.697357  8383 solver.cpp:244]     Train net output #0: loss = 0.00013923 (* 1 = 0.00013923 loss)
I0811 15:24:25.697365  8383 sgd_solver.cpp:106] Iteration 76300, lr = 0.000307647
I0811 15:24:28.992260  8383 solver.cpp:228] Iteration 76400, loss = 0.000130345
I0811 15:24:28.992311  8383 solver.cpp:244]     Train net output #0: loss = 0.000130345 (* 1 = 0.000130345 loss)
I0811 15:24:28.992317  8383 sgd_solver.cpp:106] Iteration 76400, lr = 0.000307408
I0811 15:24:32.217490  8383 solver.cpp:337] Iteration 76500, Testing net (#0)
I0811 15:24:39.077086  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895355
I0811 15:24:39.077148  8383 solver.cpp:404]     Test net output #1: loss = 0.714925 (* 1 = 0.714925 loss)
I0811 15:24:39.091101  8383 solver.cpp:228] Iteration 76500, loss = 6.96362e-05
I0811 15:24:39.091151  8383 solver.cpp:244]     Train net output #0: loss = 6.96362e-05 (* 1 = 6.96362e-05 loss)
I0811 15:24:39.091169  8383 sgd_solver.cpp:106] Iteration 76500, lr = 0.000307169
I0811 15:24:42.327550  8383 solver.cpp:228] Iteration 76600, loss = 4.25647e-05
I0811 15:24:42.327589  8383 solver.cpp:244]     Train net output #0: loss = 4.25647e-05 (* 1 = 4.25647e-05 loss)
I0811 15:24:42.327594  8383 sgd_solver.cpp:106] Iteration 76600, lr = 0.00030693
I0811 15:24:45.565979  8383 solver.cpp:228] Iteration 76700, loss = 0.00017922
I0811 15:24:45.566022  8383 solver.cpp:244]     Train net output #0: loss = 0.00017922 (* 1 = 0.00017922 loss)
I0811 15:24:45.566028  8383 sgd_solver.cpp:106] Iteration 76700, lr = 0.000306692
I0811 15:24:48.826656  8383 solver.cpp:228] Iteration 76800, loss = 5.57356e-05
I0811 15:24:48.826702  8383 solver.cpp:244]     Train net output #0: loss = 5.57356e-05 (* 1 = 5.57356e-05 loss)
I0811 15:24:48.826709  8383 sgd_solver.cpp:106] Iteration 76800, lr = 0.000306454
I0811 15:24:49.676283  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:24:52.107050  8383 solver.cpp:228] Iteration 76900, loss = 0.000147025
I0811 15:24:52.107092  8383 solver.cpp:244]     Train net output #0: loss = 0.000147025 (* 1 = 0.000147025 loss)
I0811 15:24:52.107098  8383 sgd_solver.cpp:106] Iteration 76900, lr = 0.000306217
I0811 15:24:55.367641  8383 solver.cpp:337] Iteration 77000, Testing net (#0)
I0811 15:25:02.086961  8383 solver.cpp:404]     Test net output #0: accuracy = 0.899774
I0811 15:25:02.087016  8383 solver.cpp:404]     Test net output #1: loss = 0.684328 (* 1 = 0.684328 loss)
I0811 15:25:02.097806  8383 solver.cpp:228] Iteration 77000, loss = 0.000127454
I0811 15:25:02.097872  8383 solver.cpp:244]     Train net output #0: loss = 0.000127454 (* 1 = 0.000127454 loss)
I0811 15:25:02.097896  8383 sgd_solver.cpp:106] Iteration 77000, lr = 0.00030598
I0811 15:25:05.305166  8383 solver.cpp:228] Iteration 77100, loss = 9.88971e-05
I0811 15:25:05.305219  8383 solver.cpp:244]     Train net output #0: loss = 9.88971e-05 (* 1 = 9.88971e-05 loss)
I0811 15:25:05.305227  8383 sgd_solver.cpp:106] Iteration 77100, lr = 0.000305744
I0811 15:25:08.588358  8383 solver.cpp:228] Iteration 77200, loss = 4.05771e-05
I0811 15:25:08.588394  8383 solver.cpp:244]     Train net output #0: loss = 4.05771e-05 (* 1 = 4.05771e-05 loss)
I0811 15:25:08.588402  8383 sgd_solver.cpp:106] Iteration 77200, lr = 0.000305508
I0811 15:25:11.852521  8383 solver.cpp:228] Iteration 77300, loss = 4.53894e-05
I0811 15:25:11.852563  8383 solver.cpp:244]     Train net output #0: loss = 4.53894e-05 (* 1 = 4.53894e-05 loss)
I0811 15:25:11.852571  8383 sgd_solver.cpp:106] Iteration 77300, lr = 0.000305273
I0811 15:25:15.116842  8383 solver.cpp:228] Iteration 77400, loss = 5.99961e-05
I0811 15:25:15.116891  8383 solver.cpp:244]     Train net output #0: loss = 5.99961e-05 (* 1 = 5.99961e-05 loss)
I0811 15:25:15.116897  8383 sgd_solver.cpp:106] Iteration 77400, lr = 0.000305038
I0811 15:25:18.341886  8383 solver.cpp:337] Iteration 77500, Testing net (#0)
I0811 15:25:24.825588  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897967
I0811 15:25:24.825670  8383 solver.cpp:404]     Test net output #1: loss = 0.698395 (* 1 = 0.698395 loss)
I0811 15:25:24.836061  8383 solver.cpp:228] Iteration 77500, loss = 9.90798e-05
I0811 15:25:24.836091  8383 solver.cpp:244]     Train net output #0: loss = 9.90798e-05 (* 1 = 9.90798e-05 loss)
I0811 15:25:24.836104  8383 sgd_solver.cpp:106] Iteration 77500, lr = 0.000304803
I0811 15:25:28.084413  8383 solver.cpp:228] Iteration 77600, loss = 0.000121371
I0811 15:25:28.084461  8383 solver.cpp:244]     Train net output #0: loss = 0.000121371 (* 1 = 0.000121371 loss)
I0811 15:25:28.084472  8383 sgd_solver.cpp:106] Iteration 77600, lr = 0.000304569
I0811 15:25:31.387293  8383 solver.cpp:228] Iteration 77700, loss = 3.06763e-05
I0811 15:25:31.387351  8383 solver.cpp:244]     Train net output #0: loss = 3.06763e-05 (* 1 = 3.06763e-05 loss)
I0811 15:25:31.387362  8383 sgd_solver.cpp:106] Iteration 77700, lr = 0.000304335
I0811 15:25:34.638983  8383 solver.cpp:228] Iteration 77800, loss = 0.000181969
I0811 15:25:34.639024  8383 solver.cpp:244]     Train net output #0: loss = 0.000181969 (* 1 = 0.000181969 loss)
I0811 15:25:34.639029  8383 sgd_solver.cpp:106] Iteration 77800, lr = 0.000304101
I0811 15:25:37.911633  8383 solver.cpp:228] Iteration 77900, loss = 3.65538e-05
I0811 15:25:37.911651  8383 solver.cpp:244]     Train net output #0: loss = 3.65538e-05 (* 1 = 3.65538e-05 loss)
I0811 15:25:37.911658  8383 sgd_solver.cpp:106] Iteration 77900, lr = 0.000303868
I0811 15:25:41.174918  8383 solver.cpp:337] Iteration 78000, Testing net (#0)
I0811 15:25:46.580716  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:25:48.044785  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896806
I0811 15:25:48.044828  8383 solver.cpp:404]     Test net output #1: loss = 0.708288 (* 1 = 0.708288 loss)
I0811 15:25:48.055166  8383 solver.cpp:228] Iteration 78000, loss = 0.000139989
I0811 15:25:48.055196  8383 solver.cpp:244]     Train net output #0: loss = 0.000139989 (* 1 = 0.000139989 loss)
I0811 15:25:48.055207  8383 sgd_solver.cpp:106] Iteration 78000, lr = 0.000303636
I0811 15:25:51.277452  8383 solver.cpp:228] Iteration 78100, loss = 0.000131382
I0811 15:25:51.277487  8383 solver.cpp:244]     Train net output #0: loss = 0.000131382 (* 1 = 0.000131382 loss)
I0811 15:25:51.277494  8383 sgd_solver.cpp:106] Iteration 78100, lr = 0.000303404
I0811 15:25:54.551127  8383 solver.cpp:228] Iteration 78200, loss = 0.000287435
I0811 15:25:54.551167  8383 solver.cpp:244]     Train net output #0: loss = 0.000287435 (* 1 = 0.000287435 loss)
I0811 15:25:54.551174  8383 sgd_solver.cpp:106] Iteration 78200, lr = 0.000303172
I0811 15:25:57.821912  8383 solver.cpp:228] Iteration 78300, loss = 8.76077e-05
I0811 15:25:57.821951  8383 solver.cpp:244]     Train net output #0: loss = 8.76077e-05 (* 1 = 8.76077e-05 loss)
I0811 15:25:57.821959  8383 sgd_solver.cpp:106] Iteration 78300, lr = 0.000302941
I0811 15:26:01.107081  8383 solver.cpp:228] Iteration 78400, loss = 0.000108447
I0811 15:26:01.107120  8383 solver.cpp:244]     Train net output #0: loss = 0.000108447 (* 1 = 0.000108447 loss)
I0811 15:26:01.107127  8383 sgd_solver.cpp:106] Iteration 78400, lr = 0.00030271
I0811 15:26:04.389518  8383 solver.cpp:337] Iteration 78500, Testing net (#0)
I0811 15:26:11.077040  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896645
I0811 15:26:11.077083  8383 solver.cpp:404]     Test net output #1: loss = 0.711702 (* 1 = 0.711702 loss)
I0811 15:26:11.087196  8383 solver.cpp:228] Iteration 78500, loss = 9.40417e-05
I0811 15:26:11.087214  8383 solver.cpp:244]     Train net output #0: loss = 9.40417e-05 (* 1 = 9.40417e-05 loss)
I0811 15:26:11.087234  8383 sgd_solver.cpp:106] Iteration 78500, lr = 0.000302479
I0811 15:26:14.310236  8383 solver.cpp:228] Iteration 78600, loss = 9.29135e-05
I0811 15:26:14.310281  8383 solver.cpp:244]     Train net output #0: loss = 9.29135e-05 (* 1 = 9.29135e-05 loss)
I0811 15:26:14.310376  8383 sgd_solver.cpp:106] Iteration 78600, lr = 0.000302249
I0811 15:26:17.552043  8383 solver.cpp:228] Iteration 78700, loss = 4.62035e-05
I0811 15:26:17.552089  8383 solver.cpp:244]     Train net output #0: loss = 4.62035e-05 (* 1 = 4.62035e-05 loss)
I0811 15:26:17.552096  8383 sgd_solver.cpp:106] Iteration 78700, lr = 0.000302019
I0811 15:26:20.803182  8383 solver.cpp:228] Iteration 78800, loss = 8.34321e-05
I0811 15:26:20.803222  8383 solver.cpp:244]     Train net output #0: loss = 8.34321e-05 (* 1 = 8.34321e-05 loss)
I0811 15:26:20.803230  8383 sgd_solver.cpp:106] Iteration 78800, lr = 0.00030179
I0811 15:26:24.103304  8383 solver.cpp:228] Iteration 78900, loss = 3.93081e-05
I0811 15:26:24.103324  8383 solver.cpp:244]     Train net output #0: loss = 3.93081e-05 (* 1 = 3.93081e-05 loss)
I0811 15:26:24.103330  8383 sgd_solver.cpp:106] Iteration 78900, lr = 0.000301561
I0811 15:26:27.377267  8383 solver.cpp:337] Iteration 79000, Testing net (#0)
I0811 15:26:34.106215  8383 solver.cpp:404]     Test net output #0: accuracy = 0.899709
I0811 15:26:34.106278  8383 solver.cpp:404]     Test net output #1: loss = 0.68798 (* 1 = 0.68798 loss)
I0811 15:26:34.118736  8383 solver.cpp:228] Iteration 79000, loss = 4.69635e-05
I0811 15:26:34.118777  8383 solver.cpp:244]     Train net output #0: loss = 4.69635e-05 (* 1 = 4.69635e-05 loss)
I0811 15:26:34.118791  8383 sgd_solver.cpp:106] Iteration 79000, lr = 0.000301333
I0811 15:26:37.301100  8383 solver.cpp:228] Iteration 79100, loss = 9.973e-05
I0811 15:26:37.301139  8383 solver.cpp:244]     Train net output #0: loss = 9.973e-05 (* 1 = 9.973e-05 loss)
I0811 15:26:37.301147  8383 sgd_solver.cpp:106] Iteration 79100, lr = 0.000301105
I0811 15:26:40.594929  8383 solver.cpp:228] Iteration 79200, loss = 4.74943e-05
I0811 15:26:40.594974  8383 solver.cpp:244]     Train net output #0: loss = 4.74943e-05 (* 1 = 4.74943e-05 loss)
I0811 15:26:40.594982  8383 sgd_solver.cpp:106] Iteration 79200, lr = 0.000300877
I0811 15:26:43.853400  8383 solver.cpp:228] Iteration 79300, loss = 8.88163e-05
I0811 15:26:43.853437  8383 solver.cpp:244]     Train net output #0: loss = 8.88163e-05 (* 1 = 8.88163e-05 loss)
I0811 15:26:43.853443  8383 sgd_solver.cpp:106] Iteration 79300, lr = 0.00030065
I0811 15:26:47.109424  8383 solver.cpp:228] Iteration 79400, loss = 4.85111e-05
I0811 15:26:47.109463  8383 solver.cpp:244]     Train net output #0: loss = 4.85111e-05 (* 1 = 4.85111e-05 loss)
I0811 15:26:47.109469  8383 sgd_solver.cpp:106] Iteration 79400, lr = 0.000300423
I0811 15:26:50.400935  8383 solver.cpp:337] Iteration 79500, Testing net (#0)
I0811 15:26:52.548286  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:26:57.152222  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896936
I0811 15:26:57.152307  8383 solver.cpp:404]     Test net output #1: loss = 0.71192 (* 1 = 0.71192 loss)
I0811 15:26:57.165907  8383 solver.cpp:228] Iteration 79500, loss = 9.23252e-05
I0811 15:26:57.165943  8383 solver.cpp:244]     Train net output #0: loss = 9.23252e-05 (* 1 = 9.23252e-05 loss)
I0811 15:26:57.165963  8383 sgd_solver.cpp:106] Iteration 79500, lr = 0.000300196
I0811 15:27:00.393414  8383 solver.cpp:228] Iteration 79600, loss = 0.000185088
I0811 15:27:00.393455  8383 solver.cpp:244]     Train net output #0: loss = 0.000185088 (* 1 = 0.000185088 loss)
I0811 15:27:00.393462  8383 sgd_solver.cpp:106] Iteration 79600, lr = 0.00029997
I0811 15:27:03.704931  8383 solver.cpp:228] Iteration 79700, loss = 7.84612e-05
I0811 15:27:03.704972  8383 solver.cpp:244]     Train net output #0: loss = 7.84612e-05 (* 1 = 7.84612e-05 loss)
I0811 15:27:03.704977  8383 sgd_solver.cpp:106] Iteration 79700, lr = 0.000299744
I0811 15:27:06.971998  8383 solver.cpp:228] Iteration 79800, loss = 6.88099e-05
I0811 15:27:06.972039  8383 solver.cpp:244]     Train net output #0: loss = 6.88099e-05 (* 1 = 6.88099e-05 loss)
I0811 15:27:06.972046  8383 sgd_solver.cpp:106] Iteration 79800, lr = 0.000299519
I0811 15:27:10.227619  8383 solver.cpp:228] Iteration 79900, loss = 0.000136101
I0811 15:27:10.227659  8383 solver.cpp:244]     Train net output #0: loss = 0.000136101 (* 1 = 0.000136101 loss)
I0811 15:27:10.227665  8383 sgd_solver.cpp:106] Iteration 79900, lr = 0.000299294
I0811 15:27:13.493077  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_80000.caffemodel
I0811 15:27:13.875222  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_80000.solverstate
I0811 15:27:14.010020  8383 solver.cpp:337] Iteration 80000, Testing net (#0)
I0811 15:27:20.364440  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896096
I0811 15:27:20.364516  8383 solver.cpp:404]     Test net output #1: loss = 0.717795 (* 1 = 0.717795 loss)
I0811 15:27:20.377472  8383 solver.cpp:228] Iteration 80000, loss = 4.29848e-05
I0811 15:27:20.377533  8383 solver.cpp:244]     Train net output #0: loss = 4.29848e-05 (* 1 = 4.29848e-05 loss)
I0811 15:27:20.377557  8383 sgd_solver.cpp:106] Iteration 80000, lr = 0.00029907
I0811 15:27:23.598752  8383 solver.cpp:228] Iteration 80100, loss = 7.98327e-05
I0811 15:27:23.598794  8383 solver.cpp:244]     Train net output #0: loss = 7.98327e-05 (* 1 = 7.98327e-05 loss)
I0811 15:27:23.598801  8383 sgd_solver.cpp:106] Iteration 80100, lr = 0.000298846
I0811 15:27:26.857913  8383 solver.cpp:228] Iteration 80200, loss = 0.000204052
I0811 15:27:26.857955  8383 solver.cpp:244]     Train net output #0: loss = 0.000204052 (* 1 = 0.000204052 loss)
I0811 15:27:26.857964  8383 sgd_solver.cpp:106] Iteration 80200, lr = 0.000298622
I0811 15:27:30.131461  8383 solver.cpp:228] Iteration 80300, loss = 5.32189e-05
I0811 15:27:30.131502  8383 solver.cpp:244]     Train net output #0: loss = 5.32189e-05 (* 1 = 5.32189e-05 loss)
I0811 15:27:30.131508  8383 sgd_solver.cpp:106] Iteration 80300, lr = 0.000298399
I0811 15:27:33.383148  8383 solver.cpp:228] Iteration 80400, loss = 6.51344e-05
I0811 15:27:33.383185  8383 solver.cpp:244]     Train net output #0: loss = 6.51344e-05 (* 1 = 6.51344e-05 loss)
I0811 15:27:33.383191  8383 sgd_solver.cpp:106] Iteration 80400, lr = 0.000298176
I0811 15:27:36.683845  8383 solver.cpp:337] Iteration 80500, Testing net (#0)
I0811 15:27:43.189477  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:27:43.463181  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898097
I0811 15:27:43.463573  8383 solver.cpp:404]     Test net output #1: loss = 0.705655 (* 1 = 0.705655 loss)
I0811 15:27:43.475749  8383 solver.cpp:228] Iteration 80500, loss = 8.37977e-05
I0811 15:27:43.475920  8383 solver.cpp:244]     Train net output #0: loss = 8.37977e-05 (* 1 = 8.37977e-05 loss)
I0811 15:27:43.475991  8383 sgd_solver.cpp:106] Iteration 80500, lr = 0.000297953
I0811 15:27:46.699637  8383 solver.cpp:228] Iteration 80600, loss = 7.43165e-05
I0811 15:27:46.699683  8383 solver.cpp:244]     Train net output #0: loss = 7.43165e-05 (* 1 = 7.43165e-05 loss)
I0811 15:27:46.699692  8383 sgd_solver.cpp:106] Iteration 80600, lr = 0.000297731
I0811 15:27:49.921793  8383 solver.cpp:228] Iteration 80700, loss = 0.000105603
I0811 15:27:49.921833  8383 solver.cpp:244]     Train net output #0: loss = 0.000105603 (* 1 = 0.000105603 loss)
I0811 15:27:49.921839  8383 sgd_solver.cpp:106] Iteration 80700, lr = 0.000297509
I0811 15:27:53.207386  8383 solver.cpp:228] Iteration 80800, loss = 8.08733e-05
I0811 15:27:53.207437  8383 solver.cpp:244]     Train net output #0: loss = 8.08733e-05 (* 1 = 8.08733e-05 loss)
I0811 15:27:53.207444  8383 sgd_solver.cpp:106] Iteration 80800, lr = 0.000297288
I0811 15:27:56.489840  8383 solver.cpp:228] Iteration 80900, loss = 0.000110227
I0811 15:27:56.489881  8383 solver.cpp:244]     Train net output #0: loss = 0.000110227 (* 1 = 0.000110227 loss)
I0811 15:27:56.489887  8383 sgd_solver.cpp:106] Iteration 80900, lr = 0.000297067
I0811 15:27:59.755084  8383 solver.cpp:337] Iteration 81000, Testing net (#0)
I0811 15:28:06.746728  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89871
I0811 15:28:06.746788  8383 solver.cpp:404]     Test net output #1: loss = 0.701021 (* 1 = 0.701021 loss)
I0811 15:28:06.759613  8383 solver.cpp:228] Iteration 81000, loss = 3.76543e-05
I0811 15:28:06.759677  8383 solver.cpp:244]     Train net output #0: loss = 3.76543e-05 (* 1 = 3.76543e-05 loss)
I0811 15:28:06.759702  8383 sgd_solver.cpp:106] Iteration 81000, lr = 0.000296846
I0811 15:28:09.991816  8383 solver.cpp:228] Iteration 81100, loss = 5.69282e-05
I0811 15:28:09.991864  8383 solver.cpp:244]     Train net output #0: loss = 5.69282e-05 (* 1 = 5.69282e-05 loss)
I0811 15:28:09.991871  8383 sgd_solver.cpp:106] Iteration 81100, lr = 0.000296626
I0811 15:28:13.275311  8383 solver.cpp:228] Iteration 81200, loss = 4.46333e-05
I0811 15:28:13.275352  8383 solver.cpp:244]     Train net output #0: loss = 4.46333e-05 (* 1 = 4.46333e-05 loss)
I0811 15:28:13.275359  8383 sgd_solver.cpp:106] Iteration 81200, lr = 0.000296406
I0811 15:28:16.586474  8383 solver.cpp:228] Iteration 81300, loss = 3.6513e-05
I0811 15:28:16.586527  8383 solver.cpp:244]     Train net output #0: loss = 3.6513e-05 (* 1 = 3.6513e-05 loss)
I0811 15:28:16.586537  8383 sgd_solver.cpp:106] Iteration 81300, lr = 0.000296187
I0811 15:28:19.855553  8383 solver.cpp:228] Iteration 81400, loss = 6.84872e-05
I0811 15:28:19.855600  8383 solver.cpp:244]     Train net output #0: loss = 6.84872e-05 (* 1 = 6.84872e-05 loss)
I0811 15:28:19.855607  8383 sgd_solver.cpp:106] Iteration 81400, lr = 0.000295968
I0811 15:28:23.106861  8383 solver.cpp:337] Iteration 81500, Testing net (#0)
I0811 15:28:29.585638  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896226
I0811 15:28:29.585711  8383 solver.cpp:404]     Test net output #1: loss = 0.720662 (* 1 = 0.720662 loss)
I0811 15:28:29.596504  8383 solver.cpp:228] Iteration 81500, loss = 3.12749e-05
I0811 15:28:29.596555  8383 solver.cpp:244]     Train net output #0: loss = 3.12749e-05 (* 1 = 3.12749e-05 loss)
I0811 15:28:29.596576  8383 sgd_solver.cpp:106] Iteration 81500, lr = 0.000295749
I0811 15:28:32.925972  8383 solver.cpp:228] Iteration 81600, loss = 3.06274e-05
I0811 15:28:32.926030  8383 solver.cpp:244]     Train net output #0: loss = 3.06274e-05 (* 1 = 3.06274e-05 loss)
I0811 15:28:32.926043  8383 sgd_solver.cpp:106] Iteration 81600, lr = 0.00029553
I0811 15:28:36.189355  8383 solver.cpp:228] Iteration 81700, loss = 7.20202e-05
I0811 15:28:36.189398  8383 solver.cpp:244]     Train net output #0: loss = 7.20202e-05 (* 1 = 7.20202e-05 loss)
I0811 15:28:36.189404  8383 sgd_solver.cpp:106] Iteration 81700, lr = 0.000295312
I0811 15:28:39.420117  8383 solver.cpp:228] Iteration 81800, loss = 4.19415e-05
I0811 15:28:39.420156  8383 solver.cpp:244]     Train net output #0: loss = 4.19415e-05 (* 1 = 4.19415e-05 loss)
I0811 15:28:39.420162  8383 sgd_solver.cpp:106] Iteration 81800, lr = 0.000295095
I0811 15:28:42.719846  8383 solver.cpp:228] Iteration 81900, loss = 0.000221002
I0811 15:28:42.719880  8383 solver.cpp:244]     Train net output #0: loss = 0.000221002 (* 1 = 0.000221002 loss)
I0811 15:28:42.719887  8383 sgd_solver.cpp:106] Iteration 81900, lr = 0.000294878
I0811 15:28:45.981858  8383 solver.cpp:337] Iteration 82000, Testing net (#0)
I0811 15:28:50.691581  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:28:52.460850  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895323
I0811 15:28:52.460896  8383 solver.cpp:404]     Test net output #1: loss = 0.729307 (* 1 = 0.729307 loss)
I0811 15:28:52.473592  8383 solver.cpp:228] Iteration 82000, loss = 0.000127054
I0811 15:28:52.473609  8383 solver.cpp:244]     Train net output #0: loss = 0.000127054 (* 1 = 0.000127054 loss)
I0811 15:28:52.473618  8383 sgd_solver.cpp:106] Iteration 82000, lr = 0.000294661
I0811 15:28:55.685781  8383 solver.cpp:228] Iteration 82100, loss = 0.000114915
I0811 15:28:55.685840  8383 solver.cpp:244]     Train net output #0: loss = 0.000114915 (* 1 = 0.000114915 loss)
I0811 15:28:55.685856  8383 sgd_solver.cpp:106] Iteration 82100, lr = 0.000294444
I0811 15:28:58.988450  8383 solver.cpp:228] Iteration 82200, loss = 0.000102792
I0811 15:28:58.988497  8383 solver.cpp:244]     Train net output #0: loss = 0.000102792 (* 1 = 0.000102792 loss)
I0811 15:28:58.988503  8383 sgd_solver.cpp:106] Iteration 82200, lr = 0.000294228
I0811 15:29:02.297333  8383 solver.cpp:228] Iteration 82300, loss = 8.63376e-05
I0811 15:29:02.297366  8383 solver.cpp:244]     Train net output #0: loss = 8.63376e-05 (* 1 = 8.63376e-05 loss)
I0811 15:29:02.297372  8383 sgd_solver.cpp:106] Iteration 82300, lr = 0.000294013
I0811 15:29:05.567025  8383 solver.cpp:228] Iteration 82400, loss = 2.99778e-05
I0811 15:29:05.567060  8383 solver.cpp:244]     Train net output #0: loss = 2.99778e-05 (* 1 = 2.99778e-05 loss)
I0811 15:29:05.567066  8383 sgd_solver.cpp:106] Iteration 82400, lr = 0.000293797
I0811 15:29:08.776643  8383 solver.cpp:337] Iteration 82500, Testing net (#0)
I0811 15:29:15.444666  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897967
I0811 15:29:15.444736  8383 solver.cpp:404]     Test net output #1: loss = 0.709422 (* 1 = 0.709422 loss)
I0811 15:29:15.457525  8383 solver.cpp:228] Iteration 82500, loss = 5.78621e-05
I0811 15:29:15.457590  8383 solver.cpp:244]     Train net output #0: loss = 5.78621e-05 (* 1 = 5.78621e-05 loss)
I0811 15:29:15.457607  8383 sgd_solver.cpp:106] Iteration 82500, lr = 0.000293582
I0811 15:29:18.673099  8383 solver.cpp:228] Iteration 82600, loss = 5.28105e-05
I0811 15:29:18.673148  8383 solver.cpp:244]     Train net output #0: loss = 5.28105e-05 (* 1 = 5.28105e-05 loss)
I0811 15:29:18.673156  8383 sgd_solver.cpp:106] Iteration 82600, lr = 0.000293367
I0811 15:29:21.934542  8383 solver.cpp:228] Iteration 82700, loss = 4.19563e-05
I0811 15:29:21.934583  8383 solver.cpp:244]     Train net output #0: loss = 4.19563e-05 (* 1 = 4.19563e-05 loss)
I0811 15:29:21.934589  8383 sgd_solver.cpp:106] Iteration 82700, lr = 0.000293153
I0811 15:29:25.198259  8383 solver.cpp:228] Iteration 82800, loss = 2.5931e-05
I0811 15:29:25.198297  8383 solver.cpp:244]     Train net output #0: loss = 2.5931e-05 (* 1 = 2.5931e-05 loss)
I0811 15:29:25.198302  8383 sgd_solver.cpp:106] Iteration 82800, lr = 0.000292939
I0811 15:29:28.467056  8383 solver.cpp:228] Iteration 82900, loss = 5.4465e-05
I0811 15:29:28.467095  8383 solver.cpp:244]     Train net output #0: loss = 5.4465e-05 (* 1 = 5.4465e-05 loss)
I0811 15:29:28.467102  8383 sgd_solver.cpp:106] Iteration 82900, lr = 0.000292726
I0811 15:29:31.695709  8383 solver.cpp:337] Iteration 83000, Testing net (#0)
I0811 15:29:38.089236  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0811 15:29:38.089325  8383 solver.cpp:404]     Test net output #1: loss = 0.705713 (* 1 = 0.705713 loss)
I0811 15:29:38.099747  8383 solver.cpp:228] Iteration 83000, loss = 9.03411e-05
I0811 15:29:38.099778  8383 solver.cpp:244]     Train net output #0: loss = 9.03411e-05 (* 1 = 9.03411e-05 loss)
I0811 15:29:38.099787  8383 sgd_solver.cpp:106] Iteration 83000, lr = 0.000292513
I0811 15:29:41.340185  8383 solver.cpp:228] Iteration 83100, loss = 0.000229043
I0811 15:29:41.340222  8383 solver.cpp:244]     Train net output #0: loss = 0.000229043 (* 1 = 0.000229043 loss)
I0811 15:29:41.340229  8383 sgd_solver.cpp:106] Iteration 83100, lr = 0.0002923
I0811 15:29:44.602464  8383 solver.cpp:228] Iteration 83200, loss = 3.27457e-05
I0811 15:29:44.602504  8383 solver.cpp:244]     Train net output #0: loss = 3.27457e-05 (* 1 = 3.27457e-05 loss)
I0811 15:29:44.602509  8383 sgd_solver.cpp:106] Iteration 83200, lr = 0.000292087
I0811 15:29:47.925617  8383 solver.cpp:228] Iteration 83300, loss = 8.33641e-05
I0811 15:29:47.925662  8383 solver.cpp:244]     Train net output #0: loss = 8.33641e-05 (* 1 = 8.33641e-05 loss)
I0811 15:29:47.925668  8383 sgd_solver.cpp:106] Iteration 83300, lr = 0.000291875
I0811 15:29:51.180013  8383 solver.cpp:228] Iteration 83400, loss = 0.000174711
I0811 15:29:51.180058  8383 solver.cpp:244]     Train net output #0: loss = 0.000174711 (* 1 = 0.000174711 loss)
I0811 15:29:51.180065  8383 sgd_solver.cpp:106] Iteration 83400, lr = 0.000291664
I0811 15:29:54.390833  8383 solver.cpp:337] Iteration 83500, Testing net (#0)
I0811 15:29:56.381422  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:30:01.216240  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89671
I0811 15:30:01.216290  8383 solver.cpp:404]     Test net output #1: loss = 0.722388 (* 1 = 0.722388 loss)
I0811 15:30:01.226840  8383 solver.cpp:228] Iteration 83500, loss = 4.05799e-05
I0811 15:30:01.226863  8383 solver.cpp:244]     Train net output #0: loss = 4.05799e-05 (* 1 = 4.05799e-05 loss)
I0811 15:30:01.226876  8383 sgd_solver.cpp:106] Iteration 83500, lr = 0.000291452
I0811 15:30:04.458683  8383 solver.cpp:228] Iteration 83600, loss = 2.68794e-05
I0811 15:30:04.458729  8383 solver.cpp:244]     Train net output #0: loss = 2.68794e-05 (* 1 = 2.68794e-05 loss)
I0811 15:30:04.458736  8383 sgd_solver.cpp:106] Iteration 83600, lr = 0.000291241
I0811 15:30:07.706228  8383 solver.cpp:228] Iteration 83700, loss = 6.32664e-05
I0811 15:30:07.706269  8383 solver.cpp:244]     Train net output #0: loss = 6.32664e-05 (* 1 = 6.32664e-05 loss)
I0811 15:30:07.706275  8383 sgd_solver.cpp:106] Iteration 83700, lr = 0.00029103
I0811 15:30:10.995527  8383 solver.cpp:228] Iteration 83800, loss = 4.82163e-05
I0811 15:30:10.995573  8383 solver.cpp:244]     Train net output #0: loss = 4.82163e-05 (* 1 = 4.82163e-05 loss)
I0811 15:30:10.995579  8383 sgd_solver.cpp:106] Iteration 83800, lr = 0.00029082
I0811 15:30:14.278870  8383 solver.cpp:228] Iteration 83900, loss = 2.1589e-05
I0811 15:30:14.278913  8383 solver.cpp:244]     Train net output #0: loss = 2.1589e-05 (* 1 = 2.1589e-05 loss)
I0811 15:30:14.278919  8383 sgd_solver.cpp:106] Iteration 83900, lr = 0.00029061
I0811 15:30:17.530988  8383 solver.cpp:337] Iteration 84000, Testing net (#0)
I0811 15:30:24.154340  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895709
I0811 15:30:24.154386  8383 solver.cpp:404]     Test net output #1: loss = 0.73086 (* 1 = 0.73086 loss)
I0811 15:30:24.164780  8383 solver.cpp:228] Iteration 84000, loss = 8.51985e-05
I0811 15:30:24.164810  8383 solver.cpp:244]     Train net output #0: loss = 8.51985e-05 (* 1 = 8.51985e-05 loss)
I0811 15:30:24.164822  8383 sgd_solver.cpp:106] Iteration 84000, lr = 0.000290401
I0811 15:30:27.384963  8383 solver.cpp:228] Iteration 84100, loss = 3.50197e-05
I0811 15:30:27.385007  8383 solver.cpp:244]     Train net output #0: loss = 3.50197e-05 (* 1 = 3.50197e-05 loss)
I0811 15:30:27.385013  8383 sgd_solver.cpp:106] Iteration 84100, lr = 0.000290191
I0811 15:30:30.656234  8383 solver.cpp:228] Iteration 84200, loss = 0.000114007
I0811 15:30:30.656282  8383 solver.cpp:244]     Train net output #0: loss = 0.000114007 (* 1 = 0.000114007 loss)
I0811 15:30:30.656288  8383 sgd_solver.cpp:106] Iteration 84200, lr = 0.000289982
I0811 15:30:33.948392  8383 solver.cpp:228] Iteration 84300, loss = 4.1157e-05
I0811 15:30:33.948434  8383 solver.cpp:244]     Train net output #0: loss = 4.1157e-05 (* 1 = 4.1157e-05 loss)
I0811 15:30:33.948441  8383 sgd_solver.cpp:106] Iteration 84300, lr = 0.000289774
I0811 15:30:37.196432  8383 solver.cpp:228] Iteration 84400, loss = 6.41688e-05
I0811 15:30:37.196480  8383 solver.cpp:244]     Train net output #0: loss = 6.41688e-05 (* 1 = 6.41688e-05 loss)
I0811 15:30:37.196485  8383 sgd_solver.cpp:106] Iteration 84400, lr = 0.000289566
I0811 15:30:40.420084  8383 solver.cpp:337] Iteration 84500, Testing net (#0)
I0811 15:30:47.317242  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898387
I0811 15:30:47.317327  8383 solver.cpp:404]     Test net output #1: loss = 0.707646 (* 1 = 0.707646 loss)
I0811 15:30:47.329671  8383 solver.cpp:228] Iteration 84500, loss = 6.41851e-05
I0811 15:30:47.329704  8383 solver.cpp:244]     Train net output #0: loss = 6.41851e-05 (* 1 = 6.41851e-05 loss)
I0811 15:30:47.329715  8383 sgd_solver.cpp:106] Iteration 84500, lr = 0.000289358
I0811 15:30:50.588399  8383 solver.cpp:228] Iteration 84600, loss = 4.2054e-05
I0811 15:30:50.588436  8383 solver.cpp:244]     Train net output #0: loss = 4.2054e-05 (* 1 = 4.2054e-05 loss)
I0811 15:30:50.588443  8383 sgd_solver.cpp:106] Iteration 84600, lr = 0.00028915
I0811 15:30:53.165556  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:30:53.849721  8383 solver.cpp:228] Iteration 84700, loss = 3.96247e-05
I0811 15:30:53.849750  8383 solver.cpp:244]     Train net output #0: loss = 3.96247e-05 (* 1 = 3.96247e-05 loss)
I0811 15:30:53.849757  8383 sgd_solver.cpp:106] Iteration 84700, lr = 0.000288943
I0811 15:30:57.138957  8383 solver.cpp:228] Iteration 84800, loss = 4.89091e-05
I0811 15:30:57.138995  8383 solver.cpp:244]     Train net output #0: loss = 4.89091e-05 (* 1 = 4.89091e-05 loss)
I0811 15:30:57.139003  8383 sgd_solver.cpp:106] Iteration 84800, lr = 0.000288736
I0811 15:31:00.457540  8383 solver.cpp:228] Iteration 84900, loss = 7.59587e-05
I0811 15:31:00.457578  8383 solver.cpp:244]     Train net output #0: loss = 7.59587e-05 (* 1 = 7.59587e-05 loss)
I0811 15:31:00.457584  8383 sgd_solver.cpp:106] Iteration 84900, lr = 0.00028853
I0811 15:31:03.690943  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_85000.caffemodel
I0811 15:31:04.065615  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_85000.solverstate
I0811 15:31:04.197758  8383 solver.cpp:337] Iteration 85000, Testing net (#0)
I0811 15:31:10.684357  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897742
I0811 15:31:10.684427  8383 solver.cpp:404]     Test net output #1: loss = 0.718739 (* 1 = 0.718739 loss)
I0811 15:31:10.697010  8383 solver.cpp:228] Iteration 85000, loss = 4.68289e-05
I0811 15:31:10.697065  8383 solver.cpp:244]     Train net output #0: loss = 4.68289e-05 (* 1 = 4.68289e-05 loss)
I0811 15:31:10.697084  8383 sgd_solver.cpp:106] Iteration 85000, lr = 0.000288324
I0811 15:31:13.953467  8383 solver.cpp:228] Iteration 85100, loss = 0.000102981
I0811 15:31:13.953516  8383 solver.cpp:244]     Train net output #0: loss = 0.000102981 (* 1 = 0.000102981 loss)
I0811 15:31:13.953526  8383 sgd_solver.cpp:106] Iteration 85100, lr = 0.000288118
I0811 15:31:17.239107  8383 solver.cpp:228] Iteration 85200, loss = 8.10763e-05
I0811 15:31:17.239154  8383 solver.cpp:244]     Train net output #0: loss = 8.10763e-05 (* 1 = 8.10763e-05 loss)
I0811 15:31:17.239162  8383 sgd_solver.cpp:106] Iteration 85200, lr = 0.000287913
I0811 15:31:20.475710  8383 solver.cpp:228] Iteration 85300, loss = 6.81211e-05
I0811 15:31:20.475759  8383 solver.cpp:244]     Train net output #0: loss = 6.81211e-05 (* 1 = 6.81211e-05 loss)
I0811 15:31:20.475766  8383 sgd_solver.cpp:106] Iteration 85300, lr = 0.000287708
I0811 15:31:23.749817  8383 solver.cpp:228] Iteration 85400, loss = 4.10235e-05
I0811 15:31:23.749860  8383 solver.cpp:244]     Train net output #0: loss = 4.10235e-05 (* 1 = 4.10235e-05 loss)
I0811 15:31:23.749866  8383 sgd_solver.cpp:106] Iteration 85400, lr = 0.000287503
I0811 15:31:27.018646  8383 solver.cpp:337] Iteration 85500, Testing net (#0)
I0811 15:31:33.476096  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896129
I0811 15:31:33.476155  8383 solver.cpp:404]     Test net output #1: loss = 0.72938 (* 1 = 0.72938 loss)
I0811 15:31:33.486356  8383 solver.cpp:228] Iteration 85500, loss = 0.000127432
I0811 15:31:33.486378  8383 solver.cpp:244]     Train net output #0: loss = 0.000127432 (* 1 = 0.000127432 loss)
I0811 15:31:33.486390  8383 sgd_solver.cpp:106] Iteration 85500, lr = 0.000287298
I0811 15:31:36.722681  8383 solver.cpp:228] Iteration 85600, loss = 4.87401e-05
I0811 15:31:36.722718  8383 solver.cpp:244]     Train net output #0: loss = 4.87401e-05 (* 1 = 4.87401e-05 loss)
I0811 15:31:36.722723  8383 sgd_solver.cpp:106] Iteration 85600, lr = 0.000287094
I0811 15:31:39.958665  8383 solver.cpp:228] Iteration 85700, loss = 0.00012354
I0811 15:31:39.958722  8383 solver.cpp:244]     Train net output #0: loss = 0.00012354 (* 1 = 0.00012354 loss)
I0811 15:31:39.958729  8383 sgd_solver.cpp:106] Iteration 85700, lr = 0.000286891
I0811 15:31:43.266016  8383 solver.cpp:228] Iteration 85800, loss = 3.70827e-05
I0811 15:31:43.266065  8383 solver.cpp:244]     Train net output #0: loss = 3.70827e-05 (* 1 = 3.70827e-05 loss)
I0811 15:31:43.266072  8383 sgd_solver.cpp:106] Iteration 85800, lr = 0.000286687
I0811 15:31:46.525193  8383 solver.cpp:228] Iteration 85900, loss = 4.28474e-05
I0811 15:31:46.525244  8383 solver.cpp:244]     Train net output #0: loss = 4.28474e-05 (* 1 = 4.28474e-05 loss)
I0811 15:31:46.525251  8383 sgd_solver.cpp:106] Iteration 85900, lr = 0.000286484
I0811 15:31:49.775622  8383 solver.cpp:337] Iteration 86000, Testing net (#0)
I0811 15:31:53.206727  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:31:56.142091  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895742
I0811 15:31:56.142144  8383 solver.cpp:404]     Test net output #1: loss = 0.734055 (* 1 = 0.734055 loss)
I0811 15:31:56.155619  8383 solver.cpp:228] Iteration 86000, loss = 7.30972e-05
I0811 15:31:56.155688  8383 solver.cpp:244]     Train net output #0: loss = 7.30972e-05 (* 1 = 7.30972e-05 loss)
I0811 15:31:56.155705  8383 sgd_solver.cpp:106] Iteration 86000, lr = 0.000286281
I0811 15:31:59.419396  8383 solver.cpp:228] Iteration 86100, loss = 5.76489e-05
I0811 15:31:59.419435  8383 solver.cpp:244]     Train net output #0: loss = 5.76489e-05 (* 1 = 5.76489e-05 loss)
I0811 15:31:59.419442  8383 sgd_solver.cpp:106] Iteration 86100, lr = 0.000286079
I0811 15:32:02.657393  8383 solver.cpp:228] Iteration 86200, loss = 5.52285e-05
I0811 15:32:02.657429  8383 solver.cpp:244]     Train net output #0: loss = 5.52285e-05 (* 1 = 5.52285e-05 loss)
I0811 15:32:02.657435  8383 sgd_solver.cpp:106] Iteration 86200, lr = 0.000285877
I0811 15:32:05.906172  8383 solver.cpp:228] Iteration 86300, loss = 1.8478e-05
I0811 15:32:05.906209  8383 solver.cpp:244]     Train net output #0: loss = 1.8478e-05 (* 1 = 1.8478e-05 loss)
I0811 15:32:05.906215  8383 sgd_solver.cpp:106] Iteration 86300, lr = 0.000285675
I0811 15:32:09.169411  8383 solver.cpp:228] Iteration 86400, loss = 0.000184735
I0811 15:32:09.169452  8383 solver.cpp:244]     Train net output #0: loss = 0.000184735 (* 1 = 0.000184735 loss)
I0811 15:32:09.169458  8383 sgd_solver.cpp:106] Iteration 86400, lr = 0.000285474
I0811 15:32:12.438215  8383 solver.cpp:337] Iteration 86500, Testing net (#0)
I0811 15:32:19.186452  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898806
I0811 15:32:19.186533  8383 solver.cpp:404]     Test net output #1: loss = 0.709917 (* 1 = 0.709917 loss)
I0811 15:32:19.199533  8383 solver.cpp:228] Iteration 86500, loss = 0.000159389
I0811 15:32:19.199594  8383 solver.cpp:244]     Train net output #0: loss = 0.000159389 (* 1 = 0.000159389 loss)
I0811 15:32:19.199611  8383 sgd_solver.cpp:106] Iteration 86500, lr = 0.000285273
I0811 15:32:22.420475  8383 solver.cpp:228] Iteration 86600, loss = 0.000147751
I0811 15:32:22.420534  8383 solver.cpp:244]     Train net output #0: loss = 0.000147751 (* 1 = 0.000147751 loss)
I0811 15:32:22.420542  8383 sgd_solver.cpp:106] Iteration 86600, lr = 0.000285072
I0811 15:32:25.665012  8383 solver.cpp:228] Iteration 86700, loss = 0.00010884
I0811 15:32:25.665051  8383 solver.cpp:244]     Train net output #0: loss = 0.00010884 (* 1 = 0.00010884 loss)
I0811 15:32:25.665058  8383 sgd_solver.cpp:106] Iteration 86700, lr = 0.000284872
I0811 15:32:28.961494  8383 solver.cpp:228] Iteration 86800, loss = 8.41619e-05
I0811 15:32:28.961555  8383 solver.cpp:244]     Train net output #0: loss = 8.41619e-05 (* 1 = 8.41619e-05 loss)
I0811 15:32:28.961565  8383 sgd_solver.cpp:106] Iteration 86800, lr = 0.000284672
I0811 15:32:32.258229  8383 solver.cpp:228] Iteration 86900, loss = 5.91951e-05
I0811 15:32:32.258283  8383 solver.cpp:244]     Train net output #0: loss = 5.91951e-05 (* 1 = 5.91951e-05 loss)
I0811 15:32:32.258291  8383 sgd_solver.cpp:106] Iteration 86900, lr = 0.000284472
I0811 15:32:35.519140  8383 solver.cpp:337] Iteration 87000, Testing net (#0)
I0811 15:32:42.014195  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897419
I0811 15:32:42.014262  8383 solver.cpp:404]     Test net output #1: loss = 0.725555 (* 1 = 0.725555 loss)
I0811 15:32:42.024870  8383 solver.cpp:228] Iteration 87000, loss = 0.000183162
I0811 15:32:42.024920  8383 solver.cpp:244]     Train net output #0: loss = 0.000183162 (* 1 = 0.000183162 loss)
I0811 15:32:42.024941  8383 sgd_solver.cpp:106] Iteration 87000, lr = 0.000284272
I0811 15:32:45.231827  8383 solver.cpp:228] Iteration 87100, loss = 0.000219027
I0811 15:32:45.231878  8383 solver.cpp:244]     Train net output #0: loss = 0.000219027 (* 1 = 0.000219027 loss)
I0811 15:32:45.231884  8383 sgd_solver.cpp:106] Iteration 87100, lr = 0.000284073
I0811 15:32:48.517808  8383 solver.cpp:228] Iteration 87200, loss = 0.000118734
I0811 15:32:48.517854  8383 solver.cpp:244]     Train net output #0: loss = 0.000118734 (* 1 = 0.000118734 loss)
I0811 15:32:48.517860  8383 sgd_solver.cpp:106] Iteration 87200, lr = 0.000283875
I0811 15:32:51.791769  8383 solver.cpp:228] Iteration 87300, loss = 4.2639e-05
I0811 15:32:51.791827  8383 solver.cpp:244]     Train net output #0: loss = 4.2639e-05 (* 1 = 4.2639e-05 loss)
I0811 15:32:51.791846  8383 sgd_solver.cpp:106] Iteration 87300, lr = 0.000283676
I0811 15:32:55.086704  8383 solver.cpp:228] Iteration 87400, loss = 5.47838e-05
I0811 15:32:55.086753  8383 solver.cpp:244]     Train net output #0: loss = 5.47838e-05 (* 1 = 5.47838e-05 loss)
I0811 15:32:55.086763  8383 sgd_solver.cpp:106] Iteration 87400, lr = 0.000283478
I0811 15:32:58.316228  8383 solver.cpp:337] Iteration 87500, Testing net (#0)
I0811 15:33:00.622889  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:33:05.223143  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895871
I0811 15:33:05.223212  8383 solver.cpp:404]     Test net output #1: loss = 0.736069 (* 1 = 0.736069 loss)
I0811 15:33:05.235460  8383 solver.cpp:228] Iteration 87500, loss = 4.21661e-05
I0811 15:33:05.235484  8383 solver.cpp:244]     Train net output #0: loss = 4.21661e-05 (* 1 = 4.21661e-05 loss)
I0811 15:33:05.235498  8383 sgd_solver.cpp:106] Iteration 87500, lr = 0.00028328
I0811 15:33:08.484838  8383 solver.cpp:228] Iteration 87600, loss = 5.12172e-05
I0811 15:33:08.484874  8383 solver.cpp:244]     Train net output #0: loss = 5.12172e-05 (* 1 = 5.12172e-05 loss)
I0811 15:33:08.484879  8383 sgd_solver.cpp:106] Iteration 87600, lr = 0.000283083
I0811 15:33:11.762553  8383 solver.cpp:228] Iteration 87700, loss = 6.75747e-05
I0811 15:33:11.762598  8383 solver.cpp:244]     Train net output #0: loss = 6.75747e-05 (* 1 = 6.75747e-05 loss)
I0811 15:33:11.762604  8383 sgd_solver.cpp:106] Iteration 87700, lr = 0.000282886
I0811 15:33:15.074100  8383 solver.cpp:228] Iteration 87800, loss = 3.97719e-05
I0811 15:33:15.074151  8383 solver.cpp:244]     Train net output #0: loss = 3.97719e-05 (* 1 = 3.97719e-05 loss)
I0811 15:33:15.074162  8383 sgd_solver.cpp:106] Iteration 87800, lr = 0.000282689
I0811 15:33:18.390105  8383 solver.cpp:228] Iteration 87900, loss = 5.05704e-05
I0811 15:33:18.390141  8383 solver.cpp:244]     Train net output #0: loss = 5.05704e-05 (* 1 = 5.05704e-05 loss)
I0811 15:33:18.390146  8383 sgd_solver.cpp:106] Iteration 87900, lr = 0.000282492
I0811 15:33:21.608353  8383 solver.cpp:337] Iteration 88000, Testing net (#0)
I0811 15:33:28.234876  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897226
I0811 15:33:28.234956  8383 solver.cpp:404]     Test net output #1: loss = 0.727902 (* 1 = 0.727902 loss)
I0811 15:33:28.245615  8383 solver.cpp:228] Iteration 88000, loss = 7.86448e-05
I0811 15:33:28.245683  8383 solver.cpp:244]     Train net output #0: loss = 7.86448e-05 (* 1 = 7.86448e-05 loss)
I0811 15:33:28.245700  8383 sgd_solver.cpp:106] Iteration 88000, lr = 0.000282296
I0811 15:33:31.468958  8383 solver.cpp:228] Iteration 88100, loss = 6.21566e-05
I0811 15:33:31.469003  8383 solver.cpp:244]     Train net output #0: loss = 6.21566e-05 (* 1 = 6.21566e-05 loss)
I0811 15:33:31.469010  8383 sgd_solver.cpp:106] Iteration 88100, lr = 0.0002821
I0811 15:33:34.727556  8383 solver.cpp:228] Iteration 88200, loss = 0.000128914
I0811 15:33:34.727610  8383 solver.cpp:244]     Train net output #0: loss = 0.000128914 (* 1 = 0.000128914 loss)
I0811 15:33:34.727617  8383 sgd_solver.cpp:106] Iteration 88200, lr = 0.000281905
I0811 15:33:38.017464  8383 solver.cpp:228] Iteration 88300, loss = 8.23134e-05
I0811 15:33:38.017504  8383 solver.cpp:244]     Train net output #0: loss = 8.23134e-05 (* 1 = 8.23134e-05 loss)
I0811 15:33:38.017511  8383 sgd_solver.cpp:106] Iteration 88300, lr = 0.000281709
I0811 15:33:41.284001  8383 solver.cpp:228] Iteration 88400, loss = 5.50902e-05
I0811 15:33:41.284042  8383 solver.cpp:244]     Train net output #0: loss = 5.50902e-05 (* 1 = 5.50902e-05 loss)
I0811 15:33:41.284049  8383 sgd_solver.cpp:106] Iteration 88400, lr = 0.000281514
I0811 15:33:44.546228  8383 solver.cpp:337] Iteration 88500, Testing net (#0)
I0811 15:33:51.180802  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898323
I0811 15:33:51.180873  8383 solver.cpp:404]     Test net output #1: loss = 0.716935 (* 1 = 0.716935 loss)
I0811 15:33:51.194080  8383 solver.cpp:228] Iteration 88500, loss = 6.10333e-05
I0811 15:33:51.194145  8383 solver.cpp:244]     Train net output #0: loss = 6.10333e-05 (* 1 = 6.10333e-05 loss)
I0811 15:33:51.194169  8383 sgd_solver.cpp:106] Iteration 88500, lr = 0.00028132
I0811 15:33:54.426045  8383 solver.cpp:228] Iteration 88600, loss = 7.49648e-05
I0811 15:33:54.426081  8383 solver.cpp:244]     Train net output #0: loss = 7.49648e-05 (* 1 = 7.49648e-05 loss)
I0811 15:33:54.426087  8383 sgd_solver.cpp:106] Iteration 88600, lr = 0.000281125
I0811 15:33:57.139127  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:33:57.661365  8383 solver.cpp:228] Iteration 88700, loss = 6.19199e-05
I0811 15:33:57.661404  8383 solver.cpp:244]     Train net output #0: loss = 6.19199e-05 (* 1 = 6.19199e-05 loss)
I0811 15:33:57.661411  8383 sgd_solver.cpp:106] Iteration 88700, lr = 0.000280931
I0811 15:34:00.959475  8383 solver.cpp:228] Iteration 88800, loss = 9.64621e-05
I0811 15:34:00.959513  8383 solver.cpp:244]     Train net output #0: loss = 9.64621e-05 (* 1 = 9.64621e-05 loss)
I0811 15:34:00.959519  8383 sgd_solver.cpp:106] Iteration 88800, lr = 0.000280738
I0811 15:34:04.222209  8383 solver.cpp:228] Iteration 88900, loss = 3.36465e-05
I0811 15:34:04.222252  8383 solver.cpp:244]     Train net output #0: loss = 3.36465e-05 (* 1 = 3.36465e-05 loss)
I0811 15:34:04.222259  8383 sgd_solver.cpp:106] Iteration 88900, lr = 0.000280544
I0811 15:34:07.463189  8383 solver.cpp:337] Iteration 89000, Testing net (#0)
I0811 15:34:13.897393  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897291
I0811 15:34:13.897460  8383 solver.cpp:404]     Test net output #1: loss = 0.729865 (* 1 = 0.729865 loss)
I0811 15:34:13.910549  8383 solver.cpp:228] Iteration 89000, loss = 0.000115722
I0811 15:34:13.910589  8383 solver.cpp:244]     Train net output #0: loss = 0.000115722 (* 1 = 0.000115722 loss)
I0811 15:34:13.910601  8383 sgd_solver.cpp:106] Iteration 89000, lr = 0.000280351
I0811 15:34:17.142854  8383 solver.cpp:228] Iteration 89100, loss = 0.00016755
I0811 15:34:17.142905  8383 solver.cpp:244]     Train net output #0: loss = 0.00016755 (* 1 = 0.00016755 loss)
I0811 15:34:17.142915  8383 sgd_solver.cpp:106] Iteration 89100, lr = 0.000280159
I0811 15:34:20.364805  8383 solver.cpp:228] Iteration 89200, loss = 4.11018e-05
I0811 15:34:20.364845  8383 solver.cpp:244]     Train net output #0: loss = 4.11018e-05 (* 1 = 4.11018e-05 loss)
I0811 15:34:20.364850  8383 sgd_solver.cpp:106] Iteration 89200, lr = 0.000279966
I0811 15:34:23.623102  8383 solver.cpp:228] Iteration 89300, loss = 3.23136e-05
I0811 15:34:23.623143  8383 solver.cpp:244]     Train net output #0: loss = 3.23136e-05 (* 1 = 3.23136e-05 loss)
I0811 15:34:23.623149  8383 sgd_solver.cpp:106] Iteration 89300, lr = 0.000279774
I0811 15:34:26.902861  8383 solver.cpp:228] Iteration 89400, loss = 5.13006e-05
I0811 15:34:26.902922  8383 solver.cpp:244]     Train net output #0: loss = 5.13006e-05 (* 1 = 5.13006e-05 loss)
I0811 15:34:26.902930  8383 sgd_solver.cpp:106] Iteration 89400, lr = 0.000279582
I0811 15:34:30.190809  8383 solver.cpp:337] Iteration 89500, Testing net (#0)
I0811 15:34:36.699724  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895161
I0811 15:34:36.699771  8383 solver.cpp:404]     Test net output #1: loss = 0.744654 (* 1 = 0.744654 loss)
I0811 15:34:36.712813  8383 solver.cpp:228] Iteration 89500, loss = 0.000109313
I0811 15:34:36.712860  8383 solver.cpp:244]     Train net output #0: loss = 0.000109313 (* 1 = 0.000109313 loss)
I0811 15:34:36.712877  8383 sgd_solver.cpp:106] Iteration 89500, lr = 0.000279391
I0811 15:34:39.926486  8383 solver.cpp:228] Iteration 89600, loss = 5.27206e-05
I0811 15:34:39.926528  8383 solver.cpp:244]     Train net output #0: loss = 5.27206e-05 (* 1 = 5.27206e-05 loss)
I0811 15:34:39.926535  8383 sgd_solver.cpp:106] Iteration 89600, lr = 0.000279199
I0811 15:34:43.168114  8383 solver.cpp:228] Iteration 89700, loss = 3.24624e-05
I0811 15:34:43.168155  8383 solver.cpp:244]     Train net output #0: loss = 3.24624e-05 (* 1 = 3.24624e-05 loss)
I0811 15:34:43.168161  8383 sgd_solver.cpp:106] Iteration 89700, lr = 0.000279009
I0811 15:34:46.442770  8383 solver.cpp:228] Iteration 89800, loss = 3.36455e-05
I0811 15:34:46.442819  8383 solver.cpp:244]     Train net output #0: loss = 3.36455e-05 (* 1 = 3.36455e-05 loss)
I0811 15:34:46.442826  8383 sgd_solver.cpp:106] Iteration 89800, lr = 0.000278818
I0811 15:34:49.720620  8383 solver.cpp:228] Iteration 89900, loss = 7.29764e-05
I0811 15:34:49.720662  8383 solver.cpp:244]     Train net output #0: loss = 7.29764e-05 (* 1 = 7.29764e-05 loss)
I0811 15:34:49.720669  8383 sgd_solver.cpp:106] Iteration 89900, lr = 0.000278628
I0811 15:34:52.938489  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_90000.caffemodel
I0811 15:34:53.316365  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_90000.solverstate
I0811 15:34:53.451581  8383 solver.cpp:337] Iteration 90000, Testing net (#0)
I0811 15:34:59.901842  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897581
I0811 15:34:59.901901  8383 solver.cpp:404]     Test net output #1: loss = 0.726376 (* 1 = 0.726376 loss)
I0811 15:34:59.914774  8383 solver.cpp:228] Iteration 90000, loss = 1.80863e-05
I0811 15:34:59.914798  8383 solver.cpp:244]     Train net output #0: loss = 1.80863e-05 (* 1 = 1.80863e-05 loss)
I0811 15:34:59.914808  8383 sgd_solver.cpp:106] Iteration 90000, lr = 0.000278438
I0811 15:35:03.146432  8383 solver.cpp:228] Iteration 90100, loss = 6.42756e-05
I0811 15:35:03.146467  8383 solver.cpp:244]     Train net output #0: loss = 6.42756e-05 (* 1 = 6.42756e-05 loss)
I0811 15:35:03.146474  8383 sgd_solver.cpp:106] Iteration 90100, lr = 0.000278248
I0811 15:35:06.443789  8383 solver.cpp:228] Iteration 90200, loss = 3.48633e-05
I0811 15:35:06.443838  8383 solver.cpp:244]     Train net output #0: loss = 3.48633e-05 (* 1 = 3.48633e-05 loss)
I0811 15:35:06.443845  8383 sgd_solver.cpp:106] Iteration 90200, lr = 0.000278059
I0811 15:35:09.696074  8383 solver.cpp:228] Iteration 90300, loss = 0.000110879
I0811 15:35:09.696116  8383 solver.cpp:244]     Train net output #0: loss = 0.000110879 (* 1 = 0.000110879 loss)
I0811 15:35:09.696123  8383 sgd_solver.cpp:106] Iteration 90300, lr = 0.00027787
I0811 15:35:12.980419  8383 solver.cpp:228] Iteration 90400, loss = 3.12208e-05
I0811 15:35:12.980440  8383 solver.cpp:244]     Train net output #0: loss = 3.12208e-05 (* 1 = 3.12208e-05 loss)
I0811 15:35:12.980446  8383 sgd_solver.cpp:106] Iteration 90400, lr = 0.000277681
I0811 15:35:13.241876  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:35:16.232972  8383 solver.cpp:337] Iteration 90500, Testing net (#0)
I0811 15:35:23.260882  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897548
I0811 15:35:23.260957  8383 solver.cpp:404]     Test net output #1: loss = 0.728652 (* 1 = 0.728652 loss)
I0811 15:35:23.272269  8383 solver.cpp:228] Iteration 90500, loss = 6.12721e-05
I0811 15:35:23.272308  8383 solver.cpp:244]     Train net output #0: loss = 6.12721e-05 (* 1 = 6.12721e-05 loss)
I0811 15:35:23.272328  8383 sgd_solver.cpp:106] Iteration 90500, lr = 0.000277492
I0811 15:35:26.509793  8383 solver.cpp:228] Iteration 90600, loss = 5.14934e-05
I0811 15:35:26.509841  8383 solver.cpp:244]     Train net output #0: loss = 5.14934e-05 (* 1 = 5.14934e-05 loss)
I0811 15:35:26.509847  8383 sgd_solver.cpp:106] Iteration 90600, lr = 0.000277304
I0811 15:35:29.807188  8383 solver.cpp:228] Iteration 90700, loss = 3.22497e-05
I0811 15:35:29.807238  8383 solver.cpp:244]     Train net output #0: loss = 3.22497e-05 (* 1 = 3.22497e-05 loss)
I0811 15:35:29.807246  8383 sgd_solver.cpp:106] Iteration 90700, lr = 0.000277116
I0811 15:35:33.105892  8383 solver.cpp:228] Iteration 90800, loss = 9.0523e-05
I0811 15:35:33.105937  8383 solver.cpp:244]     Train net output #0: loss = 9.0523e-05 (* 1 = 9.0523e-05 loss)
I0811 15:35:33.105943  8383 sgd_solver.cpp:106] Iteration 90800, lr = 0.000276929
I0811 15:35:36.356056  8383 solver.cpp:228] Iteration 90900, loss = 5.10151e-05
I0811 15:35:36.356096  8383 solver.cpp:244]     Train net output #0: loss = 5.10151e-05 (* 1 = 5.10151e-05 loss)
I0811 15:35:36.356103  8383 sgd_solver.cpp:106] Iteration 90900, lr = 0.000276741
I0811 15:35:39.595348  8383 solver.cpp:337] Iteration 91000, Testing net (#0)
I0811 15:35:46.067852  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896677
I0811 15:35:46.067911  8383 solver.cpp:404]     Test net output #1: loss = 0.738113 (* 1 = 0.738113 loss)
I0811 15:35:46.080972  8383 solver.cpp:228] Iteration 91000, loss = 2.1405e-05
I0811 15:35:46.080994  8383 solver.cpp:244]     Train net output #0: loss = 2.1405e-05 (* 1 = 2.1405e-05 loss)
I0811 15:35:46.081007  8383 sgd_solver.cpp:106] Iteration 91000, lr = 0.000276554
I0811 15:35:49.350196  8383 solver.cpp:228] Iteration 91100, loss = 7.67764e-05
I0811 15:35:49.350239  8383 solver.cpp:244]     Train net output #0: loss = 7.67764e-05 (* 1 = 7.67764e-05 loss)
I0811 15:35:49.350247  8383 sgd_solver.cpp:106] Iteration 91100, lr = 0.000276368
I0811 15:35:52.598403  8383 solver.cpp:228] Iteration 91200, loss = 0.000158359
I0811 15:35:52.598449  8383 solver.cpp:244]     Train net output #0: loss = 0.000158359 (* 1 = 0.000158359 loss)
I0811 15:35:52.598456  8383 sgd_solver.cpp:106] Iteration 91200, lr = 0.000276181
I0811 15:35:55.872385  8383 solver.cpp:228] Iteration 91300, loss = 4.57915e-05
I0811 15:35:55.872422  8383 solver.cpp:244]     Train net output #0: loss = 4.57915e-05 (* 1 = 4.57915e-05 loss)
I0811 15:35:55.872429  8383 sgd_solver.cpp:106] Iteration 91300, lr = 0.000275995
I0811 15:35:59.143611  8383 solver.cpp:228] Iteration 91400, loss = 6.20847e-05
I0811 15:35:59.143651  8383 solver.cpp:244]     Train net output #0: loss = 6.20847e-05 (* 1 = 6.20847e-05 loss)
I0811 15:35:59.143656  8383 sgd_solver.cpp:106] Iteration 91400, lr = 0.000275809
I0811 15:36:02.403362  8383 solver.cpp:337] Iteration 91500, Testing net (#0)
I0811 15:36:09.056762  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895226
I0811 15:36:09.056825  8383 solver.cpp:404]     Test net output #1: loss = 0.748485 (* 1 = 0.748485 loss)
I0811 15:36:09.066778  8383 solver.cpp:228] Iteration 91500, loss = 4.07332e-05
I0811 15:36:09.066812  8383 solver.cpp:244]     Train net output #0: loss = 4.07332e-05 (* 1 = 4.07332e-05 loss)
I0811 15:36:09.066823  8383 sgd_solver.cpp:106] Iteration 91500, lr = 0.000275624
I0811 15:36:11.256661  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:36:12.257088  8383 solver.cpp:228] Iteration 91600, loss = 3.90255e-05
I0811 15:36:12.257136  8383 solver.cpp:244]     Train net output #0: loss = 3.90255e-05 (* 1 = 3.90255e-05 loss)
I0811 15:36:12.257143  8383 sgd_solver.cpp:106] Iteration 91600, lr = 0.000275438
I0811 15:36:15.512210  8383 solver.cpp:228] Iteration 91700, loss = 0.000127392
I0811 15:36:15.512248  8383 solver.cpp:244]     Train net output #0: loss = 0.000127392 (* 1 = 0.000127392 loss)
I0811 15:36:15.512253  8383 sgd_solver.cpp:106] Iteration 91700, lr = 0.000275253
I0811 15:36:18.761497  8383 solver.cpp:228] Iteration 91800, loss = 0.000157737
I0811 15:36:18.761543  8383 solver.cpp:244]     Train net output #0: loss = 0.000157737 (* 1 = 0.000157737 loss)
I0811 15:36:18.761550  8383 sgd_solver.cpp:106] Iteration 91800, lr = 0.000275069
I0811 15:36:22.022547  8383 solver.cpp:228] Iteration 91900, loss = 0.000193233
I0811 15:36:22.022586  8383 solver.cpp:244]     Train net output #0: loss = 0.000193233 (* 1 = 0.000193233 loss)
I0811 15:36:22.022593  8383 sgd_solver.cpp:106] Iteration 91900, lr = 0.000274884
I0811 15:36:25.250443  8383 solver.cpp:337] Iteration 92000, Testing net (#0)
I0811 15:36:31.791234  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898032
I0811 15:36:31.791288  8383 solver.cpp:404]     Test net output #1: loss = 0.725114 (* 1 = 0.725114 loss)
I0811 15:36:31.804375  8383 solver.cpp:228] Iteration 92000, loss = 0.00021417
I0811 15:36:31.804410  8383 solver.cpp:244]     Train net output #0: loss = 0.00021417 (* 1 = 0.00021417 loss)
I0811 15:36:31.804430  8383 sgd_solver.cpp:106] Iteration 92000, lr = 0.0002747
I0811 15:36:35.029147  8383 solver.cpp:228] Iteration 92100, loss = 3.5058e-05
I0811 15:36:35.029188  8383 solver.cpp:244]     Train net output #0: loss = 3.5058e-05 (* 1 = 3.5058e-05 loss)
I0811 15:36:35.029194  8383 sgd_solver.cpp:106] Iteration 92100, lr = 0.000274516
I0811 15:36:38.250998  8383 solver.cpp:228] Iteration 92200, loss = 4.19737e-05
I0811 15:36:38.251037  8383 solver.cpp:244]     Train net output #0: loss = 4.19737e-05 (* 1 = 4.19737e-05 loss)
I0811 15:36:38.251044  8383 sgd_solver.cpp:106] Iteration 92200, lr = 0.000274333
I0811 15:36:41.527099  8383 solver.cpp:228] Iteration 92300, loss = 7.38483e-05
I0811 15:36:41.527142  8383 solver.cpp:244]     Train net output #0: loss = 7.38483e-05 (* 1 = 7.38483e-05 loss)
I0811 15:36:41.527148  8383 sgd_solver.cpp:106] Iteration 92300, lr = 0.00027415
I0811 15:36:44.790753  8383 solver.cpp:228] Iteration 92400, loss = 5.52272e-05
I0811 15:36:44.790789  8383 solver.cpp:244]     Train net output #0: loss = 5.52272e-05 (* 1 = 5.52272e-05 loss)
I0811 15:36:44.790796  8383 sgd_solver.cpp:106] Iteration 92400, lr = 0.000273967
I0811 15:36:48.023900  8383 solver.cpp:337] Iteration 92500, Testing net (#0)
I0811 15:36:54.740520  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897677
I0811 15:36:54.740591  8383 solver.cpp:404]     Test net output #1: loss = 0.728794 (* 1 = 0.728794 loss)
I0811 15:36:54.753346  8383 solver.cpp:228] Iteration 92500, loss = 3.00989e-05
I0811 15:36:54.753412  8383 solver.cpp:244]     Train net output #0: loss = 3.00989e-05 (* 1 = 3.00989e-05 loss)
I0811 15:36:54.753434  8383 sgd_solver.cpp:106] Iteration 92500, lr = 0.000273784
I0811 15:36:57.953315  8383 solver.cpp:228] Iteration 92600, loss = 6.01447e-05
I0811 15:36:57.953356  8383 solver.cpp:244]     Train net output #0: loss = 6.01447e-05 (* 1 = 6.01447e-05 loss)
I0811 15:36:57.953361  8383 sgd_solver.cpp:106] Iteration 92600, lr = 0.000273602
I0811 15:37:01.232177  8383 solver.cpp:228] Iteration 92700, loss = 2.26432e-05
I0811 15:37:01.232214  8383 solver.cpp:244]     Train net output #0: loss = 2.26432e-05 (* 1 = 2.26432e-05 loss)
I0811 15:37:01.232220  8383 sgd_solver.cpp:106] Iteration 92700, lr = 0.00027342
I0811 15:37:04.499544  8383 solver.cpp:228] Iteration 92800, loss = 0.000136694
I0811 15:37:04.499595  8383 solver.cpp:244]     Train net output #0: loss = 0.000136694 (* 1 = 0.000136694 loss)
I0811 15:37:04.499601  8383 sgd_solver.cpp:106] Iteration 92800, lr = 0.000273238
I0811 15:37:07.766762  8383 solver.cpp:228] Iteration 92900, loss = 0.000305338
I0811 15:37:07.766801  8383 solver.cpp:244]     Train net output #0: loss = 0.000305338 (* 1 = 0.000305338 loss)
I0811 15:37:07.766808  8383 sgd_solver.cpp:106] Iteration 92900, lr = 0.000273056
I0811 15:37:11.014503  8383 solver.cpp:337] Iteration 93000, Testing net (#0)
I0811 15:37:16.712628  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:37:17.856807  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896871
I0811 15:37:17.856881  8383 solver.cpp:404]     Test net output #1: loss = 0.738216 (* 1 = 0.738216 loss)
I0811 15:37:17.869249  8383 solver.cpp:228] Iteration 93000, loss = 3.05813e-05
I0811 15:37:17.869299  8383 solver.cpp:244]     Train net output #0: loss = 3.05813e-05 (* 1 = 3.05813e-05 loss)
I0811 15:37:17.869313  8383 sgd_solver.cpp:106] Iteration 93000, lr = 0.000272875
I0811 15:37:21.105988  8383 solver.cpp:228] Iteration 93100, loss = 7.67792e-05
I0811 15:37:21.106034  8383 solver.cpp:244]     Train net output #0: loss = 7.67792e-05 (* 1 = 7.67792e-05 loss)
I0811 15:37:21.106041  8383 sgd_solver.cpp:106] Iteration 93100, lr = 0.000272694
I0811 15:37:24.423880  8383 solver.cpp:228] Iteration 93200, loss = 4.08006e-05
I0811 15:37:24.423933  8383 solver.cpp:244]     Train net output #0: loss = 4.08006e-05 (* 1 = 4.08006e-05 loss)
I0811 15:37:24.423943  8383 sgd_solver.cpp:106] Iteration 93200, lr = 0.000272513
I0811 15:37:27.690794  8383 solver.cpp:228] Iteration 93300, loss = 3.14328e-05
I0811 15:37:27.690834  8383 solver.cpp:244]     Train net output #0: loss = 3.14328e-05 (* 1 = 3.14328e-05 loss)
I0811 15:37:27.690840  8383 sgd_solver.cpp:106] Iteration 93300, lr = 0.000272333
I0811 15:37:30.962880  8383 solver.cpp:228] Iteration 93400, loss = 5.2351e-05
I0811 15:37:30.962920  8383 solver.cpp:244]     Train net output #0: loss = 5.2351e-05 (* 1 = 5.2351e-05 loss)
I0811 15:37:30.962926  8383 sgd_solver.cpp:106] Iteration 93400, lr = 0.000272153
I0811 15:37:34.201764  8383 solver.cpp:337] Iteration 93500, Testing net (#0)
I0811 15:37:40.737593  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895935
I0811 15:37:40.737653  8383 solver.cpp:404]     Test net output #1: loss = 0.746043 (* 1 = 0.746043 loss)
I0811 15:37:40.747671  8383 solver.cpp:228] Iteration 93500, loss = 4.64402e-05
I0811 15:37:40.747700  8383 solver.cpp:244]     Train net output #0: loss = 4.64402e-05 (* 1 = 4.64402e-05 loss)
I0811 15:37:40.747711  8383 sgd_solver.cpp:106] Iteration 93500, lr = 0.000271973
I0811 15:37:43.960815  8383 solver.cpp:228] Iteration 93600, loss = 3.06368e-05
I0811 15:37:43.960857  8383 solver.cpp:244]     Train net output #0: loss = 3.06368e-05 (* 1 = 3.06368e-05 loss)
I0811 15:37:43.960865  8383 sgd_solver.cpp:106] Iteration 93600, lr = 0.000271793
I0811 15:37:47.195170  8383 solver.cpp:228] Iteration 93700, loss = 6.17357e-05
I0811 15:37:47.195214  8383 solver.cpp:244]     Train net output #0: loss = 6.17357e-05 (* 1 = 6.17357e-05 loss)
I0811 15:37:47.195219  8383 sgd_solver.cpp:106] Iteration 93700, lr = 0.000271614
I0811 15:37:50.444334  8383 solver.cpp:228] Iteration 93800, loss = 4.94934e-05
I0811 15:37:50.444385  8383 solver.cpp:244]     Train net output #0: loss = 4.94934e-05 (* 1 = 4.94934e-05 loss)
I0811 15:37:50.444391  8383 sgd_solver.cpp:106] Iteration 93800, lr = 0.000271435
I0811 15:37:53.726951  8383 solver.cpp:228] Iteration 93900, loss = 6.37454e-05
I0811 15:37:53.726990  8383 solver.cpp:244]     Train net output #0: loss = 6.37454e-05 (* 1 = 6.37454e-05 loss)
I0811 15:37:53.726996  8383 sgd_solver.cpp:106] Iteration 93900, lr = 0.000271256
I0811 15:37:56.964438  8383 solver.cpp:337] Iteration 94000, Testing net (#0)
I0811 15:38:03.875900  8383 solver.cpp:404]     Test net output #0: accuracy = 0.898258
I0811 15:38:03.875967  8383 solver.cpp:404]     Test net output #1: loss = 0.726655 (* 1 = 0.726655 loss)
I0811 15:38:03.886008  8383 solver.cpp:228] Iteration 94000, loss = 8.08632e-05
I0811 15:38:03.886049  8383 solver.cpp:244]     Train net output #0: loss = 8.08632e-05 (* 1 = 8.08632e-05 loss)
I0811 15:38:03.886060  8383 sgd_solver.cpp:106] Iteration 94000, lr = 0.000271078
I0811 15:38:07.140913  8383 solver.cpp:228] Iteration 94100, loss = 0.00011933
I0811 15:38:07.140954  8383 solver.cpp:244]     Train net output #0: loss = 0.00011933 (* 1 = 0.00011933 loss)
I0811 15:38:07.140960  8383 sgd_solver.cpp:106] Iteration 94100, lr = 0.0002709
I0811 15:38:10.409189  8383 solver.cpp:228] Iteration 94200, loss = 9.27433e-05
I0811 15:38:10.409235  8383 solver.cpp:244]     Train net output #0: loss = 9.27433e-05 (* 1 = 9.27433e-05 loss)
I0811 15:38:10.409241  8383 sgd_solver.cpp:106] Iteration 94200, lr = 0.000270722
I0811 15:38:13.679942  8383 solver.cpp:228] Iteration 94300, loss = 5.65996e-05
I0811 15:38:13.679994  8383 solver.cpp:244]     Train net output #0: loss = 5.65996e-05 (* 1 = 5.65996e-05 loss)
I0811 15:38:13.680001  8383 sgd_solver.cpp:106] Iteration 94300, lr = 0.000270544
I0811 15:38:16.963511  8383 solver.cpp:228] Iteration 94400, loss = 3.53753e-05
I0811 15:38:16.963544  8383 solver.cpp:244]     Train net output #0: loss = 3.53753e-05 (* 1 = 3.53753e-05 loss)
I0811 15:38:16.963551  8383 sgd_solver.cpp:106] Iteration 94400, lr = 0.000270367
I0811 15:38:20.204910  8383 solver.cpp:337] Iteration 94500, Testing net (#0)
I0811 15:38:24.836629  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:38:26.869170  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897
I0811 15:38:26.869257  8383 solver.cpp:404]     Test net output #1: loss = 0.739011 (* 1 = 0.739011 loss)
I0811 15:38:26.881111  8383 solver.cpp:228] Iteration 94500, loss = 0.00013799
I0811 15:38:26.881175  8383 solver.cpp:244]     Train net output #0: loss = 0.00013799 (* 1 = 0.00013799 loss)
I0811 15:38:26.881198  8383 sgd_solver.cpp:106] Iteration 94500, lr = 0.000270189
I0811 15:38:30.088913  8383 solver.cpp:228] Iteration 94600, loss = 4.22339e-05
I0811 15:38:30.088950  8383 solver.cpp:244]     Train net output #0: loss = 4.22339e-05 (* 1 = 4.22339e-05 loss)
I0811 15:38:30.088956  8383 sgd_solver.cpp:106] Iteration 94600, lr = 0.000270013
I0811 15:38:33.342080  8383 solver.cpp:228] Iteration 94700, loss = 4.77027e-05
I0811 15:38:33.342128  8383 solver.cpp:244]     Train net output #0: loss = 4.77027e-05 (* 1 = 4.77027e-05 loss)
I0811 15:38:33.342136  8383 sgd_solver.cpp:106] Iteration 94700, lr = 0.000269836
I0811 15:38:36.636997  8383 solver.cpp:228] Iteration 94800, loss = 3.53799e-05
I0811 15:38:36.637038  8383 solver.cpp:244]     Train net output #0: loss = 3.53799e-05 (* 1 = 3.53799e-05 loss)
I0811 15:38:36.637045  8383 sgd_solver.cpp:106] Iteration 94800, lr = 0.00026966
I0811 15:38:39.906142  8383 solver.cpp:228] Iteration 94900, loss = 2.10937e-05
I0811 15:38:39.906183  8383 solver.cpp:244]     Train net output #0: loss = 2.10937e-05 (* 1 = 2.10937e-05 loss)
I0811 15:38:39.906189  8383 sgd_solver.cpp:106] Iteration 94900, lr = 0.000269484
I0811 15:38:43.176430  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_95000.caffemodel
I0811 15:38:43.546844  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_95000.solverstate
I0811 15:38:43.678992  8383 solver.cpp:337] Iteration 95000, Testing net (#0)
I0811 15:38:50.155235  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895774
I0811 15:38:50.155374  8383 solver.cpp:404]     Test net output #1: loss = 0.750284 (* 1 = 0.750284 loss)
I0811 15:38:50.167822  8383 solver.cpp:228] Iteration 95000, loss = 2.16407e-05
I0811 15:38:50.167852  8383 solver.cpp:244]     Train net output #0: loss = 2.16407e-05 (* 1 = 2.16407e-05 loss)
I0811 15:38:50.167875  8383 sgd_solver.cpp:106] Iteration 95000, lr = 0.000269308
I0811 15:38:53.360388  8383 solver.cpp:228] Iteration 95100, loss = 4.34763e-05
I0811 15:38:53.360430  8383 solver.cpp:244]     Train net output #0: loss = 4.34763e-05 (* 1 = 4.34763e-05 loss)
I0811 15:38:53.360436  8383 sgd_solver.cpp:106] Iteration 95100, lr = 0.000269132
I0811 15:38:56.619259  8383 solver.cpp:228] Iteration 95200, loss = 0.000161052
I0811 15:38:56.619333  8383 solver.cpp:244]     Train net output #0: loss = 0.000161052 (* 1 = 0.000161052 loss)
I0811 15:38:56.619341  8383 sgd_solver.cpp:106] Iteration 95200, lr = 0.000268957
I0811 15:38:59.877851  8383 solver.cpp:228] Iteration 95300, loss = 2.60906e-05
I0811 15:38:59.877912  8383 solver.cpp:244]     Train net output #0: loss = 2.60906e-05 (* 1 = 2.60906e-05 loss)
I0811 15:38:59.877919  8383 sgd_solver.cpp:106] Iteration 95300, lr = 0.000268782
I0811 15:39:03.157724  8383 solver.cpp:228] Iteration 95400, loss = 4.75572e-05
I0811 15:39:03.157770  8383 solver.cpp:244]     Train net output #0: loss = 4.75572e-05 (* 1 = 4.75572e-05 loss)
I0811 15:39:03.157776  8383 sgd_solver.cpp:106] Iteration 95400, lr = 0.000268608
I0811 15:39:06.382349  8383 solver.cpp:337] Iteration 95500, Testing net (#0)
I0811 15:39:12.992177  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897097
I0811 15:39:12.992252  8383 solver.cpp:404]     Test net output #1: loss = 0.740296 (* 1 = 0.740296 loss)
I0811 15:39:13.004639  8383 solver.cpp:228] Iteration 95500, loss = 4.46491e-05
I0811 15:39:13.004673  8383 solver.cpp:244]     Train net output #0: loss = 4.46491e-05 (* 1 = 4.46491e-05 loss)
I0811 15:39:13.004690  8383 sgd_solver.cpp:106] Iteration 95500, lr = 0.000268433
I0811 15:39:16.230152  8383 solver.cpp:228] Iteration 95600, loss = 0.000107679
I0811 15:39:16.230211  8383 solver.cpp:244]     Train net output #0: loss = 0.000107679 (* 1 = 0.000107679 loss)
I0811 15:39:16.230218  8383 sgd_solver.cpp:106] Iteration 95600, lr = 0.000268259
I0811 15:39:19.486511  8383 solver.cpp:228] Iteration 95700, loss = 4.49178e-05
I0811 15:39:19.486562  8383 solver.cpp:244]     Train net output #0: loss = 4.49178e-05 (* 1 = 4.49178e-05 loss)
I0811 15:39:19.486569  8383 sgd_solver.cpp:106] Iteration 95700, lr = 0.000268085
I0811 15:39:22.760815  8383 solver.cpp:228] Iteration 95800, loss = 4.55169e-05
I0811 15:39:22.760880  8383 solver.cpp:244]     Train net output #0: loss = 4.55169e-05 (* 1 = 4.55169e-05 loss)
I0811 15:39:22.760892  8383 sgd_solver.cpp:106] Iteration 95800, lr = 0.000267911
I0811 15:39:26.032722  8383 solver.cpp:228] Iteration 95900, loss = 0.000112455
I0811 15:39:26.032770  8383 solver.cpp:244]     Train net output #0: loss = 0.000112455 (* 1 = 0.000112455 loss)
I0811 15:39:26.032778  8383 sgd_solver.cpp:106] Iteration 95900, lr = 0.000267738
I0811 15:39:29.265712  8383 solver.cpp:337] Iteration 96000, Testing net (#0)
I0811 15:39:30.143796  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:39:36.137060  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897936
I0811 15:39:36.137115  8383 solver.cpp:404]     Test net output #1: loss = 0.731523 (* 1 = 0.731523 loss)
I0811 15:39:36.147724  8383 solver.cpp:228] Iteration 96000, loss = 4.37537e-05
I0811 15:39:36.147794  8383 solver.cpp:244]     Train net output #0: loss = 4.37537e-05 (* 1 = 4.37537e-05 loss)
I0811 15:39:36.147815  8383 sgd_solver.cpp:106] Iteration 96000, lr = 0.000267565
I0811 15:39:39.370072  8383 solver.cpp:228] Iteration 96100, loss = 6.66804e-05
I0811 15:39:39.370116  8383 solver.cpp:244]     Train net output #0: loss = 6.66804e-05 (* 1 = 6.66804e-05 loss)
I0811 15:39:39.370123  8383 sgd_solver.cpp:106] Iteration 96100, lr = 0.000267392
I0811 15:39:42.629066  8383 solver.cpp:228] Iteration 96200, loss = 4.79082e-05
I0811 15:39:42.629123  8383 solver.cpp:244]     Train net output #0: loss = 4.79082e-05 (* 1 = 4.79082e-05 loss)
I0811 15:39:42.629133  8383 sgd_solver.cpp:106] Iteration 96200, lr = 0.000267219
I0811 15:39:45.912317  8383 solver.cpp:228] Iteration 96300, loss = 5.38896e-05
I0811 15:39:45.912372  8383 solver.cpp:244]     Train net output #0: loss = 5.38896e-05 (* 1 = 5.38896e-05 loss)
I0811 15:39:45.912391  8383 sgd_solver.cpp:106] Iteration 96300, lr = 0.000267047
I0811 15:39:49.193927  8383 solver.cpp:228] Iteration 96400, loss = 3.54109e-05
I0811 15:39:49.193969  8383 solver.cpp:244]     Train net output #0: loss = 3.54109e-05 (* 1 = 3.54109e-05 loss)
I0811 15:39:49.193975  8383 sgd_solver.cpp:106] Iteration 96400, lr = 0.000266875
I0811 15:39:52.437557  8383 solver.cpp:337] Iteration 96500, Testing net (#0)
I0811 15:39:59.254083  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89671
I0811 15:39:59.254139  8383 solver.cpp:404]     Test net output #1: loss = 0.745403 (* 1 = 0.745403 loss)
I0811 15:39:59.267449  8383 solver.cpp:228] Iteration 96500, loss = 6.17995e-05
I0811 15:39:59.267483  8383 solver.cpp:244]     Train net output #0: loss = 6.17995e-05 (* 1 = 6.17995e-05 loss)
I0811 15:39:59.267498  8383 sgd_solver.cpp:106] Iteration 96500, lr = 0.000266703
I0811 15:40:02.508011  8383 solver.cpp:228] Iteration 96600, loss = 0.000138895
I0811 15:40:02.508045  8383 solver.cpp:244]     Train net output #0: loss = 0.000138895 (* 1 = 0.000138895 loss)
I0811 15:40:02.508051  8383 sgd_solver.cpp:106] Iteration 96600, lr = 0.000266532
I0811 15:40:05.757519  8383 solver.cpp:228] Iteration 96700, loss = 5.6666e-05
I0811 15:40:05.757572  8383 solver.cpp:244]     Train net output #0: loss = 5.6666e-05 (* 1 = 5.6666e-05 loss)
I0811 15:40:05.757583  8383 sgd_solver.cpp:106] Iteration 96700, lr = 0.00026636
I0811 15:40:09.008905  8383 solver.cpp:228] Iteration 96800, loss = 3.69799e-05
I0811 15:40:09.008949  8383 solver.cpp:244]     Train net output #0: loss = 3.69799e-05 (* 1 = 3.69799e-05 loss)
I0811 15:40:09.008955  8383 sgd_solver.cpp:106] Iteration 96800, lr = 0.000266189
I0811 15:40:12.279335  8383 solver.cpp:228] Iteration 96900, loss = 5.78415e-05
I0811 15:40:12.279373  8383 solver.cpp:244]     Train net output #0: loss = 5.78415e-05 (* 1 = 5.78415e-05 loss)
I0811 15:40:12.279379  8383 sgd_solver.cpp:106] Iteration 96900, lr = 0.000266018
I0811 15:40:15.521878  8383 solver.cpp:337] Iteration 97000, Testing net (#0)
I0811 15:40:21.438989  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:40:22.507489  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895419
I0811 15:40:22.507519  8383 solver.cpp:404]     Test net output #1: loss = 0.756005 (* 1 = 0.756005 loss)
I0811 15:40:22.519805  8383 solver.cpp:228] Iteration 97000, loss = 2.78239e-05
I0811 15:40:22.519836  8383 solver.cpp:244]     Train net output #0: loss = 2.78239e-05 (* 1 = 2.78239e-05 loss)
I0811 15:40:22.519855  8383 sgd_solver.cpp:106] Iteration 97000, lr = 0.000265848
I0811 15:40:25.753222  8383 solver.cpp:228] Iteration 97100, loss = 6.10468e-05
I0811 15:40:25.753283  8383 solver.cpp:244]     Train net output #0: loss = 6.10468e-05 (* 1 = 6.10468e-05 loss)
I0811 15:40:25.753294  8383 sgd_solver.cpp:106] Iteration 97100, lr = 0.000265678
I0811 15:40:28.977689  8383 solver.cpp:228] Iteration 97200, loss = 6.46248e-05
I0811 15:40:28.977746  8383 solver.cpp:244]     Train net output #0: loss = 6.46248e-05 (* 1 = 6.46248e-05 loss)
I0811 15:40:28.977752  8383 sgd_solver.cpp:106] Iteration 97200, lr = 0.000265508
I0811 15:40:32.228196  8383 solver.cpp:228] Iteration 97300, loss = 5.30732e-05
I0811 15:40:32.228237  8383 solver.cpp:244]     Train net output #0: loss = 5.30732e-05 (* 1 = 5.30732e-05 loss)
I0811 15:40:32.228243  8383 sgd_solver.cpp:106] Iteration 97300, lr = 0.000265338
I0811 15:40:35.511016  8383 solver.cpp:228] Iteration 97400, loss = 3.69199e-05
I0811 15:40:35.511059  8383 solver.cpp:244]     Train net output #0: loss = 3.69199e-05 (* 1 = 3.69199e-05 loss)
I0811 15:40:35.511065  8383 sgd_solver.cpp:106] Iteration 97400, lr = 0.000265168
I0811 15:40:38.745951  8383 solver.cpp:337] Iteration 97500, Testing net (#0)
I0811 15:40:45.524029  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897258
I0811 15:40:45.524096  8383 solver.cpp:404]     Test net output #1: loss = 0.742657 (* 1 = 0.742657 loss)
I0811 15:40:45.536631  8383 solver.cpp:228] Iteration 97500, loss = 2.07828e-05
I0811 15:40:45.536658  8383 solver.cpp:244]     Train net output #0: loss = 2.07828e-05 (* 1 = 2.07828e-05 loss)
I0811 15:40:45.536670  8383 sgd_solver.cpp:106] Iteration 97500, lr = 0.000264999
I0811 15:40:48.773185  8383 solver.cpp:228] Iteration 97600, loss = 3.41504e-05
I0811 15:40:48.773228  8383 solver.cpp:244]     Train net output #0: loss = 3.41504e-05 (* 1 = 3.41504e-05 loss)
I0811 15:40:48.773238  8383 sgd_solver.cpp:106] Iteration 97600, lr = 0.00026483
I0811 15:40:52.073364  8383 solver.cpp:228] Iteration 97700, loss = 0.000123564
I0811 15:40:52.073410  8383 solver.cpp:244]     Train net output #0: loss = 0.000123564 (* 1 = 0.000123564 loss)
I0811 15:40:52.073416  8383 sgd_solver.cpp:106] Iteration 97700, lr = 0.000264661
I0811 15:40:55.372236  8383 solver.cpp:228] Iteration 97800, loss = 7.59861e-05
I0811 15:40:55.372298  8383 solver.cpp:244]     Train net output #0: loss = 7.59861e-05 (* 1 = 7.59861e-05 loss)
I0811 15:40:55.372304  8383 sgd_solver.cpp:106] Iteration 97800, lr = 0.000264493
I0811 15:40:58.646399  8383 solver.cpp:228] Iteration 97900, loss = 4.88796e-05
I0811 15:40:58.646435  8383 solver.cpp:244]     Train net output #0: loss = 4.88796e-05 (* 1 = 4.88796e-05 loss)
I0811 15:40:58.646441  8383 sgd_solver.cpp:106] Iteration 97900, lr = 0.000264324
I0811 15:41:01.950525  8383 solver.cpp:337] Iteration 98000, Testing net (#0)
I0811 15:41:08.366092  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897355
I0811 15:41:08.366163  8383 solver.cpp:404]     Test net output #1: loss = 0.740456 (* 1 = 0.740456 loss)
I0811 15:41:08.377079  8383 solver.cpp:228] Iteration 98000, loss = 3.39192e-05
I0811 15:41:08.377141  8383 solver.cpp:244]     Train net output #0: loss = 3.39192e-05 (* 1 = 3.39192e-05 loss)
I0811 15:41:08.377164  8383 sgd_solver.cpp:106] Iteration 98000, lr = 0.000264156
I0811 15:41:11.615254  8383 solver.cpp:228] Iteration 98100, loss = 5.20658e-05
I0811 15:41:11.615293  8383 solver.cpp:244]     Train net output #0: loss = 5.20658e-05 (* 1 = 5.20658e-05 loss)
I0811 15:41:11.615300  8383 sgd_solver.cpp:106] Iteration 98100, lr = 0.000263989
I0811 15:41:14.827473  8383 solver.cpp:228] Iteration 98200, loss = 3.81444e-05
I0811 15:41:14.827523  8383 solver.cpp:244]     Train net output #0: loss = 3.81444e-05 (* 1 = 3.81444e-05 loss)
I0811 15:41:14.827530  8383 sgd_solver.cpp:106] Iteration 98200, lr = 0.000263821
I0811 15:41:18.061025  8383 solver.cpp:228] Iteration 98300, loss = 4.68542e-05
I0811 15:41:18.061046  8383 solver.cpp:244]     Train net output #0: loss = 4.68542e-05 (* 1 = 4.68542e-05 loss)
I0811 15:41:18.061053  8383 sgd_solver.cpp:106] Iteration 98300, lr = 0.000263654
I0811 15:41:21.358223  8383 solver.cpp:228] Iteration 98400, loss = 4.256e-05
I0811 15:41:21.358266  8383 solver.cpp:244]     Train net output #0: loss = 4.256e-05 (* 1 = 4.256e-05 loss)
I0811 15:41:21.358273  8383 sgd_solver.cpp:106] Iteration 98400, lr = 0.000263487
I0811 15:41:24.588383  8383 solver.cpp:337] Iteration 98500, Testing net (#0)
I0811 15:41:28.082824  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:41:31.384166  8383 solver.cpp:404]     Test net output #0: accuracy = 0.896871
I0811 15:41:31.384209  8383 solver.cpp:404]     Test net output #1: loss = 0.746508 (* 1 = 0.746508 loss)
I0811 15:41:31.396654  8383 solver.cpp:228] Iteration 98500, loss = 5.29528e-05
I0811 15:41:31.396687  8383 solver.cpp:244]     Train net output #0: loss = 5.29528e-05 (* 1 = 5.29528e-05 loss)
I0811 15:41:31.396702  8383 sgd_solver.cpp:106] Iteration 98500, lr = 0.00026332
I0811 15:41:34.611044  8383 solver.cpp:228] Iteration 98600, loss = 1.61161e-05
I0811 15:41:34.611093  8383 solver.cpp:244]     Train net output #0: loss = 1.61161e-05 (* 1 = 1.61161e-05 loss)
I0811 15:41:34.611102  8383 sgd_solver.cpp:106] Iteration 98600, lr = 0.000263153
I0811 15:41:37.866224  8383 solver.cpp:228] Iteration 98700, loss = 3.76409e-05
I0811 15:41:37.866283  8383 solver.cpp:244]     Train net output #0: loss = 3.76409e-05 (* 1 = 3.76409e-05 loss)
I0811 15:41:37.866295  8383 sgd_solver.cpp:106] Iteration 98700, lr = 0.000262987
I0811 15:41:41.098469  8383 solver.cpp:228] Iteration 98800, loss = 2.72963e-05
I0811 15:41:41.098506  8383 solver.cpp:244]     Train net output #0: loss = 2.72963e-05 (* 1 = 2.72963e-05 loss)
I0811 15:41:41.098513  8383 sgd_solver.cpp:106] Iteration 98800, lr = 0.000262821
I0811 15:41:44.408938  8383 solver.cpp:228] Iteration 98900, loss = 7.22553e-05
I0811 15:41:44.408969  8383 solver.cpp:244]     Train net output #0: loss = 7.22553e-05 (* 1 = 7.22553e-05 loss)
I0811 15:41:44.408975  8383 sgd_solver.cpp:106] Iteration 98900, lr = 0.000262655
I0811 15:41:47.644579  8383 solver.cpp:337] Iteration 99000, Testing net (#0)
I0811 15:41:54.449640  8383 solver.cpp:404]     Test net output #0: accuracy = 0.895871
I0811 15:41:54.449700  8383 solver.cpp:404]     Test net output #1: loss = 0.755443 (* 1 = 0.755443 loss)
I0811 15:41:54.462028  8383 solver.cpp:228] Iteration 99000, loss = 2.61855e-05
I0811 15:41:54.462051  8383 solver.cpp:244]     Train net output #0: loss = 2.61855e-05 (* 1 = 2.61855e-05 loss)
I0811 15:41:54.462074  8383 sgd_solver.cpp:106] Iteration 99000, lr = 0.00026249
I0811 15:41:57.653803  8383 solver.cpp:228] Iteration 99100, loss = 2.95885e-05
I0811 15:41:57.653857  8383 solver.cpp:244]     Train net output #0: loss = 2.95885e-05 (* 1 = 2.95885e-05 loss)
I0811 15:41:57.653866  8383 sgd_solver.cpp:106] Iteration 99100, lr = 0.000262324
I0811 15:42:00.938733  8383 solver.cpp:228] Iteration 99200, loss = 3.00441e-05
I0811 15:42:00.938787  8383 solver.cpp:244]     Train net output #0: loss = 3.00441e-05 (* 1 = 3.00441e-05 loss)
I0811 15:42:00.938796  8383 sgd_solver.cpp:106] Iteration 99200, lr = 0.000262159
I0811 15:42:04.175758  8383 solver.cpp:228] Iteration 99300, loss = 4.01563e-05
I0811 15:42:04.175801  8383 solver.cpp:244]     Train net output #0: loss = 4.01563e-05 (* 1 = 4.01563e-05 loss)
I0811 15:42:04.175806  8383 sgd_solver.cpp:106] Iteration 99300, lr = 0.000261995
I0811 15:42:07.428231  8383 solver.cpp:228] Iteration 99400, loss = 2.86685e-05
I0811 15:42:07.428267  8383 solver.cpp:244]     Train net output #0: loss = 2.86685e-05 (* 1 = 2.86685e-05 loss)
I0811 15:42:07.428273  8383 sgd_solver.cpp:106] Iteration 99400, lr = 0.00026183
I0811 15:42:10.677624  8383 solver.cpp:337] Iteration 99500, Testing net (#0)
I0811 15:42:17.401764  8383 solver.cpp:404]     Test net output #0: accuracy = 0.897871
I0811 15:42:17.401835  8383 solver.cpp:404]     Test net output #1: loss = 0.738418 (* 1 = 0.738418 loss)
I0811 15:42:17.415992  8383 solver.cpp:228] Iteration 99500, loss = 4.87556e-05
I0811 15:42:17.416033  8383 solver.cpp:244]     Train net output #0: loss = 4.87556e-05 (* 1 = 4.87556e-05 loss)
I0811 15:42:17.416049  8383 sgd_solver.cpp:106] Iteration 99500, lr = 0.000261666
I0811 15:42:20.665473  8383 solver.cpp:228] Iteration 99600, loss = 7.70168e-05
I0811 15:42:20.665513  8383 solver.cpp:244]     Train net output #0: loss = 7.70168e-05 (* 1 = 7.70168e-05 loss)
I0811 15:42:20.665518  8383 sgd_solver.cpp:106] Iteration 99600, lr = 0.000261501
I0811 15:42:23.944121  8383 solver.cpp:228] Iteration 99700, loss = 3.24658e-05
I0811 15:42:23.944169  8383 solver.cpp:244]     Train net output #0: loss = 3.24658e-05 (* 1 = 3.24658e-05 loss)
I0811 15:42:23.944180  8383 sgd_solver.cpp:106] Iteration 99700, lr = 0.000261338
I0811 15:42:27.222295  8383 solver.cpp:228] Iteration 99800, loss = 5.15269e-05
I0811 15:42:27.222331  8383 solver.cpp:244]     Train net output #0: loss = 5.15269e-05 (* 1 = 5.15269e-05 loss)
I0811 15:42:27.222337  8383 sgd_solver.cpp:106] Iteration 99800, lr = 0.000261174
I0811 15:42:30.500370  8383 solver.cpp:228] Iteration 99900, loss = 2.63285e-05
I0811 15:42:30.500411  8383 solver.cpp:244]     Train net output #0: loss = 2.63285e-05 (* 1 = 2.63285e-05 loss)
I0811 15:42:30.500417  8383 sgd_solver.cpp:106] Iteration 99900, lr = 0.000261011
I0811 15:42:33.763825  8383 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_100000.caffemodel
I0811 15:42:34.146484  8383 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_100000.solverstate
I0811 15:42:34.281291  8383 solver.cpp:337] Iteration 100000, Testing net (#0)
I0811 15:42:34.664501  8383 blocking_queue.cpp:50] Data layer prefetch queue empty
I0811 15:42:40.599476  8383 solver.cpp:404]     Test net output #0: accuracy = 0.89771
I0811 15:42:40.599539  8383 solver.cpp:404]     Test net output #1: loss = 0.74064 (* 1 = 0.74064 loss)
I0811 15:42:40.610484  8383 solver.cpp:228] Iteration 100000, loss = 0.000171259
I0811 15:42:40.610550  8383 solver.cpp:244]     Train net output #0: loss = 0.000171259 (* 1 = 0.000171259 loss)
I0811 15:42:40.610572  8383 sgd_solver.cpp:106] Iteration 100000, lr = 0.000260847
nets/person_background_and_random_alex_net/solver.prototxt
