WARNING: Logging before InitGoogleLogging() is written to STDERR
I0822 15:59:31.249091 12979 solver.cpp:48] Initializing solver from parameters: 
test_iter: 310
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
snapshot: 5000
snapshot_prefix: "models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001"
solver_mode: GPU
net: "nets/person_background_and_random_alex_net/trainval.prototxt"
I0822 15:59:31.249213 12979 solver.cpp:91] Creating training net from net file: nets/person_background_and_random_alex_net/trainval.prototxt
I0822 15:59:31.249512 12979 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0822 15:59:31.249531 12979 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0822 15:59:31.249670 12979 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 15:59:31.249744 12979 layer_factory.hpp:77] Creating layer mnist
I0822 15:59:31.250233 12979 net.cpp:100] Creating Layer mnist
I0822 15:59:31.250246 12979 net.cpp:408] mnist -> data
I0822 15:59:31.250258 12979 net.cpp:408] mnist -> label
I0822 15:59:31.250267 12979 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0822 15:59:31.251705 12992 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_train_lmdb
I0822 15:59:31.286702 12979 data_layer.cpp:41] output data size: 64,3,128,128
I0822 15:59:31.319993 12979 net.cpp:150] Setting up mnist
I0822 15:59:31.320035 12979 net.cpp:157] Top shape: 64 3 128 128 (3145728)
I0822 15:59:31.320044 12979 net.cpp:157] Top shape: 64 (64)
I0822 15:59:31.320046 12979 net.cpp:165] Memory required for data: 12583168
I0822 15:59:31.320055 12979 layer_factory.hpp:77] Creating layer conv1
I0822 15:59:31.320083 12979 net.cpp:100] Creating Layer conv1
I0822 15:59:31.320089 12979 net.cpp:434] conv1 <- data
I0822 15:59:31.320101 12979 net.cpp:408] conv1 -> conv1
I0822 15:59:31.619578 12979 net.cpp:150] Setting up conv1
I0822 15:59:31.619616 12979 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I0822 15:59:31.619619 12979 net.cpp:165] Memory required for data: 34701568
I0822 15:59:31.619637 12979 layer_factory.hpp:77] Creating layer relu1
I0822 15:59:31.619650 12979 net.cpp:100] Creating Layer relu1
I0822 15:59:31.619654 12979 net.cpp:434] relu1 <- conv1
I0822 15:59:31.619659 12979 net.cpp:395] relu1 -> conv1 (in-place)
I0822 15:59:31.619848 12979 net.cpp:150] Setting up relu1
I0822 15:59:31.619859 12979 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I0822 15:59:31.619863 12979 net.cpp:165] Memory required for data: 56819968
I0822 15:59:31.619865 12979 layer_factory.hpp:77] Creating layer norm1
I0822 15:59:31.619874 12979 net.cpp:100] Creating Layer norm1
I0822 15:59:31.619877 12979 net.cpp:434] norm1 <- conv1
I0822 15:59:31.619882 12979 net.cpp:408] norm1 -> norm1
I0822 15:59:31.620470 12979 net.cpp:150] Setting up norm1
I0822 15:59:31.620486 12979 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I0822 15:59:31.620488 12979 net.cpp:165] Memory required for data: 78938368
I0822 15:59:31.620491 12979 layer_factory.hpp:77] Creating layer pool1
I0822 15:59:31.620501 12979 net.cpp:100] Creating Layer pool1
I0822 15:59:31.620504 12979 net.cpp:434] pool1 <- norm1
I0822 15:59:31.620509 12979 net.cpp:408] pool1 -> pool1
I0822 15:59:31.620569 12979 net.cpp:150] Setting up pool1
I0822 15:59:31.620578 12979 net.cpp:157] Top shape: 64 96 15 15 (1382400)
I0822 15:59:31.620579 12979 net.cpp:165] Memory required for data: 84467968
I0822 15:59:31.620582 12979 layer_factory.hpp:77] Creating layer conv2
I0822 15:59:31.620594 12979 net.cpp:100] Creating Layer conv2
I0822 15:59:31.620599 12979 net.cpp:434] conv2 <- pool1
I0822 15:59:31.620604 12979 net.cpp:408] conv2 -> conv2
I0822 15:59:31.627310 12979 net.cpp:150] Setting up conv2
I0822 15:59:31.627327 12979 net.cpp:157] Top shape: 64 256 15 15 (3686400)
I0822 15:59:31.627331 12979 net.cpp:165] Memory required for data: 99213568
I0822 15:59:31.627341 12979 layer_factory.hpp:77] Creating layer relu2
I0822 15:59:31.627346 12979 net.cpp:100] Creating Layer relu2
I0822 15:59:31.627349 12979 net.cpp:434] relu2 <- conv2
I0822 15:59:31.627354 12979 net.cpp:395] relu2 -> conv2 (in-place)
I0822 15:59:31.627889 12979 net.cpp:150] Setting up relu2
I0822 15:59:31.627904 12979 net.cpp:157] Top shape: 64 256 15 15 (3686400)
I0822 15:59:31.627907 12979 net.cpp:165] Memory required for data: 113959168
I0822 15:59:31.627910 12979 layer_factory.hpp:77] Creating layer norm2
I0822 15:59:31.627918 12979 net.cpp:100] Creating Layer norm2
I0822 15:59:31.627920 12979 net.cpp:434] norm2 <- conv2
I0822 15:59:31.627925 12979 net.cpp:408] norm2 -> norm2
I0822 15:59:31.628157 12979 net.cpp:150] Setting up norm2
I0822 15:59:31.628170 12979 net.cpp:157] Top shape: 64 256 15 15 (3686400)
I0822 15:59:31.628173 12979 net.cpp:165] Memory required for data: 128704768
I0822 15:59:31.628176 12979 layer_factory.hpp:77] Creating layer pool2
I0822 15:59:31.628185 12979 net.cpp:100] Creating Layer pool2
I0822 15:59:31.628190 12979 net.cpp:434] pool2 <- norm2
I0822 15:59:31.628195 12979 net.cpp:408] pool2 -> pool2
I0822 15:59:31.628247 12979 net.cpp:150] Setting up pool2
I0822 15:59:31.628255 12979 net.cpp:157] Top shape: 64 256 7 7 (802816)
I0822 15:59:31.628258 12979 net.cpp:165] Memory required for data: 131916032
I0822 15:59:31.628260 12979 layer_factory.hpp:77] Creating layer conv3
I0822 15:59:31.628270 12979 net.cpp:100] Creating Layer conv3
I0822 15:59:31.628273 12979 net.cpp:434] conv3 <- pool2
I0822 15:59:31.628278 12979 net.cpp:408] conv3 -> conv3
I0822 15:59:31.642244 12979 net.cpp:150] Setting up conv3
I0822 15:59:31.642261 12979 net.cpp:157] Top shape: 64 384 7 7 (1204224)
I0822 15:59:31.642266 12979 net.cpp:165] Memory required for data: 136732928
I0822 15:59:31.642274 12979 layer_factory.hpp:77] Creating layer relu3
I0822 15:59:31.642282 12979 net.cpp:100] Creating Layer relu3
I0822 15:59:31.642284 12979 net.cpp:434] relu3 <- conv3
I0822 15:59:31.642290 12979 net.cpp:395] relu3 -> conv3 (in-place)
I0822 15:59:31.642483 12979 net.cpp:150] Setting up relu3
I0822 15:59:31.642495 12979 net.cpp:157] Top shape: 64 384 7 7 (1204224)
I0822 15:59:31.642498 12979 net.cpp:165] Memory required for data: 141549824
I0822 15:59:31.642500 12979 layer_factory.hpp:77] Creating layer conv4
I0822 15:59:31.642511 12979 net.cpp:100] Creating Layer conv4
I0822 15:59:31.642514 12979 net.cpp:434] conv4 <- conv3
I0822 15:59:31.642520 12979 net.cpp:408] conv4 -> conv4
I0822 15:59:31.654423 12979 net.cpp:150] Setting up conv4
I0822 15:59:31.654439 12979 net.cpp:157] Top shape: 64 384 7 7 (1204224)
I0822 15:59:31.654443 12979 net.cpp:165] Memory required for data: 146366720
I0822 15:59:31.654449 12979 layer_factory.hpp:77] Creating layer relu4
I0822 15:59:31.654455 12979 net.cpp:100] Creating Layer relu4
I0822 15:59:31.654458 12979 net.cpp:434] relu4 <- conv4
I0822 15:59:31.654465 12979 net.cpp:395] relu4 -> conv4 (in-place)
I0822 15:59:31.654670 12979 net.cpp:150] Setting up relu4
I0822 15:59:31.654680 12979 net.cpp:157] Top shape: 64 384 7 7 (1204224)
I0822 15:59:31.654682 12979 net.cpp:165] Memory required for data: 151183616
I0822 15:59:31.654685 12979 layer_factory.hpp:77] Creating layer conv5
I0822 15:59:31.654698 12979 net.cpp:100] Creating Layer conv5
I0822 15:59:31.654702 12979 net.cpp:434] conv5 <- conv4
I0822 15:59:31.654707 12979 net.cpp:408] conv5 -> conv5
I0822 15:59:31.663897 12979 net.cpp:150] Setting up conv5
I0822 15:59:31.663915 12979 net.cpp:157] Top shape: 64 256 7 7 (802816)
I0822 15:59:31.663919 12979 net.cpp:165] Memory required for data: 154394880
I0822 15:59:31.663928 12979 layer_factory.hpp:77] Creating layer relu5
I0822 15:59:31.663934 12979 net.cpp:100] Creating Layer relu5
I0822 15:59:31.663938 12979 net.cpp:434] relu5 <- conv5
I0822 15:59:31.663944 12979 net.cpp:395] relu5 -> conv5 (in-place)
I0822 15:59:31.664155 12979 net.cpp:150] Setting up relu5
I0822 15:59:31.664167 12979 net.cpp:157] Top shape: 64 256 7 7 (802816)
I0822 15:59:31.664170 12979 net.cpp:165] Memory required for data: 157606144
I0822 15:59:31.664173 12979 layer_factory.hpp:77] Creating layer pool5
I0822 15:59:31.664180 12979 net.cpp:100] Creating Layer pool5
I0822 15:59:31.664185 12979 net.cpp:434] pool5 <- conv5
I0822 15:59:31.664189 12979 net.cpp:408] pool5 -> pool5
I0822 15:59:31.664264 12979 net.cpp:150] Setting up pool5
I0822 15:59:31.664273 12979 net.cpp:157] Top shape: 64 256 3 3 (147456)
I0822 15:59:31.664275 12979 net.cpp:165] Memory required for data: 158195968
I0822 15:59:31.664278 12979 layer_factory.hpp:77] Creating layer fc6
I0822 15:59:31.664291 12979 net.cpp:100] Creating Layer fc6
I0822 15:59:31.664297 12979 net.cpp:434] fc6 <- pool5
I0822 15:59:31.664304 12979 net.cpp:408] fc6 -> fc6
I0822 15:59:31.798019 12979 net.cpp:150] Setting up fc6
I0822 15:59:31.798060 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:31.798064 12979 net.cpp:165] Memory required for data: 159244544
I0822 15:59:31.798077 12979 layer_factory.hpp:77] Creating layer relu6
I0822 15:59:31.798089 12979 net.cpp:100] Creating Layer relu6
I0822 15:59:31.798094 12979 net.cpp:434] relu6 <- fc6
I0822 15:59:31.798104 12979 net.cpp:395] relu6 -> fc6 (in-place)
I0822 15:59:31.798774 12979 net.cpp:150] Setting up relu6
I0822 15:59:31.798791 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:31.798794 12979 net.cpp:165] Memory required for data: 160293120
I0822 15:59:31.798797 12979 layer_factory.hpp:77] Creating layer drop6
I0822 15:59:31.798805 12979 net.cpp:100] Creating Layer drop6
I0822 15:59:31.798810 12979 net.cpp:434] drop6 <- fc6
I0822 15:59:31.798815 12979 net.cpp:395] drop6 -> fc6 (in-place)
I0822 15:59:31.798863 12979 net.cpp:150] Setting up drop6
I0822 15:59:31.798871 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:31.798874 12979 net.cpp:165] Memory required for data: 161341696
I0822 15:59:31.798877 12979 layer_factory.hpp:77] Creating layer fc7
I0822 15:59:31.798885 12979 net.cpp:100] Creating Layer fc7
I0822 15:59:31.798888 12979 net.cpp:434] fc7 <- fc6
I0822 15:59:31.798895 12979 net.cpp:408] fc7 -> fc7
I0822 15:59:32.032999 12979 net.cpp:150] Setting up fc7
I0822 15:59:32.033047 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:32.033051 12979 net.cpp:165] Memory required for data: 162390272
I0822 15:59:32.033064 12979 layer_factory.hpp:77] Creating layer relu7
I0822 15:59:32.033083 12979 net.cpp:100] Creating Layer relu7
I0822 15:59:32.033087 12979 net.cpp:434] relu7 <- fc7
I0822 15:59:32.033097 12979 net.cpp:395] relu7 -> fc7 (in-place)
I0822 15:59:32.033388 12979 net.cpp:150] Setting up relu7
I0822 15:59:32.033398 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:32.033401 12979 net.cpp:165] Memory required for data: 163438848
I0822 15:59:32.033404 12979 layer_factory.hpp:77] Creating layer drop7
I0822 15:59:32.033412 12979 net.cpp:100] Creating Layer drop7
I0822 15:59:32.033414 12979 net.cpp:434] drop7 <- fc7
I0822 15:59:32.033419 12979 net.cpp:395] drop7 -> fc7 (in-place)
I0822 15:59:32.033464 12979 net.cpp:150] Setting up drop7
I0822 15:59:32.033473 12979 net.cpp:157] Top shape: 64 4096 (262144)
I0822 15:59:32.033475 12979 net.cpp:165] Memory required for data: 164487424
I0822 15:59:32.033478 12979 layer_factory.hpp:77] Creating layer fc8
I0822 15:59:32.033486 12979 net.cpp:100] Creating Layer fc8
I0822 15:59:32.033489 12979 net.cpp:434] fc8 <- fc7
I0822 15:59:32.033496 12979 net.cpp:408] fc8 -> fc8
I0822 15:59:32.035413 12979 net.cpp:150] Setting up fc8
I0822 15:59:32.035429 12979 net.cpp:157] Top shape: 64 2 (128)
I0822 15:59:32.035431 12979 net.cpp:165] Memory required for data: 164487936
I0822 15:59:32.035437 12979 layer_factory.hpp:77] Creating layer loss
I0822 15:59:32.035451 12979 net.cpp:100] Creating Layer loss
I0822 15:59:32.035454 12979 net.cpp:434] loss <- fc8
I0822 15:59:32.035459 12979 net.cpp:434] loss <- label
I0822 15:59:32.035464 12979 net.cpp:408] loss -> loss
I0822 15:59:32.035473 12979 layer_factory.hpp:77] Creating layer loss
I0822 15:59:32.035837 12979 net.cpp:150] Setting up loss
I0822 15:59:32.035848 12979 net.cpp:157] Top shape: (1)
I0822 15:59:32.035851 12979 net.cpp:160]     with loss weight 1
I0822 15:59:32.035869 12979 net.cpp:165] Memory required for data: 164487940
I0822 15:59:32.035872 12979 net.cpp:226] loss needs backward computation.
I0822 15:59:32.035877 12979 net.cpp:226] fc8 needs backward computation.
I0822 15:59:32.035881 12979 net.cpp:226] drop7 needs backward computation.
I0822 15:59:32.035882 12979 net.cpp:226] relu7 needs backward computation.
I0822 15:59:32.035886 12979 net.cpp:226] fc7 needs backward computation.
I0822 15:59:32.035887 12979 net.cpp:226] drop6 needs backward computation.
I0822 15:59:32.035890 12979 net.cpp:226] relu6 needs backward computation.
I0822 15:59:32.035893 12979 net.cpp:226] fc6 needs backward computation.
I0822 15:59:32.035897 12979 net.cpp:226] pool5 needs backward computation.
I0822 15:59:32.035899 12979 net.cpp:226] relu5 needs backward computation.
I0822 15:59:32.035902 12979 net.cpp:226] conv5 needs backward computation.
I0822 15:59:32.035904 12979 net.cpp:226] relu4 needs backward computation.
I0822 15:59:32.035909 12979 net.cpp:226] conv4 needs backward computation.
I0822 15:59:32.035912 12979 net.cpp:226] relu3 needs backward computation.
I0822 15:59:32.035915 12979 net.cpp:226] conv3 needs backward computation.
I0822 15:59:32.035918 12979 net.cpp:226] pool2 needs backward computation.
I0822 15:59:32.035922 12979 net.cpp:226] norm2 needs backward computation.
I0822 15:59:32.035924 12979 net.cpp:226] relu2 needs backward computation.
I0822 15:59:32.035926 12979 net.cpp:226] conv2 needs backward computation.
I0822 15:59:32.035930 12979 net.cpp:226] pool1 needs backward computation.
I0822 15:59:32.035933 12979 net.cpp:226] norm1 needs backward computation.
I0822 15:59:32.035935 12979 net.cpp:226] relu1 needs backward computation.
I0822 15:59:32.035938 12979 net.cpp:226] conv1 needs backward computation.
I0822 15:59:32.035943 12979 net.cpp:228] mnist does not need backward computation.
I0822 15:59:32.035945 12979 net.cpp:270] This network produces output loss
I0822 15:59:32.035960 12979 net.cpp:283] Network initialization done.
I0822 15:59:32.036329 12979 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_background_and_random_alex_net/trainval.prototxt
I0822 15:59:32.036372 12979 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0822 15:59:32.036543 12979 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 15:59:32.036653 12979 layer_factory.hpp:77] Creating layer mnist
I0822 15:59:32.036783 12979 net.cpp:100] Creating Layer mnist
I0822 15:59:32.036792 12979 net.cpp:408] mnist -> data
I0822 15:59:32.036803 12979 net.cpp:408] mnist -> label
I0822 15:59:32.036809 12979 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0822 15:59:32.038354 12994 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_test_lmdb
I0822 15:59:32.038794 12979 data_layer.cpp:41] output data size: 100,3,128,128
I0822 15:59:32.099225 12979 net.cpp:150] Setting up mnist
I0822 15:59:32.099261 12979 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0822 15:59:32.099269 12979 net.cpp:157] Top shape: 100 (100)
I0822 15:59:32.099272 12979 net.cpp:165] Memory required for data: 19661200
I0822 15:59:32.099280 12979 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0822 15:59:32.099298 12979 net.cpp:100] Creating Layer label_mnist_1_split
I0822 15:59:32.099303 12979 net.cpp:434] label_mnist_1_split <- label
I0822 15:59:32.099314 12979 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I0822 15:59:32.099331 12979 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I0822 15:59:32.099653 12979 net.cpp:150] Setting up label_mnist_1_split
I0822 15:59:32.099685 12979 net.cpp:157] Top shape: 100 (100)
I0822 15:59:32.099692 12979 net.cpp:157] Top shape: 100 (100)
I0822 15:59:32.099697 12979 net.cpp:165] Memory required for data: 19662000
I0822 15:59:32.099704 12979 layer_factory.hpp:77] Creating layer conv1
I0822 15:59:32.099726 12979 net.cpp:100] Creating Layer conv1
I0822 15:59:32.099733 12979 net.cpp:434] conv1 <- data
I0822 15:59:32.099747 12979 net.cpp:408] conv1 -> conv1
I0822 15:59:32.104904 12979 net.cpp:150] Setting up conv1
I0822 15:59:32.104935 12979 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 15:59:32.104941 12979 net.cpp:165] Memory required for data: 54222000
I0822 15:59:32.104960 12979 layer_factory.hpp:77] Creating layer relu1
I0822 15:59:32.104974 12979 net.cpp:100] Creating Layer relu1
I0822 15:59:32.104979 12979 net.cpp:434] relu1 <- conv1
I0822 15:59:32.104989 12979 net.cpp:395] relu1 -> conv1 (in-place)
I0822 15:59:32.105360 12979 net.cpp:150] Setting up relu1
I0822 15:59:32.105377 12979 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 15:59:32.105382 12979 net.cpp:165] Memory required for data: 88782000
I0822 15:59:32.105388 12979 layer_factory.hpp:77] Creating layer norm1
I0822 15:59:32.105403 12979 net.cpp:100] Creating Layer norm1
I0822 15:59:32.105409 12979 net.cpp:434] norm1 <- conv1
I0822 15:59:32.105419 12979 net.cpp:408] norm1 -> norm1
I0822 15:59:32.106561 12979 net.cpp:150] Setting up norm1
I0822 15:59:32.106588 12979 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0822 15:59:32.106595 12979 net.cpp:165] Memory required for data: 123342000
I0822 15:59:32.106600 12979 layer_factory.hpp:77] Creating layer pool1
I0822 15:59:32.106613 12979 net.cpp:100] Creating Layer pool1
I0822 15:59:32.106621 12979 net.cpp:434] pool1 <- norm1
I0822 15:59:32.106631 12979 net.cpp:408] pool1 -> pool1
I0822 15:59:32.106750 12979 net.cpp:150] Setting up pool1
I0822 15:59:32.106763 12979 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0822 15:59:32.106768 12979 net.cpp:165] Memory required for data: 131982000
I0822 15:59:32.106773 12979 layer_factory.hpp:77] Creating layer conv2
I0822 15:59:32.106791 12979 net.cpp:100] Creating Layer conv2
I0822 15:59:32.106798 12979 net.cpp:434] conv2 <- pool1
I0822 15:59:32.106809 12979 net.cpp:408] conv2 -> conv2
I0822 15:59:32.119112 12979 net.cpp:150] Setting up conv2
I0822 15:59:32.119140 12979 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 15:59:32.119146 12979 net.cpp:165] Memory required for data: 155022000
I0822 15:59:32.119168 12979 layer_factory.hpp:77] Creating layer relu2
I0822 15:59:32.119184 12979 net.cpp:100] Creating Layer relu2
I0822 15:59:32.119189 12979 net.cpp:434] relu2 <- conv2
I0822 15:59:32.119199 12979 net.cpp:395] relu2 -> conv2 (in-place)
I0822 15:59:32.120203 12979 net.cpp:150] Setting up relu2
I0822 15:59:32.120231 12979 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 15:59:32.120237 12979 net.cpp:165] Memory required for data: 178062000
I0822 15:59:32.120242 12979 layer_factory.hpp:77] Creating layer norm2
I0822 15:59:32.120262 12979 net.cpp:100] Creating Layer norm2
I0822 15:59:32.120268 12979 net.cpp:434] norm2 <- conv2
I0822 15:59:32.120277 12979 net.cpp:408] norm2 -> norm2
I0822 15:59:32.120745 12979 net.cpp:150] Setting up norm2
I0822 15:59:32.120764 12979 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0822 15:59:32.120769 12979 net.cpp:165] Memory required for data: 201102000
I0822 15:59:32.120774 12979 layer_factory.hpp:77] Creating layer pool2
I0822 15:59:32.120782 12979 net.cpp:100] Creating Layer pool2
I0822 15:59:32.120787 12979 net.cpp:434] pool2 <- norm2
I0822 15:59:32.120798 12979 net.cpp:408] pool2 -> pool2
I0822 15:59:32.120908 12979 net.cpp:150] Setting up pool2
I0822 15:59:32.120919 12979 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 15:59:32.120923 12979 net.cpp:165] Memory required for data: 206119600
I0822 15:59:32.120928 12979 layer_factory.hpp:77] Creating layer conv3
I0822 15:59:32.120944 12979 net.cpp:100] Creating Layer conv3
I0822 15:59:32.120951 12979 net.cpp:434] conv3 <- pool2
I0822 15:59:32.120962 12979 net.cpp:408] conv3 -> conv3
I0822 15:59:32.143841 12979 net.cpp:150] Setting up conv3
I0822 15:59:32.143877 12979 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 15:59:32.143882 12979 net.cpp:165] Memory required for data: 213646000
I0822 15:59:32.143901 12979 layer_factory.hpp:77] Creating layer relu3
I0822 15:59:32.143918 12979 net.cpp:100] Creating Layer relu3
I0822 15:59:32.143924 12979 net.cpp:434] relu3 <- conv3
I0822 15:59:32.143932 12979 net.cpp:395] relu3 -> conv3 (in-place)
I0822 15:59:32.144284 12979 net.cpp:150] Setting up relu3
I0822 15:59:32.144301 12979 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 15:59:32.144305 12979 net.cpp:165] Memory required for data: 221172400
I0822 15:59:32.144309 12979 layer_factory.hpp:77] Creating layer conv4
I0822 15:59:32.144333 12979 net.cpp:100] Creating Layer conv4
I0822 15:59:32.144338 12979 net.cpp:434] conv4 <- conv3
I0822 15:59:32.144347 12979 net.cpp:408] conv4 -> conv4
I0822 15:59:32.161952 12979 net.cpp:150] Setting up conv4
I0822 15:59:32.161983 12979 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 15:59:32.161988 12979 net.cpp:165] Memory required for data: 228698800
I0822 15:59:32.161998 12979 layer_factory.hpp:77] Creating layer relu4
I0822 15:59:32.162009 12979 net.cpp:100] Creating Layer relu4
I0822 15:59:32.162014 12979 net.cpp:434] relu4 <- conv4
I0822 15:59:32.162024 12979 net.cpp:395] relu4 -> conv4 (in-place)
I0822 15:59:32.162842 12979 net.cpp:150] Setting up relu4
I0822 15:59:32.162863 12979 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0822 15:59:32.162868 12979 net.cpp:165] Memory required for data: 236225200
I0822 15:59:32.162873 12979 layer_factory.hpp:77] Creating layer conv5
I0822 15:59:32.162890 12979 net.cpp:100] Creating Layer conv5
I0822 15:59:32.162895 12979 net.cpp:434] conv5 <- conv4
I0822 15:59:32.162904 12979 net.cpp:408] conv5 -> conv5
I0822 15:59:32.175457 12979 net.cpp:150] Setting up conv5
I0822 15:59:32.175482 12979 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 15:59:32.175487 12979 net.cpp:165] Memory required for data: 241242800
I0822 15:59:32.175503 12979 layer_factory.hpp:77] Creating layer relu5
I0822 15:59:32.175511 12979 net.cpp:100] Creating Layer relu5
I0822 15:59:32.175518 12979 net.cpp:434] relu5 <- conv5
I0822 15:59:32.175524 12979 net.cpp:395] relu5 -> conv5 (in-place)
I0822 15:59:32.175798 12979 net.cpp:150] Setting up relu5
I0822 15:59:32.175812 12979 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0822 15:59:32.175815 12979 net.cpp:165] Memory required for data: 246260400
I0822 15:59:32.175819 12979 layer_factory.hpp:77] Creating layer pool5
I0822 15:59:32.175837 12979 net.cpp:100] Creating Layer pool5
I0822 15:59:32.175842 12979 net.cpp:434] pool5 <- conv5
I0822 15:59:32.175848 12979 net.cpp:408] pool5 -> pool5
I0822 15:59:32.175958 12979 net.cpp:150] Setting up pool5
I0822 15:59:32.175969 12979 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0822 15:59:32.175972 12979 net.cpp:165] Memory required for data: 247182000
I0822 15:59:32.175976 12979 layer_factory.hpp:77] Creating layer fc6
I0822 15:59:32.175987 12979 net.cpp:100] Creating Layer fc6
I0822 15:59:32.175990 12979 net.cpp:434] fc6 <- pool5
I0822 15:59:32.175999 12979 net.cpp:408] fc6 -> fc6
I0822 15:59:32.315109 12979 net.cpp:150] Setting up fc6
I0822 15:59:32.315151 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.315155 12979 net.cpp:165] Memory required for data: 248820400
I0822 15:59:32.315167 12979 layer_factory.hpp:77] Creating layer relu6
I0822 15:59:32.315181 12979 net.cpp:100] Creating Layer relu6
I0822 15:59:32.315184 12979 net.cpp:434] relu6 <- fc6
I0822 15:59:32.315192 12979 net.cpp:395] relu6 -> fc6 (in-place)
I0822 15:59:32.315495 12979 net.cpp:150] Setting up relu6
I0822 15:59:32.315505 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.315508 12979 net.cpp:165] Memory required for data: 250458800
I0822 15:59:32.315511 12979 layer_factory.hpp:77] Creating layer drop6
I0822 15:59:32.315520 12979 net.cpp:100] Creating Layer drop6
I0822 15:59:32.315522 12979 net.cpp:434] drop6 <- fc6
I0822 15:59:32.315528 12979 net.cpp:395] drop6 -> fc6 (in-place)
I0822 15:59:32.315589 12979 net.cpp:150] Setting up drop6
I0822 15:59:32.315598 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.315600 12979 net.cpp:165] Memory required for data: 252097200
I0822 15:59:32.315603 12979 layer_factory.hpp:77] Creating layer fc7
I0822 15:59:32.315613 12979 net.cpp:100] Creating Layer fc7
I0822 15:59:32.315618 12979 net.cpp:434] fc7 <- fc6
I0822 15:59:32.315623 12979 net.cpp:408] fc7 -> fc7
I0822 15:59:32.549399 12979 net.cpp:150] Setting up fc7
I0822 15:59:32.549449 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.549453 12979 net.cpp:165] Memory required for data: 253735600
I0822 15:59:32.549466 12979 layer_factory.hpp:77] Creating layer relu7
I0822 15:59:32.549479 12979 net.cpp:100] Creating Layer relu7
I0822 15:59:32.549484 12979 net.cpp:434] relu7 <- fc7
I0822 15:59:32.549491 12979 net.cpp:395] relu7 -> fc7 (in-place)
I0822 15:59:32.550345 12979 net.cpp:150] Setting up relu7
I0822 15:59:32.550361 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.550364 12979 net.cpp:165] Memory required for data: 255374000
I0822 15:59:32.550367 12979 layer_factory.hpp:77] Creating layer drop7
I0822 15:59:32.550377 12979 net.cpp:100] Creating Layer drop7
I0822 15:59:32.550381 12979 net.cpp:434] drop7 <- fc7
I0822 15:59:32.550386 12979 net.cpp:395] drop7 -> fc7 (in-place)
I0822 15:59:32.550446 12979 net.cpp:150] Setting up drop7
I0822 15:59:32.550457 12979 net.cpp:157] Top shape: 100 4096 (409600)
I0822 15:59:32.550458 12979 net.cpp:165] Memory required for data: 257012400
I0822 15:59:32.550462 12979 layer_factory.hpp:77] Creating layer fc8
I0822 15:59:32.550470 12979 net.cpp:100] Creating Layer fc8
I0822 15:59:32.550473 12979 net.cpp:434] fc8 <- fc7
I0822 15:59:32.550480 12979 net.cpp:408] fc8 -> fc8
I0822 15:59:32.550788 12979 net.cpp:150] Setting up fc8
I0822 15:59:32.550797 12979 net.cpp:157] Top shape: 100 2 (200)
I0822 15:59:32.550799 12979 net.cpp:165] Memory required for data: 257013200
I0822 15:59:32.550806 12979 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0822 15:59:32.550812 12979 net.cpp:100] Creating Layer fc8_fc8_0_split
I0822 15:59:32.550815 12979 net.cpp:434] fc8_fc8_0_split <- fc8
I0822 15:59:32.550819 12979 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0822 15:59:32.550827 12979 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0822 15:59:32.550899 12979 net.cpp:150] Setting up fc8_fc8_0_split
I0822 15:59:32.550905 12979 net.cpp:157] Top shape: 100 2 (200)
I0822 15:59:32.550909 12979 net.cpp:157] Top shape: 100 2 (200)
I0822 15:59:32.550911 12979 net.cpp:165] Memory required for data: 257014800
I0822 15:59:32.550914 12979 layer_factory.hpp:77] Creating layer accuracy
I0822 15:59:32.550921 12979 net.cpp:100] Creating Layer accuracy
I0822 15:59:32.550925 12979 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0822 15:59:32.550928 12979 net.cpp:434] accuracy <- label_mnist_1_split_0
I0822 15:59:32.550933 12979 net.cpp:408] accuracy -> accuracy
I0822 15:59:32.550942 12979 net.cpp:150] Setting up accuracy
I0822 15:59:32.550946 12979 net.cpp:157] Top shape: (1)
I0822 15:59:32.550948 12979 net.cpp:165] Memory required for data: 257014804
I0822 15:59:32.550951 12979 layer_factory.hpp:77] Creating layer loss
I0822 15:59:32.550959 12979 net.cpp:100] Creating Layer loss
I0822 15:59:32.550962 12979 net.cpp:434] loss <- fc8_fc8_0_split_1
I0822 15:59:32.550966 12979 net.cpp:434] loss <- label_mnist_1_split_1
I0822 15:59:32.550971 12979 net.cpp:408] loss -> loss
I0822 15:59:32.550978 12979 layer_factory.hpp:77] Creating layer loss
I0822 15:59:32.551359 12979 net.cpp:150] Setting up loss
I0822 15:59:32.551370 12979 net.cpp:157] Top shape: (1)
I0822 15:59:32.551373 12979 net.cpp:160]     with loss weight 1
I0822 15:59:32.551384 12979 net.cpp:165] Memory required for data: 257014808
I0822 15:59:32.551388 12979 net.cpp:226] loss needs backward computation.
I0822 15:59:32.551393 12979 net.cpp:228] accuracy does not need backward computation.
I0822 15:59:32.551396 12979 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0822 15:59:32.551399 12979 net.cpp:226] fc8 needs backward computation.
I0822 15:59:32.551401 12979 net.cpp:226] drop7 needs backward computation.
I0822 15:59:32.551404 12979 net.cpp:226] relu7 needs backward computation.
I0822 15:59:32.551406 12979 net.cpp:226] fc7 needs backward computation.
I0822 15:59:32.551409 12979 net.cpp:226] drop6 needs backward computation.
I0822 15:59:32.551412 12979 net.cpp:226] relu6 needs backward computation.
I0822 15:59:32.551414 12979 net.cpp:226] fc6 needs backward computation.
I0822 15:59:32.551417 12979 net.cpp:226] pool5 needs backward computation.
I0822 15:59:32.551420 12979 net.cpp:226] relu5 needs backward computation.
I0822 15:59:32.551425 12979 net.cpp:226] conv5 needs backward computation.
I0822 15:59:32.551429 12979 net.cpp:226] relu4 needs backward computation.
I0822 15:59:32.551431 12979 net.cpp:226] conv4 needs backward computation.
I0822 15:59:32.551434 12979 net.cpp:226] relu3 needs backward computation.
I0822 15:59:32.551436 12979 net.cpp:226] conv3 needs backward computation.
I0822 15:59:32.551440 12979 net.cpp:226] pool2 needs backward computation.
I0822 15:59:32.551443 12979 net.cpp:226] norm2 needs backward computation.
I0822 15:59:32.551446 12979 net.cpp:226] relu2 needs backward computation.
I0822 15:59:32.551450 12979 net.cpp:226] conv2 needs backward computation.
I0822 15:59:32.551452 12979 net.cpp:226] pool1 needs backward computation.
I0822 15:59:32.551455 12979 net.cpp:226] norm1 needs backward computation.
I0822 15:59:32.551458 12979 net.cpp:226] relu1 needs backward computation.
I0822 15:59:32.551460 12979 net.cpp:226] conv1 needs backward computation.
I0822 15:59:32.551465 12979 net.cpp:228] label_mnist_1_split does not need backward computation.
I0822 15:59:32.551467 12979 net.cpp:228] mnist does not need backward computation.
I0822 15:59:32.551471 12979 net.cpp:270] This network produces output accuracy
I0822 15:59:32.551475 12979 net.cpp:270] This network produces output loss
I0822 15:59:32.551494 12979 net.cpp:283] Network initialization done.
I0822 15:59:32.551584 12979 solver.cpp:60] Solver scaffolding done.
I0822 15:59:32.556053 12979 solver.cpp:337] Iteration 0, Testing net (#0)
I0822 15:59:32.664170 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 15:59:36.757109 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882451
I0822 15:59:36.757166 12979 solver.cpp:404]     Test net output #1: loss = 0.689645 (* 1 = 0.689645 loss)
I0822 15:59:36.786100 12979 solver.cpp:228] Iteration 0, loss = 0.693081
I0822 15:59:36.786157 12979 solver.cpp:244]     Train net output #0: loss = 0.693081 (* 1 = 0.693081 loss)
I0822 15:59:36.786175 12979 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0822 15:59:39.491590 12979 solver.cpp:228] Iteration 100, loss = 0.684014
I0822 15:59:39.491633 12979 solver.cpp:244]     Train net output #0: loss = 0.684014 (* 1 = 0.684014 loss)
I0822 15:59:39.491641 12979 sgd_solver.cpp:106] Iteration 100, lr = 0.000996266
I0822 15:59:42.205376 12979 solver.cpp:228] Iteration 200, loss = 0.690045
I0822 15:59:42.205416 12979 solver.cpp:244]     Train net output #0: loss = 0.690045 (* 1 = 0.690045 loss)
I0822 15:59:42.205421 12979 sgd_solver.cpp:106] Iteration 200, lr = 0.000992565
I0822 15:59:44.905938 12979 solver.cpp:228] Iteration 300, loss = 0.690776
I0822 15:59:44.905964 12979 solver.cpp:244]     Train net output #0: loss = 0.690776 (* 1 = 0.690776 loss)
I0822 15:59:44.905971 12979 sgd_solver.cpp:106] Iteration 300, lr = 0.000988896
I0822 15:59:47.611145 12979 solver.cpp:228] Iteration 400, loss = 0.69433
I0822 15:59:47.611163 12979 solver.cpp:244]     Train net output #0: loss = 0.69433 (* 1 = 0.69433 loss)
I0822 15:59:47.611167 12979 sgd_solver.cpp:106] Iteration 400, lr = 0.000985258
I0822 15:59:50.295545 12979 solver.cpp:337] Iteration 500, Testing net (#0)
I0822 15:59:54.783854 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882581
I0822 15:59:54.783891 12979 solver.cpp:404]     Test net output #1: loss = 0.676902 (* 1 = 0.676902 loss)
I0822 15:59:54.793859 12979 solver.cpp:228] Iteration 500, loss = 0.699616
I0822 15:59:54.793874 12979 solver.cpp:244]     Train net output #0: loss = 0.699616 (* 1 = 0.699616 loss)
I0822 15:59:54.793884 12979 sgd_solver.cpp:106] Iteration 500, lr = 0.000981651
I0822 15:59:57.508690 12979 solver.cpp:228] Iteration 600, loss = 0.700222
I0822 15:59:57.508707 12979 solver.cpp:244]     Train net output #0: loss = 0.700222 (* 1 = 0.700222 loss)
I0822 15:59:57.508711 12979 sgd_solver.cpp:106] Iteration 600, lr = 0.000978075
I0822 16:00:00.227854 12979 solver.cpp:228] Iteration 700, loss = 0.698416
I0822 16:00:00.227891 12979 solver.cpp:244]     Train net output #0: loss = 0.698416 (* 1 = 0.698416 loss)
I0822 16:00:00.227898 12979 sgd_solver.cpp:106] Iteration 700, lr = 0.000974529
I0822 16:00:02.949817 12979 solver.cpp:228] Iteration 800, loss = 0.685268
I0822 16:00:02.949856 12979 solver.cpp:244]     Train net output #0: loss = 0.685268 (* 1 = 0.685268 loss)
I0822 16:00:02.949862 12979 sgd_solver.cpp:106] Iteration 800, lr = 0.000971013
I0822 16:00:05.675390 12979 solver.cpp:228] Iteration 900, loss = 0.686859
I0822 16:00:05.675454 12979 solver.cpp:244]     Train net output #0: loss = 0.686859 (* 1 = 0.686859 loss)
I0822 16:00:05.675460 12979 sgd_solver.cpp:106] Iteration 900, lr = 0.000967526
I0822 16:00:08.381417 12979 solver.cpp:337] Iteration 1000, Testing net (#0)
I0822 16:00:12.574537 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882581
I0822 16:00:12.574595 12979 solver.cpp:404]     Test net output #1: loss = 0.631567 (* 1 = 0.631567 loss)
I0822 16:00:12.584630 12979 solver.cpp:228] Iteration 1000, loss = 0.697677
I0822 16:00:12.584657 12979 solver.cpp:244]     Train net output #0: loss = 0.697677 (* 1 = 0.697677 loss)
I0822 16:00:12.584681 12979 sgd_solver.cpp:106] Iteration 1000, lr = 0.000964069
I0822 16:00:15.316225 12979 solver.cpp:228] Iteration 1100, loss = 0.693475
I0822 16:00:15.316275 12979 solver.cpp:244]     Train net output #0: loss = 0.693475 (* 1 = 0.693475 loss)
I0822 16:00:15.316285 12979 sgd_solver.cpp:106] Iteration 1100, lr = 0.00096064
I0822 16:00:18.051641 12979 solver.cpp:228] Iteration 1200, loss = 0.691972
I0822 16:00:18.051681 12979 solver.cpp:244]     Train net output #0: loss = 0.691972 (* 1 = 0.691972 loss)
I0822 16:00:18.051687 12979 sgd_solver.cpp:106] Iteration 1200, lr = 0.00095724
I0822 16:00:20.784507 12979 solver.cpp:228] Iteration 1300, loss = 0.68851
I0822 16:00:20.784544 12979 solver.cpp:244]     Train net output #0: loss = 0.68851 (* 1 = 0.68851 loss)
I0822 16:00:20.784550 12979 sgd_solver.cpp:106] Iteration 1300, lr = 0.000953867
I0822 16:00:23.525076 12979 solver.cpp:228] Iteration 1400, loss = 0.709732
I0822 16:00:23.525117 12979 solver.cpp:244]     Train net output #0: loss = 0.709732 (* 1 = 0.709732 loss)
I0822 16:00:23.525125 12979 sgd_solver.cpp:106] Iteration 1400, lr = 0.000950522
I0822 16:00:26.234577 12979 solver.cpp:337] Iteration 1500, Testing net (#0)
I0822 16:00:30.626866 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117484
I0822 16:00:30.626919 12979 solver.cpp:404]     Test net output #1: loss = 0.7167 (* 1 = 0.7167 loss)
I0822 16:00:30.635921 12979 solver.cpp:228] Iteration 1500, loss = 0.69286
I0822 16:00:30.635959 12979 solver.cpp:244]     Train net output #0: loss = 0.69286 (* 1 = 0.69286 loss)
I0822 16:00:30.635973 12979 sgd_solver.cpp:106] Iteration 1500, lr = 0.000947204
I0822 16:00:33.367758 12979 solver.cpp:228] Iteration 1600, loss = 0.703913
I0822 16:00:33.367802 12979 solver.cpp:244]     Train net output #0: loss = 0.703913 (* 1 = 0.703913 loss)
I0822 16:00:33.367816 12979 sgd_solver.cpp:106] Iteration 1600, lr = 0.000943913
I0822 16:00:36.108194 12979 solver.cpp:228] Iteration 1700, loss = 0.694318
I0822 16:00:36.108253 12979 solver.cpp:244]     Train net output #0: loss = 0.694318 (* 1 = 0.694318 loss)
I0822 16:00:36.108261 12979 sgd_solver.cpp:106] Iteration 1700, lr = 0.000940649
I0822 16:00:38.846873 12979 solver.cpp:228] Iteration 1800, loss = 0.688462
I0822 16:00:38.846932 12979 solver.cpp:244]     Train net output #0: loss = 0.688462 (* 1 = 0.688462 loss)
I0822 16:00:38.846942 12979 sgd_solver.cpp:106] Iteration 1800, lr = 0.000937411
I0822 16:00:41.582705 12979 solver.cpp:228] Iteration 1900, loss = 0.684244
I0822 16:00:41.582762 12979 solver.cpp:244]     Train net output #0: loss = 0.684244 (* 1 = 0.684244 loss)
I0822 16:00:41.582767 12979 sgd_solver.cpp:106] Iteration 1900, lr = 0.000934199
I0822 16:00:44.288012 12979 solver.cpp:337] Iteration 2000, Testing net (#0)
I0822 16:00:48.982951 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117387
I0822 16:00:48.983021 12979 solver.cpp:404]     Test net output #1: loss = 0.726605 (* 1 = 0.726605 loss)
I0822 16:00:48.993093 12979 solver.cpp:228] Iteration 2000, loss = 0.700721
I0822 16:00:48.993126 12979 solver.cpp:244]     Train net output #0: loss = 0.700721 (* 1 = 0.700721 loss)
I0822 16:00:48.993140 12979 sgd_solver.cpp:106] Iteration 2000, lr = 0.000931013
I0822 16:00:51.724110 12979 solver.cpp:228] Iteration 2100, loss = 0.702045
I0822 16:00:51.724153 12979 solver.cpp:244]     Train net output #0: loss = 0.702045 (* 1 = 0.702045 loss)
I0822 16:00:51.724159 12979 sgd_solver.cpp:106] Iteration 2100, lr = 0.000927851
I0822 16:00:54.454416 12979 solver.cpp:228] Iteration 2200, loss = 0.694972
I0822 16:00:54.454442 12979 solver.cpp:244]     Train net output #0: loss = 0.694972 (* 1 = 0.694972 loss)
I0822 16:00:54.454447 12979 sgd_solver.cpp:106] Iteration 2200, lr = 0.000924715
I0822 16:00:57.187157 12979 solver.cpp:228] Iteration 2300, loss = 0.701169
I0822 16:00:57.187175 12979 solver.cpp:244]     Train net output #0: loss = 0.701169 (* 1 = 0.701169 loss)
I0822 16:00:57.187180 12979 sgd_solver.cpp:106] Iteration 2300, lr = 0.000921603
I0822 16:00:59.928943 12979 solver.cpp:228] Iteration 2400, loss = 0.696472
I0822 16:00:59.929018 12979 solver.cpp:244]     Train net output #0: loss = 0.696472 (* 1 = 0.696472 loss)
I0822 16:00:59.929035 12979 sgd_solver.cpp:106] Iteration 2400, lr = 0.000918516
I0822 16:01:02.660781 12979 solver.cpp:337] Iteration 2500, Testing net (#0)
I0822 16:01:05.600803 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:01:07.133986 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117323
I0822 16:01:07.134034 12979 solver.cpp:404]     Test net output #1: loss = 0.749752 (* 1 = 0.749752 loss)
I0822 16:01:07.144016 12979 solver.cpp:228] Iteration 2500, loss = 0.703607
I0822 16:01:07.144088 12979 solver.cpp:244]     Train net output #0: loss = 0.703607 (* 1 = 0.703607 loss)
I0822 16:01:07.144116 12979 sgd_solver.cpp:106] Iteration 2500, lr = 0.000915452
I0822 16:01:09.891166 12979 solver.cpp:228] Iteration 2600, loss = 0.705532
I0822 16:01:09.891214 12979 solver.cpp:244]     Train net output #0: loss = 0.705532 (* 1 = 0.705532 loss)
I0822 16:01:09.891224 12979 sgd_solver.cpp:106] Iteration 2600, lr = 0.000912412
I0822 16:01:12.627995 12979 solver.cpp:228] Iteration 2700, loss = 0.700039
I0822 16:01:12.628046 12979 solver.cpp:244]     Train net output #0: loss = 0.700039 (* 1 = 0.700039 loss)
I0822 16:01:12.628052 12979 sgd_solver.cpp:106] Iteration 2700, lr = 0.000909396
I0822 16:01:15.370924 12979 solver.cpp:228] Iteration 2800, loss = 0.707167
I0822 16:01:15.370980 12979 solver.cpp:244]     Train net output #0: loss = 0.707167 (* 1 = 0.707167 loss)
I0822 16:01:15.370990 12979 sgd_solver.cpp:106] Iteration 2800, lr = 0.000906403
I0822 16:01:18.102202 12979 solver.cpp:228] Iteration 2900, loss = 0.693107
I0822 16:01:18.102262 12979 solver.cpp:244]     Train net output #0: loss = 0.693107 (* 1 = 0.693107 loss)
I0822 16:01:18.102267 12979 sgd_solver.cpp:106] Iteration 2900, lr = 0.000903433
I0822 16:01:20.810354 12979 solver.cpp:337] Iteration 3000, Testing net (#0)
I0822 16:01:25.356657 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882452
I0822 16:01:25.356691 12979 solver.cpp:404]     Test net output #1: loss = 0.632269 (* 1 = 0.632269 loss)
I0822 16:01:25.366129 12979 solver.cpp:228] Iteration 3000, loss = 0.694371
I0822 16:01:25.366163 12979 solver.cpp:244]     Train net output #0: loss = 0.694371 (* 1 = 0.694371 loss)
I0822 16:01:25.366174 12979 sgd_solver.cpp:106] Iteration 3000, lr = 0.000900485
I0822 16:01:28.114331 12979 solver.cpp:228] Iteration 3100, loss = 0.69629
I0822 16:01:28.114392 12979 solver.cpp:244]     Train net output #0: loss = 0.69629 (* 1 = 0.69629 loss)
I0822 16:01:28.114403 12979 sgd_solver.cpp:106] Iteration 3100, lr = 0.00089756
I0822 16:01:30.870774 12979 solver.cpp:228] Iteration 3200, loss = 0.689002
I0822 16:01:30.870823 12979 solver.cpp:244]     Train net output #0: loss = 0.689002 (* 1 = 0.689002 loss)
I0822 16:01:30.870832 12979 sgd_solver.cpp:106] Iteration 3200, lr = 0.000894657
I0822 16:01:33.625488 12979 solver.cpp:228] Iteration 3300, loss = 0.687376
I0822 16:01:33.625540 12979 solver.cpp:244]     Train net output #0: loss = 0.687376 (* 1 = 0.687376 loss)
I0822 16:01:33.625548 12979 sgd_solver.cpp:106] Iteration 3300, lr = 0.000891776
I0822 16:01:36.384748 12979 solver.cpp:228] Iteration 3400, loss = 0.692266
I0822 16:01:36.384785 12979 solver.cpp:244]     Train net output #0: loss = 0.692266 (* 1 = 0.692266 loss)
I0822 16:01:36.384793 12979 sgd_solver.cpp:106] Iteration 3400, lr = 0.000888916
I0822 16:01:39.111459 12979 solver.cpp:337] Iteration 3500, Testing net (#0)
I0822 16:01:43.235749 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0822 16:01:43.235796 12979 solver.cpp:404]     Test net output #1: loss = 0.634416 (* 1 = 0.634416 loss)
I0822 16:01:43.244777 12979 solver.cpp:228] Iteration 3500, loss = 0.695292
I0822 16:01:43.244827 12979 solver.cpp:244]     Train net output #0: loss = 0.695292 (* 1 = 0.695292 loss)
I0822 16:01:43.244838 12979 sgd_solver.cpp:106] Iteration 3500, lr = 0.000886077
I0822 16:01:45.987668 12979 solver.cpp:228] Iteration 3600, loss = 0.704553
I0822 16:01:45.987715 12979 solver.cpp:244]     Train net output #0: loss = 0.704553 (* 1 = 0.704553 loss)
I0822 16:01:45.987722 12979 sgd_solver.cpp:106] Iteration 3600, lr = 0.00088326
I0822 16:01:48.738406 12979 solver.cpp:228] Iteration 3700, loss = 0.706029
I0822 16:01:48.738451 12979 solver.cpp:244]     Train net output #0: loss = 0.706029 (* 1 = 0.706029 loss)
I0822 16:01:48.738461 12979 sgd_solver.cpp:106] Iteration 3700, lr = 0.000880463
I0822 16:01:51.485107 12979 solver.cpp:228] Iteration 3800, loss = 0.691717
I0822 16:01:51.485167 12979 solver.cpp:244]     Train net output #0: loss = 0.691717 (* 1 = 0.691717 loss)
I0822 16:01:51.485174 12979 sgd_solver.cpp:106] Iteration 3800, lr = 0.000877687
I0822 16:01:54.220777 12979 solver.cpp:228] Iteration 3900, loss = 0.695115
I0822 16:01:54.220829 12979 solver.cpp:244]     Train net output #0: loss = 0.695115 (* 1 = 0.695115 loss)
I0822 16:01:54.220835 12979 sgd_solver.cpp:106] Iteration 3900, lr = 0.000874932
I0822 16:01:56.950014 12979 solver.cpp:337] Iteration 4000, Testing net (#0)
I0822 16:02:00.967370 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0822 16:02:00.967408 12979 solver.cpp:404]     Test net output #1: loss = 0.654338 (* 1 = 0.654338 loss)
I0822 16:02:00.977339 12979 solver.cpp:228] Iteration 4000, loss = 0.684434
I0822 16:02:00.977366 12979 solver.cpp:244]     Train net output #0: loss = 0.684434 (* 1 = 0.684434 loss)
I0822 16:02:00.977375 12979 sgd_solver.cpp:106] Iteration 4000, lr = 0.000872196
I0822 16:02:03.728626 12979 solver.cpp:228] Iteration 4100, loss = 0.700645
I0822 16:02:03.728660 12979 solver.cpp:244]     Train net output #0: loss = 0.700645 (* 1 = 0.700645 loss)
I0822 16:02:03.728667 12979 sgd_solver.cpp:106] Iteration 4100, lr = 0.00086948
I0822 16:02:06.479902 12979 solver.cpp:228] Iteration 4200, loss = 0.692028
I0822 16:02:06.479946 12979 solver.cpp:244]     Train net output #0: loss = 0.692028 (* 1 = 0.692028 loss)
I0822 16:02:06.479954 12979 sgd_solver.cpp:106] Iteration 4200, lr = 0.000866784
I0822 16:02:09.235890 12979 solver.cpp:228] Iteration 4300, loss = 0.696099
I0822 16:02:09.235934 12979 solver.cpp:244]     Train net output #0: loss = 0.696099 (* 1 = 0.696099 loss)
I0822 16:02:09.235941 12979 sgd_solver.cpp:106] Iteration 4300, lr = 0.000864108
I0822 16:02:11.983640 12979 solver.cpp:228] Iteration 4400, loss = 0.688215
I0822 16:02:11.983672 12979 solver.cpp:244]     Train net output #0: loss = 0.688215 (* 1 = 0.688215 loss)
I0822 16:02:11.983677 12979 sgd_solver.cpp:106] Iteration 4400, lr = 0.00086145
I0822 16:02:14.703547 12979 solver.cpp:337] Iteration 4500, Testing net (#0)
I0822 16:02:18.757294 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882484
I0822 16:02:18.757326 12979 solver.cpp:404]     Test net output #1: loss = 0.67852 (* 1 = 0.67852 loss)
I0822 16:02:18.766887 12979 solver.cpp:228] Iteration 4500, loss = 0.693633
I0822 16:02:18.766950 12979 solver.cpp:244]     Train net output #0: loss = 0.693633 (* 1 = 0.693633 loss)
I0822 16:02:18.766973 12979 sgd_solver.cpp:106] Iteration 4500, lr = 0.000858812
I0822 16:02:21.533872 12979 solver.cpp:228] Iteration 4600, loss = 0.691843
I0822 16:02:21.533936 12979 solver.cpp:244]     Train net output #0: loss = 0.691843 (* 1 = 0.691843 loss)
I0822 16:02:21.533948 12979 sgd_solver.cpp:106] Iteration 4600, lr = 0.000856192
I0822 16:02:24.283601 12979 solver.cpp:228] Iteration 4700, loss = 0.693528
I0822 16:02:24.283655 12979 solver.cpp:244]     Train net output #0: loss = 0.693528 (* 1 = 0.693528 loss)
I0822 16:02:24.283663 12979 sgd_solver.cpp:106] Iteration 4700, lr = 0.000853591
I0822 16:02:27.038316 12979 solver.cpp:228] Iteration 4800, loss = 0.683386
I0822 16:02:27.038357 12979 solver.cpp:244]     Train net output #0: loss = 0.683386 (* 1 = 0.683386 loss)
I0822 16:02:27.038362 12979 sgd_solver.cpp:106] Iteration 4800, lr = 0.000851008
I0822 16:02:29.791637 12979 solver.cpp:228] Iteration 4900, loss = 0.68975
I0822 16:02:29.791688 12979 solver.cpp:244]     Train net output #0: loss = 0.68975 (* 1 = 0.68975 loss)
I0822 16:02:29.791699 12979 sgd_solver.cpp:106] Iteration 4900, lr = 0.000848444
I0822 16:02:32.514441 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_5000.caffemodel
I0822 16:02:33.063786 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_5000.solverstate
I0822 16:02:33.221804 12979 solver.cpp:337] Iteration 5000, Testing net (#0)
I0822 16:02:37.224609 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117387
I0822 16:02:37.224653 12979 solver.cpp:404]     Test net output #1: loss = 0.722114 (* 1 = 0.722114 loss)
I0822 16:02:37.233438 12979 solver.cpp:228] Iteration 5000, loss = 0.684269
I0822 16:02:37.233465 12979 solver.cpp:244]     Train net output #0: loss = 0.684269 (* 1 = 0.684269 loss)
I0822 16:02:37.233480 12979 sgd_solver.cpp:106] Iteration 5000, lr = 0.000845897
I0822 16:02:39.988370 12979 solver.cpp:228] Iteration 5100, loss = 0.691202
I0822 16:02:39.988423 12979 solver.cpp:244]     Train net output #0: loss = 0.691202 (* 1 = 0.691202 loss)
I0822 16:02:39.988430 12979 sgd_solver.cpp:106] Iteration 5100, lr = 0.000843368
I0822 16:02:42.743691 12979 solver.cpp:228] Iteration 5200, loss = 0.736307
I0822 16:02:42.743742 12979 solver.cpp:244]     Train net output #0: loss = 0.736307 (* 1 = 0.736307 loss)
I0822 16:02:42.743749 12979 sgd_solver.cpp:106] Iteration 5200, lr = 0.000840857
I0822 16:02:45.500622 12979 solver.cpp:228] Iteration 5300, loss = 0.701436
I0822 16:02:45.500671 12979 solver.cpp:244]     Train net output #0: loss = 0.701436 (* 1 = 0.701436 loss)
I0822 16:02:45.500679 12979 sgd_solver.cpp:106] Iteration 5300, lr = 0.000838363
I0822 16:02:48.255782 12979 solver.cpp:228] Iteration 5400, loss = 0.691302
I0822 16:02:48.255851 12979 solver.cpp:244]     Train net output #0: loss = 0.691302 (* 1 = 0.691302 loss)
I0822 16:02:48.255864 12979 sgd_solver.cpp:106] Iteration 5400, lr = 0.000835886
I0822 16:02:50.987110 12979 solver.cpp:337] Iteration 5500, Testing net (#0)
I0822 16:02:55.026737 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0822 16:02:55.026777 12979 solver.cpp:404]     Test net output #1: loss = 0.663007 (* 1 = 0.663007 loss)
I0822 16:02:55.035612 12979 solver.cpp:228] Iteration 5500, loss = 0.696716
I0822 16:02:55.035675 12979 solver.cpp:244]     Train net output #0: loss = 0.696716 (* 1 = 0.696716 loss)
I0822 16:02:55.035684 12979 sgd_solver.cpp:106] Iteration 5500, lr = 0.000833427
I0822 16:02:57.795117 12979 solver.cpp:228] Iteration 5600, loss = 0.694034
I0822 16:02:57.795162 12979 solver.cpp:244]     Train net output #0: loss = 0.694034 (* 1 = 0.694034 loss)
I0822 16:02:57.795171 12979 sgd_solver.cpp:106] Iteration 5600, lr = 0.000830984
I0822 16:03:00.560271 12979 solver.cpp:228] Iteration 5700, loss = 0.684573
I0822 16:03:00.560323 12979 solver.cpp:244]     Train net output #0: loss = 0.684573 (* 1 = 0.684573 loss)
I0822 16:03:00.560331 12979 sgd_solver.cpp:106] Iteration 5700, lr = 0.000828558
I0822 16:03:03.303894 12979 solver.cpp:228] Iteration 5800, loss = 0.693163
I0822 16:03:03.303933 12979 solver.cpp:244]     Train net output #0: loss = 0.693163 (* 1 = 0.693163 loss)
I0822 16:03:03.303939 12979 sgd_solver.cpp:106] Iteration 5800, lr = 0.000826148
I0822 16:03:06.056365 12979 solver.cpp:228] Iteration 5900, loss = 0.675516
I0822 16:03:06.056411 12979 solver.cpp:244]     Train net output #0: loss = 0.675516 (* 1 = 0.675516 loss)
I0822 16:03:06.056418 12979 sgd_solver.cpp:106] Iteration 5900, lr = 0.000823754
I0822 16:03:08.781769 12979 solver.cpp:337] Iteration 6000, Testing net (#0)
I0822 16:03:13.062393 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882419
I0822 16:03:13.062433 12979 solver.cpp:404]     Test net output #1: loss = 0.685805 (* 1 = 0.685805 loss)
I0822 16:03:13.071319 12979 solver.cpp:228] Iteration 6000, loss = 0.697855
I0822 16:03:13.071362 12979 solver.cpp:244]     Train net output #0: loss = 0.697855 (* 1 = 0.697855 loss)
I0822 16:03:13.071372 12979 sgd_solver.cpp:106] Iteration 6000, lr = 0.000821377
I0822 16:03:15.823884 12979 solver.cpp:228] Iteration 6100, loss = 0.697765
I0822 16:03:15.823927 12979 solver.cpp:244]     Train net output #0: loss = 0.697765 (* 1 = 0.697765 loss)
I0822 16:03:15.823935 12979 sgd_solver.cpp:106] Iteration 6100, lr = 0.000819015
I0822 16:03:18.570709 12979 solver.cpp:228] Iteration 6200, loss = 0.697795
I0822 16:03:18.570772 12979 solver.cpp:244]     Train net output #0: loss = 0.697795 (* 1 = 0.697795 loss)
I0822 16:03:18.570780 12979 sgd_solver.cpp:106] Iteration 6200, lr = 0.00081667
I0822 16:03:21.321841 12979 solver.cpp:228] Iteration 6300, loss = 0.674279
I0822 16:03:21.321880 12979 solver.cpp:244]     Train net output #0: loss = 0.674279 (* 1 = 0.674279 loss)
I0822 16:03:21.321887 12979 sgd_solver.cpp:106] Iteration 6300, lr = 0.00081434
I0822 16:03:24.069097 12979 solver.cpp:228] Iteration 6400, loss = 0.704396
I0822 16:03:24.069134 12979 solver.cpp:244]     Train net output #0: loss = 0.704396 (* 1 = 0.704396 loss)
I0822 16:03:24.069140 12979 sgd_solver.cpp:106] Iteration 6400, lr = 0.000812025
I0822 16:03:26.781972 12979 solver.cpp:337] Iteration 6500, Testing net (#0)
I0822 16:03:31.050460 12979 solver.cpp:404]     Test net output #0: accuracy = 0.11729
I0822 16:03:31.050515 12979 solver.cpp:404]     Test net output #1: loss = 0.712567 (* 1 = 0.712567 loss)
I0822 16:03:31.060102 12979 solver.cpp:228] Iteration 6500, loss = 0.694509
I0822 16:03:31.060123 12979 solver.cpp:244]     Train net output #0: loss = 0.694509 (* 1 = 0.694509 loss)
I0822 16:03:31.060153 12979 sgd_solver.cpp:106] Iteration 6500, lr = 0.000809726
I0822 16:03:33.805575 12979 solver.cpp:228] Iteration 6600, loss = 0.699643
I0822 16:03:33.805593 12979 solver.cpp:244]     Train net output #0: loss = 0.699643 (* 1 = 0.699643 loss)
I0822 16:03:33.805598 12979 sgd_solver.cpp:106] Iteration 6600, lr = 0.000807442
I0822 16:03:36.565933 12979 solver.cpp:228] Iteration 6700, loss = 0.686303
I0822 16:03:36.565997 12979 solver.cpp:244]     Train net output #0: loss = 0.686303 (* 1 = 0.686303 loss)
I0822 16:03:36.566005 12979 sgd_solver.cpp:106] Iteration 6700, lr = 0.000805173
I0822 16:03:39.317075 12979 solver.cpp:228] Iteration 6800, loss = 0.688301
I0822 16:03:39.317117 12979 solver.cpp:244]     Train net output #0: loss = 0.688301 (* 1 = 0.688301 loss)
I0822 16:03:39.317122 12979 sgd_solver.cpp:106] Iteration 6800, lr = 0.000802918
I0822 16:03:42.067905 12979 solver.cpp:228] Iteration 6900, loss = 0.690453
I0822 16:03:42.067958 12979 solver.cpp:244]     Train net output #0: loss = 0.690453 (* 1 = 0.690453 loss)
I0822 16:03:42.067965 12979 sgd_solver.cpp:106] Iteration 6900, lr = 0.000800679
I0822 16:03:44.792232 12979 solver.cpp:337] Iteration 7000, Testing net (#0)
I0822 16:03:46.218664 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:03:49.563725 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117516
I0822 16:03:49.563788 12979 solver.cpp:404]     Test net output #1: loss = 0.764332 (* 1 = 0.764332 loss)
I0822 16:03:49.574064 12979 solver.cpp:228] Iteration 7000, loss = 0.702138
I0822 16:03:49.574103 12979 solver.cpp:244]     Train net output #0: loss = 0.702138 (* 1 = 0.702138 loss)
I0822 16:03:49.574122 12979 sgd_solver.cpp:106] Iteration 7000, lr = 0.000798454
I0822 16:03:52.330596 12979 solver.cpp:228] Iteration 7100, loss = 0.688202
I0822 16:03:52.330662 12979 solver.cpp:244]     Train net output #0: loss = 0.688202 (* 1 = 0.688202 loss)
I0822 16:03:52.330678 12979 sgd_solver.cpp:106] Iteration 7100, lr = 0.000796243
I0822 16:03:55.077332 12979 solver.cpp:228] Iteration 7200, loss = 0.687856
I0822 16:03:55.077371 12979 solver.cpp:244]     Train net output #0: loss = 0.687856 (* 1 = 0.687856 loss)
I0822 16:03:55.077378 12979 sgd_solver.cpp:106] Iteration 7200, lr = 0.000794046
I0822 16:03:57.815305 12979 solver.cpp:228] Iteration 7300, loss = 0.691049
I0822 16:03:57.815322 12979 solver.cpp:244]     Train net output #0: loss = 0.691049 (* 1 = 0.691049 loss)
I0822 16:03:57.815327 12979 sgd_solver.cpp:106] Iteration 7300, lr = 0.000791864
I0822 16:04:00.553005 12979 solver.cpp:228] Iteration 7400, loss = 0.694614
I0822 16:04:00.553050 12979 solver.cpp:244]     Train net output #0: loss = 0.694614 (* 1 = 0.694614 loss)
I0822 16:04:00.553056 12979 sgd_solver.cpp:106] Iteration 7400, lr = 0.000789695
I0822 16:04:03.263989 12979 solver.cpp:337] Iteration 7500, Testing net (#0)
I0822 16:04:07.609380 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0822 16:04:07.609428 12979 solver.cpp:404]     Test net output #1: loss = 0.690781 (* 1 = 0.690781 loss)
I0822 16:04:07.619197 12979 solver.cpp:228] Iteration 7500, loss = 0.693154
I0822 16:04:07.619266 12979 solver.cpp:244]     Train net output #0: loss = 0.693154 (* 1 = 0.693154 loss)
I0822 16:04:07.619287 12979 sgd_solver.cpp:106] Iteration 7500, lr = 0.000787541
I0822 16:04:10.375108 12979 solver.cpp:228] Iteration 7600, loss = 0.69274
I0822 16:04:10.375157 12979 solver.cpp:244]     Train net output #0: loss = 0.69274 (* 1 = 0.69274 loss)
I0822 16:04:10.375165 12979 sgd_solver.cpp:106] Iteration 7600, lr = 0.0007854
I0822 16:04:13.131615 12979 solver.cpp:228] Iteration 7700, loss = 0.704596
I0822 16:04:13.131662 12979 solver.cpp:244]     Train net output #0: loss = 0.704596 (* 1 = 0.704596 loss)
I0822 16:04:13.131670 12979 sgd_solver.cpp:106] Iteration 7700, lr = 0.000783272
I0822 16:04:15.880342 12979 solver.cpp:228] Iteration 7800, loss = 0.686403
I0822 16:04:15.880409 12979 solver.cpp:244]     Train net output #0: loss = 0.686403 (* 1 = 0.686403 loss)
I0822 16:04:15.880424 12979 sgd_solver.cpp:106] Iteration 7800, lr = 0.000781158
I0822 16:04:18.635443 12979 solver.cpp:228] Iteration 7900, loss = 0.688431
I0822 16:04:18.635515 12979 solver.cpp:244]     Train net output #0: loss = 0.688431 (* 1 = 0.688431 loss)
I0822 16:04:18.635529 12979 sgd_solver.cpp:106] Iteration 7900, lr = 0.000779057
I0822 16:04:21.362166 12979 solver.cpp:337] Iteration 8000, Testing net (#0)
I0822 16:04:25.613080 12979 solver.cpp:404]     Test net output #0: accuracy = 0.825291
I0822 16:04:25.613137 12979 solver.cpp:404]     Test net output #1: loss = 0.692619 (* 1 = 0.692619 loss)
I0822 16:04:25.622081 12979 solver.cpp:228] Iteration 8000, loss = 0.694684
I0822 16:04:25.622112 12979 solver.cpp:244]     Train net output #0: loss = 0.694684 (* 1 = 0.694684 loss)
I0822 16:04:25.622123 12979 sgd_solver.cpp:106] Iteration 8000, lr = 0.00077697
I0822 16:04:28.376407 12979 solver.cpp:228] Iteration 8100, loss = 0.679789
I0822 16:04:28.376448 12979 solver.cpp:244]     Train net output #0: loss = 0.679789 (* 1 = 0.679789 loss)
I0822 16:04:28.376453 12979 sgd_solver.cpp:106] Iteration 8100, lr = 0.000774895
I0822 16:04:31.122931 12979 solver.cpp:228] Iteration 8200, loss = 0.690904
I0822 16:04:31.122951 12979 solver.cpp:244]     Train net output #0: loss = 0.690904 (* 1 = 0.690904 loss)
I0822 16:04:31.122956 12979 sgd_solver.cpp:106] Iteration 8200, lr = 0.000772833
I0822 16:04:33.868885 12979 solver.cpp:228] Iteration 8300, loss = 0.694974
I0822 16:04:33.868901 12979 solver.cpp:244]     Train net output #0: loss = 0.694974 (* 1 = 0.694974 loss)
I0822 16:04:33.868906 12979 sgd_solver.cpp:106] Iteration 8300, lr = 0.000770784
I0822 16:04:36.614596 12979 solver.cpp:228] Iteration 8400, loss = 0.687732
I0822 16:04:36.614645 12979 solver.cpp:244]     Train net output #0: loss = 0.687732 (* 1 = 0.687732 loss)
I0822 16:04:36.614653 12979 sgd_solver.cpp:106] Iteration 8400, lr = 0.000768748
I0822 16:04:39.333863 12979 solver.cpp:337] Iteration 8500, Testing net (#0)
I0822 16:04:43.420933 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0822 16:04:43.420975 12979 solver.cpp:404]     Test net output #1: loss = 0.660665 (* 1 = 0.660665 loss)
I0822 16:04:43.430413 12979 solver.cpp:228] Iteration 8500, loss = 0.706985
I0822 16:04:43.430482 12979 solver.cpp:244]     Train net output #0: loss = 0.706985 (* 1 = 0.706985 loss)
I0822 16:04:43.430505 12979 sgd_solver.cpp:106] Iteration 8500, lr = 0.000766724
I0822 16:04:46.179303 12979 solver.cpp:228] Iteration 8600, loss = 0.685487
I0822 16:04:46.179371 12979 solver.cpp:244]     Train net output #0: loss = 0.685487 (* 1 = 0.685487 loss)
I0822 16:04:46.179383 12979 sgd_solver.cpp:106] Iteration 8600, lr = 0.000764712
I0822 16:04:48.930063 12979 solver.cpp:228] Iteration 8700, loss = 0.699454
I0822 16:04:48.930100 12979 solver.cpp:244]     Train net output #0: loss = 0.699454 (* 1 = 0.699454 loss)
I0822 16:04:48.930106 12979 sgd_solver.cpp:106] Iteration 8700, lr = 0.000762713
I0822 16:04:51.678019 12979 solver.cpp:228] Iteration 8800, loss = 0.687284
I0822 16:04:51.678035 12979 solver.cpp:244]     Train net output #0: loss = 0.687284 (* 1 = 0.687284 loss)
I0822 16:04:51.678040 12979 sgd_solver.cpp:106] Iteration 8800, lr = 0.000760726
I0822 16:04:54.430727 12979 solver.cpp:228] Iteration 8900, loss = 0.705175
I0822 16:04:54.430793 12979 solver.cpp:244]     Train net output #0: loss = 0.705175 (* 1 = 0.705175 loss)
I0822 16:04:54.430799 12979 sgd_solver.cpp:106] Iteration 8900, lr = 0.000758751
I0822 16:04:57.153045 12979 solver.cpp:337] Iteration 9000, Testing net (#0)
I0822 16:05:01.170655 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117613
I0822 16:05:01.170684 12979 solver.cpp:404]     Test net output #1: loss = 0.728949 (* 1 = 0.728949 loss)
I0822 16:05:01.179328 12979 solver.cpp:228] Iteration 9000, loss = 0.706823
I0822 16:05:01.179345 12979 solver.cpp:244]     Train net output #0: loss = 0.706823 (* 1 = 0.706823 loss)
I0822 16:05:01.179352 12979 sgd_solver.cpp:106] Iteration 9000, lr = 0.000756788
I0822 16:05:03.929908 12979 solver.cpp:228] Iteration 9100, loss = 0.696494
I0822 16:05:03.929949 12979 solver.cpp:244]     Train net output #0: loss = 0.696494 (* 1 = 0.696494 loss)
I0822 16:05:03.929955 12979 sgd_solver.cpp:106] Iteration 9100, lr = 0.000754836
I0822 16:05:06.680951 12979 solver.cpp:228] Iteration 9200, loss = 0.681879
I0822 16:05:06.680992 12979 solver.cpp:244]     Train net output #0: loss = 0.681879 (* 1 = 0.681879 loss)
I0822 16:05:06.680997 12979 sgd_solver.cpp:106] Iteration 9200, lr = 0.000752897
I0822 16:05:09.422555 12979 solver.cpp:228] Iteration 9300, loss = 0.701618
I0822 16:05:09.422582 12979 solver.cpp:244]     Train net output #0: loss = 0.701618 (* 1 = 0.701618 loss)
I0822 16:05:09.422587 12979 sgd_solver.cpp:106] Iteration 9300, lr = 0.000750969
I0822 16:05:12.167927 12979 solver.cpp:228] Iteration 9400, loss = 0.70638
I0822 16:05:12.167945 12979 solver.cpp:244]     Train net output #0: loss = 0.70638 (* 1 = 0.70638 loss)
I0822 16:05:12.167950 12979 sgd_solver.cpp:106] Iteration 9400, lr = 0.000749052
I0822 16:05:14.883422 12979 solver.cpp:337] Iteration 9500, Testing net (#0)
I0822 16:05:18.912070 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117677
I0822 16:05:18.912102 12979 solver.cpp:404]     Test net output #1: loss = 0.710984 (* 1 = 0.710984 loss)
I0822 16:05:18.920812 12979 solver.cpp:228] Iteration 9500, loss = 0.68988
I0822 16:05:18.920836 12979 solver.cpp:244]     Train net output #0: loss = 0.68988 (* 1 = 0.68988 loss)
I0822 16:05:18.920847 12979 sgd_solver.cpp:106] Iteration 9500, lr = 0.000747147
I0822 16:05:21.680204 12979 solver.cpp:228] Iteration 9600, loss = 0.687044
I0822 16:05:21.680253 12979 solver.cpp:244]     Train net output #0: loss = 0.687044 (* 1 = 0.687044 loss)
I0822 16:05:21.680264 12979 sgd_solver.cpp:106] Iteration 9600, lr = 0.000745253
I0822 16:05:24.435719 12979 solver.cpp:228] Iteration 9700, loss = 0.689917
I0822 16:05:24.435767 12979 solver.cpp:244]     Train net output #0: loss = 0.689917 (* 1 = 0.689917 loss)
I0822 16:05:24.435775 12979 sgd_solver.cpp:106] Iteration 9700, lr = 0.00074337
I0822 16:05:27.180088 12979 solver.cpp:228] Iteration 9800, loss = 0.702368
I0822 16:05:27.180106 12979 solver.cpp:244]     Train net output #0: loss = 0.702368 (* 1 = 0.702368 loss)
I0822 16:05:27.180111 12979 sgd_solver.cpp:106] Iteration 9800, lr = 0.000741499
I0822 16:05:29.936378 12979 solver.cpp:228] Iteration 9900, loss = 0.703947
I0822 16:05:29.936441 12979 solver.cpp:244]     Train net output #0: loss = 0.703947 (* 1 = 0.703947 loss)
I0822 16:05:29.936447 12979 sgd_solver.cpp:106] Iteration 9900, lr = 0.000739638
I0822 16:05:32.659389 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_10000.caffemodel
I0822 16:05:33.812423 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_10000.solverstate
I0822 16:05:33.977962 12979 solver.cpp:337] Iteration 10000, Testing net (#0)
I0822 16:05:38.081090 12979 solver.cpp:404]     Test net output #0: accuracy = 0.117581
I0822 16:05:38.081132 12979 solver.cpp:404]     Test net output #1: loss = 0.733886 (* 1 = 0.733886 loss)
I0822 16:05:38.090023 12979 solver.cpp:228] Iteration 10000, loss = 0.68883
I0822 16:05:38.090044 12979 solver.cpp:244]     Train net output #0: loss = 0.68883 (* 1 = 0.68883 loss)
I0822 16:05:38.090055 12979 sgd_solver.cpp:106] Iteration 10000, lr = 0.000737788
I0822 16:05:40.847084 12979 solver.cpp:228] Iteration 10100, loss = 0.673604
I0822 16:05:40.847141 12979 solver.cpp:244]     Train net output #0: loss = 0.673604 (* 1 = 0.673604 loss)
I0822 16:05:40.847149 12979 sgd_solver.cpp:106] Iteration 10100, lr = 0.000735949
I0822 16:05:43.597384 12979 solver.cpp:228] Iteration 10200, loss = 0.701964
I0822 16:05:43.597417 12979 solver.cpp:244]     Train net output #0: loss = 0.701964 (* 1 = 0.701964 loss)
I0822 16:05:43.597422 12979 sgd_solver.cpp:106] Iteration 10200, lr = 0.00073412
I0822 16:05:46.350241 12979 solver.cpp:228] Iteration 10300, loss = 0.687611
I0822 16:05:46.350301 12979 solver.cpp:244]     Train net output #0: loss = 0.687611 (* 1 = 0.687611 loss)
I0822 16:05:46.350307 12979 sgd_solver.cpp:106] Iteration 10300, lr = 0.000732303
I0822 16:05:49.097270 12979 solver.cpp:228] Iteration 10400, loss = 0.689908
I0822 16:05:49.097326 12979 solver.cpp:244]     Train net output #0: loss = 0.689908 (* 1 = 0.689908 loss)
I0822 16:05:49.097332 12979 sgd_solver.cpp:106] Iteration 10400, lr = 0.000730495
I0822 16:05:51.822566 12979 solver.cpp:337] Iteration 10500, Testing net (#0)
I0822 16:05:56.189658 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882387
I0822 16:05:56.189703 12979 solver.cpp:404]     Test net output #1: loss = 0.638253 (* 1 = 0.638253 loss)
I0822 16:05:56.198536 12979 solver.cpp:228] Iteration 10500, loss = 0.703249
I0822 16:05:56.198572 12979 solver.cpp:244]     Train net output #0: loss = 0.703249 (* 1 = 0.703249 loss)
I0822 16:05:56.198580 12979 sgd_solver.cpp:106] Iteration 10500, lr = 0.000728698
I0822 16:05:58.947466 12979 solver.cpp:228] Iteration 10600, loss = 0.692442
I0822 16:05:58.947505 12979 solver.cpp:244]     Train net output #0: loss = 0.692442 (* 1 = 0.692442 loss)
I0822 16:05:58.947511 12979 sgd_solver.cpp:106] Iteration 10600, lr = 0.000726911
I0822 16:06:01.694516 12979 solver.cpp:228] Iteration 10700, loss = 0.694653
I0822 16:06:01.694555 12979 solver.cpp:244]     Train net output #0: loss = 0.694653 (* 1 = 0.694653 loss)
I0822 16:06:01.694561 12979 sgd_solver.cpp:106] Iteration 10700, lr = 0.000725135
I0822 16:06:04.441553 12979 solver.cpp:228] Iteration 10800, loss = 0.696981
I0822 16:06:04.441599 12979 solver.cpp:244]     Train net output #0: loss = 0.696981 (* 1 = 0.696981 loss)
I0822 16:06:04.441606 12979 sgd_solver.cpp:106] Iteration 10800, lr = 0.000723368
I0822 16:06:07.184749 12979 solver.cpp:228] Iteration 10900, loss = 0.693009
I0822 16:06:07.184788 12979 solver.cpp:244]     Train net output #0: loss = 0.693009 (* 1 = 0.693009 loss)
I0822 16:06:07.184793 12979 sgd_solver.cpp:106] Iteration 10900, lr = 0.000721612
I0822 16:06:09.893306 12979 solver.cpp:337] Iteration 11000, Testing net (#0)
I0822 16:06:10.206274 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:06:13.898438 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882323
I0822 16:06:13.898463 12979 solver.cpp:404]     Test net output #1: loss = 0.65226 (* 1 = 0.65226 loss)
I0822 16:06:13.907413 12979 solver.cpp:228] Iteration 11000, loss = 0.693113
I0822 16:06:13.907434 12979 solver.cpp:244]     Train net output #0: loss = 0.693113 (* 1 = 0.693113 loss)
I0822 16:06:13.907444 12979 sgd_solver.cpp:106] Iteration 11000, lr = 0.000719865
I0822 16:06:16.660367 12979 solver.cpp:228] Iteration 11100, loss = 0.695193
I0822 16:06:16.660410 12979 solver.cpp:244]     Train net output #0: loss = 0.695193 (* 1 = 0.695193 loss)
I0822 16:06:16.660416 12979 sgd_solver.cpp:106] Iteration 11100, lr = 0.000718129
I0822 16:06:19.408040 12979 solver.cpp:228] Iteration 11200, loss = 0.708899
I0822 16:06:19.408078 12979 solver.cpp:244]     Train net output #0: loss = 0.708899 (* 1 = 0.708899 loss)
I0822 16:06:19.408083 12979 sgd_solver.cpp:106] Iteration 11200, lr = 0.000716402
I0822 16:06:22.154752 12979 solver.cpp:228] Iteration 11300, loss = 0.692681
I0822 16:06:22.154790 12979 solver.cpp:244]     Train net output #0: loss = 0.692681 (* 1 = 0.692681 loss)
I0822 16:06:22.154795 12979 sgd_solver.cpp:106] Iteration 11300, lr = 0.000714684
I0822 16:06:24.902906 12979 solver.cpp:228] Iteration 11400, loss = 0.695676
I0822 16:06:24.902948 12979 solver.cpp:244]     Train net output #0: loss = 0.695676 (* 1 = 0.695676 loss)
I0822 16:06:24.902954 12979 sgd_solver.cpp:106] Iteration 11400, lr = 0.000712977
I0822 16:06:27.619523 12979 solver.cpp:337] Iteration 11500, Testing net (#0)
I0822 16:06:31.973340 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0822 16:06:31.973379 12979 solver.cpp:404]     Test net output #1: loss = 0.667122 (* 1 = 0.667122 loss)
I0822 16:06:31.983469 12979 solver.cpp:228] Iteration 11500, loss = 0.699018
I0822 16:06:31.983511 12979 solver.cpp:244]     Train net output #0: loss = 0.699018 (* 1 = 0.699018 loss)
I0822 16:06:31.983522 12979 sgd_solver.cpp:106] Iteration 11500, lr = 0.000711278
I0822 16:06:34.742668 12979 solver.cpp:228] Iteration 11600, loss = 0.687419
I0822 16:06:34.742713 12979 solver.cpp:244]     Train net output #0: loss = 0.687419 (* 1 = 0.687419 loss)
I0822 16:06:34.742720 12979 sgd_solver.cpp:106] Iteration 11600, lr = 0.00070959
I0822 16:06:37.502432 12979 solver.cpp:228] Iteration 11700, loss = 0.698562
I0822 16:06:37.502477 12979 solver.cpp:244]     Train net output #0: loss = 0.698562 (* 1 = 0.698562 loss)
I0822 16:06:37.502485 12979 sgd_solver.cpp:106] Iteration 11700, lr = 0.00070791
I0822 16:06:40.253171 12979 solver.cpp:228] Iteration 11800, loss = 0.698584
I0822 16:06:40.253222 12979 solver.cpp:244]     Train net output #0: loss = 0.698584 (* 1 = 0.698584 loss)
I0822 16:06:40.253228 12979 sgd_solver.cpp:106] Iteration 11800, lr = 0.00070624
I0822 16:06:43.002641 12979 solver.cpp:228] Iteration 11900, loss = 0.701993
I0822 16:06:43.002681 12979 solver.cpp:244]     Train net output #0: loss = 0.701993 (* 1 = 0.701993 loss)
I0822 16:06:43.002686 12979 sgd_solver.cpp:106] Iteration 11900, lr = 0.000704579
I0822 16:06:45.728461 12979 solver.cpp:337] Iteration 12000, Testing net (#0)
I0822 16:06:50.318912 12979 solver.cpp:404]     Test net output #0: accuracy = 0.425097
I0822 16:06:50.318976 12979 solver.cpp:404]     Test net output #1: loss = 0.693913 (* 1 = 0.693913 loss)
I0822 16:06:50.329262 12979 solver.cpp:228] Iteration 12000, loss = 0.695761
I0822 16:06:50.329330 12979 solver.cpp:244]     Train net output #0: loss = 0.695761 (* 1 = 0.695761 loss)
I0822 16:06:50.329354 12979 sgd_solver.cpp:106] Iteration 12000, lr = 0.000702927
I0822 16:06:53.079645 12979 solver.cpp:228] Iteration 12100, loss = 0.691645
I0822 16:06:53.079687 12979 solver.cpp:244]     Train net output #0: loss = 0.691645 (* 1 = 0.691645 loss)
I0822 16:06:53.079694 12979 sgd_solver.cpp:106] Iteration 12100, lr = 0.000701284
I0822 16:06:55.829042 12979 solver.cpp:228] Iteration 12200, loss = 0.693567
I0822 16:06:55.829097 12979 solver.cpp:244]     Train net output #0: loss = 0.693567 (* 1 = 0.693567 loss)
I0822 16:06:55.829103 12979 sgd_solver.cpp:106] Iteration 12200, lr = 0.00069965
I0822 16:06:58.579252 12979 solver.cpp:228] Iteration 12300, loss = 0.691384
I0822 16:06:58.579300 12979 solver.cpp:244]     Train net output #0: loss = 0.691384 (* 1 = 0.691384 loss)
I0822 16:06:58.579308 12979 sgd_solver.cpp:106] Iteration 12300, lr = 0.000698024
I0822 16:07:01.326215 12979 solver.cpp:228] Iteration 12400, loss = 0.697211
I0822 16:07:01.326258 12979 solver.cpp:244]     Train net output #0: loss = 0.697211 (* 1 = 0.697211 loss)
I0822 16:07:01.326264 12979 sgd_solver.cpp:106] Iteration 12400, lr = 0.000696408
I0822 16:07:04.048637 12979 solver.cpp:337] Iteration 12500, Testing net (#0)
I0822 16:07:08.630470 12979 solver.cpp:404]     Test net output #0: accuracy = 0.123355
I0822 16:07:08.630522 12979 solver.cpp:404]     Test net output #1: loss = 0.698988 (* 1 = 0.698988 loss)
I0822 16:07:08.640621 12979 solver.cpp:228] Iteration 12500, loss = 0.685628
I0822 16:07:08.640686 12979 solver.cpp:244]     Train net output #0: loss = 0.685628 (* 1 = 0.685628 loss)
I0822 16:07:08.640707 12979 sgd_solver.cpp:106] Iteration 12500, lr = 0.0006948
I0822 16:07:11.390159 12979 solver.cpp:228] Iteration 12600, loss = 0.694923
I0822 16:07:11.390202 12979 solver.cpp:244]     Train net output #0: loss = 0.694923 (* 1 = 0.694923 loss)
I0822 16:07:11.390207 12979 sgd_solver.cpp:106] Iteration 12600, lr = 0.000693201
I0822 16:07:14.135417 12979 solver.cpp:228] Iteration 12700, loss = 0.690276
I0822 16:07:14.135437 12979 solver.cpp:244]     Train net output #0: loss = 0.690276 (* 1 = 0.690276 loss)
I0822 16:07:14.135442 12979 sgd_solver.cpp:106] Iteration 12700, lr = 0.000691611
I0822 16:07:16.878805 12979 solver.cpp:228] Iteration 12800, loss = 0.685939
I0822 16:07:16.878823 12979 solver.cpp:244]     Train net output #0: loss = 0.685939 (* 1 = 0.685939 loss)
I0822 16:07:16.878826 12979 sgd_solver.cpp:106] Iteration 12800, lr = 0.000690029
I0822 16:07:19.622922 12979 solver.cpp:228] Iteration 12900, loss = 0.693357
I0822 16:07:19.622975 12979 solver.cpp:244]     Train net output #0: loss = 0.693357 (* 1 = 0.693357 loss)
I0822 16:07:19.622980 12979 sgd_solver.cpp:106] Iteration 12900, lr = 0.000688455
I0822 16:07:22.340433 12979 solver.cpp:337] Iteration 13000, Testing net (#0)
I0822 16:07:26.618188 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882516
I0822 16:07:26.618228 12979 solver.cpp:404]     Test net output #1: loss = 0.659231 (* 1 = 0.659231 loss)
I0822 16:07:26.626948 12979 solver.cpp:228] Iteration 13000, loss = 0.697888
I0822 16:07:26.626981 12979 solver.cpp:244]     Train net output #0: loss = 0.697888 (* 1 = 0.697888 loss)
I0822 16:07:26.626991 12979 sgd_solver.cpp:106] Iteration 13000, lr = 0.00068689
I0822 16:07:29.368547 12979 solver.cpp:228] Iteration 13100, loss = 0.689413
I0822 16:07:29.368587 12979 solver.cpp:244]     Train net output #0: loss = 0.689413 (* 1 = 0.689413 loss)
I0822 16:07:29.368592 12979 sgd_solver.cpp:106] Iteration 13100, lr = 0.000685333
I0822 16:07:32.122732 12979 solver.cpp:228] Iteration 13200, loss = 0.688999
I0822 16:07:32.122772 12979 solver.cpp:244]     Train net output #0: loss = 0.688999 (* 1 = 0.688999 loss)
I0822 16:07:32.122778 12979 sgd_solver.cpp:106] Iteration 13200, lr = 0.000683784
I0822 16:07:34.874840 12979 solver.cpp:228] Iteration 13300, loss = 0.688708
I0822 16:07:34.874892 12979 solver.cpp:244]     Train net output #0: loss = 0.688708 (* 1 = 0.688708 loss)
I0822 16:07:34.874899 12979 sgd_solver.cpp:106] Iteration 13300, lr = 0.000682243
I0822 16:07:37.626276 12979 solver.cpp:228] Iteration 13400, loss = 0.708868
I0822 16:07:37.626313 12979 solver.cpp:244]     Train net output #0: loss = 0.708868 (* 1 = 0.708868 loss)
I0822 16:07:37.626318 12979 sgd_solver.cpp:106] Iteration 13400, lr = 0.000680711
I0822 16:07:40.345630 12979 solver.cpp:337] Iteration 13500, Testing net (#0)
I0822 16:07:44.792700 12979 solver.cpp:404]     Test net output #0: accuracy = 0.839161
I0822 16:07:44.792755 12979 solver.cpp:404]     Test net output #1: loss = 0.676449 (* 1 = 0.676449 loss)
I0822 16:07:44.801864 12979 solver.cpp:228] Iteration 13500, loss = 0.690745
I0822 16:07:44.801923 12979 solver.cpp:244]     Train net output #0: loss = 0.690745 (* 1 = 0.690745 loss)
I0822 16:07:44.801939 12979 sgd_solver.cpp:106] Iteration 13500, lr = 0.000679186
I0822 16:07:47.559308 12979 solver.cpp:228] Iteration 13600, loss = 0.686055
I0822 16:07:47.559345 12979 solver.cpp:244]     Train net output #0: loss = 0.686055 (* 1 = 0.686055 loss)
I0822 16:07:47.559350 12979 sgd_solver.cpp:106] Iteration 13600, lr = 0.00067767
I0822 16:07:50.314970 12979 solver.cpp:228] Iteration 13700, loss = 0.697019
I0822 16:07:50.315008 12979 solver.cpp:244]     Train net output #0: loss = 0.697019 (* 1 = 0.697019 loss)
I0822 16:07:50.315014 12979 sgd_solver.cpp:106] Iteration 13700, lr = 0.000676161
I0822 16:07:53.063015 12979 solver.cpp:228] Iteration 13800, loss = 0.684473
I0822 16:07:53.063053 12979 solver.cpp:244]     Train net output #0: loss = 0.684473 (* 1 = 0.684473 loss)
I0822 16:07:53.063058 12979 sgd_solver.cpp:106] Iteration 13800, lr = 0.00067466
I0822 16:07:55.810497 12979 solver.cpp:228] Iteration 13900, loss = 0.687147
I0822 16:07:55.810515 12979 solver.cpp:244]     Train net output #0: loss = 0.687147 (* 1 = 0.687147 loss)
I0822 16:07:55.810520 12979 sgd_solver.cpp:106] Iteration 13900, lr = 0.000673167
I0822 16:07:58.542321 12979 solver.cpp:337] Iteration 14000, Testing net (#0)
I0822 16:08:02.605254 12979 solver.cpp:404]     Test net output #0: accuracy = 0.474806
I0822 16:08:02.605303 12979 solver.cpp:404]     Test net output #1: loss = 0.700615 (* 1 = 0.700615 loss)
I0822 16:08:02.614806 12979 solver.cpp:228] Iteration 14000, loss = 0.68203
I0822 16:08:02.614877 12979 solver.cpp:244]     Train net output #0: loss = 0.68203 (* 1 = 0.68203 loss)
I0822 16:08:02.614910 12979 sgd_solver.cpp:106] Iteration 14000, lr = 0.000671681
I0822 16:08:05.361630 12979 solver.cpp:228] Iteration 14100, loss = 0.678872
I0822 16:08:05.361680 12979 solver.cpp:244]     Train net output #0: loss = 0.678872 (* 1 = 0.678872 loss)
I0822 16:08:05.361688 12979 sgd_solver.cpp:106] Iteration 14100, lr = 0.000670204
I0822 16:08:08.112368 12979 solver.cpp:228] Iteration 14200, loss = 0.668719
I0822 16:08:08.112408 12979 solver.cpp:244]     Train net output #0: loss = 0.668719 (* 1 = 0.668719 loss)
I0822 16:08:08.112414 12979 sgd_solver.cpp:106] Iteration 14200, lr = 0.000668733
I0822 16:08:10.860229 12979 solver.cpp:228] Iteration 14300, loss = 0.681591
I0822 16:08:10.860280 12979 solver.cpp:244]     Train net output #0: loss = 0.681591 (* 1 = 0.681591 loss)
I0822 16:08:10.860287 12979 sgd_solver.cpp:106] Iteration 14300, lr = 0.000667271
I0822 16:08:13.607087 12979 solver.cpp:228] Iteration 14400, loss = 0.655455
I0822 16:08:13.607126 12979 solver.cpp:244]     Train net output #0: loss = 0.655455 (* 1 = 0.655455 loss)
I0822 16:08:13.607132 12979 sgd_solver.cpp:106] Iteration 14400, lr = 0.000665815
I0822 16:08:16.328276 12979 solver.cpp:337] Iteration 14500, Testing net (#0)
I0822 16:08:17.032690 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:08:21.059648 12979 solver.cpp:404]     Test net output #0: accuracy = 0.494839
I0822 16:08:21.059701 12979 solver.cpp:404]     Test net output #1: loss = 0.713289 (* 1 = 0.713289 loss)
I0822 16:08:21.070123 12979 solver.cpp:228] Iteration 14500, loss = 0.640028
I0822 16:08:21.070149 12979 solver.cpp:244]     Train net output #0: loss = 0.640028 (* 1 = 0.640028 loss)
I0822 16:08:21.070163 12979 sgd_solver.cpp:106] Iteration 14500, lr = 0.000664367
I0822 16:08:23.821202 12979 solver.cpp:228] Iteration 14600, loss = 0.664822
I0822 16:08:23.821240 12979 solver.cpp:244]     Train net output #0: loss = 0.664822 (* 1 = 0.664822 loss)
I0822 16:08:23.821246 12979 sgd_solver.cpp:106] Iteration 14600, lr = 0.000662927
I0822 16:08:26.576964 12979 solver.cpp:228] Iteration 14700, loss = 0.66204
I0822 16:08:26.577021 12979 solver.cpp:244]     Train net output #0: loss = 0.66204 (* 1 = 0.66204 loss)
I0822 16:08:26.577028 12979 sgd_solver.cpp:106] Iteration 14700, lr = 0.000661493
I0822 16:08:29.328546 12979 solver.cpp:228] Iteration 14800, loss = 0.61318
I0822 16:08:29.328609 12979 solver.cpp:244]     Train net output #0: loss = 0.61318 (* 1 = 0.61318 loss)
I0822 16:08:29.328618 12979 sgd_solver.cpp:106] Iteration 14800, lr = 0.000660067
I0822 16:08:32.077571 12979 solver.cpp:228] Iteration 14900, loss = 0.635745
I0822 16:08:32.077631 12979 solver.cpp:244]     Train net output #0: loss = 0.635745 (* 1 = 0.635745 loss)
I0822 16:08:32.077637 12979 sgd_solver.cpp:106] Iteration 14900, lr = 0.000658648
I0822 16:08:34.795827 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_15000.caffemodel
I0822 16:08:35.450963 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_15000.solverstate
I0822 16:08:35.629575 12979 solver.cpp:337] Iteration 15000, Testing net (#0)
I0822 16:08:40.178285 12979 solver.cpp:404]     Test net output #0: accuracy = 0.516452
I0822 16:08:40.178328 12979 solver.cpp:404]     Test net output #1: loss = 0.647159 (* 1 = 0.647159 loss)
I0822 16:08:40.188071 12979 solver.cpp:228] Iteration 15000, loss = 0.630291
I0822 16:08:40.188153 12979 solver.cpp:244]     Train net output #0: loss = 0.630291 (* 1 = 0.630291 loss)
I0822 16:08:40.188182 12979 sgd_solver.cpp:106] Iteration 15000, lr = 0.000657236
I0822 16:08:42.943758 12979 solver.cpp:228] Iteration 15100, loss = 0.641364
I0822 16:08:42.943794 12979 solver.cpp:244]     Train net output #0: loss = 0.641364 (* 1 = 0.641364 loss)
I0822 16:08:42.943799 12979 sgd_solver.cpp:106] Iteration 15100, lr = 0.000655831
I0822 16:08:45.697886 12979 solver.cpp:228] Iteration 15200, loss = 0.574967
I0822 16:08:45.697937 12979 solver.cpp:244]     Train net output #0: loss = 0.574967 (* 1 = 0.574967 loss)
I0822 16:08:45.697943 12979 sgd_solver.cpp:106] Iteration 15200, lr = 0.000654434
I0822 16:08:48.450352 12979 solver.cpp:228] Iteration 15300, loss = 0.608644
I0822 16:08:48.450392 12979 solver.cpp:244]     Train net output #0: loss = 0.608644 (* 1 = 0.608644 loss)
I0822 16:08:48.450397 12979 sgd_solver.cpp:106] Iteration 15300, lr = 0.000653043
I0822 16:08:51.212882 12979 solver.cpp:228] Iteration 15400, loss = 0.682597
I0822 16:08:51.212942 12979 solver.cpp:244]     Train net output #0: loss = 0.682597 (* 1 = 0.682597 loss)
I0822 16:08:51.212949 12979 sgd_solver.cpp:106] Iteration 15400, lr = 0.000651659
I0822 16:08:53.935598 12979 solver.cpp:337] Iteration 15500, Testing net (#0)
I0822 16:08:58.178724 12979 solver.cpp:404]     Test net output #0: accuracy = 0.516645
I0822 16:08:58.178764 12979 solver.cpp:404]     Test net output #1: loss = 0.626791 (* 1 = 0.626791 loss)
I0822 16:08:58.187469 12979 solver.cpp:228] Iteration 15500, loss = 0.593558
I0822 16:08:58.187489 12979 solver.cpp:244]     Train net output #0: loss = 0.593558 (* 1 = 0.593558 loss)
I0822 16:08:58.187497 12979 sgd_solver.cpp:106] Iteration 15500, lr = 0.000650281
I0822 16:09:00.944859 12979 solver.cpp:228] Iteration 15600, loss = 0.583674
I0822 16:09:00.944922 12979 solver.cpp:244]     Train net output #0: loss = 0.583674 (* 1 = 0.583674 loss)
I0822 16:09:00.944933 12979 sgd_solver.cpp:106] Iteration 15600, lr = 0.000648911
I0822 16:09:03.701397 12979 solver.cpp:228] Iteration 15700, loss = 0.630596
I0822 16:09:03.701447 12979 solver.cpp:244]     Train net output #0: loss = 0.630596 (* 1 = 0.630596 loss)
I0822 16:09:03.701452 12979 sgd_solver.cpp:106] Iteration 15700, lr = 0.000647547
I0822 16:09:06.451393 12979 solver.cpp:228] Iteration 15800, loss = 0.595901
I0822 16:09:06.451431 12979 solver.cpp:244]     Train net output #0: loss = 0.595901 (* 1 = 0.595901 loss)
I0822 16:09:06.451437 12979 sgd_solver.cpp:106] Iteration 15800, lr = 0.00064619
I0822 16:09:09.197408 12979 solver.cpp:228] Iteration 15900, loss = 0.537023
I0822 16:09:09.197446 12979 solver.cpp:244]     Train net output #0: loss = 0.537023 (* 1 = 0.537023 loss)
I0822 16:09:09.197453 12979 sgd_solver.cpp:106] Iteration 15900, lr = 0.00064484
I0822 16:09:11.915169 12979 solver.cpp:337] Iteration 16000, Testing net (#0)
I0822 16:09:16.304842 12979 solver.cpp:404]     Test net output #0: accuracy = 0.708839
I0822 16:09:16.304900 12979 solver.cpp:404]     Test net output #1: loss = 0.483393 (* 1 = 0.483393 loss)
I0822 16:09:16.315129 12979 solver.cpp:228] Iteration 16000, loss = 0.454869
I0822 16:09:16.315170 12979 solver.cpp:244]     Train net output #0: loss = 0.454869 (* 1 = 0.454869 loss)
I0822 16:09:16.315187 12979 sgd_solver.cpp:106] Iteration 16000, lr = 0.000643496
I0822 16:09:19.068418 12979 solver.cpp:228] Iteration 16100, loss = 0.611268
I0822 16:09:19.068478 12979 solver.cpp:244]     Train net output #0: loss = 0.611268 (* 1 = 0.611268 loss)
I0822 16:09:19.068488 12979 sgd_solver.cpp:106] Iteration 16100, lr = 0.000642158
I0822 16:09:21.819562 12979 solver.cpp:228] Iteration 16200, loss = 0.524634
I0822 16:09:21.819600 12979 solver.cpp:244]     Train net output #0: loss = 0.524634 (* 1 = 0.524634 loss)
I0822 16:09:21.819605 12979 sgd_solver.cpp:106] Iteration 16200, lr = 0.000640827
I0822 16:09:24.563544 12979 solver.cpp:228] Iteration 16300, loss = 0.46182
I0822 16:09:24.563560 12979 solver.cpp:244]     Train net output #0: loss = 0.46182 (* 1 = 0.46182 loss)
I0822 16:09:24.563565 12979 sgd_solver.cpp:106] Iteration 16300, lr = 0.000639503
I0822 16:09:27.310117 12979 solver.cpp:228] Iteration 16400, loss = 0.412173
I0822 16:09:27.310155 12979 solver.cpp:244]     Train net output #0: loss = 0.412173 (* 1 = 0.412173 loss)
I0822 16:09:27.310168 12979 sgd_solver.cpp:106] Iteration 16400, lr = 0.000638185
I0822 16:09:30.042249 12979 solver.cpp:337] Iteration 16500, Testing net (#0)
I0822 16:09:34.031020 12979 solver.cpp:404]     Test net output #0: accuracy = 0.712065
I0822 16:09:34.031061 12979 solver.cpp:404]     Test net output #1: loss = 0.533114 (* 1 = 0.533114 loss)
I0822 16:09:34.039896 12979 solver.cpp:228] Iteration 16500, loss = 0.410216
I0822 16:09:34.039930 12979 solver.cpp:244]     Train net output #0: loss = 0.410216 (* 1 = 0.410216 loss)
I0822 16:09:34.039939 12979 sgd_solver.cpp:106] Iteration 16500, lr = 0.000636873
I0822 16:09:36.796736 12979 solver.cpp:228] Iteration 16600, loss = 0.418586
I0822 16:09:36.796792 12979 solver.cpp:244]     Train net output #0: loss = 0.418586 (* 1 = 0.418586 loss)
I0822 16:09:36.796800 12979 sgd_solver.cpp:106] Iteration 16600, lr = 0.000635568
I0822 16:09:39.557261 12979 solver.cpp:228] Iteration 16700, loss = 0.419374
I0822 16:09:39.557317 12979 solver.cpp:244]     Train net output #0: loss = 0.419374 (* 1 = 0.419374 loss)
I0822 16:09:39.557324 12979 sgd_solver.cpp:106] Iteration 16700, lr = 0.000634268
I0822 16:09:42.311259 12979 solver.cpp:228] Iteration 16800, loss = 0.44389
I0822 16:09:42.311311 12979 solver.cpp:244]     Train net output #0: loss = 0.44389 (* 1 = 0.44389 loss)
I0822 16:09:42.311319 12979 sgd_solver.cpp:106] Iteration 16800, lr = 0.000632975
I0822 16:09:45.066884 12979 solver.cpp:228] Iteration 16900, loss = 0.534785
I0822 16:09:45.066937 12979 solver.cpp:244]     Train net output #0: loss = 0.534785 (* 1 = 0.534785 loss)
I0822 16:09:45.066947 12979 sgd_solver.cpp:106] Iteration 16900, lr = 0.000631688
I0822 16:09:47.795625 12979 solver.cpp:337] Iteration 17000, Testing net (#0)
I0822 16:09:51.864754 12979 solver.cpp:404]     Test net output #0: accuracy = 0.840549
I0822 16:09:51.864810 12979 solver.cpp:404]     Test net output #1: loss = 0.344392 (* 1 = 0.344392 loss)
I0822 16:09:51.873843 12979 solver.cpp:228] Iteration 17000, loss = 0.322489
I0822 16:09:51.873900 12979 solver.cpp:244]     Train net output #0: loss = 0.322489 (* 1 = 0.322489 loss)
I0822 16:09:51.873914 12979 sgd_solver.cpp:106] Iteration 17000, lr = 0.000630407
I0822 16:09:54.632048 12979 solver.cpp:228] Iteration 17100, loss = 0.575272
I0822 16:09:54.632098 12979 solver.cpp:244]     Train net output #0: loss = 0.575272 (* 1 = 0.575272 loss)
I0822 16:09:54.632107 12979 sgd_solver.cpp:106] Iteration 17100, lr = 0.000629132
I0822 16:09:57.391093 12979 solver.cpp:228] Iteration 17200, loss = 0.312691
I0822 16:09:57.391152 12979 solver.cpp:244]     Train net output #0: loss = 0.312691 (* 1 = 0.312691 loss)
I0822 16:09:57.391161 12979 sgd_solver.cpp:106] Iteration 17200, lr = 0.000627864
I0822 16:10:00.146786 12979 solver.cpp:228] Iteration 17300, loss = 0.372265
I0822 16:10:00.146831 12979 solver.cpp:244]     Train net output #0: loss = 0.372265 (* 1 = 0.372265 loss)
I0822 16:10:00.146837 12979 sgd_solver.cpp:106] Iteration 17300, lr = 0.000626601
I0822 16:10:02.904244 12979 solver.cpp:228] Iteration 17400, loss = 0.466074
I0822 16:10:02.904284 12979 solver.cpp:244]     Train net output #0: loss = 0.466074 (* 1 = 0.466074 loss)
I0822 16:10:02.904294 12979 sgd_solver.cpp:106] Iteration 17400, lr = 0.000625344
I0822 16:10:05.632654 12979 solver.cpp:337] Iteration 17500, Testing net (#0)
I0822 16:10:09.801914 12979 solver.cpp:404]     Test net output #0: accuracy = 0.873613
I0822 16:10:09.801975 12979 solver.cpp:404]     Test net output #1: loss = 0.28662 (* 1 = 0.28662 loss)
I0822 16:10:09.811010 12979 solver.cpp:228] Iteration 17500, loss = 0.51018
I0822 16:10:09.811054 12979 solver.cpp:244]     Train net output #0: loss = 0.51018 (* 1 = 0.51018 loss)
I0822 16:10:09.811067 12979 sgd_solver.cpp:106] Iteration 17500, lr = 0.000624093
I0822 16:10:12.560672 12979 solver.cpp:228] Iteration 17600, loss = 0.350076
I0822 16:10:12.560720 12979 solver.cpp:244]     Train net output #0: loss = 0.350076 (* 1 = 0.350076 loss)
I0822 16:10:12.560729 12979 sgd_solver.cpp:106] Iteration 17600, lr = 0.000622847
I0822 16:10:15.312791 12979 solver.cpp:228] Iteration 17700, loss = 0.271452
I0822 16:10:15.312846 12979 solver.cpp:244]     Train net output #0: loss = 0.271452 (* 1 = 0.271452 loss)
I0822 16:10:15.312855 12979 sgd_solver.cpp:106] Iteration 17700, lr = 0.000621608
I0822 16:10:18.063303 12979 solver.cpp:228] Iteration 17800, loss = 0.534206
I0822 16:10:18.063347 12979 solver.cpp:244]     Train net output #0: loss = 0.534206 (* 1 = 0.534206 loss)
I0822 16:10:18.063367 12979 sgd_solver.cpp:106] Iteration 17800, lr = 0.000620374
I0822 16:10:20.813498 12979 solver.cpp:228] Iteration 17900, loss = 0.396433
I0822 16:10:20.813549 12979 solver.cpp:244]     Train net output #0: loss = 0.396433 (* 1 = 0.396433 loss)
I0822 16:10:20.813560 12979 sgd_solver.cpp:106] Iteration 17900, lr = 0.000619146
I0822 16:10:23.539952 12979 solver.cpp:337] Iteration 18000, Testing net (#0)
I0822 16:10:27.581790 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898936
I0822 16:10:27.581848 12979 solver.cpp:404]     Test net output #1: loss = 0.23416 (* 1 = 0.23416 loss)
I0822 16:10:27.590801 12979 solver.cpp:228] Iteration 18000, loss = 0.459547
I0822 16:10:27.590863 12979 solver.cpp:244]     Train net output #0: loss = 0.459547 (* 1 = 0.459547 loss)
I0822 16:10:27.590874 12979 sgd_solver.cpp:106] Iteration 18000, lr = 0.000617924
I0822 16:10:30.348163 12979 solver.cpp:228] Iteration 18100, loss = 0.329642
I0822 16:10:30.348206 12979 solver.cpp:244]     Train net output #0: loss = 0.329642 (* 1 = 0.329642 loss)
I0822 16:10:30.348215 12979 sgd_solver.cpp:106] Iteration 18100, lr = 0.000616707
I0822 16:10:33.106938 12979 solver.cpp:228] Iteration 18200, loss = 0.328531
I0822 16:10:33.106989 12979 solver.cpp:244]     Train net output #0: loss = 0.328531 (* 1 = 0.328531 loss)
I0822 16:10:33.106998 12979 sgd_solver.cpp:106] Iteration 18200, lr = 0.000615496
I0822 16:10:35.862534 12979 solver.cpp:228] Iteration 18300, loss = 0.36293
I0822 16:10:35.862572 12979 solver.cpp:244]     Train net output #0: loss = 0.36293 (* 1 = 0.36293 loss)
I0822 16:10:35.862579 12979 sgd_solver.cpp:106] Iteration 18300, lr = 0.00061429
I0822 16:10:38.620987 12979 solver.cpp:228] Iteration 18400, loss = 0.329317
I0822 16:10:38.621024 12979 solver.cpp:244]     Train net output #0: loss = 0.329317 (* 1 = 0.329317 loss)
I0822 16:10:38.621032 12979 sgd_solver.cpp:106] Iteration 18400, lr = 0.00061309
I0822 16:10:41.356855 12979 solver.cpp:337] Iteration 18500, Testing net (#0)
I0822 16:10:41.585937 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:10:45.508569 12979 solver.cpp:404]     Test net output #0: accuracy = 0.801258
I0822 16:10:45.508622 12979 solver.cpp:404]     Test net output #1: loss = 0.404639 (* 1 = 0.404639 loss)
I0822 16:10:45.517701 12979 solver.cpp:228] Iteration 18500, loss = 0.482523
I0822 16:10:45.517747 12979 solver.cpp:244]     Train net output #0: loss = 0.482523 (* 1 = 0.482523 loss)
I0822 16:10:45.517757 12979 sgd_solver.cpp:106] Iteration 18500, lr = 0.000611895
I0822 16:10:48.290772 12979 solver.cpp:228] Iteration 18600, loss = 0.317884
I0822 16:10:48.290825 12979 solver.cpp:244]     Train net output #0: loss = 0.317884 (* 1 = 0.317884 loss)
I0822 16:10:48.290835 12979 sgd_solver.cpp:106] Iteration 18600, lr = 0.000610706
I0822 16:10:51.049376 12979 solver.cpp:228] Iteration 18700, loss = 0.381551
I0822 16:10:51.049422 12979 solver.cpp:244]     Train net output #0: loss = 0.381551 (* 1 = 0.381551 loss)
I0822 16:10:51.049432 12979 sgd_solver.cpp:106] Iteration 18700, lr = 0.000609522
I0822 16:10:53.811928 12979 solver.cpp:228] Iteration 18800, loss = 0.415862
I0822 16:10:53.811981 12979 solver.cpp:244]     Train net output #0: loss = 0.415862 (* 1 = 0.415862 loss)
I0822 16:10:53.811990 12979 sgd_solver.cpp:106] Iteration 18800, lr = 0.000608343
I0822 16:10:56.571640 12979 solver.cpp:228] Iteration 18900, loss = 0.503615
I0822 16:10:56.571694 12979 solver.cpp:244]     Train net output #0: loss = 0.503615 (* 1 = 0.503615 loss)
I0822 16:10:56.571702 12979 sgd_solver.cpp:106] Iteration 18900, lr = 0.00060717
I0822 16:10:59.306959 12979 solver.cpp:337] Iteration 19000, Testing net (#0)
I0822 16:11:03.494956 12979 solver.cpp:404]     Test net output #0: accuracy = 0.826968
I0822 16:11:03.495010 12979 solver.cpp:404]     Test net output #1: loss = 0.377091 (* 1 = 0.377091 loss)
I0822 16:11:03.503957 12979 solver.cpp:228] Iteration 19000, loss = 0.259654
I0822 16:11:03.504012 12979 solver.cpp:244]     Train net output #0: loss = 0.259654 (* 1 = 0.259654 loss)
I0822 16:11:03.504022 12979 sgd_solver.cpp:106] Iteration 19000, lr = 0.000606002
I0822 16:11:06.259387 12979 solver.cpp:228] Iteration 19100, loss = 0.393515
I0822 16:11:06.259440 12979 solver.cpp:244]     Train net output #0: loss = 0.393515 (* 1 = 0.393515 loss)
I0822 16:11:06.259448 12979 sgd_solver.cpp:106] Iteration 19100, lr = 0.000604839
I0822 16:11:09.009016 12979 solver.cpp:228] Iteration 19200, loss = 0.333886
I0822 16:11:09.009068 12979 solver.cpp:244]     Train net output #0: loss = 0.333886 (* 1 = 0.333886 loss)
I0822 16:11:09.009073 12979 sgd_solver.cpp:106] Iteration 19200, lr = 0.000603682
I0822 16:11:11.758798 12979 solver.cpp:228] Iteration 19300, loss = 0.323791
I0822 16:11:11.758858 12979 solver.cpp:244]     Train net output #0: loss = 0.323791 (* 1 = 0.323791 loss)
I0822 16:11:11.758864 12979 sgd_solver.cpp:106] Iteration 19300, lr = 0.000602529
I0822 16:11:14.509663 12979 solver.cpp:228] Iteration 19400, loss = 0.354836
I0822 16:11:14.509718 12979 solver.cpp:244]     Train net output #0: loss = 0.354836 (* 1 = 0.354836 loss)
I0822 16:11:14.509726 12979 sgd_solver.cpp:106] Iteration 19400, lr = 0.000601382
I0822 16:11:17.234249 12979 solver.cpp:337] Iteration 19500, Testing net (#0)
I0822 16:11:21.256057 12979 solver.cpp:404]     Test net output #0: accuracy = 0.854968
I0822 16:11:21.256098 12979 solver.cpp:404]     Test net output #1: loss = 0.321289 (* 1 = 0.321289 loss)
I0822 16:11:21.265116 12979 solver.cpp:228] Iteration 19500, loss = 0.360224
I0822 16:11:21.265153 12979 solver.cpp:244]     Train net output #0: loss = 0.360224 (* 1 = 0.360224 loss)
I0822 16:11:21.265162 12979 sgd_solver.cpp:106] Iteration 19500, lr = 0.00060024
I0822 16:11:24.016527 12979 solver.cpp:228] Iteration 19600, loss = 0.362337
I0822 16:11:24.016563 12979 solver.cpp:244]     Train net output #0: loss = 0.362337 (* 1 = 0.362337 loss)
I0822 16:11:24.016569 12979 sgd_solver.cpp:106] Iteration 19600, lr = 0.000599102
I0822 16:11:26.768745 12979 solver.cpp:228] Iteration 19700, loss = 0.284659
I0822 16:11:26.768784 12979 solver.cpp:244]     Train net output #0: loss = 0.284659 (* 1 = 0.284659 loss)
I0822 16:11:26.768790 12979 sgd_solver.cpp:106] Iteration 19700, lr = 0.00059797
I0822 16:11:29.523298 12979 solver.cpp:228] Iteration 19800, loss = 0.353349
I0822 16:11:29.523345 12979 solver.cpp:244]     Train net output #0: loss = 0.353349 (* 1 = 0.353349 loss)
I0822 16:11:29.523355 12979 sgd_solver.cpp:106] Iteration 19800, lr = 0.000596843
I0822 16:11:32.278198 12979 solver.cpp:228] Iteration 19900, loss = 0.324259
I0822 16:11:32.278259 12979 solver.cpp:244]     Train net output #0: loss = 0.324259 (* 1 = 0.324259 loss)
I0822 16:11:32.278266 12979 sgd_solver.cpp:106] Iteration 19900, lr = 0.000595721
I0822 16:11:35.003602 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_20000.caffemodel
I0822 16:11:35.498271 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_20000.solverstate
I0822 16:11:35.654873 12979 solver.cpp:337] Iteration 20000, Testing net (#0)
I0822 16:11:39.702236 12979 solver.cpp:404]     Test net output #0: accuracy = 0.794323
I0822 16:11:39.702291 12979 solver.cpp:404]     Test net output #1: loss = 0.433947 (* 1 = 0.433947 loss)
I0822 16:11:39.711107 12979 solver.cpp:228] Iteration 20000, loss = 0.331746
I0822 16:11:39.711158 12979 solver.cpp:244]     Train net output #0: loss = 0.331746 (* 1 = 0.331746 loss)
I0822 16:11:39.711169 12979 sgd_solver.cpp:106] Iteration 20000, lr = 0.000594604
I0822 16:11:42.461925 12979 solver.cpp:228] Iteration 20100, loss = 0.430694
I0822 16:11:42.461979 12979 solver.cpp:244]     Train net output #0: loss = 0.430694 (* 1 = 0.430694 loss)
I0822 16:11:42.461987 12979 sgd_solver.cpp:106] Iteration 20100, lr = 0.000593491
I0822 16:11:45.214227 12979 solver.cpp:228] Iteration 20200, loss = 0.461235
I0822 16:11:45.214277 12979 solver.cpp:244]     Train net output #0: loss = 0.461235 (* 1 = 0.461235 loss)
I0822 16:11:45.214284 12979 sgd_solver.cpp:106] Iteration 20200, lr = 0.000592384
I0822 16:11:47.966109 12979 solver.cpp:228] Iteration 20300, loss = 0.386806
I0822 16:11:47.966162 12979 solver.cpp:244]     Train net output #0: loss = 0.386806 (* 1 = 0.386806 loss)
I0822 16:11:47.966171 12979 sgd_solver.cpp:106] Iteration 20300, lr = 0.000591281
I0822 16:11:50.715909 12979 solver.cpp:228] Iteration 20400, loss = 0.29478
I0822 16:11:50.715961 12979 solver.cpp:244]     Train net output #0: loss = 0.29478 (* 1 = 0.29478 loss)
I0822 16:11:50.715968 12979 sgd_solver.cpp:106] Iteration 20400, lr = 0.000590183
I0822 16:11:53.438305 12979 solver.cpp:337] Iteration 20500, Testing net (#0)
I0822 16:11:57.577097 12979 solver.cpp:404]     Test net output #0: accuracy = 0.876645
I0822 16:11:57.577141 12979 solver.cpp:404]     Test net output #1: loss = 0.277957 (* 1 = 0.277957 loss)
I0822 16:11:57.586037 12979 solver.cpp:228] Iteration 20500, loss = 0.390452
I0822 16:11:57.586077 12979 solver.cpp:244]     Train net output #0: loss = 0.390452 (* 1 = 0.390452 loss)
I0822 16:11:57.586087 12979 sgd_solver.cpp:106] Iteration 20500, lr = 0.000589089
I0822 16:12:00.335737 12979 solver.cpp:228] Iteration 20600, loss = 0.439272
I0822 16:12:00.335777 12979 solver.cpp:244]     Train net output #0: loss = 0.439272 (* 1 = 0.439272 loss)
I0822 16:12:00.335783 12979 sgd_solver.cpp:106] Iteration 20600, lr = 0.000588001
I0822 16:12:03.086638 12979 solver.cpp:228] Iteration 20700, loss = 0.349795
I0822 16:12:03.086684 12979 solver.cpp:244]     Train net output #0: loss = 0.349795 (* 1 = 0.349795 loss)
I0822 16:12:03.086691 12979 sgd_solver.cpp:106] Iteration 20700, lr = 0.000586917
I0822 16:12:05.835858 12979 solver.cpp:228] Iteration 20800, loss = 0.379793
I0822 16:12:05.835918 12979 solver.cpp:244]     Train net output #0: loss = 0.379793 (* 1 = 0.379793 loss)
I0822 16:12:05.835924 12979 sgd_solver.cpp:106] Iteration 20800, lr = 0.000585838
I0822 16:12:08.583479 12979 solver.cpp:228] Iteration 20900, loss = 0.450538
I0822 16:12:08.583528 12979 solver.cpp:244]     Train net output #0: loss = 0.450538 (* 1 = 0.450538 loss)
I0822 16:12:08.583536 12979 sgd_solver.cpp:106] Iteration 20900, lr = 0.000584763
I0822 16:12:11.299854 12979 solver.cpp:337] Iteration 21000, Testing net (#0)
I0822 16:12:15.680945 12979 solver.cpp:404]     Test net output #0: accuracy = 0.88771
I0822 16:12:15.681010 12979 solver.cpp:404]     Test net output #1: loss = 0.255951 (* 1 = 0.255951 loss)
I0822 16:12:15.691062 12979 solver.cpp:228] Iteration 21000, loss = 0.276741
I0822 16:12:15.691107 12979 solver.cpp:244]     Train net output #0: loss = 0.276741 (* 1 = 0.276741 loss)
I0822 16:12:15.691119 12979 sgd_solver.cpp:106] Iteration 21000, lr = 0.000583693
I0822 16:12:18.429911 12979 solver.cpp:228] Iteration 21100, loss = 0.317317
I0822 16:12:18.429960 12979 solver.cpp:244]     Train net output #0: loss = 0.317317 (* 1 = 0.317317 loss)
I0822 16:12:18.429966 12979 sgd_solver.cpp:106] Iteration 21100, lr = 0.000582628
I0822 16:12:21.170614 12979 solver.cpp:228] Iteration 21200, loss = 0.331653
I0822 16:12:21.170632 12979 solver.cpp:244]     Train net output #0: loss = 0.331653 (* 1 = 0.331653 loss)
I0822 16:12:21.170636 12979 sgd_solver.cpp:106] Iteration 21200, lr = 0.000581567
I0822 16:12:23.906263 12979 solver.cpp:228] Iteration 21300, loss = 0.25635
I0822 16:12:23.906317 12979 solver.cpp:244]     Train net output #0: loss = 0.25635 (* 1 = 0.25635 loss)
I0822 16:12:23.906324 12979 sgd_solver.cpp:106] Iteration 21300, lr = 0.00058051
I0822 16:12:26.652284 12979 solver.cpp:228] Iteration 21400, loss = 0.293876
I0822 16:12:26.652344 12979 solver.cpp:244]     Train net output #0: loss = 0.293876 (* 1 = 0.293876 loss)
I0822 16:12:26.652351 12979 sgd_solver.cpp:106] Iteration 21400, lr = 0.000579458
I0822 16:12:29.371162 12979 solver.cpp:337] Iteration 21500, Testing net (#0)
I0822 16:12:33.577142 12979 solver.cpp:404]     Test net output #0: accuracy = 0.832226
I0822 16:12:33.577183 12979 solver.cpp:404]     Test net output #1: loss = 0.366636 (* 1 = 0.366636 loss)
I0822 16:12:33.586930 12979 solver.cpp:228] Iteration 21500, loss = 0.343649
I0822 16:12:33.587018 12979 solver.cpp:244]     Train net output #0: loss = 0.343649 (* 1 = 0.343649 loss)
I0822 16:12:33.587040 12979 sgd_solver.cpp:106] Iteration 21500, lr = 0.000578411
I0822 16:12:36.337930 12979 solver.cpp:228] Iteration 21600, loss = 0.262881
I0822 16:12:36.337981 12979 solver.cpp:244]     Train net output #0: loss = 0.262881 (* 1 = 0.262881 loss)
I0822 16:12:36.337987 12979 sgd_solver.cpp:106] Iteration 21600, lr = 0.000577368
I0822 16:12:39.084188 12979 solver.cpp:228] Iteration 21700, loss = 0.353065
I0822 16:12:39.084224 12979 solver.cpp:244]     Train net output #0: loss = 0.353065 (* 1 = 0.353065 loss)
I0822 16:12:39.084230 12979 sgd_solver.cpp:106] Iteration 21700, lr = 0.000576329
I0822 16:12:41.829814 12979 solver.cpp:228] Iteration 21800, loss = 0.395485
I0822 16:12:41.829854 12979 solver.cpp:244]     Train net output #0: loss = 0.395485 (* 1 = 0.395485 loss)
I0822 16:12:41.829859 12979 sgd_solver.cpp:106] Iteration 21800, lr = 0.000575295
I0822 16:12:44.571954 12979 solver.cpp:228] Iteration 21900, loss = 0.379295
I0822 16:12:44.571971 12979 solver.cpp:244]     Train net output #0: loss = 0.379295 (* 1 = 0.379295 loss)
I0822 16:12:44.571976 12979 sgd_solver.cpp:106] Iteration 21900, lr = 0.000574265
I0822 16:12:47.289456 12979 solver.cpp:337] Iteration 22000, Testing net (#0)
I0822 16:12:51.644374 12979 solver.cpp:404]     Test net output #0: accuracy = 0.825516
I0822 16:12:51.644420 12979 solver.cpp:404]     Test net output #1: loss = 0.382577 (* 1 = 0.382577 loss)
I0822 16:12:51.654036 12979 solver.cpp:228] Iteration 22000, loss = 0.278232
I0822 16:12:51.654101 12979 solver.cpp:244]     Train net output #0: loss = 0.278232 (* 1 = 0.278232 loss)
I0822 16:12:51.654122 12979 sgd_solver.cpp:106] Iteration 22000, lr = 0.000573239
I0822 16:12:54.417448 12979 solver.cpp:228] Iteration 22100, loss = 0.326786
I0822 16:12:54.417502 12979 solver.cpp:244]     Train net output #0: loss = 0.326786 (* 1 = 0.326786 loss)
I0822 16:12:54.417511 12979 sgd_solver.cpp:106] Iteration 22100, lr = 0.000572217
I0822 16:12:57.181972 12979 solver.cpp:228] Iteration 22200, loss = 0.344995
I0822 16:12:57.182030 12979 solver.cpp:244]     Train net output #0: loss = 0.344995 (* 1 = 0.344995 loss)
I0822 16:12:57.182044 12979 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005712
I0822 16:12:59.938098 12979 solver.cpp:228] Iteration 22300, loss = 0.39754
I0822 16:12:59.938135 12979 solver.cpp:244]     Train net output #0: loss = 0.39754 (* 1 = 0.39754 loss)
I0822 16:12:59.938146 12979 sgd_solver.cpp:106] Iteration 22300, lr = 0.000570187
I0822 16:13:02.692451 12979 solver.cpp:228] Iteration 22400, loss = 0.379335
I0822 16:13:02.692514 12979 solver.cpp:244]     Train net output #0: loss = 0.379335 (* 1 = 0.379335 loss)
I0822 16:13:02.692523 12979 sgd_solver.cpp:106] Iteration 22400, lr = 0.000569178
I0822 16:13:05.422292 12979 solver.cpp:337] Iteration 22500, Testing net (#0)
I0822 16:13:09.490468 12979 solver.cpp:404]     Test net output #0: accuracy = 0.797871
I0822 16:13:09.490526 12979 solver.cpp:404]     Test net output #1: loss = 0.45456 (* 1 = 0.45456 loss)
I0822 16:13:09.499452 12979 solver.cpp:228] Iteration 22500, loss = 0.50176
I0822 16:13:09.499524 12979 solver.cpp:244]     Train net output #0: loss = 0.50176 (* 1 = 0.50176 loss)
I0822 16:13:09.499536 12979 sgd_solver.cpp:106] Iteration 22500, lr = 0.000568173
I0822 16:13:12.263883 12979 solver.cpp:228] Iteration 22600, loss = 0.314945
I0822 16:13:12.263944 12979 solver.cpp:244]     Train net output #0: loss = 0.314945 (* 1 = 0.314945 loss)
I0822 16:13:12.263952 12979 sgd_solver.cpp:106] Iteration 22600, lr = 0.000567173
I0822 16:13:15.018659 12979 solver.cpp:228] Iteration 22700, loss = 0.313249
I0822 16:13:15.018712 12979 solver.cpp:244]     Train net output #0: loss = 0.313249 (* 1 = 0.313249 loss)
I0822 16:13:15.018719 12979 sgd_solver.cpp:106] Iteration 22700, lr = 0.000566176
I0822 16:13:17.768703 12979 solver.cpp:228] Iteration 22800, loss = 0.230886
I0822 16:13:17.768759 12979 solver.cpp:244]     Train net output #0: loss = 0.230886 (* 1 = 0.230886 loss)
I0822 16:13:17.768765 12979 sgd_solver.cpp:106] Iteration 22800, lr = 0.000565184
I0822 16:13:20.518827 12979 solver.cpp:228] Iteration 22900, loss = 0.232496
I0822 16:13:20.518877 12979 solver.cpp:244]     Train net output #0: loss = 0.232496 (* 1 = 0.232496 loss)
I0822 16:13:20.518883 12979 sgd_solver.cpp:106] Iteration 22900, lr = 0.000564195
I0822 16:13:23.242290 12979 solver.cpp:337] Iteration 23000, Testing net (#0)
I0822 16:13:23.760861 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:13:27.241778 12979 solver.cpp:404]     Test net output #0: accuracy = 0.831517
I0822 16:13:27.241837 12979 solver.cpp:404]     Test net output #1: loss = 0.371954 (* 1 = 0.371954 loss)
I0822 16:13:27.250844 12979 solver.cpp:228] Iteration 23000, loss = 0.254174
I0822 16:13:27.250905 12979 solver.cpp:244]     Train net output #0: loss = 0.254174 (* 1 = 0.254174 loss)
I0822 16:13:27.250936 12979 sgd_solver.cpp:106] Iteration 23000, lr = 0.000563211
I0822 16:13:30.002100 12979 solver.cpp:228] Iteration 23100, loss = 0.342281
I0822 16:13:30.002156 12979 solver.cpp:244]     Train net output #0: loss = 0.342281 (* 1 = 0.342281 loss)
I0822 16:13:30.002164 12979 sgd_solver.cpp:106] Iteration 23100, lr = 0.000562231
I0822 16:13:32.748190 12979 solver.cpp:228] Iteration 23200, loss = 0.251577
I0822 16:13:32.748242 12979 solver.cpp:244]     Train net output #0: loss = 0.251577 (* 1 = 0.251577 loss)
I0822 16:13:32.748250 12979 sgd_solver.cpp:106] Iteration 23200, lr = 0.000561254
I0822 16:13:35.493829 12979 solver.cpp:228] Iteration 23300, loss = 0.211578
I0822 16:13:35.493881 12979 solver.cpp:244]     Train net output #0: loss = 0.211578 (* 1 = 0.211578 loss)
I0822 16:13:35.493887 12979 sgd_solver.cpp:106] Iteration 23300, lr = 0.000560282
I0822 16:13:38.242364 12979 solver.cpp:228] Iteration 23400, loss = 0.288985
I0822 16:13:38.242418 12979 solver.cpp:244]     Train net output #0: loss = 0.288985 (* 1 = 0.288985 loss)
I0822 16:13:38.242424 12979 sgd_solver.cpp:106] Iteration 23400, lr = 0.000559313
I0822 16:13:40.962608 12979 solver.cpp:337] Iteration 23500, Testing net (#0)
I0822 16:13:45.021008 12979 solver.cpp:404]     Test net output #0: accuracy = 0.864322
I0822 16:13:45.021067 12979 solver.cpp:404]     Test net output #1: loss = 0.304769 (* 1 = 0.304769 loss)
I0822 16:13:45.029960 12979 solver.cpp:228] Iteration 23500, loss = 0.286506
I0822 16:13:45.030026 12979 solver.cpp:244]     Train net output #0: loss = 0.286506 (* 1 = 0.286506 loss)
I0822 16:13:45.030050 12979 sgd_solver.cpp:106] Iteration 23500, lr = 0.000558349
I0822 16:13:47.776059 12979 solver.cpp:228] Iteration 23600, loss = 0.219091
I0822 16:13:47.776113 12979 solver.cpp:244]     Train net output #0: loss = 0.219091 (* 1 = 0.219091 loss)
I0822 16:13:47.776120 12979 sgd_solver.cpp:106] Iteration 23600, lr = 0.000557388
I0822 16:13:50.524886 12979 solver.cpp:228] Iteration 23700, loss = 0.291933
I0822 16:13:50.524940 12979 solver.cpp:244]     Train net output #0: loss = 0.291933 (* 1 = 0.291933 loss)
I0822 16:13:50.524947 12979 sgd_solver.cpp:106] Iteration 23700, lr = 0.000556431
I0822 16:13:53.270694 12979 solver.cpp:228] Iteration 23800, loss = 0.306166
I0822 16:13:53.270750 12979 solver.cpp:244]     Train net output #0: loss = 0.306166 (* 1 = 0.306166 loss)
I0822 16:13:53.270758 12979 sgd_solver.cpp:106] Iteration 23800, lr = 0.000555478
I0822 16:13:56.025154 12979 solver.cpp:228] Iteration 23900, loss = 0.232347
I0822 16:13:56.025209 12979 solver.cpp:244]     Train net output #0: loss = 0.232347 (* 1 = 0.232347 loss)
I0822 16:13:56.025216 12979 sgd_solver.cpp:106] Iteration 23900, lr = 0.000554529
I0822 16:13:58.742892 12979 solver.cpp:337] Iteration 24000, Testing net (#0)
I0822 16:14:02.766701 12979 solver.cpp:404]     Test net output #0: accuracy = 0.847806
I0822 16:14:02.766758 12979 solver.cpp:404]     Test net output #1: loss = 0.344618 (* 1 = 0.344618 loss)
I0822 16:14:02.775758 12979 solver.cpp:228] Iteration 24000, loss = 0.321225
I0822 16:14:02.775821 12979 solver.cpp:244]     Train net output #0: loss = 0.321225 (* 1 = 0.321225 loss)
I0822 16:14:02.775830 12979 sgd_solver.cpp:106] Iteration 24000, lr = 0.000553583
I0822 16:14:05.530747 12979 solver.cpp:228] Iteration 24100, loss = 0.326704
I0822 16:14:05.530805 12979 solver.cpp:244]     Train net output #0: loss = 0.326704 (* 1 = 0.326704 loss)
I0822 16:14:05.530812 12979 sgd_solver.cpp:106] Iteration 24100, lr = 0.000552642
I0822 16:14:08.282835 12979 solver.cpp:228] Iteration 24200, loss = 0.306008
I0822 16:14:08.282888 12979 solver.cpp:244]     Train net output #0: loss = 0.306008 (* 1 = 0.306008 loss)
I0822 16:14:08.282896 12979 sgd_solver.cpp:106] Iteration 24200, lr = 0.000551704
I0822 16:14:11.034157 12979 solver.cpp:228] Iteration 24300, loss = 0.247651
I0822 16:14:11.034196 12979 solver.cpp:244]     Train net output #0: loss = 0.247651 (* 1 = 0.247651 loss)
I0822 16:14:11.034205 12979 sgd_solver.cpp:106] Iteration 24300, lr = 0.000550769
I0822 16:14:13.794016 12979 solver.cpp:228] Iteration 24400, loss = 0.382574
I0822 16:14:13.794059 12979 solver.cpp:244]     Train net output #0: loss = 0.382574 (* 1 = 0.382574 loss)
I0822 16:14:13.794065 12979 sgd_solver.cpp:106] Iteration 24400, lr = 0.000549839
I0822 16:14:16.527503 12979 solver.cpp:337] Iteration 24500, Testing net (#0)
I0822 16:14:20.809896 12979 solver.cpp:404]     Test net output #0: accuracy = 0.88329
I0822 16:14:20.809955 12979 solver.cpp:404]     Test net output #1: loss = 0.272424 (* 1 = 0.272424 loss)
I0822 16:14:20.818868 12979 solver.cpp:228] Iteration 24500, loss = 0.291805
I0822 16:14:20.818924 12979 solver.cpp:244]     Train net output #0: loss = 0.291805 (* 1 = 0.291805 loss)
I0822 16:14:20.818938 12979 sgd_solver.cpp:106] Iteration 24500, lr = 0.000548912
I0822 16:14:23.707960 12979 solver.cpp:228] Iteration 24600, loss = 0.291484
I0822 16:14:23.708032 12979 solver.cpp:244]     Train net output #0: loss = 0.291484 (* 1 = 0.291484 loss)
I0822 16:14:23.708041 12979 sgd_solver.cpp:106] Iteration 24600, lr = 0.000547988
I0822 16:14:26.458310 12979 solver.cpp:228] Iteration 24700, loss = 0.25629
I0822 16:14:26.458354 12979 solver.cpp:244]     Train net output #0: loss = 0.25629 (* 1 = 0.25629 loss)
I0822 16:14:26.458361 12979 sgd_solver.cpp:106] Iteration 24700, lr = 0.000547069
I0822 16:14:29.199673 12979 solver.cpp:228] Iteration 24800, loss = 0.3026
I0822 16:14:29.199725 12979 solver.cpp:244]     Train net output #0: loss = 0.3026 (* 1 = 0.3026 loss)
I0822 16:14:29.199733 12979 sgd_solver.cpp:106] Iteration 24800, lr = 0.000546153
I0822 16:14:31.942782 12979 solver.cpp:228] Iteration 24900, loss = 0.290857
I0822 16:14:31.942837 12979 solver.cpp:244]     Train net output #0: loss = 0.290857 (* 1 = 0.290857 loss)
I0822 16:14:31.942844 12979 sgd_solver.cpp:106] Iteration 24900, lr = 0.00054524
I0822 16:14:34.658015 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_25000.caffemodel
I0822 16:14:35.153612 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_25000.solverstate
I0822 16:14:35.309334 12979 solver.cpp:337] Iteration 25000, Testing net (#0)
I0822 16:14:39.625478 12979 solver.cpp:404]     Test net output #0: accuracy = 0.912742
I0822 16:14:39.625527 12979 solver.cpp:404]     Test net output #1: loss = 0.204831 (* 1 = 0.204831 loss)
I0822 16:14:39.634450 12979 solver.cpp:228] Iteration 25000, loss = 0.270674
I0822 16:14:39.634510 12979 solver.cpp:244]     Train net output #0: loss = 0.270674 (* 1 = 0.270674 loss)
I0822 16:14:39.634519 12979 sgd_solver.cpp:106] Iteration 25000, lr = 0.000544331
I0822 16:14:42.384932 12979 solver.cpp:228] Iteration 25100, loss = 0.297755
I0822 16:14:42.384987 12979 solver.cpp:244]     Train net output #0: loss = 0.297755 (* 1 = 0.297755 loss)
I0822 16:14:42.384995 12979 sgd_solver.cpp:106] Iteration 25100, lr = 0.000543426
I0822 16:14:45.135726 12979 solver.cpp:228] Iteration 25200, loss = 0.25374
I0822 16:14:45.135778 12979 solver.cpp:244]     Train net output #0: loss = 0.25374 (* 1 = 0.25374 loss)
I0822 16:14:45.135785 12979 sgd_solver.cpp:106] Iteration 25200, lr = 0.000542524
I0822 16:14:47.887759 12979 solver.cpp:228] Iteration 25300, loss = 0.297549
I0822 16:14:47.887804 12979 solver.cpp:244]     Train net output #0: loss = 0.297549 (* 1 = 0.297549 loss)
I0822 16:14:47.887810 12979 sgd_solver.cpp:106] Iteration 25300, lr = 0.000541625
I0822 16:14:50.636481 12979 solver.cpp:228] Iteration 25400, loss = 0.321623
I0822 16:14:50.636525 12979 solver.cpp:244]     Train net output #0: loss = 0.321623 (* 1 = 0.321623 loss)
I0822 16:14:50.636544 12979 sgd_solver.cpp:106] Iteration 25400, lr = 0.00054073
I0822 16:14:53.363046 12979 solver.cpp:337] Iteration 25500, Testing net (#0)
I0822 16:14:57.346523 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899032
I0822 16:14:57.346580 12979 solver.cpp:404]     Test net output #1: loss = 0.234706 (* 1 = 0.234706 loss)
I0822 16:14:57.355556 12979 solver.cpp:228] Iteration 25500, loss = 0.258166
I0822 16:14:57.355623 12979 solver.cpp:244]     Train net output #0: loss = 0.258166 (* 1 = 0.258166 loss)
I0822 16:14:57.355633 12979 sgd_solver.cpp:106] Iteration 25500, lr = 0.000539839
I0822 16:15:00.110103 12979 solver.cpp:228] Iteration 25600, loss = 0.178392
I0822 16:15:00.110160 12979 solver.cpp:244]     Train net output #0: loss = 0.178392 (* 1 = 0.178392 loss)
I0822 16:15:00.110167 12979 sgd_solver.cpp:106] Iteration 25600, lr = 0.00053895
I0822 16:15:02.865687 12979 solver.cpp:228] Iteration 25700, loss = 0.370477
I0822 16:15:02.865731 12979 solver.cpp:244]     Train net output #0: loss = 0.370477 (* 1 = 0.370477 loss)
I0822 16:15:02.865736 12979 sgd_solver.cpp:106] Iteration 25700, lr = 0.000538066
I0822 16:15:05.620585 12979 solver.cpp:228] Iteration 25800, loss = 0.186593
I0822 16:15:05.620642 12979 solver.cpp:244]     Train net output #0: loss = 0.186593 (* 1 = 0.186593 loss)
I0822 16:15:05.620661 12979 sgd_solver.cpp:106] Iteration 25800, lr = 0.000537184
I0822 16:15:08.376796 12979 solver.cpp:228] Iteration 25900, loss = 0.220993
I0822 16:15:08.376850 12979 solver.cpp:244]     Train net output #0: loss = 0.220993 (* 1 = 0.220993 loss)
I0822 16:15:08.376857 12979 sgd_solver.cpp:106] Iteration 25900, lr = 0.000536306
I0822 16:15:11.107041 12979 solver.cpp:337] Iteration 26000, Testing net (#0)
I0822 16:15:15.097828 12979 solver.cpp:404]     Test net output #0: accuracy = 0.886452
I0822 16:15:15.097877 12979 solver.cpp:404]     Test net output #1: loss = 0.264662 (* 1 = 0.264662 loss)
I0822 16:15:15.106813 12979 solver.cpp:228] Iteration 26000, loss = 0.454773
I0822 16:15:15.106878 12979 solver.cpp:244]     Train net output #0: loss = 0.454773 (* 1 = 0.454773 loss)
I0822 16:15:15.106890 12979 sgd_solver.cpp:106] Iteration 26000, lr = 0.000535432
I0822 16:15:17.860222 12979 solver.cpp:228] Iteration 26100, loss = 0.343512
I0822 16:15:17.860275 12979 solver.cpp:244]     Train net output #0: loss = 0.343512 (* 1 = 0.343512 loss)
I0822 16:15:17.860282 12979 sgd_solver.cpp:106] Iteration 26100, lr = 0.00053456
I0822 16:15:20.612313 12979 solver.cpp:228] Iteration 26200, loss = 0.182247
I0822 16:15:20.612370 12979 solver.cpp:244]     Train net output #0: loss = 0.182247 (* 1 = 0.182247 loss)
I0822 16:15:20.612376 12979 sgd_solver.cpp:106] Iteration 26200, lr = 0.000533692
I0822 16:15:23.361690 12979 solver.cpp:228] Iteration 26300, loss = 0.223253
I0822 16:15:23.361744 12979 solver.cpp:244]     Train net output #0: loss = 0.223253 (* 1 = 0.223253 loss)
I0822 16:15:23.361752 12979 sgd_solver.cpp:106] Iteration 26300, lr = 0.000532828
I0822 16:15:26.114094 12979 solver.cpp:228] Iteration 26400, loss = 0.332692
I0822 16:15:26.114146 12979 solver.cpp:244]     Train net output #0: loss = 0.332692 (* 1 = 0.332692 loss)
I0822 16:15:26.114152 12979 sgd_solver.cpp:106] Iteration 26400, lr = 0.000531966
I0822 16:15:28.839989 12979 solver.cpp:337] Iteration 26500, Testing net (#0)
I0822 16:15:32.877382 12979 solver.cpp:404]     Test net output #0: accuracy = 0.882677
I0822 16:15:32.877442 12979 solver.cpp:404]     Test net output #1: loss = 0.28415 (* 1 = 0.28415 loss)
I0822 16:15:32.886378 12979 solver.cpp:228] Iteration 26500, loss = 0.289102
I0822 16:15:32.886436 12979 solver.cpp:244]     Train net output #0: loss = 0.289102 (* 1 = 0.289102 loss)
I0822 16:15:32.886452 12979 sgd_solver.cpp:106] Iteration 26500, lr = 0.000531108
I0822 16:15:35.635013 12979 solver.cpp:228] Iteration 26600, loss = 0.198002
I0822 16:15:35.635071 12979 solver.cpp:244]     Train net output #0: loss = 0.198002 (* 1 = 0.198002 loss)
I0822 16:15:35.635077 12979 sgd_solver.cpp:106] Iteration 26600, lr = 0.000530253
I0822 16:15:38.381379 12979 solver.cpp:228] Iteration 26700, loss = 0.150475
I0822 16:15:38.381433 12979 solver.cpp:244]     Train net output #0: loss = 0.150475 (* 1 = 0.150475 loss)
I0822 16:15:38.381441 12979 sgd_solver.cpp:106] Iteration 26700, lr = 0.000529401
I0822 16:15:41.129146 12979 solver.cpp:228] Iteration 26800, loss = 0.288958
I0822 16:15:41.129200 12979 solver.cpp:244]     Train net output #0: loss = 0.288958 (* 1 = 0.288958 loss)
I0822 16:15:41.129209 12979 sgd_solver.cpp:106] Iteration 26800, lr = 0.000528553
I0822 16:15:43.875335 12979 solver.cpp:228] Iteration 26900, loss = 0.249812
I0822 16:15:43.875391 12979 solver.cpp:244]     Train net output #0: loss = 0.249812 (* 1 = 0.249812 loss)
I0822 16:15:43.875398 12979 sgd_solver.cpp:106] Iteration 26900, lr = 0.000527707
I0822 16:15:46.594378 12979 solver.cpp:337] Iteration 27000, Testing net (#0)
I0822 16:15:50.644815 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896935
I0822 16:15:50.644873 12979 solver.cpp:404]     Test net output #1: loss = 0.252064 (* 1 = 0.252064 loss)
I0822 16:15:50.653844 12979 solver.cpp:228] Iteration 27000, loss = 0.248035
I0822 16:15:50.653903 12979 solver.cpp:244]     Train net output #0: loss = 0.248035 (* 1 = 0.248035 loss)
I0822 16:15:50.653914 12979 sgd_solver.cpp:106] Iteration 27000, lr = 0.000526865
I0822 16:15:53.401293 12979 solver.cpp:228] Iteration 27100, loss = 0.178239
I0822 16:15:53.401355 12979 solver.cpp:244]     Train net output #0: loss = 0.178239 (* 1 = 0.178239 loss)
I0822 16:15:53.401362 12979 sgd_solver.cpp:106] Iteration 27100, lr = 0.000526026
I0822 16:15:56.148075 12979 solver.cpp:228] Iteration 27200, loss = 0.156268
I0822 16:15:56.148130 12979 solver.cpp:244]     Train net output #0: loss = 0.156268 (* 1 = 0.156268 loss)
I0822 16:15:56.148142 12979 sgd_solver.cpp:106] Iteration 27200, lr = 0.000525189
I0822 16:15:58.894819 12979 solver.cpp:228] Iteration 27300, loss = 0.154613
I0822 16:15:58.894876 12979 solver.cpp:244]     Train net output #0: loss = 0.154613 (* 1 = 0.154613 loss)
I0822 16:15:58.894882 12979 sgd_solver.cpp:106] Iteration 27300, lr = 0.000524356
I0822 16:16:01.641032 12979 solver.cpp:228] Iteration 27400, loss = 0.29367
I0822 16:16:01.641088 12979 solver.cpp:244]     Train net output #0: loss = 0.29367 (* 1 = 0.29367 loss)
I0822 16:16:01.641095 12979 sgd_solver.cpp:106] Iteration 27400, lr = 0.000523527
I0822 16:16:04.387527 12979 solver.cpp:337] Iteration 27500, Testing net (#0)
I0822 16:16:08.425869 12979 solver.cpp:404]     Test net output #0: accuracy = 0.837452
I0822 16:16:08.425927 12979 solver.cpp:404]     Test net output #1: loss = 0.400457 (* 1 = 0.400457 loss)
I0822 16:16:08.434841 12979 solver.cpp:228] Iteration 27500, loss = 0.281373
I0822 16:16:08.434890 12979 solver.cpp:244]     Train net output #0: loss = 0.281373 (* 1 = 0.281373 loss)
I0822 16:16:08.434900 12979 sgd_solver.cpp:106] Iteration 27500, lr = 0.0005227
I0822 16:16:11.186928 12979 solver.cpp:228] Iteration 27600, loss = 0.200391
I0822 16:16:11.186981 12979 solver.cpp:244]     Train net output #0: loss = 0.200391 (* 1 = 0.200391 loss)
I0822 16:16:11.186990 12979 sgd_solver.cpp:106] Iteration 27600, lr = 0.000521876
I0822 16:16:13.934375 12979 solver.cpp:228] Iteration 27700, loss = 0.173318
I0822 16:16:13.934429 12979 solver.cpp:244]     Train net output #0: loss = 0.173318 (* 1 = 0.173318 loss)
I0822 16:16:13.934437 12979 sgd_solver.cpp:106] Iteration 27700, lr = 0.000521055
I0822 16:16:16.686084 12979 solver.cpp:228] Iteration 27800, loss = 0.307113
I0822 16:16:16.686137 12979 solver.cpp:244]     Train net output #0: loss = 0.307113 (* 1 = 0.307113 loss)
I0822 16:16:16.686144 12979 sgd_solver.cpp:106] Iteration 27800, lr = 0.000520237
I0822 16:16:19.436444 12979 solver.cpp:228] Iteration 27900, loss = 0.230005
I0822 16:16:19.436498 12979 solver.cpp:244]     Train net output #0: loss = 0.230005 (* 1 = 0.230005 loss)
I0822 16:16:19.436506 12979 sgd_solver.cpp:106] Iteration 27900, lr = 0.000519423
I0822 16:16:22.161049 12979 solver.cpp:337] Iteration 28000, Testing net (#0)
I0822 16:16:26.279196 12979 solver.cpp:404]     Test net output #0: accuracy = 0.903871
I0822 16:16:26.279256 12979 solver.cpp:404]     Test net output #1: loss = 0.233336 (* 1 = 0.233336 loss)
I0822 16:16:26.288135 12979 solver.cpp:228] Iteration 28000, loss = 0.246973
I0822 16:16:26.288203 12979 solver.cpp:244]     Train net output #0: loss = 0.246973 (* 1 = 0.246973 loss)
I0822 16:16:26.288223 12979 sgd_solver.cpp:106] Iteration 28000, lr = 0.000518611
I0822 16:16:29.030967 12979 solver.cpp:228] Iteration 28100, loss = 0.166617
I0822 16:16:29.031023 12979 solver.cpp:244]     Train net output #0: loss = 0.166617 (* 1 = 0.166617 loss)
I0822 16:16:29.031030 12979 sgd_solver.cpp:106] Iteration 28100, lr = 0.000517802
I0822 16:16:31.774564 12979 solver.cpp:228] Iteration 28200, loss = 0.167341
I0822 16:16:31.774610 12979 solver.cpp:244]     Train net output #0: loss = 0.167341 (* 1 = 0.167341 loss)
I0822 16:16:31.774617 12979 sgd_solver.cpp:106] Iteration 28200, lr = 0.000516996
I0822 16:16:34.515579 12979 solver.cpp:228] Iteration 28300, loss = 0.0869634
I0822 16:16:34.515631 12979 solver.cpp:244]     Train net output #0: loss = 0.0869634 (* 1 = 0.0869634 loss)
I0822 16:16:34.515638 12979 sgd_solver.cpp:106] Iteration 28300, lr = 0.000516193
I0822 16:16:37.256351 12979 solver.cpp:228] Iteration 28400, loss = 0.136233
I0822 16:16:37.256394 12979 solver.cpp:244]     Train net output #0: loss = 0.136233 (* 1 = 0.136233 loss)
I0822 16:16:37.256400 12979 sgd_solver.cpp:106] Iteration 28400, lr = 0.000515393
I0822 16:16:39.967206 12979 solver.cpp:337] Iteration 28500, Testing net (#0)
I0822 16:16:43.996455 12979 solver.cpp:404]     Test net output #0: accuracy = 0.86829
I0822 16:16:43.996512 12979 solver.cpp:404]     Test net output #1: loss = 0.329001 (* 1 = 0.329001 loss)
I0822 16:16:44.005461 12979 solver.cpp:228] Iteration 28500, loss = 0.273456
I0822 16:16:44.005530 12979 solver.cpp:244]     Train net output #0: loss = 0.273456 (* 1 = 0.273456 loss)
I0822 16:16:44.005540 12979 sgd_solver.cpp:106] Iteration 28500, lr = 0.000514596
I0822 16:16:46.799057 12979 solver.cpp:228] Iteration 28600, loss = 0.309748
I0822 16:16:46.799098 12979 solver.cpp:244]     Train net output #0: loss = 0.309748 (* 1 = 0.309748 loss)
I0822 16:16:46.799104 12979 sgd_solver.cpp:106] Iteration 28600, lr = 0.000513801
I0822 16:16:49.640804 12979 solver.cpp:228] Iteration 28700, loss = 0.285768
I0822 16:16:49.640858 12979 solver.cpp:244]     Train net output #0: loss = 0.285768 (* 1 = 0.285768 loss)
I0822 16:16:49.640866 12979 sgd_solver.cpp:106] Iteration 28700, lr = 0.00051301
I0822 16:16:52.391173 12979 solver.cpp:228] Iteration 28800, loss = 0.318002
I0822 16:16:52.391228 12979 solver.cpp:244]     Train net output #0: loss = 0.318002 (* 1 = 0.318002 loss)
I0822 16:16:52.391235 12979 sgd_solver.cpp:106] Iteration 28800, lr = 0.000512221
I0822 16:16:55.143416 12979 solver.cpp:228] Iteration 28900, loss = 0.340847
I0822 16:16:55.143471 12979 solver.cpp:244]     Train net output #0: loss = 0.340847 (* 1 = 0.340847 loss)
I0822 16:16:55.143478 12979 sgd_solver.cpp:106] Iteration 28900, lr = 0.000511436
I0822 16:16:57.893059 12979 solver.cpp:337] Iteration 29000, Testing net (#0)
I0822 16:17:02.074650 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898645
I0822 16:17:02.074707 12979 solver.cpp:404]     Test net output #1: loss = 0.250928 (* 1 = 0.250928 loss)
I0822 16:17:02.083653 12979 solver.cpp:228] Iteration 29000, loss = 0.0927058
I0822 16:17:02.083714 12979 solver.cpp:244]     Train net output #0: loss = 0.0927058 (* 1 = 0.0927058 loss)
I0822 16:17:02.083724 12979 sgd_solver.cpp:106] Iteration 29000, lr = 0.000510653
I0822 16:17:04.838857 12979 solver.cpp:228] Iteration 29100, loss = 0.270485
I0822 16:17:04.838901 12979 solver.cpp:244]     Train net output #0: loss = 0.270485 (* 1 = 0.270485 loss)
I0822 16:17:04.838908 12979 sgd_solver.cpp:106] Iteration 29100, lr = 0.000509872
I0822 16:17:07.593657 12979 solver.cpp:228] Iteration 29200, loss = 0.269008
I0822 16:17:07.593713 12979 solver.cpp:244]     Train net output #0: loss = 0.269008 (* 1 = 0.269008 loss)
I0822 16:17:07.593719 12979 sgd_solver.cpp:106] Iteration 29200, lr = 0.000509095
I0822 16:17:10.349231 12979 solver.cpp:228] Iteration 29300, loss = 0.1421
I0822 16:17:10.349284 12979 solver.cpp:244]     Train net output #0: loss = 0.1421 (* 1 = 0.1421 loss)
I0822 16:17:10.349292 12979 sgd_solver.cpp:106] Iteration 29300, lr = 0.00050832
I0822 16:17:13.103657 12979 solver.cpp:228] Iteration 29400, loss = 0.15033
I0822 16:17:13.103713 12979 solver.cpp:244]     Train net output #0: loss = 0.15033 (* 1 = 0.15033 loss)
I0822 16:17:13.103719 12979 sgd_solver.cpp:106] Iteration 29400, lr = 0.000507548
I0822 16:17:15.830785 12979 solver.cpp:337] Iteration 29500, Testing net (#0)
I0822 16:17:20.095103 12979 solver.cpp:404]     Test net output #0: accuracy = 0.866355
I0822 16:17:20.095165 12979 solver.cpp:404]     Test net output #1: loss = 0.342295 (* 1 = 0.342295 loss)
I0822 16:17:20.103967 12979 solver.cpp:228] Iteration 29500, loss = 0.119024
I0822 16:17:20.104019 12979 solver.cpp:244]     Train net output #0: loss = 0.119024 (* 1 = 0.119024 loss)
I0822 16:17:20.104028 12979 sgd_solver.cpp:106] Iteration 29500, lr = 0.000506779
I0822 16:17:22.856220 12979 solver.cpp:228] Iteration 29600, loss = 0.16926
I0822 16:17:22.856274 12979 solver.cpp:244]     Train net output #0: loss = 0.16926 (* 1 = 0.16926 loss)
I0822 16:17:22.856281 12979 sgd_solver.cpp:106] Iteration 29600, lr = 0.000506013
I0822 16:17:25.608340 12979 solver.cpp:228] Iteration 29700, loss = 0.285719
I0822 16:17:25.608397 12979 solver.cpp:244]     Train net output #0: loss = 0.285719 (* 1 = 0.285719 loss)
I0822 16:17:25.608405 12979 sgd_solver.cpp:106] Iteration 29700, lr = 0.000505249
I0822 16:17:28.359374 12979 solver.cpp:228] Iteration 29800, loss = 0.156094
I0822 16:17:28.359427 12979 solver.cpp:244]     Train net output #0: loss = 0.156094 (* 1 = 0.156094 loss)
I0822 16:17:28.359433 12979 sgd_solver.cpp:106] Iteration 29800, lr = 0.000504488
I0822 16:17:31.115862 12979 solver.cpp:228] Iteration 29900, loss = 0.353023
I0822 16:17:31.115909 12979 solver.cpp:244]     Train net output #0: loss = 0.353023 (* 1 = 0.353023 loss)
I0822 16:17:31.115917 12979 sgd_solver.cpp:106] Iteration 29900, lr = 0.000503729
I0822 16:17:33.867853 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_30000.caffemodel
I0822 16:17:34.347604 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_30000.solverstate
I0822 16:17:34.505353 12979 solver.cpp:337] Iteration 30000, Testing net (#0)
I0822 16:17:34.828181 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:17:38.479176 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897742
I0822 16:17:38.479234 12979 solver.cpp:404]     Test net output #1: loss = 0.263958 (* 1 = 0.263958 loss)
I0822 16:17:38.488173 12979 solver.cpp:228] Iteration 30000, loss = 0.388062
I0822 16:17:38.488230 12979 solver.cpp:244]     Train net output #0: loss = 0.388062 (* 1 = 0.388062 loss)
I0822 16:17:38.488240 12979 sgd_solver.cpp:106] Iteration 30000, lr = 0.000502973
I0822 16:17:41.234241 12979 solver.cpp:228] Iteration 30100, loss = 0.0833369
I0822 16:17:41.234295 12979 solver.cpp:244]     Train net output #0: loss = 0.0833369 (* 1 = 0.0833369 loss)
I0822 16:17:41.234303 12979 sgd_solver.cpp:106] Iteration 30100, lr = 0.00050222
I0822 16:17:43.998324 12979 solver.cpp:228] Iteration 30200, loss = 0.13399
I0822 16:17:43.998363 12979 solver.cpp:244]     Train net output #0: loss = 0.13399 (* 1 = 0.13399 loss)
I0822 16:17:43.998369 12979 sgd_solver.cpp:106] Iteration 30200, lr = 0.00050147
I0822 16:17:46.835209 12979 solver.cpp:228] Iteration 30300, loss = 0.358825
I0822 16:17:46.835264 12979 solver.cpp:244]     Train net output #0: loss = 0.358825 (* 1 = 0.358825 loss)
I0822 16:17:46.835271 12979 sgd_solver.cpp:106] Iteration 30300, lr = 0.000500722
I0822 16:17:49.578547 12979 solver.cpp:228] Iteration 30400, loss = 0.112945
I0822 16:17:49.578601 12979 solver.cpp:244]     Train net output #0: loss = 0.112945 (* 1 = 0.112945 loss)
I0822 16:17:49.578608 12979 sgd_solver.cpp:106] Iteration 30400, lr = 0.000499977
I0822 16:17:52.297838 12979 solver.cpp:337] Iteration 30500, Testing net (#0)
I0822 16:17:56.499807 12979 solver.cpp:404]     Test net output #0: accuracy = 0.890516
I0822 16:17:56.499864 12979 solver.cpp:404]     Test net output #1: loss = 0.283899 (* 1 = 0.283899 loss)
I0822 16:17:56.508807 12979 solver.cpp:228] Iteration 30500, loss = 0.142862
I0822 16:17:56.508859 12979 solver.cpp:244]     Train net output #0: loss = 0.142862 (* 1 = 0.142862 loss)
I0822 16:17:56.508868 12979 sgd_solver.cpp:106] Iteration 30500, lr = 0.000499234
I0822 16:17:59.254566 12979 solver.cpp:228] Iteration 30600, loss = 0.188483
I0822 16:17:59.254621 12979 solver.cpp:244]     Train net output #0: loss = 0.188483 (* 1 = 0.188483 loss)
I0822 16:17:59.254628 12979 sgd_solver.cpp:106] Iteration 30600, lr = 0.000498494
I0822 16:18:02.002635 12979 solver.cpp:228] Iteration 30700, loss = 0.281118
I0822 16:18:02.002691 12979 solver.cpp:244]     Train net output #0: loss = 0.281118 (* 1 = 0.281118 loss)
I0822 16:18:02.002697 12979 sgd_solver.cpp:106] Iteration 30700, lr = 0.000497756
I0822 16:18:04.746042 12979 solver.cpp:228] Iteration 30800, loss = 0.186645
I0822 16:18:04.746100 12979 solver.cpp:244]     Train net output #0: loss = 0.186645 (* 1 = 0.186645 loss)
I0822 16:18:04.746106 12979 sgd_solver.cpp:106] Iteration 30800, lr = 0.000497021
I0822 16:18:07.492270 12979 solver.cpp:228] Iteration 30900, loss = 0.207466
I0822 16:18:07.492331 12979 solver.cpp:244]     Train net output #0: loss = 0.207466 (* 1 = 0.207466 loss)
I0822 16:18:07.492338 12979 sgd_solver.cpp:106] Iteration 30900, lr = 0.000496288
I0822 16:18:10.210672 12979 solver.cpp:337] Iteration 31000, Testing net (#0)
I0822 16:18:14.383930 12979 solver.cpp:404]     Test net output #0: accuracy = 0.924806
I0822 16:18:14.383986 12979 solver.cpp:404]     Test net output #1: loss = 0.198608 (* 1 = 0.198608 loss)
I0822 16:18:14.392938 12979 solver.cpp:228] Iteration 31000, loss = 0.289182
I0822 16:18:14.393010 12979 solver.cpp:244]     Train net output #0: loss = 0.289182 (* 1 = 0.289182 loss)
I0822 16:18:14.393021 12979 sgd_solver.cpp:106] Iteration 31000, lr = 0.000495558
I0822 16:18:17.148705 12979 solver.cpp:228] Iteration 31100, loss = 0.161203
I0822 16:18:17.148757 12979 solver.cpp:244]     Train net output #0: loss = 0.161203 (* 1 = 0.161203 loss)
I0822 16:18:17.148764 12979 sgd_solver.cpp:106] Iteration 31100, lr = 0.000494831
I0822 16:18:19.901312 12979 solver.cpp:228] Iteration 31200, loss = 0.117014
I0822 16:18:19.901365 12979 solver.cpp:244]     Train net output #0: loss = 0.117014 (* 1 = 0.117014 loss)
I0822 16:18:19.901372 12979 sgd_solver.cpp:106] Iteration 31200, lr = 0.000494106
I0822 16:18:22.655216 12979 solver.cpp:228] Iteration 31300, loss = 0.106312
I0822 16:18:22.655277 12979 solver.cpp:244]     Train net output #0: loss = 0.106312 (* 1 = 0.106312 loss)
I0822 16:18:22.655285 12979 sgd_solver.cpp:106] Iteration 31300, lr = 0.000493383
I0822 16:18:25.413988 12979 solver.cpp:228] Iteration 31400, loss = 0.212959
I0822 16:18:25.414036 12979 solver.cpp:244]     Train net output #0: loss = 0.212959 (* 1 = 0.212959 loss)
I0822 16:18:25.414044 12979 sgd_solver.cpp:106] Iteration 31400, lr = 0.000492663
I0822 16:18:28.140295 12979 solver.cpp:337] Iteration 31500, Testing net (#0)
I0822 16:18:32.161039 12979 solver.cpp:404]     Test net output #0: accuracy = 0.923129
I0822 16:18:32.161097 12979 solver.cpp:404]     Test net output #1: loss = 0.209112 (* 1 = 0.209112 loss)
I0822 16:18:32.170017 12979 solver.cpp:228] Iteration 31500, loss = 0.131671
I0822 16:18:32.170073 12979 solver.cpp:244]     Train net output #0: loss = 0.131671 (* 1 = 0.131671 loss)
I0822 16:18:32.170081 12979 sgd_solver.cpp:106] Iteration 31500, lr = 0.000491946
I0822 16:18:34.913772 12979 solver.cpp:228] Iteration 31600, loss = 0.0593194
I0822 16:18:34.913820 12979 solver.cpp:244]     Train net output #0: loss = 0.0593194 (* 1 = 0.0593194 loss)
I0822 16:18:34.913826 12979 sgd_solver.cpp:106] Iteration 31600, lr = 0.00049123
I0822 16:18:37.656347 12979 solver.cpp:228] Iteration 31700, loss = 0.0880424
I0822 16:18:37.656390 12979 solver.cpp:244]     Train net output #0: loss = 0.0880424 (* 1 = 0.0880424 loss)
I0822 16:18:37.656397 12979 sgd_solver.cpp:106] Iteration 31700, lr = 0.000490518
I0822 16:18:40.395512 12979 solver.cpp:228] Iteration 31800, loss = 0.111764
I0822 16:18:40.395568 12979 solver.cpp:244]     Train net output #0: loss = 0.111764 (* 1 = 0.111764 loss)
I0822 16:18:40.395576 12979 sgd_solver.cpp:106] Iteration 31800, lr = 0.000489807
I0822 16:18:43.133774 12979 solver.cpp:228] Iteration 31900, loss = 0.114331
I0822 16:18:43.133831 12979 solver.cpp:244]     Train net output #0: loss = 0.114331 (* 1 = 0.114331 loss)
I0822 16:18:43.133837 12979 sgd_solver.cpp:106] Iteration 31900, lr = 0.000489099
I0822 16:18:45.845193 12979 solver.cpp:337] Iteration 32000, Testing net (#0)
I0822 16:18:50.238502 12979 solver.cpp:404]     Test net output #0: accuracy = 0.892226
I0822 16:18:50.238559 12979 solver.cpp:404]     Test net output #1: loss = 0.301029 (* 1 = 0.301029 loss)
I0822 16:18:50.247470 12979 solver.cpp:228] Iteration 32000, loss = 0.0646713
I0822 16:18:50.247535 12979 solver.cpp:244]     Train net output #0: loss = 0.0646713 (* 1 = 0.0646713 loss)
I0822 16:18:50.247546 12979 sgd_solver.cpp:106] Iteration 32000, lr = 0.000488394
I0822 16:18:52.998116 12979 solver.cpp:228] Iteration 32100, loss = 0.157577
I0822 16:18:52.998158 12979 solver.cpp:244]     Train net output #0: loss = 0.157577 (* 1 = 0.157577 loss)
I0822 16:18:52.998167 12979 sgd_solver.cpp:106] Iteration 32100, lr = 0.00048769
I0822 16:18:55.817390 12979 solver.cpp:228] Iteration 32200, loss = 0.0715628
I0822 16:18:55.817433 12979 solver.cpp:244]     Train net output #0: loss = 0.0715628 (* 1 = 0.0715628 loss)
I0822 16:18:55.817440 12979 sgd_solver.cpp:106] Iteration 32200, lr = 0.00048699
I0822 16:18:58.564759 12979 solver.cpp:228] Iteration 32300, loss = 0.356254
I0822 16:18:58.564829 12979 solver.cpp:244]     Train net output #0: loss = 0.356254 (* 1 = 0.356254 loss)
I0822 16:18:58.564837 12979 sgd_solver.cpp:106] Iteration 32300, lr = 0.000486291
I0822 16:19:01.316364 12979 solver.cpp:228] Iteration 32400, loss = 0.135078
I0822 16:19:01.316407 12979 solver.cpp:244]     Train net output #0: loss = 0.135078 (* 1 = 0.135078 loss)
I0822 16:19:01.316414 12979 sgd_solver.cpp:106] Iteration 32400, lr = 0.000485595
I0822 16:19:04.045852 12979 solver.cpp:337] Iteration 32500, Testing net (#0)
I0822 16:19:08.003001 12979 solver.cpp:404]     Test net output #0: accuracy = 0.890871
I0822 16:19:08.003056 12979 solver.cpp:404]     Test net output #1: loss = 0.295697 (* 1 = 0.295697 loss)
I0822 16:19:08.011961 12979 solver.cpp:228] Iteration 32500, loss = 0.121659
I0822 16:19:08.012027 12979 solver.cpp:244]     Train net output #0: loss = 0.121659 (* 1 = 0.121659 loss)
I0822 16:19:08.012037 12979 sgd_solver.cpp:106] Iteration 32500, lr = 0.000484901
I0822 16:19:10.767511 12979 solver.cpp:228] Iteration 32600, loss = 0.148407
I0822 16:19:10.767568 12979 solver.cpp:244]     Train net output #0: loss = 0.148407 (* 1 = 0.148407 loss)
I0822 16:19:10.767576 12979 sgd_solver.cpp:106] Iteration 32600, lr = 0.000484209
I0822 16:19:13.526316 12979 solver.cpp:228] Iteration 32700, loss = 0.116116
I0822 16:19:13.526362 12979 solver.cpp:244]     Train net output #0: loss = 0.116116 (* 1 = 0.116116 loss)
I0822 16:19:13.526370 12979 sgd_solver.cpp:106] Iteration 32700, lr = 0.00048352
I0822 16:19:16.281631 12979 solver.cpp:228] Iteration 32800, loss = 0.112885
I0822 16:19:16.281674 12979 solver.cpp:244]     Train net output #0: loss = 0.112885 (* 1 = 0.112885 loss)
I0822 16:19:16.281682 12979 sgd_solver.cpp:106] Iteration 32800, lr = 0.000482833
I0822 16:19:19.033995 12979 solver.cpp:228] Iteration 32900, loss = 0.185211
I0822 16:19:19.034039 12979 solver.cpp:244]     Train net output #0: loss = 0.185211 (* 1 = 0.185211 loss)
I0822 16:19:19.034057 12979 sgd_solver.cpp:106] Iteration 32900, lr = 0.000482148
I0822 16:19:21.760987 12979 solver.cpp:337] Iteration 33000, Testing net (#0)
I0822 16:19:25.846081 12979 solver.cpp:404]     Test net output #0: accuracy = 0.777065
I0822 16:19:25.846140 12979 solver.cpp:404]     Test net output #1: loss = 0.704543 (* 1 = 0.704543 loss)
I0822 16:19:25.855057 12979 solver.cpp:228] Iteration 33000, loss = 0.132789
I0822 16:19:25.855111 12979 solver.cpp:244]     Train net output #0: loss = 0.132789 (* 1 = 0.132789 loss)
I0822 16:19:25.855120 12979 sgd_solver.cpp:106] Iteration 33000, lr = 0.000481466
I0822 16:19:28.607100 12979 solver.cpp:228] Iteration 33100, loss = 0.0480717
I0822 16:19:28.607156 12979 solver.cpp:244]     Train net output #0: loss = 0.0480717 (* 1 = 0.0480717 loss)
I0822 16:19:28.607164 12979 sgd_solver.cpp:106] Iteration 33100, lr = 0.000480786
I0822 16:19:31.359220 12979 solver.cpp:228] Iteration 33200, loss = 0.201722
I0822 16:19:31.359272 12979 solver.cpp:244]     Train net output #0: loss = 0.201722 (* 1 = 0.201722 loss)
I0822 16:19:31.359278 12979 sgd_solver.cpp:106] Iteration 33200, lr = 0.000480108
I0822 16:19:34.110723 12979 solver.cpp:228] Iteration 33300, loss = 0.0466429
I0822 16:19:34.110776 12979 solver.cpp:244]     Train net output #0: loss = 0.0466429 (* 1 = 0.0466429 loss)
I0822 16:19:34.110783 12979 sgd_solver.cpp:106] Iteration 33300, lr = 0.000479432
I0822 16:19:36.860167 12979 solver.cpp:228] Iteration 33400, loss = 0.240375
I0822 16:19:36.860227 12979 solver.cpp:244]     Train net output #0: loss = 0.240375 (* 1 = 0.240375 loss)
I0822 16:19:36.860234 12979 sgd_solver.cpp:106] Iteration 33400, lr = 0.000478759
I0822 16:19:39.583173 12979 solver.cpp:337] Iteration 33500, Testing net (#0)
I0822 16:19:43.612493 12979 solver.cpp:404]     Test net output #0: accuracy = 0.938903
I0822 16:19:43.612561 12979 solver.cpp:404]     Test net output #1: loss = 0.164096 (* 1 = 0.164096 loss)
I0822 16:19:43.621534 12979 solver.cpp:228] Iteration 33500, loss = 0.147766
I0822 16:19:43.621605 12979 solver.cpp:244]     Train net output #0: loss = 0.147766 (* 1 = 0.147766 loss)
I0822 16:19:43.621615 12979 sgd_solver.cpp:106] Iteration 33500, lr = 0.000478087
I0822 16:19:46.368011 12979 solver.cpp:228] Iteration 33600, loss = 0.0764074
I0822 16:19:46.368067 12979 solver.cpp:244]     Train net output #0: loss = 0.0764074 (* 1 = 0.0764074 loss)
I0822 16:19:46.368073 12979 sgd_solver.cpp:106] Iteration 33600, lr = 0.000477418
I0822 16:19:49.113678 12979 solver.cpp:228] Iteration 33700, loss = 0.117669
I0822 16:19:49.113723 12979 solver.cpp:244]     Train net output #0: loss = 0.117669 (* 1 = 0.117669 loss)
I0822 16:19:49.113731 12979 sgd_solver.cpp:106] Iteration 33700, lr = 0.000476751
I0822 16:19:51.868502 12979 solver.cpp:228] Iteration 33800, loss = 0.0386501
I0822 16:19:51.868558 12979 solver.cpp:244]     Train net output #0: loss = 0.0386501 (* 1 = 0.0386501 loss)
I0822 16:19:51.868566 12979 sgd_solver.cpp:106] Iteration 33800, lr = 0.000476086
I0822 16:19:54.750067 12979 solver.cpp:228] Iteration 33900, loss = 0.183522
I0822 16:19:54.750121 12979 solver.cpp:244]     Train net output #0: loss = 0.183522 (* 1 = 0.183522 loss)
I0822 16:19:54.750129 12979 sgd_solver.cpp:106] Iteration 33900, lr = 0.000475424
I0822 16:19:57.536396 12979 solver.cpp:337] Iteration 34000, Testing net (#0)
I0822 16:20:01.622102 12979 solver.cpp:404]     Test net output #0: accuracy = 0.92487
I0822 16:20:01.622159 12979 solver.cpp:404]     Test net output #1: loss = 0.215814 (* 1 = 0.215814 loss)
I0822 16:20:01.631078 12979 solver.cpp:228] Iteration 34000, loss = 0.344457
I0822 16:20:01.631146 12979 solver.cpp:244]     Train net output #0: loss = 0.344457 (* 1 = 0.344457 loss)
I0822 16:20:01.631156 12979 sgd_solver.cpp:106] Iteration 34000, lr = 0.000474763
I0822 16:20:04.375774 12979 solver.cpp:228] Iteration 34100, loss = 0.16398
I0822 16:20:04.375816 12979 solver.cpp:244]     Train net output #0: loss = 0.16398 (* 1 = 0.16398 loss)
I0822 16:20:04.375823 12979 sgd_solver.cpp:106] Iteration 34100, lr = 0.000474105
I0822 16:20:07.120900 12979 solver.cpp:228] Iteration 34200, loss = 0.106217
I0822 16:20:07.120956 12979 solver.cpp:244]     Train net output #0: loss = 0.106217 (* 1 = 0.106217 loss)
I0822 16:20:07.120964 12979 sgd_solver.cpp:106] Iteration 34200, lr = 0.000473449
I0822 16:20:09.869071 12979 solver.cpp:228] Iteration 34300, loss = 0.214411
I0822 16:20:09.869125 12979 solver.cpp:244]     Train net output #0: loss = 0.214411 (* 1 = 0.214411 loss)
I0822 16:20:09.869133 12979 sgd_solver.cpp:106] Iteration 34300, lr = 0.000472795
I0822 16:20:12.615787 12979 solver.cpp:228] Iteration 34400, loss = 0.0922776
I0822 16:20:12.615839 12979 solver.cpp:244]     Train net output #0: loss = 0.0922776 (* 1 = 0.0922776 loss)
I0822 16:20:12.615846 12979 sgd_solver.cpp:106] Iteration 34400, lr = 0.000472143
I0822 16:20:15.412820 12979 solver.cpp:337] Iteration 34500, Testing net (#0)
I0822 16:20:19.440131 12979 solver.cpp:404]     Test net output #0: accuracy = 0.84971
I0822 16:20:19.440207 12979 solver.cpp:404]     Test net output #1: loss = 0.478476 (* 1 = 0.478476 loss)
I0822 16:20:19.449113 12979 solver.cpp:228] Iteration 34500, loss = 0.272702
I0822 16:20:19.449179 12979 solver.cpp:244]     Train net output #0: loss = 0.272702 (* 1 = 0.272702 loss)
I0822 16:20:19.449189 12979 sgd_solver.cpp:106] Iteration 34500, lr = 0.000471493
I0822 16:20:22.202941 12979 solver.cpp:228] Iteration 34600, loss = 0.143821
I0822 16:20:22.203004 12979 solver.cpp:244]     Train net output #0: loss = 0.143821 (* 1 = 0.143821 loss)
I0822 16:20:22.203011 12979 sgd_solver.cpp:106] Iteration 34600, lr = 0.000470845
I0822 16:20:24.955205 12979 solver.cpp:228] Iteration 34700, loss = 0.078796
I0822 16:20:24.955258 12979 solver.cpp:244]     Train net output #0: loss = 0.078796 (* 1 = 0.078796 loss)
I0822 16:20:24.955265 12979 sgd_solver.cpp:106] Iteration 34700, lr = 0.000470199
I0822 16:20:27.705457 12979 solver.cpp:228] Iteration 34800, loss = 0.16652
I0822 16:20:27.705510 12979 solver.cpp:244]     Train net output #0: loss = 0.16652 (* 1 = 0.16652 loss)
I0822 16:20:27.705518 12979 sgd_solver.cpp:106] Iteration 34800, lr = 0.000469556
I0822 16:20:30.458577 12979 solver.cpp:228] Iteration 34900, loss = 0.17949
I0822 16:20:30.458632 12979 solver.cpp:244]     Train net output #0: loss = 0.17949 (* 1 = 0.17949 loss)
I0822 16:20:30.458638 12979 sgd_solver.cpp:106] Iteration 34900, lr = 0.000468914
I0822 16:20:33.183889 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_35000.caffemodel
I0822 16:20:33.781216 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_35000.solverstate
I0822 16:20:33.939784 12979 solver.cpp:337] Iteration 35000, Testing net (#0)
I0822 16:20:37.923142 12979 solver.cpp:404]     Test net output #0: accuracy = 0.838968
I0822 16:20:37.923202 12979 solver.cpp:404]     Test net output #1: loss = 0.462121 (* 1 = 0.462121 loss)
I0822 16:20:37.932080 12979 solver.cpp:228] Iteration 35000, loss = 0.0642994
I0822 16:20:37.932169 12979 solver.cpp:244]     Train net output #0: loss = 0.0642994 (* 1 = 0.0642994 loss)
I0822 16:20:37.932181 12979 sgd_solver.cpp:106] Iteration 35000, lr = 0.000468274
I0822 16:20:40.675469 12979 solver.cpp:228] Iteration 35100, loss = 0.0766281
I0822 16:20:40.675523 12979 solver.cpp:244]     Train net output #0: loss = 0.0766281 (* 1 = 0.0766281 loss)
I0822 16:20:40.675530 12979 sgd_solver.cpp:106] Iteration 35100, lr = 0.000467637
I0822 16:20:43.415963 12979 solver.cpp:228] Iteration 35200, loss = 0.0970536
I0822 16:20:43.416019 12979 solver.cpp:244]     Train net output #0: loss = 0.0970536 (* 1 = 0.0970536 loss)
I0822 16:20:43.416026 12979 sgd_solver.cpp:106] Iteration 35200, lr = 0.000467001
I0822 16:20:46.155766 12979 solver.cpp:228] Iteration 35300, loss = 0.138543
I0822 16:20:46.155810 12979 solver.cpp:244]     Train net output #0: loss = 0.138543 (* 1 = 0.138543 loss)
I0822 16:20:46.155817 12979 sgd_solver.cpp:106] Iteration 35300, lr = 0.000466368
I0822 16:20:48.895249 12979 solver.cpp:228] Iteration 35400, loss = 0.199063
I0822 16:20:48.895304 12979 solver.cpp:244]     Train net output #0: loss = 0.199063 (* 1 = 0.199063 loss)
I0822 16:20:48.895311 12979 sgd_solver.cpp:106] Iteration 35400, lr = 0.000465736
I0822 16:20:51.611264 12979 solver.cpp:337] Iteration 35500, Testing net (#0)
I0822 16:20:55.605417 12979 solver.cpp:404]     Test net output #0: accuracy = 0.915258
I0822 16:20:55.605473 12979 solver.cpp:404]     Test net output #1: loss = 0.239717 (* 1 = 0.239717 loss)
I0822 16:20:55.614401 12979 solver.cpp:228] Iteration 35500, loss = 0.085261
I0822 16:20:55.614467 12979 solver.cpp:244]     Train net output #0: loss = 0.085261 (* 1 = 0.085261 loss)
I0822 16:20:55.614483 12979 sgd_solver.cpp:106] Iteration 35500, lr = 0.000465107
I0822 16:20:58.362277 12979 solver.cpp:228] Iteration 35600, loss = 0.0272431
I0822 16:20:58.362334 12979 solver.cpp:244]     Train net output #0: loss = 0.0272431 (* 1 = 0.0272431 loss)
I0822 16:20:58.362341 12979 sgd_solver.cpp:106] Iteration 35600, lr = 0.000464479
I0822 16:21:01.112464 12979 solver.cpp:228] Iteration 35700, loss = 0.112057
I0822 16:21:01.112522 12979 solver.cpp:244]     Train net output #0: loss = 0.112057 (* 1 = 0.112057 loss)
I0822 16:21:01.112529 12979 sgd_solver.cpp:106] Iteration 35700, lr = 0.000463854
I0822 16:21:03.902560 12979 solver.cpp:228] Iteration 35800, loss = 0.0480168
I0822 16:21:03.902616 12979 solver.cpp:244]     Train net output #0: loss = 0.0480168 (* 1 = 0.0480168 loss)
I0822 16:21:03.902622 12979 sgd_solver.cpp:106] Iteration 35800, lr = 0.00046323
I0822 16:21:06.677115 12979 solver.cpp:228] Iteration 35900, loss = 0.0983968
I0822 16:21:06.677170 12979 solver.cpp:244]     Train net output #0: loss = 0.0983968 (* 1 = 0.0983968 loss)
I0822 16:21:06.677177 12979 sgd_solver.cpp:106] Iteration 35900, lr = 0.000462609
I0822 16:21:09.401434 12979 solver.cpp:337] Iteration 36000, Testing net (#0)
I0822 16:21:13.381853 12979 solver.cpp:404]     Test net output #0: accuracy = 0.918548
I0822 16:21:13.381901 12979 solver.cpp:404]     Test net output #1: loss = 0.238442 (* 1 = 0.238442 loss)
I0822 16:21:13.390800 12979 solver.cpp:228] Iteration 36000, loss = 0.0983073
I0822 16:21:13.390852 12979 solver.cpp:244]     Train net output #0: loss = 0.0983073 (* 1 = 0.0983073 loss)
I0822 16:21:13.390862 12979 sgd_solver.cpp:106] Iteration 36000, lr = 0.000461989
I0822 16:21:16.143208 12979 solver.cpp:228] Iteration 36100, loss = 0.0392002
I0822 16:21:16.143249 12979 solver.cpp:244]     Train net output #0: loss = 0.0392002 (* 1 = 0.0392002 loss)
I0822 16:21:16.143255 12979 sgd_solver.cpp:106] Iteration 36100, lr = 0.000461371
I0822 16:21:18.893131 12979 solver.cpp:228] Iteration 36200, loss = 0.0689372
I0822 16:21:18.893173 12979 solver.cpp:244]     Train net output #0: loss = 0.0689372 (* 1 = 0.0689372 loss)
I0822 16:21:18.893185 12979 sgd_solver.cpp:106] Iteration 36200, lr = 0.000460755
I0822 16:21:21.665803 12979 solver.cpp:228] Iteration 36300, loss = 0.144215
I0822 16:21:21.665846 12979 solver.cpp:244]     Train net output #0: loss = 0.144215 (* 1 = 0.144215 loss)
I0822 16:21:21.665853 12979 sgd_solver.cpp:106] Iteration 36300, lr = 0.000460141
I0822 16:21:24.412637 12979 solver.cpp:228] Iteration 36400, loss = 0.183394
I0822 16:21:24.412704 12979 solver.cpp:244]     Train net output #0: loss = 0.183394 (* 1 = 0.183394 loss)
I0822 16:21:24.412713 12979 sgd_solver.cpp:106] Iteration 36400, lr = 0.000459529
I0822 16:21:27.138084 12979 solver.cpp:337] Iteration 36500, Testing net (#0)
I0822 16:21:31.373064 12979 solver.cpp:404]     Test net output #0: accuracy = 0.930387
I0822 16:21:31.373106 12979 solver.cpp:404]     Test net output #1: loss = 0.19536 (* 1 = 0.19536 loss)
I0822 16:21:31.381714 12979 solver.cpp:228] Iteration 36500, loss = 0.082049
I0822 16:21:31.381733 12979 solver.cpp:244]     Train net output #0: loss = 0.082049 (* 1 = 0.082049 loss)
I0822 16:21:31.381741 12979 sgd_solver.cpp:106] Iteration 36500, lr = 0.000458919
I0822 16:21:34.123697 12979 solver.cpp:228] Iteration 36600, loss = 0.0730889
I0822 16:21:34.123749 12979 solver.cpp:244]     Train net output #0: loss = 0.0730889 (* 1 = 0.0730889 loss)
I0822 16:21:34.123857 12979 sgd_solver.cpp:106] Iteration 36600, lr = 0.000458311
I0822 16:21:36.871011 12979 solver.cpp:228] Iteration 36700, loss = 0.0796778
I0822 16:21:36.871067 12979 solver.cpp:244]     Train net output #0: loss = 0.0796778 (* 1 = 0.0796778 loss)
I0822 16:21:36.871073 12979 sgd_solver.cpp:106] Iteration 36700, lr = 0.000457705
I0822 16:21:39.612756 12979 solver.cpp:228] Iteration 36800, loss = 0.0714354
I0822 16:21:39.612813 12979 solver.cpp:244]     Train net output #0: loss = 0.0714354 (* 1 = 0.0714354 loss)
I0822 16:21:39.612818 12979 sgd_solver.cpp:106] Iteration 36800, lr = 0.0004571
I0822 16:21:42.355496 12979 solver.cpp:228] Iteration 36900, loss = 0.0598097
I0822 16:21:42.355561 12979 solver.cpp:244]     Train net output #0: loss = 0.0598097 (* 1 = 0.0598097 loss)
I0822 16:21:42.355568 12979 sgd_solver.cpp:106] Iteration 36900, lr = 0.000456497
I0822 16:21:45.069819 12979 solver.cpp:337] Iteration 37000, Testing net (#0)
I0822 16:21:49.103495 12979 solver.cpp:404]     Test net output #0: accuracy = 0.915613
I0822 16:21:49.103525 12979 solver.cpp:404]     Test net output #1: loss = 0.245182 (* 1 = 0.245182 loss)
I0822 16:21:49.114270 12979 solver.cpp:228] Iteration 37000, loss = 0.139103
I0822 16:21:49.114329 12979 solver.cpp:244]     Train net output #0: loss = 0.139103 (* 1 = 0.139103 loss)
I0822 16:21:49.114346 12979 sgd_solver.cpp:106] Iteration 37000, lr = 0.000455897
I0822 16:21:51.859138 12979 solver.cpp:228] Iteration 37100, loss = 0.0588847
I0822 16:21:51.859189 12979 solver.cpp:244]     Train net output #0: loss = 0.0588847 (* 1 = 0.0588847 loss)
I0822 16:21:51.859200 12979 sgd_solver.cpp:106] Iteration 37100, lr = 0.000455298
I0822 16:21:54.600646 12979 solver.cpp:228] Iteration 37200, loss = 0.076656
I0822 16:21:54.600705 12979 solver.cpp:244]     Train net output #0: loss = 0.076656 (* 1 = 0.076656 loss)
I0822 16:21:54.600713 12979 sgd_solver.cpp:106] Iteration 37200, lr = 0.000454701
I0822 16:21:57.342025 12979 solver.cpp:228] Iteration 37300, loss = 0.0178566
I0822 16:21:57.342087 12979 solver.cpp:244]     Train net output #0: loss = 0.0178566 (* 1 = 0.0178566 loss)
I0822 16:21:57.342092 12979 sgd_solver.cpp:106] Iteration 37300, lr = 0.000454105
I0822 16:22:00.080355 12979 solver.cpp:228] Iteration 37400, loss = 0.166705
I0822 16:22:00.080409 12979 solver.cpp:244]     Train net output #0: loss = 0.166705 (* 1 = 0.166705 loss)
I0822 16:22:00.080415 12979 sgd_solver.cpp:106] Iteration 37400, lr = 0.000453512
I0822 16:22:02.790235 12979 solver.cpp:337] Iteration 37500, Testing net (#0)
I0822 16:22:03.428032 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:22:06.834692 12979 solver.cpp:404]     Test net output #0: accuracy = 0.912935
I0822 16:22:06.834758 12979 solver.cpp:404]     Test net output #1: loss = 0.261136 (* 1 = 0.261136 loss)
I0822 16:22:06.843642 12979 solver.cpp:228] Iteration 37500, loss = 0.136445
I0822 16:22:06.843678 12979 solver.cpp:244]     Train net output #0: loss = 0.136445 (* 1 = 0.136445 loss)
I0822 16:22:06.843693 12979 sgd_solver.cpp:106] Iteration 37500, lr = 0.00045292
I0822 16:22:09.579449 12979 solver.cpp:228] Iteration 37600, loss = 0.0523022
I0822 16:22:09.579471 12979 solver.cpp:244]     Train net output #0: loss = 0.0523022 (* 1 = 0.0523022 loss)
I0822 16:22:09.579476 12979 sgd_solver.cpp:106] Iteration 37600, lr = 0.00045233
I0822 16:22:12.321418 12979 solver.cpp:228] Iteration 37700, loss = 0.0460889
I0822 16:22:12.321458 12979 solver.cpp:244]     Train net output #0: loss = 0.0460889 (* 1 = 0.0460889 loss)
I0822 16:22:12.321463 12979 sgd_solver.cpp:106] Iteration 37700, lr = 0.000451742
I0822 16:22:15.062542 12979 solver.cpp:228] Iteration 37800, loss = 0.100707
I0822 16:22:15.062580 12979 solver.cpp:244]     Train net output #0: loss = 0.100707 (* 1 = 0.100707 loss)
I0822 16:22:15.062587 12979 sgd_solver.cpp:106] Iteration 37800, lr = 0.000451156
I0822 16:22:17.806617 12979 solver.cpp:228] Iteration 37900, loss = 0.340178
I0822 16:22:17.806677 12979 solver.cpp:244]     Train net output #0: loss = 0.340178 (* 1 = 0.340178 loss)
I0822 16:22:17.806690 12979 sgd_solver.cpp:106] Iteration 37900, lr = 0.000450571
I0822 16:22:20.518579 12979 solver.cpp:337] Iteration 38000, Testing net (#0)
I0822 16:22:24.881888 12979 solver.cpp:404]     Test net output #0: accuracy = 0.879709
I0822 16:22:24.881927 12979 solver.cpp:404]     Test net output #1: loss = 0.375149 (* 1 = 0.375149 loss)
I0822 16:22:24.897410 12979 solver.cpp:228] Iteration 38000, loss = 0.0724276
I0822 16:22:24.897428 12979 solver.cpp:244]     Train net output #0: loss = 0.0724276 (* 1 = 0.0724276 loss)
I0822 16:22:24.897439 12979 sgd_solver.cpp:106] Iteration 38000, lr = 0.000449989
I0822 16:22:27.641139 12979 solver.cpp:228] Iteration 38100, loss = 0.292557
I0822 16:22:27.641188 12979 solver.cpp:244]     Train net output #0: loss = 0.292557 (* 1 = 0.292557 loss)
I0822 16:22:27.641193 12979 sgd_solver.cpp:106] Iteration 38100, lr = 0.000449408
I0822 16:22:30.383277 12979 solver.cpp:228] Iteration 38200, loss = 0.053532
I0822 16:22:30.383298 12979 solver.cpp:244]     Train net output #0: loss = 0.053532 (* 1 = 0.053532 loss)
I0822 16:22:30.383303 12979 sgd_solver.cpp:106] Iteration 38200, lr = 0.000448828
I0822 16:22:33.123250 12979 solver.cpp:228] Iteration 38300, loss = 0.0685977
I0822 16:22:33.123270 12979 solver.cpp:244]     Train net output #0: loss = 0.0685977 (* 1 = 0.0685977 loss)
I0822 16:22:33.123275 12979 sgd_solver.cpp:106] Iteration 38300, lr = 0.000448251
I0822 16:22:35.866926 12979 solver.cpp:228] Iteration 38400, loss = 0.0350956
I0822 16:22:35.866973 12979 solver.cpp:244]     Train net output #0: loss = 0.0350956 (* 1 = 0.0350956 loss)
I0822 16:22:35.866981 12979 sgd_solver.cpp:106] Iteration 38400, lr = 0.000447675
I0822 16:22:38.582970 12979 solver.cpp:337] Iteration 38500, Testing net (#0)
I0822 16:22:42.584018 12979 solver.cpp:404]     Test net output #0: accuracy = 0.912226
I0822 16:22:42.584085 12979 solver.cpp:404]     Test net output #1: loss = 0.285039 (* 1 = 0.285039 loss)
I0822 16:22:42.592972 12979 solver.cpp:228] Iteration 38500, loss = 0.00631307
I0822 16:22:42.593032 12979 solver.cpp:244]     Train net output #0: loss = 0.00631307 (* 1 = 0.00631307 loss)
I0822 16:22:42.593044 12979 sgd_solver.cpp:106] Iteration 38500, lr = 0.000447101
I0822 16:22:45.342973 12979 solver.cpp:228] Iteration 38600, loss = 0.0925472
I0822 16:22:45.343011 12979 solver.cpp:244]     Train net output #0: loss = 0.0925472 (* 1 = 0.0925472 loss)
I0822 16:22:45.343019 12979 sgd_solver.cpp:106] Iteration 38600, lr = 0.000446529
I0822 16:22:48.077734 12979 solver.cpp:228] Iteration 38700, loss = 0.0894877
I0822 16:22:48.077751 12979 solver.cpp:244]     Train net output #0: loss = 0.0894877 (* 1 = 0.0894877 loss)
I0822 16:22:48.077756 12979 sgd_solver.cpp:106] Iteration 38700, lr = 0.000445958
I0822 16:22:50.811944 12979 solver.cpp:228] Iteration 38800, loss = 0.186161
I0822 16:22:50.811962 12979 solver.cpp:244]     Train net output #0: loss = 0.186161 (* 1 = 0.186161 loss)
I0822 16:22:50.811967 12979 sgd_solver.cpp:106] Iteration 38800, lr = 0.000445389
I0822 16:22:53.544687 12979 solver.cpp:228] Iteration 38900, loss = 0.053301
I0822 16:22:53.544703 12979 solver.cpp:244]     Train net output #0: loss = 0.053301 (* 1 = 0.053301 loss)
I0822 16:22:53.544708 12979 sgd_solver.cpp:106] Iteration 38900, lr = 0.000444822
I0822 16:22:56.251051 12979 solver.cpp:337] Iteration 39000, Testing net (#0)
I0822 16:23:00.451763 12979 solver.cpp:404]     Test net output #0: accuracy = 0.883677
I0822 16:23:00.451829 12979 solver.cpp:404]     Test net output #1: loss = 0.409787 (* 1 = 0.409787 loss)
I0822 16:23:00.460638 12979 solver.cpp:228] Iteration 39000, loss = 0.0355178
I0822 16:23:00.460688 12979 solver.cpp:244]     Train net output #0: loss = 0.0355178 (* 1 = 0.0355178 loss)
I0822 16:23:00.460701 12979 sgd_solver.cpp:106] Iteration 39000, lr = 0.000444256
I0822 16:23:03.208171 12979 solver.cpp:228] Iteration 39100, loss = 0.02175
I0822 16:23:03.208220 12979 solver.cpp:244]     Train net output #0: loss = 0.02175 (* 1 = 0.02175 loss)
I0822 16:23:03.208225 12979 sgd_solver.cpp:106] Iteration 39100, lr = 0.000443692
I0822 16:23:05.949810 12979 solver.cpp:228] Iteration 39200, loss = 0.113922
I0822 16:23:05.949889 12979 solver.cpp:244]     Train net output #0: loss = 0.113922 (* 1 = 0.113922 loss)
I0822 16:23:05.949897 12979 sgd_solver.cpp:106] Iteration 39200, lr = 0.00044313
I0822 16:23:08.685832 12979 solver.cpp:228] Iteration 39300, loss = 0.0389948
I0822 16:23:08.685848 12979 solver.cpp:244]     Train net output #0: loss = 0.0389948 (* 1 = 0.0389948 loss)
I0822 16:23:08.685853 12979 sgd_solver.cpp:106] Iteration 39300, lr = 0.00044257
I0822 16:23:11.427036 12979 solver.cpp:228] Iteration 39400, loss = 0.0105055
I0822 16:23:11.427053 12979 solver.cpp:244]     Train net output #0: loss = 0.0105055 (* 1 = 0.0105055 loss)
I0822 16:23:11.427057 12979 sgd_solver.cpp:106] Iteration 39400, lr = 0.000442011
I0822 16:23:14.138275 12979 solver.cpp:337] Iteration 39500, Testing net (#0)
I0822 16:23:18.259086 12979 solver.cpp:404]     Test net output #0: accuracy = 0.892451
I0822 16:23:18.259141 12979 solver.cpp:404]     Test net output #1: loss = 0.429424 (* 1 = 0.429424 loss)
I0822 16:23:18.268684 12979 solver.cpp:228] Iteration 39500, loss = 0.0209533
I0822 16:23:18.268754 12979 solver.cpp:244]     Train net output #0: loss = 0.0209533 (* 1 = 0.0209533 loss)
I0822 16:23:18.268774 12979 sgd_solver.cpp:106] Iteration 39500, lr = 0.000441453
I0822 16:23:21.017956 12979 solver.cpp:228] Iteration 39600, loss = 0.0460621
I0822 16:23:21.018000 12979 solver.cpp:244]     Train net output #0: loss = 0.0460621 (* 1 = 0.0460621 loss)
I0822 16:23:21.018007 12979 sgd_solver.cpp:106] Iteration 39600, lr = 0.000440898
I0822 16:23:23.765431 12979 solver.cpp:228] Iteration 39700, loss = 0.0712465
I0822 16:23:23.765480 12979 solver.cpp:244]     Train net output #0: loss = 0.0712465 (* 1 = 0.0712465 loss)
I0822 16:23:23.765486 12979 sgd_solver.cpp:106] Iteration 39700, lr = 0.000440344
I0822 16:23:26.509965 12979 solver.cpp:228] Iteration 39800, loss = 0.0531214
I0822 16:23:26.510026 12979 solver.cpp:244]     Train net output #0: loss = 0.0531214 (* 1 = 0.0531214 loss)
I0822 16:23:26.510032 12979 sgd_solver.cpp:106] Iteration 39800, lr = 0.000439791
I0822 16:23:29.260937 12979 solver.cpp:228] Iteration 39900, loss = 0.00666715
I0822 16:23:29.260992 12979 solver.cpp:244]     Train net output #0: loss = 0.00666715 (* 1 = 0.00666715 loss)
I0822 16:23:29.261003 12979 sgd_solver.cpp:106] Iteration 39900, lr = 0.000439241
I0822 16:23:31.985430 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_40000.caffemodel
I0822 16:23:32.634865 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_40000.solverstate
I0822 16:23:32.832651 12979 solver.cpp:337] Iteration 40000, Testing net (#0)
I0822 16:23:36.998090 12979 solver.cpp:404]     Test net output #0: accuracy = 0.871032
I0822 16:23:36.998145 12979 solver.cpp:404]     Test net output #1: loss = 0.530575 (* 1 = 0.530575 loss)
I0822 16:23:37.007695 12979 solver.cpp:228] Iteration 40000, loss = 0.110008
I0822 16:23:37.007753 12979 solver.cpp:244]     Train net output #0: loss = 0.110008 (* 1 = 0.110008 loss)
I0822 16:23:37.007779 12979 sgd_solver.cpp:106] Iteration 40000, lr = 0.000438691
I0822 16:23:39.759892 12979 solver.cpp:228] Iteration 40100, loss = 0.0389386
I0822 16:23:39.759932 12979 solver.cpp:244]     Train net output #0: loss = 0.0389386 (* 1 = 0.0389386 loss)
I0822 16:23:39.759938 12979 sgd_solver.cpp:106] Iteration 40100, lr = 0.000438144
I0822 16:23:42.505457 12979 solver.cpp:228] Iteration 40200, loss = 0.0157826
I0822 16:23:42.505494 12979 solver.cpp:244]     Train net output #0: loss = 0.0157826 (* 1 = 0.0157826 loss)
I0822 16:23:42.505499 12979 sgd_solver.cpp:106] Iteration 40200, lr = 0.000437598
I0822 16:23:45.244987 12979 solver.cpp:228] Iteration 40300, loss = 0.0116794
I0822 16:23:45.245005 12979 solver.cpp:244]     Train net output #0: loss = 0.0116794 (* 1 = 0.0116794 loss)
I0822 16:23:45.245010 12979 sgd_solver.cpp:106] Iteration 40300, lr = 0.000437053
I0822 16:23:47.987944 12979 solver.cpp:228] Iteration 40400, loss = 0.0273277
I0822 16:23:47.988004 12979 solver.cpp:244]     Train net output #0: loss = 0.0273277 (* 1 = 0.0273277 loss)
I0822 16:23:47.988018 12979 sgd_solver.cpp:106] Iteration 40400, lr = 0.000436511
I0822 16:23:50.703445 12979 solver.cpp:337] Iteration 40500, Testing net (#0)
I0822 16:23:54.939196 12979 solver.cpp:404]     Test net output #0: accuracy = 0.906323
I0822 16:23:54.939244 12979 solver.cpp:404]     Test net output #1: loss = 0.359087 (* 1 = 0.359087 loss)
I0822 16:23:54.949275 12979 solver.cpp:228] Iteration 40500, loss = 0.0135772
I0822 16:23:54.949312 12979 solver.cpp:244]     Train net output #0: loss = 0.0135772 (* 1 = 0.0135772 loss)
I0822 16:23:54.949322 12979 sgd_solver.cpp:106] Iteration 40500, lr = 0.000435969
I0822 16:23:57.703651 12979 solver.cpp:228] Iteration 40600, loss = 0.0951521
I0822 16:23:57.703698 12979 solver.cpp:244]     Train net output #0: loss = 0.0951521 (* 1 = 0.0951521 loss)
I0822 16:23:57.703706 12979 sgd_solver.cpp:106] Iteration 40600, lr = 0.00043543
I0822 16:24:00.442359 12979 solver.cpp:228] Iteration 40700, loss = 0.02489
I0822 16:24:00.442378 12979 solver.cpp:244]     Train net output #0: loss = 0.02489 (* 1 = 0.02489 loss)
I0822 16:24:00.442384 12979 sgd_solver.cpp:106] Iteration 40700, lr = 0.000434892
I0822 16:24:03.181560 12979 solver.cpp:228] Iteration 40800, loss = 0.0126363
I0822 16:24:03.181576 12979 solver.cpp:244]     Train net output #0: loss = 0.0126363 (* 1 = 0.0126363 loss)
I0822 16:24:03.181581 12979 sgd_solver.cpp:106] Iteration 40800, lr = 0.000434355
I0822 16:24:05.930652 12979 solver.cpp:228] Iteration 40900, loss = 0.0259743
I0822 16:24:05.930701 12979 solver.cpp:244]     Train net output #0: loss = 0.0259743 (* 1 = 0.0259743 loss)
I0822 16:24:05.930708 12979 sgd_solver.cpp:106] Iteration 40900, lr = 0.00043382
I0822 16:24:08.644098 12979 solver.cpp:337] Iteration 41000, Testing net (#0)
I0822 16:24:12.818194 12979 solver.cpp:404]     Test net output #0: accuracy = 0.836001
I0822 16:24:12.818255 12979 solver.cpp:404]     Test net output #1: loss = 0.673708 (* 1 = 0.673708 loss)
I0822 16:24:12.826863 12979 solver.cpp:228] Iteration 41000, loss = 0.0608302
I0822 16:24:12.826895 12979 solver.cpp:244]     Train net output #0: loss = 0.0608302 (* 1 = 0.0608302 loss)
I0822 16:24:12.826905 12979 sgd_solver.cpp:106] Iteration 41000, lr = 0.000433286
I0822 16:24:15.566303 12979 solver.cpp:228] Iteration 41100, loss = 0.0157692
I0822 16:24:15.566326 12979 solver.cpp:244]     Train net output #0: loss = 0.0157692 (* 1 = 0.0157692 loss)
I0822 16:24:15.566331 12979 sgd_solver.cpp:106] Iteration 41100, lr = 0.000432755
I0822 16:24:18.307253 12979 solver.cpp:228] Iteration 41200, loss = 0.0280224
I0822 16:24:18.307312 12979 solver.cpp:244]     Train net output #0: loss = 0.0280224 (* 1 = 0.0280224 loss)
I0822 16:24:18.307322 12979 sgd_solver.cpp:106] Iteration 41200, lr = 0.000432224
I0822 16:24:21.046316 12979 solver.cpp:228] Iteration 41300, loss = 0.0135858
I0822 16:24:21.046334 12979 solver.cpp:244]     Train net output #0: loss = 0.0135858 (* 1 = 0.0135858 loss)
I0822 16:24:21.046339 12979 sgd_solver.cpp:106] Iteration 41300, lr = 0.000431695
I0822 16:24:23.785943 12979 solver.cpp:228] Iteration 41400, loss = 0.0055631
I0822 16:24:23.785984 12979 solver.cpp:244]     Train net output #0: loss = 0.0055631 (* 1 = 0.0055631 loss)
I0822 16:24:23.785989 12979 sgd_solver.cpp:106] Iteration 41400, lr = 0.000431168
I0822 16:24:26.497467 12979 solver.cpp:337] Iteration 41500, Testing net (#0)
I0822 16:24:30.517859 12979 solver.cpp:404]     Test net output #0: accuracy = 0.90829
I0822 16:24:30.517904 12979 solver.cpp:404]     Test net output #1: loss = 0.381253 (* 1 = 0.381253 loss)
I0822 16:24:30.526803 12979 solver.cpp:228] Iteration 41500, loss = 0.12957
I0822 16:24:30.526847 12979 solver.cpp:244]     Train net output #0: loss = 0.12957 (* 1 = 0.12957 loss)
I0822 16:24:30.526859 12979 sgd_solver.cpp:106] Iteration 41500, lr = 0.000430642
I0822 16:24:33.273515 12979 solver.cpp:228] Iteration 41600, loss = 0.0307035
I0822 16:24:33.273553 12979 solver.cpp:244]     Train net output #0: loss = 0.0307035 (* 1 = 0.0307035 loss)
I0822 16:24:33.273557 12979 sgd_solver.cpp:106] Iteration 41600, lr = 0.000430117
I0822 16:24:36.018808 12979 solver.cpp:228] Iteration 41700, loss = 0.0105399
I0822 16:24:36.018826 12979 solver.cpp:244]     Train net output #0: loss = 0.0105399 (* 1 = 0.0105399 loss)
I0822 16:24:36.018831 12979 sgd_solver.cpp:106] Iteration 41700, lr = 0.000429594
I0822 16:24:38.761725 12979 solver.cpp:228] Iteration 41800, loss = 0.00524079
I0822 16:24:38.761742 12979 solver.cpp:244]     Train net output #0: loss = 0.00524079 (* 1 = 0.00524079 loss)
I0822 16:24:38.761746 12979 sgd_solver.cpp:106] Iteration 41800, lr = 0.000429073
I0822 16:24:41.501899 12979 solver.cpp:228] Iteration 41900, loss = 0.124506
I0822 16:24:41.501916 12979 solver.cpp:244]     Train net output #0: loss = 0.124506 (* 1 = 0.124506 loss)
I0822 16:24:41.501920 12979 sgd_solver.cpp:106] Iteration 41900, lr = 0.000428553
I0822 16:24:44.213546 12979 solver.cpp:337] Iteration 42000, Testing net (#0)
I0822 16:24:48.242945 12979 solver.cpp:404]     Test net output #0: accuracy = 0.892258
I0822 16:24:48.243005 12979 solver.cpp:404]     Test net output #1: loss = 0.446707 (* 1 = 0.446707 loss)
I0822 16:24:48.251750 12979 solver.cpp:228] Iteration 42000, loss = 0.0271694
I0822 16:24:48.251796 12979 solver.cpp:244]     Train net output #0: loss = 0.0271694 (* 1 = 0.0271694 loss)
I0822 16:24:48.251807 12979 sgd_solver.cpp:106] Iteration 42000, lr = 0.000428034
I0822 16:24:50.996196 12979 solver.cpp:228] Iteration 42100, loss = 0.00371241
I0822 16:24:50.996246 12979 solver.cpp:244]     Train net output #0: loss = 0.00371241 (* 1 = 0.00371241 loss)
I0822 16:24:50.996253 12979 sgd_solver.cpp:106] Iteration 42100, lr = 0.000427517
I0822 16:24:53.727404 12979 solver.cpp:228] Iteration 42200, loss = 0.179555
I0822 16:24:53.727422 12979 solver.cpp:244]     Train net output #0: loss = 0.179555 (* 1 = 0.179555 loss)
I0822 16:24:53.727427 12979 sgd_solver.cpp:106] Iteration 42200, lr = 0.000427002
I0822 16:24:56.459678 12979 solver.cpp:228] Iteration 42300, loss = 0.011799
I0822 16:24:56.459695 12979 solver.cpp:244]     Train net output #0: loss = 0.011799 (* 1 = 0.011799 loss)
I0822 16:24:56.459699 12979 sgd_solver.cpp:106] Iteration 42300, lr = 0.000426488
I0822 16:24:59.189498 12979 solver.cpp:228] Iteration 42400, loss = 0.0496645
I0822 16:24:59.189515 12979 solver.cpp:244]     Train net output #0: loss = 0.0496645 (* 1 = 0.0496645 loss)
I0822 16:24:59.189520 12979 sgd_solver.cpp:106] Iteration 42400, lr = 0.000425975
I0822 16:25:01.894511 12979 solver.cpp:337] Iteration 42500, Testing net (#0)
I0822 16:25:05.923599 12979 solver.cpp:404]     Test net output #0: accuracy = 0.887774
I0822 16:25:05.923635 12979 solver.cpp:404]     Test net output #1: loss = 0.480036 (* 1 = 0.480036 loss)
I0822 16:25:05.932327 12979 solver.cpp:228] Iteration 42500, loss = 0.00301066
I0822 16:25:05.932345 12979 solver.cpp:244]     Train net output #0: loss = 0.00301066 (* 1 = 0.00301066 loss)
I0822 16:25:05.932353 12979 sgd_solver.cpp:106] Iteration 42500, lr = 0.000425464
I0822 16:25:08.679502 12979 solver.cpp:228] Iteration 42600, loss = 0.0997643
I0822 16:25:08.679558 12979 solver.cpp:244]     Train net output #0: loss = 0.0997643 (* 1 = 0.0997643 loss)
I0822 16:25:08.679569 12979 sgd_solver.cpp:106] Iteration 42600, lr = 0.000424954
I0822 16:25:11.424731 12979 solver.cpp:228] Iteration 42700, loss = 0.00191188
I0822 16:25:11.424767 12979 solver.cpp:244]     Train net output #0: loss = 0.00191188 (* 1 = 0.00191188 loss)
I0822 16:25:11.424772 12979 sgd_solver.cpp:106] Iteration 42700, lr = 0.000424445
I0822 16:25:14.172653 12979 solver.cpp:228] Iteration 42800, loss = 0.00144171
I0822 16:25:14.172694 12979 solver.cpp:244]     Train net output #0: loss = 0.00144171 (* 1 = 0.00144171 loss)
I0822 16:25:14.172700 12979 sgd_solver.cpp:106] Iteration 42800, lr = 0.000423938
I0822 16:25:16.914054 12979 solver.cpp:228] Iteration 42900, loss = 0.0146903
I0822 16:25:16.914072 12979 solver.cpp:244]     Train net output #0: loss = 0.0146903 (* 1 = 0.0146903 loss)
I0822 16:25:16.914077 12979 sgd_solver.cpp:106] Iteration 42900, lr = 0.000423433
I0822 16:25:19.629421 12979 solver.cpp:337] Iteration 43000, Testing net (#0)
I0822 16:25:19.944864 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:25:23.634503 12979 solver.cpp:404]     Test net output #0: accuracy = 0.903194
I0822 16:25:23.634533 12979 solver.cpp:404]     Test net output #1: loss = 0.423704 (* 1 = 0.423704 loss)
I0822 16:25:23.643266 12979 solver.cpp:228] Iteration 43000, loss = 0.008281
I0822 16:25:23.643295 12979 solver.cpp:244]     Train net output #0: loss = 0.008281 (* 1 = 0.008281 loss)
I0822 16:25:23.643301 12979 sgd_solver.cpp:106] Iteration 43000, lr = 0.000422929
I0822 16:25:26.390033 12979 solver.cpp:228] Iteration 43100, loss = 0.0531748
I0822 16:25:26.390100 12979 solver.cpp:244]     Train net output #0: loss = 0.0531748 (* 1 = 0.0531748 loss)
I0822 16:25:26.390105 12979 sgd_solver.cpp:106] Iteration 43100, lr = 0.000422426
I0822 16:25:29.132781 12979 solver.cpp:228] Iteration 43200, loss = 0.00580496
I0822 16:25:29.132843 12979 solver.cpp:244]     Train net output #0: loss = 0.00580496 (* 1 = 0.00580496 loss)
I0822 16:25:29.132848 12979 sgd_solver.cpp:106] Iteration 43200, lr = 0.000421924
I0822 16:25:31.877787 12979 solver.cpp:228] Iteration 43300, loss = 0.0132933
I0822 16:25:31.877851 12979 solver.cpp:244]     Train net output #0: loss = 0.0132933 (* 1 = 0.0132933 loss)
I0822 16:25:31.877856 12979 sgd_solver.cpp:106] Iteration 43300, lr = 0.000421424
I0822 16:25:34.624655 12979 solver.cpp:228] Iteration 43400, loss = 0.037036
I0822 16:25:34.624718 12979 solver.cpp:244]     Train net output #0: loss = 0.037036 (* 1 = 0.037036 loss)
I0822 16:25:34.624723 12979 sgd_solver.cpp:106] Iteration 43400, lr = 0.000420926
I0822 16:25:37.342783 12979 solver.cpp:337] Iteration 43500, Testing net (#0)
I0822 16:25:41.347731 12979 solver.cpp:404]     Test net output #0: accuracy = 0.921839
I0822 16:25:41.347769 12979 solver.cpp:404]     Test net output #1: loss = 0.349804 (* 1 = 0.349804 loss)
I0822 16:25:41.356492 12979 solver.cpp:228] Iteration 43500, loss = 0.0722002
I0822 16:25:41.356523 12979 solver.cpp:244]     Train net output #0: loss = 0.0722002 (* 1 = 0.0722002 loss)
I0822 16:25:41.356530 12979 sgd_solver.cpp:106] Iteration 43500, lr = 0.000420429
I0822 16:25:44.109995 12979 solver.cpp:228] Iteration 43600, loss = 0.127526
I0822 16:25:44.110049 12979 solver.cpp:244]     Train net output #0: loss = 0.127526 (* 1 = 0.127526 loss)
I0822 16:25:44.110056 12979 sgd_solver.cpp:106] Iteration 43600, lr = 0.000419933
I0822 16:25:46.853289 12979 solver.cpp:228] Iteration 43700, loss = 0.0320362
I0822 16:25:46.853348 12979 solver.cpp:244]     Train net output #0: loss = 0.0320362 (* 1 = 0.0320362 loss)
I0822 16:25:46.853354 12979 sgd_solver.cpp:106] Iteration 43700, lr = 0.000419438
I0822 16:25:49.595361 12979 solver.cpp:228] Iteration 43800, loss = 0.0202541
I0822 16:25:49.595423 12979 solver.cpp:244]     Train net output #0: loss = 0.0202541 (* 1 = 0.0202541 loss)
I0822 16:25:49.595430 12979 sgd_solver.cpp:106] Iteration 43800, lr = 0.000418945
I0822 16:25:52.336244 12979 solver.cpp:228] Iteration 43900, loss = 0.00180209
I0822 16:25:52.336304 12979 solver.cpp:244]     Train net output #0: loss = 0.00180209 (* 1 = 0.00180209 loss)
I0822 16:25:52.336310 12979 sgd_solver.cpp:106] Iteration 43900, lr = 0.000418453
I0822 16:25:55.050781 12979 solver.cpp:337] Iteration 44000, Testing net (#0)
I0822 16:25:59.094650 12979 solver.cpp:404]     Test net output #0: accuracy = 0.862806
I0822 16:25:59.094674 12979 solver.cpp:404]     Test net output #1: loss = 0.667819 (* 1 = 0.667819 loss)
I0822 16:25:59.104074 12979 solver.cpp:228] Iteration 44000, loss = 0.00863888
I0822 16:25:59.104135 12979 solver.cpp:244]     Train net output #0: loss = 0.00863888 (* 1 = 0.00863888 loss)
I0822 16:25:59.104158 12979 sgd_solver.cpp:106] Iteration 44000, lr = 0.000417963
I0822 16:26:01.850932 12979 solver.cpp:228] Iteration 44100, loss = 0.00237272
I0822 16:26:01.851012 12979 solver.cpp:244]     Train net output #0: loss = 0.00237272 (* 1 = 0.00237272 loss)
I0822 16:26:01.851027 12979 sgd_solver.cpp:106] Iteration 44100, lr = 0.000417474
I0822 16:26:04.593777 12979 solver.cpp:228] Iteration 44200, loss = 0.00093231
I0822 16:26:04.593796 12979 solver.cpp:244]     Train net output #0: loss = 0.00093231 (* 1 = 0.00093231 loss)
I0822 16:26:04.593799 12979 sgd_solver.cpp:106] Iteration 44200, lr = 0.000416986
I0822 16:26:07.331233 12979 solver.cpp:228] Iteration 44300, loss = 0.0197946
I0822 16:26:07.331249 12979 solver.cpp:244]     Train net output #0: loss = 0.0197946 (* 1 = 0.0197946 loss)
I0822 16:26:07.331254 12979 sgd_solver.cpp:106] Iteration 44300, lr = 0.000416499
I0822 16:26:10.071593 12979 solver.cpp:228] Iteration 44400, loss = 0.00112893
I0822 16:26:10.071611 12979 solver.cpp:244]     Train net output #0: loss = 0.00112893 (* 1 = 0.00112893 loss)
I0822 16:26:10.071616 12979 sgd_solver.cpp:106] Iteration 44400, lr = 0.000416014
I0822 16:26:12.786119 12979 solver.cpp:337] Iteration 44500, Testing net (#0)
I0822 16:26:16.962523 12979 solver.cpp:404]     Test net output #0: accuracy = 0.917548
I0822 16:26:16.962560 12979 solver.cpp:404]     Test net output #1: loss = 0.390012 (* 1 = 0.390012 loss)
I0822 16:26:16.971295 12979 solver.cpp:228] Iteration 44500, loss = 0.0120796
I0822 16:26:16.971329 12979 solver.cpp:244]     Train net output #0: loss = 0.0120796 (* 1 = 0.0120796 loss)
I0822 16:26:16.971339 12979 sgd_solver.cpp:106] Iteration 44500, lr = 0.00041553
I0822 16:26:19.716519 12979 solver.cpp:228] Iteration 44600, loss = 0.00178919
I0822 16:26:19.716558 12979 solver.cpp:244]     Train net output #0: loss = 0.00178919 (* 1 = 0.00178919 loss)
I0822 16:26:19.716564 12979 sgd_solver.cpp:106] Iteration 44600, lr = 0.000415048
I0822 16:26:22.465226 12979 solver.cpp:228] Iteration 44700, loss = 0.00293069
I0822 16:26:22.465283 12979 solver.cpp:244]     Train net output #0: loss = 0.00293069 (* 1 = 0.00293069 loss)
I0822 16:26:22.465416 12979 sgd_solver.cpp:106] Iteration 44700, lr = 0.000414567
I0822 16:26:25.203716 12979 solver.cpp:228] Iteration 44800, loss = 0.000835185
I0822 16:26:25.203763 12979 solver.cpp:244]     Train net output #0: loss = 0.000835185 (* 1 = 0.000835185 loss)
I0822 16:26:25.203769 12979 sgd_solver.cpp:106] Iteration 44800, lr = 0.000414087
I0822 16:26:27.943094 12979 solver.cpp:228] Iteration 44900, loss = 0.00655673
I0822 16:26:27.943145 12979 solver.cpp:244]     Train net output #0: loss = 0.00655673 (* 1 = 0.00655673 loss)
I0822 16:26:27.943150 12979 sgd_solver.cpp:106] Iteration 44900, lr = 0.000413608
I0822 16:26:30.653195 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_45000.caffemodel
I0822 16:26:31.420660 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_45000.solverstate
I0822 16:26:31.580850 12979 solver.cpp:337] Iteration 45000, Testing net (#0)
I0822 16:26:35.613924 12979 solver.cpp:404]     Test net output #0: accuracy = 0.911323
I0822 16:26:35.613981 12979 solver.cpp:404]     Test net output #1: loss = 0.43088 (* 1 = 0.43088 loss)
I0822 16:26:35.624742 12979 solver.cpp:228] Iteration 45000, loss = 0.00238767
I0822 16:26:35.624794 12979 solver.cpp:244]     Train net output #0: loss = 0.00238767 (* 1 = 0.00238767 loss)
I0822 16:26:35.624812 12979 sgd_solver.cpp:106] Iteration 45000, lr = 0.000413131
I0822 16:26:38.372262 12979 solver.cpp:228] Iteration 45100, loss = 0.000567293
I0822 16:26:38.372299 12979 solver.cpp:244]     Train net output #0: loss = 0.000567293 (* 1 = 0.000567293 loss)
I0822 16:26:38.372304 12979 sgd_solver.cpp:106] Iteration 45100, lr = 0.000412655
I0822 16:26:41.128995 12979 solver.cpp:228] Iteration 45200, loss = 0.00319886
I0822 16:26:41.129048 12979 solver.cpp:244]     Train net output #0: loss = 0.00319886 (* 1 = 0.00319886 loss)
I0822 16:26:41.129058 12979 sgd_solver.cpp:106] Iteration 45200, lr = 0.00041218
I0822 16:26:43.879287 12979 solver.cpp:228] Iteration 45300, loss = 0.00212768
I0822 16:26:43.879339 12979 solver.cpp:244]     Train net output #0: loss = 0.00212768 (* 1 = 0.00212768 loss)
I0822 16:26:43.879348 12979 sgd_solver.cpp:106] Iteration 45300, lr = 0.000411706
I0822 16:26:46.626575 12979 solver.cpp:228] Iteration 45400, loss = 0.00318187
I0822 16:26:46.626611 12979 solver.cpp:244]     Train net output #0: loss = 0.00318187 (* 1 = 0.00318187 loss)
I0822 16:26:46.626617 12979 sgd_solver.cpp:106] Iteration 45400, lr = 0.000411234
I0822 16:26:49.342161 12979 solver.cpp:337] Iteration 45500, Testing net (#0)
I0822 16:26:53.353430 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895871
I0822 16:26:53.353488 12979 solver.cpp:404]     Test net output #1: loss = 0.518798 (* 1 = 0.518798 loss)
I0822 16:26:53.362253 12979 solver.cpp:228] Iteration 45500, loss = 0.00150611
I0822 16:26:53.362282 12979 solver.cpp:244]     Train net output #0: loss = 0.00150611 (* 1 = 0.00150611 loss)
I0822 16:26:53.362293 12979 sgd_solver.cpp:106] Iteration 45500, lr = 0.000410763
I0822 16:26:56.098155 12979 solver.cpp:228] Iteration 45600, loss = 0.000579181
I0822 16:26:56.098204 12979 solver.cpp:244]     Train net output #0: loss = 0.000579181 (* 1 = 0.000579181 loss)
I0822 16:26:56.098209 12979 sgd_solver.cpp:106] Iteration 45600, lr = 0.000410293
I0822 16:26:58.830157 12979 solver.cpp:228] Iteration 45700, loss = 0.000330678
I0822 16:26:58.830174 12979 solver.cpp:244]     Train net output #0: loss = 0.000330678 (* 1 = 0.000330678 loss)
I0822 16:26:58.830183 12979 sgd_solver.cpp:106] Iteration 45700, lr = 0.000409825
I0822 16:27:01.562671 12979 solver.cpp:228] Iteration 45800, loss = 0.00159124
I0822 16:27:01.562690 12979 solver.cpp:244]     Train net output #0: loss = 0.00159124 (* 1 = 0.00159124 loss)
I0822 16:27:01.562693 12979 sgd_solver.cpp:106] Iteration 45800, lr = 0.000409358
I0822 16:27:04.292969 12979 solver.cpp:228] Iteration 45900, loss = 0.000530824
I0822 16:27:04.292986 12979 solver.cpp:244]     Train net output #0: loss = 0.000530824 (* 1 = 0.000530824 loss)
I0822 16:27:04.292999 12979 sgd_solver.cpp:106] Iteration 45900, lr = 0.000408892
I0822 16:27:06.998251 12979 solver.cpp:337] Iteration 46000, Testing net (#0)
I0822 16:27:11.156819 12979 solver.cpp:404]     Test net output #0: accuracy = 0.905194
I0822 16:27:11.156883 12979 solver.cpp:404]     Test net output #1: loss = 0.484086 (* 1 = 0.484086 loss)
I0822 16:27:11.166402 12979 solver.cpp:228] Iteration 46000, loss = 0.000727613
I0822 16:27:11.166466 12979 solver.cpp:244]     Train net output #0: loss = 0.000727613 (* 1 = 0.000727613 loss)
I0822 16:27:11.166484 12979 sgd_solver.cpp:106] Iteration 46000, lr = 0.000408427
I0822 16:27:13.912722 12979 solver.cpp:228] Iteration 46100, loss = 0.00067392
I0822 16:27:13.912760 12979 solver.cpp:244]     Train net output #0: loss = 0.00067392 (* 1 = 0.00067392 loss)
I0822 16:27:13.912765 12979 sgd_solver.cpp:106] Iteration 46100, lr = 0.000407964
I0822 16:27:16.654151 12979 solver.cpp:228] Iteration 46200, loss = 0.00107204
I0822 16:27:16.654170 12979 solver.cpp:244]     Train net output #0: loss = 0.00107204 (* 1 = 0.00107204 loss)
I0822 16:27:16.654175 12979 sgd_solver.cpp:106] Iteration 46200, lr = 0.000407501
I0822 16:27:19.391602 12979 solver.cpp:228] Iteration 46300, loss = 0.00195358
I0822 16:27:19.391620 12979 solver.cpp:244]     Train net output #0: loss = 0.00195358 (* 1 = 0.00195358 loss)
I0822 16:27:19.391625 12979 sgd_solver.cpp:106] Iteration 46300, lr = 0.00040704
I0822 16:27:22.128926 12979 solver.cpp:228] Iteration 46400, loss = 0.000408833
I0822 16:27:22.128945 12979 solver.cpp:244]     Train net output #0: loss = 0.000408833 (* 1 = 0.000408833 loss)
I0822 16:27:22.128949 12979 sgd_solver.cpp:106] Iteration 46400, lr = 0.00040658
I0822 16:27:24.841985 12979 solver.cpp:337] Iteration 46500, Testing net (#0)
I0822 16:27:28.920462 12979 solver.cpp:404]     Test net output #0: accuracy = 0.910129
I0822 16:27:28.920526 12979 solver.cpp:404]     Test net output #1: loss = 0.460612 (* 1 = 0.460612 loss)
I0822 16:27:28.929319 12979 solver.cpp:228] Iteration 46500, loss = 0.00132522
I0822 16:27:28.929361 12979 solver.cpp:244]     Train net output #0: loss = 0.00132522 (* 1 = 0.00132522 loss)
I0822 16:27:28.929373 12979 sgd_solver.cpp:106] Iteration 46500, lr = 0.000406122
I0822 16:27:31.682370 12979 solver.cpp:228] Iteration 46600, loss = 0.00066629
I0822 16:27:31.682415 12979 solver.cpp:244]     Train net output #0: loss = 0.00066629 (* 1 = 0.00066629 loss)
I0822 16:27:31.682422 12979 sgd_solver.cpp:106] Iteration 46600, lr = 0.000405664
I0822 16:27:34.429247 12979 solver.cpp:228] Iteration 46700, loss = 0.00190501
I0822 16:27:34.429293 12979 solver.cpp:244]     Train net output #0: loss = 0.00190501 (* 1 = 0.00190501 loss)
I0822 16:27:34.429298 12979 sgd_solver.cpp:106] Iteration 46700, lr = 0.000405208
I0822 16:27:37.176784 12979 solver.cpp:228] Iteration 46800, loss = 0.000362715
I0822 16:27:37.176854 12979 solver.cpp:244]     Train net output #0: loss = 0.000362715 (* 1 = 0.000362715 loss)
I0822 16:27:37.176867 12979 sgd_solver.cpp:106] Iteration 46800, lr = 0.000404753
I0822 16:27:39.923303 12979 solver.cpp:228] Iteration 46900, loss = 0.00487641
I0822 16:27:39.923321 12979 solver.cpp:244]     Train net output #0: loss = 0.00487641 (* 1 = 0.00487641 loss)
I0822 16:27:39.923324 12979 sgd_solver.cpp:106] Iteration 46900, lr = 0.000404299
I0822 16:27:42.646064 12979 solver.cpp:337] Iteration 47000, Testing net (#0)
I0822 16:27:46.821300 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899451
I0822 16:27:46.821365 12979 solver.cpp:404]     Test net output #1: loss = 0.541017 (* 1 = 0.541017 loss)
I0822 16:27:46.830883 12979 solver.cpp:228] Iteration 47000, loss = 0.000892195
I0822 16:27:46.830946 12979 solver.cpp:244]     Train net output #0: loss = 0.000892195 (* 1 = 0.000892195 loss)
I0822 16:27:46.830971 12979 sgd_solver.cpp:106] Iteration 47000, lr = 0.000403847
I0822 16:27:49.582211 12979 solver.cpp:228] Iteration 47100, loss = 0.000735213
I0822 16:27:49.582244 12979 solver.cpp:244]     Train net output #0: loss = 0.000735213 (* 1 = 0.000735213 loss)
I0822 16:27:49.582250 12979 sgd_solver.cpp:106] Iteration 47100, lr = 0.000403395
I0822 16:27:52.326896 12979 solver.cpp:228] Iteration 47200, loss = 0.000490074
I0822 16:27:52.326943 12979 solver.cpp:244]     Train net output #0: loss = 0.000490074 (* 1 = 0.000490074 loss)
I0822 16:27:52.326949 12979 sgd_solver.cpp:106] Iteration 47200, lr = 0.000402945
I0822 16:27:55.067502 12979 solver.cpp:228] Iteration 47300, loss = 0.000664448
I0822 16:27:55.067564 12979 solver.cpp:244]     Train net output #0: loss = 0.000664448 (* 1 = 0.000664448 loss)
I0822 16:27:55.067569 12979 sgd_solver.cpp:106] Iteration 47300, lr = 0.000402496
I0822 16:27:57.819164 12979 solver.cpp:228] Iteration 47400, loss = 0.00101219
I0822 16:27:57.819222 12979 solver.cpp:244]     Train net output #0: loss = 0.00101219 (* 1 = 0.00101219 loss)
I0822 16:27:57.819232 12979 sgd_solver.cpp:106] Iteration 47400, lr = 0.000402048
I0822 16:28:00.536247 12979 solver.cpp:337] Iteration 47500, Testing net (#0)
I0822 16:28:04.709439 12979 solver.cpp:404]     Test net output #0: accuracy = 0.893645
I0822 16:28:04.709475 12979 solver.cpp:404]     Test net output #1: loss = 0.579524 (* 1 = 0.579524 loss)
I0822 16:28:04.720374 12979 solver.cpp:228] Iteration 47500, loss = 0.000235026
I0822 16:28:04.720449 12979 solver.cpp:244]     Train net output #0: loss = 0.000235026 (* 1 = 0.000235026 loss)
I0822 16:28:04.720465 12979 sgd_solver.cpp:106] Iteration 47500, lr = 0.000401601
I0822 16:28:07.475304 12979 solver.cpp:228] Iteration 47600, loss = 0.00131251
I0822 16:28:07.475353 12979 solver.cpp:244]     Train net output #0: loss = 0.00131251 (* 1 = 0.00131251 loss)
I0822 16:28:07.475363 12979 sgd_solver.cpp:106] Iteration 47600, lr = 0.000401155
I0822 16:28:10.223368 12979 solver.cpp:228] Iteration 47700, loss = 0.000477557
I0822 16:28:10.223413 12979 solver.cpp:244]     Train net output #0: loss = 0.000477557 (* 1 = 0.000477557 loss)
I0822 16:28:10.223418 12979 sgd_solver.cpp:106] Iteration 47700, lr = 0.000400711
I0822 16:28:12.966511 12979 solver.cpp:228] Iteration 47800, loss = 0.000409564
I0822 16:28:12.966545 12979 solver.cpp:244]     Train net output #0: loss = 0.000409564 (* 1 = 0.000409564 loss)
I0822 16:28:12.966552 12979 sgd_solver.cpp:106] Iteration 47800, lr = 0.000400267
I0822 16:28:15.713130 12979 solver.cpp:228] Iteration 47900, loss = 0.000580697
I0822 16:28:15.713207 12979 solver.cpp:244]     Train net output #0: loss = 0.000580697 (* 1 = 0.000580697 loss)
I0822 16:28:15.713222 12979 sgd_solver.cpp:106] Iteration 47900, lr = 0.000399825
I0822 16:28:18.434244 12979 solver.cpp:337] Iteration 48000, Testing net (#0)
I0822 16:28:22.615293 12979 solver.cpp:404]     Test net output #0: accuracy = 0.903
I0822 16:28:22.615326 12979 solver.cpp:404]     Test net output #1: loss = 0.532682 (* 1 = 0.532682 loss)
I0822 16:28:22.624548 12979 solver.cpp:228] Iteration 48000, loss = 0.000183616
I0822 16:28:22.624577 12979 solver.cpp:244]     Train net output #0: loss = 0.000183616 (* 1 = 0.000183616 loss)
I0822 16:28:22.624585 12979 sgd_solver.cpp:106] Iteration 48000, lr = 0.000399384
I0822 16:28:25.366773 12979 solver.cpp:228] Iteration 48100, loss = 0.000285925
I0822 16:28:25.366807 12979 solver.cpp:244]     Train net output #0: loss = 0.000285925 (* 1 = 0.000285925 loss)
I0822 16:28:25.366812 12979 sgd_solver.cpp:106] Iteration 48100, lr = 0.000398944
I0822 16:28:28.103907 12979 solver.cpp:228] Iteration 48200, loss = 0.000161991
I0822 16:28:28.103927 12979 solver.cpp:244]     Train net output #0: loss = 0.000161991 (* 1 = 0.000161991 loss)
I0822 16:28:28.103931 12979 sgd_solver.cpp:106] Iteration 48200, lr = 0.000398505
I0822 16:28:30.843129 12979 solver.cpp:228] Iteration 48300, loss = 0.000385124
I0822 16:28:30.843147 12979 solver.cpp:244]     Train net output #0: loss = 0.000385124 (* 1 = 0.000385124 loss)
I0822 16:28:30.843152 12979 sgd_solver.cpp:106] Iteration 48300, lr = 0.000398068
I0822 16:28:33.580147 12979 solver.cpp:228] Iteration 48400, loss = 0.00191708
I0822 16:28:33.580165 12979 solver.cpp:244]     Train net output #0: loss = 0.00191708 (* 1 = 0.00191708 loss)
I0822 16:28:33.580170 12979 sgd_solver.cpp:106] Iteration 48400, lr = 0.000397631
I0822 16:28:36.289388 12979 solver.cpp:337] Iteration 48500, Testing net (#0)
I0822 16:28:40.308075 12979 solver.cpp:404]     Test net output #0: accuracy = 0.913355
I0822 16:28:40.308104 12979 solver.cpp:404]     Test net output #1: loss = 0.473755 (* 1 = 0.473755 loss)
I0822 16:28:40.316834 12979 solver.cpp:228] Iteration 48500, loss = 0.000215677
I0822 16:28:40.316864 12979 solver.cpp:244]     Train net output #0: loss = 0.000215677 (* 1 = 0.000215677 loss)
I0822 16:28:40.316871 12979 sgd_solver.cpp:106] Iteration 48500, lr = 0.000397196
I0822 16:28:43.061995 12979 solver.cpp:228] Iteration 48600, loss = 0.00229877
I0822 16:28:43.062034 12979 solver.cpp:244]     Train net output #0: loss = 0.00229877 (* 1 = 0.00229877 loss)
I0822 16:28:43.062041 12979 sgd_solver.cpp:106] Iteration 48600, lr = 0.000396761
I0822 16:28:45.802738 12979 solver.cpp:228] Iteration 48700, loss = 0.00112951
I0822 16:28:45.802757 12979 solver.cpp:244]     Train net output #0: loss = 0.00112951 (* 1 = 0.00112951 loss)
I0822 16:28:45.802762 12979 sgd_solver.cpp:106] Iteration 48700, lr = 0.000396328
I0822 16:28:48.539430 12979 solver.cpp:228] Iteration 48800, loss = 0.00101377
I0822 16:28:48.539449 12979 solver.cpp:244]     Train net output #0: loss = 0.00101377 (* 1 = 0.00101377 loss)
I0822 16:28:48.539454 12979 sgd_solver.cpp:106] Iteration 48800, lr = 0.000395896
I0822 16:28:51.283002 12979 solver.cpp:228] Iteration 48900, loss = 0.000341663
I0822 16:28:51.283018 12979 solver.cpp:244]     Train net output #0: loss = 0.000341663 (* 1 = 0.000341663 loss)
I0822 16:28:51.283023 12979 sgd_solver.cpp:106] Iteration 48900, lr = 0.000395465
I0822 16:28:53.993244 12979 solver.cpp:337] Iteration 49000, Testing net (#0)
I0822 16:28:54.889672 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:28:58.021978 12979 solver.cpp:404]     Test net output #0: accuracy = 0.902419
I0822 16:28:58.021996 12979 solver.cpp:404]     Test net output #1: loss = 0.550085 (* 1 = 0.550085 loss)
I0822 16:28:58.031348 12979 solver.cpp:228] Iteration 49000, loss = 0.000378308
I0822 16:28:58.031409 12979 solver.cpp:244]     Train net output #0: loss = 0.000378308 (* 1 = 0.000378308 loss)
I0822 16:28:58.031424 12979 sgd_solver.cpp:106] Iteration 49000, lr = 0.000395035
I0822 16:29:00.770521 12979 solver.cpp:228] Iteration 49100, loss = 0.00023366
I0822 16:29:00.770560 12979 solver.cpp:244]     Train net output #0: loss = 0.00023366 (* 1 = 0.00023366 loss)
I0822 16:29:00.770565 12979 sgd_solver.cpp:106] Iteration 49100, lr = 0.000394606
I0822 16:29:03.503172 12979 solver.cpp:228] Iteration 49200, loss = 0.000199492
I0822 16:29:03.503192 12979 solver.cpp:244]     Train net output #0: loss = 0.000199492 (* 1 = 0.000199492 loss)
I0822 16:29:03.503197 12979 sgd_solver.cpp:106] Iteration 49200, lr = 0.000394178
I0822 16:29:06.234191 12979 solver.cpp:228] Iteration 49300, loss = 0.000206208
I0822 16:29:06.234208 12979 solver.cpp:244]     Train net output #0: loss = 0.000206208 (* 1 = 0.000206208 loss)
I0822 16:29:06.234215 12979 sgd_solver.cpp:106] Iteration 49300, lr = 0.000393752
I0822 16:29:08.966588 12979 solver.cpp:228] Iteration 49400, loss = 0.000191305
I0822 16:29:08.966606 12979 solver.cpp:244]     Train net output #0: loss = 0.000191305 (* 1 = 0.000191305 loss)
I0822 16:29:08.966610 12979 sgd_solver.cpp:106] Iteration 49400, lr = 0.000393326
I0822 16:29:11.671654 12979 solver.cpp:337] Iteration 49500, Testing net (#0)
I0822 16:29:15.671764 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899097
I0822 16:29:15.671818 12979 solver.cpp:404]     Test net output #1: loss = 0.575586 (* 1 = 0.575586 loss)
I0822 16:29:15.681376 12979 solver.cpp:228] Iteration 49500, loss = 0.000175653
I0822 16:29:15.681433 12979 solver.cpp:244]     Train net output #0: loss = 0.000175653 (* 1 = 0.000175653 loss)
I0822 16:29:15.681454 12979 sgd_solver.cpp:106] Iteration 49500, lr = 0.000392902
I0822 16:29:18.429864 12979 solver.cpp:228] Iteration 49600, loss = 0.000264469
I0822 16:29:18.429908 12979 solver.cpp:244]     Train net output #0: loss = 0.000264469 (* 1 = 0.000264469 loss)
I0822 16:29:18.429915 12979 sgd_solver.cpp:106] Iteration 49600, lr = 0.000392478
I0822 16:29:21.185012 12979 solver.cpp:228] Iteration 49700, loss = 0.000913141
I0822 16:29:21.185070 12979 solver.cpp:244]     Train net output #0: loss = 0.000913141 (* 1 = 0.000913141 loss)
I0822 16:29:21.185081 12979 sgd_solver.cpp:106] Iteration 49700, lr = 0.000392056
I0822 16:29:23.926594 12979 solver.cpp:228] Iteration 49800, loss = 0.00112477
I0822 16:29:23.926656 12979 solver.cpp:244]     Train net output #0: loss = 0.00112477 (* 1 = 0.00112477 loss)
I0822 16:29:23.926661 12979 sgd_solver.cpp:106] Iteration 49800, lr = 0.000391635
I0822 16:29:26.672067 12979 solver.cpp:228] Iteration 49900, loss = 0.000153017
I0822 16:29:26.672111 12979 solver.cpp:244]     Train net output #0: loss = 0.000153017 (* 1 = 0.000153017 loss)
I0822 16:29:26.672117 12979 sgd_solver.cpp:106] Iteration 49900, lr = 0.000391214
I0822 16:29:29.389988 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_50000.caffemodel
I0822 16:29:30.317096 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_50000.solverstate
I0822 16:29:30.478412 12979 solver.cpp:337] Iteration 50000, Testing net (#0)
I0822 16:29:34.478747 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895613
I0822 16:29:34.478808 12979 solver.cpp:404]     Test net output #1: loss = 0.599906 (* 1 = 0.599906 loss)
I0822 16:29:34.488374 12979 solver.cpp:228] Iteration 50000, loss = 0.000178989
I0822 16:29:34.488440 12979 solver.cpp:244]     Train net output #0: loss = 0.000178989 (* 1 = 0.000178989 loss)
I0822 16:29:34.488461 12979 sgd_solver.cpp:106] Iteration 50000, lr = 0.000390795
I0822 16:29:37.235502 12979 solver.cpp:228] Iteration 50100, loss = 0.000657552
I0822 16:29:37.235541 12979 solver.cpp:244]     Train net output #0: loss = 0.000657552 (* 1 = 0.000657552 loss)
I0822 16:29:37.235546 12979 sgd_solver.cpp:106] Iteration 50100, lr = 0.000390377
I0822 16:29:39.985348 12979 solver.cpp:228] Iteration 50200, loss = 0.000207077
I0822 16:29:39.985406 12979 solver.cpp:244]     Train net output #0: loss = 0.000207077 (* 1 = 0.000207077 loss)
I0822 16:29:39.985419 12979 sgd_solver.cpp:106] Iteration 50200, lr = 0.00038996
I0822 16:29:42.732218 12979 solver.cpp:228] Iteration 50300, loss = 0.000141363
I0822 16:29:42.732236 12979 solver.cpp:244]     Train net output #0: loss = 0.000141363 (* 1 = 0.000141363 loss)
I0822 16:29:42.732242 12979 sgd_solver.cpp:106] Iteration 50300, lr = 0.000389544
I0822 16:29:45.473980 12979 solver.cpp:228] Iteration 50400, loss = 0.000247608
I0822 16:29:45.474037 12979 solver.cpp:244]     Train net output #0: loss = 0.000247608 (* 1 = 0.000247608 loss)
I0822 16:29:45.474045 12979 sgd_solver.cpp:106] Iteration 50400, lr = 0.000389128
I0822 16:29:48.193436 12979 solver.cpp:337] Iteration 50500, Testing net (#0)
I0822 16:29:52.487036 12979 solver.cpp:404]     Test net output #0: accuracy = 0.911871
I0822 16:29:52.487089 12979 solver.cpp:404]     Test net output #1: loss = 0.501582 (* 1 = 0.501582 loss)
I0822 16:29:52.495955 12979 solver.cpp:228] Iteration 50500, loss = 0.000658904
I0822 16:29:52.495997 12979 solver.cpp:244]     Train net output #0: loss = 0.000658904 (* 1 = 0.000658904 loss)
I0822 16:29:52.496008 12979 sgd_solver.cpp:106] Iteration 50500, lr = 0.000388714
I0822 16:29:55.245057 12979 solver.cpp:228] Iteration 50600, loss = 0.000140807
I0822 16:29:55.245110 12979 solver.cpp:244]     Train net output #0: loss = 0.000140807 (* 1 = 0.000140807 loss)
I0822 16:29:55.245121 12979 sgd_solver.cpp:106] Iteration 50600, lr = 0.000388301
I0822 16:29:57.990172 12979 solver.cpp:228] Iteration 50700, loss = 0.000678134
I0822 16:29:57.990213 12979 solver.cpp:244]     Train net output #0: loss = 0.000678134 (* 1 = 0.000678134 loss)
I0822 16:29:57.990218 12979 sgd_solver.cpp:106] Iteration 50700, lr = 0.000387889
I0822 16:30:00.733355 12979 solver.cpp:228] Iteration 50800, loss = 0.000195437
I0822 16:30:00.733373 12979 solver.cpp:244]     Train net output #0: loss = 0.000195437 (* 1 = 0.000195437 loss)
I0822 16:30:00.733378 12979 sgd_solver.cpp:106] Iteration 50800, lr = 0.000387478
I0822 16:30:03.477375 12979 solver.cpp:228] Iteration 50900, loss = 0.000264821
I0822 16:30:03.477392 12979 solver.cpp:244]     Train net output #0: loss = 0.000264821 (* 1 = 0.000264821 loss)
I0822 16:30:03.477396 12979 sgd_solver.cpp:106] Iteration 50900, lr = 0.000387069
I0822 16:30:06.193050 12979 solver.cpp:337] Iteration 51000, Testing net (#0)
I0822 16:30:10.200099 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896774
I0822 16:30:10.200168 12979 solver.cpp:404]     Test net output #1: loss = 0.602083 (* 1 = 0.602083 loss)
I0822 16:30:10.209735 12979 solver.cpp:228] Iteration 51000, loss = 0.000235806
I0822 16:30:10.209794 12979 solver.cpp:244]     Train net output #0: loss = 0.000235806 (* 1 = 0.000235806 loss)
I0822 16:30:10.209813 12979 sgd_solver.cpp:106] Iteration 51000, lr = 0.00038666
I0822 16:30:12.951901 12979 solver.cpp:228] Iteration 51100, loss = 0.000333285
I0822 16:30:12.951941 12979 solver.cpp:244]     Train net output #0: loss = 0.000333285 (* 1 = 0.000333285 loss)
I0822 16:30:12.951946 12979 sgd_solver.cpp:106] Iteration 51100, lr = 0.000386252
I0822 16:30:15.689963 12979 solver.cpp:228] Iteration 51200, loss = 0.000460922
I0822 16:30:15.689990 12979 solver.cpp:244]     Train net output #0: loss = 0.000460922 (* 1 = 0.000460922 loss)
I0822 16:30:15.689996 12979 sgd_solver.cpp:106] Iteration 51200, lr = 0.000385845
I0822 16:30:18.431437 12979 solver.cpp:228] Iteration 51300, loss = 0.000134146
I0822 16:30:18.431452 12979 solver.cpp:244]     Train net output #0: loss = 0.000134146 (* 1 = 0.000134146 loss)
I0822 16:30:18.431457 12979 sgd_solver.cpp:106] Iteration 51300, lr = 0.000385439
I0822 16:30:21.176422 12979 solver.cpp:228] Iteration 51400, loss = 0.000200893
I0822 16:30:21.176479 12979 solver.cpp:244]     Train net output #0: loss = 0.000200893 (* 1 = 0.000200893 loss)
I0822 16:30:21.176486 12979 sgd_solver.cpp:106] Iteration 51400, lr = 0.000385034
I0822 16:30:23.889554 12979 solver.cpp:337] Iteration 51500, Testing net (#0)
I0822 16:30:27.917048 12979 solver.cpp:404]     Test net output #0: accuracy = 0.894355
I0822 16:30:27.917115 12979 solver.cpp:404]     Test net output #1: loss = 0.619619 (* 1 = 0.619619 loss)
I0822 16:30:27.925851 12979 solver.cpp:228] Iteration 51500, loss = 0.000217466
I0822 16:30:27.925897 12979 solver.cpp:244]     Train net output #0: loss = 0.000217466 (* 1 = 0.000217466 loss)
I0822 16:30:27.925911 12979 sgd_solver.cpp:106] Iteration 51500, lr = 0.00038463
I0822 16:30:30.683141 12979 solver.cpp:228] Iteration 51600, loss = 0.00074808
I0822 16:30:30.683286 12979 solver.cpp:244]     Train net output #0: loss = 0.00074808 (* 1 = 0.00074808 loss)
I0822 16:30:30.683297 12979 sgd_solver.cpp:106] Iteration 51600, lr = 0.000384227
I0822 16:30:33.430285 12979 solver.cpp:228] Iteration 51700, loss = 0.000105671
I0822 16:30:33.430330 12979 solver.cpp:244]     Train net output #0: loss = 0.000105671 (* 1 = 0.000105671 loss)
I0822 16:30:33.430337 12979 sgd_solver.cpp:106] Iteration 51700, lr = 0.000383825
I0822 16:30:36.174566 12979 solver.cpp:228] Iteration 51800, loss = 0.000759412
I0822 16:30:36.174623 12979 solver.cpp:244]     Train net output #0: loss = 0.000759412 (* 1 = 0.000759412 loss)
I0822 16:30:36.174634 12979 sgd_solver.cpp:106] Iteration 51800, lr = 0.000383424
I0822 16:30:38.924039 12979 solver.cpp:228] Iteration 51900, loss = 0.000708192
I0822 16:30:38.924093 12979 solver.cpp:244]     Train net output #0: loss = 0.000708192 (* 1 = 0.000708192 loss)
I0822 16:30:38.924103 12979 sgd_solver.cpp:106] Iteration 51900, lr = 0.000383024
I0822 16:30:41.639839 12979 solver.cpp:337] Iteration 52000, Testing net (#0)
I0822 16:30:45.886741 12979 solver.cpp:404]     Test net output #0: accuracy = 0.891806
I0822 16:30:45.886793 12979 solver.cpp:404]     Test net output #1: loss = 0.6415 (* 1 = 0.6415 loss)
I0822 16:30:45.895685 12979 solver.cpp:228] Iteration 52000, loss = 0.000519656
I0822 16:30:45.895730 12979 solver.cpp:244]     Train net output #0: loss = 0.000519656 (* 1 = 0.000519656 loss)
I0822 16:30:45.895740 12979 sgd_solver.cpp:106] Iteration 52000, lr = 0.000382625
I0822 16:30:48.647318 12979 solver.cpp:228] Iteration 52100, loss = 0.000306586
I0822 16:30:48.647366 12979 solver.cpp:244]     Train net output #0: loss = 0.000306586 (* 1 = 0.000306586 loss)
I0822 16:30:48.647372 12979 sgd_solver.cpp:106] Iteration 52100, lr = 0.000382227
I0822 16:30:51.391336 12979 solver.cpp:228] Iteration 52200, loss = 0.000593037
I0822 16:30:51.391353 12979 solver.cpp:244]     Train net output #0: loss = 0.000593037 (* 1 = 0.000593037 loss)
I0822 16:30:51.391358 12979 sgd_solver.cpp:106] Iteration 52200, lr = 0.00038183
I0822 16:30:54.139397 12979 solver.cpp:228] Iteration 52300, loss = 0.000410661
I0822 16:30:54.139452 12979 solver.cpp:244]     Train net output #0: loss = 0.000410661 (* 1 = 0.000410661 loss)
I0822 16:30:54.139462 12979 sgd_solver.cpp:106] Iteration 52300, lr = 0.000381433
I0822 16:30:56.884390 12979 solver.cpp:228] Iteration 52400, loss = 0.000222553
I0822 16:30:56.884446 12979 solver.cpp:244]     Train net output #0: loss = 0.000222553 (* 1 = 0.000222553 loss)
I0822 16:30:56.884452 12979 sgd_solver.cpp:106] Iteration 52400, lr = 0.000381038
I0822 16:30:59.601402 12979 solver.cpp:337] Iteration 52500, Testing net (#0)
I0822 16:31:03.770720 12979 solver.cpp:404]     Test net output #0: accuracy = 0.909742
I0822 16:31:03.770781 12979 solver.cpp:404]     Test net output #1: loss = 0.524397 (* 1 = 0.524397 loss)
I0822 16:31:03.779495 12979 solver.cpp:228] Iteration 52500, loss = 0.000170405
I0822 16:31:03.779528 12979 solver.cpp:244]     Train net output #0: loss = 0.000170405 (* 1 = 0.000170405 loss)
I0822 16:31:03.779539 12979 sgd_solver.cpp:106] Iteration 52500, lr = 0.000380644
I0822 16:31:06.520664 12979 solver.cpp:228] Iteration 52600, loss = 0.000139654
I0822 16:31:06.520707 12979 solver.cpp:244]     Train net output #0: loss = 0.000139654 (* 1 = 0.000139654 loss)
I0822 16:31:06.520714 12979 sgd_solver.cpp:106] Iteration 52600, lr = 0.000380251
I0822 16:31:09.270756 12979 solver.cpp:228] Iteration 52700, loss = 0.000269659
I0822 16:31:09.270807 12979 solver.cpp:244]     Train net output #0: loss = 0.000269659 (* 1 = 0.000269659 loss)
I0822 16:31:09.270813 12979 sgd_solver.cpp:106] Iteration 52700, lr = 0.000379858
I0822 16:31:12.005363 12979 solver.cpp:228] Iteration 52800, loss = 0.000202592
I0822 16:31:12.005380 12979 solver.cpp:244]     Train net output #0: loss = 0.000202592 (* 1 = 0.000202592 loss)
I0822 16:31:12.005384 12979 sgd_solver.cpp:106] Iteration 52800, lr = 0.000379467
I0822 16:31:14.739657 12979 solver.cpp:228] Iteration 52900, loss = 0.000375639
I0822 16:31:14.739675 12979 solver.cpp:244]     Train net output #0: loss = 0.000375639 (* 1 = 0.000375639 loss)
I0822 16:31:14.739692 12979 sgd_solver.cpp:106] Iteration 52900, lr = 0.000379077
I0822 16:31:17.449565 12979 solver.cpp:337] Iteration 53000, Testing net (#0)
I0822 16:31:21.786339 12979 solver.cpp:404]     Test net output #0: accuracy = 0.894064
I0822 16:31:21.786382 12979 solver.cpp:404]     Test net output #1: loss = 0.631354 (* 1 = 0.631354 loss)
I0822 16:31:21.795223 12979 solver.cpp:228] Iteration 53000, loss = 0.000124218
I0822 16:31:21.795263 12979 solver.cpp:244]     Train net output #0: loss = 0.000124218 (* 1 = 0.000124218 loss)
I0822 16:31:21.795274 12979 sgd_solver.cpp:106] Iteration 53000, lr = 0.000378687
I0822 16:31:24.536533 12979 solver.cpp:228] Iteration 53100, loss = 0.000430733
I0822 16:31:24.536569 12979 solver.cpp:244]     Train net output #0: loss = 0.000430733 (* 1 = 0.000430733 loss)
I0822 16:31:24.536576 12979 sgd_solver.cpp:106] Iteration 53100, lr = 0.000378298
I0822 16:31:27.274942 12979 solver.cpp:228] Iteration 53200, loss = 0.000557596
I0822 16:31:27.274960 12979 solver.cpp:244]     Train net output #0: loss = 0.000557596 (* 1 = 0.000557596 loss)
I0822 16:31:27.274965 12979 sgd_solver.cpp:106] Iteration 53200, lr = 0.000377911
I0822 16:31:30.013552 12979 solver.cpp:228] Iteration 53300, loss = 0.00050056
I0822 16:31:30.013568 12979 solver.cpp:244]     Train net output #0: loss = 0.00050056 (* 1 = 0.00050056 loss)
I0822 16:31:30.013573 12979 sgd_solver.cpp:106] Iteration 53300, lr = 0.000377524
I0822 16:31:32.760361 12979 solver.cpp:228] Iteration 53400, loss = 0.000223395
I0822 16:31:32.760402 12979 solver.cpp:244]     Train net output #0: loss = 0.000223395 (* 1 = 0.000223395 loss)
I0822 16:31:32.760408 12979 sgd_solver.cpp:106] Iteration 53400, lr = 0.000377138
I0822 16:31:35.474387 12979 solver.cpp:337] Iteration 53500, Testing net (#0)
I0822 16:31:39.602231 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898097
I0822 16:31:39.602247 12979 solver.cpp:404]     Test net output #1: loss = 0.606738 (* 1 = 0.606738 loss)
I0822 16:31:39.611651 12979 solver.cpp:228] Iteration 53500, loss = 0.000569375
I0822 16:31:39.611713 12979 solver.cpp:244]     Train net output #0: loss = 0.000569375 (* 1 = 0.000569375 loss)
I0822 16:31:39.611729 12979 sgd_solver.cpp:106] Iteration 53500, lr = 0.000376753
I0822 16:31:42.365082 12979 solver.cpp:228] Iteration 53600, loss = 0.000271908
I0822 16:31:42.365129 12979 solver.cpp:244]     Train net output #0: loss = 0.000271908 (* 1 = 0.000271908 loss)
I0822 16:31:42.365139 12979 sgd_solver.cpp:106] Iteration 53600, lr = 0.000376369
I0822 16:31:45.118839 12979 solver.cpp:228] Iteration 53700, loss = 0.000377413
I0822 16:31:45.118914 12979 solver.cpp:244]     Train net output #0: loss = 0.000377413 (* 1 = 0.000377413 loss)
I0822 16:31:45.118929 12979 sgd_solver.cpp:106] Iteration 53700, lr = 0.000375986
I0822 16:31:47.869076 12979 solver.cpp:228] Iteration 53800, loss = 0.0016114
I0822 16:31:47.869107 12979 solver.cpp:244]     Train net output #0: loss = 0.0016114 (* 1 = 0.0016114 loss)
I0822 16:31:47.869113 12979 sgd_solver.cpp:106] Iteration 53800, lr = 0.000375604
I0822 16:31:50.618472 12979 solver.cpp:228] Iteration 53900, loss = 0.000395677
I0822 16:31:50.618532 12979 solver.cpp:244]     Train net output #0: loss = 0.000395677 (* 1 = 0.000395677 loss)
I0822 16:31:50.618538 12979 sgd_solver.cpp:106] Iteration 53900, lr = 0.000375223
I0822 16:31:53.337530 12979 solver.cpp:337] Iteration 54000, Testing net (#0)
I0822 16:31:57.300222 12979 solver.cpp:404]     Test net output #0: accuracy = 0.888806
I0822 16:31:57.300287 12979 solver.cpp:404]     Test net output #1: loss = 0.675621 (* 1 = 0.675621 loss)
I0822 16:31:57.309132 12979 solver.cpp:228] Iteration 54000, loss = 0.000253388
I0822 16:31:57.309193 12979 solver.cpp:244]     Train net output #0: loss = 0.000253388 (* 1 = 0.000253388 loss)
I0822 16:31:57.309206 12979 sgd_solver.cpp:106] Iteration 54000, lr = 0.000374842
I0822 16:32:00.057839 12979 solver.cpp:228] Iteration 54100, loss = 0.000426387
I0822 16:32:00.057874 12979 solver.cpp:244]     Train net output #0: loss = 0.000426387 (* 1 = 0.000426387 loss)
I0822 16:32:00.057880 12979 sgd_solver.cpp:106] Iteration 54100, lr = 0.000374463
I0822 16:32:02.801945 12979 solver.cpp:228] Iteration 54200, loss = 0.000136246
I0822 16:32:02.802007 12979 solver.cpp:244]     Train net output #0: loss = 0.000136246 (* 1 = 0.000136246 loss)
I0822 16:32:02.802013 12979 sgd_solver.cpp:106] Iteration 54200, lr = 0.000374084
I0822 16:32:05.543284 12979 solver.cpp:228] Iteration 54300, loss = 0.00037311
I0822 16:32:05.543346 12979 solver.cpp:244]     Train net output #0: loss = 0.00037311 (* 1 = 0.00037311 loss)
I0822 16:32:05.543351 12979 sgd_solver.cpp:106] Iteration 54300, lr = 0.000373707
I0822 16:32:08.286751 12979 solver.cpp:228] Iteration 54400, loss = 0.000292712
I0822 16:32:08.286801 12979 solver.cpp:244]     Train net output #0: loss = 0.000292712 (* 1 = 0.000292712 loss)
I0822 16:32:08.286808 12979 sgd_solver.cpp:106] Iteration 54400, lr = 0.00037333
I0822 16:32:11.003262 12979 solver.cpp:337] Iteration 54500, Testing net (#0)
I0822 16:32:11.801870 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:32:15.229717 12979 solver.cpp:404]     Test net output #0: accuracy = 0.907612
I0822 16:32:15.229765 12979 solver.cpp:404]     Test net output #1: loss = 0.55035 (* 1 = 0.55035 loss)
I0822 16:32:15.239235 12979 solver.cpp:228] Iteration 54500, loss = 0.000163695
I0822 16:32:15.239300 12979 solver.cpp:244]     Train net output #0: loss = 0.000163695 (* 1 = 0.000163695 loss)
I0822 16:32:15.239323 12979 sgd_solver.cpp:106] Iteration 54500, lr = 0.000372954
I0822 16:32:17.977265 12979 solver.cpp:228] Iteration 54600, loss = 7.31072e-05
I0822 16:32:17.977306 12979 solver.cpp:244]     Train net output #0: loss = 7.31072e-05 (* 1 = 7.31072e-05 loss)
I0822 16:32:17.977311 12979 sgd_solver.cpp:106] Iteration 54600, lr = 0.000372579
I0822 16:32:20.716353 12979 solver.cpp:228] Iteration 54700, loss = 0.000198531
I0822 16:32:20.716387 12979 solver.cpp:244]     Train net output #0: loss = 0.000198531 (* 1 = 0.000198531 loss)
I0822 16:32:20.716392 12979 sgd_solver.cpp:106] Iteration 54700, lr = 0.000372205
I0822 16:32:23.455616 12979 solver.cpp:228] Iteration 54800, loss = 0.000223431
I0822 16:32:23.455633 12979 solver.cpp:244]     Train net output #0: loss = 0.000223431 (* 1 = 0.000223431 loss)
I0822 16:32:23.455638 12979 sgd_solver.cpp:106] Iteration 54800, lr = 0.000371832
I0822 16:32:26.197443 12979 solver.cpp:228] Iteration 54900, loss = 0.000180555
I0822 16:32:26.197460 12979 solver.cpp:244]     Train net output #0: loss = 0.000180555 (* 1 = 0.000180555 loss)
I0822 16:32:26.197465 12979 sgd_solver.cpp:106] Iteration 54900, lr = 0.000371459
I0822 16:32:28.909271 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_55000.caffemodel
I0822 16:32:29.897483 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_55000.solverstate
I0822 16:32:30.061738 12979 solver.cpp:337] Iteration 55000, Testing net (#0)
I0822 16:32:34.083077 12979 solver.cpp:404]     Test net output #0: accuracy = 0.894935
I0822 16:32:34.083125 12979 solver.cpp:404]     Test net output #1: loss = 0.637239 (* 1 = 0.637239 loss)
I0822 16:32:34.092690 12979 solver.cpp:228] Iteration 55000, loss = 0.000141819
I0822 16:32:34.092756 12979 solver.cpp:244]     Train net output #0: loss = 0.000141819 (* 1 = 0.000141819 loss)
I0822 16:32:34.092778 12979 sgd_solver.cpp:106] Iteration 55000, lr = 0.000371088
I0822 16:32:36.835080 12979 solver.cpp:228] Iteration 55100, loss = 0.000212497
I0822 16:32:36.835129 12979 solver.cpp:244]     Train net output #0: loss = 0.000212497 (* 1 = 0.000212497 loss)
I0822 16:32:36.835135 12979 sgd_solver.cpp:106] Iteration 55100, lr = 0.000370717
I0822 16:32:39.575785 12979 solver.cpp:228] Iteration 55200, loss = 0.000139496
I0822 16:32:39.575845 12979 solver.cpp:244]     Train net output #0: loss = 0.000139496 (* 1 = 0.000139496 loss)
I0822 16:32:39.575850 12979 sgd_solver.cpp:106] Iteration 55200, lr = 0.000370347
I0822 16:32:42.315040 12979 solver.cpp:228] Iteration 55300, loss = 0.000127572
I0822 16:32:42.315099 12979 solver.cpp:244]     Train net output #0: loss = 0.000127572 (* 1 = 0.000127572 loss)
I0822 16:32:42.315105 12979 sgd_solver.cpp:106] Iteration 55300, lr = 0.000369978
I0822 16:32:45.054386 12979 solver.cpp:228] Iteration 55400, loss = 0.000298185
I0822 16:32:45.054451 12979 solver.cpp:244]     Train net output #0: loss = 0.000298185 (* 1 = 0.000298185 loss)
I0822 16:32:45.054456 12979 sgd_solver.cpp:106] Iteration 55400, lr = 0.00036961
I0822 16:32:47.767788 12979 solver.cpp:337] Iteration 55500, Testing net (#0)
I0822 16:32:51.923663 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899
I0822 16:32:51.923715 12979 solver.cpp:404]     Test net output #1: loss = 0.612222 (* 1 = 0.612222 loss)
I0822 16:32:51.932633 12979 solver.cpp:228] Iteration 55500, loss = 0.000279219
I0822 16:32:51.932684 12979 solver.cpp:244]     Train net output #0: loss = 0.000279219 (* 1 = 0.000279219 loss)
I0822 16:32:51.932695 12979 sgd_solver.cpp:106] Iteration 55500, lr = 0.000369243
I0822 16:32:54.684512 12979 solver.cpp:228] Iteration 55600, loss = 0.000244172
I0822 16:32:54.684569 12979 solver.cpp:244]     Train net output #0: loss = 0.000244172 (* 1 = 0.000244172 loss)
I0822 16:32:54.684581 12979 sgd_solver.cpp:106] Iteration 55600, lr = 0.000368877
I0822 16:32:57.433903 12979 solver.cpp:228] Iteration 55700, loss = 0.000295703
I0822 16:32:57.433964 12979 solver.cpp:244]     Train net output #0: loss = 0.000295703 (* 1 = 0.000295703 loss)
I0822 16:32:57.433969 12979 sgd_solver.cpp:106] Iteration 55700, lr = 0.000368511
I0822 16:33:00.180472 12979 solver.cpp:228] Iteration 55800, loss = 0.000259013
I0822 16:33:00.180531 12979 solver.cpp:244]     Train net output #0: loss = 0.000259013 (* 1 = 0.000259013 loss)
I0822 16:33:00.180537 12979 sgd_solver.cpp:106] Iteration 55800, lr = 0.000368146
I0822 16:33:02.924371 12979 solver.cpp:228] Iteration 55900, loss = 0.000175068
I0822 16:33:02.924429 12979 solver.cpp:244]     Train net output #0: loss = 0.000175068 (* 1 = 0.000175068 loss)
I0822 16:33:02.924435 12979 sgd_solver.cpp:106] Iteration 55900, lr = 0.000367783
I0822 16:33:05.648082 12979 solver.cpp:337] Iteration 56000, Testing net (#0)
I0822 16:33:09.981559 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895871
I0822 16:33:09.981597 12979 solver.cpp:404]     Test net output #1: loss = 0.636571 (* 1 = 0.636571 loss)
I0822 16:33:09.990299 12979 solver.cpp:228] Iteration 56000, loss = 0.00026042
I0822 16:33:09.990332 12979 solver.cpp:244]     Train net output #0: loss = 0.00026042 (* 1 = 0.00026042 loss)
I0822 16:33:09.990342 12979 sgd_solver.cpp:106] Iteration 56000, lr = 0.00036742
I0822 16:33:12.725903 12979 solver.cpp:228] Iteration 56100, loss = 0.000150827
I0822 16:33:12.725951 12979 solver.cpp:244]     Train net output #0: loss = 0.000150827 (* 1 = 0.000150827 loss)
I0822 16:33:12.725957 12979 sgd_solver.cpp:106] Iteration 56100, lr = 0.000367057
I0822 16:33:15.469486 12979 solver.cpp:228] Iteration 56200, loss = 0.000308356
I0822 16:33:15.469553 12979 solver.cpp:244]     Train net output #0: loss = 0.000308356 (* 1 = 0.000308356 loss)
I0822 16:33:15.469564 12979 sgd_solver.cpp:106] Iteration 56200, lr = 0.000366696
I0822 16:33:18.208597 12979 solver.cpp:228] Iteration 56300, loss = 0.000278542
I0822 16:33:18.208614 12979 solver.cpp:244]     Train net output #0: loss = 0.000278542 (* 1 = 0.000278542 loss)
I0822 16:33:18.208618 12979 sgd_solver.cpp:106] Iteration 56300, lr = 0.000366336
I0822 16:33:20.941339 12979 solver.cpp:228] Iteration 56400, loss = 0.000197228
I0822 16:33:20.941355 12979 solver.cpp:244]     Train net output #0: loss = 0.000197228 (* 1 = 0.000197228 loss)
I0822 16:33:20.941360 12979 sgd_solver.cpp:106] Iteration 56400, lr = 0.000365976
I0822 16:33:23.647699 12979 solver.cpp:337] Iteration 56500, Testing net (#0)
I0822 16:33:27.686045 12979 solver.cpp:404]     Test net output #0: accuracy = 0.905806
I0822 16:33:27.686103 12979 solver.cpp:404]     Test net output #1: loss = 0.570527 (* 1 = 0.570527 loss)
I0822 16:33:27.695611 12979 solver.cpp:228] Iteration 56500, loss = 0.000128337
I0822 16:33:27.695675 12979 solver.cpp:244]     Train net output #0: loss = 0.000128337 (* 1 = 0.000128337 loss)
I0822 16:33:27.695694 12979 sgd_solver.cpp:106] Iteration 56500, lr = 0.000365617
I0822 16:33:30.443856 12979 solver.cpp:228] Iteration 56600, loss = 0.000209154
I0822 16:33:30.443904 12979 solver.cpp:244]     Train net output #0: loss = 0.000209154 (* 1 = 0.000209154 loss)
I0822 16:33:30.443910 12979 sgd_solver.cpp:106] Iteration 56600, lr = 0.000365259
I0822 16:33:33.194953 12979 solver.cpp:228] Iteration 56700, loss = 0.000127378
I0822 16:33:33.194994 12979 solver.cpp:244]     Train net output #0: loss = 0.000127378 (* 1 = 0.000127378 loss)
I0822 16:33:33.195000 12979 sgd_solver.cpp:106] Iteration 56700, lr = 0.000364902
I0822 16:33:35.944072 12979 solver.cpp:228] Iteration 56800, loss = 0.000182298
I0822 16:33:35.944109 12979 solver.cpp:244]     Train net output #0: loss = 0.000182298 (* 1 = 0.000182298 loss)
I0822 16:33:35.944114 12979 sgd_solver.cpp:106] Iteration 56800, lr = 0.000364545
I0822 16:33:38.685508 12979 solver.cpp:228] Iteration 56900, loss = 0.000100991
I0822 16:33:38.685526 12979 solver.cpp:244]     Train net output #0: loss = 0.000100991 (* 1 = 0.000100991 loss)
I0822 16:33:38.685530 12979 sgd_solver.cpp:106] Iteration 56900, lr = 0.00036419
I0822 16:33:41.399271 12979 solver.cpp:337] Iteration 57000, Testing net (#0)
I0822 16:33:45.407757 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896226
I0822 16:33:45.407814 12979 solver.cpp:404]     Test net output #1: loss = 0.632948 (* 1 = 0.632948 loss)
I0822 16:33:45.418540 12979 solver.cpp:228] Iteration 57000, loss = 0.000184066
I0822 16:33:45.418607 12979 solver.cpp:244]     Train net output #0: loss = 0.000184066 (* 1 = 0.000184066 loss)
I0822 16:33:45.418627 12979 sgd_solver.cpp:106] Iteration 57000, lr = 0.000363835
I0822 16:33:48.169878 12979 solver.cpp:228] Iteration 57100, loss = 0.000298244
I0822 16:33:48.169916 12979 solver.cpp:244]     Train net output #0: loss = 0.000298244 (* 1 = 0.000298244 loss)
I0822 16:33:48.169922 12979 sgd_solver.cpp:106] Iteration 57100, lr = 0.000363481
I0822 16:33:50.916245 12979 solver.cpp:228] Iteration 57200, loss = 0.000144392
I0822 16:33:50.916262 12979 solver.cpp:244]     Train net output #0: loss = 0.000144392 (* 1 = 0.000144392 loss)
I0822 16:33:50.916267 12979 sgd_solver.cpp:106] Iteration 57200, lr = 0.000363128
I0822 16:33:53.657132 12979 solver.cpp:228] Iteration 57300, loss = 0.000231267
I0822 16:33:53.657156 12979 solver.cpp:244]     Train net output #0: loss = 0.000231267 (* 1 = 0.000231267 loss)
I0822 16:33:53.657162 12979 sgd_solver.cpp:106] Iteration 57300, lr = 0.000362775
I0822 16:33:56.399210 12979 solver.cpp:228] Iteration 57400, loss = 0.000355548
I0822 16:33:56.399227 12979 solver.cpp:244]     Train net output #0: loss = 0.000355548 (* 1 = 0.000355548 loss)
I0822 16:33:56.399232 12979 sgd_solver.cpp:106] Iteration 57400, lr = 0.000362424
I0822 16:33:59.115093 12979 solver.cpp:337] Iteration 57500, Testing net (#0)
I0822 16:34:03.353351 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896903
I0822 16:34:03.353386 12979 solver.cpp:404]     Test net output #1: loss = 0.63568 (* 1 = 0.63568 loss)
I0822 16:34:03.362938 12979 solver.cpp:228] Iteration 57500, loss = 0.000195366
I0822 16:34:03.363003 12979 solver.cpp:244]     Train net output #0: loss = 0.000195366 (* 1 = 0.000195366 loss)
I0822 16:34:03.363026 12979 sgd_solver.cpp:106] Iteration 57500, lr = 0.000362073
I0822 16:34:06.115206 12979 solver.cpp:228] Iteration 57600, loss = 0.000235104
I0822 16:34:06.115260 12979 solver.cpp:244]     Train net output #0: loss = 0.000235104 (* 1 = 0.000235104 loss)
I0822 16:34:06.115268 12979 sgd_solver.cpp:106] Iteration 57600, lr = 0.000361723
I0822 16:34:08.865447 12979 solver.cpp:228] Iteration 57700, loss = 0.000106421
I0822 16:34:08.865496 12979 solver.cpp:244]     Train net output #0: loss = 0.000106421 (* 1 = 0.000106421 loss)
I0822 16:34:08.865502 12979 sgd_solver.cpp:106] Iteration 57700, lr = 0.000361374
I0822 16:34:11.615311 12979 solver.cpp:228] Iteration 57800, loss = 0.000428467
I0822 16:34:11.615365 12979 solver.cpp:244]     Train net output #0: loss = 0.000428467 (* 1 = 0.000428467 loss)
I0822 16:34:11.615372 12979 sgd_solver.cpp:106] Iteration 57800, lr = 0.000361025
I0822 16:34:14.359333 12979 solver.cpp:228] Iteration 57900, loss = 0.000326907
I0822 16:34:14.359377 12979 solver.cpp:244]     Train net output #0: loss = 0.000326907 (* 1 = 0.000326907 loss)
I0822 16:34:14.359382 12979 sgd_solver.cpp:106] Iteration 57900, lr = 0.000360678
I0822 16:34:17.076247 12979 solver.cpp:337] Iteration 58000, Testing net (#0)
I0822 16:34:21.114961 12979 solver.cpp:404]     Test net output #0: accuracy = 0.901032
I0822 16:34:21.114990 12979 solver.cpp:404]     Test net output #1: loss = 0.608164 (* 1 = 0.608164 loss)
I0822 16:34:21.124441 12979 solver.cpp:228] Iteration 58000, loss = 7.58098e-05
I0822 16:34:21.124507 12979 solver.cpp:244]     Train net output #0: loss = 7.58098e-05 (* 1 = 7.58098e-05 loss)
I0822 16:34:21.124523 12979 sgd_solver.cpp:106] Iteration 58000, lr = 0.000360331
I0822 16:34:23.869624 12979 solver.cpp:228] Iteration 58100, loss = 0.000126394
I0822 16:34:23.869678 12979 solver.cpp:244]     Train net output #0: loss = 0.000126394 (* 1 = 0.000126394 loss)
I0822 16:34:23.869688 12979 sgd_solver.cpp:106] Iteration 58100, lr = 0.000359985
I0822 16:34:26.615618 12979 solver.cpp:228] Iteration 58200, loss = 0.000306273
I0822 16:34:26.615672 12979 solver.cpp:244]     Train net output #0: loss = 0.000306273 (* 1 = 0.000306273 loss)
I0822 16:34:26.615679 12979 sgd_solver.cpp:106] Iteration 58200, lr = 0.00035964
I0822 16:34:29.357105 12979 solver.cpp:228] Iteration 58300, loss = 0.000198463
I0822 16:34:29.357152 12979 solver.cpp:244]     Train net output #0: loss = 0.000198463 (* 1 = 0.000198463 loss)
I0822 16:34:29.357169 12979 sgd_solver.cpp:106] Iteration 58300, lr = 0.000359295
I0822 16:34:32.108373 12979 solver.cpp:228] Iteration 58400, loss = 0.00144562
I0822 16:34:32.108434 12979 solver.cpp:244]     Train net output #0: loss = 0.00144562 (* 1 = 0.00144562 loss)
I0822 16:34:32.108444 12979 sgd_solver.cpp:106] Iteration 58400, lr = 0.000358951
I0822 16:34:34.827371 12979 solver.cpp:337] Iteration 58500, Testing net (#0)
I0822 16:34:38.851059 12979 solver.cpp:404]     Test net output #0: accuracy = 0.902355
I0822 16:34:38.851117 12979 solver.cpp:404]     Test net output #1: loss = 0.605164 (* 1 = 0.605164 loss)
I0822 16:34:38.860157 12979 solver.cpp:228] Iteration 58500, loss = 7.26225e-05
I0822 16:34:38.860215 12979 solver.cpp:244]     Train net output #0: loss = 7.26225e-05 (* 1 = 7.26225e-05 loss)
I0822 16:34:38.860229 12979 sgd_solver.cpp:106] Iteration 58500, lr = 0.000358608
I0822 16:34:41.601272 12979 solver.cpp:228] Iteration 58600, loss = 0.00033203
I0822 16:34:41.601310 12979 solver.cpp:244]     Train net output #0: loss = 0.00033203 (* 1 = 0.00033203 loss)
I0822 16:34:41.601315 12979 sgd_solver.cpp:106] Iteration 58600, lr = 0.000358266
I0822 16:34:44.342489 12979 solver.cpp:228] Iteration 58700, loss = 0.148934
I0822 16:34:44.342553 12979 solver.cpp:244]     Train net output #0: loss = 0.148934 (* 1 = 0.148934 loss)
I0822 16:34:44.342564 12979 sgd_solver.cpp:106] Iteration 58700, lr = 0.000357925
I0822 16:34:47.086730 12979 solver.cpp:228] Iteration 58800, loss = 0.000110761
I0822 16:34:47.086746 12979 solver.cpp:244]     Train net output #0: loss = 0.000110761 (* 1 = 0.000110761 loss)
I0822 16:34:47.086751 12979 sgd_solver.cpp:106] Iteration 58800, lr = 0.000357584
I0822 16:34:49.825683 12979 solver.cpp:228] Iteration 58900, loss = 0.000134864
I0822 16:34:49.825706 12979 solver.cpp:244]     Train net output #0: loss = 0.000134864 (* 1 = 0.000134864 loss)
I0822 16:34:49.825711 12979 sgd_solver.cpp:106] Iteration 58900, lr = 0.000357244
I0822 16:34:52.537678 12979 solver.cpp:337] Iteration 59000, Testing net (#0)
I0822 16:34:56.680768 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897
I0822 16:34:56.680809 12979 solver.cpp:404]     Test net output #1: loss = 0.639416 (* 1 = 0.639416 loss)
I0822 16:34:56.690366 12979 solver.cpp:228] Iteration 59000, loss = 0.000205333
I0822 16:34:56.690445 12979 solver.cpp:244]     Train net output #0: loss = 0.000205333 (* 1 = 0.000205333 loss)
I0822 16:34:56.690469 12979 sgd_solver.cpp:106] Iteration 59000, lr = 0.000356905
I0822 16:34:59.435968 12979 solver.cpp:228] Iteration 59100, loss = 0.000178113
I0822 16:34:59.436027 12979 solver.cpp:244]     Train net output #0: loss = 0.000178113 (* 1 = 0.000178113 loss)
I0822 16:34:59.436035 12979 sgd_solver.cpp:106] Iteration 59100, lr = 0.000356566
I0822 16:35:02.185087 12979 solver.cpp:228] Iteration 59200, loss = 0.000100514
I0822 16:35:02.185122 12979 solver.cpp:244]     Train net output #0: loss = 0.000100514 (* 1 = 0.000100514 loss)
I0822 16:35:02.185127 12979 sgd_solver.cpp:106] Iteration 59200, lr = 0.000356228
I0822 16:35:04.931982 12979 solver.cpp:228] Iteration 59300, loss = 0.000502321
I0822 16:35:04.932034 12979 solver.cpp:244]     Train net output #0: loss = 0.000502321 (* 1 = 0.000502321 loss)
I0822 16:35:04.932040 12979 sgd_solver.cpp:106] Iteration 59300, lr = 0.000355892
I0822 16:35:07.677597 12979 solver.cpp:228] Iteration 59400, loss = 0.000139154
I0822 16:35:07.677645 12979 solver.cpp:244]     Train net output #0: loss = 0.000139154 (* 1 = 0.000139154 loss)
I0822 16:35:07.677651 12979 sgd_solver.cpp:106] Iteration 59400, lr = 0.000355555
I0822 16:35:10.390946 12979 solver.cpp:337] Iteration 59500, Testing net (#0)
I0822 16:35:14.480365 12979 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0822 16:35:14.480397 12979 solver.cpp:404]     Test net output #1: loss = 0.668057 (* 1 = 0.668057 loss)
I0822 16:35:14.489938 12979 solver.cpp:228] Iteration 59500, loss = 0.000194875
I0822 16:35:14.490005 12979 solver.cpp:244]     Train net output #0: loss = 0.000194875 (* 1 = 0.000194875 loss)
I0822 16:35:14.490027 12979 sgd_solver.cpp:106] Iteration 59500, lr = 0.00035522
I0822 16:35:17.238487 12979 solver.cpp:228] Iteration 59600, loss = 0.000517906
I0822 16:35:17.238538 12979 solver.cpp:244]     Train net output #0: loss = 0.000517906 (* 1 = 0.000517906 loss)
I0822 16:35:17.238548 12979 sgd_solver.cpp:106] Iteration 59600, lr = 0.000354885
I0822 16:35:19.988735 12979 solver.cpp:228] Iteration 59700, loss = 0.000149152
I0822 16:35:19.988801 12979 solver.cpp:244]     Train net output #0: loss = 0.000149152 (* 1 = 0.000149152 loss)
I0822 16:35:19.988812 12979 sgd_solver.cpp:106] Iteration 59700, lr = 0.000354551
I0822 16:35:22.729961 12979 solver.cpp:228] Iteration 59800, loss = 0.000170119
I0822 16:35:22.729998 12979 solver.cpp:244]     Train net output #0: loss = 0.000170119 (* 1 = 0.000170119 loss)
I0822 16:35:22.730003 12979 sgd_solver.cpp:106] Iteration 59800, lr = 0.000354218
I0822 16:35:25.464385 12979 solver.cpp:228] Iteration 59900, loss = 0.000122868
I0822 16:35:25.464402 12979 solver.cpp:244]     Train net output #0: loss = 0.000122868 (* 1 = 0.000122868 loss)
I0822 16:35:25.464407 12979 sgd_solver.cpp:106] Iteration 59900, lr = 0.000353885
I0822 16:35:28.168705 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_60000.caffemodel
I0822 16:35:29.028348 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_60000.solverstate
I0822 16:35:29.187846 12979 solver.cpp:337] Iteration 60000, Testing net (#0)
I0822 16:35:33.174850 12979 solver.cpp:404]     Test net output #0: accuracy = 0.902807
I0822 16:35:33.174880 12979 solver.cpp:404]     Test net output #1: loss = 0.605991 (* 1 = 0.605991 loss)
I0822 16:35:33.184459 12979 solver.cpp:228] Iteration 60000, loss = 0.000143408
I0822 16:35:33.184530 12979 solver.cpp:244]     Train net output #0: loss = 0.000143408 (* 1 = 0.000143408 loss)
I0822 16:35:33.184557 12979 sgd_solver.cpp:106] Iteration 60000, lr = 0.000353553
I0822 16:35:35.925464 12979 solver.cpp:228] Iteration 60100, loss = 0.000301652
I0822 16:35:35.925500 12979 solver.cpp:244]     Train net output #0: loss = 0.000301652 (* 1 = 0.000301652 loss)
I0822 16:35:35.925504 12979 sgd_solver.cpp:106] Iteration 60100, lr = 0.000353222
I0822 16:35:38.663811 12979 solver.cpp:228] Iteration 60200, loss = 0.000304794
I0822 16:35:38.663830 12979 solver.cpp:244]     Train net output #0: loss = 0.000304794 (* 1 = 0.000304794 loss)
I0822 16:35:38.663835 12979 sgd_solver.cpp:106] Iteration 60200, lr = 0.000352892
I0822 16:35:41.405984 12979 solver.cpp:228] Iteration 60300, loss = 0.000142056
I0822 16:35:41.406002 12979 solver.cpp:244]     Train net output #0: loss = 0.000142056 (* 1 = 0.000142056 loss)
I0822 16:35:41.406005 12979 sgd_solver.cpp:106] Iteration 60300, lr = 0.000352562
I0822 16:35:44.143275 12979 solver.cpp:228] Iteration 60400, loss = 0.000520365
I0822 16:35:44.143291 12979 solver.cpp:244]     Train net output #0: loss = 0.000520365 (* 1 = 0.000520365 loss)
I0822 16:35:44.143296 12979 sgd_solver.cpp:106] Iteration 60400, lr = 0.000352233
I0822 16:35:46.855975 12979 solver.cpp:337] Iteration 60500, Testing net (#0)
I0822 16:35:50.849789 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89771
I0822 16:35:50.849823 12979 solver.cpp:404]     Test net output #1: loss = 0.635699 (* 1 = 0.635699 loss)
I0822 16:35:50.858530 12979 solver.cpp:228] Iteration 60500, loss = 0.000192354
I0822 16:35:50.858561 12979 solver.cpp:244]     Train net output #0: loss = 0.000192354 (* 1 = 0.000192354 loss)
I0822 16:35:50.858568 12979 sgd_solver.cpp:106] Iteration 60500, lr = 0.000351905
I0822 16:35:53.603759 12979 solver.cpp:228] Iteration 60600, loss = 0.000198384
I0822 16:35:53.603826 12979 solver.cpp:244]     Train net output #0: loss = 0.000198384 (* 1 = 0.000198384 loss)
I0822 16:35:53.603833 12979 sgd_solver.cpp:106] Iteration 60600, lr = 0.000351578
I0822 16:35:56.348312 12979 solver.cpp:228] Iteration 60700, loss = 0.000191866
I0822 16:35:56.348376 12979 solver.cpp:244]     Train net output #0: loss = 0.000191866 (* 1 = 0.000191866 loss)
I0822 16:35:56.348381 12979 sgd_solver.cpp:106] Iteration 60700, lr = 0.000351251
I0822 16:35:59.092732 12979 solver.cpp:228] Iteration 60800, loss = 0.00028101
I0822 16:35:59.092794 12979 solver.cpp:244]     Train net output #0: loss = 0.00028101 (* 1 = 0.00028101 loss)
I0822 16:35:59.092800 12979 sgd_solver.cpp:106] Iteration 60800, lr = 0.000350925
I0822 16:36:01.835439 12979 solver.cpp:228] Iteration 60900, loss = 0.000138878
I0822 16:36:01.835502 12979 solver.cpp:244]     Train net output #0: loss = 0.000138878 (* 1 = 0.000138878 loss)
I0822 16:36:01.835510 12979 sgd_solver.cpp:106] Iteration 60900, lr = 0.000350599
I0822 16:36:04.553506 12979 solver.cpp:337] Iteration 61000, Testing net (#0)
I0822 16:36:04.664742 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:36:08.567484 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89771
I0822 16:36:08.567523 12979 solver.cpp:404]     Test net output #1: loss = 0.638893 (* 1 = 0.638893 loss)
I0822 16:36:08.576282 12979 solver.cpp:228] Iteration 61000, loss = 0.000114147
I0822 16:36:08.576316 12979 solver.cpp:244]     Train net output #0: loss = 0.000114147 (* 1 = 0.000114147 loss)
I0822 16:36:08.576325 12979 sgd_solver.cpp:106] Iteration 61000, lr = 0.000350275
I0822 16:36:11.321769 12979 solver.cpp:228] Iteration 61100, loss = 0.000134394
I0822 16:36:11.321818 12979 solver.cpp:244]     Train net output #0: loss = 0.000134394 (* 1 = 0.000134394 loss)
I0822 16:36:11.321823 12979 sgd_solver.cpp:106] Iteration 61100, lr = 0.000349951
I0822 16:36:14.064441 12979 solver.cpp:228] Iteration 61200, loss = 0.00021778
I0822 16:36:14.064493 12979 solver.cpp:244]     Train net output #0: loss = 0.00021778 (* 1 = 0.00021778 loss)
I0822 16:36:14.064498 12979 sgd_solver.cpp:106] Iteration 61200, lr = 0.000349627
I0822 16:36:16.813428 12979 solver.cpp:228] Iteration 61300, loss = 0.000166865
I0822 16:36:16.813479 12979 solver.cpp:244]     Train net output #0: loss = 0.000166865 (* 1 = 0.000166865 loss)
I0822 16:36:16.813489 12979 sgd_solver.cpp:106] Iteration 61300, lr = 0.000349305
I0822 16:36:19.556572 12979 solver.cpp:228] Iteration 61400, loss = 0.000128663
I0822 16:36:19.556610 12979 solver.cpp:244]     Train net output #0: loss = 0.000128663 (* 1 = 0.000128663 loss)
I0822 16:36:19.556617 12979 sgd_solver.cpp:106] Iteration 61400, lr = 0.000348983
I0822 16:36:22.273530 12979 solver.cpp:337] Iteration 61500, Testing net (#0)
I0822 16:36:26.320984 12979 solver.cpp:404]     Test net output #0: accuracy = 0.893452
I0822 16:36:26.321002 12979 solver.cpp:404]     Test net output #1: loss = 0.676237 (* 1 = 0.676237 loss)
I0822 16:36:26.330453 12979 solver.cpp:228] Iteration 61500, loss = 0.000203894
I0822 16:36:26.330514 12979 solver.cpp:244]     Train net output #0: loss = 0.000203894 (* 1 = 0.000203894 loss)
I0822 16:36:26.330528 12979 sgd_solver.cpp:106] Iteration 61500, lr = 0.000348662
I0822 16:36:29.083317 12979 solver.cpp:228] Iteration 61600, loss = 0.000127629
I0822 16:36:29.083380 12979 solver.cpp:244]     Train net output #0: loss = 0.000127629 (* 1 = 0.000127629 loss)
I0822 16:36:29.083392 12979 sgd_solver.cpp:106] Iteration 61600, lr = 0.000348341
I0822 16:36:31.825366 12979 solver.cpp:228] Iteration 61700, loss = 0.000124296
I0822 16:36:31.825429 12979 solver.cpp:244]     Train net output #0: loss = 0.000124296 (* 1 = 0.000124296 loss)
I0822 16:36:31.825435 12979 sgd_solver.cpp:106] Iteration 61700, lr = 0.000348021
I0822 16:36:34.567118 12979 solver.cpp:228] Iteration 61800, loss = 0.00084441
I0822 16:36:34.567175 12979 solver.cpp:244]     Train net output #0: loss = 0.00084441 (* 1 = 0.00084441 loss)
I0822 16:36:34.567181 12979 sgd_solver.cpp:106] Iteration 61800, lr = 0.000347702
I0822 16:36:37.312549 12979 solver.cpp:228] Iteration 61900, loss = 0.00063404
I0822 16:36:37.312602 12979 solver.cpp:244]     Train net output #0: loss = 0.00063404 (* 1 = 0.00063404 loss)
I0822 16:36:37.312614 12979 sgd_solver.cpp:106] Iteration 61900, lr = 0.000347384
I0822 16:36:40.026248 12979 solver.cpp:337] Iteration 62000, Testing net (#0)
I0822 16:36:44.019665 12979 solver.cpp:404]     Test net output #0: accuracy = 0.905645
I0822 16:36:44.019707 12979 solver.cpp:404]     Test net output #1: loss = 0.575808 (* 1 = 0.575808 loss)
I0822 16:36:44.028650 12979 solver.cpp:228] Iteration 62000, loss = 0.000145137
I0822 16:36:44.028717 12979 solver.cpp:244]     Train net output #0: loss = 0.000145137 (* 1 = 0.000145137 loss)
I0822 16:36:44.028728 12979 sgd_solver.cpp:106] Iteration 62000, lr = 0.000347066
I0822 16:36:46.769642 12979 solver.cpp:228] Iteration 62100, loss = 0.000166339
I0822 16:36:46.769677 12979 solver.cpp:244]     Train net output #0: loss = 0.000166339 (* 1 = 0.000166339 loss)
I0822 16:36:46.769682 12979 sgd_solver.cpp:106] Iteration 62100, lr = 0.000346749
I0822 16:36:49.508386 12979 solver.cpp:228] Iteration 62200, loss = 0.000222074
I0822 16:36:49.508404 12979 solver.cpp:244]     Train net output #0: loss = 0.000222074 (* 1 = 0.000222074 loss)
I0822 16:36:49.508409 12979 sgd_solver.cpp:106] Iteration 62200, lr = 0.000346433
I0822 16:36:52.244837 12979 solver.cpp:228] Iteration 62300, loss = 0.00034311
I0822 16:36:52.244853 12979 solver.cpp:244]     Train net output #0: loss = 0.00034311 (* 1 = 0.00034311 loss)
I0822 16:36:52.244858 12979 sgd_solver.cpp:106] Iteration 62300, lr = 0.000346117
I0822 16:36:54.985250 12979 solver.cpp:228] Iteration 62400, loss = 0.000138416
I0822 16:36:54.985268 12979 solver.cpp:244]     Train net output #0: loss = 0.000138416 (* 1 = 0.000138416 loss)
I0822 16:36:54.985273 12979 sgd_solver.cpp:106] Iteration 62400, lr = 0.000345802
I0822 16:36:57.694300 12979 solver.cpp:337] Iteration 62500, Testing net (#0)
I0822 16:37:02.001211 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896097
I0822 16:37:02.001282 12979 solver.cpp:404]     Test net output #1: loss = 0.654114 (* 1 = 0.654114 loss)
I0822 16:37:02.010710 12979 solver.cpp:228] Iteration 62500, loss = 0.000131107
I0822 16:37:02.010776 12979 solver.cpp:244]     Train net output #0: loss = 0.000131107 (* 1 = 0.000131107 loss)
I0822 16:37:02.010802 12979 sgd_solver.cpp:106] Iteration 62500, lr = 0.000345487
I0822 16:37:04.752822 12979 solver.cpp:228] Iteration 62600, loss = 0.000320873
I0822 16:37:04.752859 12979 solver.cpp:244]     Train net output #0: loss = 0.000320873 (* 1 = 0.000320873 loss)
I0822 16:37:04.752864 12979 sgd_solver.cpp:106] Iteration 62600, lr = 0.000345174
I0822 16:37:07.496939 12979 solver.cpp:228] Iteration 62700, loss = 0.00029186
I0822 16:37:07.496978 12979 solver.cpp:244]     Train net output #0: loss = 0.00029186 (* 1 = 0.00029186 loss)
I0822 16:37:07.496983 12979 sgd_solver.cpp:106] Iteration 62700, lr = 0.00034486
I0822 16:37:10.240260 12979 solver.cpp:228] Iteration 62800, loss = 0.000162556
I0822 16:37:10.240278 12979 solver.cpp:244]     Train net output #0: loss = 0.000162556 (* 1 = 0.000162556 loss)
I0822 16:37:10.240281 12979 sgd_solver.cpp:106] Iteration 62800, lr = 0.000344548
I0822 16:37:12.991078 12979 solver.cpp:228] Iteration 62900, loss = 0.000153958
I0822 16:37:12.991128 12979 solver.cpp:244]     Train net output #0: loss = 0.000153958 (* 1 = 0.000153958 loss)
I0822 16:37:12.991135 12979 sgd_solver.cpp:106] Iteration 62900, lr = 0.000344236
I0822 16:37:15.708395 12979 solver.cpp:337] Iteration 63000, Testing net (#0)
I0822 16:37:19.780859 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898838
I0822 16:37:19.780915 12979 solver.cpp:404]     Test net output #1: loss = 0.635306 (* 1 = 0.635306 loss)
I0822 16:37:19.789598 12979 solver.cpp:228] Iteration 63000, loss = 0.000131748
I0822 16:37:19.789631 12979 solver.cpp:244]     Train net output #0: loss = 0.000131748 (* 1 = 0.000131748 loss)
I0822 16:37:19.789643 12979 sgd_solver.cpp:106] Iteration 63000, lr = 0.000343925
I0822 16:37:22.524667 12979 solver.cpp:228] Iteration 63100, loss = 0.000115946
I0822 16:37:22.524687 12979 solver.cpp:244]     Train net output #0: loss = 0.000115946 (* 1 = 0.000115946 loss)
I0822 16:37:22.524690 12979 sgd_solver.cpp:106] Iteration 63100, lr = 0.000343615
I0822 16:37:25.257575 12979 solver.cpp:228] Iteration 63200, loss = 9.84837e-05
I0822 16:37:25.257593 12979 solver.cpp:244]     Train net output #0: loss = 9.84837e-05 (* 1 = 9.84837e-05 loss)
I0822 16:37:25.257598 12979 sgd_solver.cpp:106] Iteration 63200, lr = 0.000343305
I0822 16:37:27.989868 12979 solver.cpp:228] Iteration 63300, loss = 0.000286062
I0822 16:37:27.989886 12979 solver.cpp:244]     Train net output #0: loss = 0.000286062 (* 1 = 0.000286062 loss)
I0822 16:37:27.989892 12979 sgd_solver.cpp:106] Iteration 63300, lr = 0.000342996
I0822 16:37:30.720625 12979 solver.cpp:228] Iteration 63400, loss = 0.000144619
I0822 16:37:30.720643 12979 solver.cpp:244]     Train net output #0: loss = 0.000144619 (* 1 = 0.000144619 loss)
I0822 16:37:30.720649 12979 sgd_solver.cpp:106] Iteration 63400, lr = 0.000342687
I0822 16:37:33.424943 12979 solver.cpp:337] Iteration 63500, Testing net (#0)
I0822 16:37:37.489009 12979 solver.cpp:404]     Test net output #0: accuracy = 0.894742
I0822 16:37:37.489071 12979 solver.cpp:404]     Test net output #1: loss = 0.66928 (* 1 = 0.66928 loss)
I0822 16:37:37.498546 12979 solver.cpp:228] Iteration 63500, loss = 0.000147836
I0822 16:37:37.498617 12979 solver.cpp:244]     Train net output #0: loss = 0.000147836 (* 1 = 0.000147836 loss)
I0822 16:37:37.498637 12979 sgd_solver.cpp:106] Iteration 63500, lr = 0.000342379
I0822 16:37:40.246510 12979 solver.cpp:228] Iteration 63600, loss = 0.000200154
I0822 16:37:40.246549 12979 solver.cpp:244]     Train net output #0: loss = 0.000200154 (* 1 = 0.000200154 loss)
I0822 16:37:40.246556 12979 sgd_solver.cpp:106] Iteration 63600, lr = 0.000342072
I0822 16:37:42.994954 12979 solver.cpp:228] Iteration 63700, loss = 0.000122026
I0822 16:37:42.995003 12979 solver.cpp:244]     Train net output #0: loss = 0.000122026 (* 1 = 0.000122026 loss)
I0822 16:37:42.995012 12979 sgd_solver.cpp:106] Iteration 63700, lr = 0.000341766
I0822 16:37:45.745585 12979 solver.cpp:228] Iteration 63800, loss = 0.000140546
I0822 16:37:45.745643 12979 solver.cpp:244]     Train net output #0: loss = 0.000140546 (* 1 = 0.000140546 loss)
I0822 16:37:45.745653 12979 sgd_solver.cpp:106] Iteration 63800, lr = 0.00034146
I0822 16:37:48.488909 12979 solver.cpp:228] Iteration 63900, loss = 0.000151035
I0822 16:37:48.488968 12979 solver.cpp:244]     Train net output #0: loss = 0.000151035 (* 1 = 0.000151035 loss)
I0822 16:37:48.488975 12979 sgd_solver.cpp:106] Iteration 63900, lr = 0.000341154
I0822 16:37:51.205015 12979 solver.cpp:337] Iteration 64000, Testing net (#0)
I0822 16:37:55.320056 12979 solver.cpp:404]     Test net output #0: accuracy = 0.903064
I0822 16:37:55.320109 12979 solver.cpp:404]     Test net output #1: loss = 0.60986 (* 1 = 0.60986 loss)
I0822 16:37:55.332267 12979 solver.cpp:228] Iteration 64000, loss = 0.000168835
I0822 16:37:55.332324 12979 solver.cpp:244]     Train net output #0: loss = 0.000168835 (* 1 = 0.000168835 loss)
I0822 16:37:55.332339 12979 sgd_solver.cpp:106] Iteration 64000, lr = 0.00034085
I0822 16:37:58.082623 12979 solver.cpp:228] Iteration 64100, loss = 0.000122202
I0822 16:37:58.082658 12979 solver.cpp:244]     Train net output #0: loss = 0.000122202 (* 1 = 0.000122202 loss)
I0822 16:37:58.082662 12979 sgd_solver.cpp:106] Iteration 64100, lr = 0.000340546
I0822 16:38:00.833359 12979 solver.cpp:228] Iteration 64200, loss = 6.25404e-05
I0822 16:38:00.833408 12979 solver.cpp:244]     Train net output #0: loss = 6.25404e-05 (* 1 = 6.25404e-05 loss)
I0822 16:38:00.833418 12979 sgd_solver.cpp:106] Iteration 64200, lr = 0.000340242
I0822 16:38:03.579610 12979 solver.cpp:228] Iteration 64300, loss = 0.000330322
I0822 16:38:03.579648 12979 solver.cpp:244]     Train net output #0: loss = 0.000330322 (* 1 = 0.000330322 loss)
I0822 16:38:03.579653 12979 sgd_solver.cpp:106] Iteration 64300, lr = 0.00033994
I0822 16:38:06.325525 12979 solver.cpp:228] Iteration 64400, loss = 0.000156814
I0822 16:38:06.325543 12979 solver.cpp:244]     Train net output #0: loss = 0.000156814 (* 1 = 0.000156814 loss)
I0822 16:38:06.325548 12979 sgd_solver.cpp:106] Iteration 64400, lr = 0.000339638
I0822 16:38:09.044930 12979 solver.cpp:337] Iteration 64500, Testing net (#0)
I0822 16:38:13.101801 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897645
I0822 16:38:13.101857 12979 solver.cpp:404]     Test net output #1: loss = 0.652729 (* 1 = 0.652729 loss)
I0822 16:38:13.110702 12979 solver.cpp:228] Iteration 64500, loss = 0.000116774
I0822 16:38:13.110746 12979 solver.cpp:244]     Train net output #0: loss = 0.000116774 (* 1 = 0.000116774 loss)
I0822 16:38:13.110757 12979 sgd_solver.cpp:106] Iteration 64500, lr = 0.000339336
I0822 16:38:15.862767 12979 solver.cpp:228] Iteration 64600, loss = 0.000109775
I0822 16:38:15.862805 12979 solver.cpp:244]     Train net output #0: loss = 0.000109775 (* 1 = 0.000109775 loss)
I0822 16:38:15.862810 12979 sgd_solver.cpp:106] Iteration 64600, lr = 0.000339035
I0822 16:38:18.604758 12979 solver.cpp:228] Iteration 64700, loss = 0.000102576
I0822 16:38:18.604776 12979 solver.cpp:244]     Train net output #0: loss = 0.000102576 (* 1 = 0.000102576 loss)
I0822 16:38:18.604780 12979 sgd_solver.cpp:106] Iteration 64700, lr = 0.000338735
I0822 16:38:21.347381 12979 solver.cpp:228] Iteration 64800, loss = 0.000155891
I0822 16:38:21.347398 12979 solver.cpp:244]     Train net output #0: loss = 0.000155891 (* 1 = 0.000155891 loss)
I0822 16:38:21.347403 12979 sgd_solver.cpp:106] Iteration 64800, lr = 0.000338435
I0822 16:38:24.094867 12979 solver.cpp:228] Iteration 64900, loss = 9.89004e-05
I0822 16:38:24.094918 12979 solver.cpp:244]     Train net output #0: loss = 9.89004e-05 (* 1 = 9.89004e-05 loss)
I0822 16:38:24.094928 12979 sgd_solver.cpp:106] Iteration 64900, lr = 0.000338136
I0822 16:38:26.814168 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_65000.caffemodel
I0822 16:38:27.552218 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_65000.solverstate
I0822 16:38:27.748565 12979 solver.cpp:337] Iteration 65000, Testing net (#0)
I0822 16:38:31.977588 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897516
I0822 16:38:31.977640 12979 solver.cpp:404]     Test net output #1: loss = 0.657714 (* 1 = 0.657714 loss)
I0822 16:38:31.986538 12979 solver.cpp:228] Iteration 65000, loss = 0.000104758
I0822 16:38:31.986580 12979 solver.cpp:244]     Train net output #0: loss = 0.000104758 (* 1 = 0.000104758 loss)
I0822 16:38:31.986591 12979 sgd_solver.cpp:106] Iteration 65000, lr = 0.000337838
I0822 16:38:34.726958 12979 solver.cpp:228] Iteration 65100, loss = 0.000120418
I0822 16:38:34.726995 12979 solver.cpp:244]     Train net output #0: loss = 0.000120418 (* 1 = 0.000120418 loss)
I0822 16:38:34.727001 12979 sgd_solver.cpp:106] Iteration 65100, lr = 0.00033754
I0822 16:38:37.465622 12979 solver.cpp:228] Iteration 65200, loss = 0.00011423
I0822 16:38:37.465639 12979 solver.cpp:244]     Train net output #0: loss = 0.00011423 (* 1 = 0.00011423 loss)
I0822 16:38:37.465644 12979 sgd_solver.cpp:106] Iteration 65200, lr = 0.000337243
I0822 16:38:40.204910 12979 solver.cpp:228] Iteration 65300, loss = 7.61926e-05
I0822 16:38:40.204926 12979 solver.cpp:244]     Train net output #0: loss = 7.61926e-05 (* 1 = 7.61926e-05 loss)
I0822 16:38:40.204931 12979 sgd_solver.cpp:106] Iteration 65300, lr = 0.000336946
I0822 16:38:42.942492 12979 solver.cpp:228] Iteration 65400, loss = 0.000108873
I0822 16:38:42.942509 12979 solver.cpp:244]     Train net output #0: loss = 0.000108873 (* 1 = 0.000108873 loss)
I0822 16:38:42.942514 12979 sgd_solver.cpp:106] Iteration 65400, lr = 0.00033665
I0822 16:38:45.652341 12979 solver.cpp:337] Iteration 65500, Testing net (#0)
I0822 16:38:49.809823 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897903
I0822 16:38:49.809880 12979 solver.cpp:404]     Test net output #1: loss = 0.6535 (* 1 = 0.6535 loss)
I0822 16:38:49.818557 12979 solver.cpp:228] Iteration 65500, loss = 8.12021e-05
I0822 16:38:49.818577 12979 solver.cpp:244]     Train net output #0: loss = 8.12021e-05 (* 1 = 8.12021e-05 loss)
I0822 16:38:49.818598 12979 sgd_solver.cpp:106] Iteration 65500, lr = 0.000336355
I0822 16:38:52.554741 12979 solver.cpp:228] Iteration 65600, loss = 0.00012126
I0822 16:38:52.554760 12979 solver.cpp:244]     Train net output #0: loss = 0.00012126 (* 1 = 0.00012126 loss)
I0822 16:38:52.554765 12979 sgd_solver.cpp:106] Iteration 65600, lr = 0.00033606
I0822 16:38:55.292814 12979 solver.cpp:228] Iteration 65700, loss = 8.60913e-05
I0822 16:38:55.292831 12979 solver.cpp:244]     Train net output #0: loss = 8.60913e-05 (* 1 = 8.60913e-05 loss)
I0822 16:38:55.292835 12979 sgd_solver.cpp:106] Iteration 65700, lr = 0.000335766
I0822 16:38:58.038601 12979 solver.cpp:228] Iteration 65800, loss = 7.90403e-05
I0822 16:38:58.038673 12979 solver.cpp:244]     Train net output #0: loss = 7.90403e-05 (* 1 = 7.90403e-05 loss)
I0822 16:38:58.038686 12979 sgd_solver.cpp:106] Iteration 65800, lr = 0.000335473
I0822 16:39:00.779705 12979 solver.cpp:228] Iteration 65900, loss = 0.000101597
I0822 16:39:00.779721 12979 solver.cpp:244]     Train net output #0: loss = 0.000101597 (* 1 = 0.000101597 loss)
I0822 16:39:00.779726 12979 sgd_solver.cpp:106] Iteration 65900, lr = 0.00033518
I0822 16:39:03.491729 12979 solver.cpp:337] Iteration 66000, Testing net (#0)
I0822 16:39:07.511359 12979 solver.cpp:404]     Test net output #0: accuracy = 0.900904
I0822 16:39:07.511422 12979 solver.cpp:404]     Test net output #1: loss = 0.634028 (* 1 = 0.634028 loss)
I0822 16:39:07.521015 12979 solver.cpp:228] Iteration 66000, loss = 0.000128524
I0822 16:39:07.521072 12979 solver.cpp:244]     Train net output #0: loss = 0.000128524 (* 1 = 0.000128524 loss)
I0822 16:39:07.521092 12979 sgd_solver.cpp:106] Iteration 66000, lr = 0.000334887
I0822 16:39:10.262215 12979 solver.cpp:228] Iteration 66100, loss = 0.0001037
I0822 16:39:10.262253 12979 solver.cpp:244]     Train net output #0: loss = 0.0001037 (* 1 = 0.0001037 loss)
I0822 16:39:10.262259 12979 sgd_solver.cpp:106] Iteration 66100, lr = 0.000334596
I0822 16:39:13.001555 12979 solver.cpp:228] Iteration 66200, loss = 0.000184992
I0822 16:39:13.001574 12979 solver.cpp:244]     Train net output #0: loss = 0.000184992 (* 1 = 0.000184992 loss)
I0822 16:39:13.001579 12979 sgd_solver.cpp:106] Iteration 66200, lr = 0.000334304
I0822 16:39:15.741345 12979 solver.cpp:228] Iteration 66300, loss = 8.8381e-05
I0822 16:39:15.741363 12979 solver.cpp:244]     Train net output #0: loss = 8.8381e-05 (* 1 = 8.8381e-05 loss)
I0822 16:39:15.741366 12979 sgd_solver.cpp:106] Iteration 66300, lr = 0.000334014
I0822 16:39:18.492261 12979 solver.cpp:228] Iteration 66400, loss = 5.92248e-05
I0822 16:39:18.492317 12979 solver.cpp:244]     Train net output #0: loss = 5.92248e-05 (* 1 = 5.92248e-05 loss)
I0822 16:39:18.492329 12979 sgd_solver.cpp:106] Iteration 66400, lr = 0.000333724
I0822 16:39:21.212486 12979 solver.cpp:337] Iteration 66500, Testing net (#0)
I0822 16:39:25.207350 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89771
I0822 16:39:25.207407 12979 solver.cpp:404]     Test net output #1: loss = 0.658956 (* 1 = 0.658956 loss)
I0822 16:39:25.216984 12979 solver.cpp:228] Iteration 66500, loss = 0.00028727
I0822 16:39:25.217046 12979 solver.cpp:244]     Train net output #0: loss = 0.00028727 (* 1 = 0.00028727 loss)
I0822 16:39:25.217072 12979 sgd_solver.cpp:106] Iteration 66500, lr = 0.000333434
I0822 16:39:27.949065 12979 solver.cpp:228] Iteration 66600, loss = 0.000109894
I0822 16:39:27.949100 12979 solver.cpp:244]     Train net output #0: loss = 0.000109894 (* 1 = 0.000109894 loss)
I0822 16:39:27.949105 12979 sgd_solver.cpp:106] Iteration 66600, lr = 0.000333146
I0822 16:39:30.680483 12979 solver.cpp:228] Iteration 66700, loss = 0.000159487
I0822 16:39:30.680500 12979 solver.cpp:244]     Train net output #0: loss = 0.000159487 (* 1 = 0.000159487 loss)
I0822 16:39:30.680505 12979 sgd_solver.cpp:106] Iteration 66700, lr = 0.000332857
I0822 16:39:33.414837 12979 solver.cpp:228] Iteration 66800, loss = 0.000158132
I0822 16:39:33.414891 12979 solver.cpp:244]     Train net output #0: loss = 0.000158132 (* 1 = 0.000158132 loss)
I0822 16:39:33.414903 12979 sgd_solver.cpp:106] Iteration 66800, lr = 0.00033257
I0822 16:39:36.155125 12979 solver.cpp:228] Iteration 66900, loss = 7.28057e-05
I0822 16:39:36.155164 12979 solver.cpp:244]     Train net output #0: loss = 7.28057e-05 (* 1 = 7.28057e-05 loss)
I0822 16:39:36.155170 12979 sgd_solver.cpp:106] Iteration 66900, lr = 0.000332283
I0822 16:39:38.878197 12979 solver.cpp:337] Iteration 67000, Testing net (#0)
I0822 16:39:40.191365 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:39:43.152168 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896
I0822 16:39:43.152192 12979 solver.cpp:404]     Test net output #1: loss = 0.679541 (* 1 = 0.679541 loss)
I0822 16:39:43.160879 12979 solver.cpp:228] Iteration 67000, loss = 0.000444681
I0822 16:39:43.160899 12979 solver.cpp:244]     Train net output #0: loss = 0.000444681 (* 1 = 0.000444681 loss)
I0822 16:39:43.160908 12979 sgd_solver.cpp:106] Iteration 67000, lr = 0.000331996
I0822 16:39:45.906355 12979 solver.cpp:228] Iteration 67100, loss = 0.000170333
I0822 16:39:45.906393 12979 solver.cpp:244]     Train net output #0: loss = 0.000170333 (* 1 = 0.000170333 loss)
I0822 16:39:45.906397 12979 sgd_solver.cpp:106] Iteration 67100, lr = 0.00033171
I0822 16:39:48.649610 12979 solver.cpp:228] Iteration 67200, loss = 4.3963e-05
I0822 16:39:48.649628 12979 solver.cpp:244]     Train net output #0: loss = 4.3963e-05 (* 1 = 4.3963e-05 loss)
I0822 16:39:48.649633 12979 sgd_solver.cpp:106] Iteration 67200, lr = 0.000331425
I0822 16:39:51.389874 12979 solver.cpp:228] Iteration 67300, loss = 0.0001938
I0822 16:39:51.389890 12979 solver.cpp:244]     Train net output #0: loss = 0.0001938 (* 1 = 0.0001938 loss)
I0822 16:39:51.389895 12979 sgd_solver.cpp:106] Iteration 67300, lr = 0.00033114
I0822 16:39:54.129019 12979 solver.cpp:228] Iteration 67400, loss = 5.35175e-05
I0822 16:39:54.129039 12979 solver.cpp:244]     Train net output #0: loss = 5.35175e-05 (* 1 = 5.35175e-05 loss)
I0822 16:39:54.129043 12979 sgd_solver.cpp:106] Iteration 67400, lr = 0.000330856
I0822 16:39:56.841725 12979 solver.cpp:337] Iteration 67500, Testing net (#0)
I0822 16:40:00.806879 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899613
I0822 16:40:00.806941 12979 solver.cpp:404]     Test net output #1: loss = 0.649696 (* 1 = 0.649696 loss)
I0822 16:40:00.816534 12979 solver.cpp:228] Iteration 67500, loss = 8.00909e-05
I0822 16:40:00.816596 12979 solver.cpp:244]     Train net output #0: loss = 8.00909e-05 (* 1 = 8.00909e-05 loss)
I0822 16:40:00.816619 12979 sgd_solver.cpp:106] Iteration 67500, lr = 0.000330572
I0822 16:40:03.561138 12979 solver.cpp:228] Iteration 67600, loss = 0.000153008
I0822 16:40:03.561182 12979 solver.cpp:244]     Train net output #0: loss = 0.000153008 (* 1 = 0.000153008 loss)
I0822 16:40:03.561187 12979 sgd_solver.cpp:106] Iteration 67600, lr = 0.000330289
I0822 16:40:06.301507 12979 solver.cpp:228] Iteration 67700, loss = 0.000138755
I0822 16:40:06.301525 12979 solver.cpp:244]     Train net output #0: loss = 0.000138755 (* 1 = 0.000138755 loss)
I0822 16:40:06.301529 12979 sgd_solver.cpp:106] Iteration 67700, lr = 0.000330007
I0822 16:40:09.045122 12979 solver.cpp:228] Iteration 67800, loss = 0.00020927
I0822 16:40:09.045140 12979 solver.cpp:244]     Train net output #0: loss = 0.00020927 (* 1 = 0.00020927 loss)
I0822 16:40:09.045145 12979 sgd_solver.cpp:106] Iteration 67800, lr = 0.000329725
I0822 16:40:11.786036 12979 solver.cpp:228] Iteration 67900, loss = 0.000149311
I0822 16:40:11.786054 12979 solver.cpp:244]     Train net output #0: loss = 0.000149311 (* 1 = 0.000149311 loss)
I0822 16:40:11.786059 12979 sgd_solver.cpp:106] Iteration 67900, lr = 0.000329443
I0822 16:40:14.501227 12979 solver.cpp:337] Iteration 68000, Testing net (#0)
I0822 16:40:18.487769 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899516
I0822 16:40:18.487829 12979 solver.cpp:404]     Test net output #1: loss = 0.653752 (* 1 = 0.653752 loss)
I0822 16:40:18.496646 12979 solver.cpp:228] Iteration 68000, loss = 7.0239e-05
I0822 16:40:18.496713 12979 solver.cpp:244]     Train net output #0: loss = 7.0239e-05 (* 1 = 7.0239e-05 loss)
I0822 16:40:18.496727 12979 sgd_solver.cpp:106] Iteration 68000, lr = 0.000329163
I0822 16:40:21.244899 12979 solver.cpp:228] Iteration 68100, loss = 0.000398826
I0822 16:40:21.244938 12979 solver.cpp:244]     Train net output #0: loss = 0.000398826 (* 1 = 0.000398826 loss)
I0822 16:40:21.244943 12979 sgd_solver.cpp:106] Iteration 68100, lr = 0.000328882
I0822 16:40:23.987476 12979 solver.cpp:228] Iteration 68200, loss = 0.000110136
I0822 16:40:23.987493 12979 solver.cpp:244]     Train net output #0: loss = 0.000110136 (* 1 = 0.000110136 loss)
I0822 16:40:23.987510 12979 sgd_solver.cpp:106] Iteration 68200, lr = 0.000328603
I0822 16:40:26.728384 12979 solver.cpp:228] Iteration 68300, loss = 0.000100779
I0822 16:40:26.728402 12979 solver.cpp:244]     Train net output #0: loss = 0.000100779 (* 1 = 0.000100779 loss)
I0822 16:40:26.728407 12979 sgd_solver.cpp:106] Iteration 68300, lr = 0.000328324
I0822 16:40:29.468238 12979 solver.cpp:228] Iteration 68400, loss = 0.000129504
I0822 16:40:29.468255 12979 solver.cpp:244]     Train net output #0: loss = 0.000129504 (* 1 = 0.000129504 loss)
I0822 16:40:29.468260 12979 sgd_solver.cpp:106] Iteration 68400, lr = 0.000328045
I0822 16:40:32.188916 12979 solver.cpp:337] Iteration 68500, Testing net (#0)
I0822 16:40:36.249457 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89858
I0822 16:40:36.249507 12979 solver.cpp:404]     Test net output #1: loss = 0.661007 (* 1 = 0.661007 loss)
I0822 16:40:36.258329 12979 solver.cpp:228] Iteration 68500, loss = 0.000120961
I0822 16:40:36.258368 12979 solver.cpp:244]     Train net output #0: loss = 0.000120961 (* 1 = 0.000120961 loss)
I0822 16:40:36.258380 12979 sgd_solver.cpp:106] Iteration 68500, lr = 0.000327767
I0822 16:40:39.001343 12979 solver.cpp:228] Iteration 68600, loss = 5.73917e-05
I0822 16:40:39.001375 12979 solver.cpp:244]     Train net output #0: loss = 5.73917e-05 (* 1 = 5.73917e-05 loss)
I0822 16:40:39.001380 12979 sgd_solver.cpp:106] Iteration 68600, lr = 0.000327489
I0822 16:40:41.754566 12979 solver.cpp:228] Iteration 68700, loss = 9.46121e-05
I0822 16:40:41.754585 12979 solver.cpp:244]     Train net output #0: loss = 9.46121e-05 (* 1 = 9.46121e-05 loss)
I0822 16:40:41.754590 12979 sgd_solver.cpp:106] Iteration 68700, lr = 0.000327212
I0822 16:40:44.514766 12979 solver.cpp:228] Iteration 68800, loss = 8.10883e-05
I0822 16:40:44.514783 12979 solver.cpp:244]     Train net output #0: loss = 8.10883e-05 (* 1 = 8.10883e-05 loss)
I0822 16:40:44.514788 12979 sgd_solver.cpp:106] Iteration 68800, lr = 0.000326936
I0822 16:40:47.262529 12979 solver.cpp:228] Iteration 68900, loss = 6.68943e-05
I0822 16:40:47.262547 12979 solver.cpp:244]     Train net output #0: loss = 6.68943e-05 (* 1 = 6.68943e-05 loss)
I0822 16:40:47.262552 12979 sgd_solver.cpp:106] Iteration 68900, lr = 0.00032666
I0822 16:40:49.975282 12979 solver.cpp:337] Iteration 69000, Testing net (#0)
I0822 16:40:54.071315 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895161
I0822 16:40:54.071377 12979 solver.cpp:404]     Test net output #1: loss = 0.689107 (* 1 = 0.689107 loss)
I0822 16:40:54.080020 12979 solver.cpp:228] Iteration 69000, loss = 8.8576e-05
I0822 16:40:54.080054 12979 solver.cpp:244]     Train net output #0: loss = 8.8576e-05 (* 1 = 8.8576e-05 loss)
I0822 16:40:54.080065 12979 sgd_solver.cpp:106] Iteration 69000, lr = 0.000326385
I0822 16:40:56.818677 12979 solver.cpp:228] Iteration 69100, loss = 0.000107054
I0822 16:40:56.818709 12979 solver.cpp:244]     Train net output #0: loss = 0.000107054 (* 1 = 0.000107054 loss)
I0822 16:40:56.818716 12979 sgd_solver.cpp:106] Iteration 69100, lr = 0.00032611
I0822 16:40:59.557592 12979 solver.cpp:228] Iteration 69200, loss = 0.000109303
I0822 16:40:59.557648 12979 solver.cpp:244]     Train net output #0: loss = 0.000109303 (* 1 = 0.000109303 loss)
I0822 16:40:59.557660 12979 sgd_solver.cpp:106] Iteration 69200, lr = 0.000325836
I0822 16:41:02.296727 12979 solver.cpp:228] Iteration 69300, loss = 5.7108e-05
I0822 16:41:02.296744 12979 solver.cpp:244]     Train net output #0: loss = 5.7108e-05 (* 1 = 5.7108e-05 loss)
I0822 16:41:02.296748 12979 sgd_solver.cpp:106] Iteration 69300, lr = 0.000325562
I0822 16:41:05.042093 12979 solver.cpp:228] Iteration 69400, loss = 7.47321e-05
I0822 16:41:05.042166 12979 solver.cpp:244]     Train net output #0: loss = 7.47321e-05 (* 1 = 7.47321e-05 loss)
I0822 16:41:05.042183 12979 sgd_solver.cpp:106] Iteration 69400, lr = 0.000325289
I0822 16:41:07.767421 12979 solver.cpp:337] Iteration 69500, Testing net (#0)
I0822 16:41:11.781476 12979 solver.cpp:404]     Test net output #0: accuracy = 0.900806
I0822 16:41:11.781534 12979 solver.cpp:404]     Test net output #1: loss = 0.647261 (* 1 = 0.647261 loss)
I0822 16:41:11.790227 12979 solver.cpp:228] Iteration 69500, loss = 0.000134372
I0822 16:41:11.790278 12979 solver.cpp:244]     Train net output #0: loss = 0.000134372 (* 1 = 0.000134372 loss)
I0822 16:41:11.790289 12979 sgd_solver.cpp:106] Iteration 69500, lr = 0.000325016
I0822 16:41:14.538300 12979 solver.cpp:228] Iteration 69600, loss = 6.35707e-05
I0822 16:41:14.538337 12979 solver.cpp:244]     Train net output #0: loss = 6.35707e-05 (* 1 = 6.35707e-05 loss)
I0822 16:41:14.538343 12979 sgd_solver.cpp:106] Iteration 69600, lr = 0.000324744
I0822 16:41:17.290468 12979 solver.cpp:228] Iteration 69700, loss = 7.10072e-05
I0822 16:41:17.290508 12979 solver.cpp:244]     Train net output #0: loss = 7.10072e-05 (* 1 = 7.10072e-05 loss)
I0822 16:41:17.290513 12979 sgd_solver.cpp:106] Iteration 69700, lr = 0.000324473
I0822 16:41:20.036128 12979 solver.cpp:228] Iteration 69800, loss = 0.000108129
I0822 16:41:20.036152 12979 solver.cpp:244]     Train net output #0: loss = 0.000108129 (* 1 = 0.000108129 loss)
I0822 16:41:20.036157 12979 sgd_solver.cpp:106] Iteration 69800, lr = 0.000324202
I0822 16:41:22.778363 12979 solver.cpp:228] Iteration 69900, loss = 9.78878e-05
I0822 16:41:22.778381 12979 solver.cpp:244]     Train net output #0: loss = 9.78878e-05 (* 1 = 9.78878e-05 loss)
I0822 16:41:22.778386 12979 sgd_solver.cpp:106] Iteration 69900, lr = 0.000323931
I0822 16:41:25.490021 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_70000.caffemodel
I0822 16:41:25.998589 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_70000.solverstate
I0822 16:41:26.156513 12979 solver.cpp:337] Iteration 70000, Testing net (#0)
I0822 16:41:30.125442 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898935
I0822 16:41:30.125489 12979 solver.cpp:404]     Test net output #1: loss = 0.665074 (* 1 = 0.665074 loss)
I0822 16:41:30.134212 12979 solver.cpp:228] Iteration 70000, loss = 0.000105631
I0822 16:41:30.134245 12979 solver.cpp:244]     Train net output #0: loss = 0.000105631 (* 1 = 0.000105631 loss)
I0822 16:41:30.134268 12979 sgd_solver.cpp:106] Iteration 70000, lr = 0.000323661
I0822 16:41:32.884004 12979 solver.cpp:228] Iteration 70100, loss = 7.75684e-05
I0822 16:41:32.884049 12979 solver.cpp:244]     Train net output #0: loss = 7.75684e-05 (* 1 = 7.75684e-05 loss)
I0822 16:41:32.884055 12979 sgd_solver.cpp:106] Iteration 70100, lr = 0.000323392
I0822 16:41:35.627236 12979 solver.cpp:228] Iteration 70200, loss = 0.000138261
I0822 16:41:35.627285 12979 solver.cpp:244]     Train net output #0: loss = 0.000138261 (* 1 = 0.000138261 loss)
I0822 16:41:35.627389 12979 sgd_solver.cpp:106] Iteration 70200, lr = 0.000323123
I0822 16:41:38.368114 12979 solver.cpp:228] Iteration 70300, loss = 0.000113579
I0822 16:41:38.368132 12979 solver.cpp:244]     Train net output #0: loss = 0.000113579 (* 1 = 0.000113579 loss)
I0822 16:41:38.368145 12979 sgd_solver.cpp:106] Iteration 70300, lr = 0.000322854
I0822 16:41:41.102547 12979 solver.cpp:228] Iteration 70400, loss = 7.26516e-05
I0822 16:41:41.102566 12979 solver.cpp:244]     Train net output #0: loss = 7.26516e-05 (* 1 = 7.26516e-05 loss)
I0822 16:41:41.102571 12979 sgd_solver.cpp:106] Iteration 70400, lr = 0.000322587
I0822 16:41:43.808116 12979 solver.cpp:337] Iteration 70500, Testing net (#0)
I0822 16:41:47.802096 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899161
I0822 16:41:47.802157 12979 solver.cpp:404]     Test net output #1: loss = 0.663708 (* 1 = 0.663708 loss)
I0822 16:41:47.811684 12979 solver.cpp:228] Iteration 70500, loss = 0.000123643
I0822 16:41:47.811743 12979 solver.cpp:244]     Train net output #0: loss = 0.000123643 (* 1 = 0.000123643 loss)
I0822 16:41:47.811763 12979 sgd_solver.cpp:106] Iteration 70500, lr = 0.000322319
I0822 16:41:50.557477 12979 solver.cpp:228] Iteration 70600, loss = 0.000112348
I0822 16:41:50.557521 12979 solver.cpp:244]     Train net output #0: loss = 0.000112348 (* 1 = 0.000112348 loss)
I0822 16:41:50.557528 12979 sgd_solver.cpp:106] Iteration 70600, lr = 0.000322052
I0822 16:41:53.299595 12979 solver.cpp:228] Iteration 70700, loss = 0.000139548
I0822 16:41:53.299636 12979 solver.cpp:244]     Train net output #0: loss = 0.000139548 (* 1 = 0.000139548 loss)
I0822 16:41:53.299643 12979 sgd_solver.cpp:106] Iteration 70700, lr = 0.000321786
I0822 16:41:56.038189 12979 solver.cpp:228] Iteration 70800, loss = 9.26904e-05
I0822 16:41:56.038208 12979 solver.cpp:244]     Train net output #0: loss = 9.26904e-05 (* 1 = 9.26904e-05 loss)
I0822 16:41:56.038213 12979 sgd_solver.cpp:106] Iteration 70800, lr = 0.00032152
I0822 16:41:58.776191 12979 solver.cpp:228] Iteration 70900, loss = 0.000102346
I0822 16:41:58.776208 12979 solver.cpp:244]     Train net output #0: loss = 0.000102346 (* 1 = 0.000102346 loss)
I0822 16:41:58.776213 12979 sgd_solver.cpp:106] Iteration 70900, lr = 0.000321255
I0822 16:42:01.488093 12979 solver.cpp:337] Iteration 71000, Testing net (#0)
I0822 16:42:05.476132 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895323
I0822 16:42:05.476214 12979 solver.cpp:404]     Test net output #1: loss = 0.694757 (* 1 = 0.694757 loss)
I0822 16:42:05.484997 12979 solver.cpp:228] Iteration 71000, loss = 0.00012521
I0822 16:42:05.485046 12979 solver.cpp:244]     Train net output #0: loss = 0.00012521 (* 1 = 0.00012521 loss)
I0822 16:42:05.485064 12979 sgd_solver.cpp:106] Iteration 71000, lr = 0.00032099
I0822 16:42:08.230964 12979 solver.cpp:228] Iteration 71100, loss = 9.27477e-05
I0822 16:42:08.231005 12979 solver.cpp:244]     Train net output #0: loss = 9.27477e-05 (* 1 = 9.27477e-05 loss)
I0822 16:42:08.231010 12979 sgd_solver.cpp:106] Iteration 71100, lr = 0.000320726
I0822 16:42:10.976918 12979 solver.cpp:228] Iteration 71200, loss = 0.000424691
I0822 16:42:10.976956 12979 solver.cpp:244]     Train net output #0: loss = 0.000424691 (* 1 = 0.000424691 loss)
I0822 16:42:10.976968 12979 sgd_solver.cpp:106] Iteration 71200, lr = 0.000320462
I0822 16:42:13.722709 12979 solver.cpp:228] Iteration 71300, loss = 0.000107873
I0822 16:42:13.722750 12979 solver.cpp:244]     Train net output #0: loss = 0.000107873 (* 1 = 0.000107873 loss)
I0822 16:42:13.722755 12979 sgd_solver.cpp:106] Iteration 71300, lr = 0.000320199
I0822 16:42:16.463816 12979 solver.cpp:228] Iteration 71400, loss = 9.29779e-05
I0822 16:42:16.463846 12979 solver.cpp:244]     Train net output #0: loss = 9.29779e-05 (* 1 = 9.29779e-05 loss)
I0822 16:42:16.463851 12979 sgd_solver.cpp:106] Iteration 71400, lr = 0.000319936
I0822 16:42:19.181629 12979 solver.cpp:337] Iteration 71500, Testing net (#0)
I0822 16:42:23.395098 12979 solver.cpp:404]     Test net output #0: accuracy = 0.900419
I0822 16:42:23.395161 12979 solver.cpp:404]     Test net output #1: loss = 0.657955 (* 1 = 0.657955 loss)
I0822 16:42:23.404660 12979 solver.cpp:228] Iteration 71500, loss = 0.000100579
I0822 16:42:23.404722 12979 solver.cpp:244]     Train net output #0: loss = 0.000100579 (* 1 = 0.000100579 loss)
I0822 16:42:23.404747 12979 sgd_solver.cpp:106] Iteration 71500, lr = 0.000319674
I0822 16:42:26.147666 12979 solver.cpp:228] Iteration 71600, loss = 0.0002793
I0822 16:42:26.147707 12979 solver.cpp:244]     Train net output #0: loss = 0.0002793 (* 1 = 0.0002793 loss)
I0822 16:42:26.147713 12979 sgd_solver.cpp:106] Iteration 71600, lr = 0.000319412
I0822 16:42:28.890832 12979 solver.cpp:228] Iteration 71700, loss = 7.97701e-05
I0822 16:42:28.890851 12979 solver.cpp:244]     Train net output #0: loss = 7.97701e-05 (* 1 = 7.97701e-05 loss)
I0822 16:42:28.890856 12979 sgd_solver.cpp:106] Iteration 71700, lr = 0.00031915
I0822 16:42:31.633798 12979 solver.cpp:228] Iteration 71800, loss = 5.02316e-05
I0822 16:42:31.633816 12979 solver.cpp:244]     Train net output #0: loss = 5.02316e-05 (* 1 = 5.02316e-05 loss)
I0822 16:42:31.633821 12979 sgd_solver.cpp:106] Iteration 71800, lr = 0.00031889
I0822 16:42:34.375108 12979 solver.cpp:228] Iteration 71900, loss = 0.000192167
I0822 16:42:34.375126 12979 solver.cpp:244]     Train net output #0: loss = 0.000192167 (* 1 = 0.000192167 loss)
I0822 16:42:34.375131 12979 sgd_solver.cpp:106] Iteration 71900, lr = 0.000318629
I0822 16:42:37.088708 12979 solver.cpp:337] Iteration 72000, Testing net (#0)
I0822 16:42:41.180425 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0822 16:42:41.180486 12979 solver.cpp:404]     Test net output #1: loss = 0.67037 (* 1 = 0.67037 loss)
I0822 16:42:41.189277 12979 solver.cpp:228] Iteration 72000, loss = 7.58998e-05
I0822 16:42:41.189318 12979 solver.cpp:244]     Train net output #0: loss = 7.58998e-05 (* 1 = 7.58998e-05 loss)
I0822 16:42:41.189332 12979 sgd_solver.cpp:106] Iteration 72000, lr = 0.00031837
I0822 16:42:43.933557 12979 solver.cpp:228] Iteration 72100, loss = 0.000121039
I0822 16:42:43.933596 12979 solver.cpp:244]     Train net output #0: loss = 0.000121039 (* 1 = 0.000121039 loss)
I0822 16:42:43.933601 12979 sgd_solver.cpp:106] Iteration 72100, lr = 0.00031811
I0822 16:42:46.673202 12979 solver.cpp:228] Iteration 72200, loss = 4.51092e-05
I0822 16:42:46.673219 12979 solver.cpp:244]     Train net output #0: loss = 4.51092e-05 (* 1 = 4.51092e-05 loss)
I0822 16:42:46.673224 12979 sgd_solver.cpp:106] Iteration 72200, lr = 0.000317852
I0822 16:42:49.408897 12979 solver.cpp:228] Iteration 72300, loss = 6.62152e-05
I0822 16:42:49.408915 12979 solver.cpp:244]     Train net output #0: loss = 6.62152e-05 (* 1 = 6.62152e-05 loss)
I0822 16:42:49.408921 12979 sgd_solver.cpp:106] Iteration 72300, lr = 0.000317593
I0822 16:42:52.146939 12979 solver.cpp:228] Iteration 72400, loss = 9.11858e-05
I0822 16:42:52.146957 12979 solver.cpp:244]     Train net output #0: loss = 9.11858e-05 (* 1 = 9.11858e-05 loss)
I0822 16:42:52.146962 12979 sgd_solver.cpp:106] Iteration 72400, lr = 0.000317335
I0822 16:42:54.856660 12979 solver.cpp:337] Iteration 72500, Testing net (#0)
I0822 16:42:59.098812 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897193
I0822 16:42:59.098871 12979 solver.cpp:404]     Test net output #1: loss = 0.683784 (* 1 = 0.683784 loss)
I0822 16:42:59.108412 12979 solver.cpp:228] Iteration 72500, loss = 0.000119756
I0822 16:42:59.108467 12979 solver.cpp:244]     Train net output #0: loss = 0.000119756 (* 1 = 0.000119756 loss)
I0822 16:42:59.108486 12979 sgd_solver.cpp:106] Iteration 72500, lr = 0.000317078
I0822 16:43:01.851583 12979 solver.cpp:228] Iteration 72600, loss = 0.000132206
I0822 16:43:01.851641 12979 solver.cpp:244]     Train net output #0: loss = 0.000132206 (* 1 = 0.000132206 loss)
I0822 16:43:01.851651 12979 sgd_solver.cpp:106] Iteration 72600, lr = 0.000316821
I0822 16:43:04.594432 12979 solver.cpp:228] Iteration 72700, loss = 5.94633e-05
I0822 16:43:04.594473 12979 solver.cpp:244]     Train net output #0: loss = 5.94633e-05 (* 1 = 5.94633e-05 loss)
I0822 16:43:04.594478 12979 sgd_solver.cpp:106] Iteration 72700, lr = 0.000316565
I0822 16:43:07.332772 12979 solver.cpp:228] Iteration 72800, loss = 6.60008e-05
I0822 16:43:07.332789 12979 solver.cpp:244]     Train net output #0: loss = 6.60008e-05 (* 1 = 6.60008e-05 loss)
I0822 16:43:07.332794 12979 sgd_solver.cpp:106] Iteration 72800, lr = 0.000316309
I0822 16:43:10.070170 12979 solver.cpp:228] Iteration 72900, loss = 5.52575e-05
I0822 16:43:10.070188 12979 solver.cpp:244]     Train net output #0: loss = 5.52575e-05 (* 1 = 5.52575e-05 loss)
I0822 16:43:10.070193 12979 sgd_solver.cpp:106] Iteration 72900, lr = 0.000316054
I0822 16:43:12.780822 12979 solver.cpp:337] Iteration 73000, Testing net (#0)
I0822 16:43:13.289206 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:43:16.985828 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897645
I0822 16:43:16.985874 12979 solver.cpp:404]     Test net output #1: loss = 0.679315 (* 1 = 0.679315 loss)
I0822 16:43:16.995930 12979 solver.cpp:228] Iteration 73000, loss = 9.35685e-05
I0822 16:43:16.995967 12979 solver.cpp:244]     Train net output #0: loss = 9.35685e-05 (* 1 = 9.35685e-05 loss)
I0822 16:43:16.995990 12979 sgd_solver.cpp:106] Iteration 73000, lr = 0.000315799
I0822 16:43:19.747524 12979 solver.cpp:228] Iteration 73100, loss = 0.00019105
I0822 16:43:19.747572 12979 solver.cpp:244]     Train net output #0: loss = 0.00019105 (* 1 = 0.00019105 loss)
I0822 16:43:19.747581 12979 sgd_solver.cpp:106] Iteration 73100, lr = 0.000315544
I0822 16:43:22.494972 12979 solver.cpp:228] Iteration 73200, loss = 4.99754e-05
I0822 16:43:22.495021 12979 solver.cpp:244]     Train net output #0: loss = 4.99754e-05 (* 1 = 4.99754e-05 loss)
I0822 16:43:22.495030 12979 sgd_solver.cpp:106] Iteration 73200, lr = 0.00031529
I0822 16:43:25.242745 12979 solver.cpp:228] Iteration 73300, loss = 0.000187888
I0822 16:43:25.242786 12979 solver.cpp:244]     Train net output #0: loss = 0.000187888 (* 1 = 0.000187888 loss)
I0822 16:43:25.242791 12979 sgd_solver.cpp:106] Iteration 73300, lr = 0.000315037
I0822 16:43:27.984817 12979 solver.cpp:228] Iteration 73400, loss = 0.000192002
I0822 16:43:27.984834 12979 solver.cpp:244]     Train net output #0: loss = 0.000192002 (* 1 = 0.000192002 loss)
I0822 16:43:27.984839 12979 sgd_solver.cpp:106] Iteration 73400, lr = 0.000314784
I0822 16:43:30.699070 12979 solver.cpp:337] Iteration 73500, Testing net (#0)
I0822 16:43:34.788238 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899967
I0822 16:43:34.788283 12979 solver.cpp:404]     Test net output #1: loss = 0.66553 (* 1 = 0.66553 loss)
I0822 16:43:34.797194 12979 solver.cpp:228] Iteration 73500, loss = 5.51118e-05
I0822 16:43:34.797233 12979 solver.cpp:244]     Train net output #0: loss = 5.51118e-05 (* 1 = 5.51118e-05 loss)
I0822 16:43:34.797245 12979 sgd_solver.cpp:106] Iteration 73500, lr = 0.000314531
I0822 16:43:37.533428 12979 solver.cpp:228] Iteration 73600, loss = 5.33751e-05
I0822 16:43:37.533466 12979 solver.cpp:244]     Train net output #0: loss = 5.33751e-05 (* 1 = 5.33751e-05 loss)
I0822 16:43:37.533471 12979 sgd_solver.cpp:106] Iteration 73600, lr = 0.000314279
I0822 16:43:40.267186 12979 solver.cpp:228] Iteration 73700, loss = 0.000155377
I0822 16:43:40.267204 12979 solver.cpp:244]     Train net output #0: loss = 0.000155377 (* 1 = 0.000155377 loss)
I0822 16:43:40.267208 12979 sgd_solver.cpp:106] Iteration 73700, lr = 0.000314028
I0822 16:43:43.001184 12979 solver.cpp:228] Iteration 73800, loss = 7.81066e-05
I0822 16:43:43.001201 12979 solver.cpp:244]     Train net output #0: loss = 7.81066e-05 (* 1 = 7.81066e-05 loss)
I0822 16:43:43.001206 12979 sgd_solver.cpp:106] Iteration 73800, lr = 0.000313777
I0822 16:43:45.732483 12979 solver.cpp:228] Iteration 73900, loss = 4.36862e-05
I0822 16:43:45.732501 12979 solver.cpp:244]     Train net output #0: loss = 4.36862e-05 (* 1 = 4.36862e-05 loss)
I0822 16:43:45.732506 12979 sgd_solver.cpp:106] Iteration 73900, lr = 0.000313526
I0822 16:43:48.439869 12979 solver.cpp:337] Iteration 74000, Testing net (#0)
I0822 16:43:52.495645 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897484
I0822 16:43:52.495705 12979 solver.cpp:404]     Test net output #1: loss = 0.68413 (* 1 = 0.68413 loss)
I0822 16:43:52.504426 12979 solver.cpp:228] Iteration 74000, loss = 4.74324e-05
I0822 16:43:52.504467 12979 solver.cpp:244]     Train net output #0: loss = 4.74324e-05 (* 1 = 4.74324e-05 loss)
I0822 16:43:52.504488 12979 sgd_solver.cpp:106] Iteration 74000, lr = 0.000313276
I0822 16:43:55.254209 12979 solver.cpp:228] Iteration 74100, loss = 5.86164e-05
I0822 16:43:55.254268 12979 solver.cpp:244]     Train net output #0: loss = 5.86164e-05 (* 1 = 5.86164e-05 loss)
I0822 16:43:55.254276 12979 sgd_solver.cpp:106] Iteration 74100, lr = 0.000313026
I0822 16:43:57.999725 12979 solver.cpp:228] Iteration 74200, loss = 7.35364e-05
I0822 16:43:57.999786 12979 solver.cpp:244]     Train net output #0: loss = 7.35364e-05 (* 1 = 7.35364e-05 loss)
I0822 16:43:57.999796 12979 sgd_solver.cpp:106] Iteration 74200, lr = 0.000312777
I0822 16:44:00.746860 12979 solver.cpp:228] Iteration 74300, loss = 4.6352e-05
I0822 16:44:00.746917 12979 solver.cpp:244]     Train net output #0: loss = 4.6352e-05 (* 1 = 4.6352e-05 loss)
I0822 16:44:00.746924 12979 sgd_solver.cpp:106] Iteration 74300, lr = 0.000312528
I0822 16:44:03.485234 12979 solver.cpp:228] Iteration 74400, loss = 0.000111753
I0822 16:44:03.485273 12979 solver.cpp:244]     Train net output #0: loss = 0.000111753 (* 1 = 0.000111753 loss)
I0822 16:44:03.485278 12979 sgd_solver.cpp:106] Iteration 74400, lr = 0.00031228
I0822 16:44:06.198698 12979 solver.cpp:337] Iteration 74500, Testing net (#0)
I0822 16:44:10.200740 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895903
I0822 16:44:10.200758 12979 solver.cpp:404]     Test net output #1: loss = 0.700273 (* 1 = 0.700273 loss)
I0822 16:44:10.209352 12979 solver.cpp:228] Iteration 74500, loss = 7.89593e-05
I0822 16:44:10.209370 12979 solver.cpp:244]     Train net output #0: loss = 7.89593e-05 (* 1 = 7.89593e-05 loss)
I0822 16:44:10.209377 12979 sgd_solver.cpp:106] Iteration 74500, lr = 0.000312032
I0822 16:44:12.953308 12979 solver.cpp:228] Iteration 74600, loss = 5.93548e-05
I0822 16:44:12.953348 12979 solver.cpp:244]     Train net output #0: loss = 5.93548e-05 (* 1 = 5.93548e-05 loss)
I0822 16:44:12.953353 12979 sgd_solver.cpp:106] Iteration 74600, lr = 0.000311784
I0822 16:44:15.696929 12979 solver.cpp:228] Iteration 74700, loss = 4.26223e-05
I0822 16:44:15.696959 12979 solver.cpp:244]     Train net output #0: loss = 4.26223e-05 (* 1 = 4.26223e-05 loss)
I0822 16:44:15.696966 12979 sgd_solver.cpp:106] Iteration 74700, lr = 0.000311537
I0822 16:44:18.437731 12979 solver.cpp:228] Iteration 74800, loss = 0.000141848
I0822 16:44:18.437747 12979 solver.cpp:244]     Train net output #0: loss = 0.000141848 (* 1 = 0.000141848 loss)
I0822 16:44:18.437752 12979 sgd_solver.cpp:106] Iteration 74800, lr = 0.000311291
I0822 16:44:21.179386 12979 solver.cpp:228] Iteration 74900, loss = 0.000121341
I0822 16:44:21.179404 12979 solver.cpp:244]     Train net output #0: loss = 0.000121341 (* 1 = 0.000121341 loss)
I0822 16:44:21.179407 12979 sgd_solver.cpp:106] Iteration 74900, lr = 0.000311045
I0822 16:44:23.895370 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_75000.caffemodel
I0822 16:44:24.394136 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_75000.solverstate
I0822 16:44:24.554512 12979 solver.cpp:337] Iteration 75000, Testing net (#0)
I0822 16:44:28.541571 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898419
I0822 16:44:28.541596 12979 solver.cpp:404]     Test net output #1: loss = 0.680815 (* 1 = 0.680815 loss)
I0822 16:44:28.550185 12979 solver.cpp:228] Iteration 75000, loss = 3.75899e-05
I0822 16:44:28.550201 12979 solver.cpp:244]     Train net output #0: loss = 3.75899e-05 (* 1 = 3.75899e-05 loss)
I0822 16:44:28.550209 12979 sgd_solver.cpp:106] Iteration 75000, lr = 0.000310799
I0822 16:44:31.294147 12979 solver.cpp:228] Iteration 75100, loss = 6.14539e-05
I0822 16:44:31.294167 12979 solver.cpp:244]     Train net output #0: loss = 6.14539e-05 (* 1 = 6.14539e-05 loss)
I0822 16:44:31.294170 12979 sgd_solver.cpp:106] Iteration 75100, lr = 0.000310554
I0822 16:44:34.035112 12979 solver.cpp:228] Iteration 75200, loss = 0.000136016
I0822 16:44:34.035130 12979 solver.cpp:244]     Train net output #0: loss = 0.000136016 (* 1 = 0.000136016 loss)
I0822 16:44:34.035135 12979 sgd_solver.cpp:106] Iteration 75200, lr = 0.000310309
I0822 16:44:36.775951 12979 solver.cpp:228] Iteration 75300, loss = 0.000170515
I0822 16:44:36.775969 12979 solver.cpp:244]     Train net output #0: loss = 0.000170515 (* 1 = 0.000170515 loss)
I0822 16:44:36.775972 12979 sgd_solver.cpp:106] Iteration 75300, lr = 0.000310065
I0822 16:44:39.516048 12979 solver.cpp:228] Iteration 75400, loss = 5.21507e-05
I0822 16:44:39.516065 12979 solver.cpp:244]     Train net output #0: loss = 5.21507e-05 (* 1 = 5.21507e-05 loss)
I0822 16:44:39.516070 12979 sgd_solver.cpp:106] Iteration 75400, lr = 0.000309821
I0822 16:44:42.230038 12979 solver.cpp:337] Iteration 75500, Testing net (#0)
I0822 16:44:46.259205 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898774
I0822 16:44:46.259234 12979 solver.cpp:404]     Test net output #1: loss = 0.678769 (* 1 = 0.678769 loss)
I0822 16:44:46.268564 12979 solver.cpp:228] Iteration 75500, loss = 7.85281e-05
I0822 16:44:46.268620 12979 solver.cpp:244]     Train net output #0: loss = 7.85281e-05 (* 1 = 7.85281e-05 loss)
I0822 16:44:46.268633 12979 sgd_solver.cpp:106] Iteration 75500, lr = 0.000309578
I0822 16:44:49.013097 12979 solver.cpp:228] Iteration 75600, loss = 5.80431e-05
I0822 16:44:49.013156 12979 solver.cpp:244]     Train net output #0: loss = 5.80431e-05 (* 1 = 5.80431e-05 loss)
I0822 16:44:49.013164 12979 sgd_solver.cpp:106] Iteration 75600, lr = 0.000309335
I0822 16:44:51.752372 12979 solver.cpp:228] Iteration 75700, loss = 6.39019e-05
I0822 16:44:51.752431 12979 solver.cpp:244]     Train net output #0: loss = 6.39019e-05 (* 1 = 6.39019e-05 loss)
I0822 16:44:51.752437 12979 sgd_solver.cpp:106] Iteration 75700, lr = 0.000309093
I0822 16:44:54.492861 12979 solver.cpp:228] Iteration 75800, loss = 5.30256e-05
I0822 16:44:54.492920 12979 solver.cpp:244]     Train net output #0: loss = 5.30256e-05 (* 1 = 5.30256e-05 loss)
I0822 16:44:54.492926 12979 sgd_solver.cpp:106] Iteration 75800, lr = 0.000308851
I0822 16:44:57.233332 12979 solver.cpp:228] Iteration 75900, loss = 0.000105374
I0822 16:44:57.233397 12979 solver.cpp:244]     Train net output #0: loss = 0.000105374 (* 1 = 0.000105374 loss)
I0822 16:44:57.233403 12979 sgd_solver.cpp:106] Iteration 75900, lr = 0.000308609
I0822 16:44:59.946972 12979 solver.cpp:337] Iteration 76000, Testing net (#0)
I0822 16:45:04.112800 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898613
I0822 16:45:04.112836 12979 solver.cpp:404]     Test net output #1: loss = 0.680099 (* 1 = 0.680099 loss)
I0822 16:45:04.122257 12979 solver.cpp:228] Iteration 76000, loss = 5.47401e-05
I0822 16:45:04.122323 12979 solver.cpp:244]     Train net output #0: loss = 5.47401e-05 (* 1 = 5.47401e-05 loss)
I0822 16:45:04.122344 12979 sgd_solver.cpp:106] Iteration 76000, lr = 0.000308368
I0822 16:45:06.873436 12979 solver.cpp:228] Iteration 76100, loss = 4.3203e-05
I0822 16:45:06.873494 12979 solver.cpp:244]     Train net output #0: loss = 4.3203e-05 (* 1 = 4.3203e-05 loss)
I0822 16:45:06.873504 12979 sgd_solver.cpp:106] Iteration 76100, lr = 0.000308127
I0822 16:45:09.616662 12979 solver.cpp:228] Iteration 76200, loss = 5.61616e-05
I0822 16:45:09.616717 12979 solver.cpp:244]     Train net output #0: loss = 5.61616e-05 (* 1 = 5.61616e-05 loss)
I0822 16:45:09.616724 12979 sgd_solver.cpp:106] Iteration 76200, lr = 0.000307887
I0822 16:45:12.359845 12979 solver.cpp:228] Iteration 76300, loss = 0.000122163
I0822 16:45:12.359861 12979 solver.cpp:244]     Train net output #0: loss = 0.000122163 (* 1 = 0.000122163 loss)
I0822 16:45:12.359874 12979 sgd_solver.cpp:106] Iteration 76300, lr = 0.000307647
I0822 16:45:15.098127 12979 solver.cpp:228] Iteration 76400, loss = 9.67997e-05
I0822 16:45:15.098145 12979 solver.cpp:244]     Train net output #0: loss = 9.67997e-05 (* 1 = 9.67997e-05 loss)
I0822 16:45:15.098150 12979 sgd_solver.cpp:106] Iteration 76400, lr = 0.000307408
I0822 16:45:17.809810 12979 solver.cpp:337] Iteration 76500, Testing net (#0)
I0822 16:45:22.021679 12979 solver.cpp:404]     Test net output #0: accuracy = 0.895903
I0822 16:45:22.021714 12979 solver.cpp:404]     Test net output #1: loss = 0.706695 (* 1 = 0.706695 loss)
I0822 16:45:22.031132 12979 solver.cpp:228] Iteration 76500, loss = 8.10904e-05
I0822 16:45:22.031193 12979 solver.cpp:244]     Train net output #0: loss = 8.10904e-05 (* 1 = 8.10904e-05 loss)
I0822 16:45:22.031208 12979 sgd_solver.cpp:106] Iteration 76500, lr = 0.000307169
I0822 16:45:24.777123 12979 solver.cpp:228] Iteration 76600, loss = 8.80031e-05
I0822 16:45:24.777163 12979 solver.cpp:244]     Train net output #0: loss = 8.80031e-05 (* 1 = 8.80031e-05 loss)
I0822 16:45:24.777168 12979 sgd_solver.cpp:106] Iteration 76600, lr = 0.00030693
I0822 16:45:27.520246 12979 solver.cpp:228] Iteration 76700, loss = 0.000159513
I0822 16:45:27.520263 12979 solver.cpp:244]     Train net output #0: loss = 0.000159513 (* 1 = 0.000159513 loss)
I0822 16:45:27.520267 12979 sgd_solver.cpp:106] Iteration 76700, lr = 0.000306692
I0822 16:45:30.264928 12979 solver.cpp:228] Iteration 76800, loss = 8.19865e-05
I0822 16:45:30.264947 12979 solver.cpp:244]     Train net output #0: loss = 8.19865e-05 (* 1 = 8.19865e-05 loss)
I0822 16:45:30.264951 12979 sgd_solver.cpp:106] Iteration 76800, lr = 0.000306454
I0822 16:45:33.009011 12979 solver.cpp:228] Iteration 76900, loss = 0.000130963
I0822 16:45:33.009052 12979 solver.cpp:244]     Train net output #0: loss = 0.000130963 (* 1 = 0.000130963 loss)
I0822 16:45:33.009058 12979 sgd_solver.cpp:106] Iteration 76900, lr = 0.000306217
I0822 16:45:35.728771 12979 solver.cpp:337] Iteration 77000, Testing net (#0)
I0822 16:45:39.816612 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899516
I0822 16:45:39.816678 12979 solver.cpp:404]     Test net output #1: loss = 0.677719 (* 1 = 0.677719 loss)
I0822 16:45:39.825407 12979 solver.cpp:228] Iteration 77000, loss = 7.71274e-05
I0822 16:45:39.825449 12979 solver.cpp:244]     Train net output #0: loss = 7.71274e-05 (* 1 = 7.71274e-05 loss)
I0822 16:45:39.825460 12979 sgd_solver.cpp:106] Iteration 77000, lr = 0.00030598
I0822 16:45:42.564049 12979 solver.cpp:228] Iteration 77100, loss = 8.39625e-05
I0822 16:45:42.564086 12979 solver.cpp:244]     Train net output #0: loss = 8.39625e-05 (* 1 = 8.39625e-05 loss)
I0822 16:45:42.564091 12979 sgd_solver.cpp:106] Iteration 77100, lr = 0.000305744
I0822 16:45:45.299994 12979 solver.cpp:228] Iteration 77200, loss = 5.11638e-05
I0822 16:45:45.300012 12979 solver.cpp:244]     Train net output #0: loss = 5.11638e-05 (* 1 = 5.11638e-05 loss)
I0822 16:45:45.300016 12979 sgd_solver.cpp:106] Iteration 77200, lr = 0.000305508
I0822 16:45:48.033979 12979 solver.cpp:228] Iteration 77300, loss = 3.57102e-05
I0822 16:45:48.033996 12979 solver.cpp:244]     Train net output #0: loss = 3.57102e-05 (* 1 = 3.57102e-05 loss)
I0822 16:45:48.034000 12979 sgd_solver.cpp:106] Iteration 77300, lr = 0.000305273
I0822 16:45:50.765911 12979 solver.cpp:228] Iteration 77400, loss = 6.31494e-05
I0822 16:45:50.765930 12979 solver.cpp:244]     Train net output #0: loss = 6.31494e-05 (* 1 = 6.31494e-05 loss)
I0822 16:45:50.765936 12979 sgd_solver.cpp:106] Iteration 77400, lr = 0.000305038
I0822 16:45:53.470381 12979 solver.cpp:337] Iteration 77500, Testing net (#0)
I0822 16:45:57.473039 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0822 16:45:57.473107 12979 solver.cpp:404]     Test net output #1: loss = 0.683267 (* 1 = 0.683267 loss)
I0822 16:45:57.481824 12979 solver.cpp:228] Iteration 77500, loss = 7.0258e-05
I0822 16:45:57.481870 12979 solver.cpp:244]     Train net output #0: loss = 7.0258e-05 (* 1 = 7.0258e-05 loss)
I0822 16:45:57.481883 12979 sgd_solver.cpp:106] Iteration 77500, lr = 0.000304803
I0822 16:46:00.223762 12979 solver.cpp:228] Iteration 77600, loss = 7.10743e-05
I0822 16:46:00.223798 12979 solver.cpp:244]     Train net output #0: loss = 7.10743e-05 (* 1 = 7.10743e-05 loss)
I0822 16:46:00.223803 12979 sgd_solver.cpp:106] Iteration 77600, lr = 0.000304569
I0822 16:46:02.964040 12979 solver.cpp:228] Iteration 77700, loss = 3.84952e-05
I0822 16:46:02.964059 12979 solver.cpp:244]     Train net output #0: loss = 3.84952e-05 (* 1 = 3.84952e-05 loss)
I0822 16:46:02.964064 12979 sgd_solver.cpp:106] Iteration 77700, lr = 0.000304335
I0822 16:46:05.705080 12979 solver.cpp:228] Iteration 77800, loss = 3.84937e-05
I0822 16:46:05.705097 12979 solver.cpp:244]     Train net output #0: loss = 3.84937e-05 (* 1 = 3.84937e-05 loss)
I0822 16:46:05.705101 12979 sgd_solver.cpp:106] Iteration 77800, lr = 0.000304101
I0822 16:46:08.443953 12979 solver.cpp:228] Iteration 77900, loss = 5.98075e-05
I0822 16:46:08.443971 12979 solver.cpp:244]     Train net output #0: loss = 5.98075e-05 (* 1 = 5.98075e-05 loss)
I0822 16:46:08.443975 12979 sgd_solver.cpp:106] Iteration 77900, lr = 0.000303868
I0822 16:46:11.157069 12979 solver.cpp:337] Iteration 78000, Testing net (#0)
I0822 16:46:15.180287 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898806
I0822 16:46:15.180305 12979 solver.cpp:404]     Test net output #1: loss = 0.684197 (* 1 = 0.684197 loss)
I0822 16:46:15.188870 12979 solver.cpp:228] Iteration 78000, loss = 0.000130857
I0822 16:46:15.188906 12979 solver.cpp:244]     Train net output #0: loss = 0.000130857 (* 1 = 0.000130857 loss)
I0822 16:46:15.188913 12979 sgd_solver.cpp:106] Iteration 78000, lr = 0.000303636
I0822 16:46:17.932287 12979 solver.cpp:228] Iteration 78100, loss = 9.49694e-05
I0822 16:46:17.932325 12979 solver.cpp:244]     Train net output #0: loss = 9.49694e-05 (* 1 = 9.49694e-05 loss)
I0822 16:46:17.932332 12979 sgd_solver.cpp:106] Iteration 78100, lr = 0.000303404
I0822 16:46:20.674571 12979 solver.cpp:228] Iteration 78200, loss = 0.000139701
I0822 16:46:20.674588 12979 solver.cpp:244]     Train net output #0: loss = 0.000139701 (* 1 = 0.000139701 loss)
I0822 16:46:20.674593 12979 sgd_solver.cpp:106] Iteration 78200, lr = 0.000303172
I0822 16:46:23.418910 12979 solver.cpp:228] Iteration 78300, loss = 6.60418e-05
I0822 16:46:23.418927 12979 solver.cpp:244]     Train net output #0: loss = 6.60418e-05 (* 1 = 6.60418e-05 loss)
I0822 16:46:23.418931 12979 sgd_solver.cpp:106] Iteration 78300, lr = 0.000302941
I0822 16:46:26.159842 12979 solver.cpp:228] Iteration 78400, loss = 3.25545e-05
I0822 16:46:26.159859 12979 solver.cpp:244]     Train net output #0: loss = 3.25545e-05 (* 1 = 3.25545e-05 loss)
I0822 16:46:26.159864 12979 sgd_solver.cpp:106] Iteration 78400, lr = 0.00030271
I0822 16:46:28.883996 12979 solver.cpp:337] Iteration 78500, Testing net (#0)
I0822 16:46:33.061034 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896065
I0822 16:46:33.061089 12979 solver.cpp:404]     Test net output #1: loss = 0.707065 (* 1 = 0.707065 loss)
I0822 16:46:33.070029 12979 solver.cpp:228] Iteration 78500, loss = 0.000148375
I0822 16:46:33.070067 12979 solver.cpp:244]     Train net output #0: loss = 0.000148375 (* 1 = 0.000148375 loss)
I0822 16:46:33.070092 12979 sgd_solver.cpp:106] Iteration 78500, lr = 0.000302479
I0822 16:46:35.818769 12979 solver.cpp:228] Iteration 78600, loss = 9.84275e-05
I0822 16:46:35.818830 12979 solver.cpp:244]     Train net output #0: loss = 9.84275e-05 (* 1 = 9.84275e-05 loss)
I0822 16:46:35.818836 12979 sgd_solver.cpp:106] Iteration 78600, lr = 0.000302249
I0822 16:46:38.562196 12979 solver.cpp:228] Iteration 78700, loss = 9.413e-05
I0822 16:46:38.562245 12979 solver.cpp:244]     Train net output #0: loss = 9.413e-05 (* 1 = 9.413e-05 loss)
I0822 16:46:38.562250 12979 sgd_solver.cpp:106] Iteration 78700, lr = 0.000302019
I0822 16:46:41.305907 12979 solver.cpp:228] Iteration 78800, loss = 7.50976e-05
I0822 16:46:41.305956 12979 solver.cpp:244]     Train net output #0: loss = 7.50976e-05 (* 1 = 7.50976e-05 loss)
I0822 16:46:41.305963 12979 sgd_solver.cpp:106] Iteration 78800, lr = 0.00030179
I0822 16:46:44.050617 12979 solver.cpp:228] Iteration 78900, loss = 6.55835e-05
I0822 16:46:44.050668 12979 solver.cpp:244]     Train net output #0: loss = 6.55835e-05 (* 1 = 6.55835e-05 loss)
I0822 16:46:44.050673 12979 sgd_solver.cpp:106] Iteration 78900, lr = 0.000301561
I0822 16:46:46.767519 12979 solver.cpp:337] Iteration 79000, Testing net (#0)
I0822 16:46:47.172453 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:46:50.862963 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899064
I0822 16:46:50.863011 12979 solver.cpp:404]     Test net output #1: loss = 0.68392 (* 1 = 0.68392 loss)
I0822 16:46:50.871692 12979 solver.cpp:228] Iteration 79000, loss = 5.39293e-05
I0822 16:46:50.871740 12979 solver.cpp:244]     Train net output #0: loss = 5.39293e-05 (* 1 = 5.39293e-05 loss)
I0822 16:46:50.871752 12979 sgd_solver.cpp:106] Iteration 79000, lr = 0.000301333
I0822 16:46:53.617132 12979 solver.cpp:228] Iteration 79100, loss = 0.000116263
I0822 16:46:53.617182 12979 solver.cpp:244]     Train net output #0: loss = 0.000116263 (* 1 = 0.000116263 loss)
I0822 16:46:53.617190 12979 sgd_solver.cpp:106] Iteration 79100, lr = 0.000301105
I0822 16:46:56.370733 12979 solver.cpp:228] Iteration 79200, loss = 7.56144e-05
I0822 16:46:56.370792 12979 solver.cpp:244]     Train net output #0: loss = 7.56144e-05 (* 1 = 7.56144e-05 loss)
I0822 16:46:56.370798 12979 sgd_solver.cpp:106] Iteration 79200, lr = 0.000300877
I0822 16:46:59.112123 12979 solver.cpp:228] Iteration 79300, loss = 5.35834e-05
I0822 16:46:59.112187 12979 solver.cpp:244]     Train net output #0: loss = 5.35834e-05 (* 1 = 5.35834e-05 loss)
I0822 16:46:59.112193 12979 sgd_solver.cpp:106] Iteration 79300, lr = 0.00030065
I0822 16:47:01.853222 12979 solver.cpp:228] Iteration 79400, loss = 7.49143e-05
I0822 16:47:01.853286 12979 solver.cpp:244]     Train net output #0: loss = 7.49143e-05 (* 1 = 7.49143e-05 loss)
I0822 16:47:01.853291 12979 sgd_solver.cpp:106] Iteration 79400, lr = 0.000300423
I0822 16:47:04.564206 12979 solver.cpp:337] Iteration 79500, Testing net (#0)
I0822 16:47:08.647383 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898354
I0822 16:47:08.647408 12979 solver.cpp:404]     Test net output #1: loss = 0.691455 (* 1 = 0.691455 loss)
I0822 16:47:08.657431 12979 solver.cpp:228] Iteration 79500, loss = 0.000105273
I0822 16:47:08.657469 12979 solver.cpp:244]     Train net output #0: loss = 0.000105273 (* 1 = 0.000105273 loss)
I0822 16:47:08.657480 12979 sgd_solver.cpp:106] Iteration 79500, lr = 0.000300196
I0822 16:47:11.402452 12979 solver.cpp:228] Iteration 79600, loss = 5.4067e-05
I0822 16:47:11.402498 12979 solver.cpp:244]     Train net output #0: loss = 5.4067e-05 (* 1 = 5.4067e-05 loss)
I0822 16:47:11.402504 12979 sgd_solver.cpp:106] Iteration 79600, lr = 0.00029997
I0822 16:47:14.142900 12979 solver.cpp:228] Iteration 79700, loss = 7.47913e-05
I0822 16:47:14.142941 12979 solver.cpp:244]     Train net output #0: loss = 7.47913e-05 (* 1 = 7.47913e-05 loss)
I0822 16:47:14.142947 12979 sgd_solver.cpp:106] Iteration 79700, lr = 0.000299744
I0822 16:47:16.881230 12979 solver.cpp:228] Iteration 79800, loss = 0.000149999
I0822 16:47:16.881247 12979 solver.cpp:244]     Train net output #0: loss = 0.000149999 (* 1 = 0.000149999 loss)
I0822 16:47:16.881252 12979 sgd_solver.cpp:106] Iteration 79800, lr = 0.000299519
I0822 16:47:19.619309 12979 solver.cpp:228] Iteration 79900, loss = 5.6657e-05
I0822 16:47:19.619328 12979 solver.cpp:244]     Train net output #0: loss = 5.6657e-05 (* 1 = 5.6657e-05 loss)
I0822 16:47:19.619333 12979 sgd_solver.cpp:106] Iteration 79900, lr = 0.000299294
I0822 16:47:22.329907 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_80000.caffemodel
I0822 16:47:22.808037 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_80000.solverstate
I0822 16:47:22.968154 12979 solver.cpp:337] Iteration 80000, Testing net (#0)
I0822 16:47:27.224309 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897807
I0822 16:47:27.224347 12979 solver.cpp:404]     Test net output #1: loss = 0.698335 (* 1 = 0.698335 loss)
I0822 16:47:27.233103 12979 solver.cpp:228] Iteration 80000, loss = 5.92498e-05
I0822 16:47:27.233153 12979 solver.cpp:244]     Train net output #0: loss = 5.92498e-05 (* 1 = 5.92498e-05 loss)
I0822 16:47:27.233165 12979 sgd_solver.cpp:106] Iteration 80000, lr = 0.00029907
I0822 16:47:29.976784 12979 solver.cpp:228] Iteration 80100, loss = 5.7189e-05
I0822 16:47:29.976820 12979 solver.cpp:244]     Train net output #0: loss = 5.7189e-05 (* 1 = 5.7189e-05 loss)
I0822 16:47:29.976825 12979 sgd_solver.cpp:106] Iteration 80100, lr = 0.000298846
I0822 16:47:32.721272 12979 solver.cpp:228] Iteration 80200, loss = 0.000226104
I0822 16:47:32.721290 12979 solver.cpp:244]     Train net output #0: loss = 0.000226104 (* 1 = 0.000226104 loss)
I0822 16:47:32.721295 12979 sgd_solver.cpp:106] Iteration 80200, lr = 0.000298622
I0822 16:47:35.464037 12979 solver.cpp:228] Iteration 80300, loss = 7.14987e-05
I0822 16:47:35.464054 12979 solver.cpp:244]     Train net output #0: loss = 7.14987e-05 (* 1 = 7.14987e-05 loss)
I0822 16:47:35.464059 12979 sgd_solver.cpp:106] Iteration 80300, lr = 0.000298399
I0822 16:47:38.216907 12979 solver.cpp:228] Iteration 80400, loss = 8.19351e-05
I0822 16:47:38.216956 12979 solver.cpp:244]     Train net output #0: loss = 8.19351e-05 (* 1 = 8.19351e-05 loss)
I0822 16:47:38.216964 12979 sgd_solver.cpp:106] Iteration 80400, lr = 0.000298176
I0822 16:47:40.933295 12979 solver.cpp:337] Iteration 80500, Testing net (#0)
I0822 16:47:45.090988 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898097
I0822 16:47:45.091030 12979 solver.cpp:404]     Test net output #1: loss = 0.696023 (* 1 = 0.696023 loss)
I0822 16:47:45.099828 12979 solver.cpp:228] Iteration 80500, loss = 8.56109e-05
I0822 16:47:45.099853 12979 solver.cpp:244]     Train net output #0: loss = 8.56109e-05 (* 1 = 8.56109e-05 loss)
I0822 16:47:45.099867 12979 sgd_solver.cpp:106] Iteration 80500, lr = 0.000297953
I0822 16:47:47.841076 12979 solver.cpp:228] Iteration 80600, loss = 7.69675e-05
I0822 16:47:47.841114 12979 solver.cpp:244]     Train net output #0: loss = 7.69675e-05 (* 1 = 7.69675e-05 loss)
I0822 16:47:47.841120 12979 sgd_solver.cpp:106] Iteration 80600, lr = 0.000297731
I0822 16:47:50.570960 12979 solver.cpp:228] Iteration 80700, loss = 9.37447e-05
I0822 16:47:50.570978 12979 solver.cpp:244]     Train net output #0: loss = 9.37447e-05 (* 1 = 9.37447e-05 loss)
I0822 16:47:50.570983 12979 sgd_solver.cpp:106] Iteration 80700, lr = 0.000297509
I0822 16:47:53.303123 12979 solver.cpp:228] Iteration 80800, loss = 5.6588e-05
I0822 16:47:53.303140 12979 solver.cpp:244]     Train net output #0: loss = 5.6588e-05 (* 1 = 5.6588e-05 loss)
I0822 16:47:53.303145 12979 sgd_solver.cpp:106] Iteration 80800, lr = 0.000297288
I0822 16:47:56.038975 12979 solver.cpp:228] Iteration 80900, loss = 4.15596e-05
I0822 16:47:56.039037 12979 solver.cpp:244]     Train net output #0: loss = 4.15596e-05 (* 1 = 4.15596e-05 loss)
I0822 16:47:56.039047 12979 sgd_solver.cpp:106] Iteration 80900, lr = 0.000297067
I0822 16:47:58.743422 12979 solver.cpp:337] Iteration 81000, Testing net (#0)
I0822 16:48:02.750927 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899065
I0822 16:48:02.750960 12979 solver.cpp:404]     Test net output #1: loss = 0.688826 (* 1 = 0.688826 loss)
I0822 16:48:02.760382 12979 solver.cpp:228] Iteration 81000, loss = 6.38167e-05
I0822 16:48:02.760453 12979 solver.cpp:244]     Train net output #0: loss = 6.38167e-05 (* 1 = 6.38167e-05 loss)
I0822 16:48:02.760478 12979 sgd_solver.cpp:106] Iteration 81000, lr = 0.000296846
I0822 16:48:05.507140 12979 solver.cpp:228] Iteration 81100, loss = 7.74684e-05
I0822 16:48:05.507179 12979 solver.cpp:244]     Train net output #0: loss = 7.74684e-05 (* 1 = 7.74684e-05 loss)
I0822 16:48:05.507185 12979 sgd_solver.cpp:106] Iteration 81100, lr = 0.000296626
I0822 16:48:08.248951 12979 solver.cpp:228] Iteration 81200, loss = 6.83579e-05
I0822 16:48:08.249007 12979 solver.cpp:244]     Train net output #0: loss = 6.83579e-05 (* 1 = 6.83579e-05 loss)
I0822 16:48:08.249014 12979 sgd_solver.cpp:106] Iteration 81200, lr = 0.000296406
I0822 16:48:10.999341 12979 solver.cpp:228] Iteration 81300, loss = 5.17544e-05
I0822 16:48:10.999379 12979 solver.cpp:244]     Train net output #0: loss = 5.17544e-05 (* 1 = 5.17544e-05 loss)
I0822 16:48:10.999387 12979 sgd_solver.cpp:106] Iteration 81300, lr = 0.000296187
I0822 16:48:13.747712 12979 solver.cpp:228] Iteration 81400, loss = 4.88446e-05
I0822 16:48:13.747783 12979 solver.cpp:244]     Train net output #0: loss = 4.88446e-05 (* 1 = 4.88446e-05 loss)
I0822 16:48:13.747797 12979 sgd_solver.cpp:106] Iteration 81400, lr = 0.000295968
I0822 16:48:16.465528 12979 solver.cpp:337] Iteration 81500, Testing net (#0)
I0822 16:48:20.475088 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898194
I0822 16:48:20.475126 12979 solver.cpp:404]     Test net output #1: loss = 0.695666 (* 1 = 0.695666 loss)
I0822 16:48:20.483824 12979 solver.cpp:228] Iteration 81500, loss = 4.67677e-05
I0822 16:48:20.483850 12979 solver.cpp:244]     Train net output #0: loss = 4.67677e-05 (* 1 = 4.67677e-05 loss)
I0822 16:48:20.483857 12979 sgd_solver.cpp:106] Iteration 81500, lr = 0.000295749
I0822 16:48:23.232211 12979 solver.cpp:228] Iteration 81600, loss = 2.91958e-05
I0822 16:48:23.232250 12979 solver.cpp:244]     Train net output #0: loss = 2.91958e-05 (* 1 = 2.91958e-05 loss)
I0822 16:48:23.232255 12979 sgd_solver.cpp:106] Iteration 81600, lr = 0.00029553
I0822 16:48:25.981267 12979 solver.cpp:228] Iteration 81700, loss = 7.69701e-05
I0822 16:48:25.981286 12979 solver.cpp:244]     Train net output #0: loss = 7.69701e-05 (* 1 = 7.69701e-05 loss)
I0822 16:48:25.981289 12979 sgd_solver.cpp:106] Iteration 81700, lr = 0.000295312
I0822 16:48:28.729384 12979 solver.cpp:228] Iteration 81800, loss = 4.26088e-05
I0822 16:48:28.729401 12979 solver.cpp:244]     Train net output #0: loss = 4.26088e-05 (* 1 = 4.26088e-05 loss)
I0822 16:48:28.729405 12979 sgd_solver.cpp:106] Iteration 81800, lr = 0.000295095
I0822 16:48:31.474762 12979 solver.cpp:228] Iteration 81900, loss = 0.00016703
I0822 16:48:31.474812 12979 solver.cpp:244]     Train net output #0: loss = 0.00016703 (* 1 = 0.00016703 loss)
I0822 16:48:31.474818 12979 sgd_solver.cpp:106] Iteration 81900, lr = 0.000294878
I0822 16:48:34.203100 12979 solver.cpp:337] Iteration 82000, Testing net (#0)
I0822 16:48:38.320088 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89671
I0822 16:48:38.320121 12979 solver.cpp:404]     Test net output #1: loss = 0.711304 (* 1 = 0.711304 loss)
I0822 16:48:38.328841 12979 solver.cpp:228] Iteration 82000, loss = 0.000124712
I0822 16:48:38.328873 12979 solver.cpp:244]     Train net output #0: loss = 0.000124712 (* 1 = 0.000124712 loss)
I0822 16:48:38.328881 12979 sgd_solver.cpp:106] Iteration 82000, lr = 0.000294661
I0822 16:48:41.081324 12979 solver.cpp:228] Iteration 82100, loss = 0.000103137
I0822 16:48:41.081398 12979 solver.cpp:244]     Train net output #0: loss = 0.000103137 (* 1 = 0.000103137 loss)
I0822 16:48:41.081409 12979 sgd_solver.cpp:106] Iteration 82100, lr = 0.000294444
I0822 16:48:43.823806 12979 solver.cpp:228] Iteration 82200, loss = 6.60052e-05
I0822 16:48:43.823823 12979 solver.cpp:244]     Train net output #0: loss = 6.60052e-05 (* 1 = 6.60052e-05 loss)
I0822 16:48:43.823828 12979 sgd_solver.cpp:106] Iteration 82200, lr = 0.000294228
I0822 16:48:46.565827 12979 solver.cpp:228] Iteration 82300, loss = 8.3503e-05
I0822 16:48:46.565845 12979 solver.cpp:244]     Train net output #0: loss = 8.3503e-05 (* 1 = 8.3503e-05 loss)
I0822 16:48:46.565848 12979 sgd_solver.cpp:106] Iteration 82300, lr = 0.000294013
I0822 16:48:49.308516 12979 solver.cpp:228] Iteration 82400, loss = 5.97579e-05
I0822 16:48:49.308593 12979 solver.cpp:244]     Train net output #0: loss = 5.97579e-05 (* 1 = 5.97579e-05 loss)
I0822 16:48:49.308598 12979 sgd_solver.cpp:106] Iteration 82400, lr = 0.000293797
I0822 16:48:52.025625 12979 solver.cpp:337] Iteration 82500, Testing net (#0)
I0822 16:48:56.083612 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89829
I0822 16:48:56.083641 12979 solver.cpp:404]     Test net output #1: loss = 0.696966 (* 1 = 0.696966 loss)
I0822 16:48:56.093113 12979 solver.cpp:228] Iteration 82500, loss = 5.62586e-05
I0822 16:48:56.093178 12979 solver.cpp:244]     Train net output #0: loss = 5.62586e-05 (* 1 = 5.62586e-05 loss)
I0822 16:48:56.093201 12979 sgd_solver.cpp:106] Iteration 82500, lr = 0.000293582
I0822 16:48:58.838127 12979 solver.cpp:228] Iteration 82600, loss = 6.61973e-05
I0822 16:48:58.838176 12979 solver.cpp:244]     Train net output #0: loss = 6.61973e-05 (* 1 = 6.61973e-05 loss)
I0822 16:48:58.838186 12979 sgd_solver.cpp:106] Iteration 82600, lr = 0.000293367
I0822 16:49:01.595511 12979 solver.cpp:228] Iteration 82700, loss = 4.07241e-05
I0822 16:49:01.595559 12979 solver.cpp:244]     Train net output #0: loss = 4.07241e-05 (* 1 = 4.07241e-05 loss)
I0822 16:49:01.595566 12979 sgd_solver.cpp:106] Iteration 82700, lr = 0.000293153
I0822 16:49:04.337383 12979 solver.cpp:228] Iteration 82800, loss = 4.03264e-05
I0822 16:49:04.337399 12979 solver.cpp:244]     Train net output #0: loss = 4.03264e-05 (* 1 = 4.03264e-05 loss)
I0822 16:49:04.337404 12979 sgd_solver.cpp:106] Iteration 82800, lr = 0.000292939
I0822 16:49:07.075512 12979 solver.cpp:228] Iteration 82900, loss = 4.80021e-05
I0822 16:49:07.075531 12979 solver.cpp:244]     Train net output #0: loss = 4.80021e-05 (* 1 = 4.80021e-05 loss)
I0822 16:49:07.075536 12979 sgd_solver.cpp:106] Iteration 82900, lr = 0.000292726
I0822 16:49:09.788857 12979 solver.cpp:337] Iteration 83000, Testing net (#0)
I0822 16:49:13.917093 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898903
I0822 16:49:13.917129 12979 solver.cpp:404]     Test net output #1: loss = 0.693954 (* 1 = 0.693954 loss)
I0822 16:49:13.925848 12979 solver.cpp:228] Iteration 83000, loss = 6.83572e-05
I0822 16:49:13.925865 12979 solver.cpp:244]     Train net output #0: loss = 6.83572e-05 (* 1 = 6.83572e-05 loss)
I0822 16:49:13.925874 12979 sgd_solver.cpp:106] Iteration 83000, lr = 0.000292513
I0822 16:49:16.661201 12979 solver.cpp:228] Iteration 83100, loss = 0.000211126
I0822 16:49:16.661217 12979 solver.cpp:244]     Train net output #0: loss = 0.000211126 (* 1 = 0.000211126 loss)
I0822 16:49:16.661222 12979 sgd_solver.cpp:106] Iteration 83100, lr = 0.0002923
I0822 16:49:19.399240 12979 solver.cpp:228] Iteration 83200, loss = 3.5859e-05
I0822 16:49:19.399260 12979 solver.cpp:244]     Train net output #0: loss = 3.5859e-05 (* 1 = 3.5859e-05 loss)
I0822 16:49:19.399265 12979 sgd_solver.cpp:106] Iteration 83200, lr = 0.000292087
I0822 16:49:22.137192 12979 solver.cpp:228] Iteration 83300, loss = 3.63376e-05
I0822 16:49:22.137209 12979 solver.cpp:244]     Train net output #0: loss = 3.63376e-05 (* 1 = 3.63376e-05 loss)
I0822 16:49:22.137214 12979 sgd_solver.cpp:106] Iteration 83300, lr = 0.000291875
I0822 16:49:24.876309 12979 solver.cpp:228] Iteration 83400, loss = 0.000191203
I0822 16:49:24.876328 12979 solver.cpp:244]     Train net output #0: loss = 0.000191203 (* 1 = 0.000191203 loss)
I0822 16:49:24.876333 12979 sgd_solver.cpp:106] Iteration 83400, lr = 0.000291664
I0822 16:49:27.588874 12979 solver.cpp:337] Iteration 83500, Testing net (#0)
I0822 16:49:31.609820 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898548
I0822 16:49:31.609874 12979 solver.cpp:404]     Test net output #1: loss = 0.695869 (* 1 = 0.695869 loss)
I0822 16:49:31.618696 12979 solver.cpp:228] Iteration 83500, loss = 6.70575e-05
I0822 16:49:31.618738 12979 solver.cpp:244]     Train net output #0: loss = 6.70575e-05 (* 1 = 6.70575e-05 loss)
I0822 16:49:31.618749 12979 sgd_solver.cpp:106] Iteration 83500, lr = 0.000291452
I0822 16:49:34.366173 12979 solver.cpp:228] Iteration 83600, loss = 4.08808e-05
I0822 16:49:34.366235 12979 solver.cpp:244]     Train net output #0: loss = 4.08808e-05 (* 1 = 4.08808e-05 loss)
I0822 16:49:34.366241 12979 sgd_solver.cpp:106] Iteration 83600, lr = 0.000291241
I0822 16:49:37.107113 12979 solver.cpp:228] Iteration 83700, loss = 7.68373e-05
I0822 16:49:37.107175 12979 solver.cpp:244]     Train net output #0: loss = 7.68373e-05 (* 1 = 7.68373e-05 loss)
I0822 16:49:37.107182 12979 sgd_solver.cpp:106] Iteration 83700, lr = 0.00029103
I0822 16:49:39.850147 12979 solver.cpp:228] Iteration 83800, loss = 6.01036e-05
I0822 16:49:39.850209 12979 solver.cpp:244]     Train net output #0: loss = 6.01036e-05 (* 1 = 6.01036e-05 loss)
I0822 16:49:39.850215 12979 sgd_solver.cpp:106] Iteration 83800, lr = 0.00029082
I0822 16:49:42.593809 12979 solver.cpp:228] Iteration 83900, loss = 4.11452e-05
I0822 16:49:42.593869 12979 solver.cpp:244]     Train net output #0: loss = 4.11452e-05 (* 1 = 4.11452e-05 loss)
I0822 16:49:42.593875 12979 sgd_solver.cpp:106] Iteration 83900, lr = 0.00029061
I0822 16:49:45.309651 12979 solver.cpp:337] Iteration 84000, Testing net (#0)
I0822 16:49:49.360015 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896677
I0822 16:49:49.360081 12979 solver.cpp:404]     Test net output #1: loss = 0.715791 (* 1 = 0.715791 loss)
I0822 16:49:49.369580 12979 solver.cpp:228] Iteration 84000, loss = 0.000111849
I0822 16:49:49.369643 12979 solver.cpp:244]     Train net output #0: loss = 0.000111849 (* 1 = 0.000111849 loss)
I0822 16:49:49.369663 12979 sgd_solver.cpp:106] Iteration 84000, lr = 0.000290401
I0822 16:49:52.111084 12979 solver.cpp:228] Iteration 84100, loss = 4.03193e-05
I0822 16:49:52.111150 12979 solver.cpp:244]     Train net output #0: loss = 4.03193e-05 (* 1 = 4.03193e-05 loss)
I0822 16:49:52.111156 12979 sgd_solver.cpp:106] Iteration 84100, lr = 0.000290191
I0822 16:49:54.846865 12979 solver.cpp:228] Iteration 84200, loss = 5.32992e-05
I0822 16:49:54.846926 12979 solver.cpp:244]     Train net output #0: loss = 5.32992e-05 (* 1 = 5.32992e-05 loss)
I0822 16:49:54.846932 12979 sgd_solver.cpp:106] Iteration 84200, lr = 0.000289982
I0822 16:49:57.578088 12979 solver.cpp:228] Iteration 84300, loss = 6.40486e-05
I0822 16:49:57.578148 12979 solver.cpp:244]     Train net output #0: loss = 6.40486e-05 (* 1 = 6.40486e-05 loss)
I0822 16:49:57.578155 12979 sgd_solver.cpp:106] Iteration 84300, lr = 0.000289774
I0822 16:50:00.312714 12979 solver.cpp:228] Iteration 84400, loss = 6.18233e-05
I0822 16:50:00.312773 12979 solver.cpp:244]     Train net output #0: loss = 6.18233e-05 (* 1 = 6.18233e-05 loss)
I0822 16:50:00.312783 12979 sgd_solver.cpp:106] Iteration 84400, lr = 0.000289566
I0822 16:50:03.019327 12979 solver.cpp:337] Iteration 84500, Testing net (#0)
I0822 16:50:07.461760 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899
I0822 16:50:07.461812 12979 solver.cpp:404]     Test net output #1: loss = 0.694531 (* 1 = 0.694531 loss)
I0822 16:50:07.470629 12979 solver.cpp:228] Iteration 84500, loss = 8.40141e-05
I0822 16:50:07.470667 12979 solver.cpp:244]     Train net output #0: loss = 8.40141e-05 (* 1 = 8.40141e-05 loss)
I0822 16:50:07.470688 12979 sgd_solver.cpp:106] Iteration 84500, lr = 0.000289358
I0822 16:50:10.220347 12979 solver.cpp:228] Iteration 84600, loss = 3.09215e-05
I0822 16:50:10.220427 12979 solver.cpp:244]     Train net output #0: loss = 3.09215e-05 (* 1 = 3.09215e-05 loss)
I0822 16:50:10.220440 12979 sgd_solver.cpp:106] Iteration 84600, lr = 0.00028915
I0822 16:50:12.961112 12979 solver.cpp:228] Iteration 84700, loss = 5.10441e-05
I0822 16:50:12.961129 12979 solver.cpp:244]     Train net output #0: loss = 5.10441e-05 (* 1 = 5.10441e-05 loss)
I0822 16:50:12.961133 12979 sgd_solver.cpp:106] Iteration 84700, lr = 0.000288943
I0822 16:50:15.699792 12979 solver.cpp:228] Iteration 84800, loss = 5.67848e-05
I0822 16:50:15.699811 12979 solver.cpp:244]     Train net output #0: loss = 5.67848e-05 (* 1 = 5.67848e-05 loss)
I0822 16:50:15.699816 12979 sgd_solver.cpp:106] Iteration 84800, lr = 0.000288736
I0822 16:50:18.441639 12979 solver.cpp:228] Iteration 84900, loss = 0.000116036
I0822 16:50:18.441655 12979 solver.cpp:244]     Train net output #0: loss = 0.000116036 (* 1 = 0.000116036 loss)
I0822 16:50:18.441660 12979 sgd_solver.cpp:106] Iteration 84900, lr = 0.00028853
I0822 16:50:21.153728 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_85000.caffemodel
I0822 16:50:21.636843 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_85000.solverstate
I0822 16:50:21.796608 12979 solver.cpp:337] Iteration 85000, Testing net (#0)
I0822 16:50:22.514304 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:50:26.271157 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898516
I0822 16:50:26.271198 12979 solver.cpp:404]     Test net output #1: loss = 0.699092 (* 1 = 0.699092 loss)
I0822 16:50:26.281282 12979 solver.cpp:228] Iteration 85000, loss = 3.78696e-05
I0822 16:50:26.281322 12979 solver.cpp:244]     Train net output #0: loss = 3.78696e-05 (* 1 = 3.78696e-05 loss)
I0822 16:50:26.281335 12979 sgd_solver.cpp:106] Iteration 85000, lr = 0.000288324
I0822 16:50:29.031898 12979 solver.cpp:228] Iteration 85100, loss = 8.36842e-05
I0822 16:50:29.031935 12979 solver.cpp:244]     Train net output #0: loss = 8.36842e-05 (* 1 = 8.36842e-05 loss)
I0822 16:50:29.031940 12979 sgd_solver.cpp:106] Iteration 85100, lr = 0.000288118
I0822 16:50:31.778875 12979 solver.cpp:228] Iteration 85200, loss = 7.8725e-05
I0822 16:50:31.778931 12979 solver.cpp:244]     Train net output #0: loss = 7.8725e-05 (* 1 = 7.8725e-05 loss)
I0822 16:50:31.778942 12979 sgd_solver.cpp:106] Iteration 85200, lr = 0.000287913
I0822 16:50:34.525686 12979 solver.cpp:228] Iteration 85300, loss = 8.53569e-05
I0822 16:50:34.525732 12979 solver.cpp:244]     Train net output #0: loss = 8.53569e-05 (* 1 = 8.53569e-05 loss)
I0822 16:50:34.525738 12979 sgd_solver.cpp:106] Iteration 85300, lr = 0.000287708
I0822 16:50:37.277477 12979 solver.cpp:228] Iteration 85400, loss = 7.49099e-05
I0822 16:50:37.277539 12979 solver.cpp:244]     Train net output #0: loss = 7.49099e-05 (* 1 = 7.49099e-05 loss)
I0822 16:50:37.277551 12979 sgd_solver.cpp:106] Iteration 85400, lr = 0.000287503
I0822 16:50:40.003887 12979 solver.cpp:337] Iteration 85500, Testing net (#0)
I0822 16:50:43.937876 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898645
I0822 16:50:43.937922 12979 solver.cpp:404]     Test net output #1: loss = 0.70118 (* 1 = 0.70118 loss)
I0822 16:50:43.946800 12979 solver.cpp:228] Iteration 85500, loss = 0.000130757
I0822 16:50:43.946841 12979 solver.cpp:244]     Train net output #0: loss = 0.000130757 (* 1 = 0.000130757 loss)
I0822 16:50:43.946852 12979 sgd_solver.cpp:106] Iteration 85500, lr = 0.000287298
I0822 16:50:46.687724 12979 solver.cpp:228] Iteration 85600, loss = 4.70651e-05
I0822 16:50:46.687759 12979 solver.cpp:244]     Train net output #0: loss = 4.70651e-05 (* 1 = 4.70651e-05 loss)
I0822 16:50:46.687765 12979 sgd_solver.cpp:106] Iteration 85600, lr = 0.000287094
I0822 16:50:49.435247 12979 solver.cpp:228] Iteration 85700, loss = 4.44647e-05
I0822 16:50:49.435288 12979 solver.cpp:244]     Train net output #0: loss = 4.44647e-05 (* 1 = 4.44647e-05 loss)
I0822 16:50:49.435294 12979 sgd_solver.cpp:106] Iteration 85700, lr = 0.000286891
I0822 16:50:52.178215 12979 solver.cpp:228] Iteration 85800, loss = 2.70208e-05
I0822 16:50:52.178238 12979 solver.cpp:244]     Train net output #0: loss = 2.70208e-05 (* 1 = 2.70208e-05 loss)
I0822 16:50:52.178243 12979 sgd_solver.cpp:106] Iteration 85800, lr = 0.000286687
I0822 16:50:54.920323 12979 solver.cpp:228] Iteration 85900, loss = 4.54267e-05
I0822 16:50:54.920356 12979 solver.cpp:244]     Train net output #0: loss = 4.54267e-05 (* 1 = 4.54267e-05 loss)
I0822 16:50:54.920362 12979 sgd_solver.cpp:106] Iteration 85900, lr = 0.000286484
I0822 16:50:57.635793 12979 solver.cpp:337] Iteration 86000, Testing net (#0)
I0822 16:51:01.635252 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896742
I0822 16:51:01.635315 12979 solver.cpp:404]     Test net output #1: loss = 0.718409 (* 1 = 0.718409 loss)
I0822 16:51:01.644870 12979 solver.cpp:228] Iteration 86000, loss = 7.36092e-05
I0822 16:51:01.644935 12979 solver.cpp:244]     Train net output #0: loss = 7.36092e-05 (* 1 = 7.36092e-05 loss)
I0822 16:51:01.644953 12979 sgd_solver.cpp:106] Iteration 86000, lr = 0.000286281
I0822 16:51:04.388258 12979 solver.cpp:228] Iteration 86100, loss = 3.93301e-05
I0822 16:51:04.388310 12979 solver.cpp:244]     Train net output #0: loss = 3.93301e-05 (* 1 = 3.93301e-05 loss)
I0822 16:51:04.388316 12979 sgd_solver.cpp:106] Iteration 86100, lr = 0.000286079
I0822 16:51:07.127401 12979 solver.cpp:228] Iteration 86200, loss = 4.83664e-05
I0822 16:51:07.127430 12979 solver.cpp:244]     Train net output #0: loss = 4.83664e-05 (* 1 = 4.83664e-05 loss)
I0822 16:51:07.127435 12979 sgd_solver.cpp:106] Iteration 86200, lr = 0.000285877
I0822 16:51:09.866705 12979 solver.cpp:228] Iteration 86300, loss = 3.86236e-05
I0822 16:51:09.866722 12979 solver.cpp:244]     Train net output #0: loss = 3.86236e-05 (* 1 = 3.86236e-05 loss)
I0822 16:51:09.866727 12979 sgd_solver.cpp:106] Iteration 86300, lr = 0.000285675
I0822 16:51:12.606369 12979 solver.cpp:228] Iteration 86400, loss = 0.000101066
I0822 16:51:12.606387 12979 solver.cpp:244]     Train net output #0: loss = 0.000101066 (* 1 = 0.000101066 loss)
I0822 16:51:12.606392 12979 sgd_solver.cpp:106] Iteration 86400, lr = 0.000285474
I0822 16:51:15.321658 12979 solver.cpp:337] Iteration 86500, Testing net (#0)
I0822 16:51:19.337720 12979 solver.cpp:404]     Test net output #0: accuracy = 0.899355
I0822 16:51:19.337738 12979 solver.cpp:404]     Test net output #1: loss = 0.696133 (* 1 = 0.696133 loss)
I0822 16:51:19.347342 12979 solver.cpp:228] Iteration 86500, loss = 8.70935e-05
I0822 16:51:19.347405 12979 solver.cpp:244]     Train net output #0: loss = 8.70935e-05 (* 1 = 8.70935e-05 loss)
I0822 16:51:19.347425 12979 sgd_solver.cpp:106] Iteration 86500, lr = 0.000285273
I0822 16:51:22.102378 12979 solver.cpp:228] Iteration 86600, loss = 0.000116052
I0822 16:51:22.102437 12979 solver.cpp:244]     Train net output #0: loss = 0.000116052 (* 1 = 0.000116052 loss)
I0822 16:51:22.102447 12979 sgd_solver.cpp:106] Iteration 86600, lr = 0.000285072
I0822 16:51:24.844799 12979 solver.cpp:228] Iteration 86700, loss = 5.16841e-05
I0822 16:51:24.844861 12979 solver.cpp:244]     Train net output #0: loss = 5.16841e-05 (* 1 = 5.16841e-05 loss)
I0822 16:51:24.844867 12979 sgd_solver.cpp:106] Iteration 86700, lr = 0.000284872
I0822 16:51:27.582942 12979 solver.cpp:228] Iteration 86800, loss = 0.000106372
I0822 16:51:27.583000 12979 solver.cpp:244]     Train net output #0: loss = 0.000106372 (* 1 = 0.000106372 loss)
I0822 16:51:27.583005 12979 sgd_solver.cpp:106] Iteration 86800, lr = 0.000284672
I0822 16:51:30.322286 12979 solver.cpp:228] Iteration 86900, loss = 0.000127522
I0822 16:51:30.322347 12979 solver.cpp:244]     Train net output #0: loss = 0.000127522 (* 1 = 0.000127522 loss)
I0822 16:51:30.322353 12979 sgd_solver.cpp:106] Iteration 86900, lr = 0.000284472
I0822 16:51:33.035043 12979 solver.cpp:337] Iteration 87000, Testing net (#0)
I0822 16:51:37.021008 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898322
I0822 16:51:37.021073 12979 solver.cpp:404]     Test net output #1: loss = 0.70576 (* 1 = 0.70576 loss)
I0822 16:51:37.029840 12979 solver.cpp:228] Iteration 87000, loss = 0.000100801
I0822 16:51:37.029886 12979 solver.cpp:244]     Train net output #0: loss = 0.000100801 (* 1 = 0.000100801 loss)
I0822 16:51:37.029898 12979 sgd_solver.cpp:106] Iteration 87000, lr = 0.000284272
I0822 16:51:39.768246 12979 solver.cpp:228] Iteration 87100, loss = 0.000138857
I0822 16:51:39.768282 12979 solver.cpp:244]     Train net output #0: loss = 0.000138857 (* 1 = 0.000138857 loss)
I0822 16:51:39.768288 12979 sgd_solver.cpp:106] Iteration 87100, lr = 0.000284073
I0822 16:51:42.507477 12979 solver.cpp:228] Iteration 87200, loss = 0.000125548
I0822 16:51:42.507494 12979 solver.cpp:244]     Train net output #0: loss = 0.000125548 (* 1 = 0.000125548 loss)
I0822 16:51:42.507499 12979 sgd_solver.cpp:106] Iteration 87200, lr = 0.000283875
I0822 16:51:45.248090 12979 solver.cpp:228] Iteration 87300, loss = 5.47806e-05
I0822 16:51:45.248106 12979 solver.cpp:244]     Train net output #0: loss = 5.47806e-05 (* 1 = 5.47806e-05 loss)
I0822 16:51:45.248111 12979 sgd_solver.cpp:106] Iteration 87300, lr = 0.000283676
I0822 16:51:47.989627 12979 solver.cpp:228] Iteration 87400, loss = 5.7557e-05
I0822 16:51:47.989647 12979 solver.cpp:244]     Train net output #0: loss = 5.7557e-05 (* 1 = 5.7557e-05 loss)
I0822 16:51:47.989651 12979 sgd_solver.cpp:106] Iteration 87400, lr = 0.000283478
I0822 16:51:50.702467 12979 solver.cpp:337] Iteration 87500, Testing net (#0)
I0822 16:51:55.025811 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897645
I0822 16:51:55.025848 12979 solver.cpp:404]     Test net output #1: loss = 0.712109 (* 1 = 0.712109 loss)
I0822 16:51:55.034555 12979 solver.cpp:228] Iteration 87500, loss = 3.50882e-05
I0822 16:51:55.034590 12979 solver.cpp:244]     Train net output #0: loss = 3.50882e-05 (* 1 = 3.50882e-05 loss)
I0822 16:51:55.034601 12979 sgd_solver.cpp:106] Iteration 87500, lr = 0.00028328
I0822 16:51:57.774025 12979 solver.cpp:228] Iteration 87600, loss = 4.75092e-05
I0822 16:51:57.774090 12979 solver.cpp:244]     Train net output #0: loss = 4.75092e-05 (* 1 = 4.75092e-05 loss)
I0822 16:51:57.774103 12979 sgd_solver.cpp:106] Iteration 87600, lr = 0.000283083
I0822 16:52:00.522974 12979 solver.cpp:228] Iteration 87700, loss = 5.16303e-05
I0822 16:52:00.523043 12979 solver.cpp:244]     Train net output #0: loss = 5.16303e-05 (* 1 = 5.16303e-05 loss)
I0822 16:52:00.523056 12979 sgd_solver.cpp:106] Iteration 87700, lr = 0.000282886
I0822 16:52:03.279165 12979 solver.cpp:228] Iteration 87800, loss = 5.78817e-05
I0822 16:52:03.279225 12979 solver.cpp:244]     Train net output #0: loss = 5.78817e-05 (* 1 = 5.78817e-05 loss)
I0822 16:52:03.279232 12979 sgd_solver.cpp:106] Iteration 87800, lr = 0.000282689
I0822 16:52:06.018456 12979 solver.cpp:228] Iteration 87900, loss = 2.58961e-05
I0822 16:52:06.018496 12979 solver.cpp:244]     Train net output #0: loss = 2.58961e-05 (* 1 = 2.58961e-05 loss)
I0822 16:52:06.018501 12979 sgd_solver.cpp:106] Iteration 87900, lr = 0.000282492
I0822 16:52:08.722735 12979 solver.cpp:337] Iteration 88000, Testing net (#0)
I0822 16:52:12.775267 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897451
I0822 16:52:12.775324 12979 solver.cpp:404]     Test net output #1: loss = 0.712463 (* 1 = 0.712463 loss)
I0822 16:52:12.784118 12979 solver.cpp:228] Iteration 88000, loss = 8.12075e-05
I0822 16:52:12.784163 12979 solver.cpp:244]     Train net output #0: loss = 8.12075e-05 (* 1 = 8.12075e-05 loss)
I0822 16:52:12.784174 12979 sgd_solver.cpp:106] Iteration 88000, lr = 0.000282296
I0822 16:52:15.531242 12979 solver.cpp:228] Iteration 88100, loss = 6.94905e-05
I0822 16:52:15.531277 12979 solver.cpp:244]     Train net output #0: loss = 6.94905e-05 (* 1 = 6.94905e-05 loss)
I0822 16:52:15.531283 12979 sgd_solver.cpp:106] Iteration 88100, lr = 0.0002821
I0822 16:52:18.278050 12979 solver.cpp:228] Iteration 88200, loss = 6.00822e-05
I0822 16:52:18.278106 12979 solver.cpp:244]     Train net output #0: loss = 6.00822e-05 (* 1 = 6.00822e-05 loss)
I0822 16:52:18.278115 12979 sgd_solver.cpp:106] Iteration 88200, lr = 0.000281905
I0822 16:52:21.025923 12979 solver.cpp:228] Iteration 88300, loss = 0.00010589
I0822 16:52:21.025972 12979 solver.cpp:244]     Train net output #0: loss = 0.00010589 (* 1 = 0.00010589 loss)
I0822 16:52:21.025979 12979 sgd_solver.cpp:106] Iteration 88300, lr = 0.000281709
I0822 16:52:23.767755 12979 solver.cpp:228] Iteration 88400, loss = 5.52747e-05
I0822 16:52:23.767772 12979 solver.cpp:244]     Train net output #0: loss = 5.52747e-05 (* 1 = 5.52747e-05 loss)
I0822 16:52:23.767776 12979 sgd_solver.cpp:106] Iteration 88400, lr = 0.000281514
I0822 16:52:26.483151 12979 solver.cpp:337] Iteration 88500, Testing net (#0)
I0822 16:52:30.516787 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898484
I0822 16:52:30.516849 12979 solver.cpp:404]     Test net output #1: loss = 0.704926 (* 1 = 0.704926 loss)
I0822 16:52:30.525602 12979 solver.cpp:228] Iteration 88500, loss = 7.49068e-05
I0822 16:52:30.525640 12979 solver.cpp:244]     Train net output #0: loss = 7.49068e-05 (* 1 = 7.49068e-05 loss)
I0822 16:52:30.525655 12979 sgd_solver.cpp:106] Iteration 88500, lr = 0.00028132
I0822 16:52:33.274580 12979 solver.cpp:228] Iteration 88600, loss = 5.80492e-05
I0822 16:52:33.274616 12979 solver.cpp:244]     Train net output #0: loss = 5.80492e-05 (* 1 = 5.80492e-05 loss)
I0822 16:52:33.274621 12979 sgd_solver.cpp:106] Iteration 88600, lr = 0.000281125
I0822 16:52:36.019779 12979 solver.cpp:228] Iteration 88700, loss = 8.15468e-05
I0822 16:52:36.019798 12979 solver.cpp:244]     Train net output #0: loss = 8.15468e-05 (* 1 = 8.15468e-05 loss)
I0822 16:52:36.019803 12979 sgd_solver.cpp:106] Iteration 88700, lr = 0.000280931
I0822 16:52:38.763932 12979 solver.cpp:228] Iteration 88800, loss = 8.26076e-05
I0822 16:52:38.763949 12979 solver.cpp:244]     Train net output #0: loss = 8.26076e-05 (* 1 = 8.26076e-05 loss)
I0822 16:52:38.763954 12979 sgd_solver.cpp:106] Iteration 88800, lr = 0.000280738
I0822 16:52:41.514866 12979 solver.cpp:228] Iteration 88900, loss = 6.30758e-05
I0822 16:52:41.514915 12979 solver.cpp:244]     Train net output #0: loss = 6.30758e-05 (* 1 = 6.30758e-05 loss)
I0822 16:52:41.514924 12979 sgd_solver.cpp:106] Iteration 88900, lr = 0.000280544
I0822 16:52:44.240459 12979 solver.cpp:337] Iteration 89000, Testing net (#0)
I0822 16:52:48.255954 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898193
I0822 16:52:48.255991 12979 solver.cpp:404]     Test net output #1: loss = 0.710375 (* 1 = 0.710375 loss)
I0822 16:52:48.264753 12979 solver.cpp:228] Iteration 89000, loss = 0.000214908
I0822 16:52:48.264789 12979 solver.cpp:244]     Train net output #0: loss = 0.000214908 (* 1 = 0.000214908 loss)
I0822 16:52:48.264797 12979 sgd_solver.cpp:106] Iteration 89000, lr = 0.000280351
I0822 16:52:51.020987 12979 solver.cpp:228] Iteration 89100, loss = 6.40009e-05
I0822 16:52:51.021059 12979 solver.cpp:244]     Train net output #0: loss = 6.40009e-05 (* 1 = 6.40009e-05 loss)
I0822 16:52:51.021075 12979 sgd_solver.cpp:106] Iteration 89100, lr = 0.000280159
I0822 16:52:53.767607 12979 solver.cpp:228] Iteration 89200, loss = 4.95904e-05
I0822 16:52:53.767643 12979 solver.cpp:244]     Train net output #0: loss = 4.95904e-05 (* 1 = 4.95904e-05 loss)
I0822 16:52:53.767649 12979 sgd_solver.cpp:106] Iteration 89200, lr = 0.000279966
I0822 16:52:56.511893 12979 solver.cpp:228] Iteration 89300, loss = 5.25721e-05
I0822 16:52:56.511932 12979 solver.cpp:244]     Train net output #0: loss = 5.25721e-05 (* 1 = 5.25721e-05 loss)
I0822 16:52:56.511939 12979 sgd_solver.cpp:106] Iteration 89300, lr = 0.000279774
I0822 16:52:59.255260 12979 solver.cpp:228] Iteration 89400, loss = 6.45538e-05
I0822 16:52:59.255278 12979 solver.cpp:244]     Train net output #0: loss = 6.45538e-05 (* 1 = 6.45538e-05 loss)
I0822 16:52:59.255283 12979 sgd_solver.cpp:106] Iteration 89400, lr = 0.000279582
I0822 16:53:01.973023 12979 solver.cpp:337] Iteration 89500, Testing net (#0)
I0822 16:53:05.990803 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896742
I0822 16:53:05.990844 12979 solver.cpp:404]     Test net output #1: loss = 0.724593 (* 1 = 0.724593 loss)
I0822 16:53:05.999589 12979 solver.cpp:228] Iteration 89500, loss = 5.84654e-05
I0822 16:53:05.999622 12979 solver.cpp:244]     Train net output #0: loss = 5.84654e-05 (* 1 = 5.84654e-05 loss)
I0822 16:53:05.999630 12979 sgd_solver.cpp:106] Iteration 89500, lr = 0.000279391
I0822 16:53:08.744426 12979 solver.cpp:228] Iteration 89600, loss = 7.04713e-05
I0822 16:53:08.744491 12979 solver.cpp:244]     Train net output #0: loss = 7.04713e-05 (* 1 = 7.04713e-05 loss)
I0822 16:53:08.744498 12979 sgd_solver.cpp:106] Iteration 89600, lr = 0.000279199
I0822 16:53:11.484195 12979 solver.cpp:228] Iteration 89700, loss = 5.38034e-05
I0822 16:53:11.484258 12979 solver.cpp:244]     Train net output #0: loss = 5.38034e-05 (* 1 = 5.38034e-05 loss)
I0822 16:53:11.484264 12979 sgd_solver.cpp:106] Iteration 89700, lr = 0.000279009
I0822 16:53:14.225582 12979 solver.cpp:228] Iteration 89800, loss = 3.20035e-05
I0822 16:53:14.225652 12979 solver.cpp:244]     Train net output #0: loss = 3.20035e-05 (* 1 = 3.20035e-05 loss)
I0822 16:53:14.225658 12979 sgd_solver.cpp:106] Iteration 89800, lr = 0.000278818
I0822 16:53:16.966549 12979 solver.cpp:228] Iteration 89900, loss = 6.36114e-05
I0822 16:53:16.966615 12979 solver.cpp:244]     Train net output #0: loss = 6.36114e-05 (* 1 = 6.36114e-05 loss)
I0822 16:53:16.966620 12979 sgd_solver.cpp:106] Iteration 89900, lr = 0.000278628
I0822 16:53:19.681630 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_90000.caffemodel
I0822 16:53:20.165149 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_90000.solverstate
I0822 16:53:20.325557 12979 solver.cpp:337] Iteration 90000, Testing net (#0)
I0822 16:53:24.337524 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898194
I0822 16:53:24.337560 12979 solver.cpp:404]     Test net output #1: loss = 0.709608 (* 1 = 0.709608 loss)
I0822 16:53:24.346964 12979 solver.cpp:228] Iteration 90000, loss = 3.38416e-05
I0822 16:53:24.347025 12979 solver.cpp:244]     Train net output #0: loss = 3.38416e-05 (* 1 = 3.38416e-05 loss)
I0822 16:53:24.347040 12979 sgd_solver.cpp:106] Iteration 90000, lr = 0.000278438
I0822 16:53:27.085762 12979 solver.cpp:228] Iteration 90100, loss = 4.28395e-05
I0822 16:53:27.085782 12979 solver.cpp:244]     Train net output #0: loss = 4.28395e-05 (* 1 = 4.28395e-05 loss)
I0822 16:53:27.085786 12979 sgd_solver.cpp:106] Iteration 90100, lr = 0.000278248
I0822 16:53:29.823645 12979 solver.cpp:228] Iteration 90200, loss = 4.01461e-05
I0822 16:53:29.823663 12979 solver.cpp:244]     Train net output #0: loss = 4.01461e-05 (* 1 = 4.01461e-05 loss)
I0822 16:53:29.823668 12979 sgd_solver.cpp:106] Iteration 90200, lr = 0.000278059
I0822 16:53:32.564847 12979 solver.cpp:228] Iteration 90300, loss = 6.33959e-05
I0822 16:53:32.564885 12979 solver.cpp:244]     Train net output #0: loss = 6.33959e-05 (* 1 = 6.33959e-05 loss)
I0822 16:53:32.564890 12979 sgd_solver.cpp:106] Iteration 90300, lr = 0.00027787
I0822 16:53:35.309521 12979 solver.cpp:228] Iteration 90400, loss = 6.77327e-05
I0822 16:53:35.309587 12979 solver.cpp:244]     Train net output #0: loss = 6.77327e-05 (* 1 = 6.77327e-05 loss)
I0822 16:53:35.309600 12979 sgd_solver.cpp:106] Iteration 90400, lr = 0.000277681
I0822 16:53:38.022444 12979 solver.cpp:337] Iteration 90500, Testing net (#0)
I0822 16:53:42.035892 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0822 16:53:42.035931 12979 solver.cpp:404]     Test net output #1: loss = 0.706798 (* 1 = 0.706798 loss)
I0822 16:53:42.044690 12979 solver.cpp:228] Iteration 90500, loss = 4.31831e-05
I0822 16:53:42.044724 12979 solver.cpp:244]     Train net output #0: loss = 4.31831e-05 (* 1 = 4.31831e-05 loss)
I0822 16:53:42.044734 12979 sgd_solver.cpp:106] Iteration 90500, lr = 0.000277492
I0822 16:53:44.791651 12979 solver.cpp:228] Iteration 90600, loss = 8.22721e-05
I0822 16:53:44.791689 12979 solver.cpp:244]     Train net output #0: loss = 8.22721e-05 (* 1 = 8.22721e-05 loss)
I0822 16:53:44.791695 12979 sgd_solver.cpp:106] Iteration 90600, lr = 0.000277304
I0822 16:53:47.534962 12979 solver.cpp:228] Iteration 90700, loss = 4.38425e-05
I0822 16:53:47.534981 12979 solver.cpp:244]     Train net output #0: loss = 4.38425e-05 (* 1 = 4.38425e-05 loss)
I0822 16:53:47.534986 12979 sgd_solver.cpp:106] Iteration 90700, lr = 0.000277116
I0822 16:53:50.281558 12979 solver.cpp:228] Iteration 90800, loss = 4.0526e-05
I0822 16:53:50.281574 12979 solver.cpp:244]     Train net output #0: loss = 4.0526e-05 (* 1 = 4.0526e-05 loss)
I0822 16:53:50.281579 12979 sgd_solver.cpp:106] Iteration 90800, lr = 0.000276929
I0822 16:53:53.025367 12979 solver.cpp:228] Iteration 90900, loss = 5.17597e-05
I0822 16:53:53.025383 12979 solver.cpp:244]     Train net output #0: loss = 5.17597e-05 (* 1 = 5.17597e-05 loss)
I0822 16:53:53.025388 12979 sgd_solver.cpp:106] Iteration 90900, lr = 0.000276741
I0822 16:53:55.739385 12979 solver.cpp:337] Iteration 91000, Testing net (#0)
I0822 16:53:59.790995 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898516
I0822 16:53:59.791055 12979 solver.cpp:404]     Test net output #1: loss = 0.710196 (* 1 = 0.710196 loss)
I0822 16:53:59.799763 12979 solver.cpp:228] Iteration 91000, loss = 2.78918e-05
I0822 16:53:59.799810 12979 solver.cpp:244]     Train net output #0: loss = 2.78918e-05 (* 1 = 2.78918e-05 loss)
I0822 16:53:59.799823 12979 sgd_solver.cpp:106] Iteration 91000, lr = 0.000276554
I0822 16:54:02.536268 12979 solver.cpp:228] Iteration 91100, loss = 5.40554e-05
I0822 16:54:02.536303 12979 solver.cpp:244]     Train net output #0: loss = 5.40554e-05 (* 1 = 5.40554e-05 loss)
I0822 16:54:02.536309 12979 sgd_solver.cpp:106] Iteration 91100, lr = 0.000276368
I0822 16:54:05.274523 12979 solver.cpp:228] Iteration 91200, loss = 0.000140642
I0822 16:54:05.274562 12979 solver.cpp:244]     Train net output #0: loss = 0.000140642 (* 1 = 0.000140642 loss)
I0822 16:54:05.274567 12979 sgd_solver.cpp:106] Iteration 91200, lr = 0.000276181
I0822 16:54:08.007298 12979 solver.cpp:228] Iteration 91300, loss = 3.24903e-05
I0822 16:54:08.007318 12979 solver.cpp:244]     Train net output #0: loss = 3.24903e-05 (* 1 = 3.24903e-05 loss)
I0822 16:54:08.007323 12979 sgd_solver.cpp:106] Iteration 91300, lr = 0.000275995
I0822 16:54:10.744062 12979 solver.cpp:228] Iteration 91400, loss = 4.93138e-05
I0822 16:54:10.744079 12979 solver.cpp:244]     Train net output #0: loss = 4.93138e-05 (* 1 = 4.93138e-05 loss)
I0822 16:54:10.744084 12979 sgd_solver.cpp:106] Iteration 91400, lr = 0.000275809
I0822 16:54:13.451516 12979 solver.cpp:337] Iteration 91500, Testing net (#0)
I0822 16:54:13.699014 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:54:17.719100 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896548
I0822 16:54:17.719148 12979 solver.cpp:404]     Test net output #1: loss = 0.728776 (* 1 = 0.728776 loss)
I0822 16:54:17.727953 12979 solver.cpp:228] Iteration 91500, loss = 4.99738e-05
I0822 16:54:17.727990 12979 solver.cpp:244]     Train net output #0: loss = 4.99738e-05 (* 1 = 4.99738e-05 loss)
I0822 16:54:17.728001 12979 sgd_solver.cpp:106] Iteration 91500, lr = 0.000275624
I0822 16:54:20.476436 12979 solver.cpp:228] Iteration 91600, loss = 4.54157e-05
I0822 16:54:20.476482 12979 solver.cpp:244]     Train net output #0: loss = 4.54157e-05 (* 1 = 4.54157e-05 loss)
I0822 16:54:20.476488 12979 sgd_solver.cpp:106] Iteration 91600, lr = 0.000275438
I0822 16:54:23.216517 12979 solver.cpp:228] Iteration 91700, loss = 0.000163771
I0822 16:54:23.216536 12979 solver.cpp:244]     Train net output #0: loss = 0.000163771 (* 1 = 0.000163771 loss)
I0822 16:54:23.216541 12979 sgd_solver.cpp:106] Iteration 91700, lr = 0.000275253
I0822 16:54:25.954979 12979 solver.cpp:228] Iteration 91800, loss = 2.81407e-05
I0822 16:54:25.954996 12979 solver.cpp:244]     Train net output #0: loss = 2.81407e-05 (* 1 = 2.81407e-05 loss)
I0822 16:54:25.955000 12979 sgd_solver.cpp:106] Iteration 91800, lr = 0.000275069
I0822 16:54:28.697190 12979 solver.cpp:228] Iteration 91900, loss = 0.000114355
I0822 16:54:28.697207 12979 solver.cpp:244]     Train net output #0: loss = 0.000114355 (* 1 = 0.000114355 loss)
I0822 16:54:28.697212 12979 sgd_solver.cpp:106] Iteration 91900, lr = 0.000274884
I0822 16:54:31.408175 12979 solver.cpp:337] Iteration 92000, Testing net (#0)
I0822 16:54:35.416692 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898516
I0822 16:54:35.416750 12979 solver.cpp:404]     Test net output #1: loss = 0.711477 (* 1 = 0.711477 loss)
I0822 16:54:35.425391 12979 solver.cpp:228] Iteration 92000, loss = 0.000212207
I0822 16:54:35.425423 12979 solver.cpp:244]     Train net output #0: loss = 0.000212207 (* 1 = 0.000212207 loss)
I0822 16:54:35.425433 12979 sgd_solver.cpp:106] Iteration 92000, lr = 0.0002747
I0822 16:54:38.168831 12979 solver.cpp:228] Iteration 92100, loss = 3.26236e-05
I0822 16:54:38.168853 12979 solver.cpp:244]     Train net output #0: loss = 3.26236e-05 (* 1 = 3.26236e-05 loss)
I0822 16:54:38.168858 12979 sgd_solver.cpp:106] Iteration 92100, lr = 0.000274516
I0822 16:54:40.911635 12979 solver.cpp:228] Iteration 92200, loss = 5.98797e-05
I0822 16:54:40.911653 12979 solver.cpp:244]     Train net output #0: loss = 5.98797e-05 (* 1 = 5.98797e-05 loss)
I0822 16:54:40.911659 12979 sgd_solver.cpp:106] Iteration 92200, lr = 0.000274333
I0822 16:54:43.651087 12979 solver.cpp:228] Iteration 92300, loss = 5.34664e-05
I0822 16:54:43.651104 12979 solver.cpp:244]     Train net output #0: loss = 5.34664e-05 (* 1 = 5.34664e-05 loss)
I0822 16:54:43.651108 12979 sgd_solver.cpp:106] Iteration 92300, lr = 0.00027415
I0822 16:54:46.393941 12979 solver.cpp:228] Iteration 92400, loss = 7.07043e-05
I0822 16:54:46.393959 12979 solver.cpp:244]     Train net output #0: loss = 7.07043e-05 (* 1 = 7.07043e-05 loss)
I0822 16:54:46.393964 12979 sgd_solver.cpp:106] Iteration 92400, lr = 0.000273967
I0822 16:54:49.110991 12979 solver.cpp:337] Iteration 92500, Testing net (#0)
I0822 16:54:53.160856 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0822 16:54:53.160898 12979 solver.cpp:404]     Test net output #1: loss = 0.710068 (* 1 = 0.710068 loss)
I0822 16:54:53.169704 12979 solver.cpp:228] Iteration 92500, loss = 4.85941e-05
I0822 16:54:53.169742 12979 solver.cpp:244]     Train net output #0: loss = 4.85941e-05 (* 1 = 4.85941e-05 loss)
I0822 16:54:53.169751 12979 sgd_solver.cpp:106] Iteration 92500, lr = 0.000273784
I0822 16:54:55.925602 12979 solver.cpp:228] Iteration 92600, loss = 9.37591e-05
I0822 16:54:55.925654 12979 solver.cpp:244]     Train net output #0: loss = 9.37591e-05 (* 1 = 9.37591e-05 loss)
I0822 16:54:55.925662 12979 sgd_solver.cpp:106] Iteration 92600, lr = 0.000273602
I0822 16:54:58.667560 12979 solver.cpp:228] Iteration 92700, loss = 3.79825e-05
I0822 16:54:58.667577 12979 solver.cpp:244]     Train net output #0: loss = 3.79825e-05 (* 1 = 3.79825e-05 loss)
I0822 16:54:58.667582 12979 sgd_solver.cpp:106] Iteration 92700, lr = 0.00027342
I0822 16:55:01.409502 12979 solver.cpp:228] Iteration 92800, loss = 5.93776e-05
I0822 16:55:01.409519 12979 solver.cpp:244]     Train net output #0: loss = 5.93776e-05 (* 1 = 5.93776e-05 loss)
I0822 16:55:01.409524 12979 sgd_solver.cpp:106] Iteration 92800, lr = 0.000273238
I0822 16:55:04.151962 12979 solver.cpp:228] Iteration 92900, loss = 0.000113091
I0822 16:55:04.151978 12979 solver.cpp:244]     Train net output #0: loss = 0.000113091 (* 1 = 0.000113091 loss)
I0822 16:55:04.151983 12979 sgd_solver.cpp:106] Iteration 92900, lr = 0.000273056
I0822 16:55:06.866734 12979 solver.cpp:337] Iteration 93000, Testing net (#0)
I0822 16:55:10.892673 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898194
I0822 16:55:10.892735 12979 solver.cpp:404]     Test net output #1: loss = 0.715558 (* 1 = 0.715558 loss)
I0822 16:55:10.901484 12979 solver.cpp:228] Iteration 93000, loss = 5.27577e-05
I0822 16:55:10.901535 12979 solver.cpp:244]     Train net output #0: loss = 5.27577e-05 (* 1 = 5.27577e-05 loss)
I0822 16:55:10.901546 12979 sgd_solver.cpp:106] Iteration 93000, lr = 0.000272875
I0822 16:55:13.645385 12979 solver.cpp:228] Iteration 93100, loss = 3.87999e-05
I0822 16:55:13.645431 12979 solver.cpp:244]     Train net output #0: loss = 3.87999e-05 (* 1 = 3.87999e-05 loss)
I0822 16:55:13.645437 12979 sgd_solver.cpp:106] Iteration 93100, lr = 0.000272694
I0822 16:55:16.389436 12979 solver.cpp:228] Iteration 93200, loss = 3.14526e-05
I0822 16:55:16.389508 12979 solver.cpp:244]     Train net output #0: loss = 3.14526e-05 (* 1 = 3.14526e-05 loss)
I0822 16:55:16.389520 12979 sgd_solver.cpp:106] Iteration 93200, lr = 0.000272513
I0822 16:55:19.134182 12979 solver.cpp:228] Iteration 93300, loss = 3.65241e-05
I0822 16:55:19.134238 12979 solver.cpp:244]     Train net output #0: loss = 3.65241e-05 (* 1 = 3.65241e-05 loss)
I0822 16:55:19.134244 12979 sgd_solver.cpp:106] Iteration 93300, lr = 0.000272333
I0822 16:55:21.873464 12979 solver.cpp:228] Iteration 93400, loss = 5.16461e-05
I0822 16:55:21.873533 12979 solver.cpp:244]     Train net output #0: loss = 5.16461e-05 (* 1 = 5.16461e-05 loss)
I0822 16:55:21.873539 12979 sgd_solver.cpp:106] Iteration 93400, lr = 0.000272153
I0822 16:55:24.586632 12979 solver.cpp:337] Iteration 93500, Testing net (#0)
I0822 16:55:28.568615 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896742
I0822 16:55:28.568683 12979 solver.cpp:404]     Test net output #1: loss = 0.728465 (* 1 = 0.728465 loss)
I0822 16:55:28.577437 12979 solver.cpp:228] Iteration 93500, loss = 5.49817e-05
I0822 16:55:28.577478 12979 solver.cpp:244]     Train net output #0: loss = 5.49817e-05 (* 1 = 5.49817e-05 loss)
I0822 16:55:28.577489 12979 sgd_solver.cpp:106] Iteration 93500, lr = 0.000271973
I0822 16:55:31.324416 12979 solver.cpp:228] Iteration 93600, loss = 4.2204e-05
I0822 16:55:31.324455 12979 solver.cpp:244]     Train net output #0: loss = 4.2204e-05 (* 1 = 4.2204e-05 loss)
I0822 16:55:31.324460 12979 sgd_solver.cpp:106] Iteration 93600, lr = 0.000271793
I0822 16:55:34.065517 12979 solver.cpp:228] Iteration 93700, loss = 6.11198e-05
I0822 16:55:34.065567 12979 solver.cpp:244]     Train net output #0: loss = 6.11198e-05 (* 1 = 6.11198e-05 loss)
I0822 16:55:34.065574 12979 sgd_solver.cpp:106] Iteration 93700, lr = 0.000271614
I0822 16:55:36.806309 12979 solver.cpp:228] Iteration 93800, loss = 4.16557e-05
I0822 16:55:36.806326 12979 solver.cpp:244]     Train net output #0: loss = 4.16557e-05 (* 1 = 4.16557e-05 loss)
I0822 16:55:36.806330 12979 sgd_solver.cpp:106] Iteration 93800, lr = 0.000271435
I0822 16:55:39.547404 12979 solver.cpp:228] Iteration 93900, loss = 6.01907e-05
I0822 16:55:39.547421 12979 solver.cpp:244]     Train net output #0: loss = 6.01907e-05 (* 1 = 6.01907e-05 loss)
I0822 16:55:39.547426 12979 sgd_solver.cpp:106] Iteration 93900, lr = 0.000271256
I0822 16:55:42.260018 12979 solver.cpp:337] Iteration 94000, Testing net (#0)
I0822 16:55:46.428371 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898935
I0822 16:55:46.428426 12979 solver.cpp:404]     Test net output #1: loss = 0.709512 (* 1 = 0.709512 loss)
I0822 16:55:46.437299 12979 solver.cpp:228] Iteration 94000, loss = 9.08965e-05
I0822 16:55:46.437342 12979 solver.cpp:244]     Train net output #0: loss = 9.08965e-05 (* 1 = 9.08965e-05 loss)
I0822 16:55:46.437366 12979 sgd_solver.cpp:106] Iteration 94000, lr = 0.000271078
I0822 16:55:49.190757 12979 solver.cpp:228] Iteration 94100, loss = 6.89608e-05
I0822 16:55:49.190796 12979 solver.cpp:244]     Train net output #0: loss = 6.89608e-05 (* 1 = 6.89608e-05 loss)
I0822 16:55:49.190801 12979 sgd_solver.cpp:106] Iteration 94100, lr = 0.0002709
I0822 16:55:51.933548 12979 solver.cpp:228] Iteration 94200, loss = 4.0634e-05
I0822 16:55:51.933567 12979 solver.cpp:244]     Train net output #0: loss = 4.0634e-05 (* 1 = 4.0634e-05 loss)
I0822 16:55:51.933571 12979 sgd_solver.cpp:106] Iteration 94200, lr = 0.000270722
I0822 16:55:54.676316 12979 solver.cpp:228] Iteration 94300, loss = 3.65627e-05
I0822 16:55:54.676331 12979 solver.cpp:244]     Train net output #0: loss = 3.65627e-05 (* 1 = 3.65627e-05 loss)
I0822 16:55:54.676337 12979 sgd_solver.cpp:106] Iteration 94300, lr = 0.000270544
I0822 16:55:57.416417 12979 solver.cpp:228] Iteration 94400, loss = 3.91829e-05
I0822 16:55:57.416438 12979 solver.cpp:244]     Train net output #0: loss = 3.91829e-05 (* 1 = 3.91829e-05 loss)
I0822 16:55:57.416443 12979 sgd_solver.cpp:106] Iteration 94400, lr = 0.000270367
I0822 16:56:00.129572 12979 solver.cpp:337] Iteration 94500, Testing net (#0)
I0822 16:56:04.386106 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898613
I0822 16:56:04.386157 12979 solver.cpp:404]     Test net output #1: loss = 0.713649 (* 1 = 0.713649 loss)
I0822 16:56:04.394966 12979 solver.cpp:228] Iteration 94500, loss = 8.31203e-05
I0822 16:56:04.394990 12979 solver.cpp:244]     Train net output #0: loss = 8.31203e-05 (* 1 = 8.31203e-05 loss)
I0822 16:56:04.395002 12979 sgd_solver.cpp:106] Iteration 94500, lr = 0.000270189
I0822 16:56:07.128010 12979 solver.cpp:228] Iteration 94600, loss = 5.0847e-05
I0822 16:56:07.128029 12979 solver.cpp:244]     Train net output #0: loss = 5.0847e-05 (* 1 = 5.0847e-05 loss)
I0822 16:56:07.128034 12979 sgd_solver.cpp:106] Iteration 94600, lr = 0.000270013
I0822 16:56:09.859879 12979 solver.cpp:228] Iteration 94700, loss = 3.56373e-05
I0822 16:56:09.859896 12979 solver.cpp:244]     Train net output #0: loss = 3.56373e-05 (* 1 = 3.56373e-05 loss)
I0822 16:56:09.859901 12979 sgd_solver.cpp:106] Iteration 94700, lr = 0.000269836
I0822 16:56:12.589957 12979 solver.cpp:228] Iteration 94800, loss = 5.32041e-05
I0822 16:56:12.589985 12979 solver.cpp:244]     Train net output #0: loss = 5.32041e-05 (* 1 = 5.32041e-05 loss)
I0822 16:56:12.589990 12979 sgd_solver.cpp:106] Iteration 94800, lr = 0.00026966
I0822 16:56:15.320322 12979 solver.cpp:228] Iteration 94900, loss = 3.7666e-05
I0822 16:56:15.320339 12979 solver.cpp:244]     Train net output #0: loss = 3.7666e-05 (* 1 = 3.7666e-05 loss)
I0822 16:56:15.320344 12979 sgd_solver.cpp:106] Iteration 94900, lr = 0.000269484
I0822 16:56:18.025580 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_95000.caffemodel
I0822 16:56:18.493999 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_95000.solverstate
I0822 16:56:18.654353 12979 solver.cpp:337] Iteration 95000, Testing net (#0)
I0822 16:56:22.628285 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897806
I0822 16:56:22.628347 12979 solver.cpp:404]     Test net output #1: loss = 0.722425 (* 1 = 0.722425 loss)
I0822 16:56:22.637078 12979 solver.cpp:228] Iteration 95000, loss = 3.62965e-05
I0822 16:56:22.637109 12979 solver.cpp:244]     Train net output #0: loss = 3.62965e-05 (* 1 = 3.62965e-05 loss)
I0822 16:56:22.637116 12979 sgd_solver.cpp:106] Iteration 95000, lr = 0.000269308
I0822 16:56:25.378098 12979 solver.cpp:228] Iteration 95100, loss = 3.69572e-05
I0822 16:56:25.378123 12979 solver.cpp:244]     Train net output #0: loss = 3.69572e-05 (* 1 = 3.69572e-05 loss)
I0822 16:56:25.378129 12979 sgd_solver.cpp:106] Iteration 95100, lr = 0.000269132
I0822 16:56:28.119107 12979 solver.cpp:228] Iteration 95200, loss = 0.000108127
I0822 16:56:28.119124 12979 solver.cpp:244]     Train net output #0: loss = 0.000108127 (* 1 = 0.000108127 loss)
I0822 16:56:28.119128 12979 sgd_solver.cpp:106] Iteration 95200, lr = 0.000268957
I0822 16:56:30.856283 12979 solver.cpp:228] Iteration 95300, loss = 4.87818e-05
I0822 16:56:30.856302 12979 solver.cpp:244]     Train net output #0: loss = 4.87818e-05 (* 1 = 4.87818e-05 loss)
I0822 16:56:30.856305 12979 sgd_solver.cpp:106] Iteration 95300, lr = 0.000268782
I0822 16:56:33.597674 12979 solver.cpp:228] Iteration 95400, loss = 5.36776e-05
I0822 16:56:33.597692 12979 solver.cpp:244]     Train net output #0: loss = 5.36776e-05 (* 1 = 5.36776e-05 loss)
I0822 16:56:33.597697 12979 sgd_solver.cpp:106] Iteration 95400, lr = 0.000268608
I0822 16:56:36.309212 12979 solver.cpp:337] Iteration 95500, Testing net (#0)
I0822 16:56:40.549492 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897548
I0822 16:56:40.549553 12979 solver.cpp:404]     Test net output #1: loss = 0.724312 (* 1 = 0.724312 loss)
I0822 16:56:40.558351 12979 solver.cpp:228] Iteration 95500, loss = 5.57002e-05
I0822 16:56:40.558401 12979 solver.cpp:244]     Train net output #0: loss = 5.57002e-05 (* 1 = 5.57002e-05 loss)
I0822 16:56:40.558414 12979 sgd_solver.cpp:106] Iteration 95500, lr = 0.000268433
I0822 16:56:43.304062 12979 solver.cpp:228] Iteration 95600, loss = 8.82071e-05
I0822 16:56:43.304096 12979 solver.cpp:244]     Train net output #0: loss = 8.82071e-05 (* 1 = 8.82071e-05 loss)
I0822 16:56:43.304101 12979 sgd_solver.cpp:106] Iteration 95600, lr = 0.000268259
I0822 16:56:46.047938 12979 solver.cpp:228] Iteration 95700, loss = 5.61919e-05
I0822 16:56:46.047956 12979 solver.cpp:244]     Train net output #0: loss = 5.61919e-05 (* 1 = 5.61919e-05 loss)
I0822 16:56:46.047961 12979 sgd_solver.cpp:106] Iteration 95700, lr = 0.000268085
I0822 16:56:48.790488 12979 solver.cpp:228] Iteration 95800, loss = 5.64554e-05
I0822 16:56:48.790505 12979 solver.cpp:244]     Train net output #0: loss = 5.64554e-05 (* 1 = 5.64554e-05 loss)
I0822 16:56:48.790509 12979 sgd_solver.cpp:106] Iteration 95800, lr = 0.000267911
I0822 16:56:51.534047 12979 solver.cpp:228] Iteration 95900, loss = 6.51719e-05
I0822 16:56:51.534065 12979 solver.cpp:244]     Train net output #0: loss = 6.51719e-05 (* 1 = 6.51719e-05 loss)
I0822 16:56:51.534070 12979 sgd_solver.cpp:106] Iteration 95900, lr = 0.000267738
I0822 16:56:54.250738 12979 solver.cpp:337] Iteration 96000, Testing net (#0)
I0822 16:56:58.336447 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898452
I0822 16:56:58.336509 12979 solver.cpp:404]     Test net output #1: loss = 0.716922 (* 1 = 0.716922 loss)
I0822 16:56:58.345844 12979 solver.cpp:228] Iteration 96000, loss = 6.3261e-05
I0822 16:56:58.345898 12979 solver.cpp:244]     Train net output #0: loss = 6.3261e-05 (* 1 = 6.3261e-05 loss)
I0822 16:56:58.345913 12979 sgd_solver.cpp:106] Iteration 96000, lr = 0.000267565
I0822 16:57:01.096963 12979 solver.cpp:228] Iteration 96100, loss = 5.33812e-05
I0822 16:57:01.097028 12979 solver.cpp:244]     Train net output #0: loss = 5.33812e-05 (* 1 = 5.33812e-05 loss)
I0822 16:57:01.097035 12979 sgd_solver.cpp:106] Iteration 96100, lr = 0.000267392
I0822 16:57:03.841104 12979 solver.cpp:228] Iteration 96200, loss = 3.86636e-05
I0822 16:57:03.841152 12979 solver.cpp:244]     Train net output #0: loss = 3.86636e-05 (* 1 = 3.86636e-05 loss)
I0822 16:57:03.841161 12979 sgd_solver.cpp:106] Iteration 96200, lr = 0.000267219
I0822 16:57:06.591831 12979 solver.cpp:228] Iteration 96300, loss = 6.01095e-05
I0822 16:57:06.591871 12979 solver.cpp:244]     Train net output #0: loss = 6.01095e-05 (* 1 = 6.01095e-05 loss)
I0822 16:57:06.591876 12979 sgd_solver.cpp:106] Iteration 96300, lr = 0.000267047
I0822 16:57:09.335894 12979 solver.cpp:228] Iteration 96400, loss = 4.87144e-05
I0822 16:57:09.335913 12979 solver.cpp:244]     Train net output #0: loss = 4.87144e-05 (* 1 = 4.87144e-05 loss)
I0822 16:57:09.335921 12979 sgd_solver.cpp:106] Iteration 96400, lr = 0.000266875
I0822 16:57:12.051105 12979 solver.cpp:337] Iteration 96500, Testing net (#0)
I0822 16:57:16.044124 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898387
I0822 16:57:16.044193 12979 solver.cpp:404]     Test net output #1: loss = 0.718799 (* 1 = 0.718799 loss)
I0822 16:57:16.052955 12979 solver.cpp:228] Iteration 96500, loss = 2.68885e-05
I0822 16:57:16.053001 12979 solver.cpp:244]     Train net output #0: loss = 2.68885e-05 (* 1 = 2.68885e-05 loss)
I0822 16:57:16.053012 12979 sgd_solver.cpp:106] Iteration 96500, lr = 0.000266703
I0822 16:57:18.797376 12979 solver.cpp:228] Iteration 96600, loss = 8.87751e-05
I0822 16:57:18.797410 12979 solver.cpp:244]     Train net output #0: loss = 8.87751e-05 (* 1 = 8.87751e-05 loss)
I0822 16:57:18.797416 12979 sgd_solver.cpp:106] Iteration 96600, lr = 0.000266532
I0822 16:57:21.544978 12979 solver.cpp:228] Iteration 96700, loss = 7.71752e-05
I0822 16:57:21.545037 12979 solver.cpp:244]     Train net output #0: loss = 7.71752e-05 (* 1 = 7.71752e-05 loss)
I0822 16:57:21.545049 12979 sgd_solver.cpp:106] Iteration 96700, lr = 0.00026636
I0822 16:57:24.287297 12979 solver.cpp:228] Iteration 96800, loss = 3.8709e-05
I0822 16:57:24.287314 12979 solver.cpp:244]     Train net output #0: loss = 3.8709e-05 (* 1 = 3.8709e-05 loss)
I0822 16:57:24.287318 12979 sgd_solver.cpp:106] Iteration 96800, lr = 0.000266189
I0822 16:57:27.026172 12979 solver.cpp:228] Iteration 96900, loss = 7.11746e-05
I0822 16:57:27.026191 12979 solver.cpp:244]     Train net output #0: loss = 7.11746e-05 (* 1 = 7.11746e-05 loss)
I0822 16:57:27.026196 12979 sgd_solver.cpp:106] Iteration 96900, lr = 0.000266018
I0822 16:57:29.738541 12979 solver.cpp:337] Iteration 97000, Testing net (#0)
I0822 16:57:30.076522 12979 blocking_queue.cpp:50] Data layer prefetch queue empty
I0822 16:57:33.717928 12979 solver.cpp:404]     Test net output #0: accuracy = 0.897419
I0822 16:57:33.717994 12979 solver.cpp:404]     Test net output #1: loss = 0.729085 (* 1 = 0.729085 loss)
I0822 16:57:33.726814 12979 solver.cpp:228] Iteration 97000, loss = 3.67949e-05
I0822 16:57:33.726860 12979 solver.cpp:244]     Train net output #0: loss = 3.67949e-05 (* 1 = 3.67949e-05 loss)
I0822 16:57:33.726871 12979 sgd_solver.cpp:106] Iteration 97000, lr = 0.000265848
I0822 16:57:36.467809 12979 solver.cpp:228] Iteration 97100, loss = 6.18929e-05
I0822 16:57:36.467847 12979 solver.cpp:244]     Train net output #0: loss = 6.18929e-05 (* 1 = 6.18929e-05 loss)
I0822 16:57:36.467854 12979 sgd_solver.cpp:106] Iteration 97100, lr = 0.000265678
I0822 16:57:39.206586 12979 solver.cpp:228] Iteration 97200, loss = 5.73175e-05
I0822 16:57:39.206604 12979 solver.cpp:244]     Train net output #0: loss = 5.73175e-05 (* 1 = 5.73175e-05 loss)
I0822 16:57:39.206609 12979 sgd_solver.cpp:106] Iteration 97200, lr = 0.000265508
I0822 16:57:41.945174 12979 solver.cpp:228] Iteration 97300, loss = 6.23047e-05
I0822 16:57:41.945191 12979 solver.cpp:244]     Train net output #0: loss = 6.23047e-05 (* 1 = 6.23047e-05 loss)
I0822 16:57:41.945196 12979 sgd_solver.cpp:106] Iteration 97300, lr = 0.000265338
I0822 16:57:44.683303 12979 solver.cpp:228] Iteration 97400, loss = 3.28559e-05
I0822 16:57:44.683321 12979 solver.cpp:244]     Train net output #0: loss = 3.28559e-05 (* 1 = 3.28559e-05 loss)
I0822 16:57:44.683326 12979 sgd_solver.cpp:106] Iteration 97400, lr = 0.000265168
I0822 16:57:47.397188 12979 solver.cpp:337] Iteration 97500, Testing net (#0)
I0822 16:57:51.404887 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898193
I0822 16:57:51.404950 12979 solver.cpp:404]     Test net output #1: loss = 0.721701 (* 1 = 0.721701 loss)
I0822 16:57:51.413734 12979 solver.cpp:228] Iteration 97500, loss = 1.97178e-05
I0822 16:57:51.413794 12979 solver.cpp:244]     Train net output #0: loss = 1.97178e-05 (* 1 = 1.97178e-05 loss)
I0822 16:57:51.413806 12979 sgd_solver.cpp:106] Iteration 97500, lr = 0.000264999
I0822 16:57:54.160485 12979 solver.cpp:228] Iteration 97600, loss = 8.93862e-05
I0822 16:57:54.160531 12979 solver.cpp:244]     Train net output #0: loss = 8.93862e-05 (* 1 = 8.93862e-05 loss)
I0822 16:57:54.160537 12979 sgd_solver.cpp:106] Iteration 97600, lr = 0.00026483
I0822 16:57:56.915622 12979 solver.cpp:228] Iteration 97700, loss = 3.92335e-05
I0822 16:57:56.915671 12979 solver.cpp:244]     Train net output #0: loss = 3.92335e-05 (* 1 = 3.92335e-05 loss)
I0822 16:57:56.915679 12979 sgd_solver.cpp:106] Iteration 97700, lr = 0.000264661
I0822 16:57:59.656937 12979 solver.cpp:228] Iteration 97800, loss = 4.7419e-05
I0822 16:57:59.656954 12979 solver.cpp:244]     Train net output #0: loss = 4.7419e-05 (* 1 = 4.7419e-05 loss)
I0822 16:57:59.656958 12979 sgd_solver.cpp:106] Iteration 97800, lr = 0.000264493
I0822 16:58:02.400425 12979 solver.cpp:228] Iteration 97900, loss = 4.8905e-05
I0822 16:58:02.400442 12979 solver.cpp:244]     Train net output #0: loss = 4.8905e-05 (* 1 = 4.8905e-05 loss)
I0822 16:58:02.400447 12979 sgd_solver.cpp:106] Iteration 97900, lr = 0.000264324
I0822 16:58:05.117854 12979 solver.cpp:337] Iteration 98000, Testing net (#0)
I0822 16:58:09.114259 12979 solver.cpp:404]     Test net output #0: accuracy = 0.89829
I0822 16:58:09.114323 12979 solver.cpp:404]     Test net output #1: loss = 0.720743 (* 1 = 0.720743 loss)
I0822 16:58:09.123921 12979 solver.cpp:228] Iteration 98000, loss = 2.90141e-05
I0822 16:58:09.123978 12979 solver.cpp:244]     Train net output #0: loss = 2.90141e-05 (* 1 = 2.90141e-05 loss)
I0822 16:58:09.123999 12979 sgd_solver.cpp:106] Iteration 98000, lr = 0.000264156
I0822 16:58:11.860841 12979 solver.cpp:228] Iteration 98100, loss = 5.95275e-05
I0822 16:58:11.860877 12979 solver.cpp:244]     Train net output #0: loss = 5.95275e-05 (* 1 = 5.95275e-05 loss)
I0822 16:58:11.860883 12979 sgd_solver.cpp:106] Iteration 98100, lr = 0.000263989
I0822 16:58:14.599017 12979 solver.cpp:228] Iteration 98200, loss = 2.64181e-05
I0822 16:58:14.599058 12979 solver.cpp:244]     Train net output #0: loss = 2.64181e-05 (* 1 = 2.64181e-05 loss)
I0822 16:58:14.599063 12979 sgd_solver.cpp:106] Iteration 98200, lr = 0.000263821
I0822 16:58:17.330041 12979 solver.cpp:228] Iteration 98300, loss = 5.37685e-05
I0822 16:58:17.330059 12979 solver.cpp:244]     Train net output #0: loss = 5.37685e-05 (* 1 = 5.37685e-05 loss)
I0822 16:58:17.330062 12979 sgd_solver.cpp:106] Iteration 98300, lr = 0.000263654
I0822 16:58:20.080590 12979 solver.cpp:228] Iteration 98400, loss = 6.31584e-05
I0822 16:58:20.080651 12979 solver.cpp:244]     Train net output #0: loss = 6.31584e-05 (* 1 = 6.31584e-05 loss)
I0822 16:58:20.080662 12979 sgd_solver.cpp:106] Iteration 98400, lr = 0.000263487
I0822 16:58:22.793377 12979 solver.cpp:337] Iteration 98500, Testing net (#0)
I0822 16:58:26.807114 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898548
I0822 16:58:26.807171 12979 solver.cpp:404]     Test net output #1: loss = 0.720554 (* 1 = 0.720554 loss)
I0822 16:58:26.815940 12979 solver.cpp:228] Iteration 98500, loss = 4.66827e-05
I0822 16:58:26.815981 12979 solver.cpp:244]     Train net output #0: loss = 4.66827e-05 (* 1 = 4.66827e-05 loss)
I0822 16:58:26.815992 12979 sgd_solver.cpp:106] Iteration 98500, lr = 0.00026332
I0822 16:58:29.559202 12979 solver.cpp:228] Iteration 98600, loss = 2.24189e-05
I0822 16:58:29.559237 12979 solver.cpp:244]     Train net output #0: loss = 2.24189e-05 (* 1 = 2.24189e-05 loss)
I0822 16:58:29.559242 12979 sgd_solver.cpp:106] Iteration 98600, lr = 0.000263153
I0822 16:58:32.296627 12979 solver.cpp:228] Iteration 98700, loss = 2.33084e-05
I0822 16:58:32.296643 12979 solver.cpp:244]     Train net output #0: loss = 2.33084e-05 (* 1 = 2.33084e-05 loss)
I0822 16:58:32.296648 12979 sgd_solver.cpp:106] Iteration 98700, lr = 0.000262987
I0822 16:58:35.038261 12979 solver.cpp:228] Iteration 98800, loss = 2.97664e-05
I0822 16:58:35.038280 12979 solver.cpp:244]     Train net output #0: loss = 2.97664e-05 (* 1 = 2.97664e-05 loss)
I0822 16:58:35.038285 12979 sgd_solver.cpp:106] Iteration 98800, lr = 0.000262821
I0822 16:58:37.777861 12979 solver.cpp:228] Iteration 98900, loss = 7.23117e-05
I0822 16:58:37.777878 12979 solver.cpp:244]     Train net output #0: loss = 7.23117e-05 (* 1 = 7.23117e-05 loss)
I0822 16:58:37.777884 12979 sgd_solver.cpp:106] Iteration 98900, lr = 0.000262655
I0822 16:58:40.491591 12979 solver.cpp:337] Iteration 99000, Testing net (#0)
I0822 16:58:44.574389 12979 solver.cpp:404]     Test net output #0: accuracy = 0.896967
I0822 16:58:44.574427 12979 solver.cpp:404]     Test net output #1: loss = 0.734352 (* 1 = 0.734352 loss)
I0822 16:58:44.583071 12979 solver.cpp:228] Iteration 99000, loss = 3.32751e-05
I0822 16:58:44.583088 12979 solver.cpp:244]     Train net output #0: loss = 3.32751e-05 (* 1 = 3.32751e-05 loss)
I0822 16:58:44.583096 12979 sgd_solver.cpp:106] Iteration 99000, lr = 0.00026249
I0822 16:58:47.336624 12979 solver.cpp:228] Iteration 99100, loss = 4.34877e-05
I0822 16:58:47.336673 12979 solver.cpp:244]     Train net output #0: loss = 4.34877e-05 (* 1 = 4.34877e-05 loss)
I0822 16:58:47.336684 12979 sgd_solver.cpp:106] Iteration 99100, lr = 0.000262324
I0822 16:58:50.086740 12979 solver.cpp:228] Iteration 99200, loss = 4.14347e-05
I0822 16:58:50.086788 12979 solver.cpp:244]     Train net output #0: loss = 4.14347e-05 (* 1 = 4.14347e-05 loss)
I0822 16:58:50.086796 12979 sgd_solver.cpp:106] Iteration 99200, lr = 0.000262159
I0822 16:58:52.829669 12979 solver.cpp:228] Iteration 99300, loss = 5.71119e-05
I0822 16:58:52.829697 12979 solver.cpp:244]     Train net output #0: loss = 5.71119e-05 (* 1 = 5.71119e-05 loss)
I0822 16:58:52.829702 12979 sgd_solver.cpp:106] Iteration 99300, lr = 0.000261995
I0822 16:58:55.576354 12979 solver.cpp:228] Iteration 99400, loss = 2.79789e-05
I0822 16:58:55.576371 12979 solver.cpp:244]     Train net output #0: loss = 2.79789e-05 (* 1 = 2.79789e-05 loss)
I0822 16:58:55.576376 12979 sgd_solver.cpp:106] Iteration 99400, lr = 0.00026183
I0822 16:58:58.293718 12979 solver.cpp:337] Iteration 99500, Testing net (#0)
I0822 16:59:02.421164 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898677
I0822 16:59:02.421227 12979 solver.cpp:404]     Test net output #1: loss = 0.719008 (* 1 = 0.719008 loss)
I0822 16:59:02.430835 12979 solver.cpp:228] Iteration 99500, loss = 4.45038e-05
I0822 16:59:02.430896 12979 solver.cpp:244]     Train net output #0: loss = 4.45038e-05 (* 1 = 4.45038e-05 loss)
I0822 16:59:02.430915 12979 sgd_solver.cpp:106] Iteration 99500, lr = 0.000261666
I0822 16:59:05.173324 12979 solver.cpp:228] Iteration 99600, loss = 2.98882e-05
I0822 16:59:05.173362 12979 solver.cpp:244]     Train net output #0: loss = 2.98882e-05 (* 1 = 2.98882e-05 loss)
I0822 16:59:05.173367 12979 sgd_solver.cpp:106] Iteration 99600, lr = 0.000261501
I0822 16:59:07.915170 12979 solver.cpp:228] Iteration 99700, loss = 2.38492e-05
I0822 16:59:07.915189 12979 solver.cpp:244]     Train net output #0: loss = 2.38492e-05 (* 1 = 2.38492e-05 loss)
I0822 16:59:07.915194 12979 sgd_solver.cpp:106] Iteration 99700, lr = 0.000261338
I0822 16:59:10.661520 12979 solver.cpp:228] Iteration 99800, loss = 0.000103335
I0822 16:59:10.661556 12979 solver.cpp:244]     Train net output #0: loss = 0.000103335 (* 1 = 0.000103335 loss)
I0822 16:59:10.661562 12979 sgd_solver.cpp:106] Iteration 99800, lr = 0.000261174
I0822 16:59:13.409399 12979 solver.cpp:228] Iteration 99900, loss = 7.20756e-05
I0822 16:59:13.409476 12979 solver.cpp:244]     Train net output #0: loss = 7.20756e-05 (* 1 = 7.20756e-05 loss)
I0822 16:59:13.409492 12979 sgd_solver.cpp:106] Iteration 99900, lr = 0.000261011
I0822 16:59:16.134722 12979 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_100000.caffemodel
I0822 16:59:16.757035 12979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random_alex_net/person_background_and_random_alex_net_lr_0.001_iter_100000.solverstate
I0822 16:59:16.966671 12979 solver.cpp:337] Iteration 100000, Testing net (#0)
I0822 16:59:20.940652 12979 solver.cpp:404]     Test net output #0: accuracy = 0.898323
I0822 16:59:20.940713 12979 solver.cpp:404]     Test net output #1: loss = 0.723521 (* 1 = 0.723521 loss)
I0822 16:59:20.950235 12979 solver.cpp:228] Iteration 100000, loss = 8.58321e-05
I0822 16:59:20.950295 12979 solver.cpp:244]     Train net output #0: loss = 8.58321e-05 (* 1 = 8.58321e-05 loss)
I0822 16:59:20.950314 12979 sgd_solver.cpp:106] Iteration 100000, lr = 0.000260847
nets/person_background_and_random_alex_net/solver.prototxt
