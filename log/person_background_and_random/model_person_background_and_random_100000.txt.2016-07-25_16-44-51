WARNING: Logging before InitGoogleLogging() is written to STDERR
I0725 16:44:53.051751 20892 solver.cpp:48] Initializing solver from parameters: 
test_iter: 310
test_interval: 500
base_lr: 1e-05
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
snapshot: 5000
snapshot_prefix: "models/person_background_and_random/person_background_and_random_lr_0.00001"
solver_mode: GPU
net: "nets/person_background_and_random/trainval.prototxt"
I0725 16:44:53.051831 20892 solver.cpp:91] Creating training net from net file: nets/person_background_and_random/trainval.prototxt
I0725 16:44:53.052080 20892 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0725 16:44:53.052103 20892 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0725 16:44:53.052160 20892 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 96
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0725 16:44:53.052201 20892 layer_factory.hpp:77] Creating layer mnist
I0725 16:44:53.052932 20892 net.cpp:91] Creating Layer mnist
I0725 16:44:53.052943 20892 net.cpp:399] mnist -> data
I0725 16:44:53.052965 20892 net.cpp:399] mnist -> label
I0725 16:44:53.052978 20892 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0725 16:44:53.054255 20899 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_train_lmdb
I0725 16:45:12.102217 20892 data_layer.cpp:41] output data size: 64,3,128,128
I0725 16:45:12.122400 20892 net.cpp:141] Setting up mnist
I0725 16:45:12.122450 20892 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0725 16:45:12.122457 20892 net.cpp:148] Top shape: 64 (64)
I0725 16:45:12.122460 20892 net.cpp:156] Memory required for data: 12583168
I0725 16:45:12.122468 20892 layer_factory.hpp:77] Creating layer conv1
I0725 16:45:12.122536 20892 net.cpp:91] Creating Layer conv1
I0725 16:45:12.122541 20892 net.cpp:425] conv1 <- data
I0725 16:45:12.122550 20892 net.cpp:399] conv1 -> conv1
I0725 16:45:12.249830 20892 net.cpp:141] Setting up conv1
I0725 16:45:12.249864 20892 net.cpp:148] Top shape: 64 96 124 124 (94470144)
I0725 16:45:12.249867 20892 net.cpp:156] Memory required for data: 390463744
I0725 16:45:12.249882 20892 layer_factory.hpp:77] Creating layer pool1
I0725 16:45:12.249897 20892 net.cpp:91] Creating Layer pool1
I0725 16:45:12.249900 20892 net.cpp:425] pool1 <- conv1
I0725 16:45:12.249904 20892 net.cpp:399] pool1 -> pool1
I0725 16:45:12.249959 20892 net.cpp:141] Setting up pool1
I0725 16:45:12.249965 20892 net.cpp:148] Top shape: 64 96 62 62 (23617536)
I0725 16:45:12.249969 20892 net.cpp:156] Memory required for data: 484933888
I0725 16:45:12.249971 20892 layer_factory.hpp:77] Creating layer conv2
I0725 16:45:12.249982 20892 net.cpp:91] Creating Layer conv2
I0725 16:45:12.249985 20892 net.cpp:425] conv2 <- pool1
I0725 16:45:12.249990 20892 net.cpp:399] conv2 -> conv2
I0725 16:45:12.252318 20892 net.cpp:141] Setting up conv2
I0725 16:45:12.252333 20892 net.cpp:148] Top shape: 64 50 58 58 (10764800)
I0725 16:45:12.252336 20892 net.cpp:156] Memory required for data: 527993088
I0725 16:45:12.252344 20892 layer_factory.hpp:77] Creating layer pool2
I0725 16:45:12.252351 20892 net.cpp:91] Creating Layer pool2
I0725 16:45:12.252353 20892 net.cpp:425] pool2 <- conv2
I0725 16:45:12.252357 20892 net.cpp:399] pool2 -> pool2
I0725 16:45:12.252404 20892 net.cpp:141] Setting up pool2
I0725 16:45:12.252410 20892 net.cpp:148] Top shape: 64 50 29 29 (2691200)
I0725 16:45:12.252413 20892 net.cpp:156] Memory required for data: 538757888
I0725 16:45:12.252415 20892 layer_factory.hpp:77] Creating layer ip1
I0725 16:45:12.252424 20892 net.cpp:91] Creating Layer ip1
I0725 16:45:12.252427 20892 net.cpp:425] ip1 <- pool2
I0725 16:45:12.252431 20892 net.cpp:399] ip1 -> ip1
I0725 16:45:12.400054 20892 net.cpp:141] Setting up ip1
I0725 16:45:12.400101 20892 net.cpp:148] Top shape: 64 500 (32000)
I0725 16:45:12.400115 20892 net.cpp:156] Memory required for data: 538885888
I0725 16:45:12.400131 20892 layer_factory.hpp:77] Creating layer relu1
I0725 16:45:12.400163 20892 net.cpp:91] Creating Layer relu1
I0725 16:45:12.400168 20892 net.cpp:425] relu1 <- ip1
I0725 16:45:12.400174 20892 net.cpp:386] relu1 -> ip1 (in-place)
I0725 16:45:12.400514 20892 net.cpp:141] Setting up relu1
I0725 16:45:12.400527 20892 net.cpp:148] Top shape: 64 500 (32000)
I0725 16:45:12.400540 20892 net.cpp:156] Memory required for data: 539013888
I0725 16:45:12.400544 20892 layer_factory.hpp:77] Creating layer ip2
I0725 16:45:12.400554 20892 net.cpp:91] Creating Layer ip2
I0725 16:45:12.400557 20892 net.cpp:425] ip2 <- ip1
I0725 16:45:12.400563 20892 net.cpp:399] ip2 -> ip2
I0725 16:45:12.400671 20892 net.cpp:141] Setting up ip2
I0725 16:45:12.400679 20892 net.cpp:148] Top shape: 64 2 (128)
I0725 16:45:12.400682 20892 net.cpp:156] Memory required for data: 539014400
I0725 16:45:12.400687 20892 layer_factory.hpp:77] Creating layer loss
I0725 16:45:12.400699 20892 net.cpp:91] Creating Layer loss
I0725 16:45:12.400702 20892 net.cpp:425] loss <- ip2
I0725 16:45:12.400705 20892 net.cpp:425] loss <- label
I0725 16:45:12.400710 20892 net.cpp:399] loss -> loss
I0725 16:45:12.400719 20892 layer_factory.hpp:77] Creating layer loss
I0725 16:45:12.400943 20892 net.cpp:141] Setting up loss
I0725 16:45:12.400954 20892 net.cpp:148] Top shape: (1)
I0725 16:45:12.400967 20892 net.cpp:151]     with loss weight 1
I0725 16:45:12.400986 20892 net.cpp:156] Memory required for data: 539014404
I0725 16:45:12.400990 20892 net.cpp:217] loss needs backward computation.
I0725 16:45:12.400992 20892 net.cpp:217] ip2 needs backward computation.
I0725 16:45:12.400995 20892 net.cpp:217] relu1 needs backward computation.
I0725 16:45:12.400998 20892 net.cpp:217] ip1 needs backward computation.
I0725 16:45:12.401000 20892 net.cpp:217] pool2 needs backward computation.
I0725 16:45:12.401003 20892 net.cpp:217] conv2 needs backward computation.
I0725 16:45:12.401006 20892 net.cpp:217] pool1 needs backward computation.
I0725 16:45:12.401021 20892 net.cpp:217] conv1 needs backward computation.
I0725 16:45:12.401024 20892 net.cpp:219] mnist does not need backward computation.
I0725 16:45:12.401026 20892 net.cpp:261] This network produces output loss
I0725 16:45:12.401046 20892 net.cpp:274] Network initialization done.
I0725 16:45:12.401399 20892 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_background_and_random/trainval.prototxt
I0725 16:45:12.401437 20892 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0725 16:45:12.401516 20892 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_and_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_and_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 96
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0725 16:45:12.401569 20892 layer_factory.hpp:77] Creating layer mnist
I0725 16:45:12.401667 20892 net.cpp:91] Creating Layer mnist
I0725 16:45:12.401676 20892 net.cpp:399] mnist -> data
I0725 16:45:12.401682 20892 net.cpp:399] mnist -> label
I0725 16:45:12.401690 20892 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_and_random_color_mean.binaryproto
I0725 16:45:12.402812 20902 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_and_random_test_lmdb
I0725 16:45:12.402993 20892 data_layer.cpp:41] output data size: 100,3,128,128
I0725 16:45:12.435677 20892 net.cpp:141] Setting up mnist
I0725 16:45:12.435715 20892 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0725 16:45:12.435721 20892 net.cpp:148] Top shape: 100 (100)
I0725 16:45:12.435724 20892 net.cpp:156] Memory required for data: 19661200
I0725 16:45:12.435730 20892 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0725 16:45:12.435744 20892 net.cpp:91] Creating Layer label_mnist_1_split
I0725 16:45:12.435748 20892 net.cpp:425] label_mnist_1_split <- label
I0725 16:45:12.435755 20892 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0725 16:45:12.435765 20892 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0725 16:45:12.436051 20892 net.cpp:141] Setting up label_mnist_1_split
I0725 16:45:12.436076 20892 net.cpp:148] Top shape: 100 (100)
I0725 16:45:12.436080 20892 net.cpp:148] Top shape: 100 (100)
I0725 16:45:12.436084 20892 net.cpp:156] Memory required for data: 19662000
I0725 16:45:12.436086 20892 layer_factory.hpp:77] Creating layer conv1
I0725 16:45:12.436100 20892 net.cpp:91] Creating Layer conv1
I0725 16:45:12.436103 20892 net.cpp:425] conv1 <- data
I0725 16:45:12.436110 20892 net.cpp:399] conv1 -> conv1
I0725 16:45:12.437273 20892 net.cpp:141] Setting up conv1
I0725 16:45:12.437288 20892 net.cpp:148] Top shape: 100 96 124 124 (147609600)
I0725 16:45:12.437290 20892 net.cpp:156] Memory required for data: 610100400
I0725 16:45:12.437300 20892 layer_factory.hpp:77] Creating layer pool1
I0725 16:45:12.437309 20892 net.cpp:91] Creating Layer pool1
I0725 16:45:12.437312 20892 net.cpp:425] pool1 <- conv1
I0725 16:45:12.437317 20892 net.cpp:399] pool1 -> pool1
I0725 16:45:12.440433 20892 net.cpp:141] Setting up pool1
I0725 16:45:12.440469 20892 net.cpp:148] Top shape: 100 96 62 62 (36902400)
I0725 16:45:12.440477 20892 net.cpp:156] Memory required for data: 757710000
I0725 16:45:12.440485 20892 layer_factory.hpp:77] Creating layer conv2
I0725 16:45:12.440508 20892 net.cpp:91] Creating Layer conv2
I0725 16:45:12.440517 20892 net.cpp:425] conv2 <- pool1
I0725 16:45:12.440531 20892 net.cpp:399] conv2 -> conv2
I0725 16:45:12.442195 20892 net.cpp:141] Setting up conv2
I0725 16:45:12.442209 20892 net.cpp:148] Top shape: 100 50 58 58 (16820000)
I0725 16:45:12.442211 20892 net.cpp:156] Memory required for data: 824990000
I0725 16:45:12.442219 20892 layer_factory.hpp:77] Creating layer pool2
I0725 16:45:12.442225 20892 net.cpp:91] Creating Layer pool2
I0725 16:45:12.442229 20892 net.cpp:425] pool2 <- conv2
I0725 16:45:12.442234 20892 net.cpp:399] pool2 -> pool2
I0725 16:45:12.442268 20892 net.cpp:141] Setting up pool2
I0725 16:45:12.442286 20892 net.cpp:148] Top shape: 100 50 29 29 (4205000)
I0725 16:45:12.442291 20892 net.cpp:156] Memory required for data: 841810000
I0725 16:45:12.442293 20892 layer_factory.hpp:77] Creating layer ip1
I0725 16:45:12.442315 20892 net.cpp:91] Creating Layer ip1
I0725 16:45:12.442318 20892 net.cpp:425] ip1 <- pool2
I0725 16:45:12.442323 20892 net.cpp:399] ip1 -> ip1
I0725 16:45:12.589807 20892 net.cpp:141] Setting up ip1
I0725 16:45:12.589844 20892 net.cpp:148] Top shape: 100 500 (50000)
I0725 16:45:12.589848 20892 net.cpp:156] Memory required for data: 842010000
I0725 16:45:12.589862 20892 layer_factory.hpp:77] Creating layer relu1
I0725 16:45:12.589874 20892 net.cpp:91] Creating Layer relu1
I0725 16:45:12.589879 20892 net.cpp:425] relu1 <- ip1
I0725 16:45:12.589885 20892 net.cpp:386] relu1 -> ip1 (in-place)
I0725 16:45:12.590318 20892 net.cpp:141] Setting up relu1
I0725 16:45:12.590330 20892 net.cpp:148] Top shape: 100 500 (50000)
I0725 16:45:12.590344 20892 net.cpp:156] Memory required for data: 842210000
I0725 16:45:12.590348 20892 layer_factory.hpp:77] Creating layer ip2
I0725 16:45:12.590356 20892 net.cpp:91] Creating Layer ip2
I0725 16:45:12.590359 20892 net.cpp:425] ip2 <- ip1
I0725 16:45:12.590365 20892 net.cpp:399] ip2 -> ip2
I0725 16:45:12.590483 20892 net.cpp:141] Setting up ip2
I0725 16:45:12.590490 20892 net.cpp:148] Top shape: 100 2 (200)
I0725 16:45:12.590503 20892 net.cpp:156] Memory required for data: 842210800
I0725 16:45:12.590508 20892 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0725 16:45:12.590514 20892 net.cpp:91] Creating Layer ip2_ip2_0_split
I0725 16:45:12.590517 20892 net.cpp:425] ip2_ip2_0_split <- ip2
I0725 16:45:12.590523 20892 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0725 16:45:12.590528 20892 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0725 16:45:12.590559 20892 net.cpp:141] Setting up ip2_ip2_0_split
I0725 16:45:12.590566 20892 net.cpp:148] Top shape: 100 2 (200)
I0725 16:45:12.590580 20892 net.cpp:148] Top shape: 100 2 (200)
I0725 16:45:12.590584 20892 net.cpp:156] Memory required for data: 842212400
I0725 16:45:12.590586 20892 layer_factory.hpp:77] Creating layer accuracy
I0725 16:45:12.590592 20892 net.cpp:91] Creating Layer accuracy
I0725 16:45:12.590595 20892 net.cpp:425] accuracy <- ip2_ip2_0_split_0
I0725 16:45:12.590600 20892 net.cpp:425] accuracy <- label_mnist_1_split_0
I0725 16:45:12.590605 20892 net.cpp:399] accuracy -> accuracy
I0725 16:45:12.590611 20892 net.cpp:141] Setting up accuracy
I0725 16:45:12.590615 20892 net.cpp:148] Top shape: (1)
I0725 16:45:12.590617 20892 net.cpp:156] Memory required for data: 842212404
I0725 16:45:12.590620 20892 layer_factory.hpp:77] Creating layer loss
I0725 16:45:12.590636 20892 net.cpp:91] Creating Layer loss
I0725 16:45:12.590638 20892 net.cpp:425] loss <- ip2_ip2_0_split_1
I0725 16:45:12.590642 20892 net.cpp:425] loss <- label_mnist_1_split_1
I0725 16:45:12.590646 20892 net.cpp:399] loss -> loss
I0725 16:45:12.590653 20892 layer_factory.hpp:77] Creating layer loss
I0725 16:45:12.590911 20892 net.cpp:141] Setting up loss
I0725 16:45:12.590922 20892 net.cpp:148] Top shape: (1)
I0725 16:45:12.590936 20892 net.cpp:151]     with loss weight 1
I0725 16:45:12.590958 20892 net.cpp:156] Memory required for data: 842212408
I0725 16:45:12.590961 20892 net.cpp:217] loss needs backward computation.
I0725 16:45:12.590976 20892 net.cpp:219] accuracy does not need backward computation.
I0725 16:45:12.590979 20892 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0725 16:45:12.590982 20892 net.cpp:217] ip2 needs backward computation.
I0725 16:45:12.590986 20892 net.cpp:217] relu1 needs backward computation.
I0725 16:45:12.590987 20892 net.cpp:217] ip1 needs backward computation.
I0725 16:45:12.590991 20892 net.cpp:217] pool2 needs backward computation.
I0725 16:45:12.590993 20892 net.cpp:217] conv2 needs backward computation.
I0725 16:45:12.590996 20892 net.cpp:217] pool1 needs backward computation.
I0725 16:45:12.590999 20892 net.cpp:217] conv1 needs backward computation.
I0725 16:45:12.591002 20892 net.cpp:219] label_mnist_1_split does not need backward computation.
I0725 16:45:12.591006 20892 net.cpp:219] mnist does not need backward computation.
I0725 16:45:12.591008 20892 net.cpp:261] This network produces output accuracy
I0725 16:45:12.591012 20892 net.cpp:261] This network produces output loss
I0725 16:45:12.591020 20892 net.cpp:274] Network initialization done.
I0725 16:45:12.591116 20892 solver.cpp:60] Solver scaffolding done.
I0725 16:45:12.593024 20892 solver.cpp:337] Iteration 0, Testing net (#0)
I0725 16:45:12.974992 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 16:45:25.265465 20892 solver.cpp:404]     Test net output #0: accuracy = 0.537032
I0725 16:45:25.265524 20892 solver.cpp:404]     Test net output #1: loss = 0.689437 (* 1 = 0.689437 loss)
I0725 16:45:25.297997 20892 solver.cpp:228] Iteration 0, loss = 0.689723
I0725 16:45:25.298063 20892 solver.cpp:244]     Train net output #0: loss = 0.689723 (* 1 = 0.689723 loss)
I0725 16:45:25.298080 20892 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0725 16:45:33.791535 20892 solver.cpp:228] Iteration 100, loss = 0.6682
I0725 16:45:33.791599 20892 solver.cpp:244]     Train net output #0: loss = 0.6682 (* 1 = 0.6682 loss)
I0725 16:45:33.791605 20892 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-06
I0725 16:45:42.324659 20892 solver.cpp:228] Iteration 200, loss = 0.656586
I0725 16:45:42.324708 20892 solver.cpp:244]     Train net output #0: loss = 0.656586 (* 1 = 0.656586 loss)
I0725 16:45:42.324715 20892 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-06
I0725 16:45:51.051080 20892 solver.cpp:228] Iteration 300, loss = 0.675266
I0725 16:45:51.051136 20892 solver.cpp:244]     Train net output #0: loss = 0.675266 (* 1 = 0.675266 loss)
I0725 16:45:51.051143 20892 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-06
I0725 16:46:00.650542 20892 solver.cpp:228] Iteration 400, loss = 0.604726
I0725 16:46:00.650588 20892 solver.cpp:244]     Train net output #0: loss = 0.604726 (* 1 = 0.604726 loss)
I0725 16:46:00.650593 20892 sgd_solver.cpp:106] Iteration 400, lr = 9.85258e-06
I0725 16:46:10.070212 20892 solver.cpp:337] Iteration 500, Testing net (#0)
I0725 16:46:23.929318 20892 solver.cpp:404]     Test net output #0: accuracy = 0.579968
I0725 16:46:23.929360 20892 solver.cpp:404]     Test net output #1: loss = 0.610816 (* 1 = 0.610816 loss)
I0725 16:46:23.956161 20892 solver.cpp:228] Iteration 500, loss = 0.634867
I0725 16:46:23.956195 20892 solver.cpp:244]     Train net output #0: loss = 0.634867 (* 1 = 0.634867 loss)
I0725 16:46:23.956208 20892 sgd_solver.cpp:106] Iteration 500, lr = 9.81651e-06
I0725 16:46:33.265971 20892 solver.cpp:228] Iteration 600, loss = 0.663558
I0725 16:46:33.266026 20892 solver.cpp:244]     Train net output #0: loss = 0.663558 (* 1 = 0.663558 loss)
I0725 16:46:33.266032 20892 sgd_solver.cpp:106] Iteration 600, lr = 9.78075e-06
I0725 16:46:42.632949 20892 solver.cpp:228] Iteration 700, loss = 0.646294
I0725 16:46:42.632994 20892 solver.cpp:244]     Train net output #0: loss = 0.646294 (* 1 = 0.646294 loss)
I0725 16:46:42.633000 20892 sgd_solver.cpp:106] Iteration 700, lr = 9.74529e-06
I0725 16:46:52.050688 20892 solver.cpp:228] Iteration 800, loss = 0.687724
I0725 16:46:52.050740 20892 solver.cpp:244]     Train net output #0: loss = 0.687724 (* 1 = 0.687724 loss)
I0725 16:46:52.050746 20892 sgd_solver.cpp:106] Iteration 800, lr = 9.71013e-06
I0725 16:47:01.487103 20892 solver.cpp:228] Iteration 900, loss = 0.650752
I0725 16:47:01.487150 20892 solver.cpp:244]     Train net output #0: loss = 0.650752 (* 1 = 0.650752 loss)
I0725 16:47:01.487156 20892 sgd_solver.cpp:106] Iteration 900, lr = 9.67526e-06
I0725 16:47:10.814070 20892 solver.cpp:337] Iteration 1000, Testing net (#0)
I0725 16:47:24.889892 20892 solver.cpp:404]     Test net output #0: accuracy = 0.621645
I0725 16:47:24.889955 20892 solver.cpp:404]     Test net output #1: loss = 0.596782 (* 1 = 0.596782 loss)
I0725 16:47:24.919457 20892 solver.cpp:228] Iteration 1000, loss = 0.642618
I0725 16:47:24.919524 20892 solver.cpp:244]     Train net output #0: loss = 0.642618 (* 1 = 0.642618 loss)
I0725 16:47:24.919538 20892 sgd_solver.cpp:106] Iteration 1000, lr = 9.64069e-06
I0725 16:47:34.314208 20892 solver.cpp:228] Iteration 1100, loss = 0.673957
I0725 16:47:34.314288 20892 solver.cpp:244]     Train net output #0: loss = 0.673957 (* 1 = 0.673957 loss)
I0725 16:47:34.314296 20892 sgd_solver.cpp:106] Iteration 1100, lr = 9.6064e-06
I0725 16:47:43.731043 20892 solver.cpp:228] Iteration 1200, loss = 0.569919
I0725 16:47:43.731088 20892 solver.cpp:244]     Train net output #0: loss = 0.569919 (* 1 = 0.569919 loss)
I0725 16:47:43.731094 20892 sgd_solver.cpp:106] Iteration 1200, lr = 9.5724e-06
I0725 16:47:53.149390 20892 solver.cpp:228] Iteration 1300, loss = 0.595464
I0725 16:47:53.149443 20892 solver.cpp:244]     Train net output #0: loss = 0.595464 (* 1 = 0.595464 loss)
I0725 16:47:53.149452 20892 sgd_solver.cpp:106] Iteration 1300, lr = 9.53867e-06
I0725 16:48:02.569589 20892 solver.cpp:228] Iteration 1400, loss = 0.660431
I0725 16:48:02.569627 20892 solver.cpp:244]     Train net output #0: loss = 0.660431 (* 1 = 0.660431 loss)
I0725 16:48:02.569633 20892 sgd_solver.cpp:106] Iteration 1400, lr = 9.50522e-06
I0725 16:48:11.892969 20892 solver.cpp:337] Iteration 1500, Testing net (#0)
I0725 16:48:26.116881 20892 solver.cpp:404]     Test net output #0: accuracy = 0.636806
I0725 16:48:26.116945 20892 solver.cpp:404]     Test net output #1: loss = 0.587454 (* 1 = 0.587454 loss)
I0725 16:48:26.146960 20892 solver.cpp:228] Iteration 1500, loss = 0.640396
I0725 16:48:26.147029 20892 solver.cpp:244]     Train net output #0: loss = 0.640396 (* 1 = 0.640396 loss)
I0725 16:48:26.147050 20892 sgd_solver.cpp:106] Iteration 1500, lr = 9.47204e-06
I0725 16:48:35.489891 20892 solver.cpp:228] Iteration 1600, loss = 0.650484
I0725 16:48:35.489956 20892 solver.cpp:244]     Train net output #0: loss = 0.650484 (* 1 = 0.650484 loss)
I0725 16:48:35.489964 20892 sgd_solver.cpp:106] Iteration 1600, lr = 9.43913e-06
I0725 16:48:44.906258 20892 solver.cpp:228] Iteration 1700, loss = 0.591729
I0725 16:48:44.906316 20892 solver.cpp:244]     Train net output #0: loss = 0.591729 (* 1 = 0.591729 loss)
I0725 16:48:44.906322 20892 sgd_solver.cpp:106] Iteration 1700, lr = 9.40649e-06
I0725 16:48:54.318621 20892 solver.cpp:228] Iteration 1800, loss = 0.691084
I0725 16:48:54.318678 20892 solver.cpp:244]     Train net output #0: loss = 0.691084 (* 1 = 0.691084 loss)
I0725 16:48:54.318686 20892 sgd_solver.cpp:106] Iteration 1800, lr = 9.37411e-06
I0725 16:49:01.962927 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 16:49:03.780773 20892 solver.cpp:228] Iteration 1900, loss = 0.56864
I0725 16:49:03.780817 20892 solver.cpp:244]     Train net output #0: loss = 0.56864 (* 1 = 0.56864 loss)
I0725 16:49:03.780823 20892 sgd_solver.cpp:106] Iteration 1900, lr = 9.34199e-06
I0725 16:49:13.263962 20892 solver.cpp:337] Iteration 2000, Testing net (#0)
I0725 16:49:27.282258 20892 solver.cpp:404]     Test net output #0: accuracy = 0.666194
I0725 16:49:27.282310 20892 solver.cpp:404]     Test net output #1: loss = 0.5741 (* 1 = 0.5741 loss)
I0725 16:49:27.313539 20892 solver.cpp:228] Iteration 2000, loss = 0.612133
I0725 16:49:27.313602 20892 solver.cpp:244]     Train net output #0: loss = 0.612133 (* 1 = 0.612133 loss)
I0725 16:49:27.313621 20892 sgd_solver.cpp:106] Iteration 2000, lr = 9.31012e-06
I0725 16:49:36.744856 20892 solver.cpp:228] Iteration 2100, loss = 0.572453
I0725 16:49:36.744911 20892 solver.cpp:244]     Train net output #0: loss = 0.572453 (* 1 = 0.572453 loss)
I0725 16:49:36.744918 20892 sgd_solver.cpp:106] Iteration 2100, lr = 9.27851e-06
I0725 16:49:46.324942 20892 solver.cpp:228] Iteration 2200, loss = 0.609533
I0725 16:49:46.324985 20892 solver.cpp:244]     Train net output #0: loss = 0.609533 (* 1 = 0.609533 loss)
I0725 16:49:46.324992 20892 sgd_solver.cpp:106] Iteration 2200, lr = 9.24715e-06
I0725 16:49:55.905402 20892 solver.cpp:228] Iteration 2300, loss = 0.566646
I0725 16:49:55.905458 20892 solver.cpp:244]     Train net output #0: loss = 0.566646 (* 1 = 0.566646 loss)
I0725 16:49:55.905467 20892 sgd_solver.cpp:106] Iteration 2300, lr = 9.21603e-06
I0725 16:50:05.330827 20892 solver.cpp:228] Iteration 2400, loss = 0.611294
I0725 16:50:05.330869 20892 solver.cpp:244]     Train net output #0: loss = 0.611294 (* 1 = 0.611294 loss)
I0725 16:50:05.330876 20892 sgd_solver.cpp:106] Iteration 2400, lr = 9.18515e-06
I0725 16:50:14.660578 20892 solver.cpp:337] Iteration 2500, Testing net (#0)
I0725 16:50:28.742260 20892 solver.cpp:404]     Test net output #0: accuracy = 0.689387
I0725 16:50:28.742328 20892 solver.cpp:404]     Test net output #1: loss = 0.563569 (* 1 = 0.563569 loss)
I0725 16:50:28.772388 20892 solver.cpp:228] Iteration 2500, loss = 0.517078
I0725 16:50:28.772465 20892 solver.cpp:244]     Train net output #0: loss = 0.517078 (* 1 = 0.517078 loss)
I0725 16:50:28.772485 20892 sgd_solver.cpp:106] Iteration 2500, lr = 9.15452e-06
I0725 16:50:38.121889 20892 solver.cpp:228] Iteration 2600, loss = 0.544262
I0725 16:50:38.121956 20892 solver.cpp:244]     Train net output #0: loss = 0.544262 (* 1 = 0.544262 loss)
I0725 16:50:38.121975 20892 sgd_solver.cpp:106] Iteration 2600, lr = 9.12412e-06
I0725 16:50:47.545441 20892 solver.cpp:228] Iteration 2700, loss = 0.616915
I0725 16:50:47.545512 20892 solver.cpp:244]     Train net output #0: loss = 0.616915 (* 1 = 0.616915 loss)
I0725 16:50:47.545521 20892 sgd_solver.cpp:106] Iteration 2700, lr = 9.09396e-06
I0725 16:50:57.107640 20892 solver.cpp:228] Iteration 2800, loss = 0.568412
I0725 16:50:57.107704 20892 solver.cpp:244]     Train net output #0: loss = 0.568412 (* 1 = 0.568412 loss)
I0725 16:50:57.107714 20892 sgd_solver.cpp:106] Iteration 2800, lr = 9.06403e-06
I0725 16:51:06.653956 20892 solver.cpp:228] Iteration 2900, loss = 0.588787
I0725 16:51:06.654021 20892 solver.cpp:244]     Train net output #0: loss = 0.588787 (* 1 = 0.588787 loss)
I0725 16:51:06.654031 20892 sgd_solver.cpp:106] Iteration 2900, lr = 9.03433e-06
I0725 16:51:15.978770 20892 solver.cpp:337] Iteration 3000, Testing net (#0)
I0725 16:51:30.197250 20892 solver.cpp:404]     Test net output #0: accuracy = 0.704742
I0725 16:51:30.197327 20892 solver.cpp:404]     Test net output #1: loss = 0.553437 (* 1 = 0.553437 loss)
I0725 16:51:30.228875 20892 solver.cpp:228] Iteration 3000, loss = 0.577692
I0725 16:51:30.228910 20892 solver.cpp:244]     Train net output #0: loss = 0.577692 (* 1 = 0.577692 loss)
I0725 16:51:30.228921 20892 sgd_solver.cpp:106] Iteration 3000, lr = 9.00485e-06
I0725 16:51:39.604897 20892 solver.cpp:228] Iteration 3100, loss = 0.547405
I0725 16:51:39.604950 20892 solver.cpp:244]     Train net output #0: loss = 0.547405 (* 1 = 0.547405 loss)
I0725 16:51:39.604959 20892 sgd_solver.cpp:106] Iteration 3100, lr = 8.9756e-06
I0725 16:51:49.017710 20892 solver.cpp:228] Iteration 3200, loss = 0.560835
I0725 16:51:49.017752 20892 solver.cpp:244]     Train net output #0: loss = 0.560835 (* 1 = 0.560835 loss)
I0725 16:51:49.017760 20892 sgd_solver.cpp:106] Iteration 3200, lr = 8.94657e-06
I0725 16:51:58.426043 20892 solver.cpp:228] Iteration 3300, loss = 0.535471
I0725 16:51:58.426090 20892 solver.cpp:244]     Train net output #0: loss = 0.535471 (* 1 = 0.535471 loss)
I0725 16:51:58.426097 20892 sgd_solver.cpp:106] Iteration 3300, lr = 8.91776e-06
I0725 16:52:07.842463 20892 solver.cpp:228] Iteration 3400, loss = 0.6396
I0725 16:52:07.842520 20892 solver.cpp:244]     Train net output #0: loss = 0.6396 (* 1 = 0.6396 loss)
I0725 16:52:07.842527 20892 sgd_solver.cpp:106] Iteration 3400, lr = 8.88916e-06
I0725 16:52:17.163955 20892 solver.cpp:337] Iteration 3500, Testing net (#0)
I0725 16:52:28.037797 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 16:52:31.278038 20892 solver.cpp:404]     Test net output #0: accuracy = 0.712322
I0725 16:52:31.278100 20892 solver.cpp:404]     Test net output #1: loss = 0.547974 (* 1 = 0.547974 loss)
I0725 16:52:31.307832 20892 solver.cpp:228] Iteration 3500, loss = 0.642854
I0725 16:52:31.307917 20892 solver.cpp:244]     Train net output #0: loss = 0.642854 (* 1 = 0.642854 loss)
I0725 16:52:31.307941 20892 sgd_solver.cpp:106] Iteration 3500, lr = 8.86077e-06
I0725 16:52:40.784342 20892 solver.cpp:228] Iteration 3600, loss = 0.499324
I0725 16:52:40.784389 20892 solver.cpp:244]     Train net output #0: loss = 0.499324 (* 1 = 0.499324 loss)
I0725 16:52:40.784396 20892 sgd_solver.cpp:106] Iteration 3600, lr = 8.8326e-06
I0725 16:52:50.354513 20892 solver.cpp:228] Iteration 3700, loss = 0.578002
I0725 16:52:50.354558 20892 solver.cpp:244]     Train net output #0: loss = 0.578002 (* 1 = 0.578002 loss)
I0725 16:52:50.354564 20892 sgd_solver.cpp:106] Iteration 3700, lr = 8.80463e-06
I0725 16:52:59.769492 20892 solver.cpp:228] Iteration 3800, loss = 0.572922
I0725 16:52:59.769556 20892 solver.cpp:244]     Train net output #0: loss = 0.572922 (* 1 = 0.572922 loss)
I0725 16:52:59.769565 20892 sgd_solver.cpp:106] Iteration 3800, lr = 8.77687e-06
I0725 16:53:09.191339 20892 solver.cpp:228] Iteration 3900, loss = 0.550264
I0725 16:53:09.191388 20892 solver.cpp:244]     Train net output #0: loss = 0.550264 (* 1 = 0.550264 loss)
I0725 16:53:09.191396 20892 sgd_solver.cpp:106] Iteration 3900, lr = 8.74932e-06
I0725 16:53:18.510817 20892 solver.cpp:337] Iteration 4000, Testing net (#0)
I0725 16:53:32.647883 20892 solver.cpp:404]     Test net output #0: accuracy = 0.727677
I0725 16:53:32.647943 20892 solver.cpp:404]     Test net output #1: loss = 0.536324 (* 1 = 0.536324 loss)
I0725 16:53:32.675022 20892 solver.cpp:228] Iteration 4000, loss = 0.542233
I0725 16:53:32.675062 20892 solver.cpp:244]     Train net output #0: loss = 0.542233 (* 1 = 0.542233 loss)
I0725 16:53:32.675072 20892 sgd_solver.cpp:106] Iteration 4000, lr = 8.72196e-06
I0725 16:53:42.030728 20892 solver.cpp:228] Iteration 4100, loss = 0.538517
I0725 16:53:42.030771 20892 solver.cpp:244]     Train net output #0: loss = 0.538517 (* 1 = 0.538517 loss)
I0725 16:53:42.030778 20892 sgd_solver.cpp:106] Iteration 4100, lr = 8.6948e-06
I0725 16:53:51.451439 20892 solver.cpp:228] Iteration 4200, loss = 0.480872
I0725 16:53:51.451488 20892 solver.cpp:244]     Train net output #0: loss = 0.480872 (* 1 = 0.480872 loss)
I0725 16:53:51.451494 20892 sgd_solver.cpp:106] Iteration 4200, lr = 8.66784e-06
I0725 16:54:00.872740 20892 solver.cpp:228] Iteration 4300, loss = 0.529201
I0725 16:54:00.872792 20892 solver.cpp:244]     Train net output #0: loss = 0.529201 (* 1 = 0.529201 loss)
I0725 16:54:00.872798 20892 sgd_solver.cpp:106] Iteration 4300, lr = 8.64107e-06
I0725 16:54:10.294502 20892 solver.cpp:228] Iteration 4400, loss = 0.521844
I0725 16:54:10.294559 20892 solver.cpp:244]     Train net output #0: loss = 0.521844 (* 1 = 0.521844 loss)
I0725 16:54:10.294565 20892 sgd_solver.cpp:106] Iteration 4400, lr = 8.6145e-06
I0725 16:54:19.620241 20892 solver.cpp:337] Iteration 4500, Testing net (#0)
I0725 16:54:33.738188 20892 solver.cpp:404]     Test net output #0: accuracy = 0.736871
I0725 16:54:33.738268 20892 solver.cpp:404]     Test net output #1: loss = 0.52959 (* 1 = 0.52959 loss)
I0725 16:54:33.766916 20892 solver.cpp:228] Iteration 4500, loss = 0.565733
I0725 16:54:33.766988 20892 solver.cpp:244]     Train net output #0: loss = 0.565733 (* 1 = 0.565733 loss)
I0725 16:54:33.767009 20892 sgd_solver.cpp:106] Iteration 4500, lr = 8.58812e-06
I0725 16:54:43.176513 20892 solver.cpp:228] Iteration 4600, loss = 0.505472
I0725 16:54:43.176569 20892 solver.cpp:244]     Train net output #0: loss = 0.505472 (* 1 = 0.505472 loss)
I0725 16:54:43.176576 20892 sgd_solver.cpp:106] Iteration 4600, lr = 8.56192e-06
I0725 16:54:52.752385 20892 solver.cpp:228] Iteration 4700, loss = 0.575023
I0725 16:54:52.752429 20892 solver.cpp:244]     Train net output #0: loss = 0.575023 (* 1 = 0.575023 loss)
I0725 16:54:52.752435 20892 sgd_solver.cpp:106] Iteration 4700, lr = 8.53591e-06
I0725 16:55:02.203511 20892 solver.cpp:228] Iteration 4800, loss = 0.550612
I0725 16:55:02.203579 20892 solver.cpp:244]     Train net output #0: loss = 0.550612 (* 1 = 0.550612 loss)
I0725 16:55:02.203589 20892 sgd_solver.cpp:106] Iteration 4800, lr = 8.51008e-06
I0725 16:55:11.603277 20892 solver.cpp:228] Iteration 4900, loss = 0.56225
I0725 16:55:11.603333 20892 solver.cpp:244]     Train net output #0: loss = 0.56225 (* 1 = 0.56225 loss)
I0725 16:55:11.603340 20892 sgd_solver.cpp:106] Iteration 4900, lr = 8.48444e-06
I0725 16:55:20.879504 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_5000.caffemodel
I0725 16:55:21.254493 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_5000.solverstate
I0725 16:55:21.352331 20892 solver.cpp:337] Iteration 5000, Testing net (#0)
I0725 16:55:28.691447 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 16:55:35.255038 20892 solver.cpp:404]     Test net output #0: accuracy = 0.745258
I0725 16:55:35.255101 20892 solver.cpp:404]     Test net output #1: loss = 0.521194 (* 1 = 0.521194 loss)
I0725 16:55:35.281818 20892 solver.cpp:228] Iteration 5000, loss = 0.639162
I0725 16:55:35.281874 20892 solver.cpp:244]     Train net output #0: loss = 0.639162 (* 1 = 0.639162 loss)
I0725 16:55:35.281885 20892 sgd_solver.cpp:106] Iteration 5000, lr = 8.45897e-06
I0725 16:55:44.673071 20892 solver.cpp:228] Iteration 5100, loss = 0.518108
I0725 16:55:44.673115 20892 solver.cpp:244]     Train net output #0: loss = 0.518108 (* 1 = 0.518108 loss)
I0725 16:55:44.673121 20892 sgd_solver.cpp:106] Iteration 5100, lr = 8.43368e-06
I0725 16:55:54.081002 20892 solver.cpp:228] Iteration 5200, loss = 0.538156
I0725 16:55:54.081051 20892 solver.cpp:244]     Train net output #0: loss = 0.538156 (* 1 = 0.538156 loss)
I0725 16:55:54.081058 20892 sgd_solver.cpp:106] Iteration 5200, lr = 8.40857e-06
I0725 16:56:03.489588 20892 solver.cpp:228] Iteration 5300, loss = 0.573702
I0725 16:56:03.489653 20892 solver.cpp:244]     Train net output #0: loss = 0.573702 (* 1 = 0.573702 loss)
I0725 16:56:03.489662 20892 sgd_solver.cpp:106] Iteration 5300, lr = 8.38363e-06
I0725 16:56:12.896625 20892 solver.cpp:228] Iteration 5400, loss = 0.497313
I0725 16:56:12.896680 20892 solver.cpp:244]     Train net output #0: loss = 0.497313 (* 1 = 0.497313 loss)
I0725 16:56:12.896689 20892 sgd_solver.cpp:106] Iteration 5400, lr = 8.35886e-06
I0725 16:56:22.216037 20892 solver.cpp:337] Iteration 5500, Testing net (#0)
I0725 16:56:36.385013 20892 solver.cpp:404]     Test net output #0: accuracy = 0.746613
I0725 16:56:36.385064 20892 solver.cpp:404]     Test net output #1: loss = 0.517892 (* 1 = 0.517892 loss)
I0725 16:56:36.414573 20892 solver.cpp:228] Iteration 5500, loss = 0.478998
I0725 16:56:36.414619 20892 solver.cpp:244]     Train net output #0: loss = 0.478998 (* 1 = 0.478998 loss)
I0725 16:56:36.414633 20892 sgd_solver.cpp:106] Iteration 5500, lr = 8.33427e-06
I0725 16:56:45.751579 20892 solver.cpp:228] Iteration 5600, loss = 0.63326
I0725 16:56:45.751627 20892 solver.cpp:244]     Train net output #0: loss = 0.63326 (* 1 = 0.63326 loss)
I0725 16:56:45.751636 20892 sgd_solver.cpp:106] Iteration 5600, lr = 8.30984e-06
I0725 16:56:55.169735 20892 solver.cpp:228] Iteration 5700, loss = 0.542177
I0725 16:56:55.169780 20892 solver.cpp:244]     Train net output #0: loss = 0.542177 (* 1 = 0.542177 loss)
I0725 16:56:55.169788 20892 sgd_solver.cpp:106] Iteration 5700, lr = 8.28557e-06
I0725 16:57:04.583154 20892 solver.cpp:228] Iteration 5800, loss = 0.537271
I0725 16:57:04.583212 20892 solver.cpp:244]     Train net output #0: loss = 0.537271 (* 1 = 0.537271 loss)
I0725 16:57:04.583220 20892 sgd_solver.cpp:106] Iteration 5800, lr = 8.26148e-06
I0725 16:57:13.997530 20892 solver.cpp:228] Iteration 5900, loss = 0.540126
I0725 16:57:13.997572 20892 solver.cpp:244]     Train net output #0: loss = 0.540126 (* 1 = 0.540126 loss)
I0725 16:57:13.997578 20892 sgd_solver.cpp:106] Iteration 5900, lr = 8.23754e-06
I0725 16:57:23.321490 20892 solver.cpp:337] Iteration 6000, Testing net (#0)
I0725 16:57:37.371891 20892 solver.cpp:404]     Test net output #0: accuracy = 0.754678
I0725 16:57:37.371949 20892 solver.cpp:404]     Test net output #1: loss = 0.508598 (* 1 = 0.508598 loss)
I0725 16:57:37.401394 20892 solver.cpp:228] Iteration 6000, loss = 0.593409
I0725 16:57:37.401440 20892 solver.cpp:244]     Train net output #0: loss = 0.593409 (* 1 = 0.593409 loss)
I0725 16:57:37.401451 20892 sgd_solver.cpp:106] Iteration 6000, lr = 8.21377e-06
I0725 16:57:46.777976 20892 solver.cpp:228] Iteration 6100, loss = 0.566777
I0725 16:57:46.778020 20892 solver.cpp:244]     Train net output #0: loss = 0.566777 (* 1 = 0.566777 loss)
I0725 16:57:46.778026 20892 sgd_solver.cpp:106] Iteration 6100, lr = 8.19015e-06
I0725 16:57:56.187932 20892 solver.cpp:228] Iteration 6200, loss = 0.405816
I0725 16:57:56.187970 20892 solver.cpp:244]     Train net output #0: loss = 0.405816 (* 1 = 0.405816 loss)
I0725 16:57:56.187978 20892 sgd_solver.cpp:106] Iteration 6200, lr = 8.1667e-06
I0725 16:58:05.603714 20892 solver.cpp:228] Iteration 6300, loss = 0.492226
I0725 16:58:05.603760 20892 solver.cpp:244]     Train net output #0: loss = 0.492226 (* 1 = 0.492226 loss)
I0725 16:58:05.603765 20892 sgd_solver.cpp:106] Iteration 6300, lr = 8.1434e-06
I0725 16:58:15.018998 20892 solver.cpp:228] Iteration 6400, loss = 0.475602
I0725 16:58:15.019059 20892 solver.cpp:244]     Train net output #0: loss = 0.475602 (* 1 = 0.475602 loss)
I0725 16:58:15.019068 20892 sgd_solver.cpp:106] Iteration 6400, lr = 8.12025e-06
I0725 16:58:24.338037 20892 solver.cpp:337] Iteration 6500, Testing net (#0)
I0725 16:58:33.645483 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 16:58:38.449946 20892 solver.cpp:404]     Test net output #0: accuracy = 0.755871
I0725 16:58:38.449995 20892 solver.cpp:404]     Test net output #1: loss = 0.50575 (* 1 = 0.50575 loss)
I0725 16:58:38.479601 20892 solver.cpp:228] Iteration 6500, loss = 0.550408
I0725 16:58:38.479666 20892 solver.cpp:244]     Train net output #0: loss = 0.550408 (* 1 = 0.550408 loss)
I0725 16:58:38.479686 20892 sgd_solver.cpp:106] Iteration 6500, lr = 8.09726e-06
I0725 16:58:47.776008 20892 solver.cpp:228] Iteration 6600, loss = 0.571895
I0725 16:58:47.776062 20892 solver.cpp:244]     Train net output #0: loss = 0.571895 (* 1 = 0.571895 loss)
I0725 16:58:47.776069 20892 sgd_solver.cpp:106] Iteration 6600, lr = 8.07442e-06
I0725 16:58:57.185248 20892 solver.cpp:228] Iteration 6700, loss = 0.551329
I0725 16:58:57.185292 20892 solver.cpp:244]     Train net output #0: loss = 0.551329 (* 1 = 0.551329 loss)
I0725 16:58:57.185297 20892 sgd_solver.cpp:106] Iteration 6700, lr = 8.05173e-06
I0725 16:59:06.596163 20892 solver.cpp:228] Iteration 6800, loss = 0.516475
I0725 16:59:06.596210 20892 solver.cpp:244]     Train net output #0: loss = 0.516475 (* 1 = 0.516475 loss)
I0725 16:59:06.596216 20892 sgd_solver.cpp:106] Iteration 6800, lr = 8.02918e-06
I0725 16:59:16.006662 20892 solver.cpp:228] Iteration 6900, loss = 0.582038
I0725 16:59:16.006706 20892 solver.cpp:244]     Train net output #0: loss = 0.582038 (* 1 = 0.582038 loss)
I0725 16:59:16.006712 20892 sgd_solver.cpp:106] Iteration 6900, lr = 8.00679e-06
I0725 16:59:25.329087 20892 solver.cpp:337] Iteration 7000, Testing net (#0)
I0725 16:59:39.458649 20892 solver.cpp:404]     Test net output #0: accuracy = 0.75629
I0725 16:59:39.458698 20892 solver.cpp:404]     Test net output #1: loss = 0.50219 (* 1 = 0.50219 loss)
I0725 16:59:39.484940 20892 solver.cpp:228] Iteration 7000, loss = 0.549211
I0725 16:59:39.484972 20892 solver.cpp:244]     Train net output #0: loss = 0.549211 (* 1 = 0.549211 loss)
I0725 16:59:39.484982 20892 sgd_solver.cpp:106] Iteration 7000, lr = 7.98454e-06
I0725 16:59:48.993201 20892 solver.cpp:228] Iteration 7100, loss = 0.549238
I0725 16:59:48.993245 20892 solver.cpp:244]     Train net output #0: loss = 0.549238 (* 1 = 0.549238 loss)
I0725 16:59:48.993252 20892 sgd_solver.cpp:106] Iteration 7100, lr = 7.96243e-06
I0725 16:59:58.495477 20892 solver.cpp:228] Iteration 7200, loss = 0.470882
I0725 16:59:58.495529 20892 solver.cpp:244]     Train net output #0: loss = 0.470882 (* 1 = 0.470882 loss)
I0725 16:59:58.495537 20892 sgd_solver.cpp:106] Iteration 7200, lr = 7.94046e-06
I0725 17:00:07.873852 20892 solver.cpp:228] Iteration 7300, loss = 0.464358
I0725 17:00:07.873895 20892 solver.cpp:244]     Train net output #0: loss = 0.464358 (* 1 = 0.464358 loss)
I0725 17:00:07.873903 20892 sgd_solver.cpp:106] Iteration 7300, lr = 7.91864e-06
I0725 17:00:17.236032 20892 solver.cpp:228] Iteration 7400, loss = 0.518767
I0725 17:00:17.236080 20892 solver.cpp:244]     Train net output #0: loss = 0.518767 (* 1 = 0.518767 loss)
I0725 17:00:17.236086 20892 sgd_solver.cpp:106] Iteration 7400, lr = 7.89695e-06
I0725 17:00:26.557417 20892 solver.cpp:337] Iteration 7500, Testing net (#0)
I0725 17:00:40.759045 20892 solver.cpp:404]     Test net output #0: accuracy = 0.759871
I0725 17:00:40.759104 20892 solver.cpp:404]     Test net output #1: loss = 0.49624 (* 1 = 0.49624 loss)
I0725 17:00:40.788039 20892 solver.cpp:228] Iteration 7500, loss = 0.433273
I0725 17:00:40.788063 20892 solver.cpp:244]     Train net output #0: loss = 0.433273 (* 1 = 0.433273 loss)
I0725 17:00:40.788074 20892 sgd_solver.cpp:106] Iteration 7500, lr = 7.87541e-06
I0725 17:00:50.067167 20892 solver.cpp:228] Iteration 7600, loss = 0.52097
I0725 17:00:50.067232 20892 solver.cpp:244]     Train net output #0: loss = 0.52097 (* 1 = 0.52097 loss)
I0725 17:00:50.067241 20892 sgd_solver.cpp:106] Iteration 7600, lr = 7.854e-06
I0725 17:00:59.484055 20892 solver.cpp:228] Iteration 7700, loss = 0.452803
I0725 17:00:59.484112 20892 solver.cpp:244]     Train net output #0: loss = 0.452803 (* 1 = 0.452803 loss)
I0725 17:00:59.484120 20892 sgd_solver.cpp:106] Iteration 7700, lr = 7.83272e-06
I0725 17:01:08.898180 20892 solver.cpp:228] Iteration 7800, loss = 0.436058
I0725 17:01:08.898219 20892 solver.cpp:244]     Train net output #0: loss = 0.436058 (* 1 = 0.436058 loss)
I0725 17:01:08.898226 20892 sgd_solver.cpp:106] Iteration 7800, lr = 7.81158e-06
I0725 17:01:18.315882 20892 solver.cpp:228] Iteration 7900, loss = 0.570529
I0725 17:01:18.315942 20892 solver.cpp:244]     Train net output #0: loss = 0.570529 (* 1 = 0.570529 loss)
I0725 17:01:18.315949 20892 sgd_solver.cpp:106] Iteration 7900, lr = 7.79057e-06
I0725 17:01:27.635519 20892 solver.cpp:337] Iteration 8000, Testing net (#0)
I0725 17:01:41.108814 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:01:42.000501 20892 solver.cpp:404]     Test net output #0: accuracy = 0.765387
I0725 17:01:42.000561 20892 solver.cpp:404]     Test net output #1: loss = 0.489685 (* 1 = 0.489685 loss)
I0725 17:01:42.027451 20892 solver.cpp:228] Iteration 8000, loss = 0.540127
I0725 17:01:42.027478 20892 solver.cpp:244]     Train net output #0: loss = 0.540127 (* 1 = 0.540127 loss)
I0725 17:01:42.027489 20892 sgd_solver.cpp:106] Iteration 8000, lr = 7.7697e-06
I0725 17:01:51.394207 20892 solver.cpp:228] Iteration 8100, loss = 0.42386
I0725 17:01:51.394274 20892 solver.cpp:244]     Train net output #0: loss = 0.42386 (* 1 = 0.42386 loss)
I0725 17:01:51.394280 20892 sgd_solver.cpp:106] Iteration 8100, lr = 7.74895e-06
I0725 17:02:00.919921 20892 solver.cpp:228] Iteration 8200, loss = 0.572153
I0725 17:02:00.919987 20892 solver.cpp:244]     Train net output #0: loss = 0.572153 (* 1 = 0.572153 loss)
I0725 17:02:00.919996 20892 sgd_solver.cpp:106] Iteration 8200, lr = 7.72833e-06
I0725 17:02:10.449187 20892 solver.cpp:228] Iteration 8300, loss = 0.410475
I0725 17:02:10.449234 20892 solver.cpp:244]     Train net output #0: loss = 0.410475 (* 1 = 0.410475 loss)
I0725 17:02:10.449240 20892 sgd_solver.cpp:106] Iteration 8300, lr = 7.70784e-06
I0725 17:02:19.866045 20892 solver.cpp:228] Iteration 8400, loss = 0.507517
I0725 17:02:19.866091 20892 solver.cpp:244]     Train net output #0: loss = 0.507517 (* 1 = 0.507517 loss)
I0725 17:02:19.866098 20892 sgd_solver.cpp:106] Iteration 8400, lr = 7.68748e-06
I0725 17:02:29.184661 20892 solver.cpp:337] Iteration 8500, Testing net (#0)
I0725 17:02:43.454970 20892 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0725 17:02:43.455016 20892 solver.cpp:404]     Test net output #1: loss = 0.487916 (* 1 = 0.487916 loss)
I0725 17:02:43.483256 20892 solver.cpp:228] Iteration 8500, loss = 0.465788
I0725 17:02:43.483289 20892 solver.cpp:244]     Train net output #0: loss = 0.465788 (* 1 = 0.465788 loss)
I0725 17:02:43.483299 20892 sgd_solver.cpp:106] Iteration 8500, lr = 7.66724e-06
I0725 17:02:52.863060 20892 solver.cpp:228] Iteration 8600, loss = 0.483807
I0725 17:02:52.863100 20892 solver.cpp:244]     Train net output #0: loss = 0.483807 (* 1 = 0.483807 loss)
I0725 17:02:52.863106 20892 sgd_solver.cpp:106] Iteration 8600, lr = 7.64712e-06
I0725 17:03:02.405961 20892 solver.cpp:228] Iteration 8700, loss = 0.546062
I0725 17:03:02.406003 20892 solver.cpp:244]     Train net output #0: loss = 0.546062 (* 1 = 0.546062 loss)
I0725 17:03:02.406010 20892 sgd_solver.cpp:106] Iteration 8700, lr = 7.62713e-06
I0725 17:03:11.898828 20892 solver.cpp:228] Iteration 8800, loss = 0.494577
I0725 17:03:11.898866 20892 solver.cpp:244]     Train net output #0: loss = 0.494577 (* 1 = 0.494577 loss)
I0725 17:03:11.898872 20892 sgd_solver.cpp:106] Iteration 8800, lr = 7.60726e-06
I0725 17:03:21.314724 20892 solver.cpp:228] Iteration 8900, loss = 0.418887
I0725 17:03:21.314764 20892 solver.cpp:244]     Train net output #0: loss = 0.418887 (* 1 = 0.418887 loss)
I0725 17:03:21.314770 20892 sgd_solver.cpp:106] Iteration 8900, lr = 7.58751e-06
I0725 17:03:30.635840 20892 solver.cpp:337] Iteration 9000, Testing net (#0)
I0725 17:03:44.756430 20892 solver.cpp:404]     Test net output #0: accuracy = 0.760387
I0725 17:03:44.756477 20892 solver.cpp:404]     Test net output #1: loss = 0.489949 (* 1 = 0.489949 loss)
I0725 17:03:44.785882 20892 solver.cpp:228] Iteration 9000, loss = 0.441488
I0725 17:03:44.785933 20892 solver.cpp:244]     Train net output #0: loss = 0.441488 (* 1 = 0.441488 loss)
I0725 17:03:44.785943 20892 sgd_solver.cpp:106] Iteration 9000, lr = 7.56788e-06
I0725 17:03:54.133458 20892 solver.cpp:228] Iteration 9100, loss = 0.467035
I0725 17:03:54.133515 20892 solver.cpp:244]     Train net output #0: loss = 0.467035 (* 1 = 0.467035 loss)
I0725 17:03:54.133522 20892 sgd_solver.cpp:106] Iteration 9100, lr = 7.54836e-06
I0725 17:04:03.544209 20892 solver.cpp:228] Iteration 9200, loss = 0.517337
I0725 17:04:03.544263 20892 solver.cpp:244]     Train net output #0: loss = 0.517337 (* 1 = 0.517337 loss)
I0725 17:04:03.544270 20892 sgd_solver.cpp:106] Iteration 9200, lr = 7.52897e-06
I0725 17:04:12.963548 20892 solver.cpp:228] Iteration 9300, loss = 0.45845
I0725 17:04:12.963592 20892 solver.cpp:244]     Train net output #0: loss = 0.45845 (* 1 = 0.45845 loss)
I0725 17:04:12.963598 20892 sgd_solver.cpp:106] Iteration 9300, lr = 7.50969e-06
I0725 17:04:22.527974 20892 solver.cpp:228] Iteration 9400, loss = 0.457518
I0725 17:04:22.528013 20892 solver.cpp:244]     Train net output #0: loss = 0.457518 (* 1 = 0.457518 loss)
I0725 17:04:22.528019 20892 sgd_solver.cpp:106] Iteration 9400, lr = 7.49052e-06
I0725 17:04:31.982295 20892 solver.cpp:337] Iteration 9500, Testing net (#0)
I0725 17:04:45.864428 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:04:46.040319 20892 solver.cpp:404]     Test net output #0: accuracy = 0.769677
I0725 17:04:46.040393 20892 solver.cpp:404]     Test net output #1: loss = 0.480539 (* 1 = 0.480539 loss)
I0725 17:04:46.069355 20892 solver.cpp:228] Iteration 9500, loss = 0.507771
I0725 17:04:46.069417 20892 solver.cpp:244]     Train net output #0: loss = 0.507771 (* 1 = 0.507771 loss)
I0725 17:04:46.069429 20892 sgd_solver.cpp:106] Iteration 9500, lr = 7.47147e-06
I0725 17:04:55.454169 20892 solver.cpp:228] Iteration 9600, loss = 0.476722
I0725 17:04:55.454231 20892 solver.cpp:244]     Train net output #0: loss = 0.476722 (* 1 = 0.476722 loss)
I0725 17:04:55.454237 20892 sgd_solver.cpp:106] Iteration 9600, lr = 7.45253e-06
I0725 17:05:04.868785 20892 solver.cpp:228] Iteration 9700, loss = 0.521356
I0725 17:05:04.868841 20892 solver.cpp:244]     Train net output #0: loss = 0.521356 (* 1 = 0.521356 loss)
I0725 17:05:04.868849 20892 sgd_solver.cpp:106] Iteration 9700, lr = 7.4337e-06
I0725 17:05:14.282212 20892 solver.cpp:228] Iteration 9800, loss = 0.502931
I0725 17:05:14.282249 20892 solver.cpp:244]     Train net output #0: loss = 0.502931 (* 1 = 0.502931 loss)
I0725 17:05:14.282256 20892 sgd_solver.cpp:106] Iteration 9800, lr = 7.41499e-06
I0725 17:05:23.698251 20892 solver.cpp:228] Iteration 9900, loss = 0.499844
I0725 17:05:23.698315 20892 solver.cpp:244]     Train net output #0: loss = 0.499844 (* 1 = 0.499844 loss)
I0725 17:05:23.698324 20892 sgd_solver.cpp:106] Iteration 9900, lr = 7.39638e-06
I0725 17:05:33.017874 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_10000.caffemodel
I0725 17:05:33.369005 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_10000.solverstate
I0725 17:05:33.467020 20892 solver.cpp:337] Iteration 10000, Testing net (#0)
I0725 17:05:47.486201 20892 solver.cpp:404]     Test net output #0: accuracy = 0.771871
I0725 17:05:47.486255 20892 solver.cpp:404]     Test net output #1: loss = 0.476785 (* 1 = 0.476785 loss)
I0725 17:05:47.515617 20892 solver.cpp:228] Iteration 10000, loss = 0.524273
I0725 17:05:47.515686 20892 solver.cpp:244]     Train net output #0: loss = 0.524273 (* 1 = 0.524273 loss)
I0725 17:05:47.515697 20892 sgd_solver.cpp:106] Iteration 10000, lr = 7.37788e-06
I0725 17:05:56.930483 20892 solver.cpp:228] Iteration 10100, loss = 0.441541
I0725 17:05:56.930538 20892 solver.cpp:244]     Train net output #0: loss = 0.441541 (* 1 = 0.441541 loss)
I0725 17:05:56.930546 20892 sgd_solver.cpp:106] Iteration 10100, lr = 7.35949e-06
I0725 17:06:06.339319 20892 solver.cpp:228] Iteration 10200, loss = 0.505845
I0725 17:06:06.339367 20892 solver.cpp:244]     Train net output #0: loss = 0.505845 (* 1 = 0.505845 loss)
I0725 17:06:06.339373 20892 sgd_solver.cpp:106] Iteration 10200, lr = 7.3412e-06
I0725 17:06:15.751786 20892 solver.cpp:228] Iteration 10300, loss = 0.478806
I0725 17:06:15.751842 20892 solver.cpp:244]     Train net output #0: loss = 0.478806 (* 1 = 0.478806 loss)
I0725 17:06:15.751850 20892 sgd_solver.cpp:106] Iteration 10300, lr = 7.32302e-06
I0725 17:06:25.159642 20892 solver.cpp:228] Iteration 10400, loss = 0.532937
I0725 17:06:25.159694 20892 solver.cpp:244]     Train net output #0: loss = 0.532937 (* 1 = 0.532937 loss)
I0725 17:06:25.159701 20892 sgd_solver.cpp:106] Iteration 10400, lr = 7.30495e-06
I0725 17:06:34.480693 20892 solver.cpp:337] Iteration 10500, Testing net (#0)
I0725 17:06:48.679900 20892 solver.cpp:404]     Test net output #0: accuracy = 0.773516
I0725 17:06:48.679947 20892 solver.cpp:404]     Test net output #1: loss = 0.474321 (* 1 = 0.474321 loss)
I0725 17:06:48.709168 20892 solver.cpp:228] Iteration 10500, loss = 0.418472
I0725 17:06:48.709213 20892 solver.cpp:244]     Train net output #0: loss = 0.418472 (* 1 = 0.418472 loss)
I0725 17:06:48.709223 20892 sgd_solver.cpp:106] Iteration 10500, lr = 7.28698e-06
I0725 17:06:58.044622 20892 solver.cpp:228] Iteration 10600, loss = 0.423306
I0725 17:06:58.044666 20892 solver.cpp:244]     Train net output #0: loss = 0.423306 (* 1 = 0.423306 loss)
I0725 17:06:58.044672 20892 sgd_solver.cpp:106] Iteration 10600, lr = 7.26911e-06
I0725 17:07:07.462463 20892 solver.cpp:228] Iteration 10700, loss = 0.440393
I0725 17:07:07.462524 20892 solver.cpp:244]     Train net output #0: loss = 0.440393 (* 1 = 0.440393 loss)
I0725 17:07:07.462532 20892 sgd_solver.cpp:106] Iteration 10700, lr = 7.25135e-06
I0725 17:07:16.874405 20892 solver.cpp:228] Iteration 10800, loss = 0.478344
I0725 17:07:16.874452 20892 solver.cpp:244]     Train net output #0: loss = 0.478344 (* 1 = 0.478344 loss)
I0725 17:07:16.874459 20892 sgd_solver.cpp:106] Iteration 10800, lr = 7.23368e-06
I0725 17:07:26.288388 20892 solver.cpp:228] Iteration 10900, loss = 0.458353
I0725 17:07:26.288430 20892 solver.cpp:244]     Train net output #0: loss = 0.458353 (* 1 = 0.458353 loss)
I0725 17:07:26.288436 20892 sgd_solver.cpp:106] Iteration 10900, lr = 7.21612e-06
I0725 17:07:35.607290 20892 solver.cpp:337] Iteration 11000, Testing net (#0)
I0725 17:07:49.859649 20892 solver.cpp:404]     Test net output #0: accuracy = 0.771259
I0725 17:07:49.859710 20892 solver.cpp:404]     Test net output #1: loss = 0.475788 (* 1 = 0.475788 loss)
I0725 17:07:49.889216 20892 solver.cpp:228] Iteration 11000, loss = 0.529712
I0725 17:07:49.889272 20892 solver.cpp:244]     Train net output #0: loss = 0.529712 (* 1 = 0.529712 loss)
I0725 17:07:49.889292 20892 sgd_solver.cpp:106] Iteration 11000, lr = 7.19865e-06
I0725 17:07:55.045094 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:07:59.355614 20892 solver.cpp:228] Iteration 11100, loss = 0.384354
I0725 17:07:59.355655 20892 solver.cpp:244]     Train net output #0: loss = 0.384354 (* 1 = 0.384354 loss)
I0725 17:07:59.355662 20892 sgd_solver.cpp:106] Iteration 11100, lr = 7.18129e-06
I0725 17:08:08.819962 20892 solver.cpp:228] Iteration 11200, loss = 0.461507
I0725 17:08:08.820003 20892 solver.cpp:244]     Train net output #0: loss = 0.461507 (* 1 = 0.461507 loss)
I0725 17:08:08.820010 20892 sgd_solver.cpp:106] Iteration 11200, lr = 7.16402e-06
I0725 17:08:18.169701 20892 solver.cpp:228] Iteration 11300, loss = 0.558158
I0725 17:08:18.169767 20892 solver.cpp:244]     Train net output #0: loss = 0.558158 (* 1 = 0.558158 loss)
I0725 17:08:18.169776 20892 sgd_solver.cpp:106] Iteration 11300, lr = 7.14684e-06
I0725 17:08:27.587208 20892 solver.cpp:228] Iteration 11400, loss = 0.420902
I0725 17:08:27.587265 20892 solver.cpp:244]     Train net output #0: loss = 0.420902 (* 1 = 0.420902 loss)
I0725 17:08:27.587275 20892 sgd_solver.cpp:106] Iteration 11400, lr = 7.12977e-06
I0725 17:08:36.910002 20892 solver.cpp:337] Iteration 11500, Testing net (#0)
I0725 17:08:51.189054 20892 solver.cpp:404]     Test net output #0: accuracy = 0.779516
I0725 17:08:51.189112 20892 solver.cpp:404]     Test net output #1: loss = 0.46612 (* 1 = 0.46612 loss)
I0725 17:08:51.218554 20892 solver.cpp:228] Iteration 11500, loss = 0.38745
I0725 17:08:51.218590 20892 solver.cpp:244]     Train net output #0: loss = 0.38745 (* 1 = 0.38745 loss)
I0725 17:08:51.218600 20892 sgd_solver.cpp:106] Iteration 11500, lr = 7.11278e-06
I0725 17:09:00.617939 20892 solver.cpp:228] Iteration 11600, loss = 0.40695
I0725 17:09:00.617985 20892 solver.cpp:244]     Train net output #0: loss = 0.40695 (* 1 = 0.40695 loss)
I0725 17:09:00.617990 20892 sgd_solver.cpp:106] Iteration 11600, lr = 7.09589e-06
I0725 17:09:10.034065 20892 solver.cpp:228] Iteration 11700, loss = 0.394602
I0725 17:09:10.034116 20892 solver.cpp:244]     Train net output #0: loss = 0.394602 (* 1 = 0.394602 loss)
I0725 17:09:10.034121 20892 sgd_solver.cpp:106] Iteration 11700, lr = 7.0791e-06
I0725 17:09:19.456982 20892 solver.cpp:228] Iteration 11800, loss = 0.431515
I0725 17:09:19.457022 20892 solver.cpp:244]     Train net output #0: loss = 0.431515 (* 1 = 0.431515 loss)
I0725 17:09:19.457028 20892 sgd_solver.cpp:106] Iteration 11800, lr = 7.0624e-06
I0725 17:09:28.869680 20892 solver.cpp:228] Iteration 11900, loss = 0.368351
I0725 17:09:28.869719 20892 solver.cpp:244]     Train net output #0: loss = 0.368351 (* 1 = 0.368351 loss)
I0725 17:09:28.869726 20892 sgd_solver.cpp:106] Iteration 11900, lr = 7.04579e-06
I0725 17:09:38.195193 20892 solver.cpp:337] Iteration 12000, Testing net (#0)
I0725 17:09:52.329310 20892 solver.cpp:404]     Test net output #0: accuracy = 0.779935
I0725 17:09:52.329358 20892 solver.cpp:404]     Test net output #1: loss = 0.464957 (* 1 = 0.464957 loss)
I0725 17:09:52.355726 20892 solver.cpp:228] Iteration 12000, loss = 0.507789
I0725 17:09:52.355770 20892 solver.cpp:244]     Train net output #0: loss = 0.507789 (* 1 = 0.507789 loss)
I0725 17:09:52.355782 20892 sgd_solver.cpp:106] Iteration 12000, lr = 7.02927e-06
I0725 17:10:01.740164 20892 solver.cpp:228] Iteration 12100, loss = 0.500158
I0725 17:10:01.740221 20892 solver.cpp:244]     Train net output #0: loss = 0.500158 (* 1 = 0.500158 loss)
I0725 17:10:01.740228 20892 sgd_solver.cpp:106] Iteration 12100, lr = 7.01284e-06
I0725 17:10:11.151605 20892 solver.cpp:228] Iteration 12200, loss = 0.454605
I0725 17:10:11.151654 20892 solver.cpp:244]     Train net output #0: loss = 0.454605 (* 1 = 0.454605 loss)
I0725 17:10:11.151659 20892 sgd_solver.cpp:106] Iteration 12200, lr = 6.9965e-06
I0725 17:10:20.557972 20892 solver.cpp:228] Iteration 12300, loss = 0.435993
I0725 17:10:20.558012 20892 solver.cpp:244]     Train net output #0: loss = 0.435993 (* 1 = 0.435993 loss)
I0725 17:10:20.558018 20892 sgd_solver.cpp:106] Iteration 12300, lr = 6.98024e-06
I0725 17:10:29.967092 20892 solver.cpp:228] Iteration 12400, loss = 0.441922
I0725 17:10:29.967140 20892 solver.cpp:244]     Train net output #0: loss = 0.441922 (* 1 = 0.441922 loss)
I0725 17:10:29.967147 20892 sgd_solver.cpp:106] Iteration 12400, lr = 6.96408e-06
I0725 17:10:39.284133 20892 solver.cpp:337] Iteration 12500, Testing net (#0)
I0725 17:10:51.912930 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:10:53.520936 20892 solver.cpp:404]     Test net output #0: accuracy = 0.783129
I0725 17:10:53.520968 20892 solver.cpp:404]     Test net output #1: loss = 0.461014 (* 1 = 0.461014 loss)
I0725 17:10:53.547296 20892 solver.cpp:228] Iteration 12500, loss = 0.414848
I0725 17:10:53.547346 20892 solver.cpp:244]     Train net output #0: loss = 0.414848 (* 1 = 0.414848 loss)
I0725 17:10:53.547368 20892 sgd_solver.cpp:106] Iteration 12500, lr = 6.948e-06
I0725 17:11:02.892644 20892 solver.cpp:228] Iteration 12600, loss = 0.464655
I0725 17:11:02.892681 20892 solver.cpp:244]     Train net output #0: loss = 0.464655 (* 1 = 0.464655 loss)
I0725 17:11:02.892688 20892 sgd_solver.cpp:106] Iteration 12600, lr = 6.93201e-06
I0725 17:11:12.297092 20892 solver.cpp:228] Iteration 12700, loss = 0.38779
I0725 17:11:12.297135 20892 solver.cpp:244]     Train net output #0: loss = 0.38779 (* 1 = 0.38779 loss)
I0725 17:11:12.297142 20892 sgd_solver.cpp:106] Iteration 12700, lr = 6.91611e-06
I0725 17:11:21.702376 20892 solver.cpp:228] Iteration 12800, loss = 0.380703
I0725 17:11:21.702420 20892 solver.cpp:244]     Train net output #0: loss = 0.380703 (* 1 = 0.380703 loss)
I0725 17:11:21.702427 20892 sgd_solver.cpp:106] Iteration 12800, lr = 6.90029e-06
I0725 17:11:31.108206 20892 solver.cpp:228] Iteration 12900, loss = 0.401328
I0725 17:11:31.108254 20892 solver.cpp:244]     Train net output #0: loss = 0.401328 (* 1 = 0.401328 loss)
I0725 17:11:31.108260 20892 sgd_solver.cpp:106] Iteration 12900, lr = 6.88455e-06
I0725 17:11:40.429543 20892 solver.cpp:337] Iteration 13000, Testing net (#0)
I0725 17:11:54.591364 20892 solver.cpp:404]     Test net output #0: accuracy = 0.781194
I0725 17:11:54.591411 20892 solver.cpp:404]     Test net output #1: loss = 0.461708 (* 1 = 0.461708 loss)
I0725 17:11:54.623836 20892 solver.cpp:228] Iteration 13000, loss = 0.466599
I0725 17:11:54.623898 20892 solver.cpp:244]     Train net output #0: loss = 0.466599 (* 1 = 0.466599 loss)
I0725 17:11:54.623916 20892 sgd_solver.cpp:106] Iteration 13000, lr = 6.8689e-06
I0725 17:12:03.980092 20892 solver.cpp:228] Iteration 13100, loss = 0.446699
I0725 17:12:03.980139 20892 solver.cpp:244]     Train net output #0: loss = 0.446699 (* 1 = 0.446699 loss)
I0725 17:12:03.980144 20892 sgd_solver.cpp:106] Iteration 13100, lr = 6.85333e-06
I0725 17:12:13.391744 20892 solver.cpp:228] Iteration 13200, loss = 0.436307
I0725 17:12:13.391793 20892 solver.cpp:244]     Train net output #0: loss = 0.436307 (* 1 = 0.436307 loss)
I0725 17:12:13.391800 20892 sgd_solver.cpp:106] Iteration 13200, lr = 6.83784e-06
I0725 17:12:22.803364 20892 solver.cpp:228] Iteration 13300, loss = 0.468063
I0725 17:12:22.803428 20892 solver.cpp:244]     Train net output #0: loss = 0.468063 (* 1 = 0.468063 loss)
I0725 17:12:22.803436 20892 sgd_solver.cpp:106] Iteration 13300, lr = 6.82243e-06
I0725 17:12:32.215932 20892 solver.cpp:228] Iteration 13400, loss = 0.392689
I0725 17:12:32.215991 20892 solver.cpp:244]     Train net output #0: loss = 0.392689 (* 1 = 0.392689 loss)
I0725 17:12:32.215997 20892 sgd_solver.cpp:106] Iteration 13400, lr = 6.80711e-06
I0725 17:12:41.529868 20892 solver.cpp:337] Iteration 13500, Testing net (#0)
I0725 17:12:55.731011 20892 solver.cpp:404]     Test net output #0: accuracy = 0.786807
I0725 17:12:55.731052 20892 solver.cpp:404]     Test net output #1: loss = 0.454807 (* 1 = 0.454807 loss)
I0725 17:12:55.756880 20892 solver.cpp:228] Iteration 13500, loss = 0.450853
I0725 17:12:55.756923 20892 solver.cpp:244]     Train net output #0: loss = 0.450853 (* 1 = 0.450853 loss)
I0725 17:12:55.756943 20892 sgd_solver.cpp:106] Iteration 13500, lr = 6.79186e-06
I0725 17:13:05.078294 20892 solver.cpp:228] Iteration 13600, loss = 0.53159
I0725 17:13:05.078351 20892 solver.cpp:244]     Train net output #0: loss = 0.53159 (* 1 = 0.53159 loss)
I0725 17:13:05.078358 20892 sgd_solver.cpp:106] Iteration 13600, lr = 6.7767e-06
I0725 17:13:14.494216 20892 solver.cpp:228] Iteration 13700, loss = 0.445569
I0725 17:13:14.494263 20892 solver.cpp:244]     Train net output #0: loss = 0.445569 (* 1 = 0.445569 loss)
I0725 17:13:14.494271 20892 sgd_solver.cpp:106] Iteration 13700, lr = 6.76161e-06
I0725 17:13:23.903064 20892 solver.cpp:228] Iteration 13800, loss = 0.449233
I0725 17:13:23.903120 20892 solver.cpp:244]     Train net output #0: loss = 0.449233 (* 1 = 0.449233 loss)
I0725 17:13:23.903128 20892 sgd_solver.cpp:106] Iteration 13800, lr = 6.7466e-06
I0725 17:13:33.311319 20892 solver.cpp:228] Iteration 13900, loss = 0.489737
I0725 17:13:33.311364 20892 solver.cpp:244]     Train net output #0: loss = 0.489737 (* 1 = 0.489737 loss)
I0725 17:13:33.311370 20892 sgd_solver.cpp:106] Iteration 13900, lr = 6.73167e-06
I0725 17:13:42.626483 20892 solver.cpp:337] Iteration 14000, Testing net (#0)
I0725 17:13:53.325239 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:13:56.842862 20892 solver.cpp:404]     Test net output #0: accuracy = 0.786612
I0725 17:13:56.842917 20892 solver.cpp:404]     Test net output #1: loss = 0.455445 (* 1 = 0.455445 loss)
I0725 17:13:56.869520 20892 solver.cpp:228] Iteration 14000, loss = 0.450562
I0725 17:13:56.869560 20892 solver.cpp:244]     Train net output #0: loss = 0.450562 (* 1 = 0.450562 loss)
I0725 17:13:56.869570 20892 sgd_solver.cpp:106] Iteration 14000, lr = 6.71681e-06
I0725 17:14:06.259208 20892 solver.cpp:228] Iteration 14100, loss = 0.412733
I0725 17:14:06.259249 20892 solver.cpp:244]     Train net output #0: loss = 0.412733 (* 1 = 0.412733 loss)
I0725 17:14:06.259255 20892 sgd_solver.cpp:106] Iteration 14100, lr = 6.70204e-06
I0725 17:14:15.667038 20892 solver.cpp:228] Iteration 14200, loss = 0.429112
I0725 17:14:15.667083 20892 solver.cpp:244]     Train net output #0: loss = 0.429112 (* 1 = 0.429112 loss)
I0725 17:14:15.667088 20892 sgd_solver.cpp:106] Iteration 14200, lr = 6.68733e-06
I0725 17:14:25.071220 20892 solver.cpp:228] Iteration 14300, loss = 0.40274
I0725 17:14:25.071280 20892 solver.cpp:244]     Train net output #0: loss = 0.40274 (* 1 = 0.40274 loss)
I0725 17:14:25.071286 20892 sgd_solver.cpp:106] Iteration 14300, lr = 6.6727e-06
I0725 17:14:34.480370 20892 solver.cpp:228] Iteration 14400, loss = 0.434138
I0725 17:14:34.480412 20892 solver.cpp:244]     Train net output #0: loss = 0.434138 (* 1 = 0.434138 loss)
I0725 17:14:34.480418 20892 sgd_solver.cpp:106] Iteration 14400, lr = 6.65815e-06
I0725 17:14:43.792196 20892 solver.cpp:337] Iteration 14500, Testing net (#0)
I0725 17:14:57.862278 20892 solver.cpp:404]     Test net output #0: accuracy = 0.784226
I0725 17:14:57.862323 20892 solver.cpp:404]     Test net output #1: loss = 0.456096 (* 1 = 0.456096 loss)
I0725 17:14:57.888721 20892 solver.cpp:228] Iteration 14500, loss = 0.46554
I0725 17:14:57.888767 20892 solver.cpp:244]     Train net output #0: loss = 0.46554 (* 1 = 0.46554 loss)
I0725 17:14:57.888777 20892 sgd_solver.cpp:106] Iteration 14500, lr = 6.64367e-06
I0725 17:15:07.252216 20892 solver.cpp:228] Iteration 14600, loss = 0.426154
I0725 17:15:07.252276 20892 solver.cpp:244]     Train net output #0: loss = 0.426154 (* 1 = 0.426154 loss)
I0725 17:15:07.252285 20892 sgd_solver.cpp:106] Iteration 14600, lr = 6.62927e-06
I0725 17:15:16.659714 20892 solver.cpp:228] Iteration 14700, loss = 0.431884
I0725 17:15:16.659759 20892 solver.cpp:244]     Train net output #0: loss = 0.431884 (* 1 = 0.431884 loss)
I0725 17:15:16.659767 20892 sgd_solver.cpp:106] Iteration 14700, lr = 6.61493e-06
I0725 17:15:26.066174 20892 solver.cpp:228] Iteration 14800, loss = 0.471248
I0725 17:15:26.066215 20892 solver.cpp:244]     Train net output #0: loss = 0.471248 (* 1 = 0.471248 loss)
I0725 17:15:26.066220 20892 sgd_solver.cpp:106] Iteration 14800, lr = 6.60067e-06
I0725 17:15:35.475180 20892 solver.cpp:228] Iteration 14900, loss = 0.464807
I0725 17:15:35.475220 20892 solver.cpp:244]     Train net output #0: loss = 0.464807 (* 1 = 0.464807 loss)
I0725 17:15:35.475226 20892 sgd_solver.cpp:106] Iteration 14900, lr = 6.58648e-06
I0725 17:15:44.799129 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_15000.caffemodel
I0725 17:15:45.155550 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_15000.solverstate
I0725 17:15:45.255210 20892 solver.cpp:337] Iteration 15000, Testing net (#0)
I0725 17:15:59.210500 20892 solver.cpp:404]     Test net output #0: accuracy = 0.789484
I0725 17:15:59.210546 20892 solver.cpp:404]     Test net output #1: loss = 0.449996 (* 1 = 0.449996 loss)
I0725 17:15:59.239748 20892 solver.cpp:228] Iteration 15000, loss = 0.428259
I0725 17:15:59.239794 20892 solver.cpp:244]     Train net output #0: loss = 0.428259 (* 1 = 0.428259 loss)
I0725 17:15:59.239805 20892 sgd_solver.cpp:106] Iteration 15000, lr = 6.57236e-06
I0725 17:16:08.610642 20892 solver.cpp:228] Iteration 15100, loss = 0.433579
I0725 17:16:08.610685 20892 solver.cpp:244]     Train net output #0: loss = 0.433579 (* 1 = 0.433579 loss)
I0725 17:16:08.610692 20892 sgd_solver.cpp:106] Iteration 15100, lr = 6.55831e-06
I0725 17:16:18.023545 20892 solver.cpp:228] Iteration 15200, loss = 0.379202
I0725 17:16:18.023588 20892 solver.cpp:244]     Train net output #0: loss = 0.379202 (* 1 = 0.379202 loss)
I0725 17:16:18.023596 20892 sgd_solver.cpp:106] Iteration 15200, lr = 6.54433e-06
I0725 17:16:27.427590 20892 solver.cpp:228] Iteration 15300, loss = 0.424253
I0725 17:16:27.427645 20892 solver.cpp:244]     Train net output #0: loss = 0.424253 (* 1 = 0.424253 loss)
I0725 17:16:27.427652 20892 sgd_solver.cpp:106] Iteration 15300, lr = 6.53043e-06
I0725 17:16:36.828205 20892 solver.cpp:228] Iteration 15400, loss = 0.553866
I0725 17:16:36.828245 20892 solver.cpp:244]     Train net output #0: loss = 0.553866 (* 1 = 0.553866 loss)
I0725 17:16:36.828251 20892 sgd_solver.cpp:106] Iteration 15400, lr = 6.51658e-06
I0725 17:16:46.135007 20892 solver.cpp:337] Iteration 15500, Testing net (#0)
I0725 17:16:51.599246 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:17:00.275373 20892 solver.cpp:404]     Test net output #0: accuracy = 0.791742
I0725 17:17:00.275439 20892 solver.cpp:404]     Test net output #1: loss = 0.446616 (* 1 = 0.446616 loss)
I0725 17:17:00.303285 20892 solver.cpp:228] Iteration 15500, loss = 0.476422
I0725 17:17:00.303339 20892 solver.cpp:244]     Train net output #0: loss = 0.476422 (* 1 = 0.476422 loss)
I0725 17:17:00.303349 20892 sgd_solver.cpp:106] Iteration 15500, lr = 6.50281e-06
I0725 17:17:09.660456 20892 solver.cpp:228] Iteration 15600, loss = 0.44082
I0725 17:17:09.660498 20892 solver.cpp:244]     Train net output #0: loss = 0.44082 (* 1 = 0.44082 loss)
I0725 17:17:09.660504 20892 sgd_solver.cpp:106] Iteration 15600, lr = 6.48911e-06
I0725 17:17:19.062104 20892 solver.cpp:228] Iteration 15700, loss = 0.418799
I0725 17:17:19.062156 20892 solver.cpp:244]     Train net output #0: loss = 0.418799 (* 1 = 0.418799 loss)
I0725 17:17:19.062163 20892 sgd_solver.cpp:106] Iteration 15700, lr = 6.47547e-06
I0725 17:17:28.463378 20892 solver.cpp:228] Iteration 15800, loss = 0.482517
I0725 17:17:28.463423 20892 solver.cpp:244]     Train net output #0: loss = 0.482517 (* 1 = 0.482517 loss)
I0725 17:17:28.463428 20892 sgd_solver.cpp:106] Iteration 15800, lr = 6.4619e-06
I0725 17:17:37.864837 20892 solver.cpp:228] Iteration 15900, loss = 0.350295
I0725 17:17:37.864892 20892 solver.cpp:244]     Train net output #0: loss = 0.350295 (* 1 = 0.350295 loss)
I0725 17:17:37.864898 20892 sgd_solver.cpp:106] Iteration 15900, lr = 6.4484e-06
I0725 17:17:47.179934 20892 solver.cpp:337] Iteration 16000, Testing net (#0)
I0725 17:18:01.354462 20892 solver.cpp:404]     Test net output #0: accuracy = 0.791516
I0725 17:18:01.354507 20892 solver.cpp:404]     Test net output #1: loss = 0.446412 (* 1 = 0.446412 loss)
I0725 17:18:01.383816 20892 solver.cpp:228] Iteration 16000, loss = 0.425206
I0725 17:18:01.383873 20892 solver.cpp:244]     Train net output #0: loss = 0.425206 (* 1 = 0.425206 loss)
I0725 17:18:01.383893 20892 sgd_solver.cpp:106] Iteration 16000, lr = 6.43496e-06
I0725 17:18:10.868660 20892 solver.cpp:228] Iteration 16100, loss = 0.49299
I0725 17:18:10.868698 20892 solver.cpp:244]     Train net output #0: loss = 0.49299 (* 1 = 0.49299 loss)
I0725 17:18:10.868705 20892 sgd_solver.cpp:106] Iteration 16100, lr = 6.42158e-06
I0725 17:18:20.310389 20892 solver.cpp:228] Iteration 16200, loss = 0.364063
I0725 17:18:20.310433 20892 solver.cpp:244]     Train net output #0: loss = 0.364063 (* 1 = 0.364063 loss)
I0725 17:18:20.310439 20892 sgd_solver.cpp:106] Iteration 16200, lr = 6.40827e-06
I0725 17:18:29.714865 20892 solver.cpp:228] Iteration 16300, loss = 0.384598
I0725 17:18:29.714915 20892 solver.cpp:244]     Train net output #0: loss = 0.384598 (* 1 = 0.384598 loss)
I0725 17:18:29.714921 20892 sgd_solver.cpp:106] Iteration 16300, lr = 6.39503e-06
I0725 17:18:39.063679 20892 solver.cpp:228] Iteration 16400, loss = 0.383536
I0725 17:18:39.063721 20892 solver.cpp:244]     Train net output #0: loss = 0.383536 (* 1 = 0.383536 loss)
I0725 17:18:39.063727 20892 sgd_solver.cpp:106] Iteration 16400, lr = 6.38185e-06
I0725 17:18:48.381382 20892 solver.cpp:337] Iteration 16500, Testing net (#0)
I0725 17:19:02.525600 20892 solver.cpp:404]     Test net output #0: accuracy = 0.785258
I0725 17:19:02.525650 20892 solver.cpp:404]     Test net output #1: loss = 0.452524 (* 1 = 0.452524 loss)
I0725 17:19:02.551961 20892 solver.cpp:228] Iteration 16500, loss = 0.479494
I0725 17:19:02.552005 20892 solver.cpp:244]     Train net output #0: loss = 0.479494 (* 1 = 0.479494 loss)
I0725 17:19:02.552014 20892 sgd_solver.cpp:106] Iteration 16500, lr = 6.36873e-06
I0725 17:19:11.950819 20892 solver.cpp:228] Iteration 16600, loss = 0.460013
I0725 17:19:11.950863 20892 solver.cpp:244]     Train net output #0: loss = 0.460013 (* 1 = 0.460013 loss)
I0725 17:19:11.950870 20892 sgd_solver.cpp:106] Iteration 16600, lr = 6.35567e-06
I0725 17:19:21.365002 20892 solver.cpp:228] Iteration 16700, loss = 0.43144
I0725 17:19:21.365052 20892 solver.cpp:244]     Train net output #0: loss = 0.43144 (* 1 = 0.43144 loss)
I0725 17:19:21.365058 20892 sgd_solver.cpp:106] Iteration 16700, lr = 6.34268e-06
I0725 17:19:30.770690 20892 solver.cpp:228] Iteration 16800, loss = 0.437853
I0725 17:19:30.770730 20892 solver.cpp:244]     Train net output #0: loss = 0.437853 (* 1 = 0.437853 loss)
I0725 17:19:30.770735 20892 sgd_solver.cpp:106] Iteration 16800, lr = 6.32975e-06
I0725 17:19:40.177860 20892 solver.cpp:228] Iteration 16900, loss = 0.445118
I0725 17:19:40.177896 20892 solver.cpp:244]     Train net output #0: loss = 0.445118 (* 1 = 0.445118 loss)
I0725 17:19:40.177902 20892 sgd_solver.cpp:106] Iteration 16900, lr = 6.31688e-06
I0725 17:19:49.489683 20892 solver.cpp:337] Iteration 17000, Testing net (#0)
I0725 17:19:52.931099 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:20:03.770202 20892 solver.cpp:404]     Test net output #0: accuracy = 0.794065
I0725 17:20:03.770261 20892 solver.cpp:404]     Test net output #1: loss = 0.441904 (* 1 = 0.441904 loss)
I0725 17:20:03.799125 20892 solver.cpp:228] Iteration 17000, loss = 0.392508
I0725 17:20:03.799191 20892 solver.cpp:244]     Train net output #0: loss = 0.392508 (* 1 = 0.392508 loss)
I0725 17:20:03.799202 20892 sgd_solver.cpp:106] Iteration 17000, lr = 6.30407e-06
I0725 17:20:13.229418 20892 solver.cpp:228] Iteration 17100, loss = 0.479577
I0725 17:20:13.229467 20892 solver.cpp:244]     Train net output #0: loss = 0.479577 (* 1 = 0.479577 loss)
I0725 17:20:13.229475 20892 sgd_solver.cpp:106] Iteration 17100, lr = 6.29132e-06
I0725 17:20:22.697868 20892 solver.cpp:228] Iteration 17200, loss = 0.362633
I0725 17:20:22.697908 20892 solver.cpp:244]     Train net output #0: loss = 0.362633 (* 1 = 0.362633 loss)
I0725 17:20:22.697914 20892 sgd_solver.cpp:106] Iteration 17200, lr = 6.27864e-06
I0725 17:20:32.109263 20892 solver.cpp:228] Iteration 17300, loss = 0.369655
I0725 17:20:32.109304 20892 solver.cpp:244]     Train net output #0: loss = 0.369655 (* 1 = 0.369655 loss)
I0725 17:20:32.109310 20892 sgd_solver.cpp:106] Iteration 17300, lr = 6.26601e-06
I0725 17:20:41.516142 20892 solver.cpp:228] Iteration 17400, loss = 0.445462
I0725 17:20:41.516192 20892 solver.cpp:244]     Train net output #0: loss = 0.445462 (* 1 = 0.445462 loss)
I0725 17:20:41.516198 20892 sgd_solver.cpp:106] Iteration 17400, lr = 6.25344e-06
I0725 17:20:50.835568 20892 solver.cpp:337] Iteration 17500, Testing net (#0)
I0725 17:21:05.046596 20892 solver.cpp:404]     Test net output #0: accuracy = 0.794871
I0725 17:21:05.046653 20892 solver.cpp:404]     Test net output #1: loss = 0.440202 (* 1 = 0.440202 loss)
I0725 17:21:05.075925 20892 solver.cpp:228] Iteration 17500, loss = 0.491089
I0725 17:21:05.075984 20892 solver.cpp:244]     Train net output #0: loss = 0.491089 (* 1 = 0.491089 loss)
I0725 17:21:05.075995 20892 sgd_solver.cpp:106] Iteration 17500, lr = 6.24093e-06
I0725 17:21:14.478610 20892 solver.cpp:228] Iteration 17600, loss = 0.361662
I0725 17:21:14.478655 20892 solver.cpp:244]     Train net output #0: loss = 0.361662 (* 1 = 0.361662 loss)
I0725 17:21:14.478662 20892 sgd_solver.cpp:106] Iteration 17600, lr = 6.22847e-06
I0725 17:21:23.892755 20892 solver.cpp:228] Iteration 17700, loss = 0.352557
I0725 17:21:23.892799 20892 solver.cpp:244]     Train net output #0: loss = 0.352557 (* 1 = 0.352557 loss)
I0725 17:21:23.892805 20892 sgd_solver.cpp:106] Iteration 17700, lr = 6.21608e-06
I0725 17:21:33.304910 20892 solver.cpp:228] Iteration 17800, loss = 0.474295
I0725 17:21:33.304949 20892 solver.cpp:244]     Train net output #0: loss = 0.474295 (* 1 = 0.474295 loss)
I0725 17:21:33.304955 20892 sgd_solver.cpp:106] Iteration 17800, lr = 6.20374e-06
I0725 17:21:42.715975 20892 solver.cpp:228] Iteration 17900, loss = 0.429937
I0725 17:21:42.716025 20892 solver.cpp:244]     Train net output #0: loss = 0.429937 (* 1 = 0.429937 loss)
I0725 17:21:42.716032 20892 sgd_solver.cpp:106] Iteration 17900, lr = 6.19146e-06
I0725 17:21:52.033030 20892 solver.cpp:337] Iteration 18000, Testing net (#0)
I0725 17:22:06.122473 20892 solver.cpp:404]     Test net output #0: accuracy = 0.794839
I0725 17:22:06.122515 20892 solver.cpp:404]     Test net output #1: loss = 0.439264 (* 1 = 0.439264 loss)
I0725 17:22:06.152942 20892 solver.cpp:228] Iteration 18000, loss = 0.459611
I0725 17:22:06.152995 20892 solver.cpp:244]     Train net output #0: loss = 0.459611 (* 1 = 0.459611 loss)
I0725 17:22:06.153007 20892 sgd_solver.cpp:106] Iteration 18000, lr = 6.17924e-06
I0725 17:22:15.574800 20892 solver.cpp:228] Iteration 18100, loss = 0.449377
I0725 17:22:15.574843 20892 solver.cpp:244]     Train net output #0: loss = 0.449377 (* 1 = 0.449377 loss)
I0725 17:22:15.574849 20892 sgd_solver.cpp:106] Iteration 18100, lr = 6.16707e-06
I0725 17:22:25.144966 20892 solver.cpp:228] Iteration 18200, loss = 0.480819
I0725 17:22:25.145006 20892 solver.cpp:244]     Train net output #0: loss = 0.480819 (* 1 = 0.480819 loss)
I0725 17:22:25.145014 20892 sgd_solver.cpp:106] Iteration 18200, lr = 6.15496e-06
I0725 17:22:34.554232 20892 solver.cpp:228] Iteration 18300, loss = 0.445604
I0725 17:22:34.554292 20892 solver.cpp:244]     Train net output #0: loss = 0.445604 (* 1 = 0.445604 loss)
I0725 17:22:34.554299 20892 sgd_solver.cpp:106] Iteration 18300, lr = 6.1429e-06
I0725 17:22:43.960665 20892 solver.cpp:228] Iteration 18400, loss = 0.346248
I0725 17:22:43.960711 20892 solver.cpp:244]     Train net output #0: loss = 0.346248 (* 1 = 0.346248 loss)
I0725 17:22:43.960716 20892 sgd_solver.cpp:106] Iteration 18400, lr = 6.1309e-06
I0725 17:22:53.216375 20892 solver.cpp:337] Iteration 18500, Testing net (#0)
I0725 17:22:58.696224 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:23:07.480677 20892 solver.cpp:404]     Test net output #0: accuracy = 0.791613
I0725 17:23:07.480734 20892 solver.cpp:404]     Test net output #1: loss = 0.442961 (* 1 = 0.442961 loss)
I0725 17:23:07.510206 20892 solver.cpp:228] Iteration 18500, loss = 0.417965
I0725 17:23:07.510251 20892 solver.cpp:244]     Train net output #0: loss = 0.417965 (* 1 = 0.417965 loss)
I0725 17:23:07.510262 20892 sgd_solver.cpp:106] Iteration 18500, lr = 6.11895e-06
I0725 17:23:16.912772 20892 solver.cpp:228] Iteration 18600, loss = 0.346788
I0725 17:23:16.912819 20892 solver.cpp:244]     Train net output #0: loss = 0.346788 (* 1 = 0.346788 loss)
I0725 17:23:16.912827 20892 sgd_solver.cpp:106] Iteration 18600, lr = 6.10706e-06
I0725 17:23:26.474907 20892 solver.cpp:228] Iteration 18700, loss = 0.440788
I0725 17:23:26.474951 20892 solver.cpp:244]     Train net output #0: loss = 0.440788 (* 1 = 0.440788 loss)
I0725 17:23:26.474967 20892 sgd_solver.cpp:106] Iteration 18700, lr = 6.09522e-06
I0725 17:23:35.958019 20892 solver.cpp:228] Iteration 18800, loss = 0.476491
I0725 17:23:35.958066 20892 solver.cpp:244]     Train net output #0: loss = 0.476491 (* 1 = 0.476491 loss)
I0725 17:23:35.958072 20892 sgd_solver.cpp:106] Iteration 18800, lr = 6.08343e-06
I0725 17:23:45.360147 20892 solver.cpp:228] Iteration 18900, loss = 0.441194
I0725 17:23:45.360195 20892 solver.cpp:244]     Train net output #0: loss = 0.441194 (* 1 = 0.441194 loss)
I0725 17:23:45.360201 20892 sgd_solver.cpp:106] Iteration 18900, lr = 6.0717e-06
I0725 17:23:54.672369 20892 solver.cpp:337] Iteration 19000, Testing net (#0)
I0725 17:24:08.643774 20892 solver.cpp:404]     Test net output #0: accuracy = 0.800452
I0725 17:24:08.643812 20892 solver.cpp:404]     Test net output #1: loss = 0.432404 (* 1 = 0.432404 loss)
I0725 17:24:08.672778 20892 solver.cpp:228] Iteration 19000, loss = 0.440241
I0725 17:24:08.672802 20892 solver.cpp:244]     Train net output #0: loss = 0.440241 (* 1 = 0.440241 loss)
I0725 17:24:08.672826 20892 sgd_solver.cpp:106] Iteration 19000, lr = 6.06002e-06
I0725 17:24:18.049975 20892 solver.cpp:228] Iteration 19100, loss = 0.445062
I0725 17:24:18.050012 20892 solver.cpp:244]     Train net output #0: loss = 0.445062 (* 1 = 0.445062 loss)
I0725 17:24:18.050019 20892 sgd_solver.cpp:106] Iteration 19100, lr = 6.04839e-06
I0725 17:24:27.462213 20892 solver.cpp:228] Iteration 19200, loss = 0.406386
I0725 17:24:27.462265 20892 solver.cpp:244]     Train net output #0: loss = 0.406386 (* 1 = 0.406386 loss)
I0725 17:24:27.462271 20892 sgd_solver.cpp:106] Iteration 19200, lr = 6.03682e-06
I0725 17:24:36.870961 20892 solver.cpp:228] Iteration 19300, loss = 0.39879
I0725 17:24:36.871011 20892 solver.cpp:244]     Train net output #0: loss = 0.39879 (* 1 = 0.39879 loss)
I0725 17:24:36.871016 20892 sgd_solver.cpp:106] Iteration 19300, lr = 6.02529e-06
I0725 17:24:46.274668 20892 solver.cpp:228] Iteration 19400, loss = 0.468635
I0725 17:24:46.274715 20892 solver.cpp:244]     Train net output #0: loss = 0.468635 (* 1 = 0.468635 loss)
I0725 17:24:46.274724 20892 sgd_solver.cpp:106] Iteration 19400, lr = 6.01382e-06
I0725 17:24:55.588171 20892 solver.cpp:337] Iteration 19500, Testing net (#0)
I0725 17:25:09.946893 20892 solver.cpp:404]     Test net output #0: accuracy = 0.799484
I0725 17:25:09.946946 20892 solver.cpp:404]     Test net output #1: loss = 0.432833 (* 1 = 0.432833 loss)
I0725 17:25:09.975745 20892 solver.cpp:228] Iteration 19500, loss = 0.362326
I0725 17:25:09.975808 20892 solver.cpp:244]     Train net output #0: loss = 0.362326 (* 1 = 0.362326 loss)
I0725 17:25:09.975819 20892 sgd_solver.cpp:106] Iteration 19500, lr = 6.0024e-06
I0725 17:25:19.307157 20892 solver.cpp:228] Iteration 19600, loss = 0.349741
I0725 17:25:19.307211 20892 solver.cpp:244]     Train net output #0: loss = 0.349741 (* 1 = 0.349741 loss)
I0725 17:25:19.307219 20892 sgd_solver.cpp:106] Iteration 19600, lr = 5.99102e-06
I0725 17:25:28.711809 20892 solver.cpp:228] Iteration 19700, loss = 0.33967
I0725 17:25:28.711856 20892 solver.cpp:244]     Train net output #0: loss = 0.33967 (* 1 = 0.33967 loss)
I0725 17:25:28.711863 20892 sgd_solver.cpp:106] Iteration 19700, lr = 5.9797e-06
I0725 17:25:38.117481 20892 solver.cpp:228] Iteration 19800, loss = 0.394656
I0725 17:25:38.117532 20892 solver.cpp:244]     Train net output #0: loss = 0.394656 (* 1 = 0.394656 loss)
I0725 17:25:38.117539 20892 sgd_solver.cpp:106] Iteration 19800, lr = 5.96843e-06
I0725 17:25:47.520339 20892 solver.cpp:228] Iteration 19900, loss = 0.377868
I0725 17:25:47.520395 20892 solver.cpp:244]     Train net output #0: loss = 0.377868 (* 1 = 0.377868 loss)
I0725 17:25:47.520401 20892 sgd_solver.cpp:106] Iteration 19900, lr = 5.95721e-06
I0725 17:25:56.830971 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_20000.caffemodel
I0725 17:25:57.188912 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_20000.solverstate
I0725 17:25:57.288928 20892 solver.cpp:337] Iteration 20000, Testing net (#0)
I0725 17:26:01.389319 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:26:11.284348 20892 solver.cpp:404]     Test net output #0: accuracy = 0.801
I0725 17:26:11.284394 20892 solver.cpp:404]     Test net output #1: loss = 0.430541 (* 1 = 0.430541 loss)
I0725 17:26:11.313746 20892 solver.cpp:228] Iteration 20000, loss = 0.441944
I0725 17:26:11.313804 20892 solver.cpp:244]     Train net output #0: loss = 0.441944 (* 1 = 0.441944 loss)
I0725 17:26:11.313817 20892 sgd_solver.cpp:106] Iteration 20000, lr = 5.94604e-06
I0725 17:26:20.666651 20892 solver.cpp:228] Iteration 20100, loss = 0.38041
I0725 17:26:20.666702 20892 solver.cpp:244]     Train net output #0: loss = 0.38041 (* 1 = 0.38041 loss)
I0725 17:26:20.666709 20892 sgd_solver.cpp:106] Iteration 20100, lr = 5.93491e-06
I0725 17:26:30.075664 20892 solver.cpp:228] Iteration 20200, loss = 0.401542
I0725 17:26:30.075713 20892 solver.cpp:244]     Train net output #0: loss = 0.401542 (* 1 = 0.401542 loss)
I0725 17:26:30.075719 20892 sgd_solver.cpp:106] Iteration 20200, lr = 5.92384e-06
I0725 17:26:39.481304 20892 solver.cpp:228] Iteration 20300, loss = 0.363261
I0725 17:26:39.481348 20892 solver.cpp:244]     Train net output #0: loss = 0.363261 (* 1 = 0.363261 loss)
I0725 17:26:39.481353 20892 sgd_solver.cpp:106] Iteration 20300, lr = 5.91281e-06
I0725 17:26:48.885226 20892 solver.cpp:228] Iteration 20400, loss = 0.357429
I0725 17:26:48.885265 20892 solver.cpp:244]     Train net output #0: loss = 0.357429 (* 1 = 0.357429 loss)
I0725 17:26:48.885272 20892 sgd_solver.cpp:106] Iteration 20400, lr = 5.90183e-06
I0725 17:26:58.195569 20892 solver.cpp:337] Iteration 20500, Testing net (#0)
I0725 17:27:12.424595 20892 solver.cpp:404]     Test net output #0: accuracy = 0.799097
I0725 17:27:12.424643 20892 solver.cpp:404]     Test net output #1: loss = 0.432639 (* 1 = 0.432639 loss)
I0725 17:27:12.453533 20892 solver.cpp:228] Iteration 20500, loss = 0.492315
I0725 17:27:12.453553 20892 solver.cpp:244]     Train net output #0: loss = 0.492315 (* 1 = 0.492315 loss)
I0725 17:27:12.453562 20892 sgd_solver.cpp:106] Iteration 20500, lr = 5.89089e-06
I0725 17:27:21.808557 20892 solver.cpp:228] Iteration 20600, loss = 0.516847
I0725 17:27:21.808595 20892 solver.cpp:244]     Train net output #0: loss = 0.516847 (* 1 = 0.516847 loss)
I0725 17:27:21.808603 20892 sgd_solver.cpp:106] Iteration 20600, lr = 5.88001e-06
I0725 17:27:31.219157 20892 solver.cpp:228] Iteration 20700, loss = 0.398458
I0725 17:27:31.219200 20892 solver.cpp:244]     Train net output #0: loss = 0.398458 (* 1 = 0.398458 loss)
I0725 17:27:31.219207 20892 sgd_solver.cpp:106] Iteration 20700, lr = 5.86917e-06
I0725 17:27:40.623661 20892 solver.cpp:228] Iteration 20800, loss = 0.457742
I0725 17:27:40.623699 20892 solver.cpp:244]     Train net output #0: loss = 0.457742 (* 1 = 0.457742 loss)
I0725 17:27:40.623705 20892 sgd_solver.cpp:106] Iteration 20800, lr = 5.85838e-06
I0725 17:27:50.036720 20892 solver.cpp:228] Iteration 20900, loss = 0.35571
I0725 17:27:50.036778 20892 solver.cpp:244]     Train net output #0: loss = 0.35571 (* 1 = 0.35571 loss)
I0725 17:27:50.036785 20892 sgd_solver.cpp:106] Iteration 20900, lr = 5.84763e-06
I0725 17:27:59.314003 20892 solver.cpp:337] Iteration 21000, Testing net (#0)
I0725 17:28:13.347836 20892 solver.cpp:404]     Test net output #0: accuracy = 0.802806
I0725 17:28:13.347879 20892 solver.cpp:404]     Test net output #1: loss = 0.426937 (* 1 = 0.426937 loss)
I0725 17:28:13.377502 20892 solver.cpp:228] Iteration 21000, loss = 0.437799
I0725 17:28:13.377557 20892 solver.cpp:244]     Train net output #0: loss = 0.437799 (* 1 = 0.437799 loss)
I0725 17:28:13.377566 20892 sgd_solver.cpp:106] Iteration 21000, lr = 5.83693e-06
I0725 17:28:22.786869 20892 solver.cpp:228] Iteration 21100, loss = 0.473647
I0725 17:28:22.786911 20892 solver.cpp:244]     Train net output #0: loss = 0.473647 (* 1 = 0.473647 loss)
I0725 17:28:22.786917 20892 sgd_solver.cpp:106] Iteration 21100, lr = 5.82628e-06
I0725 17:28:32.193120 20892 solver.cpp:228] Iteration 21200, loss = 0.456669
I0725 17:28:32.193158 20892 solver.cpp:244]     Train net output #0: loss = 0.456669 (* 1 = 0.456669 loss)
I0725 17:28:32.193164 20892 sgd_solver.cpp:106] Iteration 21200, lr = 5.81567e-06
I0725 17:28:41.597115 20892 solver.cpp:228] Iteration 21300, loss = 0.428158
I0725 17:28:41.597165 20892 solver.cpp:244]     Train net output #0: loss = 0.428158 (* 1 = 0.428158 loss)
I0725 17:28:41.597172 20892 sgd_solver.cpp:106] Iteration 21300, lr = 5.8051e-06
I0725 17:28:50.996196 20892 solver.cpp:228] Iteration 21400, loss = 0.355839
I0725 17:28:50.996245 20892 solver.cpp:244]     Train net output #0: loss = 0.355839 (* 1 = 0.355839 loss)
I0725 17:28:50.996253 20892 sgd_solver.cpp:106] Iteration 21400, lr = 5.79458e-06
I0725 17:29:00.271677 20892 solver.cpp:337] Iteration 21500, Testing net (#0)
I0725 17:29:03.426584 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:29:14.534013 20892 solver.cpp:404]     Test net output #0: accuracy = 0.802516
I0725 17:29:14.534060 20892 solver.cpp:404]     Test net output #1: loss = 0.427713 (* 1 = 0.427713 loss)
I0725 17:29:14.563205 20892 solver.cpp:228] Iteration 21500, loss = 0.371982
I0725 17:29:14.563241 20892 solver.cpp:244]     Train net output #0: loss = 0.371982 (* 1 = 0.371982 loss)
I0725 17:29:14.563251 20892 sgd_solver.cpp:106] Iteration 21500, lr = 5.78411e-06
I0725 17:29:23.950567 20892 solver.cpp:228] Iteration 21600, loss = 0.38469
I0725 17:29:23.950613 20892 solver.cpp:244]     Train net output #0: loss = 0.38469 (* 1 = 0.38469 loss)
I0725 17:29:23.950619 20892 sgd_solver.cpp:106] Iteration 21600, lr = 5.77368e-06
I0725 17:29:33.352699 20892 solver.cpp:228] Iteration 21700, loss = 0.47128
I0725 17:29:33.352743 20892 solver.cpp:244]     Train net output #0: loss = 0.47128 (* 1 = 0.47128 loss)
I0725 17:29:33.352749 20892 sgd_solver.cpp:106] Iteration 21700, lr = 5.76329e-06
I0725 17:29:42.758016 20892 solver.cpp:228] Iteration 21800, loss = 0.378306
I0725 17:29:42.758064 20892 solver.cpp:244]     Train net output #0: loss = 0.378306 (* 1 = 0.378306 loss)
I0725 17:29:42.758070 20892 sgd_solver.cpp:106] Iteration 21800, lr = 5.75295e-06
I0725 17:29:52.159183 20892 solver.cpp:228] Iteration 21900, loss = 0.402233
I0725 17:29:52.159231 20892 solver.cpp:244]     Train net output #0: loss = 0.402233 (* 1 = 0.402233 loss)
I0725 17:29:52.159256 20892 sgd_solver.cpp:106] Iteration 21900, lr = 5.74265e-06
I0725 17:30:01.470108 20892 solver.cpp:337] Iteration 22000, Testing net (#0)
I0725 17:30:15.580816 20892 solver.cpp:404]     Test net output #0: accuracy = 0.798322
I0725 17:30:15.580883 20892 solver.cpp:404]     Test net output #1: loss = 0.431729 (* 1 = 0.431729 loss)
I0725 17:30:15.607589 20892 solver.cpp:228] Iteration 22000, loss = 0.41719
I0725 17:30:15.607655 20892 solver.cpp:244]     Train net output #0: loss = 0.41719 (* 1 = 0.41719 loss)
I0725 17:30:15.607674 20892 sgd_solver.cpp:106] Iteration 22000, lr = 5.73239e-06
I0725 17:30:24.965926 20892 solver.cpp:228] Iteration 22100, loss = 0.363059
I0725 17:30:24.965979 20892 solver.cpp:244]     Train net output #0: loss = 0.363059 (* 1 = 0.363059 loss)
I0725 17:30:24.965986 20892 sgd_solver.cpp:106] Iteration 22100, lr = 5.72217e-06
I0725 17:30:34.369163 20892 solver.cpp:228] Iteration 22200, loss = 0.428833
I0725 17:30:34.369216 20892 solver.cpp:244]     Train net output #0: loss = 0.428833 (* 1 = 0.428833 loss)
I0725 17:30:34.369225 20892 sgd_solver.cpp:106] Iteration 22200, lr = 5.712e-06
I0725 17:30:43.779651 20892 solver.cpp:228] Iteration 22300, loss = 0.495701
I0725 17:30:43.779700 20892 solver.cpp:244]     Train net output #0: loss = 0.495701 (* 1 = 0.495701 loss)
I0725 17:30:43.779708 20892 sgd_solver.cpp:106] Iteration 22300, lr = 5.70187e-06
I0725 17:30:53.187237 20892 solver.cpp:228] Iteration 22400, loss = 0.372463
I0725 17:30:53.187280 20892 solver.cpp:244]     Train net output #0: loss = 0.372463 (* 1 = 0.372463 loss)
I0725 17:30:53.187286 20892 sgd_solver.cpp:106] Iteration 22400, lr = 5.69178e-06
I0725 17:31:02.496678 20892 solver.cpp:337] Iteration 22500, Testing net (#0)
I0725 17:31:16.630461 20892 solver.cpp:404]     Test net output #0: accuracy = 0.804452
I0725 17:31:16.630534 20892 solver.cpp:404]     Test net output #1: loss = 0.424116 (* 1 = 0.424116 loss)
I0725 17:31:16.659768 20892 solver.cpp:228] Iteration 22500, loss = 0.536259
I0725 17:31:16.659834 20892 solver.cpp:244]     Train net output #0: loss = 0.536259 (* 1 = 0.536259 loss)
I0725 17:31:16.659847 20892 sgd_solver.cpp:106] Iteration 22500, lr = 5.68173e-06
I0725 17:31:26.037446 20892 solver.cpp:228] Iteration 22600, loss = 0.448912
I0725 17:31:26.037502 20892 solver.cpp:244]     Train net output #0: loss = 0.448912 (* 1 = 0.448912 loss)
I0725 17:31:26.037509 20892 sgd_solver.cpp:106] Iteration 22600, lr = 5.67173e-06
I0725 17:31:35.443699 20892 solver.cpp:228] Iteration 22700, loss = 0.417551
I0725 17:31:35.443764 20892 solver.cpp:244]     Train net output #0: loss = 0.417551 (* 1 = 0.417551 loss)
I0725 17:31:35.443773 20892 sgd_solver.cpp:106] Iteration 22700, lr = 5.66176e-06
I0725 17:31:44.833822 20892 solver.cpp:228] Iteration 22800, loss = 0.384957
I0725 17:31:44.833881 20892 solver.cpp:244]     Train net output #0: loss = 0.384957 (* 1 = 0.384957 loss)
I0725 17:31:44.833889 20892 sgd_solver.cpp:106] Iteration 22800, lr = 5.65184e-06
I0725 17:31:54.200419 20892 solver.cpp:228] Iteration 22900, loss = 0.313876
I0725 17:31:54.200470 20892 solver.cpp:244]     Train net output #0: loss = 0.313876 (* 1 = 0.313876 loss)
I0725 17:31:54.200479 20892 sgd_solver.cpp:106] Iteration 22900, lr = 5.64195e-06
I0725 17:32:03.517066 20892 solver.cpp:337] Iteration 23000, Testing net (#0)
I0725 17:32:04.331015 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:32:17.715134 20892 solver.cpp:404]     Test net output #0: accuracy = 0.804516
I0725 17:32:17.715196 20892 solver.cpp:404]     Test net output #1: loss = 0.422013 (* 1 = 0.422013 loss)
I0725 17:32:17.744488 20892 solver.cpp:228] Iteration 23000, loss = 0.337372
I0725 17:32:17.744547 20892 solver.cpp:244]     Train net output #0: loss = 0.337372 (* 1 = 0.337372 loss)
I0725 17:32:17.744559 20892 sgd_solver.cpp:106] Iteration 23000, lr = 5.63211e-06
I0725 17:32:27.121120 20892 solver.cpp:228] Iteration 23100, loss = 0.364478
I0725 17:32:27.121176 20892 solver.cpp:244]     Train net output #0: loss = 0.364478 (* 1 = 0.364478 loss)
I0725 17:32:27.121184 20892 sgd_solver.cpp:106] Iteration 23100, lr = 5.62231e-06
I0725 17:32:36.528581 20892 solver.cpp:228] Iteration 23200, loss = 0.374023
I0725 17:32:36.528628 20892 solver.cpp:244]     Train net output #0: loss = 0.374023 (* 1 = 0.374023 loss)
I0725 17:32:36.528635 20892 sgd_solver.cpp:106] Iteration 23200, lr = 5.61254e-06
I0725 17:32:45.936272 20892 solver.cpp:228] Iteration 23300, loss = 0.356053
I0725 17:32:45.936334 20892 solver.cpp:244]     Train net output #0: loss = 0.356053 (* 1 = 0.356053 loss)
I0725 17:32:45.936342 20892 sgd_solver.cpp:106] Iteration 23300, lr = 5.60282e-06
I0725 17:32:55.341553 20892 solver.cpp:228] Iteration 23400, loss = 0.461287
I0725 17:32:55.341612 20892 solver.cpp:244]     Train net output #0: loss = 0.461287 (* 1 = 0.461287 loss)
I0725 17:32:55.341620 20892 sgd_solver.cpp:106] Iteration 23400, lr = 5.59313e-06
I0725 17:33:04.651362 20892 solver.cpp:337] Iteration 23500, Testing net (#0)
I0725 17:33:18.898016 20892 solver.cpp:404]     Test net output #0: accuracy = 0.805
I0725 17:33:18.898072 20892 solver.cpp:404]     Test net output #1: loss = 0.422766 (* 1 = 0.422766 loss)
I0725 17:33:18.927623 20892 solver.cpp:228] Iteration 23500, loss = 0.456764
I0725 17:33:18.927677 20892 solver.cpp:244]     Train net output #0: loss = 0.456764 (* 1 = 0.456764 loss)
I0725 17:33:18.927690 20892 sgd_solver.cpp:106] Iteration 23500, lr = 5.58349e-06
I0725 17:33:28.299513 20892 solver.cpp:228] Iteration 23600, loss = 0.478306
I0725 17:33:28.299562 20892 solver.cpp:244]     Train net output #0: loss = 0.478306 (* 1 = 0.478306 loss)
I0725 17:33:28.299571 20892 sgd_solver.cpp:106] Iteration 23600, lr = 5.57388e-06
I0725 17:33:37.872270 20892 solver.cpp:228] Iteration 23700, loss = 0.348682
I0725 17:33:37.872323 20892 solver.cpp:244]     Train net output #0: loss = 0.348682 (* 1 = 0.348682 loss)
I0725 17:33:37.872330 20892 sgd_solver.cpp:106] Iteration 23700, lr = 5.56431e-06
I0725 17:33:47.294617 20892 solver.cpp:228] Iteration 23800, loss = 0.422983
I0725 17:33:47.294668 20892 solver.cpp:244]     Train net output #0: loss = 0.422983 (* 1 = 0.422983 loss)
I0725 17:33:47.294674 20892 sgd_solver.cpp:106] Iteration 23800, lr = 5.55478e-06
I0725 17:33:56.697702 20892 solver.cpp:228] Iteration 23900, loss = 0.348026
I0725 17:33:56.697746 20892 solver.cpp:244]     Train net output #0: loss = 0.348026 (* 1 = 0.348026 loss)
I0725 17:33:56.697751 20892 sgd_solver.cpp:106] Iteration 23900, lr = 5.54529e-06
I0725 17:34:05.937588 20892 solver.cpp:337] Iteration 24000, Testing net (#0)
I0725 17:34:20.095166 20892 solver.cpp:404]     Test net output #0: accuracy = 0.796968
I0725 17:34:20.095217 20892 solver.cpp:404]     Test net output #1: loss = 0.431167 (* 1 = 0.431167 loss)
I0725 17:34:20.126693 20892 solver.cpp:228] Iteration 24000, loss = 0.489344
I0725 17:34:20.126715 20892 solver.cpp:244]     Train net output #0: loss = 0.489344 (* 1 = 0.489344 loss)
I0725 17:34:20.126734 20892 sgd_solver.cpp:106] Iteration 24000, lr = 5.53583e-06
I0725 17:34:29.509902 20892 solver.cpp:228] Iteration 24100, loss = 0.507612
I0725 17:34:29.509959 20892 solver.cpp:244]     Train net output #0: loss = 0.507612 (* 1 = 0.507612 loss)
I0725 17:34:29.509968 20892 sgd_solver.cpp:106] Iteration 24100, lr = 5.52642e-06
I0725 17:34:39.035342 20892 solver.cpp:228] Iteration 24200, loss = 0.371434
I0725 17:34:39.035396 20892 solver.cpp:244]     Train net output #0: loss = 0.371434 (* 1 = 0.371434 loss)
I0725 17:34:39.035409 20892 sgd_solver.cpp:106] Iteration 24200, lr = 5.51704e-06
I0725 17:34:48.484313 20892 solver.cpp:228] Iteration 24300, loss = 0.50211
I0725 17:34:48.484357 20892 solver.cpp:244]     Train net output #0: loss = 0.50211 (* 1 = 0.50211 loss)
I0725 17:34:48.484364 20892 sgd_solver.cpp:106] Iteration 24300, lr = 5.50769e-06
I0725 17:34:57.812436 20892 solver.cpp:228] Iteration 24400, loss = 0.351921
I0725 17:34:57.812497 20892 solver.cpp:244]     Train net output #0: loss = 0.351921 (* 1 = 0.351921 loss)
I0725 17:34:57.812505 20892 sgd_solver.cpp:106] Iteration 24400, lr = 5.49839e-06
I0725 17:35:07.123560 20892 solver.cpp:337] Iteration 24500, Testing net (#0)
I0725 17:35:10.486004 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:35:21.216989 20892 solver.cpp:404]     Test net output #0: accuracy = 0.806581
I0725 17:35:21.217043 20892 solver.cpp:404]     Test net output #1: loss = 0.41956 (* 1 = 0.41956 loss)
I0725 17:35:21.246088 20892 solver.cpp:228] Iteration 24500, loss = 0.449735
I0725 17:35:21.246140 20892 solver.cpp:244]     Train net output #0: loss = 0.449735 (* 1 = 0.449735 loss)
I0725 17:35:21.246153 20892 sgd_solver.cpp:106] Iteration 24500, lr = 5.48912e-06
I0725 17:35:30.590582 20892 solver.cpp:228] Iteration 24600, loss = 0.373048
I0725 17:35:30.590647 20892 solver.cpp:244]     Train net output #0: loss = 0.373048 (* 1 = 0.373048 loss)
I0725 17:35:30.590656 20892 sgd_solver.cpp:106] Iteration 24600, lr = 5.47988e-06
I0725 17:35:40.146687 20892 solver.cpp:228] Iteration 24700, loss = 0.374915
I0725 17:35:40.146735 20892 solver.cpp:244]     Train net output #0: loss = 0.374915 (* 1 = 0.374915 loss)
I0725 17:35:40.146742 20892 sgd_solver.cpp:106] Iteration 24700, lr = 5.47069e-06
I0725 17:35:49.603159 20892 solver.cpp:228] Iteration 24800, loss = 0.412499
I0725 17:35:49.603200 20892 solver.cpp:244]     Train net output #0: loss = 0.412499 (* 1 = 0.412499 loss)
I0725 17:35:49.603206 20892 sgd_solver.cpp:106] Iteration 24800, lr = 5.46153e-06
I0725 17:35:59.009212 20892 solver.cpp:228] Iteration 24900, loss = 0.320903
I0725 17:35:59.009263 20892 solver.cpp:244]     Train net output #0: loss = 0.320903 (* 1 = 0.320903 loss)
I0725 17:35:59.009271 20892 sgd_solver.cpp:106] Iteration 24900, lr = 5.4524e-06
I0725 17:36:08.260766 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_25000.caffemodel
I0725 17:36:08.612272 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_25000.solverstate
I0725 17:36:08.710242 20892 solver.cpp:337] Iteration 25000, Testing net (#0)
I0725 17:36:22.772524 20892 solver.cpp:404]     Test net output #0: accuracy = 0.807258
I0725 17:36:22.772580 20892 solver.cpp:404]     Test net output #1: loss = 0.418147 (* 1 = 0.418147 loss)
I0725 17:36:22.801929 20892 solver.cpp:228] Iteration 25000, loss = 0.406469
I0725 17:36:22.801965 20892 solver.cpp:244]     Train net output #0: loss = 0.406469 (* 1 = 0.406469 loss)
I0725 17:36:22.801986 20892 sgd_solver.cpp:106] Iteration 25000, lr = 5.44331e-06
I0725 17:36:32.194020 20892 solver.cpp:228] Iteration 25100, loss = 0.395811
I0725 17:36:32.194059 20892 solver.cpp:244]     Train net output #0: loss = 0.395811 (* 1 = 0.395811 loss)
I0725 17:36:32.194066 20892 sgd_solver.cpp:106] Iteration 25100, lr = 5.43426e-06
I0725 17:36:41.612323 20892 solver.cpp:228] Iteration 25200, loss = 0.357265
I0725 17:36:41.612372 20892 solver.cpp:244]     Train net output #0: loss = 0.357265 (* 1 = 0.357265 loss)
I0725 17:36:41.612381 20892 sgd_solver.cpp:106] Iteration 25200, lr = 5.42524e-06
I0725 17:36:51.027036 20892 solver.cpp:228] Iteration 25300, loss = 0.48682
I0725 17:36:51.027096 20892 solver.cpp:244]     Train net output #0: loss = 0.48682 (* 1 = 0.48682 loss)
I0725 17:36:51.027114 20892 sgd_solver.cpp:106] Iteration 25300, lr = 5.41625e-06
I0725 17:37:00.440892 20892 solver.cpp:228] Iteration 25400, loss = 0.408323
I0725 17:37:00.440946 20892 solver.cpp:244]     Train net output #0: loss = 0.408323 (* 1 = 0.408323 loss)
I0725 17:37:00.440954 20892 sgd_solver.cpp:106] Iteration 25400, lr = 5.4073e-06
I0725 17:37:09.759554 20892 solver.cpp:337] Iteration 25500, Testing net (#0)
I0725 17:37:24.038921 20892 solver.cpp:404]     Test net output #0: accuracy = 0.807097
I0725 17:37:24.038964 20892 solver.cpp:404]     Test net output #1: loss = 0.418227 (* 1 = 0.418227 loss)
I0725 17:37:24.071241 20892 solver.cpp:228] Iteration 25500, loss = 0.425399
I0725 17:37:24.071274 20892 solver.cpp:244]     Train net output #0: loss = 0.425399 (* 1 = 0.425399 loss)
I0725 17:37:24.071285 20892 sgd_solver.cpp:106] Iteration 25500, lr = 5.39839e-06
I0725 17:37:33.430003 20892 solver.cpp:228] Iteration 25600, loss = 0.31729
I0725 17:37:33.430042 20892 solver.cpp:244]     Train net output #0: loss = 0.31729 (* 1 = 0.31729 loss)
I0725 17:37:33.430048 20892 sgd_solver.cpp:106] Iteration 25600, lr = 5.3895e-06
I0725 17:37:42.838707 20892 solver.cpp:228] Iteration 25700, loss = 0.363133
I0725 17:37:42.838749 20892 solver.cpp:244]     Train net output #0: loss = 0.363133 (* 1 = 0.363133 loss)
I0725 17:37:42.838755 20892 sgd_solver.cpp:106] Iteration 25700, lr = 5.38066e-06
I0725 17:37:52.246670 20892 solver.cpp:228] Iteration 25800, loss = 0.362876
I0725 17:37:52.246708 20892 solver.cpp:244]     Train net output #0: loss = 0.362876 (* 1 = 0.362876 loss)
I0725 17:37:52.246716 20892 sgd_solver.cpp:106] Iteration 25800, lr = 5.37184e-06
I0725 17:38:01.659554 20892 solver.cpp:228] Iteration 25900, loss = 0.348705
I0725 17:38:01.659610 20892 solver.cpp:244]     Train net output #0: loss = 0.348705 (* 1 = 0.348705 loss)
I0725 17:38:01.659620 20892 sgd_solver.cpp:106] Iteration 25900, lr = 5.36306e-06
I0725 17:38:10.971287 20892 solver.cpp:337] Iteration 26000, Testing net (#0)
I0725 17:38:12.973109 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:38:25.278663 20892 solver.cpp:404]     Test net output #0: accuracy = 0.80429
I0725 17:38:25.278717 20892 solver.cpp:404]     Test net output #1: loss = 0.422312 (* 1 = 0.422312 loss)
I0725 17:38:25.310938 20892 solver.cpp:228] Iteration 26000, loss = 0.484119
I0725 17:38:25.310962 20892 solver.cpp:244]     Train net output #0: loss = 0.484119 (* 1 = 0.484119 loss)
I0725 17:38:25.310991 20892 sgd_solver.cpp:106] Iteration 26000, lr = 5.35432e-06
I0725 17:38:34.685617 20892 solver.cpp:228] Iteration 26100, loss = 0.514707
I0725 17:38:34.685657 20892 solver.cpp:244]     Train net output #0: loss = 0.514707 (* 1 = 0.514707 loss)
I0725 17:38:34.685662 20892 sgd_solver.cpp:106] Iteration 26100, lr = 5.3456e-06
I0725 17:38:44.234261 20892 solver.cpp:228] Iteration 26200, loss = 0.345311
I0725 17:38:44.234300 20892 solver.cpp:244]     Train net output #0: loss = 0.345311 (* 1 = 0.345311 loss)
I0725 17:38:44.234307 20892 sgd_solver.cpp:106] Iteration 26200, lr = 5.33692e-06
I0725 17:38:53.644670 20892 solver.cpp:228] Iteration 26300, loss = 0.331518
I0725 17:38:53.644706 20892 solver.cpp:244]     Train net output #0: loss = 0.331518 (* 1 = 0.331518 loss)
I0725 17:38:53.644711 20892 sgd_solver.cpp:106] Iteration 26300, lr = 5.32828e-06
I0725 17:39:03.050309 20892 solver.cpp:228] Iteration 26400, loss = 0.422529
I0725 17:39:03.050350 20892 solver.cpp:244]     Train net output #0: loss = 0.422529 (* 1 = 0.422529 loss)
I0725 17:39:03.050356 20892 sgd_solver.cpp:106] Iteration 26400, lr = 5.31966e-06
I0725 17:39:12.362964 20892 solver.cpp:337] Iteration 26500, Testing net (#0)
I0725 17:39:26.562429 20892 solver.cpp:404]     Test net output #0: accuracy = 0.811387
I0725 17:39:26.562495 20892 solver.cpp:404]     Test net output #1: loss = 0.412501 (* 1 = 0.412501 loss)
I0725 17:39:26.591524 20892 solver.cpp:228] Iteration 26500, loss = 0.400679
I0725 17:39:26.591562 20892 solver.cpp:244]     Train net output #0: loss = 0.400679 (* 1 = 0.400679 loss)
I0725 17:39:26.591573 20892 sgd_solver.cpp:106] Iteration 26500, lr = 5.31108e-06
I0725 17:39:36.024274 20892 solver.cpp:228] Iteration 26600, loss = 0.403482
I0725 17:39:36.024317 20892 solver.cpp:244]     Train net output #0: loss = 0.403482 (* 1 = 0.403482 loss)
I0725 17:39:36.024324 20892 sgd_solver.cpp:106] Iteration 26600, lr = 5.30253e-06
I0725 17:39:45.553807 20892 solver.cpp:228] Iteration 26700, loss = 0.385724
I0725 17:39:45.553860 20892 solver.cpp:244]     Train net output #0: loss = 0.385724 (* 1 = 0.385724 loss)
I0725 17:39:45.553869 20892 sgd_solver.cpp:106] Iteration 26700, lr = 5.29401e-06
I0725 17:39:54.967980 20892 solver.cpp:228] Iteration 26800, loss = 0.327769
I0725 17:39:54.968046 20892 solver.cpp:244]     Train net output #0: loss = 0.327769 (* 1 = 0.327769 loss)
I0725 17:39:54.968055 20892 sgd_solver.cpp:106] Iteration 26800, lr = 5.28552e-06
I0725 17:40:04.353096 20892 solver.cpp:228] Iteration 26900, loss = 0.441391
I0725 17:40:04.353138 20892 solver.cpp:244]     Train net output #0: loss = 0.441391 (* 1 = 0.441391 loss)
I0725 17:40:04.353144 20892 sgd_solver.cpp:106] Iteration 26900, lr = 5.27707e-06
I0725 17:40:13.621966 20892 solver.cpp:337] Iteration 27000, Testing net (#0)
I0725 17:40:27.927099 20892 solver.cpp:404]     Test net output #0: accuracy = 0.810258
I0725 17:40:27.927142 20892 solver.cpp:404]     Test net output #1: loss = 0.413482 (* 1 = 0.413482 loss)
I0725 17:40:27.953909 20892 solver.cpp:228] Iteration 27000, loss = 0.345781
I0725 17:40:27.953958 20892 solver.cpp:244]     Train net output #0: loss = 0.345781 (* 1 = 0.345781 loss)
I0725 17:40:27.953977 20892 sgd_solver.cpp:106] Iteration 27000, lr = 5.26865e-06
I0725 17:40:37.326611 20892 solver.cpp:228] Iteration 27100, loss = 0.349103
I0725 17:40:37.326658 20892 solver.cpp:244]     Train net output #0: loss = 0.349103 (* 1 = 0.349103 loss)
I0725 17:40:37.326664 20892 sgd_solver.cpp:106] Iteration 27100, lr = 5.26025e-06
I0725 17:40:46.737188 20892 solver.cpp:228] Iteration 27200, loss = 0.280799
I0725 17:40:46.737252 20892 solver.cpp:244]     Train net output #0: loss = 0.280799 (* 1 = 0.280799 loss)
I0725 17:40:46.737260 20892 sgd_solver.cpp:106] Iteration 27200, lr = 5.25189e-06
I0725 17:40:56.149433 20892 solver.cpp:228] Iteration 27300, loss = 0.31287
I0725 17:40:56.149494 20892 solver.cpp:244]     Train net output #0: loss = 0.31287 (* 1 = 0.31287 loss)
I0725 17:40:56.149502 20892 sgd_solver.cpp:106] Iteration 27300, lr = 5.24356e-06
I0725 17:41:05.557301 20892 solver.cpp:228] Iteration 27400, loss = 0.395025
I0725 17:41:05.557363 20892 solver.cpp:244]     Train net output #0: loss = 0.395025 (* 1 = 0.395025 loss)
I0725 17:41:05.557368 20892 sgd_solver.cpp:106] Iteration 27400, lr = 5.23527e-06
I0725 17:41:14.874970 20892 solver.cpp:337] Iteration 27500, Testing net (#0)
I0725 17:41:16.431529 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:41:28.881835 20892 solver.cpp:404]     Test net output #0: accuracy = 0.810806
I0725 17:41:28.881888 20892 solver.cpp:404]     Test net output #1: loss = 0.41263 (* 1 = 0.41263 loss)
I0725 17:41:28.910961 20892 solver.cpp:228] Iteration 27500, loss = 0.454835
I0725 17:41:28.910995 20892 solver.cpp:244]     Train net output #0: loss = 0.454835 (* 1 = 0.454835 loss)
I0725 17:41:28.911005 20892 sgd_solver.cpp:106] Iteration 27500, lr = 5.227e-06
I0725 17:41:38.274690 20892 solver.cpp:228] Iteration 27600, loss = 0.338359
I0725 17:41:38.274746 20892 solver.cpp:244]     Train net output #0: loss = 0.338359 (* 1 = 0.338359 loss)
I0725 17:41:38.274754 20892 sgd_solver.cpp:106] Iteration 27600, lr = 5.21876e-06
I0725 17:41:47.682243 20892 solver.cpp:228] Iteration 27700, loss = 0.428776
I0725 17:41:47.682310 20892 solver.cpp:244]     Train net output #0: loss = 0.428776 (* 1 = 0.428776 loss)
I0725 17:41:47.682332 20892 sgd_solver.cpp:106] Iteration 27700, lr = 5.21055e-06
I0725 17:41:57.088904 20892 solver.cpp:228] Iteration 27800, loss = 0.479448
I0725 17:41:57.088954 20892 solver.cpp:244]     Train net output #0: loss = 0.479448 (* 1 = 0.479448 loss)
I0725 17:41:57.088968 20892 sgd_solver.cpp:106] Iteration 27800, lr = 5.20237e-06
I0725 17:42:06.490471 20892 solver.cpp:228] Iteration 27900, loss = 0.469095
I0725 17:42:06.490516 20892 solver.cpp:244]     Train net output #0: loss = 0.469095 (* 1 = 0.469095 loss)
I0725 17:42:06.490522 20892 sgd_solver.cpp:106] Iteration 27900, lr = 5.19423e-06
I0725 17:42:15.801558 20892 solver.cpp:337] Iteration 28000, Testing net (#0)
I0725 17:42:29.899269 20892 solver.cpp:404]     Test net output #0: accuracy = 0.810129
I0725 17:42:29.899334 20892 solver.cpp:404]     Test net output #1: loss = 0.413701 (* 1 = 0.413701 loss)
I0725 17:42:29.930629 20892 solver.cpp:228] Iteration 28000, loss = 0.39873
I0725 17:42:29.930691 20892 solver.cpp:244]     Train net output #0: loss = 0.39873 (* 1 = 0.39873 loss)
I0725 17:42:29.930708 20892 sgd_solver.cpp:106] Iteration 28000, lr = 5.18611e-06
I0725 17:42:39.212874 20892 solver.cpp:228] Iteration 28100, loss = 0.419667
I0725 17:42:39.212913 20892 solver.cpp:244]     Train net output #0: loss = 0.419667 (* 1 = 0.419667 loss)
I0725 17:42:39.212918 20892 sgd_solver.cpp:106] Iteration 28100, lr = 5.17802e-06
I0725 17:42:48.742552 20892 solver.cpp:228] Iteration 28200, loss = 0.405815
I0725 17:42:48.742593 20892 solver.cpp:244]     Train net output #0: loss = 0.405815 (* 1 = 0.405815 loss)
I0725 17:42:48.742599 20892 sgd_solver.cpp:106] Iteration 28200, lr = 5.16996e-06
I0725 17:42:58.223109 20892 solver.cpp:228] Iteration 28300, loss = 0.397728
I0725 17:42:58.223163 20892 solver.cpp:244]     Train net output #0: loss = 0.397728 (* 1 = 0.397728 loss)
I0725 17:42:58.223172 20892 sgd_solver.cpp:106] Iteration 28300, lr = 5.16193e-06
I0725 17:43:07.594838 20892 solver.cpp:228] Iteration 28400, loss = 0.336882
I0725 17:43:07.594889 20892 solver.cpp:244]     Train net output #0: loss = 0.336882 (* 1 = 0.336882 loss)
I0725 17:43:07.594898 20892 sgd_solver.cpp:106] Iteration 28400, lr = 5.15393e-06
I0725 17:43:16.874744 20892 solver.cpp:337] Iteration 28500, Testing net (#0)
I0725 17:43:31.042495 20892 solver.cpp:404]     Test net output #0: accuracy = 0.813161
I0725 17:43:31.042541 20892 solver.cpp:404]     Test net output #1: loss = 0.409616 (* 1 = 0.409616 loss)
I0725 17:43:31.069654 20892 solver.cpp:228] Iteration 28500, loss = 0.393376
I0725 17:43:31.069691 20892 solver.cpp:244]     Train net output #0: loss = 0.393376 (* 1 = 0.393376 loss)
I0725 17:43:31.069701 20892 sgd_solver.cpp:106] Iteration 28500, lr = 5.14596e-06
I0725 17:43:40.438351 20892 solver.cpp:228] Iteration 28600, loss = 0.485062
I0725 17:43:40.438398 20892 solver.cpp:244]     Train net output #0: loss = 0.485062 (* 1 = 0.485062 loss)
I0725 17:43:40.438405 20892 sgd_solver.cpp:106] Iteration 28600, lr = 5.13801e-06
I0725 17:43:49.840785 20892 solver.cpp:228] Iteration 28700, loss = 0.396571
I0725 17:43:49.840837 20892 solver.cpp:244]     Train net output #0: loss = 0.396571 (* 1 = 0.396571 loss)
I0725 17:43:49.840843 20892 sgd_solver.cpp:106] Iteration 28700, lr = 5.1301e-06
I0725 17:43:59.242885 20892 solver.cpp:228] Iteration 28800, loss = 0.29483
I0725 17:43:59.242933 20892 solver.cpp:244]     Train net output #0: loss = 0.29483 (* 1 = 0.29483 loss)
I0725 17:43:59.242939 20892 sgd_solver.cpp:106] Iteration 28800, lr = 5.12221e-06
I0725 17:44:08.646193 20892 solver.cpp:228] Iteration 28900, loss = 0.444469
I0725 17:44:08.646236 20892 solver.cpp:244]     Train net output #0: loss = 0.444469 (* 1 = 0.444469 loss)
I0725 17:44:08.646242 20892 sgd_solver.cpp:106] Iteration 28900, lr = 5.11435e-06
I0725 17:44:12.031163 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:44:17.956192 20892 solver.cpp:337] Iteration 29000, Testing net (#0)
I0725 17:44:32.090103 20892 solver.cpp:404]     Test net output #0: accuracy = 0.812162
I0725 17:44:32.090158 20892 solver.cpp:404]     Test net output #1: loss = 0.411021 (* 1 = 0.411021 loss)
I0725 17:44:32.119695 20892 solver.cpp:228] Iteration 29000, loss = 0.347405
I0725 17:44:32.119761 20892 solver.cpp:244]     Train net output #0: loss = 0.347405 (* 1 = 0.347405 loss)
I0725 17:44:32.119772 20892 sgd_solver.cpp:106] Iteration 29000, lr = 5.10652e-06
I0725 17:44:41.473489 20892 solver.cpp:228] Iteration 29100, loss = 0.414303
I0725 17:44:41.473546 20892 solver.cpp:244]     Train net output #0: loss = 0.414303 (* 1 = 0.414303 loss)
I0725 17:44:41.473553 20892 sgd_solver.cpp:106] Iteration 29100, lr = 5.09872e-06
I0725 17:44:50.884747 20892 solver.cpp:228] Iteration 29200, loss = 0.419712
I0725 17:44:50.884785 20892 solver.cpp:244]     Train net output #0: loss = 0.419712 (* 1 = 0.419712 loss)
I0725 17:44:50.884793 20892 sgd_solver.cpp:106] Iteration 29200, lr = 5.09095e-06
I0725 17:45:00.295300 20892 solver.cpp:228] Iteration 29300, loss = 0.301597
I0725 17:45:00.295354 20892 solver.cpp:244]     Train net output #0: loss = 0.301597 (* 1 = 0.301597 loss)
I0725 17:45:00.295361 20892 sgd_solver.cpp:106] Iteration 29300, lr = 5.0832e-06
I0725 17:45:09.702942 20892 solver.cpp:228] Iteration 29400, loss = 0.349377
I0725 17:45:09.703003 20892 solver.cpp:244]     Train net output #0: loss = 0.349377 (* 1 = 0.349377 loss)
I0725 17:45:09.703011 20892 sgd_solver.cpp:106] Iteration 29400, lr = 5.07548e-06
I0725 17:45:19.012826 20892 solver.cpp:337] Iteration 29500, Testing net (#0)
I0725 17:45:33.142035 20892 solver.cpp:404]     Test net output #0: accuracy = 0.807581
I0725 17:45:33.142096 20892 solver.cpp:404]     Test net output #1: loss = 0.417087 (* 1 = 0.417087 loss)
I0725 17:45:33.173766 20892 solver.cpp:228] Iteration 29500, loss = 0.379939
I0725 17:45:33.173842 20892 solver.cpp:244]     Train net output #0: loss = 0.379939 (* 1 = 0.379939 loss)
I0725 17:45:33.173856 20892 sgd_solver.cpp:106] Iteration 29500, lr = 5.06779e-06
I0725 17:45:42.520714 20892 solver.cpp:228] Iteration 29600, loss = 0.436895
I0725 17:45:42.520756 20892 solver.cpp:244]     Train net output #0: loss = 0.436895 (* 1 = 0.436895 loss)
I0725 17:45:42.520763 20892 sgd_solver.cpp:106] Iteration 29600, lr = 5.06012e-06
I0725 17:45:51.938362 20892 solver.cpp:228] Iteration 29700, loss = 0.566302
I0725 17:45:51.938402 20892 solver.cpp:244]     Train net output #0: loss = 0.566302 (* 1 = 0.566302 loss)
I0725 17:45:51.938408 20892 sgd_solver.cpp:106] Iteration 29700, lr = 5.05249e-06
I0725 17:46:01.355002 20892 solver.cpp:228] Iteration 29800, loss = 0.379159
I0725 17:46:01.355062 20892 solver.cpp:244]     Train net output #0: loss = 0.379159 (* 1 = 0.379159 loss)
I0725 17:46:01.355070 20892 sgd_solver.cpp:106] Iteration 29800, lr = 5.04488e-06
I0725 17:46:10.767957 20892 solver.cpp:228] Iteration 29900, loss = 0.458132
I0725 17:46:10.768010 20892 solver.cpp:244]     Train net output #0: loss = 0.458132 (* 1 = 0.458132 loss)
I0725 17:46:10.768018 20892 sgd_solver.cpp:106] Iteration 29900, lr = 5.03729e-06
I0725 17:46:20.089516 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_30000.caffemodel
I0725 17:46:20.464545 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_30000.solverstate
I0725 17:46:20.571154 20892 solver.cpp:337] Iteration 30000, Testing net (#0)
I0725 17:46:34.627909 20892 solver.cpp:404]     Test net output #0: accuracy = 0.814258
I0725 17:46:34.627957 20892 solver.cpp:404]     Test net output #1: loss = 0.407922 (* 1 = 0.407922 loss)
I0725 17:46:34.654343 20892 solver.cpp:228] Iteration 30000, loss = 0.392252
I0725 17:46:34.654392 20892 solver.cpp:244]     Train net output #0: loss = 0.392252 (* 1 = 0.392252 loss)
I0725 17:46:34.654402 20892 sgd_solver.cpp:106] Iteration 30000, lr = 5.02973e-06
I0725 17:46:44.121042 20892 solver.cpp:228] Iteration 30100, loss = 0.358263
I0725 17:46:44.121101 20892 solver.cpp:244]     Train net output #0: loss = 0.358263 (* 1 = 0.358263 loss)
I0725 17:46:44.121109 20892 sgd_solver.cpp:106] Iteration 30100, lr = 5.0222e-06
I0725 17:46:53.546074 20892 solver.cpp:228] Iteration 30200, loss = 0.341552
I0725 17:46:53.546135 20892 solver.cpp:244]     Train net output #0: loss = 0.341552 (* 1 = 0.341552 loss)
I0725 17:46:53.546142 20892 sgd_solver.cpp:106] Iteration 30200, lr = 5.0147e-06
I0725 17:47:01.846074 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:47:02.871152 20892 solver.cpp:228] Iteration 30300, loss = 0.446256
I0725 17:47:02.871214 20892 solver.cpp:244]     Train net output #0: loss = 0.446256 (* 1 = 0.446256 loss)
I0725 17:47:02.871220 20892 sgd_solver.cpp:106] Iteration 30300, lr = 5.00722e-06
I0725 17:47:12.275431 20892 solver.cpp:228] Iteration 30400, loss = 0.454513
I0725 17:47:12.275478 20892 solver.cpp:244]     Train net output #0: loss = 0.454513 (* 1 = 0.454513 loss)
I0725 17:47:12.275485 20892 sgd_solver.cpp:106] Iteration 30400, lr = 4.99976e-06
I0725 17:47:21.586246 20892 solver.cpp:337] Iteration 30500, Testing net (#0)
I0725 17:47:35.672356 20892 solver.cpp:404]     Test net output #0: accuracy = 0.814226
I0725 17:47:35.672433 20892 solver.cpp:404]     Test net output #1: loss = 0.406983 (* 1 = 0.406983 loss)
I0725 17:47:35.701964 20892 solver.cpp:228] Iteration 30500, loss = 0.453088
I0725 17:47:35.702003 20892 solver.cpp:244]     Train net output #0: loss = 0.453088 (* 1 = 0.453088 loss)
I0725 17:47:35.702021 20892 sgd_solver.cpp:106] Iteration 30500, lr = 4.99234e-06
I0725 17:47:45.036633 20892 solver.cpp:228] Iteration 30600, loss = 0.355456
I0725 17:47:45.036689 20892 solver.cpp:244]     Train net output #0: loss = 0.355456 (* 1 = 0.355456 loss)
I0725 17:47:45.036695 20892 sgd_solver.cpp:106] Iteration 30600, lr = 4.98494e-06
I0725 17:47:54.444044 20892 solver.cpp:228] Iteration 30700, loss = 0.342569
I0725 17:47:54.444103 20892 solver.cpp:244]     Train net output #0: loss = 0.342569 (* 1 = 0.342569 loss)
I0725 17:47:54.444110 20892 sgd_solver.cpp:106] Iteration 30700, lr = 4.97756e-06
I0725 17:48:03.845592 20892 solver.cpp:228] Iteration 30800, loss = 0.402394
I0725 17:48:03.845636 20892 solver.cpp:244]     Train net output #0: loss = 0.402394 (* 1 = 0.402394 loss)
I0725 17:48:03.845643 20892 sgd_solver.cpp:106] Iteration 30800, lr = 4.97021e-06
I0725 17:48:13.257477 20892 solver.cpp:228] Iteration 30900, loss = 0.336238
I0725 17:48:13.257537 20892 solver.cpp:244]     Train net output #0: loss = 0.336238 (* 1 = 0.336238 loss)
I0725 17:48:13.257545 20892 sgd_solver.cpp:106] Iteration 30900, lr = 4.96288e-06
I0725 17:48:22.573349 20892 solver.cpp:337] Iteration 31000, Testing net (#0)
I0725 17:48:36.715709 20892 solver.cpp:404]     Test net output #0: accuracy = 0.814516
I0725 17:48:36.715754 20892 solver.cpp:404]     Test net output #1: loss = 0.407023 (* 1 = 0.407023 loss)
I0725 17:48:36.745115 20892 solver.cpp:228] Iteration 31000, loss = 0.316476
I0725 17:48:36.745157 20892 solver.cpp:244]     Train net output #0: loss = 0.316476 (* 1 = 0.316476 loss)
I0725 17:48:36.745167 20892 sgd_solver.cpp:106] Iteration 31000, lr = 4.95558e-06
I0725 17:48:46.040535 20892 solver.cpp:228] Iteration 31100, loss = 0.444346
I0725 17:48:46.040594 20892 solver.cpp:244]     Train net output #0: loss = 0.444346 (* 1 = 0.444346 loss)
I0725 17:48:46.040601 20892 sgd_solver.cpp:106] Iteration 31100, lr = 4.94831e-06
I0725 17:48:55.452018 20892 solver.cpp:228] Iteration 31200, loss = 0.356088
I0725 17:48:55.452071 20892 solver.cpp:244]     Train net output #0: loss = 0.356088 (* 1 = 0.356088 loss)
I0725 17:48:55.452078 20892 sgd_solver.cpp:106] Iteration 31200, lr = 4.94106e-06
I0725 17:49:04.863539 20892 solver.cpp:228] Iteration 31300, loss = 0.417453
I0725 17:49:04.863582 20892 solver.cpp:244]     Train net output #0: loss = 0.417453 (* 1 = 0.417453 loss)
I0725 17:49:04.863589 20892 sgd_solver.cpp:106] Iteration 31300, lr = 4.93383e-06
I0725 17:49:14.270797 20892 solver.cpp:228] Iteration 31400, loss = 0.402259
I0725 17:49:14.270845 20892 solver.cpp:244]     Train net output #0: loss = 0.402259 (* 1 = 0.402259 loss)
I0725 17:49:14.270853 20892 sgd_solver.cpp:106] Iteration 31400, lr = 4.92663e-06
I0725 17:49:23.585749 20892 solver.cpp:337] Iteration 31500, Testing net (#0)
I0725 17:49:37.657547 20892 solver.cpp:404]     Test net output #0: accuracy = 0.805807
I0725 17:49:37.657603 20892 solver.cpp:404]     Test net output #1: loss = 0.417308 (* 1 = 0.417308 loss)
I0725 17:49:37.684272 20892 solver.cpp:228] Iteration 31500, loss = 0.319829
I0725 17:49:37.684309 20892 solver.cpp:244]     Train net output #0: loss = 0.319829 (* 1 = 0.319829 loss)
I0725 17:49:37.684321 20892 sgd_solver.cpp:106] Iteration 31500, lr = 4.91946e-06
I0725 17:49:47.020071 20892 solver.cpp:228] Iteration 31600, loss = 0.357006
I0725 17:49:47.020112 20892 solver.cpp:244]     Train net output #0: loss = 0.357006 (* 1 = 0.357006 loss)
I0725 17:49:47.020118 20892 sgd_solver.cpp:106] Iteration 31600, lr = 4.9123e-06
I0725 17:49:56.431146 20892 solver.cpp:228] Iteration 31700, loss = 0.377522
I0725 17:49:56.431190 20892 solver.cpp:244]     Train net output #0: loss = 0.377522 (* 1 = 0.377522 loss)
I0725 17:49:56.431195 20892 sgd_solver.cpp:106] Iteration 31700, lr = 4.90518e-06
I0725 17:50:05.841418 20892 solver.cpp:228] Iteration 31800, loss = 0.370742
I0725 17:50:05.841465 20892 solver.cpp:244]     Train net output #0: loss = 0.370742 (* 1 = 0.370742 loss)
I0725 17:50:05.841472 20892 sgd_solver.cpp:106] Iteration 31800, lr = 4.89807e-06
I0725 17:50:15.248600 20892 solver.cpp:228] Iteration 31900, loss = 0.304739
I0725 17:50:15.248649 20892 solver.cpp:244]     Train net output #0: loss = 0.304739 (* 1 = 0.304739 loss)
I0725 17:50:15.248657 20892 sgd_solver.cpp:106] Iteration 31900, lr = 4.89099e-06
I0725 17:50:22.875702 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:50:24.568089 20892 solver.cpp:337] Iteration 32000, Testing net (#0)
I0725 17:50:38.808668 20892 solver.cpp:404]     Test net output #0: accuracy = 0.816226
I0725 17:50:38.808714 20892 solver.cpp:404]     Test net output #1: loss = 0.405475 (* 1 = 0.405475 loss)
I0725 17:50:38.837774 20892 solver.cpp:228] Iteration 32000, loss = 0.341772
I0725 17:50:38.837834 20892 solver.cpp:244]     Train net output #0: loss = 0.341772 (* 1 = 0.341772 loss)
I0725 17:50:38.837846 20892 sgd_solver.cpp:106] Iteration 32000, lr = 4.88394e-06
I0725 17:50:48.197953 20892 solver.cpp:228] Iteration 32100, loss = 0.380399
I0725 17:50:48.198014 20892 solver.cpp:244]     Train net output #0: loss = 0.380399 (* 1 = 0.380399 loss)
I0725 17:50:48.198021 20892 sgd_solver.cpp:106] Iteration 32100, lr = 4.8769e-06
I0725 17:50:57.604564 20892 solver.cpp:228] Iteration 32200, loss = 0.323188
I0725 17:50:57.604619 20892 solver.cpp:244]     Train net output #0: loss = 0.323188 (* 1 = 0.323188 loss)
I0725 17:50:57.604625 20892 sgd_solver.cpp:106] Iteration 32200, lr = 4.86989e-06
I0725 17:51:07.013121 20892 solver.cpp:228] Iteration 32300, loss = 0.407423
I0725 17:51:07.013176 20892 solver.cpp:244]     Train net output #0: loss = 0.407423 (* 1 = 0.407423 loss)
I0725 17:51:07.013183 20892 sgd_solver.cpp:106] Iteration 32300, lr = 4.86291e-06
I0725 17:51:16.423940 20892 solver.cpp:228] Iteration 32400, loss = 0.378388
I0725 17:51:16.423996 20892 solver.cpp:244]     Train net output #0: loss = 0.378388 (* 1 = 0.378388 loss)
I0725 17:51:16.424005 20892 sgd_solver.cpp:106] Iteration 32400, lr = 4.85595e-06
I0725 17:51:25.737606 20892 solver.cpp:337] Iteration 32500, Testing net (#0)
I0725 17:51:39.887964 20892 solver.cpp:404]     Test net output #0: accuracy = 0.816387
I0725 17:51:39.888005 20892 solver.cpp:404]     Test net output #1: loss = 0.404603 (* 1 = 0.404603 loss)
I0725 17:51:39.917080 20892 solver.cpp:228] Iteration 32500, loss = 0.362143
I0725 17:51:39.917103 20892 solver.cpp:244]     Train net output #0: loss = 0.362143 (* 1 = 0.362143 loss)
I0725 17:51:39.917111 20892 sgd_solver.cpp:106] Iteration 32500, lr = 4.84901e-06
I0725 17:51:49.194090 20892 solver.cpp:228] Iteration 32600, loss = 0.393474
I0725 17:51:49.194133 20892 solver.cpp:244]     Train net output #0: loss = 0.393474 (* 1 = 0.393474 loss)
I0725 17:51:49.194139 20892 sgd_solver.cpp:106] Iteration 32600, lr = 4.84209e-06
I0725 17:51:58.598635 20892 solver.cpp:228] Iteration 32700, loss = 0.457157
I0725 17:51:58.598692 20892 solver.cpp:244]     Train net output #0: loss = 0.457157 (* 1 = 0.457157 loss)
I0725 17:51:58.598700 20892 sgd_solver.cpp:106] Iteration 32700, lr = 4.8352e-06
I0725 17:52:08.006649 20892 solver.cpp:228] Iteration 32800, loss = 0.259432
I0725 17:52:08.006690 20892 solver.cpp:244]     Train net output #0: loss = 0.259432 (* 1 = 0.259432 loss)
I0725 17:52:08.006697 20892 sgd_solver.cpp:106] Iteration 32800, lr = 4.82833e-06
I0725 17:52:17.412225 20892 solver.cpp:228] Iteration 32900, loss = 0.5156
I0725 17:52:17.412284 20892 solver.cpp:244]     Train net output #0: loss = 0.5156 (* 1 = 0.5156 loss)
I0725 17:52:17.412292 20892 sgd_solver.cpp:106] Iteration 32900, lr = 4.82148e-06
I0725 17:52:26.721463 20892 solver.cpp:337] Iteration 33000, Testing net (#0)
I0725 17:52:40.818832 20892 solver.cpp:404]     Test net output #0: accuracy = 0.817
I0725 17:52:40.818893 20892 solver.cpp:404]     Test net output #1: loss = 0.403265 (* 1 = 0.403265 loss)
I0725 17:52:40.848057 20892 solver.cpp:228] Iteration 33000, loss = 0.27011
I0725 17:52:40.848119 20892 solver.cpp:244]     Train net output #0: loss = 0.27011 (* 1 = 0.27011 loss)
I0725 17:52:40.848131 20892 sgd_solver.cpp:106] Iteration 33000, lr = 4.81466e-06
I0725 17:52:50.173044 20892 solver.cpp:228] Iteration 33100, loss = 0.435958
I0725 17:52:50.173080 20892 solver.cpp:244]     Train net output #0: loss = 0.435958 (* 1 = 0.435958 loss)
I0725 17:52:50.173086 20892 sgd_solver.cpp:106] Iteration 33100, lr = 4.80786e-06
I0725 17:52:58.074728 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:52:59.578778 20892 solver.cpp:228] Iteration 33200, loss = 0.364806
I0725 17:52:59.578826 20892 solver.cpp:244]     Train net output #0: loss = 0.364806 (* 1 = 0.364806 loss)
I0725 17:52:59.578835 20892 sgd_solver.cpp:106] Iteration 33200, lr = 4.80108e-06
I0725 17:53:08.982942 20892 solver.cpp:228] Iteration 33300, loss = 0.375254
I0725 17:53:08.982981 20892 solver.cpp:244]     Train net output #0: loss = 0.375254 (* 1 = 0.375254 loss)
I0725 17:53:08.982988 20892 sgd_solver.cpp:106] Iteration 33300, lr = 4.79432e-06
I0725 17:53:18.384829 20892 solver.cpp:228] Iteration 33400, loss = 0.465988
I0725 17:53:18.384876 20892 solver.cpp:244]     Train net output #0: loss = 0.465988 (* 1 = 0.465988 loss)
I0725 17:53:18.384884 20892 sgd_solver.cpp:106] Iteration 33400, lr = 4.78759e-06
I0725 17:53:27.697681 20892 solver.cpp:337] Iteration 33500, Testing net (#0)
I0725 17:53:41.914079 20892 solver.cpp:404]     Test net output #0: accuracy = 0.813258
I0725 17:53:41.914134 20892 solver.cpp:404]     Test net output #1: loss = 0.408793 (* 1 = 0.408793 loss)
I0725 17:53:41.943255 20892 solver.cpp:228] Iteration 33500, loss = 0.377616
I0725 17:53:41.943311 20892 solver.cpp:244]     Train net output #0: loss = 0.377616 (* 1 = 0.377616 loss)
I0725 17:53:41.943325 20892 sgd_solver.cpp:106] Iteration 33500, lr = 4.78087e-06
I0725 17:53:51.312712 20892 solver.cpp:228] Iteration 33600, loss = 0.299551
I0725 17:53:51.312752 20892 solver.cpp:244]     Train net output #0: loss = 0.299551 (* 1 = 0.299551 loss)
I0725 17:53:51.312758 20892 sgd_solver.cpp:106] Iteration 33600, lr = 4.77418e-06
I0725 17:54:00.716915 20892 solver.cpp:228] Iteration 33700, loss = 0.410341
I0725 17:54:00.716975 20892 solver.cpp:244]     Train net output #0: loss = 0.410341 (* 1 = 0.410341 loss)
I0725 17:54:00.716982 20892 sgd_solver.cpp:106] Iteration 33700, lr = 4.76751e-06
I0725 17:54:10.119896 20892 solver.cpp:228] Iteration 33800, loss = 0.351313
I0725 17:54:10.119948 20892 solver.cpp:244]     Train net output #0: loss = 0.351313 (* 1 = 0.351313 loss)
I0725 17:54:10.119957 20892 sgd_solver.cpp:106] Iteration 33800, lr = 4.76086e-06
I0725 17:54:19.518869 20892 solver.cpp:228] Iteration 33900, loss = 0.403224
I0725 17:54:19.518925 20892 solver.cpp:244]     Train net output #0: loss = 0.403224 (* 1 = 0.403224 loss)
I0725 17:54:19.518934 20892 sgd_solver.cpp:106] Iteration 33900, lr = 4.75424e-06
I0725 17:54:28.822907 20892 solver.cpp:337] Iteration 34000, Testing net (#0)
I0725 17:54:42.774416 20892 solver.cpp:404]     Test net output #0: accuracy = 0.819162
I0725 17:54:42.774461 20892 solver.cpp:404]     Test net output #1: loss = 0.40012 (* 1 = 0.40012 loss)
I0725 17:54:42.803445 20892 solver.cpp:228] Iteration 34000, loss = 0.414428
I0725 17:54:42.803467 20892 solver.cpp:244]     Train net output #0: loss = 0.414428 (* 1 = 0.414428 loss)
I0725 17:54:42.803478 20892 sgd_solver.cpp:106] Iteration 34000, lr = 4.74763e-06
I0725 17:54:52.245860 20892 solver.cpp:228] Iteration 34100, loss = 0.311312
I0725 17:54:52.245918 20892 solver.cpp:244]     Train net output #0: loss = 0.311312 (* 1 = 0.311312 loss)
I0725 17:54:52.245925 20892 sgd_solver.cpp:106] Iteration 34100, lr = 4.74105e-06
I0725 17:55:01.716262 20892 solver.cpp:228] Iteration 34200, loss = 0.303099
I0725 17:55:01.716315 20892 solver.cpp:244]     Train net output #0: loss = 0.303099 (* 1 = 0.303099 loss)
I0725 17:55:01.716321 20892 sgd_solver.cpp:106] Iteration 34200, lr = 4.73449e-06
I0725 17:55:11.129098 20892 solver.cpp:228] Iteration 34300, loss = 0.438317
I0725 17:55:11.129142 20892 solver.cpp:244]     Train net output #0: loss = 0.438317 (* 1 = 0.438317 loss)
I0725 17:55:11.129148 20892 sgd_solver.cpp:106] Iteration 34300, lr = 4.72795e-06
I0725 17:55:20.540349 20892 solver.cpp:228] Iteration 34400, loss = 0.325496
I0725 17:55:20.540385 20892 solver.cpp:244]     Train net output #0: loss = 0.325496 (* 1 = 0.325496 loss)
I0725 17:55:20.540391 20892 sgd_solver.cpp:106] Iteration 34400, lr = 4.72143e-06
I0725 17:55:29.862166 20892 solver.cpp:337] Iteration 34500, Testing net (#0)
I0725 17:55:43.907210 20892 solver.cpp:404]     Test net output #0: accuracy = 0.817806
I0725 17:55:43.907249 20892 solver.cpp:404]     Test net output #1: loss = 0.401389 (* 1 = 0.401389 loss)
I0725 17:55:43.936303 20892 solver.cpp:228] Iteration 34500, loss = 0.398473
I0725 17:55:43.936357 20892 solver.cpp:244]     Train net output #0: loss = 0.398473 (* 1 = 0.398473 loss)
I0725 17:55:43.936367 20892 sgd_solver.cpp:106] Iteration 34500, lr = 4.71493e-06
I0725 17:55:53.295037 20892 solver.cpp:228] Iteration 34600, loss = 0.473576
I0725 17:55:53.295092 20892 solver.cpp:244]     Train net output #0: loss = 0.473576 (* 1 = 0.473576 loss)
I0725 17:55:53.295099 20892 sgd_solver.cpp:106] Iteration 34600, lr = 4.70845e-06
I0725 17:56:02.703783 20892 solver.cpp:228] Iteration 34700, loss = 0.376147
I0725 17:56:02.703847 20892 solver.cpp:244]     Train net output #0: loss = 0.376147 (* 1 = 0.376147 loss)
I0725 17:56:02.703856 20892 sgd_solver.cpp:106] Iteration 34700, lr = 4.70199e-06
I0725 17:56:04.680224 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:56:12.110409 20892 solver.cpp:228] Iteration 34800, loss = 0.388408
I0725 17:56:12.110447 20892 solver.cpp:244]     Train net output #0: loss = 0.388408 (* 1 = 0.388408 loss)
I0725 17:56:12.110453 20892 sgd_solver.cpp:106] Iteration 34800, lr = 4.69556e-06
I0725 17:56:21.517956 20892 solver.cpp:228] Iteration 34900, loss = 0.391691
I0725 17:56:21.517993 20892 solver.cpp:244]     Train net output #0: loss = 0.391691 (* 1 = 0.391691 loss)
I0725 17:56:21.517999 20892 sgd_solver.cpp:106] Iteration 34900, lr = 4.68914e-06
I0725 17:56:30.834439 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_35000.caffemodel
I0725 17:56:31.281605 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_35000.solverstate
I0725 17:56:31.443847 20892 solver.cpp:337] Iteration 35000, Testing net (#0)
I0725 17:56:45.349406 20892 solver.cpp:404]     Test net output #0: accuracy = 0.818097
I0725 17:56:45.349454 20892 solver.cpp:404]     Test net output #1: loss = 0.401518 (* 1 = 0.401518 loss)
I0725 17:56:45.378767 20892 solver.cpp:228] Iteration 35000, loss = 0.318437
I0725 17:56:45.378826 20892 solver.cpp:244]     Train net output #0: loss = 0.318437 (* 1 = 0.318437 loss)
I0725 17:56:45.378837 20892 sgd_solver.cpp:106] Iteration 35000, lr = 4.68274e-06
I0725 17:56:54.736291 20892 solver.cpp:228] Iteration 35100, loss = 0.472598
I0725 17:56:54.736348 20892 solver.cpp:244]     Train net output #0: loss = 0.472598 (* 1 = 0.472598 loss)
I0725 17:56:54.736356 20892 sgd_solver.cpp:106] Iteration 35100, lr = 4.67637e-06
I0725 17:57:04.149464 20892 solver.cpp:228] Iteration 35200, loss = 0.354012
I0725 17:57:04.149502 20892 solver.cpp:244]     Train net output #0: loss = 0.354012 (* 1 = 0.354012 loss)
I0725 17:57:04.149507 20892 sgd_solver.cpp:106] Iteration 35200, lr = 4.67001e-06
I0725 17:57:13.556253 20892 solver.cpp:228] Iteration 35300, loss = 0.329803
I0725 17:57:13.556313 20892 solver.cpp:244]     Train net output #0: loss = 0.329803 (* 1 = 0.329803 loss)
I0725 17:57:13.556319 20892 sgd_solver.cpp:106] Iteration 35300, lr = 4.66368e-06
I0725 17:57:22.961318 20892 solver.cpp:228] Iteration 35400, loss = 0.320302
I0725 17:57:22.961366 20892 solver.cpp:244]     Train net output #0: loss = 0.320302 (* 1 = 0.320302 loss)
I0725 17:57:22.961374 20892 sgd_solver.cpp:106] Iteration 35400, lr = 4.65736e-06
I0725 17:57:32.274937 20892 solver.cpp:337] Iteration 35500, Testing net (#0)
I0725 17:57:46.325426 20892 solver.cpp:404]     Test net output #0: accuracy = 0.817936
I0725 17:57:46.325495 20892 solver.cpp:404]     Test net output #1: loss = 0.401607 (* 1 = 0.401607 loss)
I0725 17:57:46.355505 20892 solver.cpp:228] Iteration 35500, loss = 0.385954
I0725 17:57:46.355557 20892 solver.cpp:244]     Train net output #0: loss = 0.385954 (* 1 = 0.385954 loss)
I0725 17:57:46.355581 20892 sgd_solver.cpp:106] Iteration 35500, lr = 4.65107e-06
I0725 17:57:55.733755 20892 solver.cpp:228] Iteration 35600, loss = 0.335268
I0725 17:57:55.733809 20892 solver.cpp:244]     Train net output #0: loss = 0.335268 (* 1 = 0.335268 loss)
I0725 17:57:55.733817 20892 sgd_solver.cpp:106] Iteration 35600, lr = 4.64479e-06
I0725 17:58:05.295133 20892 solver.cpp:228] Iteration 35700, loss = 0.381838
I0725 17:58:05.295173 20892 solver.cpp:244]     Train net output #0: loss = 0.381838 (* 1 = 0.381838 loss)
I0725 17:58:05.295179 20892 sgd_solver.cpp:106] Iteration 35700, lr = 4.63854e-06
I0725 17:58:14.752226 20892 solver.cpp:228] Iteration 35800, loss = 0.296946
I0725 17:58:14.752276 20892 solver.cpp:244]     Train net output #0: loss = 0.296946 (* 1 = 0.296946 loss)
I0725 17:58:14.752282 20892 sgd_solver.cpp:106] Iteration 35800, lr = 4.6323e-06
I0725 17:58:24.083262 20892 solver.cpp:228] Iteration 35900, loss = 0.360787
I0725 17:58:24.083307 20892 solver.cpp:244]     Train net output #0: loss = 0.360787 (* 1 = 0.360787 loss)
I0725 17:58:24.083313 20892 sgd_solver.cpp:106] Iteration 35900, lr = 4.62609e-06
I0725 17:58:33.361727 20892 solver.cpp:337] Iteration 36000, Testing net (#0)
I0725 17:58:47.490964 20892 solver.cpp:404]     Test net output #0: accuracy = 0.819226
I0725 17:58:47.491019 20892 solver.cpp:404]     Test net output #1: loss = 0.398814 (* 1 = 0.398814 loss)
I0725 17:58:47.517397 20892 solver.cpp:228] Iteration 36000, loss = 0.379388
I0725 17:58:47.517436 20892 solver.cpp:244]     Train net output #0: loss = 0.379388 (* 1 = 0.379388 loss)
I0725 17:58:47.517447 20892 sgd_solver.cpp:106] Iteration 36000, lr = 4.61989e-06
I0725 17:58:53.594157 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 17:58:56.885502 20892 solver.cpp:228] Iteration 36100, loss = 0.352037
I0725 17:58:56.885546 20892 solver.cpp:244]     Train net output #0: loss = 0.352037 (* 1 = 0.352037 loss)
I0725 17:58:56.885553 20892 sgd_solver.cpp:106] Iteration 36100, lr = 4.61371e-06
I0725 17:59:06.293598 20892 solver.cpp:228] Iteration 36200, loss = 0.324786
I0725 17:59:06.293648 20892 solver.cpp:244]     Train net output #0: loss = 0.324786 (* 1 = 0.324786 loss)
I0725 17:59:06.293654 20892 sgd_solver.cpp:106] Iteration 36200, lr = 4.60755e-06
I0725 17:59:15.703681 20892 solver.cpp:228] Iteration 36300, loss = 0.350624
I0725 17:59:15.703725 20892 solver.cpp:244]     Train net output #0: loss = 0.350624 (* 1 = 0.350624 loss)
I0725 17:59:15.703732 20892 sgd_solver.cpp:106] Iteration 36300, lr = 4.60141e-06
I0725 17:59:25.111297 20892 solver.cpp:228] Iteration 36400, loss = 0.400795
I0725 17:59:25.111337 20892 solver.cpp:244]     Train net output #0: loss = 0.400795 (* 1 = 0.400795 loss)
I0725 17:59:25.111343 20892 sgd_solver.cpp:106] Iteration 36400, lr = 4.59529e-06
I0725 17:59:34.427891 20892 solver.cpp:337] Iteration 36500, Testing net (#0)
I0725 17:59:48.644764 20892 solver.cpp:404]     Test net output #0: accuracy = 0.818871
I0725 17:59:48.644827 20892 solver.cpp:404]     Test net output #1: loss = 0.399966 (* 1 = 0.399966 loss)
I0725 17:59:48.673573 20892 solver.cpp:228] Iteration 36500, loss = 0.366326
I0725 17:59:48.673634 20892 solver.cpp:244]     Train net output #0: loss = 0.366326 (* 1 = 0.366326 loss)
I0725 17:59:48.673652 20892 sgd_solver.cpp:106] Iteration 36500, lr = 4.58919e-06
I0725 17:59:57.979733 20892 solver.cpp:228] Iteration 36600, loss = 0.379757
I0725 17:59:57.979778 20892 solver.cpp:244]     Train net output #0: loss = 0.379757 (* 1 = 0.379757 loss)
I0725 17:59:57.979784 20892 sgd_solver.cpp:106] Iteration 36600, lr = 4.58311e-06
I0725 18:00:07.375663 20892 solver.cpp:228] Iteration 36700, loss = 0.416052
I0725 18:00:07.375705 20892 solver.cpp:244]     Train net output #0: loss = 0.416052 (* 1 = 0.416052 loss)
I0725 18:00:07.375711 20892 sgd_solver.cpp:106] Iteration 36700, lr = 4.57705e-06
I0725 18:00:16.779860 20892 solver.cpp:228] Iteration 36800, loss = 0.454755
I0725 18:00:16.779904 20892 solver.cpp:244]     Train net output #0: loss = 0.454755 (* 1 = 0.454755 loss)
I0725 18:00:16.779911 20892 sgd_solver.cpp:106] Iteration 36800, lr = 4.571e-06
I0725 18:00:26.180891 20892 solver.cpp:228] Iteration 36900, loss = 0.387121
I0725 18:00:26.180948 20892 solver.cpp:244]     Train net output #0: loss = 0.387121 (* 1 = 0.387121 loss)
I0725 18:00:26.180953 20892 sgd_solver.cpp:106] Iteration 36900, lr = 4.56497e-06
I0725 18:00:35.486968 20892 solver.cpp:337] Iteration 37000, Testing net (#0)
I0725 18:00:49.638190 20892 solver.cpp:404]     Test net output #0: accuracy = 0.813323
I0725 18:00:49.638236 20892 solver.cpp:404]     Test net output #1: loss = 0.406981 (* 1 = 0.406981 loss)
I0725 18:00:49.665241 20892 solver.cpp:228] Iteration 37000, loss = 0.314076
I0725 18:00:49.665287 20892 solver.cpp:244]     Train net output #0: loss = 0.314076 (* 1 = 0.314076 loss)
I0725 18:00:49.665303 20892 sgd_solver.cpp:106] Iteration 37000, lr = 4.55897e-06
I0725 18:00:59.027031 20892 solver.cpp:228] Iteration 37100, loss = 0.367254
I0725 18:00:59.027081 20892 solver.cpp:244]     Train net output #0: loss = 0.367254 (* 1 = 0.367254 loss)
I0725 18:00:59.027088 20892 sgd_solver.cpp:106] Iteration 37100, lr = 4.55298e-06
I0725 18:01:08.438853 20892 solver.cpp:228] Iteration 37200, loss = 0.345403
I0725 18:01:08.438895 20892 solver.cpp:244]     Train net output #0: loss = 0.345403 (* 1 = 0.345403 loss)
I0725 18:01:08.438902 20892 sgd_solver.cpp:106] Iteration 37200, lr = 4.54701e-06
I0725 18:01:17.852854 20892 solver.cpp:228] Iteration 37300, loss = 0.383995
I0725 18:01:17.852896 20892 solver.cpp:244]     Train net output #0: loss = 0.383995 (* 1 = 0.383995 loss)
I0725 18:01:17.852902 20892 sgd_solver.cpp:106] Iteration 37300, lr = 4.54105e-06
I0725 18:01:27.261095 20892 solver.cpp:228] Iteration 37400, loss = 0.310474
I0725 18:01:27.261137 20892 solver.cpp:244]     Train net output #0: loss = 0.310474 (* 1 = 0.310474 loss)
I0725 18:01:27.261143 20892 sgd_solver.cpp:106] Iteration 37400, lr = 4.53512e-06
I0725 18:01:36.580858 20892 solver.cpp:337] Iteration 37500, Testing net (#0)
I0725 18:01:49.007565 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:01:50.705221 20892 solver.cpp:404]     Test net output #0: accuracy = 0.820419
I0725 18:01:50.705266 20892 solver.cpp:404]     Test net output #1: loss = 0.396764 (* 1 = 0.396764 loss)
I0725 18:01:50.735782 20892 solver.cpp:228] Iteration 37500, loss = 0.257211
I0725 18:01:50.735836 20892 solver.cpp:244]     Train net output #0: loss = 0.257211 (* 1 = 0.257211 loss)
I0725 18:01:50.735848 20892 sgd_solver.cpp:106] Iteration 37500, lr = 4.5292e-06
I0725 18:02:00.127890 20892 solver.cpp:228] Iteration 37600, loss = 0.330771
I0725 18:02:00.127928 20892 solver.cpp:244]     Train net output #0: loss = 0.330771 (* 1 = 0.330771 loss)
I0725 18:02:00.127934 20892 sgd_solver.cpp:106] Iteration 37600, lr = 4.5233e-06
I0725 18:02:09.543179 20892 solver.cpp:228] Iteration 37700, loss = 0.431473
I0725 18:02:09.543225 20892 solver.cpp:244]     Train net output #0: loss = 0.431473 (* 1 = 0.431473 loss)
I0725 18:02:09.543231 20892 sgd_solver.cpp:106] Iteration 37700, lr = 4.51742e-06
I0725 18:02:18.956406 20892 solver.cpp:228] Iteration 37800, loss = 0.365781
I0725 18:02:18.956464 20892 solver.cpp:244]     Train net output #0: loss = 0.365781 (* 1 = 0.365781 loss)
I0725 18:02:18.956470 20892 sgd_solver.cpp:106] Iteration 37800, lr = 4.51156e-06
I0725 18:02:28.366657 20892 solver.cpp:228] Iteration 37900, loss = 0.40337
I0725 18:02:28.366703 20892 solver.cpp:244]     Train net output #0: loss = 0.40337 (* 1 = 0.40337 loss)
I0725 18:02:28.366708 20892 sgd_solver.cpp:106] Iteration 37900, lr = 4.50571e-06
I0725 18:02:37.686579 20892 solver.cpp:337] Iteration 38000, Testing net (#0)
I0725 18:02:51.955086 20892 solver.cpp:404]     Test net output #0: accuracy = 0.820549
I0725 18:02:51.955140 20892 solver.cpp:404]     Test net output #1: loss = 0.396957 (* 1 = 0.396957 loss)
I0725 18:02:51.984205 20892 solver.cpp:228] Iteration 38000, loss = 0.334477
I0725 18:02:51.984263 20892 solver.cpp:244]     Train net output #0: loss = 0.334477 (* 1 = 0.334477 loss)
I0725 18:02:51.984278 20892 sgd_solver.cpp:106] Iteration 38000, lr = 4.49989e-06
I0725 18:03:01.364761 20892 solver.cpp:228] Iteration 38100, loss = 0.339491
I0725 18:03:01.364809 20892 solver.cpp:244]     Train net output #0: loss = 0.339491 (* 1 = 0.339491 loss)
I0725 18:03:01.364819 20892 sgd_solver.cpp:106] Iteration 38100, lr = 4.49408e-06
I0725 18:03:10.775452 20892 solver.cpp:228] Iteration 38200, loss = 0.466548
I0725 18:03:10.775501 20892 solver.cpp:244]     Train net output #0: loss = 0.466548 (* 1 = 0.466548 loss)
I0725 18:03:10.775511 20892 sgd_solver.cpp:106] Iteration 38200, lr = 4.48828e-06
I0725 18:03:20.178179 20892 solver.cpp:228] Iteration 38300, loss = 0.550545
I0725 18:03:20.178220 20892 solver.cpp:244]     Train net output #0: loss = 0.550545 (* 1 = 0.550545 loss)
I0725 18:03:20.178230 20892 sgd_solver.cpp:106] Iteration 38300, lr = 4.48251e-06
I0725 18:03:29.584959 20892 solver.cpp:228] Iteration 38400, loss = 0.37554
I0725 18:03:29.585007 20892 solver.cpp:244]     Train net output #0: loss = 0.37554 (* 1 = 0.37554 loss)
I0725 18:03:29.585016 20892 sgd_solver.cpp:106] Iteration 38400, lr = 4.47675e-06
I0725 18:03:38.899164 20892 solver.cpp:337] Iteration 38500, Testing net (#0)
I0725 18:03:53.159505 20892 solver.cpp:404]     Test net output #0: accuracy = 0.820839
I0725 18:03:53.159550 20892 solver.cpp:404]     Test net output #1: loss = 0.39613 (* 1 = 0.39613 loss)
I0725 18:03:53.189306 20892 solver.cpp:228] Iteration 38500, loss = 0.371254
I0725 18:03:53.189366 20892 solver.cpp:244]     Train net output #0: loss = 0.371254 (* 1 = 0.371254 loss)
I0725 18:03:53.189385 20892 sgd_solver.cpp:106] Iteration 38500, lr = 4.47101e-06
I0725 18:04:02.537346 20892 solver.cpp:228] Iteration 38600, loss = 0.412233
I0725 18:04:02.537398 20892 solver.cpp:244]     Train net output #0: loss = 0.412233 (* 1 = 0.412233 loss)
I0725 18:04:02.537406 20892 sgd_solver.cpp:106] Iteration 38600, lr = 4.46529e-06
I0725 18:04:11.952514 20892 solver.cpp:228] Iteration 38700, loss = 0.375726
I0725 18:04:11.952550 20892 solver.cpp:244]     Train net output #0: loss = 0.375726 (* 1 = 0.375726 loss)
I0725 18:04:11.952558 20892 sgd_solver.cpp:106] Iteration 38700, lr = 4.45958e-06
I0725 18:04:21.367022 20892 solver.cpp:228] Iteration 38800, loss = 0.336636
I0725 18:04:21.367060 20892 solver.cpp:244]     Train net output #0: loss = 0.336636 (* 1 = 0.336636 loss)
I0725 18:04:21.367066 20892 sgd_solver.cpp:106] Iteration 38800, lr = 4.45389e-06
I0725 18:04:30.779389 20892 solver.cpp:228] Iteration 38900, loss = 0.420165
I0725 18:04:30.779449 20892 solver.cpp:244]     Train net output #0: loss = 0.420165 (* 1 = 0.420165 loss)
I0725 18:04:30.779458 20892 sgd_solver.cpp:106] Iteration 38900, lr = 4.44822e-06
I0725 18:04:40.098573 20892 solver.cpp:337] Iteration 39000, Testing net (#0)
I0725 18:04:52.001866 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:04:54.280961 20892 solver.cpp:404]     Test net output #0: accuracy = 0.812904
I0725 18:04:54.281016 20892 solver.cpp:404]     Test net output #1: loss = 0.407518 (* 1 = 0.407518 loss)
I0725 18:04:54.307675 20892 solver.cpp:228] Iteration 39000, loss = 0.420459
I0725 18:04:54.307716 20892 solver.cpp:244]     Train net output #0: loss = 0.420459 (* 1 = 0.420459 loss)
I0725 18:04:54.307726 20892 sgd_solver.cpp:106] Iteration 39000, lr = 4.44256e-06
I0725 18:05:03.714005 20892 solver.cpp:228] Iteration 39100, loss = 0.325782
I0725 18:05:03.714063 20892 solver.cpp:244]     Train net output #0: loss = 0.325782 (* 1 = 0.325782 loss)
I0725 18:05:03.714071 20892 sgd_solver.cpp:106] Iteration 39100, lr = 4.43692e-06
I0725 18:05:13.122721 20892 solver.cpp:228] Iteration 39200, loss = 0.385956
I0725 18:05:13.122781 20892 solver.cpp:244]     Train net output #0: loss = 0.385956 (* 1 = 0.385956 loss)
I0725 18:05:13.122787 20892 sgd_solver.cpp:106] Iteration 39200, lr = 4.4313e-06
I0725 18:05:22.527959 20892 solver.cpp:228] Iteration 39300, loss = 0.385334
I0725 18:05:22.528013 20892 solver.cpp:244]     Train net output #0: loss = 0.385334 (* 1 = 0.385334 loss)
I0725 18:05:22.528020 20892 sgd_solver.cpp:106] Iteration 39300, lr = 4.42569e-06
I0725 18:05:31.933980 20892 solver.cpp:228] Iteration 39400, loss = 0.316322
I0725 18:05:31.934016 20892 solver.cpp:244]     Train net output #0: loss = 0.316322 (* 1 = 0.316322 loss)
I0725 18:05:31.934023 20892 sgd_solver.cpp:106] Iteration 39400, lr = 4.42011e-06
I0725 18:05:41.245182 20892 solver.cpp:337] Iteration 39500, Testing net (#0)
I0725 18:05:55.320096 20892 solver.cpp:404]     Test net output #0: accuracy = 0.820936
I0725 18:05:55.320155 20892 solver.cpp:404]     Test net output #1: loss = 0.396521 (* 1 = 0.396521 loss)
I0725 18:05:55.349721 20892 solver.cpp:228] Iteration 39500, loss = 0.249411
I0725 18:05:55.349792 20892 solver.cpp:244]     Train net output #0: loss = 0.249411 (* 1 = 0.249411 loss)
I0725 18:05:55.349804 20892 sgd_solver.cpp:106] Iteration 39500, lr = 4.41453e-06
I0725 18:06:04.734484 20892 solver.cpp:228] Iteration 39600, loss = 0.347119
I0725 18:06:04.734534 20892 solver.cpp:244]     Train net output #0: loss = 0.347119 (* 1 = 0.347119 loss)
I0725 18:06:04.734540 20892 sgd_solver.cpp:106] Iteration 39600, lr = 4.40898e-06
I0725 18:06:14.145092 20892 solver.cpp:228] Iteration 39700, loss = 0.323165
I0725 18:06:14.145150 20892 solver.cpp:244]     Train net output #0: loss = 0.323165 (* 1 = 0.323165 loss)
I0725 18:06:14.145156 20892 sgd_solver.cpp:106] Iteration 39700, lr = 4.40344e-06
I0725 18:06:23.549710 20892 solver.cpp:228] Iteration 39800, loss = 0.371632
I0725 18:06:23.549751 20892 solver.cpp:244]     Train net output #0: loss = 0.371632 (* 1 = 0.371632 loss)
I0725 18:06:23.549757 20892 sgd_solver.cpp:106] Iteration 39800, lr = 4.39791e-06
I0725 18:06:32.951920 20892 solver.cpp:228] Iteration 39900, loss = 0.40752
I0725 18:06:32.951963 20892 solver.cpp:244]     Train net output #0: loss = 0.40752 (* 1 = 0.40752 loss)
I0725 18:06:32.951969 20892 sgd_solver.cpp:106] Iteration 39900, lr = 4.39241e-06
I0725 18:06:42.261023 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_40000.caffemodel
I0725 18:06:42.622259 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_40000.solverstate
I0725 18:06:42.722074 20892 solver.cpp:337] Iteration 40000, Testing net (#0)
I0725 18:06:56.674597 20892 solver.cpp:404]     Test net output #0: accuracy = 0.821774
I0725 18:06:56.674641 20892 solver.cpp:404]     Test net output #1: loss = 0.394693 (* 1 = 0.394693 loss)
I0725 18:06:56.703759 20892 solver.cpp:228] Iteration 40000, loss = 0.396642
I0725 18:06:56.703810 20892 solver.cpp:244]     Train net output #0: loss = 0.396642 (* 1 = 0.396642 loss)
I0725 18:06:56.703820 20892 sgd_solver.cpp:106] Iteration 40000, lr = 4.38691e-06
I0725 18:07:06.057987 20892 solver.cpp:228] Iteration 40100, loss = 0.453143
I0725 18:07:06.058034 20892 solver.cpp:244]     Train net output #0: loss = 0.453143 (* 1 = 0.453143 loss)
I0725 18:07:06.058043 20892 sgd_solver.cpp:106] Iteration 40100, lr = 4.38144e-06
I0725 18:07:15.474622 20892 solver.cpp:228] Iteration 40200, loss = 0.362868
I0725 18:07:15.474670 20892 solver.cpp:244]     Train net output #0: loss = 0.362868 (* 1 = 0.362868 loss)
I0725 18:07:15.474676 20892 sgd_solver.cpp:106] Iteration 40200, lr = 4.37598e-06
I0725 18:07:24.890177 20892 solver.cpp:228] Iteration 40300, loss = 0.359757
I0725 18:07:24.890229 20892 solver.cpp:244]     Train net output #0: loss = 0.359757 (* 1 = 0.359757 loss)
I0725 18:07:24.890238 20892 sgd_solver.cpp:106] Iteration 40300, lr = 4.37053e-06
I0725 18:07:34.307725 20892 solver.cpp:228] Iteration 40400, loss = 0.416554
I0725 18:07:34.307775 20892 solver.cpp:244]     Train net output #0: loss = 0.416554 (* 1 = 0.416554 loss)
I0725 18:07:34.307783 20892 sgd_solver.cpp:106] Iteration 40400, lr = 4.36511e-06
I0725 18:07:43.628494 20892 solver.cpp:337] Iteration 40500, Testing net (#0)
I0725 18:07:54.453626 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:07:57.817117 20892 solver.cpp:404]     Test net output #0: accuracy = 0.822677
I0725 18:07:57.817159 20892 solver.cpp:404]     Test net output #1: loss = 0.393168 (* 1 = 0.393168 loss)
I0725 18:07:57.846307 20892 solver.cpp:228] Iteration 40500, loss = 0.347103
I0725 18:07:57.846354 20892 solver.cpp:244]     Train net output #0: loss = 0.347103 (* 1 = 0.347103 loss)
I0725 18:07:57.846364 20892 sgd_solver.cpp:106] Iteration 40500, lr = 4.35969e-06
I0725 18:08:07.178275 20892 solver.cpp:228] Iteration 40600, loss = 0.242118
I0725 18:08:07.178338 20892 solver.cpp:244]     Train net output #0: loss = 0.242118 (* 1 = 0.242118 loss)
I0725 18:08:07.178345 20892 sgd_solver.cpp:106] Iteration 40600, lr = 4.3543e-06
I0725 18:08:16.592710 20892 solver.cpp:228] Iteration 40700, loss = 0.446418
I0725 18:08:16.592756 20892 solver.cpp:244]     Train net output #0: loss = 0.446418 (* 1 = 0.446418 loss)
I0725 18:08:16.592762 20892 sgd_solver.cpp:106] Iteration 40700, lr = 4.34892e-06
I0725 18:08:26.009969 20892 solver.cpp:228] Iteration 40800, loss = 0.35043
I0725 18:08:26.010012 20892 solver.cpp:244]     Train net output #0: loss = 0.35043 (* 1 = 0.35043 loss)
I0725 18:08:26.010020 20892 sgd_solver.cpp:106] Iteration 40800, lr = 4.34355e-06
I0725 18:08:35.424144 20892 solver.cpp:228] Iteration 40900, loss = 0.304473
I0725 18:08:35.424185 20892 solver.cpp:244]     Train net output #0: loss = 0.304473 (* 1 = 0.304473 loss)
I0725 18:08:35.424190 20892 sgd_solver.cpp:106] Iteration 40900, lr = 4.3382e-06
I0725 18:08:44.749081 20892 solver.cpp:337] Iteration 41000, Testing net (#0)
I0725 18:08:58.965426 20892 solver.cpp:404]     Test net output #0: accuracy = 0.81971
I0725 18:08:58.965488 20892 solver.cpp:404]     Test net output #1: loss = 0.398847 (* 1 = 0.398847 loss)
I0725 18:08:58.992023 20892 solver.cpp:228] Iteration 41000, loss = 0.275324
I0725 18:08:58.992080 20892 solver.cpp:244]     Train net output #0: loss = 0.275324 (* 1 = 0.275324 loss)
I0725 18:08:58.992092 20892 sgd_solver.cpp:106] Iteration 41000, lr = 4.33286e-06
I0725 18:09:08.357102 20892 solver.cpp:228] Iteration 41100, loss = 0.282888
I0725 18:09:08.357259 20892 solver.cpp:244]     Train net output #0: loss = 0.282888 (* 1 = 0.282888 loss)
I0725 18:09:08.357280 20892 sgd_solver.cpp:106] Iteration 41100, lr = 4.32754e-06
I0725 18:09:17.927666 20892 solver.cpp:228] Iteration 41200, loss = 0.382907
I0725 18:09:17.927733 20892 solver.cpp:244]     Train net output #0: loss = 0.382907 (* 1 = 0.382907 loss)
I0725 18:09:17.927742 20892 sgd_solver.cpp:106] Iteration 41200, lr = 4.32224e-06
I0725 18:09:27.396514 20892 solver.cpp:228] Iteration 41300, loss = 0.368608
I0725 18:09:27.396574 20892 solver.cpp:244]     Train net output #0: loss = 0.368608 (* 1 = 0.368608 loss)
I0725 18:09:27.396584 20892 sgd_solver.cpp:106] Iteration 41300, lr = 4.31695e-06
I0725 18:09:36.803336 20892 solver.cpp:228] Iteration 41400, loss = 0.261041
I0725 18:09:36.803376 20892 solver.cpp:244]     Train net output #0: loss = 0.261041 (* 1 = 0.261041 loss)
I0725 18:09:36.803382 20892 sgd_solver.cpp:106] Iteration 41400, lr = 4.31168e-06
I0725 18:09:46.121178 20892 solver.cpp:337] Iteration 41500, Testing net (#0)
I0725 18:10:00.283860 20892 solver.cpp:404]     Test net output #0: accuracy = 0.823484
I0725 18:10:00.283911 20892 solver.cpp:404]     Test net output #1: loss = 0.39156 (* 1 = 0.39156 loss)
I0725 18:10:00.314759 20892 solver.cpp:228] Iteration 41500, loss = 0.540865
I0725 18:10:00.314827 20892 solver.cpp:244]     Train net output #0: loss = 0.540865 (* 1 = 0.540865 loss)
I0725 18:10:00.314839 20892 sgd_solver.cpp:106] Iteration 41500, lr = 4.30642e-06
I0725 18:10:09.725450 20892 solver.cpp:228] Iteration 41600, loss = 0.310507
I0725 18:10:09.725504 20892 solver.cpp:244]     Train net output #0: loss = 0.310507 (* 1 = 0.310507 loss)
I0725 18:10:09.725513 20892 sgd_solver.cpp:106] Iteration 41600, lr = 4.30117e-06
I0725 18:10:19.302470 20892 solver.cpp:228] Iteration 41700, loss = 0.345671
I0725 18:10:19.302521 20892 solver.cpp:244]     Train net output #0: loss = 0.345671 (* 1 = 0.345671 loss)
I0725 18:10:19.302527 20892 sgd_solver.cpp:106] Iteration 41700, lr = 4.29594e-06
I0725 18:10:28.785509 20892 solver.cpp:228] Iteration 41800, loss = 0.325078
I0725 18:10:28.785552 20892 solver.cpp:244]     Train net output #0: loss = 0.325078 (* 1 = 0.325078 loss)
I0725 18:10:28.785558 20892 sgd_solver.cpp:106] Iteration 41800, lr = 4.29073e-06
I0725 18:10:38.200601 20892 solver.cpp:228] Iteration 41900, loss = 0.300224
I0725 18:10:38.200655 20892 solver.cpp:244]     Train net output #0: loss = 0.300224 (* 1 = 0.300224 loss)
I0725 18:10:38.200664 20892 sgd_solver.cpp:106] Iteration 41900, lr = 4.28553e-06
I0725 18:10:47.527962 20892 solver.cpp:337] Iteration 42000, Testing net (#0)
I0725 18:10:59.468430 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:11:01.811174 20892 solver.cpp:404]     Test net output #0: accuracy = 0.822807
I0725 18:11:01.811224 20892 solver.cpp:404]     Test net output #1: loss = 0.392756 (* 1 = 0.392756 loss)
I0725 18:11:01.838672 20892 solver.cpp:228] Iteration 42000, loss = 0.421535
I0725 18:11:01.838726 20892 solver.cpp:244]     Train net output #0: loss = 0.421535 (* 1 = 0.421535 loss)
I0725 18:11:01.838738 20892 sgd_solver.cpp:106] Iteration 42000, lr = 4.28034e-06
I0725 18:11:11.264361 20892 solver.cpp:228] Iteration 42100, loss = 0.408025
I0725 18:11:11.264420 20892 solver.cpp:244]     Train net output #0: loss = 0.408025 (* 1 = 0.408025 loss)
I0725 18:11:11.264427 20892 sgd_solver.cpp:106] Iteration 42100, lr = 4.27517e-06
I0725 18:11:20.840801 20892 solver.cpp:228] Iteration 42200, loss = 0.326144
I0725 18:11:20.840852 20892 solver.cpp:244]     Train net output #0: loss = 0.326144 (* 1 = 0.326144 loss)
I0725 18:11:20.840859 20892 sgd_solver.cpp:106] Iteration 42200, lr = 4.27002e-06
I0725 18:11:30.200826 20892 solver.cpp:228] Iteration 42300, loss = 0.308409
I0725 18:11:30.200875 20892 solver.cpp:244]     Train net output #0: loss = 0.308409 (* 1 = 0.308409 loss)
I0725 18:11:30.200883 20892 sgd_solver.cpp:106] Iteration 42300, lr = 4.26488e-06
I0725 18:11:39.623502 20892 solver.cpp:228] Iteration 42400, loss = 0.307353
I0725 18:11:39.623553 20892 solver.cpp:244]     Train net output #0: loss = 0.307353 (* 1 = 0.307353 loss)
I0725 18:11:39.623564 20892 sgd_solver.cpp:106] Iteration 42400, lr = 4.25975e-06
I0725 18:11:48.945850 20892 solver.cpp:337] Iteration 42500, Testing net (#0)
I0725 18:12:03.215371 20892 solver.cpp:404]     Test net output #0: accuracy = 0.821581
I0725 18:12:03.215425 20892 solver.cpp:404]     Test net output #1: loss = 0.394128 (* 1 = 0.394128 loss)
I0725 18:12:03.241786 20892 solver.cpp:228] Iteration 42500, loss = 0.297996
I0725 18:12:03.241849 20892 solver.cpp:244]     Train net output #0: loss = 0.297996 (* 1 = 0.297996 loss)
I0725 18:12:03.241860 20892 sgd_solver.cpp:106] Iteration 42500, lr = 4.25464e-06
I0725 18:12:12.609779 20892 solver.cpp:228] Iteration 42600, loss = 0.380088
I0725 18:12:12.609822 20892 solver.cpp:244]     Train net output #0: loss = 0.380088 (* 1 = 0.380088 loss)
I0725 18:12:12.609827 20892 sgd_solver.cpp:106] Iteration 42600, lr = 4.24954e-06
I0725 18:12:22.015609 20892 solver.cpp:228] Iteration 42700, loss = 0.339607
I0725 18:12:22.015661 20892 solver.cpp:244]     Train net output #0: loss = 0.339607 (* 1 = 0.339607 loss)
I0725 18:12:22.015669 20892 sgd_solver.cpp:106] Iteration 42700, lr = 4.24445e-06
I0725 18:12:31.422718 20892 solver.cpp:228] Iteration 42800, loss = 0.34351
I0725 18:12:31.422772 20892 solver.cpp:244]     Train net output #0: loss = 0.34351 (* 1 = 0.34351 loss)
I0725 18:12:31.422780 20892 sgd_solver.cpp:106] Iteration 42800, lr = 4.23938e-06
I0725 18:12:40.828191 20892 solver.cpp:228] Iteration 42900, loss = 0.335349
I0725 18:12:40.828238 20892 solver.cpp:244]     Train net output #0: loss = 0.335349 (* 1 = 0.335349 loss)
I0725 18:12:40.828245 20892 sgd_solver.cpp:106] Iteration 42900, lr = 4.23433e-06
I0725 18:12:50.142776 20892 solver.cpp:337] Iteration 43000, Testing net (#0)
I0725 18:13:04.431953 20892 solver.cpp:404]     Test net output #0: accuracy = 0.822774
I0725 18:13:04.431995 20892 solver.cpp:404]     Test net output #1: loss = 0.393072 (* 1 = 0.393072 loss)
I0725 18:13:04.458534 20892 solver.cpp:228] Iteration 43000, loss = 0.349019
I0725 18:13:04.458580 20892 solver.cpp:244]     Train net output #0: loss = 0.349019 (* 1 = 0.349019 loss)
I0725 18:13:04.458588 20892 sgd_solver.cpp:106] Iteration 43000, lr = 4.22929e-06
I0725 18:13:13.802142 20892 solver.cpp:228] Iteration 43100, loss = 0.346774
I0725 18:13:13.802198 20892 solver.cpp:244]     Train net output #0: loss = 0.346774 (* 1 = 0.346774 loss)
I0725 18:13:13.802215 20892 sgd_solver.cpp:106] Iteration 43100, lr = 4.22426e-06
I0725 18:13:23.216114 20892 solver.cpp:228] Iteration 43200, loss = 0.423129
I0725 18:13:23.216177 20892 solver.cpp:244]     Train net output #0: loss = 0.423129 (* 1 = 0.423129 loss)
I0725 18:13:23.216186 20892 sgd_solver.cpp:106] Iteration 43200, lr = 4.21924e-06
I0725 18:13:32.629583 20892 solver.cpp:228] Iteration 43300, loss = 0.416681
I0725 18:13:32.629623 20892 solver.cpp:244]     Train net output #0: loss = 0.416681 (* 1 = 0.416681 loss)
I0725 18:13:32.629631 20892 sgd_solver.cpp:106] Iteration 43300, lr = 4.21424e-06
I0725 18:13:42.039415 20892 solver.cpp:228] Iteration 43400, loss = 0.287335
I0725 18:13:42.039455 20892 solver.cpp:244]     Train net output #0: loss = 0.287335 (* 1 = 0.287335 loss)
I0725 18:13:42.039461 20892 sgd_solver.cpp:106] Iteration 43400, lr = 4.20926e-06
I0725 18:13:51.355881 20892 solver.cpp:337] Iteration 43500, Testing net (#0)
I0725 18:13:59.985105 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:14:05.441813 20892 solver.cpp:404]     Test net output #0: accuracy = 0.823452
I0725 18:14:05.441867 20892 solver.cpp:404]     Test net output #1: loss = 0.390866 (* 1 = 0.390866 loss)
I0725 18:14:05.471289 20892 solver.cpp:228] Iteration 43500, loss = 0.370896
I0725 18:14:05.471352 20892 solver.cpp:244]     Train net output #0: loss = 0.370896 (* 1 = 0.370896 loss)
I0725 18:14:05.471371 20892 sgd_solver.cpp:106] Iteration 43500, lr = 4.20429e-06
I0725 18:14:14.789470 20892 solver.cpp:228] Iteration 43600, loss = 0.33058
I0725 18:14:14.789506 20892 solver.cpp:244]     Train net output #0: loss = 0.33058 (* 1 = 0.33058 loss)
I0725 18:14:14.789513 20892 sgd_solver.cpp:106] Iteration 43600, lr = 4.19933e-06
I0725 18:14:24.199719 20892 solver.cpp:228] Iteration 43700, loss = 0.373035
I0725 18:14:24.199767 20892 solver.cpp:244]     Train net output #0: loss = 0.373035 (* 1 = 0.373035 loss)
I0725 18:14:24.199774 20892 sgd_solver.cpp:106] Iteration 43700, lr = 4.19438e-06
I0725 18:14:33.611048 20892 solver.cpp:228] Iteration 43800, loss = 0.305242
I0725 18:14:33.611090 20892 solver.cpp:244]     Train net output #0: loss = 0.305242 (* 1 = 0.305242 loss)
I0725 18:14:33.611098 20892 sgd_solver.cpp:106] Iteration 43800, lr = 4.18945e-06
I0725 18:14:43.015348 20892 solver.cpp:228] Iteration 43900, loss = 0.254458
I0725 18:14:43.015401 20892 solver.cpp:244]     Train net output #0: loss = 0.254458 (* 1 = 0.254458 loss)
I0725 18:14:43.015415 20892 sgd_solver.cpp:106] Iteration 43900, lr = 4.18453e-06
I0725 18:14:52.326925 20892 solver.cpp:337] Iteration 44000, Testing net (#0)
I0725 18:15:06.502028 20892 solver.cpp:404]     Test net output #0: accuracy = 0.823581
I0725 18:15:06.502094 20892 solver.cpp:404]     Test net output #1: loss = 0.391671 (* 1 = 0.391671 loss)
I0725 18:15:06.528589 20892 solver.cpp:228] Iteration 44000, loss = 0.308402
I0725 18:15:06.528645 20892 solver.cpp:244]     Train net output #0: loss = 0.308402 (* 1 = 0.308402 loss)
I0725 18:15:06.528656 20892 sgd_solver.cpp:106] Iteration 44000, lr = 4.17963e-06
I0725 18:15:15.855448 20892 solver.cpp:228] Iteration 44100, loss = 0.374275
I0725 18:15:15.855499 20892 solver.cpp:244]     Train net output #0: loss = 0.374275 (* 1 = 0.374275 loss)
I0725 18:15:15.855516 20892 sgd_solver.cpp:106] Iteration 44100, lr = 4.17474e-06
I0725 18:15:25.264174 20892 solver.cpp:228] Iteration 44200, loss = 0.298927
I0725 18:15:25.264230 20892 solver.cpp:244]     Train net output #0: loss = 0.298927 (* 1 = 0.298927 loss)
I0725 18:15:25.264236 20892 sgd_solver.cpp:106] Iteration 44200, lr = 4.16986e-06
I0725 18:15:34.671442 20892 solver.cpp:228] Iteration 44300, loss = 0.376634
I0725 18:15:34.671499 20892 solver.cpp:244]     Train net output #0: loss = 0.376634 (* 1 = 0.376634 loss)
I0725 18:15:34.671505 20892 sgd_solver.cpp:106] Iteration 44300, lr = 4.16499e-06
I0725 18:15:44.078063 20892 solver.cpp:228] Iteration 44400, loss = 0.278346
I0725 18:15:44.078101 20892 solver.cpp:244]     Train net output #0: loss = 0.278346 (* 1 = 0.278346 loss)
I0725 18:15:44.078107 20892 sgd_solver.cpp:106] Iteration 44400, lr = 4.16014e-06
I0725 18:15:53.396019 20892 solver.cpp:337] Iteration 44500, Testing net (#0)
I0725 18:16:07.662763 20892 solver.cpp:404]     Test net output #0: accuracy = 0.816323
I0725 18:16:07.662822 20892 solver.cpp:404]     Test net output #1: loss = 0.401312 (* 1 = 0.401312 loss)
I0725 18:16:07.689494 20892 solver.cpp:228] Iteration 44500, loss = 0.332439
I0725 18:16:07.689553 20892 solver.cpp:244]     Train net output #0: loss = 0.332439 (* 1 = 0.332439 loss)
I0725 18:16:07.689563 20892 sgd_solver.cpp:106] Iteration 44500, lr = 4.1553e-06
I0725 18:16:17.092147 20892 solver.cpp:228] Iteration 44600, loss = 0.362288
I0725 18:16:17.092201 20892 solver.cpp:244]     Train net output #0: loss = 0.362288 (* 1 = 0.362288 loss)
I0725 18:16:17.092211 20892 sgd_solver.cpp:106] Iteration 44600, lr = 4.15048e-06
I0725 18:16:26.507668 20892 solver.cpp:228] Iteration 44700, loss = 0.351798
I0725 18:16:26.507733 20892 solver.cpp:244]     Train net output #0: loss = 0.351798 (* 1 = 0.351798 loss)
I0725 18:16:26.507742 20892 sgd_solver.cpp:106] Iteration 44700, lr = 4.14567e-06
I0725 18:16:35.917325 20892 solver.cpp:228] Iteration 44800, loss = 0.318348
I0725 18:16:35.917363 20892 solver.cpp:244]     Train net output #0: loss = 0.318348 (* 1 = 0.318348 loss)
I0725 18:16:35.917371 20892 sgd_solver.cpp:106] Iteration 44800, lr = 4.14087e-06
I0725 18:16:45.330106 20892 solver.cpp:228] Iteration 44900, loss = 0.322784
I0725 18:16:45.330152 20892 solver.cpp:244]     Train net output #0: loss = 0.322784 (* 1 = 0.322784 loss)
I0725 18:16:45.330158 20892 sgd_solver.cpp:106] Iteration 44900, lr = 4.13608e-06
I0725 18:16:54.651235 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_45000.caffemodel
I0725 18:16:55.069082 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_45000.solverstate
I0725 18:16:55.222025 20892 solver.cpp:337] Iteration 45000, Testing net (#0)
I0725 18:17:04.207667 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:17:09.244345 20892 solver.cpp:404]     Test net output #0: accuracy = 0.825323
I0725 18:17:09.244390 20892 solver.cpp:404]     Test net output #1: loss = 0.389731 (* 1 = 0.389731 loss)
I0725 18:17:09.273609 20892 solver.cpp:228] Iteration 45000, loss = 0.28551
I0725 18:17:09.273666 20892 solver.cpp:244]     Train net output #0: loss = 0.28551 (* 1 = 0.28551 loss)
I0725 18:17:09.273679 20892 sgd_solver.cpp:106] Iteration 45000, lr = 4.13131e-06
I0725 18:17:18.638356 20892 solver.cpp:228] Iteration 45100, loss = 0.235166
I0725 18:17:18.638423 20892 solver.cpp:244]     Train net output #0: loss = 0.235166 (* 1 = 0.235166 loss)
I0725 18:17:18.638433 20892 sgd_solver.cpp:106] Iteration 45100, lr = 4.12655e-06
I0725 18:17:28.147668 20892 solver.cpp:228] Iteration 45200, loss = 0.309351
I0725 18:17:28.147724 20892 solver.cpp:244]     Train net output #0: loss = 0.309351 (* 1 = 0.309351 loss)
I0725 18:17:28.147733 20892 sgd_solver.cpp:106] Iteration 45200, lr = 4.1218e-06
I0725 18:17:37.719259 20892 solver.cpp:228] Iteration 45300, loss = 0.389759
I0725 18:17:37.719307 20892 solver.cpp:244]     Train net output #0: loss = 0.389759 (* 1 = 0.389759 loss)
I0725 18:17:37.719315 20892 sgd_solver.cpp:106] Iteration 45300, lr = 4.11706e-06
I0725 18:17:47.055886 20892 solver.cpp:228] Iteration 45400, loss = 0.265396
I0725 18:17:47.055924 20892 solver.cpp:244]     Train net output #0: loss = 0.265396 (* 1 = 0.265396 loss)
I0725 18:17:47.055930 20892 sgd_solver.cpp:106] Iteration 45400, lr = 4.11234e-06
I0725 18:17:56.339437 20892 solver.cpp:337] Iteration 45500, Testing net (#0)
I0725 18:18:10.513909 20892 solver.cpp:404]     Test net output #0: accuracy = 0.824129
I0725 18:18:10.513972 20892 solver.cpp:404]     Test net output #1: loss = 0.39006 (* 1 = 0.39006 loss)
I0725 18:18:10.542969 20892 solver.cpp:228] Iteration 45500, loss = 0.304668
I0725 18:18:10.543015 20892 solver.cpp:244]     Train net output #0: loss = 0.304668 (* 1 = 0.304668 loss)
I0725 18:18:10.543026 20892 sgd_solver.cpp:106] Iteration 45500, lr = 4.10763e-06
I0725 18:18:19.860198 20892 solver.cpp:228] Iteration 45600, loss = 0.303909
I0725 18:18:19.860251 20892 solver.cpp:244]     Train net output #0: loss = 0.303909 (* 1 = 0.303909 loss)
I0725 18:18:19.860257 20892 sgd_solver.cpp:106] Iteration 45600, lr = 4.10293e-06
I0725 18:18:29.271862 20892 solver.cpp:228] Iteration 45700, loss = 0.308548
I0725 18:18:29.271901 20892 solver.cpp:244]     Train net output #0: loss = 0.308548 (* 1 = 0.308548 loss)
I0725 18:18:29.271908 20892 sgd_solver.cpp:106] Iteration 45700, lr = 4.09825e-06
I0725 18:18:38.684434 20892 solver.cpp:228] Iteration 45800, loss = 0.313405
I0725 18:18:38.684487 20892 solver.cpp:244]     Train net output #0: loss = 0.313405 (* 1 = 0.313405 loss)
I0725 18:18:38.684495 20892 sgd_solver.cpp:106] Iteration 45800, lr = 4.09358e-06
I0725 18:18:48.094542 20892 solver.cpp:228] Iteration 45900, loss = 0.337357
I0725 18:18:48.094588 20892 solver.cpp:244]     Train net output #0: loss = 0.337357 (* 1 = 0.337357 loss)
I0725 18:18:48.094594 20892 sgd_solver.cpp:106] Iteration 45900, lr = 4.08892e-06
I0725 18:18:57.408694 20892 solver.cpp:337] Iteration 46000, Testing net (#0)
I0725 18:19:11.634678 20892 solver.cpp:404]     Test net output #0: accuracy = 0.824774
I0725 18:19:11.634721 20892 solver.cpp:404]     Test net output #1: loss = 0.389655 (* 1 = 0.389655 loss)
I0725 18:19:11.663882 20892 solver.cpp:228] Iteration 46000, loss = 0.306988
I0725 18:19:11.663934 20892 solver.cpp:244]     Train net output #0: loss = 0.306988 (* 1 = 0.306988 loss)
I0725 18:19:11.663955 20892 sgd_solver.cpp:106] Iteration 46000, lr = 4.08427e-06
I0725 18:19:21.033936 20892 solver.cpp:228] Iteration 46100, loss = 0.24002
I0725 18:19:21.033993 20892 solver.cpp:244]     Train net output #0: loss = 0.24002 (* 1 = 0.24002 loss)
I0725 18:19:21.034000 20892 sgd_solver.cpp:106] Iteration 46100, lr = 4.07964e-06
I0725 18:19:30.447470 20892 solver.cpp:228] Iteration 46200, loss = 0.337946
I0725 18:19:30.447512 20892 solver.cpp:244]     Train net output #0: loss = 0.337946 (* 1 = 0.337946 loss)
I0725 18:19:30.447518 20892 sgd_solver.cpp:106] Iteration 46200, lr = 4.07501e-06
I0725 18:19:39.859416 20892 solver.cpp:228] Iteration 46300, loss = 0.393198
I0725 18:19:39.859460 20892 solver.cpp:244]     Train net output #0: loss = 0.393198 (* 1 = 0.393198 loss)
I0725 18:19:39.859467 20892 sgd_solver.cpp:106] Iteration 46300, lr = 4.0704e-06
I0725 18:19:49.275889 20892 solver.cpp:228] Iteration 46400, loss = 0.324976
I0725 18:19:49.275939 20892 solver.cpp:244]     Train net output #0: loss = 0.324976 (* 1 = 0.324976 loss)
I0725 18:19:49.275945 20892 sgd_solver.cpp:106] Iteration 46400, lr = 4.0658e-06
I0725 18:19:58.598343 20892 solver.cpp:337] Iteration 46500, Testing net (#0)
I0725 18:20:09.777221 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:20:12.681973 20892 solver.cpp:404]     Test net output #0: accuracy = 0.817968
I0725 18:20:12.682018 20892 solver.cpp:404]     Test net output #1: loss = 0.399044 (* 1 = 0.399044 loss)
I0725 18:20:12.711423 20892 solver.cpp:228] Iteration 46500, loss = 0.328884
I0725 18:20:12.711469 20892 solver.cpp:244]     Train net output #0: loss = 0.328884 (* 1 = 0.328884 loss)
I0725 18:20:12.711479 20892 sgd_solver.cpp:106] Iteration 46500, lr = 4.06122e-06
I0725 18:20:22.046319 20892 solver.cpp:228] Iteration 46600, loss = 0.371081
I0725 18:20:22.046362 20892 solver.cpp:244]     Train net output #0: loss = 0.371081 (* 1 = 0.371081 loss)
I0725 18:20:22.046370 20892 sgd_solver.cpp:106] Iteration 46600, lr = 4.05664e-06
I0725 18:20:31.431280 20892 solver.cpp:228] Iteration 46700, loss = 0.294849
I0725 18:20:31.431337 20892 solver.cpp:244]     Train net output #0: loss = 0.294849 (* 1 = 0.294849 loss)
I0725 18:20:31.431344 20892 sgd_solver.cpp:106] Iteration 46700, lr = 4.05208e-06
I0725 18:20:40.832954 20892 solver.cpp:228] Iteration 46800, loss = 0.309904
I0725 18:20:40.832993 20892 solver.cpp:244]     Train net output #0: loss = 0.309904 (* 1 = 0.309904 loss)
I0725 18:20:40.832999 20892 sgd_solver.cpp:106] Iteration 46800, lr = 4.04753e-06
I0725 18:20:50.238337 20892 solver.cpp:228] Iteration 46900, loss = 0.447375
I0725 18:20:50.238391 20892 solver.cpp:244]     Train net output #0: loss = 0.447375 (* 1 = 0.447375 loss)
I0725 18:20:50.238397 20892 sgd_solver.cpp:106] Iteration 46900, lr = 4.04299e-06
I0725 18:20:59.552778 20892 solver.cpp:337] Iteration 47000, Testing net (#0)
I0725 18:21:13.674067 20892 solver.cpp:404]     Test net output #0: accuracy = 0.824871
I0725 18:21:13.674126 20892 solver.cpp:404]     Test net output #1: loss = 0.389309 (* 1 = 0.389309 loss)
I0725 18:21:13.703639 20892 solver.cpp:228] Iteration 47000, loss = 0.370197
I0725 18:21:13.703670 20892 solver.cpp:244]     Train net output #0: loss = 0.370197 (* 1 = 0.370197 loss)
I0725 18:21:13.703680 20892 sgd_solver.cpp:106] Iteration 47000, lr = 4.03847e-06
I0725 18:21:23.084997 20892 solver.cpp:228] Iteration 47100, loss = 0.335702
I0725 18:21:23.085049 20892 solver.cpp:244]     Train net output #0: loss = 0.335702 (* 1 = 0.335702 loss)
I0725 18:21:23.085057 20892 sgd_solver.cpp:106] Iteration 47100, lr = 4.03395e-06
I0725 18:21:32.492146 20892 solver.cpp:228] Iteration 47200, loss = 0.492783
I0725 18:21:32.492202 20892 solver.cpp:244]     Train net output #0: loss = 0.492783 (* 1 = 0.492783 loss)
I0725 18:21:32.492210 20892 sgd_solver.cpp:106] Iteration 47200, lr = 4.02945e-06
I0725 18:21:41.897040 20892 solver.cpp:228] Iteration 47300, loss = 0.310384
I0725 18:21:41.897080 20892 solver.cpp:244]     Train net output #0: loss = 0.310384 (* 1 = 0.310384 loss)
I0725 18:21:41.897086 20892 sgd_solver.cpp:106] Iteration 47300, lr = 4.02496e-06
I0725 18:21:51.309458 20892 solver.cpp:228] Iteration 47400, loss = 0.356551
I0725 18:21:51.309520 20892 solver.cpp:244]     Train net output #0: loss = 0.356551 (* 1 = 0.356551 loss)
I0725 18:21:51.309526 20892 sgd_solver.cpp:106] Iteration 47400, lr = 4.02048e-06
I0725 18:22:00.625234 20892 solver.cpp:337] Iteration 47500, Testing net (#0)
I0725 18:22:14.826560 20892 solver.cpp:404]     Test net output #0: accuracy = 0.825258
I0725 18:22:14.826601 20892 solver.cpp:404]     Test net output #1: loss = 0.388253 (* 1 = 0.388253 loss)
I0725 18:22:14.852954 20892 solver.cpp:228] Iteration 47500, loss = 0.317735
I0725 18:22:14.852989 20892 solver.cpp:244]     Train net output #0: loss = 0.317735 (* 1 = 0.317735 loss)
I0725 18:22:14.852999 20892 sgd_solver.cpp:106] Iteration 47500, lr = 4.01601e-06
I0725 18:22:24.154525 20892 solver.cpp:228] Iteration 47600, loss = 0.331166
I0725 18:22:24.154566 20892 solver.cpp:244]     Train net output #0: loss = 0.331166 (* 1 = 0.331166 loss)
I0725 18:22:24.154572 20892 sgd_solver.cpp:106] Iteration 47600, lr = 4.01155e-06
I0725 18:22:33.711349 20892 solver.cpp:228] Iteration 47700, loss = 0.33271
I0725 18:22:33.711413 20892 solver.cpp:244]     Train net output #0: loss = 0.33271 (* 1 = 0.33271 loss)
I0725 18:22:33.711422 20892 sgd_solver.cpp:106] Iteration 47700, lr = 4.00711e-06
I0725 18:22:43.114949 20892 solver.cpp:228] Iteration 47800, loss = 0.283091
I0725 18:22:43.114998 20892 solver.cpp:244]     Train net output #0: loss = 0.283091 (* 1 = 0.283091 loss)
I0725 18:22:43.115005 20892 sgd_solver.cpp:106] Iteration 47800, lr = 4.00267e-06
I0725 18:22:52.485939 20892 solver.cpp:228] Iteration 47900, loss = 0.325171
I0725 18:22:52.485980 20892 solver.cpp:244]     Train net output #0: loss = 0.325171 (* 1 = 0.325171 loss)
I0725 18:22:52.485986 20892 sgd_solver.cpp:106] Iteration 47900, lr = 3.99825e-06
I0725 18:23:01.804894 20892 solver.cpp:337] Iteration 48000, Testing net (#0)
I0725 18:23:08.348645 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:23:16.031771 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826839
I0725 18:23:16.031817 20892 solver.cpp:404]     Test net output #1: loss = 0.385906 (* 1 = 0.385906 loss)
I0725 18:23:16.060848 20892 solver.cpp:228] Iteration 48000, loss = 0.318308
I0725 18:23:16.060881 20892 solver.cpp:244]     Train net output #0: loss = 0.318308 (* 1 = 0.318308 loss)
I0725 18:23:16.060904 20892 sgd_solver.cpp:106] Iteration 48000, lr = 3.99384e-06
I0725 18:23:25.400527 20892 solver.cpp:228] Iteration 48100, loss = 0.387207
I0725 18:23:25.400565 20892 solver.cpp:244]     Train net output #0: loss = 0.387207 (* 1 = 0.387207 loss)
I0725 18:23:25.400571 20892 sgd_solver.cpp:106] Iteration 48100, lr = 3.98944e-06
I0725 18:23:34.806304 20892 solver.cpp:228] Iteration 48200, loss = 0.357311
I0725 18:23:34.806346 20892 solver.cpp:244]     Train net output #0: loss = 0.357311 (* 1 = 0.357311 loss)
I0725 18:23:34.806352 20892 sgd_solver.cpp:106] Iteration 48200, lr = 3.98505e-06
I0725 18:23:44.215003 20892 solver.cpp:228] Iteration 48300, loss = 0.381247
I0725 18:23:44.215047 20892 solver.cpp:244]     Train net output #0: loss = 0.381247 (* 1 = 0.381247 loss)
I0725 18:23:44.215054 20892 sgd_solver.cpp:106] Iteration 48300, lr = 3.98068e-06
I0725 18:23:53.623670 20892 solver.cpp:228] Iteration 48400, loss = 0.349552
I0725 18:23:53.623728 20892 solver.cpp:244]     Train net output #0: loss = 0.349552 (* 1 = 0.349552 loss)
I0725 18:23:53.623734 20892 sgd_solver.cpp:106] Iteration 48400, lr = 3.97631e-06
I0725 18:24:02.932770 20892 solver.cpp:337] Iteration 48500, Testing net (#0)
I0725 18:24:17.087568 20892 solver.cpp:404]     Test net output #0: accuracy = 0.823581
I0725 18:24:17.087610 20892 solver.cpp:404]     Test net output #1: loss = 0.391792 (* 1 = 0.391792 loss)
I0725 18:24:17.116562 20892 solver.cpp:228] Iteration 48500, loss = 0.280992
I0725 18:24:17.116614 20892 solver.cpp:244]     Train net output #0: loss = 0.280992 (* 1 = 0.280992 loss)
I0725 18:24:17.116624 20892 sgd_solver.cpp:106] Iteration 48500, lr = 3.97196e-06
I0725 18:24:26.409580 20892 solver.cpp:228] Iteration 48600, loss = 0.315367
I0725 18:24:26.409629 20892 solver.cpp:244]     Train net output #0: loss = 0.315367 (* 1 = 0.315367 loss)
I0725 18:24:26.409636 20892 sgd_solver.cpp:106] Iteration 48600, lr = 3.96761e-06
I0725 18:24:35.820751 20892 solver.cpp:228] Iteration 48700, loss = 0.590055
I0725 18:24:35.820806 20892 solver.cpp:244]     Train net output #0: loss = 0.590055 (* 1 = 0.590055 loss)
I0725 18:24:35.820812 20892 sgd_solver.cpp:106] Iteration 48700, lr = 3.96328e-06
I0725 18:24:45.224328 20892 solver.cpp:228] Iteration 48800, loss = 0.380425
I0725 18:24:45.224370 20892 solver.cpp:244]     Train net output #0: loss = 0.380425 (* 1 = 0.380425 loss)
I0725 18:24:45.224377 20892 sgd_solver.cpp:106] Iteration 48800, lr = 3.95896e-06
I0725 18:24:54.629748 20892 solver.cpp:228] Iteration 48900, loss = 0.326209
I0725 18:24:54.629799 20892 solver.cpp:244]     Train net output #0: loss = 0.326209 (* 1 = 0.326209 loss)
I0725 18:24:54.629806 20892 sgd_solver.cpp:106] Iteration 48900, lr = 3.95465e-06
I0725 18:25:03.942116 20892 solver.cpp:337] Iteration 49000, Testing net (#0)
I0725 18:25:17.944386 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827516
I0725 18:25:17.944442 20892 solver.cpp:404]     Test net output #1: loss = 0.384849 (* 1 = 0.384849 loss)
I0725 18:25:17.973888 20892 solver.cpp:228] Iteration 49000, loss = 0.357756
I0725 18:25:17.973943 20892 solver.cpp:244]     Train net output #0: loss = 0.357756 (* 1 = 0.357756 loss)
I0725 18:25:17.973955 20892 sgd_solver.cpp:106] Iteration 49000, lr = 3.95035e-06
I0725 18:25:27.307693 20892 solver.cpp:228] Iteration 49100, loss = 0.298509
I0725 18:25:27.307746 20892 solver.cpp:244]     Train net output #0: loss = 0.298509 (* 1 = 0.298509 loss)
I0725 18:25:27.307754 20892 sgd_solver.cpp:106] Iteration 49100, lr = 3.94606e-06
I0725 18:25:36.830173 20892 solver.cpp:228] Iteration 49200, loss = 0.305688
I0725 18:25:36.830222 20892 solver.cpp:244]     Train net output #0: loss = 0.305688 (* 1 = 0.305688 loss)
I0725 18:25:36.830230 20892 sgd_solver.cpp:106] Iteration 49200, lr = 3.94178e-06
I0725 18:25:46.335472 20892 solver.cpp:228] Iteration 49300, loss = 0.336258
I0725 18:25:46.335525 20892 solver.cpp:244]     Train net output #0: loss = 0.336258 (* 1 = 0.336258 loss)
I0725 18:25:46.335533 20892 sgd_solver.cpp:106] Iteration 49300, lr = 3.93752e-06
I0725 18:25:55.699285 20892 solver.cpp:228] Iteration 49400, loss = 0.424533
I0725 18:25:55.699342 20892 solver.cpp:244]     Train net output #0: loss = 0.424533 (* 1 = 0.424533 loss)
I0725 18:25:55.699368 20892 sgd_solver.cpp:106] Iteration 49400, lr = 3.93326e-06
I0725 18:26:04.998483 20892 solver.cpp:337] Iteration 49500, Testing net (#0)
I0725 18:26:12.567950 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:26:19.200150 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826484
I0725 18:26:19.200193 20892 solver.cpp:404]     Test net output #1: loss = 0.386617 (* 1 = 0.386617 loss)
I0725 18:26:19.229017 20892 solver.cpp:228] Iteration 49500, loss = 0.287731
I0725 18:26:19.229079 20892 solver.cpp:244]     Train net output #0: loss = 0.287731 (* 1 = 0.287731 loss)
I0725 18:26:19.229099 20892 sgd_solver.cpp:106] Iteration 49500, lr = 3.92902e-06
I0725 18:26:28.558929 20892 solver.cpp:228] Iteration 49600, loss = 0.266131
I0725 18:26:28.558970 20892 solver.cpp:244]     Train net output #0: loss = 0.266131 (* 1 = 0.266131 loss)
I0725 18:26:28.558976 20892 sgd_solver.cpp:106] Iteration 49600, lr = 3.92478e-06
I0725 18:26:37.964557 20892 solver.cpp:228] Iteration 49700, loss = 0.296619
I0725 18:26:37.964604 20892 solver.cpp:244]     Train net output #0: loss = 0.296619 (* 1 = 0.296619 loss)
I0725 18:26:37.964610 20892 sgd_solver.cpp:106] Iteration 49700, lr = 3.92056e-06
I0725 18:26:47.372930 20892 solver.cpp:228] Iteration 49800, loss = 0.319642
I0725 18:26:47.372972 20892 solver.cpp:244]     Train net output #0: loss = 0.319642 (* 1 = 0.319642 loss)
I0725 18:26:47.372978 20892 sgd_solver.cpp:106] Iteration 49800, lr = 3.91634e-06
I0725 18:26:56.777806 20892 solver.cpp:228] Iteration 49900, loss = 0.35476
I0725 18:26:56.777845 20892 solver.cpp:244]     Train net output #0: loss = 0.35476 (* 1 = 0.35476 loss)
I0725 18:26:56.777851 20892 sgd_solver.cpp:106] Iteration 49900, lr = 3.91214e-06
I0725 18:27:06.081493 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_50000.caffemodel
I0725 18:27:06.438405 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_50000.solverstate
I0725 18:27:06.538265 20892 solver.cpp:337] Iteration 50000, Testing net (#0)
I0725 18:27:20.401260 20892 solver.cpp:404]     Test net output #0: accuracy = 0.824807
I0725 18:27:20.401319 20892 solver.cpp:404]     Test net output #1: loss = 0.388632 (* 1 = 0.388632 loss)
I0725 18:27:20.430501 20892 solver.cpp:228] Iteration 50000, loss = 0.350901
I0725 18:27:20.430555 20892 solver.cpp:244]     Train net output #0: loss = 0.350901 (* 1 = 0.350901 loss)
I0725 18:27:20.430567 20892 sgd_solver.cpp:106] Iteration 50000, lr = 3.90795e-06
I0725 18:27:29.800340 20892 solver.cpp:228] Iteration 50100, loss = 0.36926
I0725 18:27:29.800390 20892 solver.cpp:244]     Train net output #0: loss = 0.36926 (* 1 = 0.36926 loss)
I0725 18:27:29.800396 20892 sgd_solver.cpp:106] Iteration 50100, lr = 3.90377e-06
I0725 18:27:39.206574 20892 solver.cpp:228] Iteration 50200, loss = 0.332669
I0725 18:27:39.206615 20892 solver.cpp:244]     Train net output #0: loss = 0.332669 (* 1 = 0.332669 loss)
I0725 18:27:39.206621 20892 sgd_solver.cpp:106] Iteration 50200, lr = 3.8996e-06
I0725 18:27:48.606632 20892 solver.cpp:228] Iteration 50300, loss = 0.27336
I0725 18:27:48.606670 20892 solver.cpp:244]     Train net output #0: loss = 0.27336 (* 1 = 0.27336 loss)
I0725 18:27:48.606676 20892 sgd_solver.cpp:106] Iteration 50300, lr = 3.89544e-06
I0725 18:27:58.007886 20892 solver.cpp:228] Iteration 50400, loss = 0.376786
I0725 18:27:58.007939 20892 solver.cpp:244]     Train net output #0: loss = 0.376786 (* 1 = 0.376786 loss)
I0725 18:27:58.007946 20892 sgd_solver.cpp:106] Iteration 50400, lr = 3.89128e-06
I0725 18:28:07.313133 20892 solver.cpp:337] Iteration 50500, Testing net (#0)
I0725 18:28:21.417078 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826226
I0725 18:28:21.417135 20892 solver.cpp:404]     Test net output #1: loss = 0.387118 (* 1 = 0.387118 loss)
I0725 18:28:21.449195 20892 solver.cpp:228] Iteration 50500, loss = 0.271056
I0725 18:28:21.449266 20892 solver.cpp:244]     Train net output #0: loss = 0.271056 (* 1 = 0.271056 loss)
I0725 18:28:21.449277 20892 sgd_solver.cpp:106] Iteration 50500, lr = 3.88714e-06
I0725 18:28:30.780586 20892 solver.cpp:228] Iteration 50600, loss = 0.275503
I0725 18:28:30.780639 20892 solver.cpp:244]     Train net output #0: loss = 0.275503 (* 1 = 0.275503 loss)
I0725 18:28:30.780658 20892 sgd_solver.cpp:106] Iteration 50600, lr = 3.88301e-06
I0725 18:28:40.191277 20892 solver.cpp:228] Iteration 50700, loss = 0.368365
I0725 18:28:40.191329 20892 solver.cpp:244]     Train net output #0: loss = 0.368365 (* 1 = 0.368365 loss)
I0725 18:28:40.191335 20892 sgd_solver.cpp:106] Iteration 50700, lr = 3.87889e-06
I0725 18:28:49.602701 20892 solver.cpp:228] Iteration 50800, loss = 0.469013
I0725 18:28:49.602766 20892 solver.cpp:244]     Train net output #0: loss = 0.469013 (* 1 = 0.469013 loss)
I0725 18:28:49.602774 20892 sgd_solver.cpp:106] Iteration 50800, lr = 3.87478e-06
I0725 18:28:59.017376 20892 solver.cpp:228] Iteration 50900, loss = 0.257307
I0725 18:28:59.017413 20892 solver.cpp:244]     Train net output #0: loss = 0.257307 (* 1 = 0.257307 loss)
I0725 18:28:59.017419 20892 sgd_solver.cpp:106] Iteration 50900, lr = 3.87068e-06
I0725 18:29:08.336325 20892 solver.cpp:337] Iteration 51000, Testing net (#0)
I0725 18:29:16.946307 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:29:22.334314 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827226
I0725 18:29:22.334369 20892 solver.cpp:404]     Test net output #1: loss = 0.384599 (* 1 = 0.384599 loss)
I0725 18:29:22.360993 20892 solver.cpp:228] Iteration 51000, loss = 0.248702
I0725 18:29:22.361048 20892 solver.cpp:244]     Train net output #0: loss = 0.248702 (* 1 = 0.248702 loss)
I0725 18:29:22.361060 20892 sgd_solver.cpp:106] Iteration 51000, lr = 3.8666e-06
I0725 18:29:31.737993 20892 solver.cpp:228] Iteration 51100, loss = 0.338173
I0725 18:29:31.738051 20892 solver.cpp:244]     Train net output #0: loss = 0.338173 (* 1 = 0.338173 loss)
I0725 18:29:31.738059 20892 sgd_solver.cpp:106] Iteration 51100, lr = 3.86252e-06
I0725 18:29:41.142071 20892 solver.cpp:228] Iteration 51200, loss = 0.351092
I0725 18:29:41.142130 20892 solver.cpp:244]     Train net output #0: loss = 0.351092 (* 1 = 0.351092 loss)
I0725 18:29:41.142138 20892 sgd_solver.cpp:106] Iteration 51200, lr = 3.85845e-06
I0725 18:29:50.542160 20892 solver.cpp:228] Iteration 51300, loss = 0.442646
I0725 18:29:50.542212 20892 solver.cpp:244]     Train net output #0: loss = 0.442646 (* 1 = 0.442646 loss)
I0725 18:29:50.542218 20892 sgd_solver.cpp:106] Iteration 51300, lr = 3.85439e-06
I0725 18:29:59.939779 20892 solver.cpp:228] Iteration 51400, loss = 0.28368
I0725 18:29:59.939816 20892 solver.cpp:244]     Train net output #0: loss = 0.28368 (* 1 = 0.28368 loss)
I0725 18:29:59.939822 20892 sgd_solver.cpp:106] Iteration 51400, lr = 3.85034e-06
I0725 18:30:09.245015 20892 solver.cpp:337] Iteration 51500, Testing net (#0)
I0725 18:30:23.325572 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826903
I0725 18:30:23.325633 20892 solver.cpp:404]     Test net output #1: loss = 0.386198 (* 1 = 0.386198 loss)
I0725 18:30:23.356878 20892 solver.cpp:228] Iteration 51500, loss = 0.353079
I0725 18:30:23.356930 20892 solver.cpp:244]     Train net output #0: loss = 0.353079 (* 1 = 0.353079 loss)
I0725 18:30:23.356948 20892 sgd_solver.cpp:106] Iteration 51500, lr = 3.8463e-06
I0725 18:30:32.730108 20892 solver.cpp:228] Iteration 51600, loss = 0.314575
I0725 18:30:32.730161 20892 solver.cpp:244]     Train net output #0: loss = 0.314575 (* 1 = 0.314575 loss)
I0725 18:30:32.730170 20892 sgd_solver.cpp:106] Iteration 51600, lr = 3.84227e-06
I0725 18:30:42.140241 20892 solver.cpp:228] Iteration 51700, loss = 0.272115
I0725 18:30:42.140295 20892 solver.cpp:244]     Train net output #0: loss = 0.272115 (* 1 = 0.272115 loss)
I0725 18:30:42.140303 20892 sgd_solver.cpp:106] Iteration 51700, lr = 3.83825e-06
I0725 18:30:51.541196 20892 solver.cpp:228] Iteration 51800, loss = 0.307948
I0725 18:30:51.541250 20892 solver.cpp:244]     Train net output #0: loss = 0.307948 (* 1 = 0.307948 loss)
I0725 18:30:51.541257 20892 sgd_solver.cpp:106] Iteration 51800, lr = 3.83424e-06
I0725 18:31:00.947603 20892 solver.cpp:228] Iteration 51900, loss = 0.244388
I0725 18:31:00.947666 20892 solver.cpp:244]     Train net output #0: loss = 0.244388 (* 1 = 0.244388 loss)
I0725 18:31:00.947674 20892 sgd_solver.cpp:106] Iteration 51900, lr = 3.83024e-06
I0725 18:31:10.219185 20892 solver.cpp:337] Iteration 52000, Testing net (#0)
I0725 18:31:24.406543 20892 solver.cpp:404]     Test net output #0: accuracy = 0.819774
I0725 18:31:24.406597 20892 solver.cpp:404]     Test net output #1: loss = 0.396344 (* 1 = 0.396344 loss)
I0725 18:31:24.436317 20892 solver.cpp:228] Iteration 52000, loss = 0.278054
I0725 18:31:24.436379 20892 solver.cpp:244]     Train net output #0: loss = 0.278054 (* 1 = 0.278054 loss)
I0725 18:31:24.436398 20892 sgd_solver.cpp:106] Iteration 52000, lr = 3.82625e-06
I0725 18:31:33.790300 20892 solver.cpp:228] Iteration 52100, loss = 0.370933
I0725 18:31:33.790354 20892 solver.cpp:244]     Train net output #0: loss = 0.370933 (* 1 = 0.370933 loss)
I0725 18:31:33.790361 20892 sgd_solver.cpp:106] Iteration 52100, lr = 3.82227e-06
I0725 18:31:43.198575 20892 solver.cpp:228] Iteration 52200, loss = 0.371928
I0725 18:31:43.198622 20892 solver.cpp:244]     Train net output #0: loss = 0.371928 (* 1 = 0.371928 loss)
I0725 18:31:43.198631 20892 sgd_solver.cpp:106] Iteration 52200, lr = 3.8183e-06
I0725 18:31:52.611373 20892 solver.cpp:228] Iteration 52300, loss = 0.29941
I0725 18:31:52.611423 20892 solver.cpp:244]     Train net output #0: loss = 0.29941 (* 1 = 0.29941 loss)
I0725 18:31:52.611429 20892 sgd_solver.cpp:106] Iteration 52300, lr = 3.81433e-06
I0725 18:32:02.022609 20892 solver.cpp:228] Iteration 52400, loss = 0.338611
I0725 18:32:02.022670 20892 solver.cpp:244]     Train net output #0: loss = 0.338611 (* 1 = 0.338611 loss)
I0725 18:32:02.022677 20892 sgd_solver.cpp:106] Iteration 52400, lr = 3.81038e-06
I0725 18:32:11.339973 20892 solver.cpp:337] Iteration 52500, Testing net (#0)
I0725 18:32:20.816614 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:32:25.480993 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827968
I0725 18:32:25.481029 20892 solver.cpp:404]     Test net output #1: loss = 0.384584 (* 1 = 0.384584 loss)
I0725 18:32:25.510140 20892 solver.cpp:228] Iteration 52500, loss = 0.322052
I0725 18:32:25.510192 20892 solver.cpp:244]     Train net output #0: loss = 0.322052 (* 1 = 0.322052 loss)
I0725 18:32:25.510205 20892 sgd_solver.cpp:106] Iteration 52500, lr = 3.80644e-06
I0725 18:32:34.838721 20892 solver.cpp:228] Iteration 52600, loss = 0.390897
I0725 18:32:34.838773 20892 solver.cpp:244]     Train net output #0: loss = 0.390897 (* 1 = 0.390897 loss)
I0725 18:32:34.838780 20892 sgd_solver.cpp:106] Iteration 52600, lr = 3.80251e-06
I0725 18:32:44.246145 20892 solver.cpp:228] Iteration 52700, loss = 0.409393
I0725 18:32:44.246201 20892 solver.cpp:244]     Train net output #0: loss = 0.409393 (* 1 = 0.409393 loss)
I0725 18:32:44.246208 20892 sgd_solver.cpp:106] Iteration 52700, lr = 3.79858e-06
I0725 18:32:53.652319 20892 solver.cpp:228] Iteration 52800, loss = 0.295329
I0725 18:32:53.652369 20892 solver.cpp:244]     Train net output #0: loss = 0.295329 (* 1 = 0.295329 loss)
I0725 18:32:53.652375 20892 sgd_solver.cpp:106] Iteration 52800, lr = 3.79467e-06
I0725 18:33:03.061065 20892 solver.cpp:228] Iteration 52900, loss = 0.293828
I0725 18:33:03.061125 20892 solver.cpp:244]     Train net output #0: loss = 0.293828 (* 1 = 0.293828 loss)
I0725 18:33:03.061133 20892 sgd_solver.cpp:106] Iteration 52900, lr = 3.79076e-06
I0725 18:33:12.373531 20892 solver.cpp:337] Iteration 53000, Testing net (#0)
I0725 18:33:26.429206 20892 solver.cpp:404]     Test net output #0: accuracy = 0.828065
I0725 18:33:26.429252 20892 solver.cpp:404]     Test net output #1: loss = 0.383973 (* 1 = 0.383973 loss)
I0725 18:33:26.458268 20892 solver.cpp:228] Iteration 53000, loss = 0.253577
I0725 18:33:26.458305 20892 solver.cpp:244]     Train net output #0: loss = 0.253577 (* 1 = 0.253577 loss)
I0725 18:33:26.458325 20892 sgd_solver.cpp:106] Iteration 53000, lr = 3.78687e-06
I0725 18:33:35.830746 20892 solver.cpp:228] Iteration 53100, loss = 0.335674
I0725 18:33:35.830797 20892 solver.cpp:244]     Train net output #0: loss = 0.335674 (* 1 = 0.335674 loss)
I0725 18:33:35.830803 20892 sgd_solver.cpp:106] Iteration 53100, lr = 3.78298e-06
I0725 18:33:45.233477 20892 solver.cpp:228] Iteration 53200, loss = 0.250829
I0725 18:33:45.233516 20892 solver.cpp:244]     Train net output #0: loss = 0.250829 (* 1 = 0.250829 loss)
I0725 18:33:45.233523 20892 sgd_solver.cpp:106] Iteration 53200, lr = 3.77911e-06
I0725 18:33:54.636418 20892 solver.cpp:228] Iteration 53300, loss = 0.388066
I0725 18:33:54.636481 20892 solver.cpp:244]     Train net output #0: loss = 0.388066 (* 1 = 0.388066 loss)
I0725 18:33:54.636488 20892 sgd_solver.cpp:106] Iteration 53300, lr = 3.77524e-06
I0725 18:34:04.034027 20892 solver.cpp:228] Iteration 53400, loss = 0.32582
I0725 18:34:04.034070 20892 solver.cpp:244]     Train net output #0: loss = 0.32582 (* 1 = 0.32582 loss)
I0725 18:34:04.034075 20892 sgd_solver.cpp:106] Iteration 53400, lr = 3.77138e-06
I0725 18:34:13.337256 20892 solver.cpp:337] Iteration 53500, Testing net (#0)
I0725 18:34:27.454159 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827903
I0725 18:34:27.454231 20892 solver.cpp:404]     Test net output #1: loss = 0.384363 (* 1 = 0.384363 loss)
I0725 18:34:27.484638 20892 solver.cpp:228] Iteration 53500, loss = 0.308713
I0725 18:34:27.484691 20892 solver.cpp:244]     Train net output #0: loss = 0.308713 (* 1 = 0.308713 loss)
I0725 18:34:27.484712 20892 sgd_solver.cpp:106] Iteration 53500, lr = 3.76753e-06
I0725 18:34:36.877035 20892 solver.cpp:228] Iteration 53600, loss = 0.346348
I0725 18:34:36.877084 20892 solver.cpp:244]     Train net output #0: loss = 0.346348 (* 1 = 0.346348 loss)
I0725 18:34:36.877090 20892 sgd_solver.cpp:106] Iteration 53600, lr = 3.76369e-06
I0725 18:34:46.288206 20892 solver.cpp:228] Iteration 53700, loss = 0.27179
I0725 18:34:46.288282 20892 solver.cpp:244]     Train net output #0: loss = 0.27179 (* 1 = 0.27179 loss)
I0725 18:34:46.288291 20892 sgd_solver.cpp:106] Iteration 53700, lr = 3.75986e-06
I0725 18:34:55.700031 20892 solver.cpp:228] Iteration 53800, loss = 0.421505
I0725 18:34:55.700104 20892 solver.cpp:244]     Train net output #0: loss = 0.421505 (* 1 = 0.421505 loss)
I0725 18:34:55.700112 20892 sgd_solver.cpp:106] Iteration 53800, lr = 3.75604e-06
I0725 18:35:05.117936 20892 solver.cpp:228] Iteration 53900, loss = 0.360787
I0725 18:35:05.118007 20892 solver.cpp:244]     Train net output #0: loss = 0.360787 (* 1 = 0.360787 loss)
I0725 18:35:05.118016 20892 sgd_solver.cpp:106] Iteration 53900, lr = 3.75223e-06
I0725 18:35:14.437245 20892 solver.cpp:337] Iteration 54000, Testing net (#0)
I0725 18:35:25.702401 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:35:28.563258 20892 solver.cpp:404]     Test net output #0: accuracy = 0.822452
I0725 18:35:28.563297 20892 solver.cpp:404]     Test net output #1: loss = 0.392655 (* 1 = 0.392655 loss)
I0725 18:35:28.592852 20892 solver.cpp:228] Iteration 54000, loss = 0.32653
I0725 18:35:28.592906 20892 solver.cpp:244]     Train net output #0: loss = 0.32653 (* 1 = 0.32653 loss)
I0725 18:35:28.592944 20892 sgd_solver.cpp:106] Iteration 54000, lr = 3.74842e-06
I0725 18:35:37.966420 20892 solver.cpp:228] Iteration 54100, loss = 0.384011
I0725 18:35:37.966475 20892 solver.cpp:244]     Train net output #0: loss = 0.384011 (* 1 = 0.384011 loss)
I0725 18:35:37.966483 20892 sgd_solver.cpp:106] Iteration 54100, lr = 3.74463e-06
I0725 18:35:47.375861 20892 solver.cpp:228] Iteration 54200, loss = 0.31446
I0725 18:35:47.375933 20892 solver.cpp:244]     Train net output #0: loss = 0.31446 (* 1 = 0.31446 loss)
I0725 18:35:47.375942 20892 sgd_solver.cpp:106] Iteration 54200, lr = 3.74084e-06
I0725 18:35:56.777319 20892 solver.cpp:228] Iteration 54300, loss = 0.355732
I0725 18:35:56.777359 20892 solver.cpp:244]     Train net output #0: loss = 0.355732 (* 1 = 0.355732 loss)
I0725 18:35:56.777365 20892 sgd_solver.cpp:106] Iteration 54300, lr = 3.73707e-06
I0725 18:36:06.178403 20892 solver.cpp:228] Iteration 54400, loss = 0.419893
I0725 18:36:06.178454 20892 solver.cpp:244]     Train net output #0: loss = 0.419893 (* 1 = 0.419893 loss)
I0725 18:36:06.178462 20892 sgd_solver.cpp:106] Iteration 54400, lr = 3.7333e-06
I0725 18:36:15.488792 20892 solver.cpp:337] Iteration 54500, Testing net (#0)
I0725 18:36:29.545289 20892 solver.cpp:404]     Test net output #0: accuracy = 0.828194
I0725 18:36:29.545346 20892 solver.cpp:404]     Test net output #1: loss = 0.384214 (* 1 = 0.384214 loss)
I0725 18:36:29.571777 20892 solver.cpp:228] Iteration 54500, loss = 0.33006
I0725 18:36:29.571848 20892 solver.cpp:244]     Train net output #0: loss = 0.33006 (* 1 = 0.33006 loss)
I0725 18:36:29.571861 20892 sgd_solver.cpp:106] Iteration 54500, lr = 3.72954e-06
I0725 18:36:38.938314 20892 solver.cpp:228] Iteration 54600, loss = 0.322491
I0725 18:36:38.938374 20892 solver.cpp:244]     Train net output #0: loss = 0.322491 (* 1 = 0.322491 loss)
I0725 18:36:38.938385 20892 sgd_solver.cpp:106] Iteration 54600, lr = 3.72579e-06
I0725 18:36:48.346952 20892 solver.cpp:228] Iteration 54700, loss = 0.262262
I0725 18:36:48.346997 20892 solver.cpp:244]     Train net output #0: loss = 0.262262 (* 1 = 0.262262 loss)
I0725 18:36:48.347004 20892 sgd_solver.cpp:106] Iteration 54700, lr = 3.72205e-06
I0725 18:36:57.754875 20892 solver.cpp:228] Iteration 54800, loss = 0.347272
I0725 18:36:57.754930 20892 solver.cpp:244]     Train net output #0: loss = 0.347272 (* 1 = 0.347272 loss)
I0725 18:36:57.754938 20892 sgd_solver.cpp:106] Iteration 54800, lr = 3.71832e-06
I0725 18:37:07.167872 20892 solver.cpp:228] Iteration 54900, loss = 0.315922
I0725 18:37:07.167924 20892 solver.cpp:244]     Train net output #0: loss = 0.315922 (* 1 = 0.315922 loss)
I0725 18:37:07.167932 20892 sgd_solver.cpp:106] Iteration 54900, lr = 3.71459e-06
I0725 18:37:16.484442 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_55000.caffemodel
I0725 18:37:16.837458 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_55000.solverstate
I0725 18:37:16.936944 20892 solver.cpp:337] Iteration 55000, Testing net (#0)
I0725 18:37:30.915897 20892 solver.cpp:404]     Test net output #0: accuracy = 0.82842
I0725 18:37:30.915973 20892 solver.cpp:404]     Test net output #1: loss = 0.383463 (* 1 = 0.383463 loss)
I0725 18:37:30.949821 20892 solver.cpp:228] Iteration 55000, loss = 0.365162
I0725 18:37:30.949882 20892 solver.cpp:244]     Train net output #0: loss = 0.365162 (* 1 = 0.365162 loss)
I0725 18:37:30.949908 20892 sgd_solver.cpp:106] Iteration 55000, lr = 3.71088e-06
I0725 18:37:40.287592 20892 solver.cpp:228] Iteration 55100, loss = 0.350101
I0725 18:37:40.287634 20892 solver.cpp:244]     Train net output #0: loss = 0.350101 (* 1 = 0.350101 loss)
I0725 18:37:40.287641 20892 sgd_solver.cpp:106] Iteration 55100, lr = 3.70717e-06
I0725 18:37:49.699611 20892 solver.cpp:228] Iteration 55200, loss = 0.349993
I0725 18:37:49.699677 20892 solver.cpp:244]     Train net output #0: loss = 0.349993 (* 1 = 0.349993 loss)
I0725 18:37:49.699687 20892 sgd_solver.cpp:106] Iteration 55200, lr = 3.70347e-06
I0725 18:37:59.112177 20892 solver.cpp:228] Iteration 55300, loss = 0.362721
I0725 18:37:59.112241 20892 solver.cpp:244]     Train net output #0: loss = 0.362721 (* 1 = 0.362721 loss)
I0725 18:37:59.112251 20892 sgd_solver.cpp:106] Iteration 55300, lr = 3.69978e-06
I0725 18:38:08.525332 20892 solver.cpp:228] Iteration 55400, loss = 0.261029
I0725 18:38:08.525373 20892 solver.cpp:244]     Train net output #0: loss = 0.261029 (* 1 = 0.261029 loss)
I0725 18:38:08.525380 20892 sgd_solver.cpp:106] Iteration 55400, lr = 3.6961e-06
I0725 18:38:17.839649 20892 solver.cpp:337] Iteration 55500, Testing net (#0)
I0725 18:38:31.786209 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:38:32.014444 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829581
I0725 18:38:32.014500 20892 solver.cpp:404]     Test net output #1: loss = 0.380745 (* 1 = 0.380745 loss)
I0725 18:38:32.042855 20892 solver.cpp:228] Iteration 55500, loss = 0.323501
I0725 18:38:32.042899 20892 solver.cpp:244]     Train net output #0: loss = 0.323501 (* 1 = 0.323501 loss)
I0725 18:38:32.042911 20892 sgd_solver.cpp:106] Iteration 55500, lr = 3.69243e-06
I0725 18:38:41.405638 20892 solver.cpp:228] Iteration 55600, loss = 0.454887
I0725 18:38:41.405692 20892 solver.cpp:244]     Train net output #0: loss = 0.454887 (* 1 = 0.454887 loss)
I0725 18:38:41.405700 20892 sgd_solver.cpp:106] Iteration 55600, lr = 3.68877e-06
I0725 18:38:50.810833 20892 solver.cpp:228] Iteration 55700, loss = 0.296322
I0725 18:38:50.810881 20892 solver.cpp:244]     Train net output #0: loss = 0.296322 (* 1 = 0.296322 loss)
I0725 18:38:50.810889 20892 sgd_solver.cpp:106] Iteration 55700, lr = 3.68511e-06
I0725 18:39:00.216127 20892 solver.cpp:228] Iteration 55800, loss = 0.570217
I0725 18:39:00.216186 20892 solver.cpp:244]     Train net output #0: loss = 0.570217 (* 1 = 0.570217 loss)
I0725 18:39:00.216194 20892 sgd_solver.cpp:106] Iteration 55800, lr = 3.68146e-06
I0725 18:39:09.618474 20892 solver.cpp:228] Iteration 55900, loss = 0.339741
I0725 18:39:09.618542 20892 solver.cpp:244]     Train net output #0: loss = 0.339741 (* 1 = 0.339741 loss)
I0725 18:39:09.618551 20892 sgd_solver.cpp:106] Iteration 55900, lr = 3.67783e-06
I0725 18:39:18.918943 20892 solver.cpp:337] Iteration 56000, Testing net (#0)
I0725 18:39:32.950471 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826871
I0725 18:39:32.950527 20892 solver.cpp:404]     Test net output #1: loss = 0.38614 (* 1 = 0.38614 loss)
I0725 18:39:32.979899 20892 solver.cpp:228] Iteration 56000, loss = 0.353786
I0725 18:39:32.979948 20892 solver.cpp:244]     Train net output #0: loss = 0.353786 (* 1 = 0.353786 loss)
I0725 18:39:32.979959 20892 sgd_solver.cpp:106] Iteration 56000, lr = 3.6742e-06
I0725 18:39:42.347391 20892 solver.cpp:228] Iteration 56100, loss = 0.306134
I0725 18:39:42.347450 20892 solver.cpp:244]     Train net output #0: loss = 0.306134 (* 1 = 0.306134 loss)
I0725 18:39:42.347456 20892 sgd_solver.cpp:106] Iteration 56100, lr = 3.67057e-06
I0725 18:39:51.758340 20892 solver.cpp:228] Iteration 56200, loss = 0.252241
I0725 18:39:51.758402 20892 solver.cpp:244]     Train net output #0: loss = 0.252241 (* 1 = 0.252241 loss)
I0725 18:39:51.758410 20892 sgd_solver.cpp:106] Iteration 56200, lr = 3.66696e-06
I0725 18:40:01.165349 20892 solver.cpp:228] Iteration 56300, loss = 0.288791
I0725 18:40:01.165405 20892 solver.cpp:244]     Train net output #0: loss = 0.288791 (* 1 = 0.288791 loss)
I0725 18:40:01.165412 20892 sgd_solver.cpp:106] Iteration 56300, lr = 3.66336e-06
I0725 18:40:10.565037 20892 solver.cpp:228] Iteration 56400, loss = 0.277052
I0725 18:40:10.565093 20892 solver.cpp:244]     Train net output #0: loss = 0.277052 (* 1 = 0.277052 loss)
I0725 18:40:10.565102 20892 sgd_solver.cpp:106] Iteration 56400, lr = 3.65976e-06
I0725 18:40:19.876909 20892 solver.cpp:337] Iteration 56500, Testing net (#0)
I0725 18:40:33.950923 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829678
I0725 18:40:33.950970 20892 solver.cpp:404]     Test net output #1: loss = 0.380819 (* 1 = 0.380819 loss)
I0725 18:40:33.979923 20892 solver.cpp:228] Iteration 56500, loss = 0.288306
I0725 18:40:33.979969 20892 solver.cpp:244]     Train net output #0: loss = 0.288306 (* 1 = 0.288306 loss)
I0725 18:40:33.979980 20892 sgd_solver.cpp:106] Iteration 56500, lr = 3.65617e-06
I0725 18:40:43.352349 20892 solver.cpp:228] Iteration 56600, loss = 0.308932
I0725 18:40:43.352401 20892 solver.cpp:244]     Train net output #0: loss = 0.308932 (* 1 = 0.308932 loss)
I0725 18:40:43.352407 20892 sgd_solver.cpp:106] Iteration 56600, lr = 3.65259e-06
I0725 18:40:52.766088 20892 solver.cpp:228] Iteration 56700, loss = 0.288874
I0725 18:40:52.766134 20892 solver.cpp:244]     Train net output #0: loss = 0.288874 (* 1 = 0.288874 loss)
I0725 18:40:52.766140 20892 sgd_solver.cpp:106] Iteration 56700, lr = 3.64902e-06
I0725 18:41:02.186573 20892 solver.cpp:228] Iteration 56800, loss = 0.278936
I0725 18:41:02.186631 20892 solver.cpp:244]     Train net output #0: loss = 0.278936 (* 1 = 0.278936 loss)
I0725 18:41:02.186640 20892 sgd_solver.cpp:106] Iteration 56800, lr = 3.64545e-06
I0725 18:41:11.598136 20892 solver.cpp:228] Iteration 56900, loss = 0.41779
I0725 18:41:11.598197 20892 solver.cpp:244]     Train net output #0: loss = 0.41779 (* 1 = 0.41779 loss)
I0725 18:41:11.598204 20892 sgd_solver.cpp:106] Iteration 56900, lr = 3.6419e-06
I0725 18:41:20.915323 20892 solver.cpp:337] Iteration 57000, Testing net (#0)
I0725 18:41:35.009783 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829387
I0725 18:41:35.009840 20892 solver.cpp:404]     Test net output #1: loss = 0.381893 (* 1 = 0.381893 loss)
I0725 18:41:35.038909 20892 solver.cpp:228] Iteration 57000, loss = 0.316543
I0725 18:41:35.038955 20892 solver.cpp:244]     Train net output #0: loss = 0.316543 (* 1 = 0.316543 loss)
I0725 18:41:35.038965 20892 sgd_solver.cpp:106] Iteration 57000, lr = 3.63835e-06
I0725 18:41:44.368697 20892 solver.cpp:228] Iteration 57100, loss = 0.338666
I0725 18:41:44.368758 20892 solver.cpp:244]     Train net output #0: loss = 0.338666 (* 1 = 0.338666 loss)
I0725 18:41:44.368764 20892 sgd_solver.cpp:106] Iteration 57100, lr = 3.63481e-06
I0725 18:41:53.770586 20892 solver.cpp:228] Iteration 57200, loss = 0.299299
I0725 18:41:53.770644 20892 solver.cpp:244]     Train net output #0: loss = 0.299299 (* 1 = 0.299299 loss)
I0725 18:41:53.770651 20892 sgd_solver.cpp:106] Iteration 57200, lr = 3.63128e-06
I0725 18:42:03.172971 20892 solver.cpp:228] Iteration 57300, loss = 0.425042
I0725 18:42:03.173017 20892 solver.cpp:244]     Train net output #0: loss = 0.425042 (* 1 = 0.425042 loss)
I0725 18:42:03.173022 20892 sgd_solver.cpp:106] Iteration 57300, lr = 3.62775e-06
I0725 18:42:05.054100 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:42:12.575630 20892 solver.cpp:228] Iteration 57400, loss = 0.361248
I0725 18:42:12.575673 20892 solver.cpp:244]     Train net output #0: loss = 0.361248 (* 1 = 0.361248 loss)
I0725 18:42:12.575680 20892 sgd_solver.cpp:106] Iteration 57400, lr = 3.62424e-06
I0725 18:42:21.882984 20892 solver.cpp:337] Iteration 57500, Testing net (#0)
I0725 18:42:35.901273 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827613
I0725 18:42:35.901319 20892 solver.cpp:404]     Test net output #1: loss = 0.385129 (* 1 = 0.385129 loss)
I0725 18:42:35.930637 20892 solver.cpp:228] Iteration 57500, loss = 0.273747
I0725 18:42:35.930690 20892 solver.cpp:244]     Train net output #0: loss = 0.273747 (* 1 = 0.273747 loss)
I0725 18:42:35.930701 20892 sgd_solver.cpp:106] Iteration 57500, lr = 3.62073e-06
I0725 18:42:45.261710 20892 solver.cpp:228] Iteration 57600, loss = 0.429949
I0725 18:42:45.261760 20892 solver.cpp:244]     Train net output #0: loss = 0.429949 (* 1 = 0.429949 loss)
I0725 18:42:45.261767 20892 sgd_solver.cpp:106] Iteration 57600, lr = 3.61723e-06
I0725 18:42:54.671568 20892 solver.cpp:228] Iteration 57700, loss = 0.269703
I0725 18:42:54.671623 20892 solver.cpp:244]     Train net output #0: loss = 0.269703 (* 1 = 0.269703 loss)
I0725 18:42:54.671629 20892 sgd_solver.cpp:106] Iteration 57700, lr = 3.61374e-06
I0725 18:43:04.076597 20892 solver.cpp:228] Iteration 57800, loss = 0.379829
I0725 18:43:04.076653 20892 solver.cpp:244]     Train net output #0: loss = 0.379829 (* 1 = 0.379829 loss)
I0725 18:43:04.076660 20892 sgd_solver.cpp:106] Iteration 57800, lr = 3.61025e-06
I0725 18:43:13.481058 20892 solver.cpp:228] Iteration 57900, loss = 0.27307
I0725 18:43:13.481119 20892 solver.cpp:244]     Train net output #0: loss = 0.27307 (* 1 = 0.27307 loss)
I0725 18:43:13.481127 20892 sgd_solver.cpp:106] Iteration 57900, lr = 3.60678e-06
I0725 18:43:22.791328 20892 solver.cpp:337] Iteration 58000, Testing net (#0)
I0725 18:43:36.903791 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829
I0725 18:43:36.903856 20892 solver.cpp:404]     Test net output #1: loss = 0.382562 (* 1 = 0.382562 loss)
I0725 18:43:36.933259 20892 solver.cpp:228] Iteration 58000, loss = 0.298496
I0725 18:43:36.933305 20892 solver.cpp:244]     Train net output #0: loss = 0.298496 (* 1 = 0.298496 loss)
I0725 18:43:36.933315 20892 sgd_solver.cpp:106] Iteration 58000, lr = 3.60331e-06
I0725 18:43:46.340585 20892 solver.cpp:228] Iteration 58100, loss = 0.354297
I0725 18:43:46.340631 20892 solver.cpp:244]     Train net output #0: loss = 0.354297 (* 1 = 0.354297 loss)
I0725 18:43:46.340637 20892 sgd_solver.cpp:106] Iteration 58100, lr = 3.59985e-06
I0725 18:43:55.758312 20892 solver.cpp:228] Iteration 58200, loss = 0.314004
I0725 18:43:55.758369 20892 solver.cpp:244]     Train net output #0: loss = 0.314004 (* 1 = 0.314004 loss)
I0725 18:43:55.758375 20892 sgd_solver.cpp:106] Iteration 58200, lr = 3.5964e-06
I0725 18:44:05.169004 20892 solver.cpp:228] Iteration 58300, loss = 0.305363
I0725 18:44:05.169050 20892 solver.cpp:244]     Train net output #0: loss = 0.305363 (* 1 = 0.305363 loss)
I0725 18:44:05.169056 20892 sgd_solver.cpp:106] Iteration 58300, lr = 3.59295e-06
I0725 18:44:14.582628 20892 solver.cpp:228] Iteration 58400, loss = 0.3055
I0725 18:44:14.582669 20892 solver.cpp:244]     Train net output #0: loss = 0.3055 (* 1 = 0.3055 loss)
I0725 18:44:14.582675 20892 sgd_solver.cpp:106] Iteration 58400, lr = 3.58951e-06
I0725 18:44:23.900822 20892 solver.cpp:337] Iteration 58500, Testing net (#0)
I0725 18:44:37.801770 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:44:38.018625 20892 solver.cpp:404]     Test net output #0: accuracy = 0.83
I0725 18:44:38.018652 20892 solver.cpp:404]     Test net output #1: loss = 0.380511 (* 1 = 0.380511 loss)
I0725 18:44:38.047284 20892 solver.cpp:228] Iteration 58500, loss = 0.27545
I0725 18:44:38.047329 20892 solver.cpp:244]     Train net output #0: loss = 0.27545 (* 1 = 0.27545 loss)
I0725 18:44:38.047340 20892 sgd_solver.cpp:106] Iteration 58500, lr = 3.58608e-06
I0725 18:44:47.281131 20892 solver.cpp:228] Iteration 58600, loss = 0.426918
I0725 18:44:47.281190 20892 solver.cpp:244]     Train net output #0: loss = 0.426918 (* 1 = 0.426918 loss)
I0725 18:44:47.281198 20892 sgd_solver.cpp:106] Iteration 58600, lr = 3.58266e-06
I0725 18:44:56.681056 20892 solver.cpp:228] Iteration 58700, loss = 0.366958
I0725 18:44:56.681112 20892 solver.cpp:244]     Train net output #0: loss = 0.366958 (* 1 = 0.366958 loss)
I0725 18:44:56.681118 20892 sgd_solver.cpp:106] Iteration 58700, lr = 3.57925e-06
I0725 18:45:06.143396 20892 solver.cpp:228] Iteration 58800, loss = 0.312395
I0725 18:45:06.143456 20892 solver.cpp:244]     Train net output #0: loss = 0.312395 (* 1 = 0.312395 loss)
I0725 18:45:06.143463 20892 sgd_solver.cpp:106] Iteration 58800, lr = 3.57584e-06
I0725 18:45:15.567313 20892 solver.cpp:228] Iteration 58900, loss = 0.272756
I0725 18:45:15.567361 20892 solver.cpp:244]     Train net output #0: loss = 0.272756 (* 1 = 0.272756 loss)
I0725 18:45:15.567368 20892 sgd_solver.cpp:106] Iteration 58900, lr = 3.57244e-06
I0725 18:45:24.873996 20892 solver.cpp:337] Iteration 59000, Testing net (#0)
I0725 18:45:38.821439 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829646
I0725 18:45:38.821496 20892 solver.cpp:404]     Test net output #1: loss = 0.381166 (* 1 = 0.381166 loss)
I0725 18:45:38.850522 20892 solver.cpp:228] Iteration 59000, loss = 0.321049
I0725 18:45:38.850558 20892 solver.cpp:244]     Train net output #0: loss = 0.321049 (* 1 = 0.321049 loss)
I0725 18:45:38.850570 20892 sgd_solver.cpp:106] Iteration 59000, lr = 3.56905e-06
I0725 18:45:48.217507 20892 solver.cpp:228] Iteration 59100, loss = 0.332764
I0725 18:45:48.217556 20892 solver.cpp:244]     Train net output #0: loss = 0.332764 (* 1 = 0.332764 loss)
I0725 18:45:48.217562 20892 sgd_solver.cpp:106] Iteration 59100, lr = 3.56566e-06
I0725 18:45:57.622285 20892 solver.cpp:228] Iteration 59200, loss = 0.303485
I0725 18:45:57.622347 20892 solver.cpp:244]     Train net output #0: loss = 0.303485 (* 1 = 0.303485 loss)
I0725 18:45:57.622355 20892 sgd_solver.cpp:106] Iteration 59200, lr = 3.56228e-06
I0725 18:46:07.023674 20892 solver.cpp:228] Iteration 59300, loss = 0.468027
I0725 18:46:07.023744 20892 solver.cpp:244]     Train net output #0: loss = 0.468027 (* 1 = 0.468027 loss)
I0725 18:46:07.023752 20892 sgd_solver.cpp:106] Iteration 59300, lr = 3.55891e-06
I0725 18:46:16.431923 20892 solver.cpp:228] Iteration 59400, loss = 0.415028
I0725 18:46:16.431964 20892 solver.cpp:244]     Train net output #0: loss = 0.415028 (* 1 = 0.415028 loss)
I0725 18:46:16.431970 20892 sgd_solver.cpp:106] Iteration 59400, lr = 3.55555e-06
I0725 18:46:25.744460 20892 solver.cpp:337] Iteration 59500, Testing net (#0)
I0725 18:46:39.906054 20892 solver.cpp:404]     Test net output #0: accuracy = 0.822678
I0725 18:46:39.906116 20892 solver.cpp:404]     Test net output #1: loss = 0.392012 (* 1 = 0.392012 loss)
I0725 18:46:39.935340 20892 solver.cpp:228] Iteration 59500, loss = 0.313358
I0725 18:46:39.935415 20892 solver.cpp:244]     Train net output #0: loss = 0.313358 (* 1 = 0.313358 loss)
I0725 18:46:39.935439 20892 sgd_solver.cpp:106] Iteration 59500, lr = 3.5522e-06
I0725 18:46:49.319249 20892 solver.cpp:228] Iteration 59600, loss = 0.288408
I0725 18:46:49.319294 20892 solver.cpp:244]     Train net output #0: loss = 0.288408 (* 1 = 0.288408 loss)
I0725 18:46:49.319300 20892 sgd_solver.cpp:106] Iteration 59600, lr = 3.54885e-06
I0725 18:46:58.822999 20892 solver.cpp:228] Iteration 59700, loss = 0.318031
I0725 18:46:58.823051 20892 solver.cpp:244]     Train net output #0: loss = 0.318031 (* 1 = 0.318031 loss)
I0725 18:46:58.823060 20892 sgd_solver.cpp:106] Iteration 59700, lr = 3.54551e-06
I0725 18:47:08.233732 20892 solver.cpp:228] Iteration 59800, loss = 0.434148
I0725 18:47:08.233772 20892 solver.cpp:244]     Train net output #0: loss = 0.434148 (* 1 = 0.434148 loss)
I0725 18:47:08.233779 20892 sgd_solver.cpp:106] Iteration 59800, lr = 3.54218e-06
I0725 18:47:17.642489 20892 solver.cpp:228] Iteration 59900, loss = 0.369962
I0725 18:47:17.642534 20892 solver.cpp:244]     Train net output #0: loss = 0.369962 (* 1 = 0.369962 loss)
I0725 18:47:17.642541 20892 sgd_solver.cpp:106] Iteration 59900, lr = 3.53885e-06
I0725 18:47:26.936764 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_60000.caffemodel
I0725 18:47:27.355038 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_60000.solverstate
I0725 18:47:27.508118 20892 solver.cpp:337] Iteration 60000, Testing net (#0)
I0725 18:47:41.297080 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829645
I0725 18:47:41.297124 20892 solver.cpp:404]     Test net output #1: loss = 0.381544 (* 1 = 0.381544 loss)
I0725 18:47:41.324069 20892 solver.cpp:228] Iteration 60000, loss = 0.357441
I0725 18:47:41.324134 20892 solver.cpp:244]     Train net output #0: loss = 0.357441 (* 1 = 0.357441 loss)
I0725 18:47:41.324156 20892 sgd_solver.cpp:106] Iteration 60000, lr = 3.53553e-06
I0725 18:47:50.725426 20892 solver.cpp:228] Iteration 60100, loss = 0.278279
I0725 18:47:50.725502 20892 solver.cpp:244]     Train net output #0: loss = 0.278279 (* 1 = 0.278279 loss)
I0725 18:47:50.725515 20892 sgd_solver.cpp:106] Iteration 60100, lr = 3.53222e-06
I0725 18:48:00.129427 20892 solver.cpp:228] Iteration 60200, loss = 0.402416
I0725 18:48:00.129467 20892 solver.cpp:244]     Train net output #0: loss = 0.402416 (* 1 = 0.402416 loss)
I0725 18:48:00.129473 20892 sgd_solver.cpp:106] Iteration 60200, lr = 3.52892e-06
I0725 18:48:09.539227 20892 solver.cpp:228] Iteration 60300, loss = 0.257095
I0725 18:48:09.539265 20892 solver.cpp:244]     Train net output #0: loss = 0.257095 (* 1 = 0.257095 loss)
I0725 18:48:09.539273 20892 sgd_solver.cpp:106] Iteration 60300, lr = 3.52562e-06
I0725 18:48:12.832495 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:48:18.945111 20892 solver.cpp:228] Iteration 60400, loss = 0.278222
I0725 18:48:18.945168 20892 solver.cpp:244]     Train net output #0: loss = 0.278222 (* 1 = 0.278222 loss)
I0725 18:48:18.945175 20892 sgd_solver.cpp:106] Iteration 60400, lr = 3.52233e-06
I0725 18:48:28.255336 20892 solver.cpp:337] Iteration 60500, Testing net (#0)
I0725 18:48:42.303575 20892 solver.cpp:404]     Test net output #0: accuracy = 0.83
I0725 18:48:42.303619 20892 solver.cpp:404]     Test net output #1: loss = 0.379897 (* 1 = 0.379897 loss)
I0725 18:48:42.332975 20892 solver.cpp:228] Iteration 60500, loss = 0.246368
I0725 18:48:42.333034 20892 solver.cpp:244]     Train net output #0: loss = 0.246368 (* 1 = 0.246368 loss)
I0725 18:48:42.333045 20892 sgd_solver.cpp:106] Iteration 60500, lr = 3.51905e-06
I0725 18:48:51.739744 20892 solver.cpp:228] Iteration 60600, loss = 0.281283
I0725 18:48:51.739800 20892 solver.cpp:244]     Train net output #0: loss = 0.281283 (* 1 = 0.281283 loss)
I0725 18:48:51.739809 20892 sgd_solver.cpp:106] Iteration 60600, lr = 3.51578e-06
I0725 18:49:01.148334 20892 solver.cpp:228] Iteration 60700, loss = 0.291838
I0725 18:49:01.148391 20892 solver.cpp:244]     Train net output #0: loss = 0.291838 (* 1 = 0.291838 loss)
I0725 18:49:01.148397 20892 sgd_solver.cpp:106] Iteration 60700, lr = 3.51251e-06
I0725 18:49:10.561362 20892 solver.cpp:228] Iteration 60800, loss = 0.33683
I0725 18:49:10.561410 20892 solver.cpp:244]     Train net output #0: loss = 0.33683 (* 1 = 0.33683 loss)
I0725 18:49:10.561419 20892 sgd_solver.cpp:106] Iteration 60800, lr = 3.50925e-06
I0725 18:49:19.973790 20892 solver.cpp:228] Iteration 60900, loss = 0.267648
I0725 18:49:19.973829 20892 solver.cpp:244]     Train net output #0: loss = 0.267648 (* 1 = 0.267648 loss)
I0725 18:49:19.973834 20892 sgd_solver.cpp:106] Iteration 60900, lr = 3.50599e-06
I0725 18:49:29.293742 20892 solver.cpp:337] Iteration 61000, Testing net (#0)
I0725 18:49:43.437927 20892 solver.cpp:404]     Test net output #0: accuracy = 0.82971
I0725 18:49:43.437980 20892 solver.cpp:404]     Test net output #1: loss = 0.380752 (* 1 = 0.380752 loss)
I0725 18:49:43.467114 20892 solver.cpp:228] Iteration 61000, loss = 0.323643
I0725 18:49:43.467141 20892 solver.cpp:244]     Train net output #0: loss = 0.323643 (* 1 = 0.323643 loss)
I0725 18:49:43.467151 20892 sgd_solver.cpp:106] Iteration 61000, lr = 3.50275e-06
I0725 18:49:52.758185 20892 solver.cpp:228] Iteration 61100, loss = 0.394483
I0725 18:49:52.758226 20892 solver.cpp:244]     Train net output #0: loss = 0.394483 (* 1 = 0.394483 loss)
I0725 18:49:52.758232 20892 sgd_solver.cpp:106] Iteration 61100, lr = 3.49951e-06
I0725 18:50:02.167670 20892 solver.cpp:228] Iteration 61200, loss = 0.413527
I0725 18:50:02.167713 20892 solver.cpp:244]     Train net output #0: loss = 0.413527 (* 1 = 0.413527 loss)
I0725 18:50:02.167718 20892 sgd_solver.cpp:106] Iteration 61200, lr = 3.49627e-06
I0725 18:50:11.578038 20892 solver.cpp:228] Iteration 61300, loss = 0.325747
I0725 18:50:11.578085 20892 solver.cpp:244]     Train net output #0: loss = 0.325747 (* 1 = 0.325747 loss)
I0725 18:50:11.578091 20892 sgd_solver.cpp:106] Iteration 61300, lr = 3.49305e-06
I0725 18:50:20.990803 20892 solver.cpp:228] Iteration 61400, loss = 0.377769
I0725 18:50:20.990847 20892 solver.cpp:244]     Train net output #0: loss = 0.377769 (* 1 = 0.377769 loss)
I0725 18:50:20.990854 20892 sgd_solver.cpp:106] Iteration 61400, lr = 3.48983e-06
I0725 18:50:30.312327 20892 solver.cpp:337] Iteration 61500, Testing net (#0)
I0725 18:50:44.477319 20892 solver.cpp:404]     Test net output #0: accuracy = 0.825355
I0725 18:50:44.477370 20892 solver.cpp:404]     Test net output #1: loss = 0.387523 (* 1 = 0.387523 loss)
I0725 18:50:44.506556 20892 solver.cpp:228] Iteration 61500, loss = 0.379727
I0725 18:50:44.506623 20892 solver.cpp:244]     Train net output #0: loss = 0.379727 (* 1 = 0.379727 loss)
I0725 18:50:44.506635 20892 sgd_solver.cpp:106] Iteration 61500, lr = 3.48662e-06
I0725 18:50:53.824718 20892 solver.cpp:228] Iteration 61600, loss = 0.309652
I0725 18:50:53.824764 20892 solver.cpp:244]     Train net output #0: loss = 0.309652 (* 1 = 0.309652 loss)
I0725 18:50:53.824770 20892 sgd_solver.cpp:106] Iteration 61600, lr = 3.48341e-06
I0725 18:51:03.228859 20892 solver.cpp:228] Iteration 61700, loss = 0.24237
I0725 18:51:03.228899 20892 solver.cpp:244]     Train net output #0: loss = 0.24237 (* 1 = 0.24237 loss)
I0725 18:51:03.228904 20892 sgd_solver.cpp:106] Iteration 61700, lr = 3.48021e-06
I0725 18:51:12.630650 20892 solver.cpp:228] Iteration 61800, loss = 0.352746
I0725 18:51:12.630689 20892 solver.cpp:244]     Train net output #0: loss = 0.352746 (* 1 = 0.352746 loss)
I0725 18:51:12.630695 20892 sgd_solver.cpp:106] Iteration 61800, lr = 3.47702e-06
I0725 18:51:22.038388 20892 solver.cpp:228] Iteration 61900, loss = 0.304506
I0725 18:51:22.038442 20892 solver.cpp:244]     Train net output #0: loss = 0.304506 (* 1 = 0.304506 loss)
I0725 18:51:22.038450 20892 sgd_solver.cpp:106] Iteration 61900, lr = 3.47384e-06
I0725 18:51:27.870369 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:51:31.353094 20892 solver.cpp:337] Iteration 62000, Testing net (#0)
I0725 18:51:45.510537 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830387
I0725 18:51:45.510603 20892 solver.cpp:404]     Test net output #1: loss = 0.380012 (* 1 = 0.380012 loss)
I0725 18:51:45.537204 20892 solver.cpp:228] Iteration 62000, loss = 0.334002
I0725 18:51:45.537281 20892 solver.cpp:244]     Train net output #0: loss = 0.334002 (* 1 = 0.334002 loss)
I0725 18:51:45.537295 20892 sgd_solver.cpp:106] Iteration 62000, lr = 3.47066e-06
I0725 18:51:54.844271 20892 solver.cpp:228] Iteration 62100, loss = 0.268937
I0725 18:51:54.844338 20892 solver.cpp:244]     Train net output #0: loss = 0.268937 (* 1 = 0.268937 loss)
I0725 18:51:54.844347 20892 sgd_solver.cpp:106] Iteration 62100, lr = 3.46749e-06
I0725 18:52:04.244704 20892 solver.cpp:228] Iteration 62200, loss = 0.34639
I0725 18:52:04.244760 20892 solver.cpp:244]     Train net output #0: loss = 0.34639 (* 1 = 0.34639 loss)
I0725 18:52:04.244768 20892 sgd_solver.cpp:106] Iteration 62200, lr = 3.46433e-06
I0725 18:52:13.650607 20892 solver.cpp:228] Iteration 62300, loss = 0.287517
I0725 18:52:13.650658 20892 solver.cpp:244]     Train net output #0: loss = 0.287517 (* 1 = 0.287517 loss)
I0725 18:52:13.650666 20892 sgd_solver.cpp:106] Iteration 62300, lr = 3.46117e-06
I0725 18:52:23.060838 20892 solver.cpp:228] Iteration 62400, loss = 0.420853
I0725 18:52:23.060896 20892 solver.cpp:244]     Train net output #0: loss = 0.420853 (* 1 = 0.420853 loss)
I0725 18:52:23.060904 20892 sgd_solver.cpp:106] Iteration 62400, lr = 3.45802e-06
I0725 18:52:32.372771 20892 solver.cpp:337] Iteration 62500, Testing net (#0)
I0725 18:52:46.547345 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830129
I0725 18:52:46.547401 20892 solver.cpp:404]     Test net output #1: loss = 0.379259 (* 1 = 0.379259 loss)
I0725 18:52:46.576674 20892 solver.cpp:228] Iteration 62500, loss = 0.359125
I0725 18:52:46.576707 20892 solver.cpp:244]     Train net output #0: loss = 0.359125 (* 1 = 0.359125 loss)
I0725 18:52:46.576726 20892 sgd_solver.cpp:106] Iteration 62500, lr = 3.45487e-06
I0725 18:52:55.961640 20892 solver.cpp:228] Iteration 62600, loss = 0.30402
I0725 18:52:55.961696 20892 solver.cpp:244]     Train net output #0: loss = 0.30402 (* 1 = 0.30402 loss)
I0725 18:52:55.961704 20892 sgd_solver.cpp:106] Iteration 62600, lr = 3.45173e-06
I0725 18:53:05.369299 20892 solver.cpp:228] Iteration 62700, loss = 0.273779
I0725 18:53:05.369349 20892 solver.cpp:244]     Train net output #0: loss = 0.273779 (* 1 = 0.273779 loss)
I0725 18:53:05.369357 20892 sgd_solver.cpp:106] Iteration 62700, lr = 3.4486e-06
I0725 18:53:14.785850 20892 solver.cpp:228] Iteration 62800, loss = 0.305883
I0725 18:53:14.785922 20892 solver.cpp:244]     Train net output #0: loss = 0.305883 (* 1 = 0.305883 loss)
I0725 18:53:14.785930 20892 sgd_solver.cpp:106] Iteration 62800, lr = 3.44548e-06
I0725 18:53:24.193151 20892 solver.cpp:228] Iteration 62900, loss = 0.377886
I0725 18:53:24.193189 20892 solver.cpp:244]     Train net output #0: loss = 0.377886 (* 1 = 0.377886 loss)
I0725 18:53:24.193197 20892 sgd_solver.cpp:106] Iteration 62900, lr = 3.44236e-06
I0725 18:53:33.509384 20892 solver.cpp:337] Iteration 63000, Testing net (#0)
I0725 18:53:47.558789 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832032
I0725 18:53:47.558835 20892 solver.cpp:404]     Test net output #1: loss = 0.376681 (* 1 = 0.376681 loss)
I0725 18:53:47.587801 20892 solver.cpp:228] Iteration 63000, loss = 0.447816
I0725 18:53:47.587846 20892 solver.cpp:244]     Train net output #0: loss = 0.447816 (* 1 = 0.447816 loss)
I0725 18:53:47.587857 20892 sgd_solver.cpp:106] Iteration 63000, lr = 3.43925e-06
I0725 18:53:56.951895 20892 solver.cpp:228] Iteration 63100, loss = 0.310531
I0725 18:53:56.951936 20892 solver.cpp:244]     Train net output #0: loss = 0.310531 (* 1 = 0.310531 loss)
I0725 18:53:56.951942 20892 sgd_solver.cpp:106] Iteration 63100, lr = 3.43615e-06
I0725 18:54:06.367970 20892 solver.cpp:228] Iteration 63200, loss = 0.372075
I0725 18:54:06.368016 20892 solver.cpp:244]     Train net output #0: loss = 0.372075 (* 1 = 0.372075 loss)
I0725 18:54:06.368024 20892 sgd_solver.cpp:106] Iteration 63200, lr = 3.43305e-06
I0725 18:54:15.785606 20892 solver.cpp:228] Iteration 63300, loss = 0.364562
I0725 18:54:15.785651 20892 solver.cpp:244]     Train net output #0: loss = 0.364562 (* 1 = 0.364562 loss)
I0725 18:54:15.785660 20892 sgd_solver.cpp:106] Iteration 63300, lr = 3.42996e-06
I0725 18:54:25.204231 20892 solver.cpp:228] Iteration 63400, loss = 0.374212
I0725 18:54:25.204267 20892 solver.cpp:244]     Train net output #0: loss = 0.374212 (* 1 = 0.374212 loss)
I0725 18:54:25.204272 20892 sgd_solver.cpp:106] Iteration 63400, lr = 3.42687e-06
I0725 18:54:34.522608 20892 solver.cpp:337] Iteration 63500, Testing net (#0)
I0725 18:54:37.317790 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:54:48.601119 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829226
I0725 18:54:48.601173 20892 solver.cpp:404]     Test net output #1: loss = 0.381933 (* 1 = 0.381933 loss)
I0725 18:54:48.632632 20892 solver.cpp:228] Iteration 63500, loss = 0.271301
I0725 18:54:48.632699 20892 solver.cpp:244]     Train net output #0: loss = 0.271301 (* 1 = 0.271301 loss)
I0725 18:54:48.632716 20892 sgd_solver.cpp:106] Iteration 63500, lr = 3.42379e-06
I0725 18:54:57.988621 20892 solver.cpp:228] Iteration 63600, loss = 0.387008
I0725 18:54:57.988674 20892 solver.cpp:244]     Train net output #0: loss = 0.387008 (* 1 = 0.387008 loss)
I0725 18:54:57.988682 20892 sgd_solver.cpp:106] Iteration 63600, lr = 3.42072e-06
I0725 18:55:07.395608 20892 solver.cpp:228] Iteration 63700, loss = 0.400196
I0725 18:55:07.395656 20892 solver.cpp:244]     Train net output #0: loss = 0.400196 (* 1 = 0.400196 loss)
I0725 18:55:07.395663 20892 sgd_solver.cpp:106] Iteration 63700, lr = 3.41766e-06
I0725 18:55:16.803907 20892 solver.cpp:228] Iteration 63800, loss = 0.346604
I0725 18:55:16.803957 20892 solver.cpp:244]     Train net output #0: loss = 0.346604 (* 1 = 0.346604 loss)
I0725 18:55:16.803967 20892 sgd_solver.cpp:106] Iteration 63800, lr = 3.4146e-06
I0725 18:55:26.351492 20892 solver.cpp:228] Iteration 63900, loss = 0.315565
I0725 18:55:26.351537 20892 solver.cpp:244]     Train net output #0: loss = 0.315565 (* 1 = 0.315565 loss)
I0725 18:55:26.351544 20892 sgd_solver.cpp:106] Iteration 63900, lr = 3.41154e-06
I0725 18:55:35.694865 20892 solver.cpp:337] Iteration 64000, Testing net (#0)
I0725 18:55:49.737429 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831226
I0725 18:55:49.737473 20892 solver.cpp:404]     Test net output #1: loss = 0.377399 (* 1 = 0.377399 loss)
I0725 18:55:49.766800 20892 solver.cpp:228] Iteration 64000, loss = 0.31651
I0725 18:55:49.766860 20892 solver.cpp:244]     Train net output #0: loss = 0.31651 (* 1 = 0.31651 loss)
I0725 18:55:49.766870 20892 sgd_solver.cpp:106] Iteration 64000, lr = 3.4085e-06
I0725 18:55:59.138698 20892 solver.cpp:228] Iteration 64100, loss = 0.304108
I0725 18:55:59.138752 20892 solver.cpp:244]     Train net output #0: loss = 0.304108 (* 1 = 0.304108 loss)
I0725 18:55:59.138759 20892 sgd_solver.cpp:106] Iteration 64100, lr = 3.40546e-06
I0725 18:56:08.627218 20892 solver.cpp:228] Iteration 64200, loss = 0.234249
I0725 18:56:08.627276 20892 solver.cpp:244]     Train net output #0: loss = 0.234249 (* 1 = 0.234249 loss)
I0725 18:56:08.627284 20892 sgd_solver.cpp:106] Iteration 64200, lr = 3.40242e-06
I0725 18:56:18.195379 20892 solver.cpp:228] Iteration 64300, loss = 0.283973
I0725 18:56:18.195447 20892 solver.cpp:244]     Train net output #0: loss = 0.283973 (* 1 = 0.283973 loss)
I0725 18:56:18.195454 20892 sgd_solver.cpp:106] Iteration 64300, lr = 3.3994e-06
I0725 18:56:27.536922 20892 solver.cpp:228] Iteration 64400, loss = 0.397453
I0725 18:56:27.536984 20892 solver.cpp:244]     Train net output #0: loss = 0.397453 (* 1 = 0.397453 loss)
I0725 18:56:27.536993 20892 sgd_solver.cpp:106] Iteration 64400, lr = 3.39637e-06
I0725 18:56:36.784950 20892 solver.cpp:337] Iteration 64500, Testing net (#0)
I0725 18:56:50.897531 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830904
I0725 18:56:50.897588 20892 solver.cpp:404]     Test net output #1: loss = 0.37885 (* 1 = 0.37885 loss)
I0725 18:56:50.924233 20892 solver.cpp:228] Iteration 64500, loss = 0.268257
I0725 18:56:50.924309 20892 solver.cpp:244]     Train net output #0: loss = 0.268257 (* 1 = 0.268257 loss)
I0725 18:56:50.924331 20892 sgd_solver.cpp:106] Iteration 64500, lr = 3.39336e-06
I0725 18:57:00.260211 20892 solver.cpp:228] Iteration 64600, loss = 0.447942
I0725 18:57:00.260251 20892 solver.cpp:244]     Train net output #0: loss = 0.447942 (* 1 = 0.447942 loss)
I0725 18:57:00.260257 20892 sgd_solver.cpp:106] Iteration 64600, lr = 3.39035e-06
I0725 18:57:09.670413 20892 solver.cpp:228] Iteration 64700, loss = 0.370993
I0725 18:57:09.670472 20892 solver.cpp:244]     Train net output #0: loss = 0.370993 (* 1 = 0.370993 loss)
I0725 18:57:09.670485 20892 sgd_solver.cpp:106] Iteration 64700, lr = 3.38735e-06
I0725 18:57:19.077044 20892 solver.cpp:228] Iteration 64800, loss = 0.284381
I0725 18:57:19.077086 20892 solver.cpp:244]     Train net output #0: loss = 0.284381 (* 1 = 0.284381 loss)
I0725 18:57:19.077092 20892 sgd_solver.cpp:106] Iteration 64800, lr = 3.38435e-06
I0725 18:57:28.490803 20892 solver.cpp:228] Iteration 64900, loss = 0.34633
I0725 18:57:28.490841 20892 solver.cpp:244]     Train net output #0: loss = 0.34633 (* 1 = 0.34633 loss)
I0725 18:57:28.490847 20892 sgd_solver.cpp:106] Iteration 64900, lr = 3.38136e-06
I0725 18:57:37.802171 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_65000.caffemodel
I0725 18:57:38.220808 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_65000.solverstate
I0725 18:57:38.373880 20892 solver.cpp:337] Iteration 65000, Testing net (#0)
I0725 18:57:47.817917 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 18:57:52.213419 20892 solver.cpp:404]     Test net output #0: accuracy = 0.828645
I0725 18:57:52.213462 20892 solver.cpp:404]     Test net output #1: loss = 0.382584 (* 1 = 0.382584 loss)
I0725 18:57:52.242645 20892 solver.cpp:228] Iteration 65000, loss = 0.287614
I0725 18:57:52.242696 20892 solver.cpp:244]     Train net output #0: loss = 0.287614 (* 1 = 0.287614 loss)
I0725 18:57:52.242705 20892 sgd_solver.cpp:106] Iteration 65000, lr = 3.37838e-06
I0725 18:58:01.605092 20892 solver.cpp:228] Iteration 65100, loss = 0.380194
I0725 18:58:01.605144 20892 solver.cpp:244]     Train net output #0: loss = 0.380194 (* 1 = 0.380194 loss)
I0725 18:58:01.605151 20892 sgd_solver.cpp:106] Iteration 65100, lr = 3.3754e-06
I0725 18:58:11.001657 20892 solver.cpp:228] Iteration 65200, loss = 0.251088
I0725 18:58:11.001701 20892 solver.cpp:244]     Train net output #0: loss = 0.251088 (* 1 = 0.251088 loss)
I0725 18:58:11.001708 20892 sgd_solver.cpp:106] Iteration 65200, lr = 3.37243e-06
I0725 18:58:20.396435 20892 solver.cpp:228] Iteration 65300, loss = 0.225906
I0725 18:58:20.396482 20892 solver.cpp:244]     Train net output #0: loss = 0.225906 (* 1 = 0.225906 loss)
I0725 18:58:20.396488 20892 sgd_solver.cpp:106] Iteration 65300, lr = 3.36946e-06
I0725 18:58:29.798360 20892 solver.cpp:228] Iteration 65400, loss = 0.380524
I0725 18:58:29.798419 20892 solver.cpp:244]     Train net output #0: loss = 0.380524 (* 1 = 0.380524 loss)
I0725 18:58:29.798429 20892 sgd_solver.cpp:106] Iteration 65400, lr = 3.3665e-06
I0725 18:58:39.107352 20892 solver.cpp:337] Iteration 65500, Testing net (#0)
I0725 18:58:53.138386 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830839
I0725 18:58:53.138432 20892 solver.cpp:404]     Test net output #1: loss = 0.3789 (* 1 = 0.3789 loss)
I0725 18:58:53.167412 20892 solver.cpp:228] Iteration 65500, loss = 0.254598
I0725 18:58:53.167459 20892 solver.cpp:244]     Train net output #0: loss = 0.254598 (* 1 = 0.254598 loss)
I0725 18:58:53.167469 20892 sgd_solver.cpp:106] Iteration 65500, lr = 3.36355e-06
I0725 18:59:02.468413 20892 solver.cpp:228] Iteration 65600, loss = 0.378132
I0725 18:59:02.468478 20892 solver.cpp:244]     Train net output #0: loss = 0.378132 (* 1 = 0.378132 loss)
I0725 18:59:02.468487 20892 sgd_solver.cpp:106] Iteration 65600, lr = 3.3606e-06
I0725 18:59:11.867949 20892 solver.cpp:228] Iteration 65700, loss = 0.316633
I0725 18:59:11.867996 20892 solver.cpp:244]     Train net output #0: loss = 0.316633 (* 1 = 0.316633 loss)
I0725 18:59:11.868002 20892 sgd_solver.cpp:106] Iteration 65700, lr = 3.35766e-06
I0725 18:59:21.278789 20892 solver.cpp:228] Iteration 65800, loss = 0.27784
I0725 18:59:21.278832 20892 solver.cpp:244]     Train net output #0: loss = 0.27784 (* 1 = 0.27784 loss)
I0725 18:59:21.278838 20892 sgd_solver.cpp:106] Iteration 65800, lr = 3.35473e-06
I0725 18:59:30.687436 20892 solver.cpp:228] Iteration 65900, loss = 0.353767
I0725 18:59:30.687480 20892 solver.cpp:244]     Train net output #0: loss = 0.353767 (* 1 = 0.353767 loss)
I0725 18:59:30.687489 20892 sgd_solver.cpp:106] Iteration 65900, lr = 3.3518e-06
I0725 18:59:39.988981 20892 solver.cpp:337] Iteration 66000, Testing net (#0)
I0725 18:59:53.965931 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831968
I0725 18:59:53.965971 20892 solver.cpp:404]     Test net output #1: loss = 0.376795 (* 1 = 0.376795 loss)
I0725 18:59:53.995271 20892 solver.cpp:228] Iteration 66000, loss = 0.353004
I0725 18:59:53.995314 20892 solver.cpp:244]     Train net output #0: loss = 0.353004 (* 1 = 0.353004 loss)
I0725 18:59:53.995324 20892 sgd_solver.cpp:106] Iteration 66000, lr = 3.34887e-06
I0725 19:00:03.341506 20892 solver.cpp:228] Iteration 66100, loss = 0.18367
I0725 19:00:03.341559 20892 solver.cpp:244]     Train net output #0: loss = 0.18367 (* 1 = 0.18367 loss)
I0725 19:00:03.341567 20892 sgd_solver.cpp:106] Iteration 66100, lr = 3.34596e-06
I0725 19:00:12.740303 20892 solver.cpp:228] Iteration 66200, loss = 0.529159
I0725 19:00:12.740348 20892 solver.cpp:244]     Train net output #0: loss = 0.529159 (* 1 = 0.529159 loss)
I0725 19:00:12.740355 20892 sgd_solver.cpp:106] Iteration 66200, lr = 3.34304e-06
I0725 19:00:22.141940 20892 solver.cpp:228] Iteration 66300, loss = 0.20829
I0725 19:00:22.141999 20892 solver.cpp:244]     Train net output #0: loss = 0.20829 (* 1 = 0.20829 loss)
I0725 19:00:22.142005 20892 sgd_solver.cpp:106] Iteration 66300, lr = 3.34014e-06
I0725 19:00:31.472337 20892 solver.cpp:228] Iteration 66400, loss = 0.278139
I0725 19:00:31.472388 20892 solver.cpp:244]     Train net output #0: loss = 0.278139 (* 1 = 0.278139 loss)
I0725 19:00:31.472394 20892 sgd_solver.cpp:106] Iteration 66400, lr = 3.33724e-06
I0725 19:00:40.771767 20892 solver.cpp:337] Iteration 66500, Testing net (#0)
I0725 19:00:54.847650 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831517
I0725 19:00:54.847697 20892 solver.cpp:404]     Test net output #1: loss = 0.377536 (* 1 = 0.377536 loss)
I0725 19:00:54.873972 20892 solver.cpp:228] Iteration 66500, loss = 0.266925
I0725 19:00:54.874024 20892 solver.cpp:244]     Train net output #0: loss = 0.266925 (* 1 = 0.266925 loss)
I0725 19:00:54.874035 20892 sgd_solver.cpp:106] Iteration 66500, lr = 3.33434e-06
I0725 19:01:04.238368 20892 solver.cpp:228] Iteration 66600, loss = 0.299296
I0725 19:01:04.238423 20892 solver.cpp:244]     Train net output #0: loss = 0.299296 (* 1 = 0.299296 loss)
I0725 19:01:04.238430 20892 sgd_solver.cpp:106] Iteration 66600, lr = 3.33146e-06
I0725 19:01:08.000237 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:01:13.644363 20892 solver.cpp:228] Iteration 66700, loss = 0.442046
I0725 19:01:13.644418 20892 solver.cpp:244]     Train net output #0: loss = 0.442046 (* 1 = 0.442046 loss)
I0725 19:01:13.644425 20892 sgd_solver.cpp:106] Iteration 66700, lr = 3.32857e-06
I0725 19:01:23.055163 20892 solver.cpp:228] Iteration 66800, loss = 0.337514
I0725 19:01:23.055227 20892 solver.cpp:244]     Train net output #0: loss = 0.337514 (* 1 = 0.337514 loss)
I0725 19:01:23.055235 20892 sgd_solver.cpp:106] Iteration 66800, lr = 3.3257e-06
I0725 19:01:32.461690 20892 solver.cpp:228] Iteration 66900, loss = 0.233954
I0725 19:01:32.461742 20892 solver.cpp:244]     Train net output #0: loss = 0.233954 (* 1 = 0.233954 loss)
I0725 19:01:32.461750 20892 sgd_solver.cpp:106] Iteration 66900, lr = 3.32283e-06
I0725 19:01:41.712493 20892 solver.cpp:337] Iteration 67000, Testing net (#0)
I0725 19:01:55.762207 20892 solver.cpp:404]     Test net output #0: accuracy = 0.825549
I0725 19:01:55.762272 20892 solver.cpp:404]     Test net output #1: loss = 0.388732 (* 1 = 0.388732 loss)
I0725 19:01:55.791622 20892 solver.cpp:228] Iteration 67000, loss = 0.309174
I0725 19:01:55.791702 20892 solver.cpp:244]     Train net output #0: loss = 0.309174 (* 1 = 0.309174 loss)
I0725 19:01:55.791720 20892 sgd_solver.cpp:106] Iteration 67000, lr = 3.31996e-06
I0725 19:02:05.181884 20892 solver.cpp:228] Iteration 67100, loss = 0.299226
I0725 19:02:05.181929 20892 solver.cpp:244]     Train net output #0: loss = 0.299226 (* 1 = 0.299226 loss)
I0725 19:02:05.181936 20892 sgd_solver.cpp:106] Iteration 67100, lr = 3.3171e-06
I0725 19:02:14.596457 20892 solver.cpp:228] Iteration 67200, loss = 0.28329
I0725 19:02:14.596516 20892 solver.cpp:244]     Train net output #0: loss = 0.28329 (* 1 = 0.28329 loss)
I0725 19:02:14.596524 20892 sgd_solver.cpp:106] Iteration 67200, lr = 3.31425e-06
I0725 19:02:24.014483 20892 solver.cpp:228] Iteration 67300, loss = 0.326471
I0725 19:02:24.014526 20892 solver.cpp:244]     Train net output #0: loss = 0.326471 (* 1 = 0.326471 loss)
I0725 19:02:24.014533 20892 sgd_solver.cpp:106] Iteration 67300, lr = 3.3114e-06
I0725 19:02:33.424330 20892 solver.cpp:228] Iteration 67400, loss = 0.219371
I0725 19:02:33.424394 20892 solver.cpp:244]     Train net output #0: loss = 0.219371 (* 1 = 0.219371 loss)
I0725 19:02:33.424402 20892 sgd_solver.cpp:106] Iteration 67400, lr = 3.30856e-06
I0725 19:02:42.744814 20892 solver.cpp:337] Iteration 67500, Testing net (#0)
I0725 19:02:56.838021 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831549
I0725 19:02:56.838100 20892 solver.cpp:404]     Test net output #1: loss = 0.37773 (* 1 = 0.37773 loss)
I0725 19:02:56.865028 20892 solver.cpp:228] Iteration 67500, loss = 0.25611
I0725 19:02:56.865108 20892 solver.cpp:244]     Train net output #0: loss = 0.25611 (* 1 = 0.25611 loss)
I0725 19:02:56.865120 20892 sgd_solver.cpp:106] Iteration 67500, lr = 3.30572e-06
I0725 19:03:06.251236 20892 solver.cpp:228] Iteration 67600, loss = 0.355709
I0725 19:03:06.251309 20892 solver.cpp:244]     Train net output #0: loss = 0.355709 (* 1 = 0.355709 loss)
I0725 19:03:06.251317 20892 sgd_solver.cpp:106] Iteration 67600, lr = 3.30289e-06
I0725 19:03:15.661782 20892 solver.cpp:228] Iteration 67700, loss = 0.299233
I0725 19:03:15.661855 20892 solver.cpp:244]     Train net output #0: loss = 0.299233 (* 1 = 0.299233 loss)
I0725 19:03:15.661864 20892 sgd_solver.cpp:106] Iteration 67700, lr = 3.30007e-06
I0725 19:03:25.067345 20892 solver.cpp:228] Iteration 67800, loss = 0.374039
I0725 19:03:25.067397 20892 solver.cpp:244]     Train net output #0: loss = 0.374039 (* 1 = 0.374039 loss)
I0725 19:03:25.067412 20892 sgd_solver.cpp:106] Iteration 67800, lr = 3.29725e-06
I0725 19:03:34.478713 20892 solver.cpp:228] Iteration 67900, loss = 0.372674
I0725 19:03:34.478785 20892 solver.cpp:244]     Train net output #0: loss = 0.372674 (* 1 = 0.372674 loss)
I0725 19:03:34.478792 20892 sgd_solver.cpp:106] Iteration 67900, lr = 3.29443e-06
I0725 19:03:43.789691 20892 solver.cpp:337] Iteration 68000, Testing net (#0)
I0725 19:03:58.002200 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832323
I0725 19:03:58.002251 20892 solver.cpp:404]     Test net output #1: loss = 0.376161 (* 1 = 0.376161 loss)
I0725 19:03:58.031286 20892 solver.cpp:228] Iteration 68000, loss = 0.377858
I0725 19:03:58.031345 20892 solver.cpp:244]     Train net output #0: loss = 0.377858 (* 1 = 0.377858 loss)
I0725 19:03:58.031357 20892 sgd_solver.cpp:106] Iteration 68000, lr = 3.29163e-06
I0725 19:04:07.456353 20892 solver.cpp:228] Iteration 68100, loss = 0.279245
I0725 19:04:07.456413 20892 solver.cpp:244]     Train net output #0: loss = 0.279245 (* 1 = 0.279245 loss)
I0725 19:04:07.456420 20892 sgd_solver.cpp:106] Iteration 68100, lr = 3.28882e-06
I0725 19:04:16.992504 20892 solver.cpp:228] Iteration 68200, loss = 0.336053
I0725 19:04:16.992548 20892 solver.cpp:244]     Train net output #0: loss = 0.336053 (* 1 = 0.336053 loss)
I0725 19:04:16.992554 20892 sgd_solver.cpp:106] Iteration 68200, lr = 3.28603e-06
I0725 19:04:26.385669 20892 solver.cpp:228] Iteration 68300, loss = 0.269782
I0725 19:04:26.385706 20892 solver.cpp:244]     Train net output #0: loss = 0.269782 (* 1 = 0.269782 loss)
I0725 19:04:26.385712 20892 sgd_solver.cpp:106] Iteration 68300, lr = 3.28323e-06
I0725 19:04:35.710291 20892 solver.cpp:228] Iteration 68400, loss = 0.411252
I0725 19:04:35.710332 20892 solver.cpp:244]     Train net output #0: loss = 0.411252 (* 1 = 0.411252 loss)
I0725 19:04:35.710338 20892 sgd_solver.cpp:106] Iteration 68400, lr = 3.28045e-06
I0725 19:04:45.018081 20892 solver.cpp:337] Iteration 68500, Testing net (#0)
I0725 19:04:47.100039 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:04:59.213228 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832032
I0725 19:04:59.213268 20892 solver.cpp:404]     Test net output #1: loss = 0.376824 (* 1 = 0.376824 loss)
I0725 19:04:59.242971 20892 solver.cpp:228] Iteration 68500, loss = 0.286665
I0725 19:04:59.243019 20892 solver.cpp:244]     Train net output #0: loss = 0.286665 (* 1 = 0.286665 loss)
I0725 19:04:59.243037 20892 sgd_solver.cpp:106] Iteration 68500, lr = 3.27767e-06
I0725 19:05:08.594929 20892 solver.cpp:228] Iteration 68600, loss = 0.267941
I0725 19:05:08.594972 20892 solver.cpp:244]     Train net output #0: loss = 0.267941 (* 1 = 0.267941 loss)
I0725 19:05:08.594980 20892 sgd_solver.cpp:106] Iteration 68600, lr = 3.27489e-06
I0725 19:05:18.005653 20892 solver.cpp:228] Iteration 68700, loss = 0.287
I0725 19:05:18.005717 20892 solver.cpp:244]     Train net output #0: loss = 0.287 (* 1 = 0.287 loss)
I0725 19:05:18.005724 20892 sgd_solver.cpp:106] Iteration 68700, lr = 3.27212e-06
I0725 19:05:27.418916 20892 solver.cpp:228] Iteration 68800, loss = 0.31857
I0725 19:05:27.418985 20892 solver.cpp:244]     Train net output #0: loss = 0.31857 (* 1 = 0.31857 loss)
I0725 19:05:27.418993 20892 sgd_solver.cpp:106] Iteration 68800, lr = 3.26936e-06
I0725 19:05:36.823318 20892 solver.cpp:228] Iteration 68900, loss = 0.319226
I0725 19:05:36.823365 20892 solver.cpp:244]     Train net output #0: loss = 0.319226 (* 1 = 0.319226 loss)
I0725 19:05:36.823371 20892 sgd_solver.cpp:106] Iteration 68900, lr = 3.2666e-06
I0725 19:05:46.135725 20892 solver.cpp:337] Iteration 69000, Testing net (#0)
I0725 19:06:00.319916 20892 solver.cpp:404]     Test net output #0: accuracy = 0.828097
I0725 19:06:00.319977 20892 solver.cpp:404]     Test net output #1: loss = 0.384499 (* 1 = 0.384499 loss)
I0725 19:06:00.349802 20892 solver.cpp:228] Iteration 69000, loss = 0.383431
I0725 19:06:00.349875 20892 solver.cpp:244]     Train net output #0: loss = 0.383431 (* 1 = 0.383431 loss)
I0725 19:06:00.349895 20892 sgd_solver.cpp:106] Iteration 69000, lr = 3.26385e-06
I0725 19:06:09.724851 20892 solver.cpp:228] Iteration 69100, loss = 0.292915
I0725 19:06:09.724902 20892 solver.cpp:244]     Train net output #0: loss = 0.292915 (* 1 = 0.292915 loss)
I0725 19:06:09.724910 20892 sgd_solver.cpp:106] Iteration 69100, lr = 3.2611e-06
I0725 19:06:19.126827 20892 solver.cpp:228] Iteration 69200, loss = 0.312718
I0725 19:06:19.126868 20892 solver.cpp:244]     Train net output #0: loss = 0.312718 (* 1 = 0.312718 loss)
I0725 19:06:19.126875 20892 sgd_solver.cpp:106] Iteration 69200, lr = 3.25836e-06
I0725 19:06:28.534756 20892 solver.cpp:228] Iteration 69300, loss = 0.283627
I0725 19:06:28.534801 20892 solver.cpp:244]     Train net output #0: loss = 0.283627 (* 1 = 0.283627 loss)
I0725 19:06:28.534806 20892 sgd_solver.cpp:106] Iteration 69300, lr = 3.25562e-06
I0725 19:06:37.944581 20892 solver.cpp:228] Iteration 69400, loss = 0.327319
I0725 19:06:37.944629 20892 solver.cpp:244]     Train net output #0: loss = 0.327319 (* 1 = 0.327319 loss)
I0725 19:06:37.944638 20892 sgd_solver.cpp:106] Iteration 69400, lr = 3.25289e-06
I0725 19:06:47.253548 20892 solver.cpp:337] Iteration 69500, Testing net (#0)
I0725 19:07:01.355541 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832452
I0725 19:07:01.355600 20892 solver.cpp:404]     Test net output #1: loss = 0.376065 (* 1 = 0.376065 loss)
I0725 19:07:01.382212 20892 solver.cpp:228] Iteration 69500, loss = 0.257884
I0725 19:07:01.382269 20892 solver.cpp:244]     Train net output #0: loss = 0.257884 (* 1 = 0.257884 loss)
I0725 19:07:01.382297 20892 sgd_solver.cpp:106] Iteration 69500, lr = 3.25016e-06
I0725 19:07:10.736635 20892 solver.cpp:228] Iteration 69600, loss = 0.266054
I0725 19:07:10.736688 20892 solver.cpp:244]     Train net output #0: loss = 0.266054 (* 1 = 0.266054 loss)
I0725 19:07:10.736696 20892 sgd_solver.cpp:106] Iteration 69600, lr = 3.24744e-06
I0725 19:07:20.149224 20892 solver.cpp:228] Iteration 69700, loss = 0.328081
I0725 19:07:20.149265 20892 solver.cpp:244]     Train net output #0: loss = 0.328081 (* 1 = 0.328081 loss)
I0725 19:07:20.149271 20892 sgd_solver.cpp:106] Iteration 69700, lr = 3.24473e-06
I0725 19:07:29.556203 20892 solver.cpp:228] Iteration 69800, loss = 0.287466
I0725 19:07:29.556248 20892 solver.cpp:244]     Train net output #0: loss = 0.287466 (* 1 = 0.287466 loss)
I0725 19:07:29.556257 20892 sgd_solver.cpp:106] Iteration 69800, lr = 3.24202e-06
I0725 19:07:38.956707 20892 solver.cpp:228] Iteration 69900, loss = 0.27532
I0725 19:07:38.956758 20892 solver.cpp:244]     Train net output #0: loss = 0.27532 (* 1 = 0.27532 loss)
I0725 19:07:38.956765 20892 sgd_solver.cpp:106] Iteration 69900, lr = 3.23931e-06
I0725 19:07:48.266085 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_70000.caffemodel
I0725 19:07:48.621595 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_70000.solverstate
I0725 19:07:48.719493 20892 solver.cpp:337] Iteration 70000, Testing net (#0)
I0725 19:07:53.449275 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:08:02.735782 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832323
I0725 19:08:02.735847 20892 solver.cpp:404]     Test net output #1: loss = 0.376459 (* 1 = 0.376459 loss)
I0725 19:08:02.762332 20892 solver.cpp:228] Iteration 70000, loss = 0.332515
I0725 19:08:02.762387 20892 solver.cpp:244]     Train net output #0: loss = 0.332515 (* 1 = 0.332515 loss)
I0725 19:08:02.762399 20892 sgd_solver.cpp:106] Iteration 70000, lr = 3.23661e-06
I0725 19:08:12.158699 20892 solver.cpp:228] Iteration 70100, loss = 0.354683
I0725 19:08:12.158743 20892 solver.cpp:244]     Train net output #0: loss = 0.354683 (* 1 = 0.354683 loss)
I0725 19:08:12.158749 20892 sgd_solver.cpp:106] Iteration 70100, lr = 3.23392e-06
I0725 19:08:21.570886 20892 solver.cpp:228] Iteration 70200, loss = 0.344119
I0725 19:08:21.570927 20892 solver.cpp:244]     Train net output #0: loss = 0.344119 (* 1 = 0.344119 loss)
I0725 19:08:21.570933 20892 sgd_solver.cpp:106] Iteration 70200, lr = 3.23123e-06
I0725 19:08:30.986888 20892 solver.cpp:228] Iteration 70300, loss = 0.29773
I0725 19:08:30.986937 20892 solver.cpp:244]     Train net output #0: loss = 0.29773 (* 1 = 0.29773 loss)
I0725 19:08:30.986944 20892 sgd_solver.cpp:106] Iteration 70300, lr = 3.22854e-06
I0725 19:08:40.401489 20892 solver.cpp:228] Iteration 70400, loss = 0.271483
I0725 19:08:40.401528 20892 solver.cpp:244]     Train net output #0: loss = 0.271483 (* 1 = 0.271483 loss)
I0725 19:08:40.401535 20892 sgd_solver.cpp:106] Iteration 70400, lr = 3.22586e-06
I0725 19:08:49.723896 20892 solver.cpp:337] Iteration 70500, Testing net (#0)
I0725 19:09:03.884881 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833968
I0725 19:09:03.884932 20892 solver.cpp:404]     Test net output #1: loss = 0.373717 (* 1 = 0.373717 loss)
I0725 19:09:03.911128 20892 solver.cpp:228] Iteration 70500, loss = 0.246882
I0725 19:09:03.911200 20892 solver.cpp:244]     Train net output #0: loss = 0.246882 (* 1 = 0.246882 loss)
I0725 19:09:03.911211 20892 sgd_solver.cpp:106] Iteration 70500, lr = 3.22319e-06
I0725 19:09:13.268743 20892 solver.cpp:228] Iteration 70600, loss = 0.277162
I0725 19:09:13.268808 20892 solver.cpp:244]     Train net output #0: loss = 0.277162 (* 1 = 0.277162 loss)
I0725 19:09:13.268817 20892 sgd_solver.cpp:106] Iteration 70600, lr = 3.22052e-06
I0725 19:09:22.680290 20892 solver.cpp:228] Iteration 70700, loss = 0.244629
I0725 19:09:22.680366 20892 solver.cpp:244]     Train net output #0: loss = 0.244629 (* 1 = 0.244629 loss)
I0725 19:09:22.680373 20892 sgd_solver.cpp:106] Iteration 70700, lr = 3.21786e-06
I0725 19:09:32.090015 20892 solver.cpp:228] Iteration 70800, loss = 0.221362
I0725 19:09:32.090054 20892 solver.cpp:244]     Train net output #0: loss = 0.221362 (* 1 = 0.221362 loss)
I0725 19:09:32.090060 20892 sgd_solver.cpp:106] Iteration 70800, lr = 3.2152e-06
I0725 19:09:41.496940 20892 solver.cpp:228] Iteration 70900, loss = 0.296989
I0725 19:09:41.496999 20892 solver.cpp:244]     Train net output #0: loss = 0.296989 (* 1 = 0.296989 loss)
I0725 19:09:41.497009 20892 sgd_solver.cpp:106] Iteration 70900, lr = 3.21255e-06
I0725 19:09:50.811919 20892 solver.cpp:337] Iteration 71000, Testing net (#0)
I0725 19:10:04.907356 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830903
I0725 19:10:04.907429 20892 solver.cpp:404]     Test net output #1: loss = 0.379106 (* 1 = 0.379106 loss)
I0725 19:10:04.936506 20892 solver.cpp:228] Iteration 71000, loss = 0.421423
I0725 19:10:04.936568 20892 solver.cpp:244]     Train net output #0: loss = 0.421423 (* 1 = 0.421423 loss)
I0725 19:10:04.936578 20892 sgd_solver.cpp:106] Iteration 71000, lr = 3.2099e-06
I0725 19:10:14.322370 20892 solver.cpp:228] Iteration 71100, loss = 0.307739
I0725 19:10:14.322420 20892 solver.cpp:244]     Train net output #0: loss = 0.307739 (* 1 = 0.307739 loss)
I0725 19:10:14.322429 20892 sgd_solver.cpp:106] Iteration 71100, lr = 3.20726e-06
I0725 19:10:23.729296 20892 solver.cpp:228] Iteration 71200, loss = 0.348484
I0725 19:10:23.729347 20892 solver.cpp:244]     Train net output #0: loss = 0.348484 (* 1 = 0.348484 loss)
I0725 19:10:23.729356 20892 sgd_solver.cpp:106] Iteration 71200, lr = 3.20462e-06
I0725 19:10:33.133165 20892 solver.cpp:228] Iteration 71300, loss = 0.289026
I0725 19:10:33.133227 20892 solver.cpp:244]     Train net output #0: loss = 0.289026 (* 1 = 0.289026 loss)
I0725 19:10:33.133235 20892 sgd_solver.cpp:106] Iteration 71300, lr = 3.20199e-06
I0725 19:10:42.541424 20892 solver.cpp:228] Iteration 71400, loss = 0.219625
I0725 19:10:42.541473 20892 solver.cpp:244]     Train net output #0: loss = 0.219625 (* 1 = 0.219625 loss)
I0725 19:10:42.541481 20892 sgd_solver.cpp:106] Iteration 71400, lr = 3.19936e-06
I0725 19:10:51.853813 20892 solver.cpp:337] Iteration 71500, Testing net (#0)
I0725 19:10:59.561363 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:11:06.162726 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833549
I0725 19:11:06.162781 20892 solver.cpp:404]     Test net output #1: loss = 0.374926 (* 1 = 0.374926 loss)
I0725 19:11:06.191897 20892 solver.cpp:228] Iteration 71500, loss = 0.344465
I0725 19:11:06.191951 20892 solver.cpp:244]     Train net output #0: loss = 0.344465 (* 1 = 0.344465 loss)
I0725 19:11:06.191963 20892 sgd_solver.cpp:106] Iteration 71500, lr = 3.19674e-06
I0725 19:11:15.543949 20892 solver.cpp:228] Iteration 71600, loss = 0.52495
I0725 19:11:15.544020 20892 solver.cpp:244]     Train net output #0: loss = 0.52495 (* 1 = 0.52495 loss)
I0725 19:11:15.544029 20892 sgd_solver.cpp:106] Iteration 71600, lr = 3.19412e-06
I0725 19:11:24.958961 20892 solver.cpp:228] Iteration 71700, loss = 0.346982
I0725 19:11:24.959017 20892 solver.cpp:244]     Train net output #0: loss = 0.346982 (* 1 = 0.346982 loss)
I0725 19:11:24.959024 20892 sgd_solver.cpp:106] Iteration 71700, lr = 3.1915e-06
I0725 19:11:34.370357 20892 solver.cpp:228] Iteration 71800, loss = 0.302782
I0725 19:11:34.370407 20892 solver.cpp:244]     Train net output #0: loss = 0.302782 (* 1 = 0.302782 loss)
I0725 19:11:34.370415 20892 sgd_solver.cpp:106] Iteration 71800, lr = 3.1889e-06
I0725 19:11:43.785374 20892 solver.cpp:228] Iteration 71900, loss = 0.437192
I0725 19:11:43.785419 20892 solver.cpp:244]     Train net output #0: loss = 0.437192 (* 1 = 0.437192 loss)
I0725 19:11:43.785428 20892 sgd_solver.cpp:106] Iteration 71900, lr = 3.18629e-06
I0725 19:11:53.101589 20892 solver.cpp:337] Iteration 72000, Testing net (#0)
I0725 19:12:07.137812 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832839
I0725 19:12:07.137881 20892 solver.cpp:404]     Test net output #1: loss = 0.376134 (* 1 = 0.376134 loss)
I0725 19:12:07.168864 20892 solver.cpp:228] Iteration 72000, loss = 0.333169
I0725 19:12:07.168900 20892 solver.cpp:244]     Train net output #0: loss = 0.333169 (* 1 = 0.333169 loss)
I0725 19:12:07.168915 20892 sgd_solver.cpp:106] Iteration 72000, lr = 3.1837e-06
I0725 19:12:16.560322 20892 solver.cpp:228] Iteration 72100, loss = 0.270776
I0725 19:12:16.560366 20892 solver.cpp:244]     Train net output #0: loss = 0.270776 (* 1 = 0.270776 loss)
I0725 19:12:16.560372 20892 sgd_solver.cpp:106] Iteration 72100, lr = 3.1811e-06
I0725 19:12:25.972829 20892 solver.cpp:228] Iteration 72200, loss = 0.32686
I0725 19:12:25.972893 20892 solver.cpp:244]     Train net output #0: loss = 0.32686 (* 1 = 0.32686 loss)
I0725 19:12:25.972901 20892 sgd_solver.cpp:106] Iteration 72200, lr = 3.17852e-06
I0725 19:12:35.386977 20892 solver.cpp:228] Iteration 72300, loss = 0.305504
I0725 19:12:35.387034 20892 solver.cpp:244]     Train net output #0: loss = 0.305504 (* 1 = 0.305504 loss)
I0725 19:12:35.387043 20892 sgd_solver.cpp:106] Iteration 72300, lr = 3.17593e-06
I0725 19:12:44.800384 20892 solver.cpp:228] Iteration 72400, loss = 0.272386
I0725 19:12:44.800420 20892 solver.cpp:244]     Train net output #0: loss = 0.272386 (* 1 = 0.272386 loss)
I0725 19:12:44.800426 20892 sgd_solver.cpp:106] Iteration 72400, lr = 3.17335e-06
I0725 19:12:54.122035 20892 solver.cpp:337] Iteration 72500, Testing net (#0)
I0725 19:13:08.343994 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829839
I0725 19:13:08.344064 20892 solver.cpp:404]     Test net output #1: loss = 0.381226 (* 1 = 0.381226 loss)
I0725 19:13:08.373757 20892 solver.cpp:228] Iteration 72500, loss = 0.286438
I0725 19:13:08.373823 20892 solver.cpp:244]     Train net output #0: loss = 0.286438 (* 1 = 0.286438 loss)
I0725 19:13:08.373842 20892 sgd_solver.cpp:106] Iteration 72500, lr = 3.17078e-06
I0725 19:13:17.762661 20892 solver.cpp:228] Iteration 72600, loss = 0.337302
I0725 19:13:17.762722 20892 solver.cpp:244]     Train net output #0: loss = 0.337302 (* 1 = 0.337302 loss)
I0725 19:13:17.762728 20892 sgd_solver.cpp:106] Iteration 72600, lr = 3.16821e-06
I0725 19:13:27.176352 20892 solver.cpp:228] Iteration 72700, loss = 0.312508
I0725 19:13:27.176412 20892 solver.cpp:244]     Train net output #0: loss = 0.312508 (* 1 = 0.312508 loss)
I0725 19:13:27.176420 20892 sgd_solver.cpp:106] Iteration 72700, lr = 3.16565e-06
I0725 19:13:36.586024 20892 solver.cpp:228] Iteration 72800, loss = 0.21349
I0725 19:13:36.586072 20892 solver.cpp:244]     Train net output #0: loss = 0.21349 (* 1 = 0.21349 loss)
I0725 19:13:36.586079 20892 sgd_solver.cpp:106] Iteration 72800, lr = 3.16309e-06
I0725 19:13:45.999474 20892 solver.cpp:228] Iteration 72900, loss = 0.28109
I0725 19:13:45.999528 20892 solver.cpp:244]     Train net output #0: loss = 0.28109 (* 1 = 0.28109 loss)
I0725 19:13:45.999546 20892 sgd_solver.cpp:106] Iteration 72900, lr = 3.16054e-06
I0725 19:13:55.313722 20892 solver.cpp:337] Iteration 73000, Testing net (#0)
I0725 19:14:09.366914 20892 solver.cpp:404]     Test net output #0: accuracy = 0.832903
I0725 19:14:09.366969 20892 solver.cpp:404]     Test net output #1: loss = 0.376032 (* 1 = 0.376032 loss)
I0725 19:14:09.396353 20892 solver.cpp:228] Iteration 73000, loss = 0.296964
I0725 19:14:09.396400 20892 solver.cpp:244]     Train net output #0: loss = 0.296964 (* 1 = 0.296964 loss)
I0725 19:14:09.396410 20892 sgd_solver.cpp:106] Iteration 73000, lr = 3.15799e-06
I0725 19:14:14.168807 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:14:18.781162 20892 solver.cpp:228] Iteration 73100, loss = 0.353706
I0725 19:14:18.781211 20892 solver.cpp:244]     Train net output #0: loss = 0.353706 (* 1 = 0.353706 loss)
I0725 19:14:18.781219 20892 sgd_solver.cpp:106] Iteration 73100, lr = 3.15544e-06
I0725 19:14:28.193147 20892 solver.cpp:228] Iteration 73200, loss = 0.286154
I0725 19:14:28.193195 20892 solver.cpp:244]     Train net output #0: loss = 0.286154 (* 1 = 0.286154 loss)
I0725 19:14:28.193202 20892 sgd_solver.cpp:106] Iteration 73200, lr = 3.1529e-06
I0725 19:14:37.605731 20892 solver.cpp:228] Iteration 73300, loss = 0.353443
I0725 19:14:37.605770 20892 solver.cpp:244]     Train net output #0: loss = 0.353443 (* 1 = 0.353443 loss)
I0725 19:14:37.605775 20892 sgd_solver.cpp:106] Iteration 73300, lr = 3.15037e-06
nets/person_background_and_random/solver.prototxt
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0I0725 19:14:47.021178 20892 solver.cpp:228] Iteration 73400, loss = 0.465362
I0725 19:14:47.021226 20892 solver.cpp:244]     Train net output #0: loss = 0.465362 (* 1 = 0.465362 loss)
I0725 19:14:47.021232 20892 sgd_solver.cpp:106] Iteration 73400, lr = 3.14784e-06
I0725 19:14:56.332857 20892 solver.cpp:337] Iteration 73500, Testing net (#0)
I0725 19:15:10.387491 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833904
I0725 19:15:10.387554 20892 solver.cpp:404]     Test net output #1: loss = 0.374345 (* 1 = 0.374345 loss)
I0725 19:15:10.421471 20892 solver.cpp:228] Iteration 73500, loss = 0.278907
I0725 19:15:10.421531 20892 solver.cpp:244]     Train net output #0: loss = 0.278907 (* 1 = 0.278907 loss)
I0725 19:15:10.421551 20892 sgd_solver.cpp:106] Iteration 73500, lr = 3.14531e-06
I0725 19:15:19.796187 20892 solver.cpp:228] Iteration 73600, loss = 0.34512
I0725 19:15:19.796241 20892 solver.cpp:244]     Train net output #0: loss = 0.34512 (* 1 = 0.34512 loss)
I0725 19:15:19.796247 20892 sgd_solver.cpp:106] Iteration 73600, lr = 3.14279e-06
I0725 19:15:29.208395 20892 solver.cpp:228] Iteration 73700, loss = 0.371554
I0725 19:15:29.208436 20892 solver.cpp:244]     Train net output #0: loss = 0.371554 (* 1 = 0.371554 loss)
I0725 19:15:29.208441 20892 sgd_solver.cpp:106] Iteration 73700, lr = 3.14028e-06
I0725 19:15:38.621922 20892 solver.cpp:228] Iteration 73800, loss = 0.327655
I0725 19:15:38.621969 20892 solver.cpp:244]     Train net output #0: loss = 0.327655 (* 1 = 0.327655 loss)
I0725 19:15:38.621975 20892 sgd_solver.cpp:106] Iteration 73800, lr = 3.13776e-06
I0725 19:15:48.033426 20892 solver.cpp:228] Iteration 73900, loss = 0.189557
I0725 19:15:48.033470 20892 solver.cpp:244]     Train net output #0: loss = 0.189557 (* 1 = 0.189557 loss)
I0725 19:15:48.033478 20892 sgd_solver.cpp:106] Iteration 73900, lr = 3.13526e-06
I0725 19:15:57.348601 20892 solver.cpp:337] Iteration 74000, Testing net (#0)
I0725 19:16:11.486347 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833581
I0725 19:16:11.486412 20892 solver.cpp:404]     Test net output #1: loss = 0.375466 (* 1 = 0.375466 loss)
I0725 19:16:11.518884 20892 solver.cpp:228] Iteration 74000, loss = 0.352958
I0725 19:16:11.518918 20892 solver.cpp:244]     Train net output #0: loss = 0.352958 (* 1 = 0.352958 loss)
I0725 19:16:11.518939 20892 sgd_solver.cpp:106] Iteration 74000, lr = 3.13276e-06
I0725 19:16:20.905602 20892 solver.cpp:228] Iteration 74100, loss = 0.351794
I0725 19:16:20.905647 20892 solver.cpp:244]     Train net output #0: loss = 0.351794 (* 1 = 0.351794 loss)
I0725 19:16:20.905652 20892 sgd_solver.cpp:106] Iteration 74100, lr = 3.13026e-06
I0725 19:16:30.317970 20892 solver.cpp:228] Iteration 74200, loss = 0.28676
I0725 19:16:30.318019 20892 solver.cpp:244]     Train net output #0: loss = 0.28676 (* 1 = 0.28676 loss)
I0725 19:16:30.318042 20892 sgd_solver.cpp:106] Iteration 74200, lr = 3.12777e-06
I0725 19:16:39.727234 20892 solver.cpp:228] Iteration 74300, loss = 0.199685
I0725 19:16:39.727283 20892 solver.cpp:244]     Train net output #0: loss = 0.199685 (* 1 = 0.199685 loss)
I0725 19:16:39.727290 20892 sgd_solver.cpp:106] Iteration 74300, lr = 3.12528e-06
I0725 19:16:49.135560 20892 solver.cpp:228] Iteration 74400, loss = 0.218223
I0725 19:16:49.135607 20892 solver.cpp:244]     Train net output #0: loss = 0.218223 (* 1 = 0.218223 loss)
I0725 19:16:49.135613 20892 sgd_solver.cpp:106] Iteration 74400, lr = 3.1228e-06
I0725 19:16:58.448060 20892 solver.cpp:337] Iteration 74500, Testing net (#0)
I0725 19:17:12.658651 20892 solver.cpp:404]     Test net output #0: accuracy = 0.826968
I0725 19:17:12.658707 20892 solver.cpp:404]     Test net output #1: loss = 0.387094 (* 1 = 0.387094 loss)
I0725 19:17:12.688045 20892 solver.cpp:228] Iteration 74500, loss = 0.299976
I0725 19:17:12.688127 20892 solver.cpp:244]     Train net output #0: loss = 0.299976 (* 1 = 0.299976 loss)
I0725 19:17:12.688140 20892 sgd_solver.cpp:106] Iteration 74500, lr = 3.12032e-06
I0725 19:17:22.061219 20892 solver.cpp:228] Iteration 74600, loss = 0.305306
I0725 19:17:22.061293 20892 solver.cpp:244]     Train net output #0: loss = 0.305306 (* 1 = 0.305306 loss)
I0725 19:17:22.061302 20892 sgd_solver.cpp:106] Iteration 74600, lr = 3.11784e-06
I0725 19:17:31.479099 20892 solver.cpp:228] Iteration 74700, loss = 0.230394
I0725 19:17:31.479145 20892 solver.cpp:244]     Train net output #0: loss = 0.230394 (* 1 = 0.230394 loss)
I0725 19:17:31.479151 20892 sgd_solver.cpp:106] Iteration 74700, lr = 3.11537e-06
I0725 19:17:40.897210 20892 solver.cpp:228] Iteration 74800, loss = 0.436606
I0725 19:17:40.897264 20892 solver.cpp:244]     Train net output #0: loss = 0.436606 (* 1 = 0.436606 loss)
I0725 19:17:40.897269 20892 sgd_solver.cpp:106] Iteration 74800, lr = 3.11291e-06
I0725 19:17:50.313506 20892 solver.cpp:228] Iteration 74900, loss = 0.282531
I0725 19:17:50.313555 20892 solver.cpp:244]     Train net output #0: loss = 0.282531 (* 1 = 0.282531 loss)
I0725 19:17:50.313563 20892 sgd_solver.cpp:106] Iteration 74900, lr = 3.11045e-06
I0725 19:17:53.794160 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:17:59.632879 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_75000.caffemodel
I0725 19:17:59.998168 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_75000.solverstate
I0725 19:18:00.095971 20892 solver.cpp:337] Iteration 75000, Testing net (#0)
I0725 19:18:14.094558 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833516
I0725 19:18:14.094600 20892 solver.cpp:404]     Test net output #1: loss = 0.375939 (* 1 = 0.375939 loss)
I0725 19:18:14.123698 20892 solver.cpp:228] Iteration 75000, loss = 0.227091
I0725 19:18:14.123744 20892 solver.cpp:244]     Train net output #0: loss = 0.227091 (* 1 = 0.227091 loss)
I0725 19:18:14.123754 20892 sgd_solver.cpp:106] Iteration 75000, lr = 3.10799e-06
I0725 19:18:23.500155 20892 solver.cpp:228] Iteration 75100, loss = 0.295272
I0725 19:18:23.500193 20892 solver.cpp:244]     Train net output #0: loss = 0.295272 (* 1 = 0.295272 loss)
I0725 19:18:23.500200 20892 sgd_solver.cpp:106] Iteration 75100, lr = 3.10554e-06
I0725 19:18:32.913954 20892 solver.cpp:228] Iteration 75200, loss = 0.240079
I0725 19:18:32.914008 20892 solver.cpp:244]     Train net output #0: loss = 0.240079 (* 1 = 0.240079 loss)
I0725 19:18:32.914016 20892 sgd_solver.cpp:106] Iteration 75200, lr = 3.10309e-06
I0725 19:18:42.326987 20892 solver.cpp:228] Iteration 75300, loss = 0.326227
I0725 19:18:42.327031 20892 solver.cpp:244]     Train net output #0: loss = 0.326227 (* 1 = 0.326227 loss)
I0725 19:18:42.327039 20892 sgd_solver.cpp:106] Iteration 75300, lr = 3.10065e-06
I0725 19:18:51.739184 20892 solver.cpp:228] Iteration 75400, loss = 0.340941
I0725 19:18:51.739238 20892 solver.cpp:244]     Train net output #0: loss = 0.340941 (* 1 = 0.340941 loss)
I0725 19:18:51.739245 20892 sgd_solver.cpp:106] Iteration 75400, lr = 3.09821e-06
I0725 19:19:01.057185 20892 solver.cpp:337] Iteration 75500, Testing net (#0)
I0725 19:19:15.154115 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833936
I0725 19:19:15.154167 20892 solver.cpp:404]     Test net output #1: loss = 0.374528 (* 1 = 0.374528 loss)
I0725 19:19:15.183675 20892 solver.cpp:228] Iteration 75500, loss = 0.315588
I0725 19:19:15.183737 20892 solver.cpp:244]     Train net output #0: loss = 0.315588 (* 1 = 0.315588 loss)
I0725 19:19:15.183748 20892 sgd_solver.cpp:106] Iteration 75500, lr = 3.09578e-06
I0725 19:19:24.588630 20892 solver.cpp:228] Iteration 75600, loss = 0.220306
I0725 19:19:24.588678 20892 solver.cpp:244]     Train net output #0: loss = 0.220306 (* 1 = 0.220306 loss)
I0725 19:19:24.588685 20892 sgd_solver.cpp:106] Iteration 75600, lr = 3.09335e-06
I0725 19:19:34.003841 20892 solver.cpp:228] Iteration 75700, loss = 0.200731
I0725 19:19:34.003887 20892 solver.cpp:244]     Train net output #0: loss = 0.200731 (* 1 = 0.200731 loss)
I0725 19:19:34.003895 20892 sgd_solver.cpp:106] Iteration 75700, lr = 3.09093e-06
I0725 19:19:43.415586 20892 solver.cpp:228] Iteration 75800, loss = 0.269762
I0725 19:19:43.415624 20892 solver.cpp:244]     Train net output #0: loss = 0.269762 (* 1 = 0.269762 loss)
I0725 19:19:43.415630 20892 sgd_solver.cpp:106] Iteration 75800, lr = 3.08851e-06
I0725 19:19:52.827129 20892 solver.cpp:228] Iteration 75900, loss = 0.325628
I0725 19:19:52.827178 20892 solver.cpp:244]     Train net output #0: loss = 0.325628 (* 1 = 0.325628 loss)
I0725 19:19:52.827184 20892 sgd_solver.cpp:106] Iteration 75900, lr = 3.08609e-06
I0725 19:20:02.135746 20892 solver.cpp:337] Iteration 76000, Testing net (#0)
I0725 19:20:16.373751 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834387
I0725 19:20:16.373793 20892 solver.cpp:404]     Test net output #1: loss = 0.374275 (* 1 = 0.374275 loss)
I0725 19:20:16.402858 20892 solver.cpp:228] Iteration 76000, loss = 0.353988
I0725 19:20:16.402889 20892 solver.cpp:244]     Train net output #0: loss = 0.353988 (* 1 = 0.353988 loss)
I0725 19:20:16.402896 20892 sgd_solver.cpp:106] Iteration 76000, lr = 3.08368e-06
I0725 19:20:25.730155 20892 solver.cpp:228] Iteration 76100, loss = 0.365112
I0725 19:20:25.730208 20892 solver.cpp:244]     Train net output #0: loss = 0.365112 (* 1 = 0.365112 loss)
I0725 19:20:25.730216 20892 sgd_solver.cpp:106] Iteration 76100, lr = 3.08127e-06
I0725 19:20:35.152912 20892 solver.cpp:228] Iteration 76200, loss = 0.247917
I0725 19:20:35.152971 20892 solver.cpp:244]     Train net output #0: loss = 0.247917 (* 1 = 0.247917 loss)
I0725 19:20:35.152977 20892 sgd_solver.cpp:106] Iteration 76200, lr = 3.07887e-06
I0725 19:20:44.562158 20892 solver.cpp:228] Iteration 76300, loss = 0.257415
I0725 19:20:44.562216 20892 solver.cpp:244]     Train net output #0: loss = 0.257415 (* 1 = 0.257415 loss)
I0725 19:20:44.562222 20892 sgd_solver.cpp:106] Iteration 76300, lr = 3.07647e-06
I0725 19:20:46.165510 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:20:53.978114 20892 solver.cpp:228] Iteration 76400, loss = 0.233112
I0725 19:20:53.978152 20892 solver.cpp:244]     Train net output #0: loss = 0.233112 (* 1 = 0.233112 loss)
I0725 19:20:53.978157 20892 sgd_solver.cpp:106] Iteration 76400, lr = 3.07408e-06
I0725 19:21:03.305227 20892 solver.cpp:337] Iteration 76500, Testing net (#0)
I0725 19:21:17.520340 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830775
I0725 19:21:17.520387 20892 solver.cpp:404]     Test net output #1: loss = 0.381004 (* 1 = 0.381004 loss)
I0725 19:21:17.549268 20892 solver.cpp:228] Iteration 76500, loss = 0.333357
I0725 19:21:17.549319 20892 solver.cpp:244]     Train net output #0: loss = 0.333357 (* 1 = 0.333357 loss)
I0725 19:21:17.549329 20892 sgd_solver.cpp:106] Iteration 76500, lr = 3.07169e-06
I0725 19:21:26.906011 20892 solver.cpp:228] Iteration 76600, loss = 0.323989
I0725 19:21:26.906075 20892 solver.cpp:244]     Train net output #0: loss = 0.323989 (* 1 = 0.323989 loss)
I0725 19:21:26.906085 20892 sgd_solver.cpp:106] Iteration 76600, lr = 3.0693e-06
I0725 19:21:36.317422 20892 solver.cpp:228] Iteration 76700, loss = 0.222245
I0725 19:21:36.317476 20892 solver.cpp:244]     Train net output #0: loss = 0.222245 (* 1 = 0.222245 loss)
I0725 19:21:36.317481 20892 sgd_solver.cpp:106] Iteration 76700, lr = 3.06692e-06
I0725 19:21:45.730087 20892 solver.cpp:228] Iteration 76800, loss = 0.346733
I0725 19:21:45.730254 20892 solver.cpp:244]     Train net output #0: loss = 0.346733 (* 1 = 0.346733 loss)
I0725 19:21:45.730262 20892 sgd_solver.cpp:106] Iteration 76800, lr = 3.06454e-06
I0725 19:21:55.138262 20892 solver.cpp:228] Iteration 76900, loss = 0.29076
I0725 19:21:55.138316 20892 solver.cpp:244]     Train net output #0: loss = 0.29076 (* 1 = 0.29076 loss)
I0725 19:21:55.138324 20892 sgd_solver.cpp:106] Iteration 76900, lr = 3.06217e-06
I0725 19:22:04.452787 20892 solver.cpp:337] Iteration 77000, Testing net (#0)
I0725 19:22:18.540099 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834516
I0725 19:22:18.540144 20892 solver.cpp:404]     Test net output #1: loss = 0.373147 (* 1 = 0.373147 loss)
I0725 19:22:18.566627 20892 solver.cpp:228] Iteration 77000, loss = 0.290167
I0725 19:22:18.566684 20892 solver.cpp:244]     Train net output #0: loss = 0.290167 (* 1 = 0.290167 loss)
I0725 19:22:18.566702 20892 sgd_solver.cpp:106] Iteration 77000, lr = 3.0598e-06
I0725 19:22:27.907778 20892 solver.cpp:228] Iteration 77100, loss = 0.267365
I0725 19:22:27.907835 20892 solver.cpp:244]     Train net output #0: loss = 0.267365 (* 1 = 0.267365 loss)
I0725 19:22:27.907858 20892 sgd_solver.cpp:106] Iteration 77100, lr = 3.05744e-06
I0725 19:22:37.320111 20892 solver.cpp:228] Iteration 77200, loss = 0.216152
I0725 19:22:37.320168 20892 solver.cpp:244]     Train net output #0: loss = 0.216152 (* 1 = 0.216152 loss)
I0725 19:22:37.320176 20892 sgd_solver.cpp:106] Iteration 77200, lr = 3.05508e-06
I0725 19:22:46.732743 20892 solver.cpp:228] Iteration 77300, loss = 0.294228
I0725 19:22:46.732800 20892 solver.cpp:244]     Train net output #0: loss = 0.294228 (* 1 = 0.294228 loss)
I0725 19:22:46.732806 20892 sgd_solver.cpp:106] Iteration 77300, lr = 3.05273e-06
I0725 19:22:56.142954 20892 solver.cpp:228] Iteration 77400, loss = 0.330163
I0725 19:22:56.143007 20892 solver.cpp:244]     Train net output #0: loss = 0.330163 (* 1 = 0.330163 loss)
I0725 19:22:56.143013 20892 sgd_solver.cpp:106] Iteration 77400, lr = 3.05038e-06
I0725 19:23:05.464339 20892 solver.cpp:337] Iteration 77500, Testing net (#0)
I0725 19:23:19.625857 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834581
I0725 19:23:19.625915 20892 solver.cpp:404]     Test net output #1: loss = 0.373968 (* 1 = 0.373968 loss)
I0725 19:23:19.654886 20892 solver.cpp:228] Iteration 77500, loss = 0.237389
I0725 19:23:19.654932 20892 solver.cpp:244]     Train net output #0: loss = 0.237389 (* 1 = 0.237389 loss)
I0725 19:23:19.654942 20892 sgd_solver.cpp:106] Iteration 77500, lr = 3.04803e-06
I0725 19:23:29.012392 20892 solver.cpp:228] Iteration 77600, loss = 0.321729
I0725 19:23:29.012444 20892 solver.cpp:244]     Train net output #0: loss = 0.321729 (* 1 = 0.321729 loss)
I0725 19:23:29.012450 20892 sgd_solver.cpp:106] Iteration 77600, lr = 3.04569e-06
I0725 19:23:38.426443 20892 solver.cpp:228] Iteration 77700, loss = 0.248513
I0725 19:23:38.426506 20892 solver.cpp:244]     Train net output #0: loss = 0.248513 (* 1 = 0.248513 loss)
I0725 19:23:38.426512 20892 sgd_solver.cpp:106] Iteration 77700, lr = 3.04335e-06
I0725 19:23:47.832413 20892 solver.cpp:228] Iteration 77800, loss = 0.268237
I0725 19:23:47.832450 20892 solver.cpp:244]     Train net output #0: loss = 0.268237 (* 1 = 0.268237 loss)
I0725 19:23:47.832456 20892 sgd_solver.cpp:106] Iteration 77800, lr = 3.04101e-06
I0725 19:23:56.017791 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:23:57.240813 20892 solver.cpp:228] Iteration 77900, loss = 0.276625
I0725 19:23:57.240852 20892 solver.cpp:244]     Train net output #0: loss = 0.276625 (* 1 = 0.276625 loss)
I0725 19:23:57.240859 20892 sgd_solver.cpp:106] Iteration 77900, lr = 3.03868e-06
I0725 19:24:06.557910 20892 solver.cpp:337] Iteration 78000, Testing net (#0)
I0725 19:24:20.750530 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835645
I0725 19:24:20.750603 20892 solver.cpp:404]     Test net output #1: loss = 0.371826 (* 1 = 0.371826 loss)
I0725 19:24:20.779583 20892 solver.cpp:228] Iteration 78000, loss = 0.340073
I0725 19:24:20.779623 20892 solver.cpp:244]     Train net output #0: loss = 0.340073 (* 1 = 0.340073 loss)
I0725 19:24:20.779634 20892 sgd_solver.cpp:106] Iteration 78000, lr = 3.03636e-06
I0725 19:24:30.124582 20892 solver.cpp:228] Iteration 78100, loss = 0.306052
I0725 19:24:30.124632 20892 solver.cpp:244]     Train net output #0: loss = 0.306052 (* 1 = 0.306052 loss)
I0725 19:24:30.124639 20892 sgd_solver.cpp:106] Iteration 78100, lr = 3.03404e-06
I0725 19:24:39.538756 20892 solver.cpp:228] Iteration 78200, loss = 0.320029
I0725 19:24:39.538810 20892 solver.cpp:244]     Train net output #0: loss = 0.320029 (* 1 = 0.320029 loss)
I0725 19:24:39.538817 20892 sgd_solver.cpp:106] Iteration 78200, lr = 3.03172e-06
I0725 19:24:48.946537 20892 solver.cpp:228] Iteration 78300, loss = 0.241949
I0725 19:24:48.946596 20892 solver.cpp:244]     Train net output #0: loss = 0.241949 (* 1 = 0.241949 loss)
I0725 19:24:48.946604 20892 sgd_solver.cpp:106] Iteration 78300, lr = 3.0294e-06
I0725 19:24:58.359508 20892 solver.cpp:228] Iteration 78400, loss = 0.199274
I0725 19:24:58.359557 20892 solver.cpp:244]     Train net output #0: loss = 0.199274 (* 1 = 0.199274 loss)
I0725 19:24:58.359565 20892 sgd_solver.cpp:106] Iteration 78400, lr = 3.0271e-06
I0725 19:25:07.678674 20892 solver.cpp:337] Iteration 78500, Testing net (#0)
I0725 19:25:21.713228 20892 solver.cpp:404]     Test net output #0: accuracy = 0.833419
I0725 19:25:21.713284 20892 solver.cpp:404]     Test net output #1: loss = 0.376161 (* 1 = 0.376161 loss)
I0725 19:25:21.742243 20892 solver.cpp:228] Iteration 78500, loss = 0.305512
I0725 19:25:21.742274 20892 solver.cpp:244]     Train net output #0: loss = 0.305512 (* 1 = 0.305512 loss)
I0725 19:25:21.742285 20892 sgd_solver.cpp:106] Iteration 78500, lr = 3.02479e-06
I0725 19:25:31.081022 20892 solver.cpp:228] Iteration 78600, loss = 0.366695
I0725 19:25:31.081063 20892 solver.cpp:244]     Train net output #0: loss = 0.366695 (* 1 = 0.366695 loss)
I0725 19:25:31.081069 20892 sgd_solver.cpp:106] Iteration 78600, lr = 3.02249e-06
I0725 19:25:40.483773 20892 solver.cpp:228] Iteration 78700, loss = 0.264037
I0725 19:25:40.483816 20892 solver.cpp:244]     Train net output #0: loss = 0.264037 (* 1 = 0.264037 loss)
I0725 19:25:40.483822 20892 sgd_solver.cpp:106] Iteration 78700, lr = 3.02019e-06
I0725 19:25:49.892659 20892 solver.cpp:228] Iteration 78800, loss = 0.287486
I0725 19:25:49.892699 20892 solver.cpp:244]     Train net output #0: loss = 0.287486 (* 1 = 0.287486 loss)
I0725 19:25:49.892704 20892 sgd_solver.cpp:106] Iteration 78800, lr = 3.0179e-06
I0725 19:25:59.302372 20892 solver.cpp:228] Iteration 78900, loss = 0.263452
I0725 19:25:59.302429 20892 solver.cpp:244]     Train net output #0: loss = 0.263452 (* 1 = 0.263452 loss)
I0725 19:25:59.302435 20892 sgd_solver.cpp:106] Iteration 78900, lr = 3.01561e-06
I0725 19:26:08.616905 20892 solver.cpp:337] Iteration 79000, Testing net (#0)
I0725 19:26:22.795965 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835194
I0725 19:26:22.796025 20892 solver.cpp:404]     Test net output #1: loss = 0.373178 (* 1 = 0.373178 loss)
I0725 19:26:22.825088 20892 solver.cpp:228] Iteration 79000, loss = 0.280039
I0725 19:26:22.825139 20892 solver.cpp:244]     Train net output #0: loss = 0.280039 (* 1 = 0.280039 loss)
I0725 19:26:22.825163 20892 sgd_solver.cpp:106] Iteration 79000, lr = 3.01333e-06
I0725 19:26:32.222666 20892 solver.cpp:228] Iteration 79100, loss = 0.303594
I0725 19:26:32.222707 20892 solver.cpp:244]     Train net output #0: loss = 0.303594 (* 1 = 0.303594 loss)
I0725 19:26:32.222713 20892 sgd_solver.cpp:106] Iteration 79100, lr = 3.01105e-06
I0725 19:26:41.642220 20892 solver.cpp:228] Iteration 79200, loss = 0.290988
I0725 19:26:41.642271 20892 solver.cpp:244]     Train net output #0: loss = 0.290988 (* 1 = 0.290988 loss)
I0725 19:26:41.642278 20892 sgd_solver.cpp:106] Iteration 79200, lr = 3.00877e-06
I0725 19:26:51.052014 20892 solver.cpp:228] Iteration 79300, loss = 0.246734
I0725 19:26:51.052070 20892 solver.cpp:244]     Train net output #0: loss = 0.246734 (* 1 = 0.246734 loss)
I0725 19:26:51.052078 20892 sgd_solver.cpp:106] Iteration 79300, lr = 3.0065e-06
I0725 19:27:00.470319 20892 solver.cpp:228] Iteration 79400, loss = 0.215607
I0725 19:27:00.470376 20892 solver.cpp:244]     Train net output #0: loss = 0.215607 (* 1 = 0.215607 loss)
I0725 19:27:00.470383 20892 sgd_solver.cpp:106] Iteration 79400, lr = 3.00423e-06
I0725 19:27:09.787257 20892 solver.cpp:337] Iteration 79500, Testing net (#0)
I0725 19:27:11.689723 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:27:23.930827 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834742
I0725 19:27:23.930869 20892 solver.cpp:404]     Test net output #1: loss = 0.374419 (* 1 = 0.374419 loss)
I0725 19:27:23.960289 20892 solver.cpp:228] Iteration 79500, loss = 0.304807
I0725 19:27:23.960357 20892 solver.cpp:244]     Train net output #0: loss = 0.304807 (* 1 = 0.304807 loss)
I0725 19:27:23.960376 20892 sgd_solver.cpp:106] Iteration 79500, lr = 3.00196e-06
I0725 19:27:33.337733 20892 solver.cpp:228] Iteration 79600, loss = 0.361278
I0725 19:27:33.337786 20892 solver.cpp:244]     Train net output #0: loss = 0.361278 (* 1 = 0.361278 loss)
I0725 19:27:33.337793 20892 sgd_solver.cpp:106] Iteration 79600, lr = 2.9997e-06
I0725 19:27:42.746114 20892 solver.cpp:228] Iteration 79700, loss = 0.355915
I0725 19:27:42.746163 20892 solver.cpp:244]     Train net output #0: loss = 0.355915 (* 1 = 0.355915 loss)
I0725 19:27:42.746170 20892 sgd_solver.cpp:106] Iteration 79700, lr = 2.99744e-06
I0725 19:27:52.148254 20892 solver.cpp:228] Iteration 79800, loss = 0.27711
I0725 19:27:52.148298 20892 solver.cpp:244]     Train net output #0: loss = 0.27711 (* 1 = 0.27711 loss)
I0725 19:27:52.148303 20892 sgd_solver.cpp:106] Iteration 79800, lr = 2.99519e-06
I0725 19:28:01.558281 20892 solver.cpp:228] Iteration 79900, loss = 0.329401
I0725 19:28:01.558323 20892 solver.cpp:244]     Train net output #0: loss = 0.329401 (* 1 = 0.329401 loss)
I0725 19:28:01.558331 20892 sgd_solver.cpp:106] Iteration 79900, lr = 2.99294e-06
I0725 19:28:10.873585 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_80000.caffemodel
I0725 19:28:11.226181 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_80000.solverstate
I0725 19:28:11.324959 20892 solver.cpp:337] Iteration 80000, Testing net (#0)
I0725 19:28:25.284235 20892 solver.cpp:404]     Test net output #0: accuracy = 0.830581
I0725 19:28:25.284278 20892 solver.cpp:404]     Test net output #1: loss = 0.38083 (* 1 = 0.38083 loss)
I0725 19:28:25.314131 20892 solver.cpp:228] Iteration 80000, loss = 0.262054
I0725 19:28:25.314168 20892 solver.cpp:244]     Train net output #0: loss = 0.262054 (* 1 = 0.262054 loss)
I0725 19:28:25.314178 20892 sgd_solver.cpp:106] Iteration 80000, lr = 2.9907e-06
I0725 19:28:34.710429 20892 solver.cpp:228] Iteration 80100, loss = 0.234112
I0725 19:28:34.710470 20892 solver.cpp:244]     Train net output #0: loss = 0.234112 (* 1 = 0.234112 loss)
I0725 19:28:34.710476 20892 sgd_solver.cpp:106] Iteration 80100, lr = 2.98846e-06
I0725 19:28:44.117262 20892 solver.cpp:228] Iteration 80200, loss = 0.278391
I0725 19:28:44.117300 20892 solver.cpp:244]     Train net output #0: loss = 0.278391 (* 1 = 0.278391 loss)
I0725 19:28:44.117306 20892 sgd_solver.cpp:106] Iteration 80200, lr = 2.98622e-06
I0725 19:28:53.523939 20892 solver.cpp:228] Iteration 80300, loss = 0.369231
I0725 19:28:53.523979 20892 solver.cpp:244]     Train net output #0: loss = 0.369231 (* 1 = 0.369231 loss)
I0725 19:28:53.523985 20892 sgd_solver.cpp:106] Iteration 80300, lr = 2.98399e-06
I0725 19:29:02.934837 20892 solver.cpp:228] Iteration 80400, loss = 0.273252
I0725 19:29:02.934880 20892 solver.cpp:244]     Train net output #0: loss = 0.273252 (* 1 = 0.273252 loss)
I0725 19:29:02.934886 20892 sgd_solver.cpp:106] Iteration 80400, lr = 2.98176e-06
I0725 19:29:12.255228 20892 solver.cpp:337] Iteration 80500, Testing net (#0)
I0725 19:29:26.317806 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834645
I0725 19:29:26.317863 20892 solver.cpp:404]     Test net output #1: loss = 0.373744 (* 1 = 0.373744 loss)
I0725 19:29:26.347347 20892 solver.cpp:228] Iteration 80500, loss = 0.519321
I0725 19:29:26.347398 20892 solver.cpp:244]     Train net output #0: loss = 0.519321 (* 1 = 0.519321 loss)
I0725 19:29:26.347424 20892 sgd_solver.cpp:106] Iteration 80500, lr = 2.97953e-06
I0725 19:29:35.677215 20892 solver.cpp:228] Iteration 80600, loss = 0.320782
I0725 19:29:35.677268 20892 solver.cpp:244]     Train net output #0: loss = 0.320782 (* 1 = 0.320782 loss)
I0725 19:29:35.677274 20892 sgd_solver.cpp:106] Iteration 80600, lr = 2.97731e-06
I0725 19:29:45.082087 20892 solver.cpp:228] Iteration 80700, loss = 0.301293
I0725 19:29:45.082130 20892 solver.cpp:244]     Train net output #0: loss = 0.301293 (* 1 = 0.301293 loss)
I0725 19:29:45.082137 20892 sgd_solver.cpp:106] Iteration 80700, lr = 2.97509e-06
I0725 19:29:54.490006 20892 solver.cpp:228] Iteration 80800, loss = 0.21245
I0725 19:29:54.490047 20892 solver.cpp:244]     Train net output #0: loss = 0.21245 (* 1 = 0.21245 loss)
I0725 19:29:54.490054 20892 sgd_solver.cpp:106] Iteration 80800, lr = 2.97288e-06
I0725 19:30:03.900167 20892 solver.cpp:228] Iteration 80900, loss = 0.238288
I0725 19:30:03.900209 20892 solver.cpp:244]     Train net output #0: loss = 0.238288 (* 1 = 0.238288 loss)
I0725 19:30:03.900216 20892 sgd_solver.cpp:106] Iteration 80900, lr = 2.97067e-06
I0725 19:30:13.213706 20892 solver.cpp:337] Iteration 81000, Testing net (#0)
I0725 19:30:16.788660 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:30:27.290737 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835548
I0725 19:30:27.290794 20892 solver.cpp:404]     Test net output #1: loss = 0.372409 (* 1 = 0.372409 loss)
I0725 19:30:27.320376 20892 solver.cpp:228] Iteration 81000, loss = 0.249001
I0725 19:30:27.320438 20892 solver.cpp:244]     Train net output #0: loss = 0.249001 (* 1 = 0.249001 loss)
I0725 19:30:27.320457 20892 sgd_solver.cpp:106] Iteration 81000, lr = 2.96846e-06
I0725 19:30:36.677500 20892 solver.cpp:228] Iteration 81100, loss = 0.224789
I0725 19:30:36.677538 20892 solver.cpp:244]     Train net output #0: loss = 0.224789 (* 1 = 0.224789 loss)
I0725 19:30:36.677544 20892 sgd_solver.cpp:106] Iteration 81100, lr = 2.96626e-06
I0725 19:30:46.078428 20892 solver.cpp:228] Iteration 81200, loss = 0.286375
I0725 19:30:46.078469 20892 solver.cpp:244]     Train net output #0: loss = 0.286375 (* 1 = 0.286375 loss)
I0725 19:30:46.078474 20892 sgd_solver.cpp:106] Iteration 81200, lr = 2.96406e-06
I0725 19:30:55.482076 20892 solver.cpp:228] Iteration 81300, loss = 0.291197
I0725 19:30:55.482112 20892 solver.cpp:244]     Train net output #0: loss = 0.291197 (* 1 = 0.291197 loss)
I0725 19:30:55.482118 20892 sgd_solver.cpp:106] Iteration 81300, lr = 2.96187e-06
I0725 19:31:04.888662 20892 solver.cpp:228] Iteration 81400, loss = 0.330494
I0725 19:31:04.888701 20892 solver.cpp:244]     Train net output #0: loss = 0.330494 (* 1 = 0.330494 loss)
I0725 19:31:04.888708 20892 sgd_solver.cpp:106] Iteration 81400, lr = 2.95968e-06
I0725 19:31:14.200683 20892 solver.cpp:337] Iteration 81500, Testing net (#0)
I0725 19:31:28.327061 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835226
I0725 19:31:28.327116 20892 solver.cpp:404]     Test net output #1: loss = 0.373302 (* 1 = 0.373302 loss)
I0725 19:31:28.357111 20892 solver.cpp:228] Iteration 81500, loss = 0.29835
I0725 19:31:28.357174 20892 solver.cpp:244]     Train net output #0: loss = 0.29835 (* 1 = 0.29835 loss)
I0725 19:31:28.357200 20892 sgd_solver.cpp:106] Iteration 81500, lr = 2.95749e-06
I0725 19:31:37.688652 20892 solver.cpp:228] Iteration 81600, loss = 0.333326
I0725 19:31:37.688699 20892 solver.cpp:244]     Train net output #0: loss = 0.333326 (* 1 = 0.333326 loss)
I0725 19:31:37.688706 20892 sgd_solver.cpp:106] Iteration 81600, lr = 2.9553e-06
I0725 19:31:47.097858 20892 solver.cpp:228] Iteration 81700, loss = 0.2865
I0725 19:31:47.097910 20892 solver.cpp:244]     Train net output #0: loss = 0.2865 (* 1 = 0.2865 loss)
I0725 19:31:47.097918 20892 sgd_solver.cpp:106] Iteration 81700, lr = 2.95312e-06
I0725 19:31:56.511947 20892 solver.cpp:228] Iteration 81800, loss = 0.259458
I0725 19:31:56.511988 20892 solver.cpp:244]     Train net output #0: loss = 0.259458 (* 1 = 0.259458 loss)
I0725 19:31:56.511994 20892 sgd_solver.cpp:106] Iteration 81800, lr = 2.95095e-06
I0725 19:32:05.924656 20892 solver.cpp:228] Iteration 81900, loss = 0.2803
I0725 19:32:05.924708 20892 solver.cpp:244]     Train net output #0: loss = 0.2803 (* 1 = 0.2803 loss)
I0725 19:32:05.924732 20892 sgd_solver.cpp:106] Iteration 81900, lr = 2.94878e-06
I0725 19:32:15.234321 20892 solver.cpp:337] Iteration 82000, Testing net (#0)
I0725 19:32:29.255013 20892 solver.cpp:404]     Test net output #0: accuracy = 0.827903
I0725 19:32:29.255064 20892 solver.cpp:404]     Test net output #1: loss = 0.385645 (* 1 = 0.385645 loss)
I0725 19:32:29.281934 20892 solver.cpp:228] Iteration 82000, loss = 0.517321
I0725 19:32:29.281998 20892 solver.cpp:244]     Train net output #0: loss = 0.517321 (* 1 = 0.517321 loss)
I0725 19:32:29.282017 20892 sgd_solver.cpp:106] Iteration 82000, lr = 2.94661e-06
I0725 19:32:38.789043 20892 solver.cpp:228] Iteration 82100, loss = 0.344505
I0725 19:32:38.789083 20892 solver.cpp:244]     Train net output #0: loss = 0.344505 (* 1 = 0.344505 loss)
I0725 19:32:38.789089 20892 sgd_solver.cpp:106] Iteration 82100, lr = 2.94444e-06
I0725 19:32:48.225515 20892 solver.cpp:228] Iteration 82200, loss = 0.319933
I0725 19:32:48.225556 20892 solver.cpp:244]     Train net output #0: loss = 0.319933 (* 1 = 0.319933 loss)
I0725 19:32:48.225564 20892 sgd_solver.cpp:106] Iteration 82200, lr = 2.94228e-06
I0725 19:32:57.612785 20892 solver.cpp:228] Iteration 82300, loss = 0.386858
I0725 19:32:57.612824 20892 solver.cpp:244]     Train net output #0: loss = 0.386858 (* 1 = 0.386858 loss)
I0725 19:32:57.612830 20892 sgd_solver.cpp:106] Iteration 82300, lr = 2.94012e-06
I0725 19:33:07.012493 20892 solver.cpp:228] Iteration 82400, loss = 0.250944
I0725 19:33:07.012540 20892 solver.cpp:244]     Train net output #0: loss = 0.250944 (* 1 = 0.250944 loss)
I0725 19:33:07.012547 20892 sgd_solver.cpp:106] Iteration 82400, lr = 2.93797e-06
I0725 19:33:16.337520 20892 solver.cpp:337] Iteration 82500, Testing net (#0)
I0725 19:33:17.679908 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:33:30.325723 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834678
I0725 19:33:30.325778 20892 solver.cpp:404]     Test net output #1: loss = 0.374561 (* 1 = 0.374561 loss)
I0725 19:33:30.352311 20892 solver.cpp:228] Iteration 82500, loss = 0.278246
I0725 19:33:30.352365 20892 solver.cpp:244]     Train net output #0: loss = 0.278246 (* 1 = 0.278246 loss)
I0725 19:33:30.352375 20892 sgd_solver.cpp:106] Iteration 82500, lr = 2.93582e-06
I0725 19:33:39.716641 20892 solver.cpp:228] Iteration 82600, loss = 0.221329
I0725 19:33:39.716699 20892 solver.cpp:244]     Train net output #0: loss = 0.221329 (* 1 = 0.221329 loss)
I0725 19:33:39.716706 20892 sgd_solver.cpp:106] Iteration 82600, lr = 2.93367e-06
I0725 19:33:49.124011 20892 solver.cpp:228] Iteration 82700, loss = 0.369202
I0725 19:33:49.124052 20892 solver.cpp:244]     Train net output #0: loss = 0.369202 (* 1 = 0.369202 loss)
I0725 19:33:49.124058 20892 sgd_solver.cpp:106] Iteration 82700, lr = 2.93153e-06
I0725 19:33:58.533968 20892 solver.cpp:228] Iteration 82800, loss = 0.239095
I0725 19:33:58.534011 20892 solver.cpp:244]     Train net output #0: loss = 0.239095 (* 1 = 0.239095 loss)
I0725 19:33:58.534018 20892 sgd_solver.cpp:106] Iteration 82800, lr = 2.92939e-06
I0725 19:34:07.948318 20892 solver.cpp:228] Iteration 82900, loss = 0.225948
I0725 19:34:07.948380 20892 solver.cpp:244]     Train net output #0: loss = 0.225948 (* 1 = 0.225948 loss)
I0725 19:34:07.948388 20892 sgd_solver.cpp:106] Iteration 82900, lr = 2.92726e-06
I0725 19:34:17.262739 20892 solver.cpp:337] Iteration 83000, Testing net (#0)
I0725 19:34:31.377121 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835742
I0725 19:34:31.377184 20892 solver.cpp:404]     Test net output #1: loss = 0.372802 (* 1 = 0.372802 loss)
I0725 19:34:31.404018 20892 solver.cpp:228] Iteration 83000, loss = 0.274998
I0725 19:34:31.404084 20892 solver.cpp:244]     Train net output #0: loss = 0.274998 (* 1 = 0.274998 loss)
I0725 19:34:31.404105 20892 sgd_solver.cpp:106] Iteration 83000, lr = 2.92513e-06
I0725 19:34:40.767072 20892 solver.cpp:228] Iteration 83100, loss = 0.254896
I0725 19:34:40.767112 20892 solver.cpp:244]     Train net output #0: loss = 0.254896 (* 1 = 0.254896 loss)
I0725 19:34:40.767118 20892 sgd_solver.cpp:106] Iteration 83100, lr = 2.923e-06
I0725 19:34:50.176185 20892 solver.cpp:228] Iteration 83200, loss = 0.311043
I0725 19:34:50.176239 20892 solver.cpp:244]     Train net output #0: loss = 0.311043 (* 1 = 0.311043 loss)
I0725 19:34:50.176245 20892 sgd_solver.cpp:106] Iteration 83200, lr = 2.92087e-06
I0725 19:34:59.583617 20892 solver.cpp:228] Iteration 83300, loss = 0.324118
I0725 19:34:59.583678 20892 solver.cpp:244]     Train net output #0: loss = 0.324118 (* 1 = 0.324118 loss)
I0725 19:34:59.583685 20892 sgd_solver.cpp:106] Iteration 83300, lr = 2.91875e-06
I0725 19:35:08.994561 20892 solver.cpp:228] Iteration 83400, loss = 0.339357
I0725 19:35:08.994603 20892 solver.cpp:244]     Train net output #0: loss = 0.339357 (* 1 = 0.339357 loss)
I0725 19:35:08.994609 20892 sgd_solver.cpp:106] Iteration 83400, lr = 2.91663e-06
I0725 19:35:18.311869 20892 solver.cpp:337] Iteration 83500, Testing net (#0)
I0725 19:35:32.401262 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835645
I0725 19:35:32.401309 20892 solver.cpp:404]     Test net output #1: loss = 0.371824 (* 1 = 0.371824 loss)
I0725 19:35:32.427853 20892 solver.cpp:228] Iteration 83500, loss = 0.286788
I0725 19:35:32.427899 20892 solver.cpp:244]     Train net output #0: loss = 0.286788 (* 1 = 0.286788 loss)
I0725 19:35:32.427909 20892 sgd_solver.cpp:106] Iteration 83500, lr = 2.91452e-06
I0725 19:35:41.806922 20892 solver.cpp:228] Iteration 83600, loss = 0.213319
I0725 19:35:41.806967 20892 solver.cpp:244]     Train net output #0: loss = 0.213319 (* 1 = 0.213319 loss)
I0725 19:35:41.806973 20892 sgd_solver.cpp:106] Iteration 83600, lr = 2.91241e-06
I0725 19:35:51.214100 20892 solver.cpp:228] Iteration 83700, loss = 0.298644
I0725 19:35:51.214154 20892 solver.cpp:244]     Train net output #0: loss = 0.298644 (* 1 = 0.298644 loss)
I0725 19:35:51.214159 20892 sgd_solver.cpp:106] Iteration 83700, lr = 2.9103e-06
I0725 19:36:00.622580 20892 solver.cpp:228] Iteration 83800, loss = 0.270565
I0725 19:36:00.622633 20892 solver.cpp:244]     Train net output #0: loss = 0.270565 (* 1 = 0.270565 loss)
I0725 19:36:00.622639 20892 sgd_solver.cpp:106] Iteration 83800, lr = 2.9082e-06
I0725 19:36:09.369343 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:36:10.027356 20892 solver.cpp:228] Iteration 83900, loss = 0.223256
I0725 19:36:10.027415 20892 solver.cpp:244]     Train net output #0: loss = 0.223256 (* 1 = 0.223256 loss)
I0725 19:36:10.027423 20892 sgd_solver.cpp:106] Iteration 83900, lr = 2.9061e-06
I0725 19:36:19.345664 20892 solver.cpp:337] Iteration 84000, Testing net (#0)
I0725 19:36:33.512543 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831936
I0725 19:36:33.512605 20892 solver.cpp:404]     Test net output #1: loss = 0.37908 (* 1 = 0.37908 loss)
I0725 19:36:33.541723 20892 solver.cpp:228] Iteration 84000, loss = 0.303954
I0725 19:36:33.541759 20892 solver.cpp:244]     Train net output #0: loss = 0.303954 (* 1 = 0.303954 loss)
I0725 19:36:33.541772 20892 sgd_solver.cpp:106] Iteration 84000, lr = 2.90401e-06
I0725 19:36:42.919167 20892 solver.cpp:228] Iteration 84100, loss = 0.395567
I0725 19:36:42.919221 20892 solver.cpp:244]     Train net output #0: loss = 0.395567 (* 1 = 0.395567 loss)
I0725 19:36:42.919229 20892 sgd_solver.cpp:106] Iteration 84100, lr = 2.90191e-06
I0725 19:36:52.327812 20892 solver.cpp:228] Iteration 84200, loss = 0.202412
I0725 19:36:52.327859 20892 solver.cpp:244]     Train net output #0: loss = 0.202412 (* 1 = 0.202412 loss)
I0725 19:36:52.327867 20892 sgd_solver.cpp:106] Iteration 84200, lr = 2.89982e-06
I0725 19:37:01.729252 20892 solver.cpp:228] Iteration 84300, loss = 0.211527
I0725 19:37:01.729295 20892 solver.cpp:244]     Train net output #0: loss = 0.211527 (* 1 = 0.211527 loss)
I0725 19:37:01.729302 20892 sgd_solver.cpp:106] Iteration 84300, lr = 2.89774e-06
I0725 19:37:11.139698 20892 solver.cpp:228] Iteration 84400, loss = 0.286042
I0725 19:37:11.139742 20892 solver.cpp:244]     Train net output #0: loss = 0.286042 (* 1 = 0.286042 loss)
I0725 19:37:11.139750 20892 sgd_solver.cpp:106] Iteration 84400, lr = 2.89566e-06
I0725 19:37:20.442231 20892 solver.cpp:337] Iteration 84500, Testing net (#0)
I0725 19:37:34.635788 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836387
I0725 19:37:34.635853 20892 solver.cpp:404]     Test net output #1: loss = 0.371505 (* 1 = 0.371505 loss)
I0725 19:37:34.667130 20892 solver.cpp:228] Iteration 84500, loss = 0.296141
I0725 19:37:34.667191 20892 solver.cpp:244]     Train net output #0: loss = 0.296141 (* 1 = 0.296141 loss)
I0725 19:37:34.667207 20892 sgd_solver.cpp:106] Iteration 84500, lr = 2.89358e-06
I0725 19:37:44.130746 20892 solver.cpp:228] Iteration 84600, loss = 0.363994
I0725 19:37:44.130786 20892 solver.cpp:244]     Train net output #0: loss = 0.363994 (* 1 = 0.363994 loss)
I0725 19:37:44.130794 20892 sgd_solver.cpp:106] Iteration 84600, lr = 2.8915e-06
I0725 19:37:53.646895 20892 solver.cpp:228] Iteration 84700, loss = 0.300328
I0725 19:37:53.646950 20892 solver.cpp:244]     Train net output #0: loss = 0.300328 (* 1 = 0.300328 loss)
I0725 19:37:53.646957 20892 sgd_solver.cpp:106] Iteration 84700, lr = 2.88943e-06
I0725 19:38:03.048086 20892 solver.cpp:228] Iteration 84800, loss = 0.258759
I0725 19:38:03.048125 20892 solver.cpp:244]     Train net output #0: loss = 0.258759 (* 1 = 0.258759 loss)
I0725 19:38:03.048130 20892 sgd_solver.cpp:106] Iteration 84800, lr = 2.88736e-06
I0725 19:38:12.438670 20892 solver.cpp:228] Iteration 84900, loss = 0.334783
I0725 19:38:12.438709 20892 solver.cpp:244]     Train net output #0: loss = 0.334783 (* 1 = 0.334783 loss)
I0725 19:38:12.438714 20892 sgd_solver.cpp:106] Iteration 84900, lr = 2.8853e-06
I0725 19:38:21.671160 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_85000.caffemodel
I0725 19:38:22.027179 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_85000.solverstate
I0725 19:38:22.126961 20892 solver.cpp:337] Iteration 85000, Testing net (#0)
I0725 19:38:36.182812 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836258
I0725 19:38:36.182862 20892 solver.cpp:404]     Test net output #1: loss = 0.372615 (* 1 = 0.372615 loss)
I0725 19:38:36.212438 20892 solver.cpp:228] Iteration 85000, loss = 0.231089
I0725 19:38:36.212497 20892 solver.cpp:244]     Train net output #0: loss = 0.231089 (* 1 = 0.231089 loss)
I0725 19:38:36.212507 20892 sgd_solver.cpp:106] Iteration 85000, lr = 2.88324e-06
I0725 19:38:45.595830 20892 solver.cpp:228] Iteration 85100, loss = 0.260937
I0725 19:38:45.595887 20892 solver.cpp:244]     Train net output #0: loss = 0.260937 (* 1 = 0.260937 loss)
I0725 19:38:45.595895 20892 sgd_solver.cpp:106] Iteration 85100, lr = 2.88118e-06
I0725 19:38:55.004727 20892 solver.cpp:228] Iteration 85200, loss = 0.190873
I0725 19:38:55.004771 20892 solver.cpp:244]     Train net output #0: loss = 0.190873 (* 1 = 0.190873 loss)
I0725 19:38:55.004777 20892 sgd_solver.cpp:106] Iteration 85200, lr = 2.87913e-06
I0725 19:39:04.419005 20892 solver.cpp:228] Iteration 85300, loss = 0.263174
I0725 19:39:04.419054 20892 solver.cpp:244]     Train net output #0: loss = 0.263174 (* 1 = 0.263174 loss)
I0725 19:39:04.419059 20892 sgd_solver.cpp:106] Iteration 85300, lr = 2.87708e-06
I0725 19:39:07.996289 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:39:13.831468 20892 solver.cpp:228] Iteration 85400, loss = 0.268654
I0725 19:39:13.831516 20892 solver.cpp:244]     Train net output #0: loss = 0.268654 (* 1 = 0.268654 loss)
I0725 19:39:13.831522 20892 sgd_solver.cpp:106] Iteration 85400, lr = 2.87503e-06
I0725 19:39:23.149456 20892 solver.cpp:337] Iteration 85500, Testing net (#0)
I0725 19:39:37.319077 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836
I0725 19:39:37.319121 20892 solver.cpp:404]     Test net output #1: loss = 0.371404 (* 1 = 0.371404 loss)
I0725 19:39:37.345824 20892 solver.cpp:228] Iteration 85500, loss = 0.354203
I0725 19:39:37.345868 20892 solver.cpp:244]     Train net output #0: loss = 0.354203 (* 1 = 0.354203 loss)
I0725 19:39:37.345877 20892 sgd_solver.cpp:106] Iteration 85500, lr = 2.87298e-06
I0725 19:39:46.751521 20892 solver.cpp:228] Iteration 85600, loss = 0.213591
I0725 19:39:46.751560 20892 solver.cpp:244]     Train net output #0: loss = 0.213591 (* 1 = 0.213591 loss)
I0725 19:39:46.751566 20892 sgd_solver.cpp:106] Iteration 85600, lr = 2.87094e-06
I0725 19:39:56.155959 20892 solver.cpp:228] Iteration 85700, loss = 0.271889
I0725 19:39:56.155998 20892 solver.cpp:244]     Train net output #0: loss = 0.271889 (* 1 = 0.271889 loss)
I0725 19:39:56.156004 20892 sgd_solver.cpp:106] Iteration 85700, lr = 2.86891e-06
I0725 19:40:05.564057 20892 solver.cpp:228] Iteration 85800, loss = 0.271507
I0725 19:40:05.564105 20892 solver.cpp:244]     Train net output #0: loss = 0.271507 (* 1 = 0.271507 loss)
I0725 19:40:05.564112 20892 sgd_solver.cpp:106] Iteration 85800, lr = 2.86687e-06
I0725 19:40:14.967061 20892 solver.cpp:228] Iteration 85900, loss = 0.359969
I0725 19:40:14.967103 20892 solver.cpp:244]     Train net output #0: loss = 0.359969 (* 1 = 0.359969 loss)
I0725 19:40:14.967109 20892 sgd_solver.cpp:106] Iteration 85900, lr = 2.86484e-06
I0725 19:40:24.275831 20892 solver.cpp:337] Iteration 86000, Testing net (#0)
I0725 19:40:38.396272 20892 solver.cpp:404]     Test net output #0: accuracy = 0.834936
I0725 19:40:38.396343 20892 solver.cpp:404]     Test net output #1: loss = 0.374028 (* 1 = 0.374028 loss)
I0725 19:40:38.427368 20892 solver.cpp:228] Iteration 86000, loss = 0.306207
I0725 19:40:38.427434 20892 solver.cpp:244]     Train net output #0: loss = 0.306207 (* 1 = 0.306207 loss)
I0725 19:40:38.427448 20892 sgd_solver.cpp:106] Iteration 86000, lr = 2.86281e-06
I0725 19:40:47.845201 20892 solver.cpp:228] Iteration 86100, loss = 0.262263
I0725 19:40:47.845242 20892 solver.cpp:244]     Train net output #0: loss = 0.262263 (* 1 = 0.262263 loss)
I0725 19:40:47.845249 20892 sgd_solver.cpp:106] Iteration 86100, lr = 2.86079e-06
I0725 19:40:57.414482 20892 solver.cpp:228] Iteration 86200, loss = 0.259279
I0725 19:40:57.414607 20892 solver.cpp:244]     Train net output #0: loss = 0.259279 (* 1 = 0.259279 loss)
I0725 19:40:57.414636 20892 sgd_solver.cpp:106] Iteration 86200, lr = 2.85877e-06
I0725 19:41:06.817383 20892 solver.cpp:228] Iteration 86300, loss = 0.234494
I0725 19:41:06.817436 20892 solver.cpp:244]     Train net output #0: loss = 0.234494 (* 1 = 0.234494 loss)
I0725 19:41:06.817442 20892 sgd_solver.cpp:106] Iteration 86300, lr = 2.85675e-06
I0725 19:41:16.149647 20892 solver.cpp:228] Iteration 86400, loss = 0.2774
I0725 19:41:16.149690 20892 solver.cpp:244]     Train net output #0: loss = 0.2774 (* 1 = 0.2774 loss)
I0725 19:41:16.149696 20892 sgd_solver.cpp:106] Iteration 86400, lr = 2.85474e-06
I0725 19:41:25.562271 20892 solver.cpp:337] Iteration 86500, Testing net (#0)
I0725 19:41:39.681660 20892 solver.cpp:404]     Test net output #0: accuracy = 0.83629
I0725 19:41:39.681715 20892 solver.cpp:404]     Test net output #1: loss = 0.372023 (* 1 = 0.372023 loss)
I0725 19:41:39.710695 20892 solver.cpp:228] Iteration 86500, loss = 0.279936
I0725 19:41:39.710750 20892 solver.cpp:244]     Train net output #0: loss = 0.279936 (* 1 = 0.279936 loss)
I0725 19:41:39.710762 20892 sgd_solver.cpp:106] Iteration 86500, lr = 2.85273e-06
I0725 19:41:49.072849 20892 solver.cpp:228] Iteration 86600, loss = 0.324198
I0725 19:41:49.072899 20892 solver.cpp:244]     Train net output #0: loss = 0.324198 (* 1 = 0.324198 loss)
I0725 19:41:49.072907 20892 sgd_solver.cpp:106] Iteration 86600, lr = 2.85072e-06
I0725 19:41:58.478940 20892 solver.cpp:228] Iteration 86700, loss = 0.29728
I0725 19:41:58.478992 20892 solver.cpp:244]     Train net output #0: loss = 0.29728 (* 1 = 0.29728 loss)
I0725 19:41:58.478999 20892 sgd_solver.cpp:106] Iteration 86700, lr = 2.84872e-06
I0725 19:42:07.886989 20892 solver.cpp:228] Iteration 86800, loss = 0.250902
I0725 19:42:07.887044 20892 solver.cpp:244]     Train net output #0: loss = 0.250902 (* 1 = 0.250902 loss)
I0725 19:42:07.887051 20892 sgd_solver.cpp:106] Iteration 86800, lr = 2.84672e-06
I0725 19:42:14.564157 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:42:17.290477 20892 solver.cpp:228] Iteration 86900, loss = 0.314634
I0725 19:42:17.290539 20892 solver.cpp:244]     Train net output #0: loss = 0.314634 (* 1 = 0.314634 loss)
I0725 19:42:17.290547 20892 sgd_solver.cpp:106] Iteration 86900, lr = 2.84472e-06
I0725 19:42:26.622172 20892 solver.cpp:337] Iteration 87000, Testing net (#0)
I0725 19:42:40.687293 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835968
I0725 19:42:40.687345 20892 solver.cpp:404]     Test net output #1: loss = 0.372742 (* 1 = 0.372742 loss)
I0725 19:42:40.719108 20892 solver.cpp:228] Iteration 87000, loss = 0.240872
I0725 19:42:40.719167 20892 solver.cpp:244]     Train net output #0: loss = 0.240872 (* 1 = 0.240872 loss)
I0725 19:42:40.719188 20892 sgd_solver.cpp:106] Iteration 87000, lr = 2.84272e-06
I0725 19:42:50.087745 20892 solver.cpp:228] Iteration 87100, loss = 0.376356
I0725 19:42:50.087790 20892 solver.cpp:244]     Train net output #0: loss = 0.376356 (* 1 = 0.376356 loss)
I0725 19:42:50.087795 20892 sgd_solver.cpp:106] Iteration 87100, lr = 2.84073e-06
I0725 19:42:59.488203 20892 solver.cpp:228] Iteration 87200, loss = 0.381691
I0725 19:42:59.488242 20892 solver.cpp:244]     Train net output #0: loss = 0.381691 (* 1 = 0.381691 loss)
I0725 19:42:59.488248 20892 sgd_solver.cpp:106] Iteration 87200, lr = 2.83875e-06
I0725 19:43:08.889474 20892 solver.cpp:228] Iteration 87300, loss = 0.300974
I0725 19:43:08.889518 20892 solver.cpp:244]     Train net output #0: loss = 0.300974 (* 1 = 0.300974 loss)
I0725 19:43:08.889523 20892 sgd_solver.cpp:106] Iteration 87300, lr = 2.83676e-06
I0725 19:43:18.297240 20892 solver.cpp:228] Iteration 87400, loss = 0.308979
I0725 19:43:18.297293 20892 solver.cpp:244]     Train net output #0: loss = 0.308979 (* 1 = 0.308979 loss)
I0725 19:43:18.297299 20892 sgd_solver.cpp:106] Iteration 87400, lr = 2.83478e-06
I0725 19:43:27.603262 20892 solver.cpp:337] Iteration 87500, Testing net (#0)
I0725 19:43:41.728641 20892 solver.cpp:404]     Test net output #0: accuracy = 0.83071
I0725 19:43:41.728687 20892 solver.cpp:404]     Test net output #1: loss = 0.380773 (* 1 = 0.380773 loss)
I0725 19:43:41.757603 20892 solver.cpp:228] Iteration 87500, loss = 0.272401
I0725 19:43:41.757648 20892 solver.cpp:244]     Train net output #0: loss = 0.272401 (* 1 = 0.272401 loss)
I0725 19:43:41.757658 20892 sgd_solver.cpp:106] Iteration 87500, lr = 2.8328e-06
I0725 19:43:51.143012 20892 solver.cpp:228] Iteration 87600, loss = 0.278679
I0725 19:43:51.143056 20892 solver.cpp:244]     Train net output #0: loss = 0.278679 (* 1 = 0.278679 loss)
I0725 19:43:51.143062 20892 sgd_solver.cpp:106] Iteration 87600, lr = 2.83083e-06
I0725 19:44:00.548136 20892 solver.cpp:228] Iteration 87700, loss = 0.401318
I0725 19:44:00.548180 20892 solver.cpp:244]     Train net output #0: loss = 0.401318 (* 1 = 0.401318 loss)
I0725 19:44:00.548187 20892 sgd_solver.cpp:106] Iteration 87700, lr = 2.82886e-06
I0725 19:44:09.949942 20892 solver.cpp:228] Iteration 87800, loss = 0.305161
I0725 19:44:09.949990 20892 solver.cpp:244]     Train net output #0: loss = 0.305161 (* 1 = 0.305161 loss)
I0725 19:44:09.949996 20892 sgd_solver.cpp:106] Iteration 87800, lr = 2.82689e-06
I0725 19:44:19.349587 20892 solver.cpp:228] Iteration 87900, loss = 0.299471
I0725 19:44:19.349643 20892 solver.cpp:244]     Train net output #0: loss = 0.299471 (* 1 = 0.299471 loss)
I0725 19:44:19.349650 20892 sgd_solver.cpp:106] Iteration 87900, lr = 2.82492e-06
I0725 19:44:28.653808 20892 solver.cpp:337] Iteration 88000, Testing net (#0)
I0725 19:44:42.767710 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836742
I0725 19:44:42.767755 20892 solver.cpp:404]     Test net output #1: loss = 0.371755 (* 1 = 0.371755 loss)
I0725 19:44:42.797871 20892 solver.cpp:228] Iteration 88000, loss = 0.275066
I0725 19:44:42.797916 20892 solver.cpp:244]     Train net output #0: loss = 0.275066 (* 1 = 0.275066 loss)
I0725 19:44:42.797926 20892 sgd_solver.cpp:106] Iteration 88000, lr = 2.82296e-06
I0725 19:44:52.139034 20892 solver.cpp:228] Iteration 88100, loss = 0.298092
I0725 19:44:52.139088 20892 solver.cpp:244]     Train net output #0: loss = 0.298092 (* 1 = 0.298092 loss)
I0725 19:44:52.139096 20892 sgd_solver.cpp:106] Iteration 88100, lr = 2.821e-06
I0725 19:45:01.555078 20892 solver.cpp:228] Iteration 88200, loss = 0.244484
I0725 19:45:01.555124 20892 solver.cpp:244]     Train net output #0: loss = 0.244484 (* 1 = 0.244484 loss)
I0725 19:45:01.555131 20892 sgd_solver.cpp:106] Iteration 88200, lr = 2.81905e-06
I0725 19:45:10.966924 20892 solver.cpp:228] Iteration 88300, loss = 0.361809
I0725 19:45:10.966964 20892 solver.cpp:244]     Train net output #0: loss = 0.361809 (* 1 = 0.361809 loss)
I0725 19:45:10.966969 20892 sgd_solver.cpp:106] Iteration 88300, lr = 2.81709e-06
I0725 19:45:20.352362 20892 solver.cpp:228] Iteration 88400, loss = 0.318042
I0725 19:45:20.352411 20892 solver.cpp:244]     Train net output #0: loss = 0.318042 (* 1 = 0.318042 loss)
I0725 19:45:20.352418 20892 sgd_solver.cpp:106] Iteration 88400, lr = 2.81514e-06
I0725 19:45:29.598497 20892 solver.cpp:337] Iteration 88500, Testing net (#0)
I0725 19:45:31.748932 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:45:43.653656 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837097
I0725 19:45:43.653723 20892 solver.cpp:404]     Test net output #1: loss = 0.371542 (* 1 = 0.371542 loss)
I0725 19:45:43.682745 20892 solver.cpp:228] Iteration 88500, loss = 0.313651
I0725 19:45:43.682795 20892 solver.cpp:244]     Train net output #0: loss = 0.313651 (* 1 = 0.313651 loss)
I0725 19:45:43.682804 20892 sgd_solver.cpp:106] Iteration 88500, lr = 2.8132e-06
I0725 19:45:53.069216 20892 solver.cpp:228] Iteration 88600, loss = 0.276024
I0725 19:45:53.069253 20892 solver.cpp:244]     Train net output #0: loss = 0.276024 (* 1 = 0.276024 loss)
I0725 19:45:53.069259 20892 sgd_solver.cpp:106] Iteration 88600, lr = 2.81125e-06
I0725 19:46:02.482465 20892 solver.cpp:228] Iteration 88700, loss = 0.196802
I0725 19:46:02.482503 20892 solver.cpp:244]     Train net output #0: loss = 0.196802 (* 1 = 0.196802 loss)
I0725 19:46:02.482509 20892 sgd_solver.cpp:106] Iteration 88700, lr = 2.80931e-06
I0725 19:46:11.889242 20892 solver.cpp:228] Iteration 88800, loss = 0.306694
I0725 19:46:11.889295 20892 solver.cpp:244]     Train net output #0: loss = 0.306694 (* 1 = 0.306694 loss)
I0725 19:46:11.889302 20892 sgd_solver.cpp:106] Iteration 88800, lr = 2.80738e-06
I0725 19:46:21.298475 20892 solver.cpp:228] Iteration 88900, loss = 0.374454
I0725 19:46:21.298516 20892 solver.cpp:244]     Train net output #0: loss = 0.374454 (* 1 = 0.374454 loss)
I0725 19:46:21.298522 20892 sgd_solver.cpp:106] Iteration 88900, lr = 2.80544e-06
I0725 19:46:30.616817 20892 solver.cpp:337] Iteration 89000, Testing net (#0)
I0725 19:46:44.633365 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836549
I0725 19:46:44.633411 20892 solver.cpp:404]     Test net output #1: loss = 0.371638 (* 1 = 0.371638 loss)
I0725 19:46:44.659921 20892 solver.cpp:228] Iteration 89000, loss = 0.255116
I0725 19:46:44.659955 20892 solver.cpp:244]     Train net output #0: loss = 0.255116 (* 1 = 0.255116 loss)
I0725 19:46:44.659965 20892 sgd_solver.cpp:106] Iteration 89000, lr = 2.80351e-06
I0725 19:46:54.013993 20892 solver.cpp:228] Iteration 89100, loss = 0.449789
I0725 19:46:54.014045 20892 solver.cpp:244]     Train net output #0: loss = 0.449789 (* 1 = 0.449789 loss)
I0725 19:46:54.014052 20892 sgd_solver.cpp:106] Iteration 89100, lr = 2.80159e-06
I0725 19:47:03.424895 20892 solver.cpp:228] Iteration 89200, loss = 0.280762
I0725 19:47:03.424937 20892 solver.cpp:244]     Train net output #0: loss = 0.280762 (* 1 = 0.280762 loss)
I0725 19:47:03.424943 20892 sgd_solver.cpp:106] Iteration 89200, lr = 2.79966e-06
I0725 19:47:12.831730 20892 solver.cpp:228] Iteration 89300, loss = 0.334057
I0725 19:47:12.831787 20892 solver.cpp:244]     Train net output #0: loss = 0.334057 (* 1 = 0.334057 loss)
I0725 19:47:12.831794 20892 sgd_solver.cpp:106] Iteration 89300, lr = 2.79774e-06
I0725 19:47:22.250525 20892 solver.cpp:228] Iteration 89400, loss = 0.30499
I0725 19:47:22.250581 20892 solver.cpp:244]     Train net output #0: loss = 0.30499 (* 1 = 0.30499 loss)
I0725 19:47:22.250588 20892 sgd_solver.cpp:106] Iteration 89400, lr = 2.79582e-06
I0725 19:47:31.568563 20892 solver.cpp:337] Iteration 89500, Testing net (#0)
I0725 19:47:45.656808 20892 solver.cpp:404]     Test net output #0: accuracy = 0.829097
I0725 19:47:45.656883 20892 solver.cpp:404]     Test net output #1: loss = 0.384329 (* 1 = 0.384329 loss)
I0725 19:47:45.685835 20892 solver.cpp:228] Iteration 89500, loss = 0.240873
I0725 19:47:45.685896 20892 solver.cpp:244]     Train net output #0: loss = 0.240873 (* 1 = 0.240873 loss)
I0725 19:47:45.685906 20892 sgd_solver.cpp:106] Iteration 89500, lr = 2.79391e-06
I0725 19:47:55.055299 20892 solver.cpp:228] Iteration 89600, loss = 0.294189
I0725 19:47:55.055346 20892 solver.cpp:244]     Train net output #0: loss = 0.294189 (* 1 = 0.294189 loss)
I0725 19:47:55.055352 20892 sgd_solver.cpp:106] Iteration 89600, lr = 2.79199e-06
I0725 19:48:04.474601 20892 solver.cpp:228] Iteration 89700, loss = 0.235733
I0725 19:48:04.474647 20892 solver.cpp:244]     Train net output #0: loss = 0.235733 (* 1 = 0.235733 loss)
I0725 19:48:04.474653 20892 sgd_solver.cpp:106] Iteration 89700, lr = 2.79009e-06
I0725 19:48:13.885586 20892 solver.cpp:228] Iteration 89800, loss = 0.273553
I0725 19:48:13.885635 20892 solver.cpp:244]     Train net output #0: loss = 0.273553 (* 1 = 0.273553 loss)
I0725 19:48:13.885643 20892 sgd_solver.cpp:106] Iteration 89800, lr = 2.78818e-06
I0725 19:48:23.294008 20892 solver.cpp:228] Iteration 89900, loss = 0.226964
I0725 19:48:23.294050 20892 solver.cpp:244]     Train net output #0: loss = 0.226964 (* 1 = 0.226964 loss)
I0725 19:48:23.294056 20892 sgd_solver.cpp:106] Iteration 89900, lr = 2.78628e-06
I0725 19:48:32.609866 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_90000.caffemodel
I0725 19:48:32.962951 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_90000.solverstate
I0725 19:48:33.060644 20892 solver.cpp:337] Iteration 90000, Testing net (#0)
I0725 19:48:35.434648 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:48:47.044256 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835807
I0725 19:48:47.044315 20892 solver.cpp:404]     Test net output #1: loss = 0.373306 (* 1 = 0.373306 loss)
I0725 19:48:47.073673 20892 solver.cpp:228] Iteration 90000, loss = 0.260227
I0725 19:48:47.073745 20892 solver.cpp:244]     Train net output #0: loss = 0.260227 (* 1 = 0.260227 loss)
I0725 19:48:47.073755 20892 sgd_solver.cpp:106] Iteration 90000, lr = 2.78438e-06
I0725 19:48:56.475234 20892 solver.cpp:228] Iteration 90100, loss = 0.286687
I0725 19:48:56.475277 20892 solver.cpp:244]     Train net output #0: loss = 0.286687 (* 1 = 0.286687 loss)
I0725 19:48:56.475283 20892 sgd_solver.cpp:106] Iteration 90100, lr = 2.78248e-06
I0725 19:49:05.878583 20892 solver.cpp:228] Iteration 90200, loss = 0.327222
I0725 19:49:05.878629 20892 solver.cpp:244]     Train net output #0: loss = 0.327222 (* 1 = 0.327222 loss)
I0725 19:49:05.878634 20892 sgd_solver.cpp:106] Iteration 90200, lr = 2.78059e-06
I0725 19:49:15.287614 20892 solver.cpp:228] Iteration 90300, loss = 0.364232
I0725 19:49:15.287679 20892 solver.cpp:244]     Train net output #0: loss = 0.364232 (* 1 = 0.364232 loss)
I0725 19:49:15.287686 20892 sgd_solver.cpp:106] Iteration 90300, lr = 2.77869e-06
I0725 19:49:24.697202 20892 solver.cpp:228] Iteration 90400, loss = 0.315981
I0725 19:49:24.697242 20892 solver.cpp:244]     Train net output #0: loss = 0.315981 (* 1 = 0.315981 loss)
I0725 19:49:24.697248 20892 sgd_solver.cpp:106] Iteration 90400, lr = 2.77681e-06
I0725 19:49:33.999619 20892 solver.cpp:337] Iteration 90500, Testing net (#0)
I0725 19:49:48.151360 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836968
I0725 19:49:48.151408 20892 solver.cpp:404]     Test net output #1: loss = 0.371708 (* 1 = 0.371708 loss)
I0725 19:49:48.177793 20892 solver.cpp:228] Iteration 90500, loss = 0.276114
I0725 19:49:48.177855 20892 solver.cpp:244]     Train net output #0: loss = 0.276114 (* 1 = 0.276114 loss)
I0725 19:49:48.177866 20892 sgd_solver.cpp:106] Iteration 90500, lr = 2.77492e-06
I0725 19:49:57.537070 20892 solver.cpp:228] Iteration 90600, loss = 0.305131
I0725 19:49:57.537111 20892 solver.cpp:244]     Train net output #0: loss = 0.305131 (* 1 = 0.305131 loss)
I0725 19:49:57.537117 20892 sgd_solver.cpp:106] Iteration 90600, lr = 2.77304e-06
I0725 19:50:06.943524 20892 solver.cpp:228] Iteration 90700, loss = 0.302785
I0725 19:50:06.943583 20892 solver.cpp:244]     Train net output #0: loss = 0.302785 (* 1 = 0.302785 loss)
I0725 19:50:06.943589 20892 sgd_solver.cpp:106] Iteration 90700, lr = 2.77116e-06
I0725 19:50:16.354440 20892 solver.cpp:228] Iteration 90800, loss = 0.207669
I0725 19:50:16.354482 20892 solver.cpp:244]     Train net output #0: loss = 0.207669 (* 1 = 0.207669 loss)
I0725 19:50:16.354488 20892 sgd_solver.cpp:106] Iteration 90800, lr = 2.76929e-06
I0725 19:50:25.759711 20892 solver.cpp:228] Iteration 90900, loss = 0.377435
I0725 19:50:25.759749 20892 solver.cpp:244]     Train net output #0: loss = 0.377435 (* 1 = 0.377435 loss)
I0725 19:50:25.759755 20892 sgd_solver.cpp:106] Iteration 90900, lr = 2.76741e-06
I0725 19:50:35.027930 20892 solver.cpp:337] Iteration 91000, Testing net (#0)
I0725 19:50:49.117725 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837645
I0725 19:50:49.117776 20892 solver.cpp:404]     Test net output #1: loss = 0.369494 (* 1 = 0.369494 loss)
I0725 19:50:49.147212 20892 solver.cpp:228] Iteration 91000, loss = 0.210047
I0725 19:50:49.147264 20892 solver.cpp:244]     Train net output #0: loss = 0.210047 (* 1 = 0.210047 loss)
I0725 19:50:49.147276 20892 sgd_solver.cpp:106] Iteration 91000, lr = 2.76554e-06
I0725 19:50:58.531782 20892 solver.cpp:228] Iteration 91100, loss = 0.310565
I0725 19:50:58.531823 20892 solver.cpp:244]     Train net output #0: loss = 0.310565 (* 1 = 0.310565 loss)
I0725 19:50:58.531831 20892 sgd_solver.cpp:106] Iteration 91100, lr = 2.76367e-06
I0725 19:51:07.942123 20892 solver.cpp:228] Iteration 91200, loss = 0.268318
I0725 19:51:07.942179 20892 solver.cpp:244]     Train net output #0: loss = 0.268318 (* 1 = 0.268318 loss)
I0725 19:51:07.942186 20892 sgd_solver.cpp:106] Iteration 91200, lr = 2.76181e-06
I0725 19:51:17.351258 20892 solver.cpp:228] Iteration 91300, loss = 0.247866
I0725 19:51:17.351303 20892 solver.cpp:244]     Train net output #0: loss = 0.247866 (* 1 = 0.247866 loss)
I0725 19:51:17.351310 20892 sgd_solver.cpp:106] Iteration 91300, lr = 2.75995e-06
I0725 19:51:26.766041 20892 solver.cpp:228] Iteration 91400, loss = 0.321578
I0725 19:51:26.766094 20892 solver.cpp:244]     Train net output #0: loss = 0.321578 (* 1 = 0.321578 loss)
I0725 19:51:26.766103 20892 sgd_solver.cpp:106] Iteration 91400, lr = 2.75809e-06
I0725 19:51:36.096868 20892 solver.cpp:337] Iteration 91500, Testing net (#0)
I0725 19:51:36.785059 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:51:50.266623 20892 solver.cpp:404]     Test net output #0: accuracy = 0.83358
I0725 19:51:50.266688 20892 solver.cpp:404]     Test net output #1: loss = 0.377042 (* 1 = 0.377042 loss)
I0725 19:51:50.297683 20892 solver.cpp:228] Iteration 91500, loss = 0.259009
I0725 19:51:50.297715 20892 solver.cpp:244]     Train net output #0: loss = 0.259009 (* 1 = 0.259009 loss)
I0725 19:51:50.297729 20892 sgd_solver.cpp:106] Iteration 91500, lr = 2.75624e-06
I0725 19:51:59.621454 20892 solver.cpp:228] Iteration 91600, loss = 0.238381
I0725 19:51:59.621507 20892 solver.cpp:244]     Train net output #0: loss = 0.238381 (* 1 = 0.238381 loss)
I0725 19:51:59.621515 20892 sgd_solver.cpp:106] Iteration 91600, lr = 2.75438e-06
I0725 19:52:09.034111 20892 solver.cpp:228] Iteration 91700, loss = 0.268136
I0725 19:52:09.034167 20892 solver.cpp:244]     Train net output #0: loss = 0.268136 (* 1 = 0.268136 loss)
I0725 19:52:09.034179 20892 sgd_solver.cpp:106] Iteration 91700, lr = 2.75253e-06
I0725 19:52:18.442711 20892 solver.cpp:228] Iteration 91800, loss = 0.23456
I0725 19:52:18.442754 20892 solver.cpp:244]     Train net output #0: loss = 0.23456 (* 1 = 0.23456 loss)
I0725 19:52:18.442759 20892 sgd_solver.cpp:106] Iteration 91800, lr = 2.75069e-06
I0725 19:52:27.855454 20892 solver.cpp:228] Iteration 91900, loss = 0.326957
I0725 19:52:27.855522 20892 solver.cpp:244]     Train net output #0: loss = 0.326957 (* 1 = 0.326957 loss)
I0725 19:52:27.855530 20892 sgd_solver.cpp:106] Iteration 91900, lr = 2.74884e-06
I0725 19:52:37.168244 20892 solver.cpp:337] Iteration 92000, Testing net (#0)
I0725 19:52:51.292560 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837193
I0725 19:52:51.292613 20892 solver.cpp:404]     Test net output #1: loss = 0.369994 (* 1 = 0.369994 loss)
I0725 19:52:51.321981 20892 solver.cpp:228] Iteration 92000, loss = 0.307445
I0725 19:52:51.322036 20892 solver.cpp:244]     Train net output #0: loss = 0.307445 (* 1 = 0.307445 loss)
I0725 19:52:51.322046 20892 sgd_solver.cpp:106] Iteration 92000, lr = 2.747e-06
I0725 19:53:00.717104 20892 solver.cpp:228] Iteration 92100, loss = 0.246749
I0725 19:53:00.717155 20892 solver.cpp:244]     Train net output #0: loss = 0.246749 (* 1 = 0.246749 loss)
I0725 19:53:00.717162 20892 sgd_solver.cpp:106] Iteration 92100, lr = 2.74516e-06
I0725 19:53:10.124266 20892 solver.cpp:228] Iteration 92200, loss = 0.220145
I0725 19:53:10.124310 20892 solver.cpp:244]     Train net output #0: loss = 0.220145 (* 1 = 0.220145 loss)
I0725 19:53:10.124315 20892 sgd_solver.cpp:106] Iteration 92200, lr = 2.74333e-06
I0725 19:53:19.535498 20892 solver.cpp:228] Iteration 92300, loss = 0.298614
I0725 19:53:19.535559 20892 solver.cpp:244]     Train net output #0: loss = 0.298614 (* 1 = 0.298614 loss)
I0725 19:53:19.535565 20892 sgd_solver.cpp:106] Iteration 92300, lr = 2.7415e-06
I0725 19:53:28.946748 20892 solver.cpp:228] Iteration 92400, loss = 0.260608
I0725 19:53:28.946813 20892 solver.cpp:244]     Train net output #0: loss = 0.260608 (* 1 = 0.260608 loss)
I0725 19:53:28.946822 20892 sgd_solver.cpp:106] Iteration 92400, lr = 2.73967e-06
I0725 19:53:38.256795 20892 solver.cpp:337] Iteration 92500, Testing net (#0)
I0725 19:53:52.356577 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836936
I0725 19:53:52.356621 20892 solver.cpp:404]     Test net output #1: loss = 0.371221 (* 1 = 0.371221 loss)
I0725 19:53:52.382799 20892 solver.cpp:228] Iteration 92500, loss = 0.24935
I0725 19:53:52.382851 20892 solver.cpp:244]     Train net output #0: loss = 0.24935 (* 1 = 0.24935 loss)
I0725 19:53:52.382860 20892 sgd_solver.cpp:106] Iteration 92500, lr = 2.73784e-06
I0725 19:54:01.772656 20892 solver.cpp:228] Iteration 92600, loss = 0.392604
I0725 19:54:01.772702 20892 solver.cpp:244]     Train net output #0: loss = 0.392604 (* 1 = 0.392604 loss)
I0725 19:54:01.772709 20892 sgd_solver.cpp:106] Iteration 92600, lr = 2.73602e-06
I0725 19:54:11.181092 20892 solver.cpp:228] Iteration 92700, loss = 0.314912
I0725 19:54:11.181140 20892 solver.cpp:244]     Train net output #0: loss = 0.314912 (* 1 = 0.314912 loss)
I0725 19:54:11.181148 20892 sgd_solver.cpp:106] Iteration 92700, lr = 2.7342e-06
I0725 19:54:20.597466 20892 solver.cpp:228] Iteration 92800, loss = 0.294423
I0725 19:54:20.597514 20892 solver.cpp:244]     Train net output #0: loss = 0.294423 (* 1 = 0.294423 loss)
I0725 19:54:20.597522 20892 sgd_solver.cpp:106] Iteration 92800, lr = 2.73238e-06
I0725 19:54:30.014415 20892 solver.cpp:228] Iteration 92900, loss = 0.276703
I0725 19:54:30.014461 20892 solver.cpp:244]     Train net output #0: loss = 0.276703 (* 1 = 0.276703 loss)
I0725 19:54:30.014468 20892 sgd_solver.cpp:106] Iteration 92900, lr = 2.73056e-06
I0725 19:54:39.331542 20892 solver.cpp:337] Iteration 93000, Testing net (#0)
I0725 19:54:40.650115 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:54:53.303088 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836549
I0725 19:54:53.303134 20892 solver.cpp:404]     Test net output #1: loss = 0.371212 (* 1 = 0.371212 loss)
I0725 19:54:53.329725 20892 solver.cpp:228] Iteration 93000, loss = 0.248867
I0725 19:54:53.329771 20892 solver.cpp:244]     Train net output #0: loss = 0.248867 (* 1 = 0.248867 loss)
I0725 19:54:53.329780 20892 sgd_solver.cpp:106] Iteration 93000, lr = 2.72875e-06
I0725 19:55:02.729867 20892 solver.cpp:228] Iteration 93100, loss = 0.359454
I0725 19:55:02.729926 20892 solver.cpp:244]     Train net output #0: loss = 0.359454 (* 1 = 0.359454 loss)
I0725 19:55:02.729933 20892 sgd_solver.cpp:106] Iteration 93100, lr = 2.72694e-06
I0725 19:55:12.127806 20892 solver.cpp:228] Iteration 93200, loss = 0.310525
I0725 19:55:12.127849 20892 solver.cpp:244]     Train net output #0: loss = 0.310525 (* 1 = 0.310525 loss)
I0725 19:55:12.127856 20892 sgd_solver.cpp:106] Iteration 93200, lr = 2.72513e-06
I0725 19:55:21.529470 20892 solver.cpp:228] Iteration 93300, loss = 0.308046
I0725 19:55:21.529517 20892 solver.cpp:244]     Train net output #0: loss = 0.308046 (* 1 = 0.308046 loss)
I0725 19:55:21.529523 20892 sgd_solver.cpp:106] Iteration 93300, lr = 2.72333e-06
I0725 19:55:30.933545 20892 solver.cpp:228] Iteration 93400, loss = 0.212941
I0725 19:55:30.933585 20892 solver.cpp:244]     Train net output #0: loss = 0.212941 (* 1 = 0.212941 loss)
I0725 19:55:30.933591 20892 sgd_solver.cpp:106] Iteration 93400, lr = 2.72153e-06
I0725 19:55:40.238617 20892 solver.cpp:337] Iteration 93500, Testing net (#0)
I0725 19:55:54.473179 20892 solver.cpp:404]     Test net output #0: accuracy = 0.836194
I0725 19:55:54.473248 20892 solver.cpp:404]     Test net output #1: loss = 0.372648 (* 1 = 0.372648 loss)
I0725 19:55:54.504196 20892 solver.cpp:228] Iteration 93500, loss = 0.357389
I0725 19:55:54.504231 20892 solver.cpp:244]     Train net output #0: loss = 0.357389 (* 1 = 0.357389 loss)
I0725 19:55:54.504243 20892 sgd_solver.cpp:106] Iteration 93500, lr = 2.71973e-06
I0725 19:56:03.840860 20892 solver.cpp:228] Iteration 93600, loss = 0.233016
I0725 19:56:03.840898 20892 solver.cpp:244]     Train net output #0: loss = 0.233016 (* 1 = 0.233016 loss)
I0725 19:56:03.840904 20892 sgd_solver.cpp:106] Iteration 93600, lr = 2.71793e-06
I0725 19:56:13.253176 20892 solver.cpp:228] Iteration 93700, loss = 0.251621
I0725 19:56:13.253232 20892 solver.cpp:244]     Train net output #0: loss = 0.251621 (* 1 = 0.251621 loss)
I0725 19:56:13.253237 20892 sgd_solver.cpp:106] Iteration 93700, lr = 2.71614e-06
I0725 19:56:22.657630 20892 solver.cpp:228] Iteration 93800, loss = 0.256598
I0725 19:56:22.657688 20892 solver.cpp:244]     Train net output #0: loss = 0.256598 (* 1 = 0.256598 loss)
I0725 19:56:22.657696 20892 sgd_solver.cpp:106] Iteration 93800, lr = 2.71435e-06
I0725 19:56:32.063163 20892 solver.cpp:228] Iteration 93900, loss = 0.2505
I0725 19:56:32.063205 20892 solver.cpp:244]     Train net output #0: loss = 0.2505 (* 1 = 0.2505 loss)
I0725 19:56:32.063210 20892 sgd_solver.cpp:106] Iteration 93900, lr = 2.71256e-06
I0725 19:56:41.370199 20892 solver.cpp:337] Iteration 94000, Testing net (#0)
I0725 19:56:55.596149 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837581
I0725 19:56:55.596218 20892 solver.cpp:404]     Test net output #1: loss = 0.37081 (* 1 = 0.37081 loss)
I0725 19:56:55.622665 20892 solver.cpp:228] Iteration 94000, loss = 0.255036
I0725 19:56:55.622730 20892 solver.cpp:244]     Train net output #0: loss = 0.255036 (* 1 = 0.255036 loss)
I0725 19:56:55.622741 20892 sgd_solver.cpp:106] Iteration 94000, lr = 2.71078e-06
I0725 19:57:04.970450 20892 solver.cpp:228] Iteration 94100, loss = 0.279008
I0725 19:57:04.970492 20892 solver.cpp:244]     Train net output #0: loss = 0.279008 (* 1 = 0.279008 loss)
I0725 19:57:04.970499 20892 sgd_solver.cpp:106] Iteration 94100, lr = 2.709e-06
I0725 19:57:14.380215 20892 solver.cpp:228] Iteration 94200, loss = 0.223462
I0725 19:57:14.380273 20892 solver.cpp:244]     Train net output #0: loss = 0.223462 (* 1 = 0.223462 loss)
I0725 19:57:14.380280 20892 sgd_solver.cpp:106] Iteration 94200, lr = 2.70722e-06
I0725 19:57:23.788920 20892 solver.cpp:228] Iteration 94300, loss = 0.262384
I0725 19:57:23.788965 20892 solver.cpp:244]     Train net output #0: loss = 0.262384 (* 1 = 0.262384 loss)
I0725 19:57:23.788974 20892 sgd_solver.cpp:106] Iteration 94300, lr = 2.70544e-06
I0725 19:57:28.965302 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 19:57:33.197201 20892 solver.cpp:228] Iteration 94400, loss = 0.333116
I0725 19:57:33.197228 20892 solver.cpp:244]     Train net output #0: loss = 0.333116 (* 1 = 0.333116 loss)
I0725 19:57:33.197234 20892 sgd_solver.cpp:106] Iteration 94400, lr = 2.70367e-06
I0725 19:57:42.512547 20892 solver.cpp:337] Iteration 94500, Testing net (#0)
I0725 19:57:56.613358 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837065
I0725 19:57:56.613409 20892 solver.cpp:404]     Test net output #1: loss = 0.371693 (* 1 = 0.371693 loss)
I0725 19:57:56.642802 20892 solver.cpp:228] Iteration 94500, loss = 0.327744
I0725 19:57:56.642868 20892 solver.cpp:244]     Train net output #0: loss = 0.327744 (* 1 = 0.327744 loss)
I0725 19:57:56.642889 20892 sgd_solver.cpp:106] Iteration 94500, lr = 2.70189e-06
I0725 19:58:05.984403 20892 solver.cpp:228] Iteration 94600, loss = 0.293237
I0725 19:58:05.984452 20892 solver.cpp:244]     Train net output #0: loss = 0.293237 (* 1 = 0.293237 loss)
I0725 19:58:05.984458 20892 sgd_solver.cpp:106] Iteration 94600, lr = 2.70013e-06
I0725 19:58:15.553032 20892 solver.cpp:228] Iteration 94700, loss = 0.313216
I0725 19:58:15.553078 20892 solver.cpp:244]     Train net output #0: loss = 0.313216 (* 1 = 0.313216 loss)
I0725 19:58:15.553086 20892 sgd_solver.cpp:106] Iteration 94700, lr = 2.69836e-06
I0725 19:58:24.967414 20892 solver.cpp:228] Iteration 94800, loss = 0.358828
I0725 19:58:24.967460 20892 solver.cpp:244]     Train net output #0: loss = 0.358828 (* 1 = 0.358828 loss)
I0725 19:58:24.967466 20892 sgd_solver.cpp:106] Iteration 94800, lr = 2.6966e-06
I0725 19:58:34.345845 20892 solver.cpp:228] Iteration 94900, loss = 0.288851
I0725 19:58:34.345888 20892 solver.cpp:244]     Train net output #0: loss = 0.288851 (* 1 = 0.288851 loss)
I0725 19:58:34.345895 20892 sgd_solver.cpp:106] Iteration 94900, lr = 2.69484e-06
I0725 19:58:43.584821 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_95000.caffemodel
I0725 19:58:43.935499 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_95000.solverstate
I0725 19:58:44.034157 20892 solver.cpp:337] Iteration 95000, Testing net (#0)
I0725 19:58:58.040778 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831484
I0725 19:58:58.040851 20892 solver.cpp:404]     Test net output #1: loss = 0.381153 (* 1 = 0.381153 loss)
I0725 19:58:58.074522 20892 solver.cpp:228] Iteration 95000, loss = 0.209765
I0725 19:58:58.074568 20892 solver.cpp:244]     Train net output #0: loss = 0.209765 (* 1 = 0.209765 loss)
I0725 19:58:58.074582 20892 sgd_solver.cpp:106] Iteration 95000, lr = 2.69308e-06
I0725 19:59:07.418977 20892 solver.cpp:228] Iteration 95100, loss = 0.32033
I0725 19:59:07.419034 20892 solver.cpp:244]     Train net output #0: loss = 0.32033 (* 1 = 0.32033 loss)
I0725 19:59:07.419041 20892 sgd_solver.cpp:106] Iteration 95100, lr = 2.69132e-06
I0725 19:59:16.827029 20892 solver.cpp:228] Iteration 95200, loss = 0.225793
I0725 19:59:16.827078 20892 solver.cpp:244]     Train net output #0: loss = 0.225793 (* 1 = 0.225793 loss)
I0725 19:59:16.827085 20892 sgd_solver.cpp:106] Iteration 95200, lr = 2.68957e-06
I0725 19:59:26.234436 20892 solver.cpp:228] Iteration 95300, loss = 0.296899
I0725 19:59:26.234477 20892 solver.cpp:244]     Train net output #0: loss = 0.296899 (* 1 = 0.296899 loss)
I0725 19:59:26.234483 20892 sgd_solver.cpp:106] Iteration 95300, lr = 2.68782e-06
I0725 19:59:35.647553 20892 solver.cpp:228] Iteration 95400, loss = 0.240884
I0725 19:59:35.647596 20892 solver.cpp:244]     Train net output #0: loss = 0.240884 (* 1 = 0.240884 loss)
I0725 19:59:35.647603 20892 sgd_solver.cpp:106] Iteration 95400, lr = 2.68608e-06
I0725 19:59:44.958134 20892 solver.cpp:337] Iteration 95500, Testing net (#0)
I0725 19:59:59.126184 20892 solver.cpp:404]     Test net output #0: accuracy = 0.838065
I0725 19:59:59.126230 20892 solver.cpp:404]     Test net output #1: loss = 0.370649 (* 1 = 0.370649 loss)
I0725 19:59:59.155416 20892 solver.cpp:228] Iteration 95500, loss = 0.23203
I0725 19:59:59.155470 20892 solver.cpp:244]     Train net output #0: loss = 0.23203 (* 1 = 0.23203 loss)
I0725 19:59:59.155481 20892 sgd_solver.cpp:106] Iteration 95500, lr = 2.68433e-06
I0725 20:00:08.538048 20892 solver.cpp:228] Iteration 95600, loss = 0.249116
I0725 20:00:08.538100 20892 solver.cpp:244]     Train net output #0: loss = 0.249116 (* 1 = 0.249116 loss)
I0725 20:00:08.538106 20892 sgd_solver.cpp:106] Iteration 95600, lr = 2.68259e-06
I0725 20:00:17.953091 20892 solver.cpp:228] Iteration 95700, loss = 0.29453
I0725 20:00:17.953152 20892 solver.cpp:244]     Train net output #0: loss = 0.29453 (* 1 = 0.29453 loss)
I0725 20:00:17.953160 20892 sgd_solver.cpp:106] Iteration 95700, lr = 2.68085e-06
I0725 20:00:22.660094 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 20:00:27.370110 20892 solver.cpp:228] Iteration 95800, loss = 0.331825
I0725 20:00:27.370169 20892 solver.cpp:244]     Train net output #0: loss = 0.331825 (* 1 = 0.331825 loss)
I0725 20:00:27.370177 20892 sgd_solver.cpp:106] Iteration 95800, lr = 2.67911e-06
I0725 20:00:36.777500 20892 solver.cpp:228] Iteration 95900, loss = 0.289185
I0725 20:00:36.777547 20892 solver.cpp:244]     Train net output #0: loss = 0.289185 (* 1 = 0.289185 loss)
I0725 20:00:36.777554 20892 sgd_solver.cpp:106] Iteration 95900, lr = 2.67738e-06
I0725 20:00:46.097224 20892 solver.cpp:337] Iteration 96000, Testing net (#0)
I0725 20:01:00.238577 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837774
I0725 20:01:00.238636 20892 solver.cpp:404]     Test net output #1: loss = 0.370266 (* 1 = 0.370266 loss)
I0725 20:01:00.266474 20892 solver.cpp:228] Iteration 96000, loss = 0.19913
I0725 20:01:00.266520 20892 solver.cpp:244]     Train net output #0: loss = 0.19913 (* 1 = 0.19913 loss)
I0725 20:01:00.266530 20892 sgd_solver.cpp:106] Iteration 96000, lr = 2.67565e-06
I0725 20:01:09.657620 20892 solver.cpp:228] Iteration 96100, loss = 0.221372
I0725 20:01:09.657670 20892 solver.cpp:244]     Train net output #0: loss = 0.221372 (* 1 = 0.221372 loss)
I0725 20:01:09.657675 20892 sgd_solver.cpp:106] Iteration 96100, lr = 2.67392e-06
I0725 20:01:19.068768 20892 solver.cpp:228] Iteration 96200, loss = 0.35167
I0725 20:01:19.068810 20892 solver.cpp:244]     Train net output #0: loss = 0.35167 (* 1 = 0.35167 loss)
I0725 20:01:19.068816 20892 sgd_solver.cpp:106] Iteration 96200, lr = 2.67219e-06
I0725 20:01:28.470916 20892 solver.cpp:228] Iteration 96300, loss = 0.425135
I0725 20:01:28.470963 20892 solver.cpp:244]     Train net output #0: loss = 0.425135 (* 1 = 0.425135 loss)
I0725 20:01:28.470970 20892 sgd_solver.cpp:106] Iteration 96300, lr = 2.67047e-06
I0725 20:01:37.879756 20892 solver.cpp:228] Iteration 96400, loss = 0.25565
I0725 20:01:37.879808 20892 solver.cpp:244]     Train net output #0: loss = 0.25565 (* 1 = 0.25565 loss)
I0725 20:01:37.879815 20892 sgd_solver.cpp:106] Iteration 96400, lr = 2.66875e-06
I0725 20:01:47.130432 20892 solver.cpp:337] Iteration 96500, Testing net (#0)
I0725 20:02:01.377635 20892 solver.cpp:404]     Test net output #0: accuracy = 0.838
I0725 20:02:01.377708 20892 solver.cpp:404]     Test net output #1: loss = 0.369811 (* 1 = 0.369811 loss)
I0725 20:02:01.404325 20892 solver.cpp:228] Iteration 96500, loss = 0.290591
I0725 20:02:01.404389 20892 solver.cpp:244]     Train net output #0: loss = 0.290591 (* 1 = 0.290591 loss)
I0725 20:02:01.404409 20892 sgd_solver.cpp:106] Iteration 96500, lr = 2.66703e-06
I0725 20:02:10.765316 20892 solver.cpp:228] Iteration 96600, loss = 0.374891
I0725 20:02:10.765372 20892 solver.cpp:244]     Train net output #0: loss = 0.374891 (* 1 = 0.374891 loss)
I0725 20:02:10.765378 20892 sgd_solver.cpp:106] Iteration 96600, lr = 2.66532e-06
I0725 20:02:20.169852 20892 solver.cpp:228] Iteration 96700, loss = 0.306071
I0725 20:02:20.169908 20892 solver.cpp:244]     Train net output #0: loss = 0.306071 (* 1 = 0.306071 loss)
I0725 20:02:20.169914 20892 sgd_solver.cpp:106] Iteration 96700, lr = 2.6636e-06
I0725 20:02:29.578524 20892 solver.cpp:228] Iteration 96800, loss = 0.230844
I0725 20:02:29.578565 20892 solver.cpp:244]     Train net output #0: loss = 0.230844 (* 1 = 0.230844 loss)
I0725 20:02:29.578572 20892 sgd_solver.cpp:106] Iteration 96800, lr = 2.66189e-06
I0725 20:02:38.980336 20892 solver.cpp:228] Iteration 96900, loss = 0.309789
I0725 20:02:38.980396 20892 solver.cpp:244]     Train net output #0: loss = 0.309789 (* 1 = 0.309789 loss)
I0725 20:02:38.980401 20892 sgd_solver.cpp:106] Iteration 96900, lr = 2.66018e-06
I0725 20:02:48.295518 20892 solver.cpp:337] Iteration 97000, Testing net (#0)
I0725 20:03:02.479830 20892 solver.cpp:404]     Test net output #0: accuracy = 0.831097
I0725 20:03:02.479884 20892 solver.cpp:404]     Test net output #1: loss = 0.38245 (* 1 = 0.38245 loss)
I0725 20:03:02.508966 20892 solver.cpp:228] Iteration 97000, loss = 0.30457
I0725 20:03:02.509004 20892 solver.cpp:244]     Train net output #0: loss = 0.30457 (* 1 = 0.30457 loss)
I0725 20:03:02.509016 20892 sgd_solver.cpp:106] Iteration 97000, lr = 2.65848e-06
I0725 20:03:11.858645 20892 solver.cpp:228] Iteration 97100, loss = 0.286567
I0725 20:03:11.858693 20892 solver.cpp:244]     Train net output #0: loss = 0.286567 (* 1 = 0.286567 loss)
I0725 20:03:11.858700 20892 sgd_solver.cpp:106] Iteration 97100, lr = 2.65678e-06
I0725 20:03:21.267686 20892 solver.cpp:228] Iteration 97200, loss = 0.278879
I0725 20:03:21.267726 20892 solver.cpp:244]     Train net output #0: loss = 0.278879 (* 1 = 0.278879 loss)
I0725 20:03:21.267732 20892 sgd_solver.cpp:106] Iteration 97200, lr = 2.65507e-06
I0725 20:03:29.456606 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 20:03:30.678809 20892 solver.cpp:228] Iteration 97300, loss = 0.287364
I0725 20:03:30.678866 20892 solver.cpp:244]     Train net output #0: loss = 0.287364 (* 1 = 0.287364 loss)
I0725 20:03:30.678874 20892 sgd_solver.cpp:106] Iteration 97300, lr = 2.65338e-06
I0725 20:03:40.089985 20892 solver.cpp:228] Iteration 97400, loss = 0.252379
I0725 20:03:40.090034 20892 solver.cpp:244]     Train net output #0: loss = 0.252379 (* 1 = 0.252379 loss)
I0725 20:03:40.090040 20892 sgd_solver.cpp:106] Iteration 97400, lr = 2.65168e-06
I0725 20:03:49.402665 20892 solver.cpp:337] Iteration 97500, Testing net (#0)
I0725 20:04:03.427897 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837258
I0725 20:04:03.427932 20892 solver.cpp:404]     Test net output #1: loss = 0.371875 (* 1 = 0.371875 loss)
I0725 20:04:03.462126 20892 solver.cpp:228] Iteration 97500, loss = 0.169279
I0725 20:04:03.462172 20892 solver.cpp:244]     Train net output #0: loss = 0.169279 (* 1 = 0.169279 loss)
I0725 20:04:03.462182 20892 sgd_solver.cpp:106] Iteration 97500, lr = 2.64999e-06
I0725 20:04:12.788801 20892 solver.cpp:228] Iteration 97600, loss = 0.265393
I0725 20:04:12.788849 20892 solver.cpp:244]     Train net output #0: loss = 0.265393 (* 1 = 0.265393 loss)
I0725 20:04:12.788856 20892 sgd_solver.cpp:106] Iteration 97600, lr = 2.6483e-06
I0725 20:04:22.159914 20892 solver.cpp:228] Iteration 97700, loss = 0.215303
I0725 20:04:22.159956 20892 solver.cpp:244]     Train net output #0: loss = 0.215303 (* 1 = 0.215303 loss)
I0725 20:04:22.159963 20892 sgd_solver.cpp:106] Iteration 97700, lr = 2.64661e-06
I0725 20:04:31.564432 20892 solver.cpp:228] Iteration 97800, loss = 0.244167
I0725 20:04:31.564481 20892 solver.cpp:244]     Train net output #0: loss = 0.244167 (* 1 = 0.244167 loss)
I0725 20:04:31.564488 20892 sgd_solver.cpp:106] Iteration 97800, lr = 2.64493e-06
I0725 20:04:40.966825 20892 solver.cpp:228] Iteration 97900, loss = 0.389357
I0725 20:04:40.966876 20892 solver.cpp:244]     Train net output #0: loss = 0.389357 (* 1 = 0.389357 loss)
I0725 20:04:40.966882 20892 sgd_solver.cpp:106] Iteration 97900, lr = 2.64324e-06
I0725 20:04:50.280058 20892 solver.cpp:337] Iteration 98000, Testing net (#0)
I0725 20:05:04.475006 20892 solver.cpp:404]     Test net output #0: accuracy = 0.837549
I0725 20:05:04.475064 20892 solver.cpp:404]     Test net output #1: loss = 0.370725 (* 1 = 0.370725 loss)
I0725 20:05:04.502312 20892 solver.cpp:228] Iteration 98000, loss = 0.283179
I0725 20:05:04.502375 20892 solver.cpp:244]     Train net output #0: loss = 0.283179 (* 1 = 0.283179 loss)
I0725 20:05:04.502394 20892 sgd_solver.cpp:106] Iteration 98000, lr = 2.64156e-06
I0725 20:05:13.885421 20892 solver.cpp:228] Iteration 98100, loss = 0.301272
I0725 20:05:13.885478 20892 solver.cpp:244]     Train net output #0: loss = 0.301272 (* 1 = 0.301272 loss)
I0725 20:05:13.885486 20892 sgd_solver.cpp:106] Iteration 98100, lr = 2.63989e-06
I0725 20:05:23.292824 20892 solver.cpp:228] Iteration 98200, loss = 0.276828
I0725 20:05:23.292882 20892 solver.cpp:244]     Train net output #0: loss = 0.276828 (* 1 = 0.276828 loss)
I0725 20:05:23.292889 20892 sgd_solver.cpp:106] Iteration 98200, lr = 2.63821e-06
I0725 20:05:32.698802 20892 solver.cpp:228] Iteration 98300, loss = 0.31461
I0725 20:05:32.698845 20892 solver.cpp:244]     Train net output #0: loss = 0.31461 (* 1 = 0.31461 loss)
I0725 20:05:32.698851 20892 sgd_solver.cpp:106] Iteration 98300, lr = 2.63654e-06
I0725 20:05:42.105206 20892 solver.cpp:228] Iteration 98400, loss = 0.289387
I0725 20:05:42.105243 20892 solver.cpp:244]     Train net output #0: loss = 0.289387 (* 1 = 0.289387 loss)
I0725 20:05:42.105248 20892 sgd_solver.cpp:106] Iteration 98400, lr = 2.63487e-06
I0725 20:05:51.421931 20892 solver.cpp:337] Iteration 98500, Testing net (#0)
I0725 20:06:05.509639 20892 solver.cpp:404]     Test net output #0: accuracy = 0.839742
I0725 20:06:05.509681 20892 solver.cpp:404]     Test net output #1: loss = 0.367771 (* 1 = 0.367771 loss)
I0725 20:06:05.539099 20892 solver.cpp:228] Iteration 98500, loss = 0.293628
I0725 20:06:05.539150 20892 solver.cpp:244]     Train net output #0: loss = 0.293628 (* 1 = 0.293628 loss)
I0725 20:06:05.539170 20892 sgd_solver.cpp:106] Iteration 98500, lr = 2.6332e-06
I0725 20:06:14.838223 20892 solver.cpp:228] Iteration 98600, loss = 0.207615
I0725 20:06:14.838296 20892 solver.cpp:244]     Train net output #0: loss = 0.207615 (* 1 = 0.207615 loss)
I0725 20:06:14.838304 20892 sgd_solver.cpp:106] Iteration 98600, lr = 2.63153e-06
I0725 20:06:23.497956 20892 blocking_queue.cpp:50] Data layer prefetch queue empty
I0725 20:06:24.250720 20892 solver.cpp:228] Iteration 98700, loss = 0.351101
I0725 20:06:24.250769 20892 solver.cpp:244]     Train net output #0: loss = 0.351101 (* 1 = 0.351101 loss)
I0725 20:06:24.250776 20892 sgd_solver.cpp:106] Iteration 98700, lr = 2.62987e-06
I0725 20:06:33.668964 20892 solver.cpp:228] Iteration 98800, loss = 0.224876
I0725 20:06:33.669004 20892 solver.cpp:244]     Train net output #0: loss = 0.224876 (* 1 = 0.224876 loss)
I0725 20:06:33.669010 20892 sgd_solver.cpp:106] Iteration 98800, lr = 2.62821e-06
I0725 20:06:43.086822 20892 solver.cpp:228] Iteration 98900, loss = 0.38018
I0725 20:06:43.086860 20892 solver.cpp:244]     Train net output #0: loss = 0.38018 (* 1 = 0.38018 loss)
I0725 20:06:43.086866 20892 sgd_solver.cpp:106] Iteration 98900, lr = 2.62655e-06
I0725 20:06:52.391152 20892 solver.cpp:337] Iteration 99000, Testing net (#0)
I0725 20:07:06.449002 20892 solver.cpp:404]     Test net output #0: accuracy = 0.835807
I0725 20:07:06.449054 20892 solver.cpp:404]     Test net output #1: loss = 0.375277 (* 1 = 0.375277 loss)
I0725 20:07:06.475388 20892 solver.cpp:228] Iteration 99000, loss = 0.261218
I0725 20:07:06.475438 20892 solver.cpp:244]     Train net output #0: loss = 0.261218 (* 1 = 0.261218 loss)
I0725 20:07:06.475461 20892 sgd_solver.cpp:106] Iteration 99000, lr = 2.6249e-06
I0725 20:07:15.835145 20892 solver.cpp:228] Iteration 99100, loss = 0.223723
I0725 20:07:15.835202 20892 solver.cpp:244]     Train net output #0: loss = 0.223723 (* 1 = 0.223723 loss)
I0725 20:07:15.835211 20892 sgd_solver.cpp:106] Iteration 99100, lr = 2.62324e-06
I0725 20:07:25.230989 20892 solver.cpp:228] Iteration 99200, loss = 0.300987
I0725 20:07:25.231046 20892 solver.cpp:244]     Train net output #0: loss = 0.300987 (* 1 = 0.300987 loss)
I0725 20:07:25.231052 20892 sgd_solver.cpp:106] Iteration 99200, lr = 2.62159e-06
I0725 20:07:34.629791 20892 solver.cpp:228] Iteration 99300, loss = 0.293075
I0725 20:07:34.629832 20892 solver.cpp:244]     Train net output #0: loss = 0.293075 (* 1 = 0.293075 loss)
I0725 20:07:34.629839 20892 sgd_solver.cpp:106] Iteration 99300, lr = 2.61995e-06
I0725 20:07:44.032618 20892 solver.cpp:228] Iteration 99400, loss = 0.164192
I0725 20:07:44.032670 20892 solver.cpp:244]     Train net output #0: loss = 0.164192 (* 1 = 0.164192 loss)
I0725 20:07:44.032676 20892 sgd_solver.cpp:106] Iteration 99400, lr = 2.6183e-06
I0725 20:07:53.339221 20892 solver.cpp:337] Iteration 99500, Testing net (#0)
I0725 20:08:07.450794 20892 solver.cpp:404]     Test net output #0: accuracy = 0.838871
I0725 20:08:07.450855 20892 solver.cpp:404]     Test net output #1: loss = 0.368804 (* 1 = 0.368804 loss)
I0725 20:08:07.479998 20892 solver.cpp:228] Iteration 99500, loss = 0.496843
I0725 20:08:07.480054 20892 solver.cpp:244]     Train net output #0: loss = 0.496843 (* 1 = 0.496843 loss)
I0725 20:08:07.480065 20892 sgd_solver.cpp:106] Iteration 99500, lr = 2.61666e-06
I0725 20:08:16.789453 20892 solver.cpp:228] Iteration 99600, loss = 0.181115
I0725 20:08:16.789505 20892 solver.cpp:244]     Train net output #0: loss = 0.181115 (* 1 = 0.181115 loss)
I0725 20:08:16.789511 20892 sgd_solver.cpp:106] Iteration 99600, lr = 2.61501e-06
I0725 20:08:26.193647 20892 solver.cpp:228] Iteration 99700, loss = 0.227382
I0725 20:08:26.193696 20892 solver.cpp:244]     Train net output #0: loss = 0.227382 (* 1 = 0.227382 loss)
I0725 20:08:26.193703 20892 sgd_solver.cpp:106] Iteration 99700, lr = 2.61338e-06
I0725 20:08:35.592303 20892 solver.cpp:228] Iteration 99800, loss = 0.24081
I0725 20:08:35.592344 20892 solver.cpp:244]     Train net output #0: loss = 0.24081 (* 1 = 0.24081 loss)
I0725 20:08:35.592350 20892 sgd_solver.cpp:106] Iteration 99800, lr = 2.61174e-06
I0725 20:08:44.985390 20892 solver.cpp:228] Iteration 99900, loss = 0.256885
I0725 20:08:44.985432 20892 solver.cpp:244]     Train net output #0: loss = 0.256885 (* 1 = 0.256885 loss)
I0725 20:08:44.985438 20892 sgd_solver.cpp:106] Iteration 99900, lr = 2.61011e-06
I0725 20:08:54.295239 20892 solver.cpp:454] Snapshotting to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_100000.caffemodel
I0725 20:08:54.646402 20892 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_and_random/person_background_and_random_lr_0.00001_iter_100000.solverstate
I0725 20:08:54.744783 20892 solver.cpp:337] Iteration 100000, Testing net (#0)
I0725 20:09:08.726145 20892 solver.cpp:404]     Test net output #0: accuracy = 0.838258
I0725 20:09:08.726186 20892 solver.cpp:404]     Test net output #1: loss = 0.36995 (* 1 = 0.36995 loss)
I0725 20:09:08.755327 20892 solver.cpp:228] Iteration 100000, loss = 0.365221
I0725 20:09:08.755374 20892 solver.cpp:244]     Train net output #0: loss = 0.365221 (* 1 = 0.365221 loss)
I0725 20:09:08.755384 20892 sgd_solver.cpp:106] Iteration 100000, lr = 2.60847e-06
s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
