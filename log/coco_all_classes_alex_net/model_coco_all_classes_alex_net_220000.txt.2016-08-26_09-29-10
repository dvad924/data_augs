WARNING: Logging before InitGoogleLogging() is written to STDERR
I0826 09:29:13.518851  1343 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1141
test_interval: 5000
base_lr: 1e-06
display: 100
max_iter: 220000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 20000
snapshot: 20000
snapshot_prefix: "models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001"
solver_mode: GPU
net: "nets/coco_all_classes_alex_net/trainval.prototxt"
I0826 09:29:13.518982  1343 solver.cpp:91] Creating training net from net file: nets/coco_all_classes_alex_net/trainval.prototxt
I0826 09:29:13.519275  1343 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer coco
I0826 09:29:13.519294  1343 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0826 09:29:13.519435  1343 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "coco"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/lmdb/coco_color_mean.binaryproto"
  }
  data_param {
    source: "data/lmdb/coco_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 80
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0826 09:29:13.519511  1343 layer_factory.hpp:77] Creating layer coco
I0826 09:29:13.520120  1343 net.cpp:100] Creating Layer coco
I0826 09:29:13.520133  1343 net.cpp:408] coco -> data
I0826 09:29:13.520145  1343 net.cpp:408] coco -> label
I0826 09:29:13.520162  1343 data_transformer.cpp:25] Loading mean file from: data/lmdb/coco_color_mean.binaryproto
I0826 09:29:13.521700  1352 db_lmdb.cpp:35] Opened lmdb data/lmdb/coco_train_lmdb
I0826 09:29:13.567462  1343 data_layer.cpp:41] output data size: 256,3,128,128
I0826 09:29:13.688900  1343 net.cpp:150] Setting up coco
I0826 09:29:13.688942  1343 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0826 09:29:13.688949  1343 net.cpp:157] Top shape: 256 (256)
I0826 09:29:13.688952  1343 net.cpp:165] Memory required for data: 50332672
I0826 09:29:13.688959  1343 layer_factory.hpp:77] Creating layer conv1
I0826 09:29:13.688987  1343 net.cpp:100] Creating Layer conv1
I0826 09:29:13.688992  1343 net.cpp:434] conv1 <- data
I0826 09:29:13.689000  1343 net.cpp:408] conv1 -> conv1
I0826 09:29:14.000919  1343 net.cpp:150] Setting up conv1
I0826 09:29:14.000958  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.000962  1343 net.cpp:165] Memory required for data: 138806272
I0826 09:29:14.000980  1343 layer_factory.hpp:77] Creating layer relu1
I0826 09:29:14.000994  1343 net.cpp:100] Creating Layer relu1
I0826 09:29:14.000999  1343 net.cpp:434] relu1 <- conv1
I0826 09:29:14.001005  1343 net.cpp:395] relu1 -> conv1 (in-place)
I0826 09:29:14.001195  1343 net.cpp:150] Setting up relu1
I0826 09:29:14.001207  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.001209  1343 net.cpp:165] Memory required for data: 227279872
I0826 09:29:14.001214  1343 layer_factory.hpp:77] Creating layer norm1
I0826 09:29:14.001221  1343 net.cpp:100] Creating Layer norm1
I0826 09:29:14.001224  1343 net.cpp:434] norm1 <- conv1
I0826 09:29:14.001230  1343 net.cpp:408] norm1 -> norm1
I0826 09:29:14.001739  1343 net.cpp:150] Setting up norm1
I0826 09:29:14.001755  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.001759  1343 net.cpp:165] Memory required for data: 315753472
I0826 09:29:14.001761  1343 layer_factory.hpp:77] Creating layer pool1
I0826 09:29:14.001773  1343 net.cpp:100] Creating Layer pool1
I0826 09:29:14.001777  1343 net.cpp:434] pool1 <- norm1
I0826 09:29:14.001783  1343 net.cpp:408] pool1 -> pool1
I0826 09:29:14.001827  1343 net.cpp:150] Setting up pool1
I0826 09:29:14.001834  1343 net.cpp:157] Top shape: 256 96 15 15 (5529600)
I0826 09:29:14.001837  1343 net.cpp:165] Memory required for data: 337871872
I0826 09:29:14.001840  1343 layer_factory.hpp:77] Creating layer conv2
I0826 09:29:14.001853  1343 net.cpp:100] Creating Layer conv2
I0826 09:29:14.001859  1343 net.cpp:434] conv2 <- pool1
I0826 09:29:14.001866  1343 net.cpp:408] conv2 -> conv2
I0826 09:29:14.008222  1343 net.cpp:150] Setting up conv2
I0826 09:29:14.008244  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.008249  1343 net.cpp:165] Memory required for data: 396854272
I0826 09:29:14.008260  1343 layer_factory.hpp:77] Creating layer relu2
I0826 09:29:14.008266  1343 net.cpp:100] Creating Layer relu2
I0826 09:29:14.008270  1343 net.cpp:434] relu2 <- conv2
I0826 09:29:14.008275  1343 net.cpp:395] relu2 -> conv2 (in-place)
I0826 09:29:14.008764  1343 net.cpp:150] Setting up relu2
I0826 09:29:14.008780  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.008783  1343 net.cpp:165] Memory required for data: 455836672
I0826 09:29:14.008786  1343 layer_factory.hpp:77] Creating layer norm2
I0826 09:29:14.008795  1343 net.cpp:100] Creating Layer norm2
I0826 09:29:14.008800  1343 net.cpp:434] norm2 <- conv2
I0826 09:29:14.008805  1343 net.cpp:408] norm2 -> norm2
I0826 09:29:14.009029  1343 net.cpp:150] Setting up norm2
I0826 09:29:14.009042  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.009045  1343 net.cpp:165] Memory required for data: 514819072
I0826 09:29:14.009048  1343 layer_factory.hpp:77] Creating layer pool2
I0826 09:29:14.009057  1343 net.cpp:100] Creating Layer pool2
I0826 09:29:14.009059  1343 net.cpp:434] pool2 <- norm2
I0826 09:29:14.009068  1343 net.cpp:408] pool2 -> pool2
I0826 09:29:14.009106  1343 net.cpp:150] Setting up pool2
I0826 09:29:14.009114  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.009117  1343 net.cpp:165] Memory required for data: 527664128
I0826 09:29:14.009120  1343 layer_factory.hpp:77] Creating layer conv3
I0826 09:29:14.009132  1343 net.cpp:100] Creating Layer conv3
I0826 09:29:14.009137  1343 net.cpp:434] conv3 <- pool2
I0826 09:29:14.009142  1343 net.cpp:408] conv3 -> conv3
I0826 09:29:14.022521  1343 net.cpp:150] Setting up conv3
I0826 09:29:14.022537  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.022541  1343 net.cpp:165] Memory required for data: 546931712
I0826 09:29:14.022550  1343 layer_factory.hpp:77] Creating layer relu3
I0826 09:29:14.022559  1343 net.cpp:100] Creating Layer relu3
I0826 09:29:14.022563  1343 net.cpp:434] relu3 <- conv3
I0826 09:29:14.022568  1343 net.cpp:395] relu3 -> conv3 (in-place)
I0826 09:29:14.022778  1343 net.cpp:150] Setting up relu3
I0826 09:29:14.022790  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.022794  1343 net.cpp:165] Memory required for data: 566199296
I0826 09:29:14.022796  1343 layer_factory.hpp:77] Creating layer conv4
I0826 09:29:14.022807  1343 net.cpp:100] Creating Layer conv4
I0826 09:29:14.022812  1343 net.cpp:434] conv4 <- conv3
I0826 09:29:14.022820  1343 net.cpp:408] conv4 -> conv4
I0826 09:29:14.034085  1343 net.cpp:150] Setting up conv4
I0826 09:29:14.034103  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.034107  1343 net.cpp:165] Memory required for data: 585466880
I0826 09:29:14.034114  1343 layer_factory.hpp:77] Creating layer relu4
I0826 09:29:14.034121  1343 net.cpp:100] Creating Layer relu4
I0826 09:29:14.034124  1343 net.cpp:434] relu4 <- conv4
I0826 09:29:14.034131  1343 net.cpp:395] relu4 -> conv4 (in-place)
I0826 09:29:14.034329  1343 net.cpp:150] Setting up relu4
I0826 09:29:14.034340  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.034343  1343 net.cpp:165] Memory required for data: 604734464
I0826 09:29:14.034348  1343 layer_factory.hpp:77] Creating layer conv5
I0826 09:29:14.034359  1343 net.cpp:100] Creating Layer conv5
I0826 09:29:14.034365  1343 net.cpp:434] conv5 <- conv4
I0826 09:29:14.034373  1343 net.cpp:408] conv5 -> conv5
I0826 09:29:14.042882  1343 net.cpp:150] Setting up conv5
I0826 09:29:14.042899  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.042902  1343 net.cpp:165] Memory required for data: 617579520
I0826 09:29:14.042914  1343 layer_factory.hpp:77] Creating layer relu5
I0826 09:29:14.042922  1343 net.cpp:100] Creating Layer relu5
I0826 09:29:14.042925  1343 net.cpp:434] relu5 <- conv5
I0826 09:29:14.042930  1343 net.cpp:395] relu5 -> conv5 (in-place)
I0826 09:29:14.043133  1343 net.cpp:150] Setting up relu5
I0826 09:29:14.043145  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.043148  1343 net.cpp:165] Memory required for data: 630424576
I0826 09:29:14.043151  1343 layer_factory.hpp:77] Creating layer pool5
I0826 09:29:14.043159  1343 net.cpp:100] Creating Layer pool5
I0826 09:29:14.043161  1343 net.cpp:434] pool5 <- conv5
I0826 09:29:14.043169  1343 net.cpp:408] pool5 -> pool5
I0826 09:29:14.043216  1343 net.cpp:150] Setting up pool5
I0826 09:29:14.043228  1343 net.cpp:157] Top shape: 256 256 3 3 (589824)
I0826 09:29:14.043231  1343 net.cpp:165] Memory required for data: 632783872
I0826 09:29:14.043234  1343 layer_factory.hpp:77] Creating layer fc6
I0826 09:29:14.043244  1343 net.cpp:100] Creating Layer fc6
I0826 09:29:14.043248  1343 net.cpp:434] fc6 <- pool5
I0826 09:29:14.043253  1343 net.cpp:408] fc6 -> fc6
I0826 09:29:14.174247  1343 net.cpp:150] Setting up fc6
I0826 09:29:14.174283  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.174285  1343 net.cpp:165] Memory required for data: 636978176
I0826 09:29:14.174298  1343 layer_factory.hpp:77] Creating layer relu6
I0826 09:29:14.174310  1343 net.cpp:100] Creating Layer relu6
I0826 09:29:14.174314  1343 net.cpp:434] relu6 <- fc6
I0826 09:29:14.174321  1343 net.cpp:395] relu6 -> fc6 (in-place)
I0826 09:29:14.174917  1343 net.cpp:150] Setting up relu6
I0826 09:29:14.174933  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.174937  1343 net.cpp:165] Memory required for data: 641172480
I0826 09:29:14.174940  1343 layer_factory.hpp:77] Creating layer drop6
I0826 09:29:14.174947  1343 net.cpp:100] Creating Layer drop6
I0826 09:29:14.174952  1343 net.cpp:434] drop6 <- fc6
I0826 09:29:14.174958  1343 net.cpp:395] drop6 -> fc6 (in-place)
I0826 09:29:14.174983  1343 net.cpp:150] Setting up drop6
I0826 09:29:14.174990  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.174993  1343 net.cpp:165] Memory required for data: 645366784
I0826 09:29:14.174995  1343 layer_factory.hpp:77] Creating layer fc7
I0826 09:29:14.175005  1343 net.cpp:100] Creating Layer fc7
I0826 09:29:14.175012  1343 net.cpp:434] fc7 <- fc6
I0826 09:29:14.175019  1343 net.cpp:408] fc7 -> fc7
I0826 09:29:14.405279  1343 net.cpp:150] Setting up fc7
I0826 09:29:14.405328  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.405333  1343 net.cpp:165] Memory required for data: 649561088
I0826 09:29:14.405344  1343 layer_factory.hpp:77] Creating layer relu7
I0826 09:29:14.405355  1343 net.cpp:100] Creating Layer relu7
I0826 09:29:14.405359  1343 net.cpp:434] relu7 <- fc7
I0826 09:29:14.405369  1343 net.cpp:395] relu7 -> fc7 (in-place)
I0826 09:29:14.405637  1343 net.cpp:150] Setting up relu7
I0826 09:29:14.405650  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.405653  1343 net.cpp:165] Memory required for data: 653755392
I0826 09:29:14.405656  1343 layer_factory.hpp:77] Creating layer drop7
I0826 09:29:14.405663  1343 net.cpp:100] Creating Layer drop7
I0826 09:29:14.405666  1343 net.cpp:434] drop7 <- fc7
I0826 09:29:14.405671  1343 net.cpp:395] drop7 -> fc7 (in-place)
I0826 09:29:14.405699  1343 net.cpp:150] Setting up drop7
I0826 09:29:14.405706  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.405709  1343 net.cpp:165] Memory required for data: 657949696
I0826 09:29:14.405712  1343 layer_factory.hpp:77] Creating layer fc8
I0826 09:29:14.405720  1343 net.cpp:100] Creating Layer fc8
I0826 09:29:14.405724  1343 net.cpp:434] fc8 <- fc7
I0826 09:29:14.405730  1343 net.cpp:408] fc8 -> fc8
I0826 09:29:14.411005  1343 net.cpp:150] Setting up fc8
I0826 09:29:14.411020  1343 net.cpp:157] Top shape: 256 80 (20480)
I0826 09:29:14.411023  1343 net.cpp:165] Memory required for data: 658031616
I0826 09:29:14.411029  1343 layer_factory.hpp:77] Creating layer loss
I0826 09:29:14.411043  1343 net.cpp:100] Creating Layer loss
I0826 09:29:14.411047  1343 net.cpp:434] loss <- fc8
I0826 09:29:14.411052  1343 net.cpp:434] loss <- label
I0826 09:29:14.411056  1343 net.cpp:408] loss -> loss
I0826 09:29:14.411067  1343 layer_factory.hpp:77] Creating layer loss
I0826 09:29:14.411394  1343 net.cpp:150] Setting up loss
I0826 09:29:14.411406  1343 net.cpp:157] Top shape: (1)
I0826 09:29:14.411409  1343 net.cpp:160]     with loss weight 1
I0826 09:29:14.411420  1343 net.cpp:165] Memory required for data: 658031620
I0826 09:29:14.411424  1343 net.cpp:226] loss needs backward computation.
I0826 09:29:14.411429  1343 net.cpp:226] fc8 needs backward computation.
I0826 09:29:14.411432  1343 net.cpp:226] drop7 needs backward computation.
I0826 09:29:14.411435  1343 net.cpp:226] relu7 needs backward computation.
I0826 09:29:14.411438  1343 net.cpp:226] fc7 needs backward computation.
I0826 09:29:14.411442  1343 net.cpp:226] drop6 needs backward computation.
I0826 09:29:14.411443  1343 net.cpp:226] relu6 needs backward computation.
I0826 09:29:14.411447  1343 net.cpp:226] fc6 needs backward computation.
I0826 09:29:14.411450  1343 net.cpp:226] pool5 needs backward computation.
I0826 09:29:14.411453  1343 net.cpp:226] relu5 needs backward computation.
I0826 09:29:14.411456  1343 net.cpp:226] conv5 needs backward computation.
I0826 09:29:14.411459  1343 net.cpp:226] relu4 needs backward computation.
I0826 09:29:14.411463  1343 net.cpp:226] conv4 needs backward computation.
I0826 09:29:14.411465  1343 net.cpp:226] relu3 needs backward computation.
I0826 09:29:14.411468  1343 net.cpp:226] conv3 needs backward computation.
I0826 09:29:14.411471  1343 net.cpp:226] pool2 needs backward computation.
I0826 09:29:14.411475  1343 net.cpp:226] norm2 needs backward computation.
I0826 09:29:14.411478  1343 net.cpp:226] relu2 needs backward computation.
I0826 09:29:14.411481  1343 net.cpp:226] conv2 needs backward computation.
I0826 09:29:14.411484  1343 net.cpp:226] pool1 needs backward computation.
I0826 09:29:14.411487  1343 net.cpp:226] norm1 needs backward computation.
I0826 09:29:14.411490  1343 net.cpp:226] relu1 needs backward computation.
I0826 09:29:14.411494  1343 net.cpp:226] conv1 needs backward computation.
I0826 09:29:14.411497  1343 net.cpp:228] coco does not need backward computation.
I0826 09:29:14.411501  1343 net.cpp:270] This network produces output loss
I0826 09:29:14.411519  1343 net.cpp:283] Network initialization done.
I0826 09:29:14.411859  1343 solver.cpp:181] Creating test net (#0) specified by net file: nets/coco_all_classes_alex_net/trainval.prototxt
I0826 09:29:14.411900  1343 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer coco
I0826 09:29:14.412068  1343 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "coco"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/lmdb/coco_color_mean.binaryproto"
  }
  data_param {
    source: "data/lmdb/coco_val_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 80
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0826 09:29:14.412178  1343 layer_factory.hpp:77] Creating layer coco
I0826 09:29:14.412408  1343 net.cpp:100] Creating Layer coco
I0826 09:29:14.412420  1343 net.cpp:408] coco -> data
I0826 09:29:14.412428  1343 net.cpp:408] coco -> label
I0826 09:29:14.412436  1343 data_transformer.cpp:25] Loading mean file from: data/lmdb/coco_color_mean.binaryproto
I0826 09:29:14.414034  1354 db_lmdb.cpp:35] Opened lmdb data/lmdb/coco_val_lmdb
I0826 09:29:14.414398  1343 data_layer.cpp:41] output data size: 256,3,128,128
I0826 09:29:14.545110  1343 net.cpp:150] Setting up coco
I0826 09:29:14.545147  1343 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0826 09:29:14.545153  1343 net.cpp:157] Top shape: 256 (256)
I0826 09:29:14.545156  1343 net.cpp:165] Memory required for data: 50332672
I0826 09:29:14.545163  1343 layer_factory.hpp:77] Creating layer label_coco_1_split
I0826 09:29:14.545181  1343 net.cpp:100] Creating Layer label_coco_1_split
I0826 09:29:14.545186  1343 net.cpp:434] label_coco_1_split <- label
I0826 09:29:14.545194  1343 net.cpp:408] label_coco_1_split -> label_coco_1_split_0
I0826 09:29:14.545207  1343 net.cpp:408] label_coco_1_split -> label_coco_1_split_1
I0826 09:29:14.545449  1343 net.cpp:150] Setting up label_coco_1_split
I0826 09:29:14.545481  1343 net.cpp:157] Top shape: 256 (256)
I0826 09:29:14.545490  1343 net.cpp:157] Top shape: 256 (256)
I0826 09:29:14.545495  1343 net.cpp:165] Memory required for data: 50334720
I0826 09:29:14.545501  1343 layer_factory.hpp:77] Creating layer conv1
I0826 09:29:14.545526  1343 net.cpp:100] Creating Layer conv1
I0826 09:29:14.545536  1343 net.cpp:434] conv1 <- data
I0826 09:29:14.545549  1343 net.cpp:408] conv1 -> conv1
I0826 09:29:14.553180  1343 net.cpp:150] Setting up conv1
I0826 09:29:14.553213  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.553221  1343 net.cpp:165] Memory required for data: 138808320
I0826 09:29:14.553242  1343 layer_factory.hpp:77] Creating layer relu1
I0826 09:29:14.553256  1343 net.cpp:100] Creating Layer relu1
I0826 09:29:14.553263  1343 net.cpp:434] relu1 <- conv1
I0826 09:29:14.553274  1343 net.cpp:395] relu1 -> conv1 (in-place)
I0826 09:29:14.553634  1343 net.cpp:150] Setting up relu1
I0826 09:29:14.553653  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.553658  1343 net.cpp:165] Memory required for data: 227281920
I0826 09:29:14.553663  1343 layer_factory.hpp:77] Creating layer norm1
I0826 09:29:14.553679  1343 net.cpp:100] Creating Layer norm1
I0826 09:29:14.553685  1343 net.cpp:434] norm1 <- conv1
I0826 09:29:14.553696  1343 net.cpp:408] norm1 -> norm1
I0826 09:29:14.554636  1343 net.cpp:150] Setting up norm1
I0826 09:29:14.554663  1343 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0826 09:29:14.554671  1343 net.cpp:165] Memory required for data: 315755520
I0826 09:29:14.554677  1343 layer_factory.hpp:77] Creating layer pool1
I0826 09:29:14.554689  1343 net.cpp:100] Creating Layer pool1
I0826 09:29:14.554697  1343 net.cpp:434] pool1 <- norm1
I0826 09:29:14.554735  1343 net.cpp:408] pool1 -> pool1
I0826 09:29:14.554821  1343 net.cpp:150] Setting up pool1
I0826 09:29:14.554836  1343 net.cpp:157] Top shape: 256 96 15 15 (5529600)
I0826 09:29:14.554842  1343 net.cpp:165] Memory required for data: 337873920
I0826 09:29:14.554847  1343 layer_factory.hpp:77] Creating layer conv2
I0826 09:29:14.554867  1343 net.cpp:100] Creating Layer conv2
I0826 09:29:14.554875  1343 net.cpp:434] conv2 <- pool1
I0826 09:29:14.554888  1343 net.cpp:408] conv2 -> conv2
I0826 09:29:14.567143  1343 net.cpp:150] Setting up conv2
I0826 09:29:14.567176  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.567183  1343 net.cpp:165] Memory required for data: 396856320
I0826 09:29:14.567201  1343 layer_factory.hpp:77] Creating layer relu2
I0826 09:29:14.567214  1343 net.cpp:100] Creating Layer relu2
I0826 09:29:14.567220  1343 net.cpp:434] relu2 <- conv2
I0826 09:29:14.567229  1343 net.cpp:395] relu2 -> conv2 (in-place)
I0826 09:29:14.568094  1343 net.cpp:150] Setting up relu2
I0826 09:29:14.568119  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.568125  1343 net.cpp:165] Memory required for data: 455838720
I0826 09:29:14.568130  1343 layer_factory.hpp:77] Creating layer norm2
I0826 09:29:14.568148  1343 net.cpp:100] Creating Layer norm2
I0826 09:29:14.568156  1343 net.cpp:434] norm2 <- conv2
I0826 09:29:14.568166  1343 net.cpp:408] norm2 -> norm2
I0826 09:29:14.568572  1343 net.cpp:150] Setting up norm2
I0826 09:29:14.568591  1343 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0826 09:29:14.568596  1343 net.cpp:165] Memory required for data: 514821120
I0826 09:29:14.568603  1343 layer_factory.hpp:77] Creating layer pool2
I0826 09:29:14.568614  1343 net.cpp:100] Creating Layer pool2
I0826 09:29:14.568619  1343 net.cpp:434] pool2 <- norm2
I0826 09:29:14.568631  1343 net.cpp:408] pool2 -> pool2
I0826 09:29:14.568703  1343 net.cpp:150] Setting up pool2
I0826 09:29:14.568717  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.568722  1343 net.cpp:165] Memory required for data: 527666176
I0826 09:29:14.568727  1343 layer_factory.hpp:77] Creating layer conv3
I0826 09:29:14.568748  1343 net.cpp:100] Creating Layer conv3
I0826 09:29:14.568756  1343 net.cpp:434] conv3 <- pool2
I0826 09:29:14.568768  1343 net.cpp:408] conv3 -> conv3
I0826 09:29:14.592386  1343 net.cpp:150] Setting up conv3
I0826 09:29:14.592437  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.592443  1343 net.cpp:165] Memory required for data: 546933760
I0826 09:29:14.592484  1343 layer_factory.hpp:77] Creating layer relu3
I0826 09:29:14.592499  1343 net.cpp:100] Creating Layer relu3
I0826 09:29:14.592506  1343 net.cpp:434] relu3 <- conv3
I0826 09:29:14.592519  1343 net.cpp:395] relu3 -> conv3 (in-place)
I0826 09:29:14.592854  1343 net.cpp:150] Setting up relu3
I0826 09:29:14.592874  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.592877  1343 net.cpp:165] Memory required for data: 566201344
I0826 09:29:14.592882  1343 layer_factory.hpp:77] Creating layer conv4
I0826 09:29:14.592901  1343 net.cpp:100] Creating Layer conv4
I0826 09:29:14.592906  1343 net.cpp:434] conv4 <- conv3
I0826 09:29:14.592918  1343 net.cpp:408] conv4 -> conv4
I0826 09:29:14.612092  1343 net.cpp:150] Setting up conv4
I0826 09:29:14.612140  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.612146  1343 net.cpp:165] Memory required for data: 585468928
I0826 09:29:14.612162  1343 layer_factory.hpp:77] Creating layer relu4
I0826 09:29:14.612176  1343 net.cpp:100] Creating Layer relu4
I0826 09:29:14.612181  1343 net.cpp:434] relu4 <- conv4
I0826 09:29:14.612193  1343 net.cpp:395] relu4 -> conv4 (in-place)
I0826 09:29:14.614187  1343 net.cpp:150] Setting up relu4
I0826 09:29:14.614208  1343 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0826 09:29:14.614213  1343 net.cpp:165] Memory required for data: 604736512
I0826 09:29:14.614218  1343 layer_factory.hpp:77] Creating layer conv5
I0826 09:29:14.614239  1343 net.cpp:100] Creating Layer conv5
I0826 09:29:14.614245  1343 net.cpp:434] conv5 <- conv4
I0826 09:29:14.614254  1343 net.cpp:408] conv5 -> conv5
I0826 09:29:14.626386  1343 net.cpp:150] Setting up conv5
I0826 09:29:14.626410  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.626415  1343 net.cpp:165] Memory required for data: 617581568
I0826 09:29:14.626431  1343 layer_factory.hpp:77] Creating layer relu5
I0826 09:29:14.626441  1343 net.cpp:100] Creating Layer relu5
I0826 09:29:14.626446  1343 net.cpp:434] relu5 <- conv5
I0826 09:29:14.626454  1343 net.cpp:395] relu5 -> conv5 (in-place)
I0826 09:29:14.626749  1343 net.cpp:150] Setting up relu5
I0826 09:29:14.626765  1343 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0826 09:29:14.626770  1343 net.cpp:165] Memory required for data: 630426624
I0826 09:29:14.626773  1343 layer_factory.hpp:77] Creating layer pool5
I0826 09:29:14.626791  1343 net.cpp:100] Creating Layer pool5
I0826 09:29:14.626794  1343 net.cpp:434] pool5 <- conv5
I0826 09:29:14.626802  1343 net.cpp:408] pool5 -> pool5
I0826 09:29:14.626883  1343 net.cpp:150] Setting up pool5
I0826 09:29:14.626896  1343 net.cpp:157] Top shape: 256 256 3 3 (589824)
I0826 09:29:14.626900  1343 net.cpp:165] Memory required for data: 632785920
I0826 09:29:14.626904  1343 layer_factory.hpp:77] Creating layer fc6
I0826 09:29:14.626914  1343 net.cpp:100] Creating Layer fc6
I0826 09:29:14.626917  1343 net.cpp:434] fc6 <- pool5
I0826 09:29:14.626925  1343 net.cpp:408] fc6 -> fc6
I0826 09:29:14.765414  1343 net.cpp:150] Setting up fc6
I0826 09:29:14.765452  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.765456  1343 net.cpp:165] Memory required for data: 636980224
I0826 09:29:14.765468  1343 layer_factory.hpp:77] Creating layer relu6
I0826 09:29:14.765483  1343 net.cpp:100] Creating Layer relu6
I0826 09:29:14.765488  1343 net.cpp:434] relu6 <- fc6
I0826 09:29:14.765496  1343 net.cpp:395] relu6 -> fc6 (in-place)
I0826 09:29:14.765774  1343 net.cpp:150] Setting up relu6
I0826 09:29:14.765784  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.765787  1343 net.cpp:165] Memory required for data: 641174528
I0826 09:29:14.765790  1343 layer_factory.hpp:77] Creating layer drop6
I0826 09:29:14.765799  1343 net.cpp:100] Creating Layer drop6
I0826 09:29:14.765802  1343 net.cpp:434] drop6 <- fc6
I0826 09:29:14.765806  1343 net.cpp:395] drop6 -> fc6 (in-place)
I0826 09:29:14.765835  1343 net.cpp:150] Setting up drop6
I0826 09:29:14.765841  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.765843  1343 net.cpp:165] Memory required for data: 645368832
I0826 09:29:14.765846  1343 layer_factory.hpp:77] Creating layer fc7
I0826 09:29:14.765854  1343 net.cpp:100] Creating Layer fc7
I0826 09:29:14.765857  1343 net.cpp:434] fc7 <- fc6
I0826 09:29:14.765866  1343 net.cpp:408] fc7 -> fc7
I0826 09:29:14.996310  1343 net.cpp:150] Setting up fc7
I0826 09:29:14.996357  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.996361  1343 net.cpp:165] Memory required for data: 649563136
I0826 09:29:14.996372  1343 layer_factory.hpp:77] Creating layer relu7
I0826 09:29:14.996386  1343 net.cpp:100] Creating Layer relu7
I0826 09:29:14.996390  1343 net.cpp:434] relu7 <- fc7
I0826 09:29:14.996397  1343 net.cpp:395] relu7 -> fc7 (in-place)
I0826 09:29:14.997162  1343 net.cpp:150] Setting up relu7
I0826 09:29:14.997179  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.997184  1343 net.cpp:165] Memory required for data: 653757440
I0826 09:29:14.997186  1343 layer_factory.hpp:77] Creating layer drop7
I0826 09:29:14.997194  1343 net.cpp:100] Creating Layer drop7
I0826 09:29:14.997196  1343 net.cpp:434] drop7 <- fc7
I0826 09:29:14.997202  1343 net.cpp:395] drop7 -> fc7 (in-place)
I0826 09:29:14.997234  1343 net.cpp:150] Setting up drop7
I0826 09:29:14.997244  1343 net.cpp:157] Top shape: 256 4096 (1048576)
I0826 09:29:14.997247  1343 net.cpp:165] Memory required for data: 657951744
I0826 09:29:14.997251  1343 layer_factory.hpp:77] Creating layer fc8
I0826 09:29:14.997258  1343 net.cpp:100] Creating Layer fc8
I0826 09:29:14.997262  1343 net.cpp:434] fc8 <- fc7
I0826 09:29:14.997268  1343 net.cpp:408] fc8 -> fc8
I0826 09:29:15.002435  1343 net.cpp:150] Setting up fc8
I0826 09:29:15.002451  1343 net.cpp:157] Top shape: 256 80 (20480)
I0826 09:29:15.002454  1343 net.cpp:165] Memory required for data: 658033664
I0826 09:29:15.002461  1343 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0826 09:29:15.002470  1343 net.cpp:100] Creating Layer fc8_fc8_0_split
I0826 09:29:15.002475  1343 net.cpp:434] fc8_fc8_0_split <- fc8
I0826 09:29:15.002480  1343 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0826 09:29:15.002488  1343 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0826 09:29:15.002528  1343 net.cpp:150] Setting up fc8_fc8_0_split
I0826 09:29:15.002537  1343 net.cpp:157] Top shape: 256 80 (20480)
I0826 09:29:15.002539  1343 net.cpp:157] Top shape: 256 80 (20480)
I0826 09:29:15.002542  1343 net.cpp:165] Memory required for data: 658197504
I0826 09:29:15.002545  1343 layer_factory.hpp:77] Creating layer accuracy
I0826 09:29:15.002552  1343 net.cpp:100] Creating Layer accuracy
I0826 09:29:15.002555  1343 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0826 09:29:15.002559  1343 net.cpp:434] accuracy <- label_coco_1_split_0
I0826 09:29:15.002570  1343 net.cpp:408] accuracy -> accuracy
I0826 09:29:15.002578  1343 net.cpp:150] Setting up accuracy
I0826 09:29:15.002583  1343 net.cpp:157] Top shape: (1)
I0826 09:29:15.002585  1343 net.cpp:165] Memory required for data: 658197508
I0826 09:29:15.002588  1343 layer_factory.hpp:77] Creating layer loss
I0826 09:29:15.002593  1343 net.cpp:100] Creating Layer loss
I0826 09:29:15.002596  1343 net.cpp:434] loss <- fc8_fc8_0_split_1
I0826 09:29:15.002599  1343 net.cpp:434] loss <- label_coco_1_split_1
I0826 09:29:15.002605  1343 net.cpp:408] loss -> loss
I0826 09:29:15.002612  1343 layer_factory.hpp:77] Creating layer loss
I0826 09:29:15.002977  1343 net.cpp:150] Setting up loss
I0826 09:29:15.002990  1343 net.cpp:157] Top shape: (1)
I0826 09:29:15.002993  1343 net.cpp:160]     with loss weight 1
I0826 09:29:15.003005  1343 net.cpp:165] Memory required for data: 658197512
I0826 09:29:15.003010  1343 net.cpp:226] loss needs backward computation.
I0826 09:29:15.003015  1343 net.cpp:228] accuracy does not need backward computation.
I0826 09:29:15.003020  1343 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0826 09:29:15.003022  1343 net.cpp:226] fc8 needs backward computation.
I0826 09:29:15.003026  1343 net.cpp:226] drop7 needs backward computation.
I0826 09:29:15.003027  1343 net.cpp:226] relu7 needs backward computation.
I0826 09:29:15.003031  1343 net.cpp:226] fc7 needs backward computation.
I0826 09:29:15.003033  1343 net.cpp:226] drop6 needs backward computation.
I0826 09:29:15.003036  1343 net.cpp:226] relu6 needs backward computation.
I0826 09:29:15.003039  1343 net.cpp:226] fc6 needs backward computation.
I0826 09:29:15.003042  1343 net.cpp:226] pool5 needs backward computation.
I0826 09:29:15.003046  1343 net.cpp:226] relu5 needs backward computation.
I0826 09:29:15.003048  1343 net.cpp:226] conv5 needs backward computation.
I0826 09:29:15.003051  1343 net.cpp:226] relu4 needs backward computation.
I0826 09:29:15.003054  1343 net.cpp:226] conv4 needs backward computation.
I0826 09:29:15.003057  1343 net.cpp:226] relu3 needs backward computation.
I0826 09:29:15.003060  1343 net.cpp:226] conv3 needs backward computation.
I0826 09:29:15.003065  1343 net.cpp:226] pool2 needs backward computation.
I0826 09:29:15.003069  1343 net.cpp:226] norm2 needs backward computation.
I0826 09:29:15.003072  1343 net.cpp:226] relu2 needs backward computation.
I0826 09:29:15.003075  1343 net.cpp:226] conv2 needs backward computation.
I0826 09:29:15.003078  1343 net.cpp:226] pool1 needs backward computation.
I0826 09:29:15.003082  1343 net.cpp:226] norm1 needs backward computation.
I0826 09:29:15.003085  1343 net.cpp:226] relu1 needs backward computation.
I0826 09:29:15.003088  1343 net.cpp:226] conv1 needs backward computation.
I0826 09:29:15.003093  1343 net.cpp:228] label_coco_1_split does not need backward computation.
I0826 09:29:15.003096  1343 net.cpp:228] coco does not need backward computation.
I0826 09:29:15.003099  1343 net.cpp:270] This network produces output accuracy
I0826 09:29:15.003103  1343 net.cpp:270] This network produces output loss
I0826 09:29:15.003123  1343 net.cpp:283] Network initialization done.
I0826 09:29:15.003214  1343 solver.cpp:60] Solver scaffolding done.
I0826 09:29:15.006860  1343 solver.cpp:337] Iteration 0, Testing net (#0)
I0826 09:29:15.202786  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:29:49.910532  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:29:51.508118  1343 solver.cpp:404]     Test net output #0: accuracy = 0.00320443
I0826 09:29:51.508170  1343 solver.cpp:404]     Test net output #1: loss = 4.3957 (* 1 = 4.3957 loss)
I0826 09:29:51.561003  1343 solver.cpp:228] Iteration 0, loss = 4.39595
I0826 09:29:51.561070  1343 solver.cpp:244]     Train net output #0: loss = 4.39595 (* 1 = 4.39595 loss)
I0826 09:29:51.561087  1343 sgd_solver.cpp:106] Iteration 0, lr = 1e-06
I0826 09:29:59.905684  1343 solver.cpp:228] Iteration 100, loss = 4.40148
I0826 09:29:59.905745  1343 solver.cpp:244]     Train net output #0: loss = 4.40148 (* 1 = 4.40148 loss)
I0826 09:29:59.905753  1343 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-07
I0826 09:30:08.268929  1343 solver.cpp:228] Iteration 200, loss = 4.38942
I0826 09:30:08.268997  1343 solver.cpp:244]     Train net output #0: loss = 4.38942 (* 1 = 4.38942 loss)
I0826 09:30:08.269004  1343 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-07
I0826 09:30:16.633725  1343 solver.cpp:228] Iteration 300, loss = 4.38687
I0826 09:30:16.633781  1343 solver.cpp:244]     Train net output #0: loss = 4.38687 (* 1 = 4.38687 loss)
I0826 09:30:16.633790  1343 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-07
I0826 09:30:24.995085  1343 solver.cpp:228] Iteration 400, loss = 4.37541
I0826 09:30:24.995132  1343 solver.cpp:244]     Train net output #0: loss = 4.37541 (* 1 = 4.37541 loss)
I0826 09:30:24.995138  1343 sgd_solver.cpp:106] Iteration 400, lr = 9.85258e-07
I0826 09:30:33.369261  1343 solver.cpp:228] Iteration 500, loss = 4.35776
I0826 09:30:33.369319  1343 solver.cpp:244]     Train net output #0: loss = 4.35776 (* 1 = 4.35776 loss)
I0826 09:30:33.369328  1343 sgd_solver.cpp:106] Iteration 500, lr = 9.81651e-07
I0826 09:30:41.764667  1343 solver.cpp:228] Iteration 600, loss = 4.36095
I0826 09:30:41.764724  1343 solver.cpp:244]     Train net output #0: loss = 4.36095 (* 1 = 4.36095 loss)
I0826 09:30:41.764730  1343 sgd_solver.cpp:106] Iteration 600, lr = 9.78075e-07
I0826 09:30:50.156589  1343 solver.cpp:228] Iteration 700, loss = 4.35066
I0826 09:30:50.156652  1343 solver.cpp:244]     Train net output #0: loss = 4.35066 (* 1 = 4.35066 loss)
I0826 09:30:50.156662  1343 sgd_solver.cpp:106] Iteration 700, lr = 9.74529e-07
I0826 09:30:58.536720  1343 solver.cpp:228] Iteration 800, loss = 4.34129
I0826 09:30:58.536777  1343 solver.cpp:244]     Train net output #0: loss = 4.34129 (* 1 = 4.34129 loss)
I0826 09:30:58.536787  1343 sgd_solver.cpp:106] Iteration 800, lr = 9.71013e-07
I0826 09:31:06.932119  1343 solver.cpp:228] Iteration 900, loss = 4.35041
I0826 09:31:06.932193  1343 solver.cpp:244]     Train net output #0: loss = 4.35041 (* 1 = 4.35041 loss)
I0826 09:31:06.932199  1343 sgd_solver.cpp:106] Iteration 900, lr = 9.67526e-07
I0826 09:31:15.324803  1343 solver.cpp:228] Iteration 1000, loss = 4.33151
I0826 09:31:15.324892  1343 solver.cpp:244]     Train net output #0: loss = 4.33151 (* 1 = 4.33151 loss)
I0826 09:31:15.324904  1343 sgd_solver.cpp:106] Iteration 1000, lr = 9.64069e-07
I0826 09:31:23.719380  1343 solver.cpp:228] Iteration 1100, loss = 4.32981
I0826 09:31:23.719446  1343 solver.cpp:244]     Train net output #0: loss = 4.32981 (* 1 = 4.32981 loss)
I0826 09:31:23.719456  1343 sgd_solver.cpp:106] Iteration 1100, lr = 9.6064e-07
I0826 09:31:32.120507  1343 solver.cpp:228] Iteration 1200, loss = 4.30063
I0826 09:31:32.120568  1343 solver.cpp:244]     Train net output #0: loss = 4.30063 (* 1 = 4.30063 loss)
I0826 09:31:32.120578  1343 sgd_solver.cpp:106] Iteration 1200, lr = 9.5724e-07
I0826 09:31:40.509426  1343 solver.cpp:228] Iteration 1300, loss = 4.31625
I0826 09:31:40.509485  1343 solver.cpp:244]     Train net output #0: loss = 4.31625 (* 1 = 4.31625 loss)
I0826 09:31:40.509495  1343 sgd_solver.cpp:106] Iteration 1300, lr = 9.53867e-07
I0826 09:31:48.926141  1343 solver.cpp:228] Iteration 1400, loss = 4.30282
I0826 09:31:48.926203  1343 solver.cpp:244]     Train net output #0: loss = 4.30282 (* 1 = 4.30282 loss)
I0826 09:31:48.926213  1343 sgd_solver.cpp:106] Iteration 1400, lr = 9.50522e-07
I0826 09:31:57.309464  1343 solver.cpp:228] Iteration 1500, loss = 4.31037
I0826 09:31:57.309581  1343 solver.cpp:244]     Train net output #0: loss = 4.31037 (* 1 = 4.31037 loss)
I0826 09:31:57.309598  1343 sgd_solver.cpp:106] Iteration 1500, lr = 9.47204e-07
I0826 09:32:05.723413  1343 solver.cpp:228] Iteration 1600, loss = 4.28561
I0826 09:32:05.723471  1343 solver.cpp:244]     Train net output #0: loss = 4.28561 (* 1 = 4.28561 loss)
I0826 09:32:05.723482  1343 sgd_solver.cpp:106] Iteration 1600, lr = 9.43913e-07
I0826 09:32:14.120584  1343 solver.cpp:228] Iteration 1700, loss = 4.29108
I0826 09:32:14.120651  1343 solver.cpp:244]     Train net output #0: loss = 4.29108 (* 1 = 4.29108 loss)
I0826 09:32:14.120661  1343 sgd_solver.cpp:106] Iteration 1700, lr = 9.40649e-07
I0826 09:32:22.523977  1343 solver.cpp:228] Iteration 1800, loss = 4.27707
I0826 09:32:22.524044  1343 solver.cpp:244]     Train net output #0: loss = 4.27707 (* 1 = 4.27707 loss)
I0826 09:32:22.524052  1343 sgd_solver.cpp:106] Iteration 1800, lr = 9.37411e-07
I0826 09:32:30.937392  1343 solver.cpp:228] Iteration 1900, loss = 4.26917
I0826 09:32:30.937458  1343 solver.cpp:244]     Train net output #0: loss = 4.26917 (* 1 = 4.26917 loss)
I0826 09:32:30.937465  1343 sgd_solver.cpp:106] Iteration 1900, lr = 9.34199e-07
I0826 09:32:39.344910  1343 solver.cpp:228] Iteration 2000, loss = 4.26562
I0826 09:32:39.344974  1343 solver.cpp:244]     Train net output #0: loss = 4.26562 (* 1 = 4.26562 loss)
I0826 09:32:39.344982  1343 sgd_solver.cpp:106] Iteration 2000, lr = 9.31012e-07
I0826 09:32:47.767959  1343 solver.cpp:228] Iteration 2100, loss = 4.25634
I0826 09:32:47.768013  1343 solver.cpp:244]     Train net output #0: loss = 4.25634 (* 1 = 4.25634 loss)
I0826 09:32:47.768021  1343 sgd_solver.cpp:106] Iteration 2100, lr = 9.27851e-07
I0826 09:32:56.191925  1343 solver.cpp:228] Iteration 2200, loss = 4.22515
I0826 09:32:56.191980  1343 solver.cpp:244]     Train net output #0: loss = 4.22515 (* 1 = 4.22515 loss)
I0826 09:32:56.191988  1343 sgd_solver.cpp:106] Iteration 2200, lr = 9.24715e-07
I0826 09:33:04.583281  1343 solver.cpp:228] Iteration 2300, loss = 4.22885
I0826 09:33:04.583323  1343 solver.cpp:244]     Train net output #0: loss = 4.22885 (* 1 = 4.22885 loss)
I0826 09:33:04.583329  1343 sgd_solver.cpp:106] Iteration 2300, lr = 9.21603e-07
I0826 09:33:12.991804  1343 solver.cpp:228] Iteration 2400, loss = 4.24153
I0826 09:33:12.991844  1343 solver.cpp:244]     Train net output #0: loss = 4.24153 (* 1 = 4.24153 loss)
I0826 09:33:12.991850  1343 sgd_solver.cpp:106] Iteration 2400, lr = 9.18515e-07
I0826 09:33:21.402441  1343 solver.cpp:228] Iteration 2500, loss = 4.22464
I0826 09:33:21.402504  1343 solver.cpp:244]     Train net output #0: loss = 4.22464 (* 1 = 4.22464 loss)
I0826 09:33:21.402513  1343 sgd_solver.cpp:106] Iteration 2500, lr = 9.15452e-07
I0826 09:33:29.817495  1343 solver.cpp:228] Iteration 2600, loss = 4.19676
I0826 09:33:29.817574  1343 solver.cpp:244]     Train net output #0: loss = 4.19676 (* 1 = 4.19676 loss)
I0826 09:33:29.817586  1343 sgd_solver.cpp:106] Iteration 2600, lr = 9.12412e-07
I0826 09:33:38.207823  1343 solver.cpp:228] Iteration 2700, loss = 4.23026
I0826 09:33:38.207866  1343 solver.cpp:244]     Train net output #0: loss = 4.23026 (* 1 = 4.23026 loss)
I0826 09:33:38.207872  1343 sgd_solver.cpp:106] Iteration 2700, lr = 9.09396e-07
I0826 09:33:46.626785  1343 solver.cpp:228] Iteration 2800, loss = 4.22876
I0826 09:33:46.626847  1343 solver.cpp:244]     Train net output #0: loss = 4.22876 (* 1 = 4.22876 loss)
I0826 09:33:46.626853  1343 sgd_solver.cpp:106] Iteration 2800, lr = 9.06403e-07
I0826 09:33:53.382378  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:33:55.060488  1343 solver.cpp:228] Iteration 2900, loss = 4.19504
I0826 09:33:55.060551  1343 solver.cpp:244]     Train net output #0: loss = 4.19504 (* 1 = 4.19504 loss)
I0826 09:33:55.060560  1343 sgd_solver.cpp:106] Iteration 2900, lr = 9.03433e-07
I0826 09:34:03.481508  1343 solver.cpp:228] Iteration 3000, loss = 4.19602
I0826 09:34:03.481570  1343 solver.cpp:244]     Train net output #0: loss = 4.19602 (* 1 = 4.19602 loss)
I0826 09:34:03.481580  1343 sgd_solver.cpp:106] Iteration 3000, lr = 9.00485e-07
I0826 09:34:11.900545  1343 solver.cpp:228] Iteration 3100, loss = 4.18614
I0826 09:34:11.900607  1343 solver.cpp:244]     Train net output #0: loss = 4.18614 (* 1 = 4.18614 loss)
I0826 09:34:11.900615  1343 sgd_solver.cpp:106] Iteration 3100, lr = 8.9756e-07
I0826 09:34:20.341053  1343 solver.cpp:228] Iteration 3200, loss = 4.20468
I0826 09:34:20.341111  1343 solver.cpp:244]     Train net output #0: loss = 4.20468 (* 1 = 4.20468 loss)
I0826 09:34:20.341120  1343 sgd_solver.cpp:106] Iteration 3200, lr = 8.94657e-07
I0826 09:34:28.750733  1343 solver.cpp:228] Iteration 3300, loss = 4.15637
I0826 09:34:28.750788  1343 solver.cpp:244]     Train net output #0: loss = 4.15637 (* 1 = 4.15637 loss)
I0826 09:34:28.750798  1343 sgd_solver.cpp:106] Iteration 3300, lr = 8.91776e-07
I0826 09:34:37.184522  1343 solver.cpp:228] Iteration 3400, loss = 4.17802
I0826 09:34:37.184587  1343 solver.cpp:244]     Train net output #0: loss = 4.17802 (* 1 = 4.17802 loss)
I0826 09:34:37.184595  1343 sgd_solver.cpp:106] Iteration 3400, lr = 8.88916e-07
I0826 09:34:45.615067  1343 solver.cpp:228] Iteration 3500, loss = 4.17777
I0826 09:34:45.615111  1343 solver.cpp:244]     Train net output #0: loss = 4.17777 (* 1 = 4.17777 loss)
I0826 09:34:45.615118  1343 sgd_solver.cpp:106] Iteration 3500, lr = 8.86077e-07
I0826 09:34:54.046552  1343 solver.cpp:228] Iteration 3600, loss = 4.1384
I0826 09:34:54.046615  1343 solver.cpp:244]     Train net output #0: loss = 4.1384 (* 1 = 4.1384 loss)
I0826 09:34:54.046624  1343 sgd_solver.cpp:106] Iteration 3600, lr = 8.8326e-07
I0826 09:35:02.484984  1343 solver.cpp:228] Iteration 3700, loss = 4.1332
I0826 09:35:02.485044  1343 solver.cpp:244]     Train net output #0: loss = 4.1332 (* 1 = 4.1332 loss)
I0826 09:35:02.485052  1343 sgd_solver.cpp:106] Iteration 3700, lr = 8.80463e-07
I0826 09:35:10.890966  1343 solver.cpp:228] Iteration 3800, loss = 4.15134
I0826 09:35:10.891026  1343 solver.cpp:244]     Train net output #0: loss = 4.15134 (* 1 = 4.15134 loss)
I0826 09:35:10.891034  1343 sgd_solver.cpp:106] Iteration 3800, lr = 8.77687e-07
I0826 09:35:19.314759  1343 solver.cpp:228] Iteration 3900, loss = 4.13925
I0826 09:35:19.314807  1343 solver.cpp:244]     Train net output #0: loss = 4.13925 (* 1 = 4.13925 loss)
I0826 09:35:19.314815  1343 sgd_solver.cpp:106] Iteration 3900, lr = 8.74932e-07
I0826 09:35:27.728992  1343 solver.cpp:228] Iteration 4000, loss = 4.19603
I0826 09:35:27.729045  1343 solver.cpp:244]     Train net output #0: loss = 4.19603 (* 1 = 4.19603 loss)
I0826 09:35:27.729051  1343 sgd_solver.cpp:106] Iteration 4000, lr = 8.72196e-07
I0826 09:35:36.131403  1343 solver.cpp:228] Iteration 4100, loss = 4.11312
I0826 09:35:36.131464  1343 solver.cpp:244]     Train net output #0: loss = 4.11312 (* 1 = 4.11312 loss)
I0826 09:35:36.131474  1343 sgd_solver.cpp:106] Iteration 4100, lr = 8.6948e-07
I0826 09:35:44.534737  1343 solver.cpp:228] Iteration 4200, loss = 4.11548
I0826 09:35:44.534803  1343 solver.cpp:244]     Train net output #0: loss = 4.11548 (* 1 = 4.11548 loss)
I0826 09:35:44.534814  1343 sgd_solver.cpp:106] Iteration 4200, lr = 8.66784e-07
I0826 09:35:52.956279  1343 solver.cpp:228] Iteration 4300, loss = 4.11119
I0826 09:35:52.956341  1343 solver.cpp:244]     Train net output #0: loss = 4.11119 (* 1 = 4.11119 loss)
I0826 09:35:52.956348  1343 sgd_solver.cpp:106] Iteration 4300, lr = 8.64108e-07
I0826 09:36:01.354523  1343 solver.cpp:228] Iteration 4400, loss = 4.14034
I0826 09:36:01.354584  1343 solver.cpp:244]     Train net output #0: loss = 4.14034 (* 1 = 4.14034 loss)
I0826 09:36:01.354595  1343 sgd_solver.cpp:106] Iteration 4400, lr = 8.6145e-07
I0826 09:36:09.778673  1343 solver.cpp:228] Iteration 4500, loss = 4.11006
I0826 09:36:09.778735  1343 solver.cpp:244]     Train net output #0: loss = 4.11006 (* 1 = 4.11006 loss)
I0826 09:36:09.778743  1343 sgd_solver.cpp:106] Iteration 4500, lr = 8.58812e-07
I0826 09:36:18.205911  1343 solver.cpp:228] Iteration 4600, loss = 4.13211
I0826 09:36:18.205996  1343 solver.cpp:244]     Train net output #0: loss = 4.13211 (* 1 = 4.13211 loss)
I0826 09:36:18.206007  1343 sgd_solver.cpp:106] Iteration 4600, lr = 8.56192e-07
I0826 09:36:26.612133  1343 solver.cpp:228] Iteration 4700, loss = 4.09764
I0826 09:36:26.612192  1343 solver.cpp:244]     Train net output #0: loss = 4.09764 (* 1 = 4.09764 loss)
I0826 09:36:26.612202  1343 sgd_solver.cpp:106] Iteration 4700, lr = 8.53591e-07
I0826 09:36:35.023236  1343 solver.cpp:228] Iteration 4800, loss = 4.06848
I0826 09:36:35.023273  1343 solver.cpp:244]     Train net output #0: loss = 4.06848 (* 1 = 4.06848 loss)
I0826 09:36:35.023279  1343 sgd_solver.cpp:106] Iteration 4800, lr = 8.51008e-07
I0826 09:36:43.445950  1343 solver.cpp:228] Iteration 4900, loss = 4.12589
I0826 09:36:43.446015  1343 solver.cpp:244]     Train net output #0: loss = 4.12589 (* 1 = 4.12589 loss)
I0826 09:36:43.446027  1343 sgd_solver.cpp:106] Iteration 4900, lr = 8.48444e-07
I0826 09:36:51.742477  1343 solver.cpp:337] Iteration 5000, Testing net (#0)
I0826 09:37:04.895803  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:37:28.289285  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302017
I0826 09:37:28.289333  1343 solver.cpp:404]     Test net output #1: loss = 4.08186 (* 1 = 4.08186 loss)
I0826 09:37:28.319002  1343 solver.cpp:228] Iteration 5000, loss = 4.09616
I0826 09:37:28.319049  1343 solver.cpp:244]     Train net output #0: loss = 4.09616 (* 1 = 4.09616 loss)
I0826 09:37:28.319062  1343 sgd_solver.cpp:106] Iteration 5000, lr = 8.45897e-07
I0826 09:37:36.719789  1343 solver.cpp:228] Iteration 5100, loss = 4.06779
I0826 09:37:36.719842  1343 solver.cpp:244]     Train net output #0: loss = 4.06779 (* 1 = 4.06779 loss)
I0826 09:37:36.719851  1343 sgd_solver.cpp:106] Iteration 5100, lr = 8.43368e-07
I0826 09:37:45.149621  1343 solver.cpp:228] Iteration 5200, loss = 4.09983
I0826 09:37:45.149672  1343 solver.cpp:244]     Train net output #0: loss = 4.09983 (* 1 = 4.09983 loss)
I0826 09:37:45.149680  1343 sgd_solver.cpp:106] Iteration 5200, lr = 8.40857e-07
I0826 09:37:53.560467  1343 solver.cpp:228] Iteration 5300, loss = 4.05085
I0826 09:37:53.560525  1343 solver.cpp:244]     Train net output #0: loss = 4.05085 (* 1 = 4.05085 loss)
I0826 09:37:53.560534  1343 sgd_solver.cpp:106] Iteration 5300, lr = 8.38363e-07
I0826 09:38:01.973616  1343 solver.cpp:228] Iteration 5400, loss = 4.05136
I0826 09:38:01.973670  1343 solver.cpp:244]     Train net output #0: loss = 4.05136 (* 1 = 4.05136 loss)
I0826 09:38:01.973681  1343 sgd_solver.cpp:106] Iteration 5400, lr = 8.35886e-07
I0826 09:38:10.394538  1343 solver.cpp:228] Iteration 5500, loss = 4.08476
I0826 09:38:10.394582  1343 solver.cpp:244]     Train net output #0: loss = 4.08476 (* 1 = 4.08476 loss)
I0826 09:38:10.394590  1343 sgd_solver.cpp:106] Iteration 5500, lr = 8.33427e-07
I0826 09:38:18.809211  1343 solver.cpp:228] Iteration 5600, loss = 4.05833
I0826 09:38:18.809273  1343 solver.cpp:244]     Train net output #0: loss = 4.05833 (* 1 = 4.05833 loss)
I0826 09:38:18.809278  1343 sgd_solver.cpp:106] Iteration 5600, lr = 8.30984e-07
I0826 09:38:27.219518  1343 solver.cpp:228] Iteration 5700, loss = 4.06471
I0826 09:38:27.219575  1343 solver.cpp:244]     Train net output #0: loss = 4.06471 (* 1 = 4.06471 loss)
I0826 09:38:27.219586  1343 sgd_solver.cpp:106] Iteration 5700, lr = 8.28558e-07
I0826 09:38:35.635327  1343 solver.cpp:228] Iteration 5800, loss = 4.06321
I0826 09:38:35.635386  1343 solver.cpp:244]     Train net output #0: loss = 4.06321 (* 1 = 4.06321 loss)
I0826 09:38:35.635395  1343 sgd_solver.cpp:106] Iteration 5800, lr = 8.26148e-07
I0826 09:38:44.059604  1343 solver.cpp:228] Iteration 5900, loss = 4.01867
I0826 09:38:44.059648  1343 solver.cpp:244]     Train net output #0: loss = 4.01867 (* 1 = 4.01867 loss)
I0826 09:38:44.059653  1343 sgd_solver.cpp:106] Iteration 5900, lr = 8.23754e-07
I0826 09:38:52.477566  1343 solver.cpp:228] Iteration 6000, loss = 3.97391
I0826 09:38:52.477627  1343 solver.cpp:244]     Train net output #0: loss = 3.97391 (* 1 = 3.97391 loss)
I0826 09:38:52.477634  1343 sgd_solver.cpp:106] Iteration 6000, lr = 8.21377e-07
I0826 09:39:00.882158  1343 solver.cpp:228] Iteration 6100, loss = 4.02004
I0826 09:39:00.882201  1343 solver.cpp:244]     Train net output #0: loss = 4.02004 (* 1 = 4.02004 loss)
I0826 09:39:00.882207  1343 sgd_solver.cpp:106] Iteration 6100, lr = 8.19015e-07
I0826 09:39:09.302316  1343 solver.cpp:228] Iteration 6200, loss = 4.09194
I0826 09:39:09.302376  1343 solver.cpp:244]     Train net output #0: loss = 4.09194 (* 1 = 4.09194 loss)
I0826 09:39:09.302386  1343 sgd_solver.cpp:106] Iteration 6200, lr = 8.1667e-07
I0826 09:39:17.686803  1343 solver.cpp:228] Iteration 6300, loss = 3.96245
I0826 09:39:17.686844  1343 solver.cpp:244]     Train net output #0: loss = 3.96245 (* 1 = 3.96245 loss)
I0826 09:39:17.686851  1343 sgd_solver.cpp:106] Iteration 6300, lr = 8.1434e-07
I0826 09:39:26.093217  1343 solver.cpp:228] Iteration 6400, loss = 3.95789
I0826 09:39:26.093278  1343 solver.cpp:244]     Train net output #0: loss = 3.95789 (* 1 = 3.95789 loss)
I0826 09:39:26.093286  1343 sgd_solver.cpp:106] Iteration 6400, lr = 8.12025e-07
I0826 09:39:34.500064  1343 solver.cpp:228] Iteration 6500, loss = 4.02138
I0826 09:39:34.500107  1343 solver.cpp:244]     Train net output #0: loss = 4.02138 (* 1 = 4.02138 loss)
I0826 09:39:34.500113  1343 sgd_solver.cpp:106] Iteration 6500, lr = 8.09726e-07
I0826 09:39:38.126389  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:39:42.909096  1343 solver.cpp:228] Iteration 6600, loss = 4.00593
I0826 09:39:42.909148  1343 solver.cpp:244]     Train net output #0: loss = 4.00593 (* 1 = 4.00593 loss)
I0826 09:39:42.909157  1343 sgd_solver.cpp:106] Iteration 6600, lr = 8.07442e-07
I0826 09:39:51.310237  1343 solver.cpp:228] Iteration 6700, loss = 4.00085
I0826 09:39:51.310281  1343 solver.cpp:244]     Train net output #0: loss = 4.00085 (* 1 = 4.00085 loss)
I0826 09:39:51.310287  1343 sgd_solver.cpp:106] Iteration 6700, lr = 8.05173e-07
I0826 09:39:59.712582  1343 solver.cpp:228] Iteration 6800, loss = 3.97328
I0826 09:39:59.712620  1343 solver.cpp:244]     Train net output #0: loss = 3.97328 (* 1 = 3.97328 loss)
I0826 09:39:59.712626  1343 sgd_solver.cpp:106] Iteration 6800, lr = 8.02918e-07
I0826 09:40:08.140230  1343 solver.cpp:228] Iteration 6900, loss = 3.97236
I0826 09:40:08.140292  1343 solver.cpp:244]     Train net output #0: loss = 3.97236 (* 1 = 3.97236 loss)
I0826 09:40:08.140302  1343 sgd_solver.cpp:106] Iteration 6900, lr = 8.00679e-07
I0826 09:40:16.551687  1343 solver.cpp:228] Iteration 7000, loss = 3.98846
I0826 09:40:16.551725  1343 solver.cpp:244]     Train net output #0: loss = 3.98846 (* 1 = 3.98846 loss)
I0826 09:40:16.551733  1343 sgd_solver.cpp:106] Iteration 7000, lr = 7.98454e-07
I0826 09:40:24.965782  1343 solver.cpp:228] Iteration 7100, loss = 3.94843
I0826 09:40:24.965844  1343 solver.cpp:244]     Train net output #0: loss = 3.94843 (* 1 = 3.94843 loss)
I0826 09:40:24.965854  1343 sgd_solver.cpp:106] Iteration 7100, lr = 7.96243e-07
I0826 09:40:33.388424  1343 solver.cpp:228] Iteration 7200, loss = 3.93644
I0826 09:40:33.388466  1343 solver.cpp:244]     Train net output #0: loss = 3.93644 (* 1 = 3.93644 loss)
I0826 09:40:33.388473  1343 sgd_solver.cpp:106] Iteration 7200, lr = 7.94046e-07
I0826 09:40:41.800637  1343 solver.cpp:228] Iteration 7300, loss = 3.93722
I0826 09:40:41.800693  1343 solver.cpp:244]     Train net output #0: loss = 3.93722 (* 1 = 3.93722 loss)
I0826 09:40:41.800704  1343 sgd_solver.cpp:106] Iteration 7300, lr = 7.91864e-07
I0826 09:40:50.207177  1343 solver.cpp:228] Iteration 7400, loss = 3.93934
I0826 09:40:50.207239  1343 solver.cpp:244]     Train net output #0: loss = 3.93934 (* 1 = 3.93934 loss)
I0826 09:40:50.207248  1343 sgd_solver.cpp:106] Iteration 7400, lr = 7.89695e-07
I0826 09:40:58.618175  1343 solver.cpp:228] Iteration 7500, loss = 3.89713
I0826 09:40:58.618234  1343 solver.cpp:244]     Train net output #0: loss = 3.89713 (* 1 = 3.89713 loss)
I0826 09:40:58.618243  1343 sgd_solver.cpp:106] Iteration 7500, lr = 7.87541e-07
I0826 09:41:07.023134  1343 solver.cpp:228] Iteration 7600, loss = 3.95962
I0826 09:41:07.023193  1343 solver.cpp:244]     Train net output #0: loss = 3.95962 (* 1 = 3.95962 loss)
I0826 09:41:07.023202  1343 sgd_solver.cpp:106] Iteration 7600, lr = 7.854e-07
I0826 09:41:15.439951  1343 solver.cpp:228] Iteration 7700, loss = 3.89683
I0826 09:41:15.439998  1343 solver.cpp:244]     Train net output #0: loss = 3.89683 (* 1 = 3.89683 loss)
I0826 09:41:15.440006  1343 sgd_solver.cpp:106] Iteration 7700, lr = 7.83272e-07
I0826 09:41:23.854527  1343 solver.cpp:228] Iteration 7800, loss = 3.93738
I0826 09:41:23.854586  1343 solver.cpp:244]     Train net output #0: loss = 3.93738 (* 1 = 3.93738 loss)
I0826 09:41:23.854598  1343 sgd_solver.cpp:106] Iteration 7800, lr = 7.81158e-07
I0826 09:41:32.260185  1343 solver.cpp:228] Iteration 7900, loss = 3.9508
I0826 09:41:32.260238  1343 solver.cpp:244]     Train net output #0: loss = 3.9508 (* 1 = 3.9508 loss)
I0826 09:41:32.260246  1343 sgd_solver.cpp:106] Iteration 7900, lr = 7.79057e-07
I0826 09:41:40.677633  1343 solver.cpp:228] Iteration 8000, loss = 3.89776
I0826 09:41:40.677695  1343 solver.cpp:244]     Train net output #0: loss = 3.89776 (* 1 = 3.89776 loss)
I0826 09:41:40.677706  1343 sgd_solver.cpp:106] Iteration 8000, lr = 7.7697e-07
I0826 09:41:49.080247  1343 solver.cpp:228] Iteration 8100, loss = 3.86084
I0826 09:41:49.080287  1343 solver.cpp:244]     Train net output #0: loss = 3.86084 (* 1 = 3.86084 loss)
I0826 09:41:49.080293  1343 sgd_solver.cpp:106] Iteration 8100, lr = 7.74895e-07
I0826 09:41:57.484844  1343 solver.cpp:228] Iteration 8200, loss = 3.90735
I0826 09:41:57.484897  1343 solver.cpp:244]     Train net output #0: loss = 3.90735 (* 1 = 3.90735 loss)
I0826 09:41:57.484905  1343 sgd_solver.cpp:106] Iteration 8200, lr = 7.72833e-07
I0826 09:42:05.901410  1343 solver.cpp:228] Iteration 8300, loss = 3.87208
I0826 09:42:05.901489  1343 solver.cpp:244]     Train net output #0: loss = 3.87208 (* 1 = 3.87208 loss)
I0826 09:42:05.901499  1343 sgd_solver.cpp:106] Iteration 8300, lr = 7.70784e-07
I0826 09:42:14.289620  1343 solver.cpp:228] Iteration 8400, loss = 3.92142
I0826 09:42:14.289680  1343 solver.cpp:244]     Train net output #0: loss = 3.92142 (* 1 = 3.92142 loss)
I0826 09:42:14.289686  1343 sgd_solver.cpp:106] Iteration 8400, lr = 7.68748e-07
I0826 09:42:22.702160  1343 solver.cpp:228] Iteration 8500, loss = 3.83149
I0826 09:42:22.702209  1343 solver.cpp:244]     Train net output #0: loss = 3.83149 (* 1 = 3.83149 loss)
I0826 09:42:22.702216  1343 sgd_solver.cpp:106] Iteration 8500, lr = 7.66724e-07
I0826 09:42:31.120098  1343 solver.cpp:228] Iteration 8600, loss = 3.93138
I0826 09:42:31.120139  1343 solver.cpp:244]     Train net output #0: loss = 3.93138 (* 1 = 3.93138 loss)
I0826 09:42:31.120146  1343 sgd_solver.cpp:106] Iteration 8600, lr = 7.64712e-07
I0826 09:42:39.528905  1343 solver.cpp:228] Iteration 8700, loss = 3.96261
I0826 09:42:39.528951  1343 solver.cpp:244]     Train net output #0: loss = 3.96261 (* 1 = 3.96261 loss)
I0826 09:42:39.528956  1343 sgd_solver.cpp:106] Iteration 8700, lr = 7.62713e-07
I0826 09:42:47.950724  1343 solver.cpp:228] Iteration 8800, loss = 3.90776
I0826 09:42:47.950788  1343 solver.cpp:244]     Train net output #0: loss = 3.90776 (* 1 = 3.90776 loss)
I0826 09:42:47.950801  1343 sgd_solver.cpp:106] Iteration 8800, lr = 7.60726e-07
I0826 09:42:56.377640  1343 solver.cpp:228] Iteration 8900, loss = 3.99203
I0826 09:42:56.377699  1343 solver.cpp:244]     Train net output #0: loss = 3.99203 (* 1 = 3.99203 loss)
I0826 09:42:56.377708  1343 sgd_solver.cpp:106] Iteration 8900, lr = 7.58751e-07
I0826 09:43:04.778118  1343 solver.cpp:228] Iteration 9000, loss = 3.84086
I0826 09:43:04.778179  1343 solver.cpp:244]     Train net output #0: loss = 3.84086 (* 1 = 3.84086 loss)
I0826 09:43:04.778189  1343 sgd_solver.cpp:106] Iteration 9000, lr = 7.56788e-07
I0826 09:43:13.205657  1343 solver.cpp:228] Iteration 9100, loss = 3.95416
I0826 09:43:13.205703  1343 solver.cpp:244]     Train net output #0: loss = 3.95416 (* 1 = 3.95416 loss)
I0826 09:43:13.205708  1343 sgd_solver.cpp:106] Iteration 9100, lr = 7.54836e-07
I0826 09:43:21.597044  1343 solver.cpp:228] Iteration 9200, loss = 3.84795
I0826 09:43:21.597108  1343 solver.cpp:244]     Train net output #0: loss = 3.84795 (* 1 = 3.84795 loss)
I0826 09:43:21.597120  1343 sgd_solver.cpp:106] Iteration 9200, lr = 7.52897e-07
I0826 09:43:30.004920  1343 solver.cpp:228] Iteration 9300, loss = 3.91681
I0826 09:43:30.004983  1343 solver.cpp:244]     Train net output #0: loss = 3.91681 (* 1 = 3.91681 loss)
I0826 09:43:30.004992  1343 sgd_solver.cpp:106] Iteration 9300, lr = 7.50969e-07
I0826 09:43:38.401708  1343 solver.cpp:228] Iteration 9400, loss = 3.80243
I0826 09:43:38.401779  1343 solver.cpp:244]     Train net output #0: loss = 3.80243 (* 1 = 3.80243 loss)
I0826 09:43:38.401793  1343 sgd_solver.cpp:106] Iteration 9400, lr = 7.49052e-07
I0826 09:43:46.799908  1343 solver.cpp:228] Iteration 9500, loss = 3.82307
I0826 09:43:46.799950  1343 solver.cpp:244]     Train net output #0: loss = 3.82307 (* 1 = 3.82307 loss)
I0826 09:43:46.799955  1343 sgd_solver.cpp:106] Iteration 9500, lr = 7.47147e-07
I0826 09:43:55.177924  1343 solver.cpp:228] Iteration 9600, loss = 3.88095
I0826 09:43:55.177974  1343 solver.cpp:244]     Train net output #0: loss = 3.88095 (* 1 = 3.88095 loss)
I0826 09:43:55.177983  1343 sgd_solver.cpp:106] Iteration 9600, lr = 7.45253e-07
I0826 09:44:03.593683  1343 solver.cpp:228] Iteration 9700, loss = 3.85395
I0826 09:44:03.593740  1343 solver.cpp:244]     Train net output #0: loss = 3.85395 (* 1 = 3.85395 loss)
I0826 09:44:03.593750  1343 sgd_solver.cpp:106] Iteration 9700, lr = 7.4337e-07
I0826 09:44:11.992391  1343 solver.cpp:228] Iteration 9800, loss = 3.82432
I0826 09:44:11.992446  1343 solver.cpp:244]     Train net output #0: loss = 3.82432 (* 1 = 3.82432 loss)
I0826 09:44:11.992455  1343 sgd_solver.cpp:106] Iteration 9800, lr = 7.41499e-07
I0826 09:44:20.408442  1343 solver.cpp:228] Iteration 9900, loss = 3.79922
I0826 09:44:20.408507  1343 solver.cpp:244]     Train net output #0: loss = 3.79922 (* 1 = 3.79922 loss)
I0826 09:44:20.408519  1343 sgd_solver.cpp:106] Iteration 9900, lr = 7.39638e-07
I0826 09:44:25.788611  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:44:28.740030  1343 solver.cpp:337] Iteration 10000, Testing net (#0)
I0826 09:45:05.350932  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302034
I0826 09:45:05.350982  1343 solver.cpp:404]     Test net output #1: loss = 3.83457 (* 1 = 3.83457 loss)
I0826 09:45:05.380512  1343 solver.cpp:228] Iteration 10000, loss = 3.78427
I0826 09:45:05.380555  1343 solver.cpp:244]     Train net output #0: loss = 3.78427 (* 1 = 3.78427 loss)
I0826 09:45:05.380578  1343 sgd_solver.cpp:106] Iteration 10000, lr = 7.37788e-07
I0826 09:45:13.790987  1343 solver.cpp:228] Iteration 10100, loss = 3.81976
I0826 09:45:13.791049  1343 solver.cpp:244]     Train net output #0: loss = 3.81976 (* 1 = 3.81976 loss)
I0826 09:45:13.791059  1343 sgd_solver.cpp:106] Iteration 10100, lr = 7.35949e-07
I0826 09:45:22.184427  1343 solver.cpp:228] Iteration 10200, loss = 3.78235
I0826 09:45:22.184497  1343 solver.cpp:244]     Train net output #0: loss = 3.78235 (* 1 = 3.78235 loss)
I0826 09:45:22.184506  1343 sgd_solver.cpp:106] Iteration 10200, lr = 7.3412e-07
I0826 09:45:30.590621  1343 solver.cpp:228] Iteration 10300, loss = 3.91169
I0826 09:45:30.590667  1343 solver.cpp:244]     Train net output #0: loss = 3.91169 (* 1 = 3.91169 loss)
I0826 09:45:30.590673  1343 sgd_solver.cpp:106] Iteration 10300, lr = 7.32303e-07
I0826 09:45:38.975577  1343 solver.cpp:228] Iteration 10400, loss = 3.81788
I0826 09:45:38.975646  1343 solver.cpp:244]     Train net output #0: loss = 3.81788 (* 1 = 3.81788 loss)
I0826 09:45:38.975661  1343 sgd_solver.cpp:106] Iteration 10400, lr = 7.30495e-07
I0826 09:45:47.389102  1343 solver.cpp:228] Iteration 10500, loss = 3.85438
I0826 09:45:47.389183  1343 solver.cpp:244]     Train net output #0: loss = 3.85438 (* 1 = 3.85438 loss)
I0826 09:45:47.389197  1343 sgd_solver.cpp:106] Iteration 10500, lr = 7.28698e-07
I0826 09:45:55.768332  1343 solver.cpp:228] Iteration 10600, loss = 3.8455
I0826 09:45:55.768402  1343 solver.cpp:244]     Train net output #0: loss = 3.8455 (* 1 = 3.8455 loss)
I0826 09:45:55.768417  1343 sgd_solver.cpp:106] Iteration 10600, lr = 7.26911e-07
I0826 09:46:04.160655  1343 solver.cpp:228] Iteration 10700, loss = 3.8153
I0826 09:46:04.160708  1343 solver.cpp:244]     Train net output #0: loss = 3.8153 (* 1 = 3.8153 loss)
I0826 09:46:04.160718  1343 sgd_solver.cpp:106] Iteration 10700, lr = 7.25135e-07
I0826 09:46:12.568415  1343 solver.cpp:228] Iteration 10800, loss = 3.86127
I0826 09:46:12.568500  1343 solver.cpp:244]     Train net output #0: loss = 3.86127 (* 1 = 3.86127 loss)
I0826 09:46:12.568519  1343 sgd_solver.cpp:106] Iteration 10800, lr = 7.23368e-07
I0826 09:46:14.580881  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:46:20.943421  1343 solver.cpp:228] Iteration 10900, loss = 3.80885
I0826 09:46:20.943488  1343 solver.cpp:244]     Train net output #0: loss = 3.80885 (* 1 = 3.80885 loss)
I0826 09:46:20.943500  1343 sgd_solver.cpp:106] Iteration 10900, lr = 7.21612e-07
I0826 09:46:29.316673  1343 solver.cpp:228] Iteration 11000, loss = 3.78299
I0826 09:46:29.316733  1343 solver.cpp:244]     Train net output #0: loss = 3.78299 (* 1 = 3.78299 loss)
I0826 09:46:29.316740  1343 sgd_solver.cpp:106] Iteration 11000, lr = 7.19865e-07
I0826 09:46:37.721179  1343 solver.cpp:228] Iteration 11100, loss = 3.79117
I0826 09:46:37.721246  1343 solver.cpp:244]     Train net output #0: loss = 3.79117 (* 1 = 3.79117 loss)
I0826 09:46:37.721254  1343 sgd_solver.cpp:106] Iteration 11100, lr = 7.18129e-07
I0826 09:46:46.129901  1343 solver.cpp:228] Iteration 11200, loss = 3.70713
I0826 09:46:46.129966  1343 solver.cpp:244]     Train net output #0: loss = 3.70713 (* 1 = 3.70713 loss)
I0826 09:46:46.129976  1343 sgd_solver.cpp:106] Iteration 11200, lr = 7.16402e-07
I0826 09:46:54.530071  1343 solver.cpp:228] Iteration 11300, loss = 3.75866
I0826 09:46:54.530136  1343 solver.cpp:244]     Train net output #0: loss = 3.75866 (* 1 = 3.75866 loss)
I0826 09:46:54.530148  1343 sgd_solver.cpp:106] Iteration 11300, lr = 7.14684e-07
I0826 09:47:02.929764  1343 solver.cpp:228] Iteration 11400, loss = 3.79425
I0826 09:47:02.929810  1343 solver.cpp:244]     Train net output #0: loss = 3.79425 (* 1 = 3.79425 loss)
I0826 09:47:02.929816  1343 sgd_solver.cpp:106] Iteration 11400, lr = 7.12977e-07
I0826 09:47:11.330310  1343 solver.cpp:228] Iteration 11500, loss = 3.73813
I0826 09:47:11.330351  1343 solver.cpp:244]     Train net output #0: loss = 3.73813 (* 1 = 3.73813 loss)
I0826 09:47:11.330358  1343 sgd_solver.cpp:106] Iteration 11500, lr = 7.11278e-07
I0826 09:47:19.705119  1343 solver.cpp:228] Iteration 11600, loss = 3.79269
I0826 09:47:19.705174  1343 solver.cpp:244]     Train net output #0: loss = 3.79269 (* 1 = 3.79269 loss)
I0826 09:47:19.705184  1343 sgd_solver.cpp:106] Iteration 11600, lr = 7.0959e-07
I0826 09:47:28.114051  1343 solver.cpp:228] Iteration 11700, loss = 3.85901
I0826 09:47:28.114114  1343 solver.cpp:244]     Train net output #0: loss = 3.85901 (* 1 = 3.85901 loss)
I0826 09:47:28.114125  1343 sgd_solver.cpp:106] Iteration 11700, lr = 7.0791e-07
I0826 09:47:36.491619  1343 solver.cpp:228] Iteration 11800, loss = 3.88825
I0826 09:47:36.491675  1343 solver.cpp:244]     Train net output #0: loss = 3.88825 (* 1 = 3.88825 loss)
I0826 09:47:36.491685  1343 sgd_solver.cpp:106] Iteration 11800, lr = 7.0624e-07
I0826 09:47:44.867987  1343 solver.cpp:228] Iteration 11900, loss = 3.72211
I0826 09:47:44.868041  1343 solver.cpp:244]     Train net output #0: loss = 3.72211 (* 1 = 3.72211 loss)
I0826 09:47:44.868049  1343 sgd_solver.cpp:106] Iteration 11900, lr = 7.04579e-07
I0826 09:47:53.271921  1343 solver.cpp:228] Iteration 12000, loss = 3.75826
I0826 09:47:53.271966  1343 solver.cpp:244]     Train net output #0: loss = 3.75826 (* 1 = 3.75826 loss)
I0826 09:47:53.271972  1343 sgd_solver.cpp:106] Iteration 12000, lr = 7.02927e-07
I0826 09:48:01.655328  1343 solver.cpp:228] Iteration 12100, loss = 3.84702
I0826 09:48:01.655385  1343 solver.cpp:244]     Train net output #0: loss = 3.84702 (* 1 = 3.84702 loss)
I0826 09:48:01.655395  1343 sgd_solver.cpp:106] Iteration 12100, lr = 7.01284e-07
I0826 09:48:10.075009  1343 solver.cpp:228] Iteration 12200, loss = 3.65481
I0826 09:48:10.075070  1343 solver.cpp:244]     Train net output #0: loss = 3.65481 (* 1 = 3.65481 loss)
I0826 09:48:10.075083  1343 sgd_solver.cpp:106] Iteration 12200, lr = 6.9965e-07
I0826 09:48:18.469115  1343 solver.cpp:228] Iteration 12300, loss = 3.70165
I0826 09:48:18.469164  1343 solver.cpp:244]     Train net output #0: loss = 3.70165 (* 1 = 3.70165 loss)
I0826 09:48:18.469172  1343 sgd_solver.cpp:106] Iteration 12300, lr = 6.98024e-07
I0826 09:48:26.878023  1343 solver.cpp:228] Iteration 12400, loss = 3.75811
I0826 09:48:26.878113  1343 solver.cpp:244]     Train net output #0: loss = 3.75811 (* 1 = 3.75811 loss)
I0826 09:48:26.878129  1343 sgd_solver.cpp:106] Iteration 12400, lr = 6.96408e-07
I0826 09:48:35.263172  1343 solver.cpp:228] Iteration 12500, loss = 3.82829
I0826 09:48:35.263228  1343 solver.cpp:244]     Train net output #0: loss = 3.82829 (* 1 = 3.82829 loss)
I0826 09:48:35.263240  1343 sgd_solver.cpp:106] Iteration 12500, lr = 6.948e-07
I0826 09:48:43.670439  1343 solver.cpp:228] Iteration 12600, loss = 3.73525
I0826 09:48:43.670480  1343 solver.cpp:244]     Train net output #0: loss = 3.73525 (* 1 = 3.73525 loss)
I0826 09:48:43.670485  1343 sgd_solver.cpp:106] Iteration 12600, lr = 6.93201e-07
I0826 09:48:52.071013  1343 solver.cpp:228] Iteration 12700, loss = 3.66181
I0826 09:48:52.071077  1343 solver.cpp:244]     Train net output #0: loss = 3.66181 (* 1 = 3.66181 loss)
I0826 09:48:52.071091  1343 sgd_solver.cpp:106] Iteration 12700, lr = 6.91611e-07
I0826 09:49:00.472625  1343 solver.cpp:228] Iteration 12800, loss = 3.7037
I0826 09:49:00.472692  1343 solver.cpp:244]     Train net output #0: loss = 3.7037 (* 1 = 3.7037 loss)
I0826 09:49:00.472705  1343 sgd_solver.cpp:106] Iteration 12800, lr = 6.90029e-07
I0826 09:49:08.858592  1343 solver.cpp:228] Iteration 12900, loss = 3.61604
I0826 09:49:08.858664  1343 solver.cpp:244]     Train net output #0: loss = 3.61604 (* 1 = 3.61604 loss)
I0826 09:49:08.858676  1343 sgd_solver.cpp:106] Iteration 12900, lr = 6.88455e-07
I0826 09:49:17.274957  1343 solver.cpp:228] Iteration 13000, loss = 3.81488
I0826 09:49:17.275028  1343 solver.cpp:244]     Train net output #0: loss = 3.81488 (* 1 = 3.81488 loss)
I0826 09:49:17.275039  1343 sgd_solver.cpp:106] Iteration 13000, lr = 6.8689e-07
I0826 09:49:25.676172  1343 solver.cpp:228] Iteration 13100, loss = 3.6892
I0826 09:49:25.676229  1343 solver.cpp:244]     Train net output #0: loss = 3.6892 (* 1 = 3.6892 loss)
I0826 09:49:25.676237  1343 sgd_solver.cpp:106] Iteration 13100, lr = 6.85333e-07
I0826 09:49:34.084365  1343 solver.cpp:228] Iteration 13200, loss = 3.77375
I0826 09:49:34.084425  1343 solver.cpp:244]     Train net output #0: loss = 3.77375 (* 1 = 3.77375 loss)
I0826 09:49:34.084437  1343 sgd_solver.cpp:106] Iteration 13200, lr = 6.83784e-07
I0826 09:49:42.483845  1343 solver.cpp:228] Iteration 13300, loss = 3.73424
I0826 09:49:42.483909  1343 solver.cpp:244]     Train net output #0: loss = 3.73424 (* 1 = 3.73424 loss)
I0826 09:49:42.483917  1343 sgd_solver.cpp:106] Iteration 13300, lr = 6.82243e-07
I0826 09:49:50.891317  1343 solver.cpp:228] Iteration 13400, loss = 3.65425
I0826 09:49:50.891383  1343 solver.cpp:244]     Train net output #0: loss = 3.65425 (* 1 = 3.65425 loss)
I0826 09:49:50.891394  1343 sgd_solver.cpp:106] Iteration 13400, lr = 6.80711e-07
I0826 09:49:59.281981  1343 solver.cpp:228] Iteration 13500, loss = 3.76133
I0826 09:49:59.282057  1343 solver.cpp:244]     Train net output #0: loss = 3.76133 (* 1 = 3.76133 loss)
I0826 09:49:59.282071  1343 sgd_solver.cpp:106] Iteration 13500, lr = 6.79186e-07
I0826 09:50:07.682919  1343 solver.cpp:228] Iteration 13600, loss = 3.73233
I0826 09:50:07.682976  1343 solver.cpp:244]     Train net output #0: loss = 3.73233 (* 1 = 3.73233 loss)
I0826 09:50:07.682986  1343 sgd_solver.cpp:106] Iteration 13600, lr = 6.7767e-07
I0826 09:50:16.079690  1343 solver.cpp:228] Iteration 13700, loss = 3.77502
I0826 09:50:16.079754  1343 solver.cpp:244]     Train net output #0: loss = 3.77502 (* 1 = 3.77502 loss)
I0826 09:50:16.079763  1343 sgd_solver.cpp:106] Iteration 13700, lr = 6.76161e-07
I0826 09:50:24.486135  1343 solver.cpp:228] Iteration 13800, loss = 3.76956
I0826 09:50:24.486214  1343 solver.cpp:244]     Train net output #0: loss = 3.76956 (* 1 = 3.76956 loss)
I0826 09:50:24.486229  1343 sgd_solver.cpp:106] Iteration 13800, lr = 6.7466e-07
I0826 09:50:32.877528  1343 solver.cpp:228] Iteration 13900, loss = 3.60234
I0826 09:50:32.877583  1343 solver.cpp:244]     Train net output #0: loss = 3.60234 (* 1 = 3.60234 loss)
I0826 09:50:32.877591  1343 sgd_solver.cpp:106] Iteration 13900, lr = 6.73167e-07
I0826 09:50:41.278780  1343 solver.cpp:228] Iteration 14000, loss = 3.76104
I0826 09:50:41.278841  1343 solver.cpp:244]     Train net output #0: loss = 3.76104 (* 1 = 3.76104 loss)
I0826 09:50:41.278849  1343 sgd_solver.cpp:106] Iteration 14000, lr = 6.71681e-07
I0826 09:50:49.660909  1343 solver.cpp:228] Iteration 14100, loss = 3.63138
I0826 09:50:49.660991  1343 solver.cpp:244]     Train net output #0: loss = 3.63138 (* 1 = 3.63138 loss)
I0826 09:50:49.661005  1343 sgd_solver.cpp:106] Iteration 14100, lr = 6.70204e-07
I0826 09:50:58.074800  1343 solver.cpp:228] Iteration 14200, loss = 3.70806
I0826 09:50:58.074868  1343 solver.cpp:244]     Train net output #0: loss = 3.70806 (* 1 = 3.70806 loss)
I0826 09:50:58.074877  1343 sgd_solver.cpp:106] Iteration 14200, lr = 6.68733e-07
I0826 09:51:06.485743  1343 solver.cpp:228] Iteration 14300, loss = 3.66648
I0826 09:51:06.485788  1343 solver.cpp:244]     Train net output #0: loss = 3.66648 (* 1 = 3.66648 loss)
I0826 09:51:06.485795  1343 sgd_solver.cpp:106] Iteration 14300, lr = 6.67271e-07
I0826 09:51:14.878922  1343 solver.cpp:228] Iteration 14400, loss = 3.76431
I0826 09:51:14.879009  1343 solver.cpp:244]     Train net output #0: loss = 3.76431 (* 1 = 3.76431 loss)
I0826 09:51:14.879024  1343 sgd_solver.cpp:106] Iteration 14400, lr = 6.65815e-07
I0826 09:51:22.611471  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:51:23.287900  1343 solver.cpp:228] Iteration 14500, loss = 3.73243
I0826 09:51:23.287963  1343 solver.cpp:244]     Train net output #0: loss = 3.73243 (* 1 = 3.73243 loss)
I0826 09:51:23.287974  1343 sgd_solver.cpp:106] Iteration 14500, lr = 6.64367e-07
I0826 09:51:31.701270  1343 solver.cpp:228] Iteration 14600, loss = 3.61049
I0826 09:51:31.701323  1343 solver.cpp:244]     Train net output #0: loss = 3.61049 (* 1 = 3.61049 loss)
I0826 09:51:31.701331  1343 sgd_solver.cpp:106] Iteration 14600, lr = 6.62927e-07
I0826 09:51:40.097549  1343 solver.cpp:228] Iteration 14700, loss = 3.6533
I0826 09:51:40.097605  1343 solver.cpp:244]     Train net output #0: loss = 3.6533 (* 1 = 3.6533 loss)
I0826 09:51:40.097614  1343 sgd_solver.cpp:106] Iteration 14700, lr = 6.61493e-07
I0826 09:51:48.503865  1343 solver.cpp:228] Iteration 14800, loss = 3.67971
I0826 09:51:48.503937  1343 solver.cpp:244]     Train net output #0: loss = 3.67971 (* 1 = 3.67971 loss)
I0826 09:51:48.503948  1343 sgd_solver.cpp:106] Iteration 14800, lr = 6.60067e-07
I0826 09:51:56.915241  1343 solver.cpp:228] Iteration 14900, loss = 3.57544
I0826 09:51:56.915310  1343 solver.cpp:244]     Train net output #0: loss = 3.57544 (* 1 = 3.57544 loss)
I0826 09:51:56.915319  1343 sgd_solver.cpp:106] Iteration 14900, lr = 6.58648e-07
I0826 09:52:05.232962  1343 solver.cpp:337] Iteration 15000, Testing net (#0)
I0826 09:52:42.728595  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302031
I0826 09:52:42.728643  1343 solver.cpp:404]     Test net output #1: loss = 3.6622 (* 1 = 3.6622 loss)
I0826 09:52:42.757622  1343 solver.cpp:228] Iteration 15000, loss = 3.7682
I0826 09:52:42.757643  1343 solver.cpp:244]     Train net output #0: loss = 3.7682 (* 1 = 3.7682 loss)
I0826 09:52:42.757654  1343 sgd_solver.cpp:106] Iteration 15000, lr = 6.57236e-07
I0826 09:52:51.164273  1343 solver.cpp:228] Iteration 15100, loss = 3.77268
I0826 09:52:51.164342  1343 solver.cpp:244]     Train net output #0: loss = 3.77268 (* 1 = 3.77268 loss)
I0826 09:52:51.164357  1343 sgd_solver.cpp:106] Iteration 15100, lr = 6.55831e-07
I0826 09:52:59.567454  1343 solver.cpp:228] Iteration 15200, loss = 3.70427
I0826 09:52:59.567523  1343 solver.cpp:244]     Train net output #0: loss = 3.70427 (* 1 = 3.70427 loss)
I0826 09:52:59.567536  1343 sgd_solver.cpp:106] Iteration 15200, lr = 6.54433e-07
I0826 09:53:03.856353  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:53:07.959620  1343 solver.cpp:228] Iteration 15300, loss = 3.6732
I0826 09:53:07.959662  1343 solver.cpp:244]     Train net output #0: loss = 3.6732 (* 1 = 3.6732 loss)
I0826 09:53:07.959667  1343 sgd_solver.cpp:106] Iteration 15300, lr = 6.53043e-07
I0826 09:53:16.366389  1343 solver.cpp:228] Iteration 15400, loss = 3.63698
I0826 09:53:16.366446  1343 solver.cpp:244]     Train net output #0: loss = 3.63698 (* 1 = 3.63698 loss)
I0826 09:53:16.366452  1343 sgd_solver.cpp:106] Iteration 15400, lr = 6.51658e-07
I0826 09:53:24.772872  1343 solver.cpp:228] Iteration 15500, loss = 3.60015
I0826 09:53:24.772922  1343 solver.cpp:244]     Train net output #0: loss = 3.60015 (* 1 = 3.60015 loss)
I0826 09:53:24.772930  1343 sgd_solver.cpp:106] Iteration 15500, lr = 6.50281e-07
I0826 09:53:33.185343  1343 solver.cpp:228] Iteration 15600, loss = 3.77635
I0826 09:53:33.185406  1343 solver.cpp:244]     Train net output #0: loss = 3.77635 (* 1 = 3.77635 loss)
I0826 09:53:33.185416  1343 sgd_solver.cpp:106] Iteration 15600, lr = 6.48911e-07
I0826 09:53:41.569339  1343 solver.cpp:228] Iteration 15700, loss = 3.77731
I0826 09:53:41.569397  1343 solver.cpp:244]     Train net output #0: loss = 3.77731 (* 1 = 3.77731 loss)
I0826 09:53:41.569403  1343 sgd_solver.cpp:106] Iteration 15700, lr = 6.47547e-07
I0826 09:53:49.959262  1343 solver.cpp:228] Iteration 15800, loss = 3.66515
I0826 09:53:49.959336  1343 solver.cpp:244]     Train net output #0: loss = 3.66515 (* 1 = 3.66515 loss)
I0826 09:53:49.959345  1343 sgd_solver.cpp:106] Iteration 15800, lr = 6.4619e-07
I0826 09:53:58.358374  1343 solver.cpp:228] Iteration 15900, loss = 3.63652
I0826 09:53:58.358418  1343 solver.cpp:244]     Train net output #0: loss = 3.63652 (* 1 = 3.63652 loss)
I0826 09:53:58.358425  1343 sgd_solver.cpp:106] Iteration 15900, lr = 6.4484e-07
I0826 09:54:06.750814  1343 solver.cpp:228] Iteration 16000, loss = 3.52944
I0826 09:54:06.750885  1343 solver.cpp:244]     Train net output #0: loss = 3.52944 (* 1 = 3.52944 loss)
I0826 09:54:06.750897  1343 sgd_solver.cpp:106] Iteration 16000, lr = 6.43496e-07
I0826 09:54:15.161208  1343 solver.cpp:228] Iteration 16100, loss = 3.72587
I0826 09:54:15.161255  1343 solver.cpp:244]     Train net output #0: loss = 3.72587 (* 1 = 3.72587 loss)
I0826 09:54:15.161260  1343 sgd_solver.cpp:106] Iteration 16100, lr = 6.42158e-07
I0826 09:54:23.543459  1343 solver.cpp:228] Iteration 16200, loss = 3.63462
I0826 09:54:23.543552  1343 solver.cpp:244]     Train net output #0: loss = 3.63462 (* 1 = 3.63462 loss)
I0826 09:54:23.543572  1343 sgd_solver.cpp:106] Iteration 16200, lr = 6.40827e-07
I0826 09:54:31.961540  1343 solver.cpp:228] Iteration 16300, loss = 3.65623
I0826 09:54:31.961601  1343 solver.cpp:244]     Train net output #0: loss = 3.65623 (* 1 = 3.65623 loss)
I0826 09:54:31.961609  1343 sgd_solver.cpp:106] Iteration 16300, lr = 6.39503e-07
I0826 09:54:40.344177  1343 solver.cpp:228] Iteration 16400, loss = 3.77183
I0826 09:54:40.344244  1343 solver.cpp:244]     Train net output #0: loss = 3.77183 (* 1 = 3.77183 loss)
I0826 09:54:40.344254  1343 sgd_solver.cpp:106] Iteration 16400, lr = 6.38185e-07
I0826 09:54:48.756415  1343 solver.cpp:228] Iteration 16500, loss = 3.65308
I0826 09:54:48.756469  1343 solver.cpp:244]     Train net output #0: loss = 3.65308 (* 1 = 3.65308 loss)
I0826 09:54:48.756476  1343 sgd_solver.cpp:106] Iteration 16500, lr = 6.36873e-07
I0826 09:54:57.148831  1343 solver.cpp:228] Iteration 16600, loss = 3.70794
I0826 09:54:57.148893  1343 solver.cpp:244]     Train net output #0: loss = 3.70794 (* 1 = 3.70794 loss)
I0826 09:54:57.148903  1343 sgd_solver.cpp:106] Iteration 16600, lr = 6.35568e-07
I0826 09:55:05.560245  1343 solver.cpp:228] Iteration 16700, loss = 3.59332
I0826 09:55:05.560331  1343 solver.cpp:244]     Train net output #0: loss = 3.59332 (* 1 = 3.59332 loss)
I0826 09:55:05.560351  1343 sgd_solver.cpp:106] Iteration 16700, lr = 6.34268e-07
I0826 09:55:13.933532  1343 solver.cpp:228] Iteration 16800, loss = 3.52049
I0826 09:55:13.933586  1343 solver.cpp:244]     Train net output #0: loss = 3.52049 (* 1 = 3.52049 loss)
I0826 09:55:13.933593  1343 sgd_solver.cpp:106] Iteration 16800, lr = 6.32975e-07
I0826 09:55:22.349148  1343 solver.cpp:228] Iteration 16900, loss = 3.74605
I0826 09:55:22.349206  1343 solver.cpp:244]     Train net output #0: loss = 3.74605 (* 1 = 3.74605 loss)
I0826 09:55:22.349212  1343 sgd_solver.cpp:106] Iteration 16900, lr = 6.31688e-07
I0826 09:55:30.735396  1343 solver.cpp:228] Iteration 17000, loss = 3.61935
I0826 09:55:30.735460  1343 solver.cpp:244]     Train net output #0: loss = 3.61935 (* 1 = 3.61935 loss)
I0826 09:55:30.735468  1343 sgd_solver.cpp:106] Iteration 17000, lr = 6.30407e-07
I0826 09:55:39.149396  1343 solver.cpp:228] Iteration 17100, loss = 3.7152
I0826 09:55:39.149441  1343 solver.cpp:244]     Train net output #0: loss = 3.7152 (* 1 = 3.7152 loss)
I0826 09:55:39.149446  1343 sgd_solver.cpp:106] Iteration 17100, lr = 6.29132e-07
I0826 09:55:47.542950  1343 solver.cpp:228] Iteration 17200, loss = 3.62066
I0826 09:55:47.543025  1343 solver.cpp:244]     Train net output #0: loss = 3.62066 (* 1 = 3.62066 loss)
I0826 09:55:47.543035  1343 sgd_solver.cpp:106] Iteration 17200, lr = 6.27864e-07
I0826 09:55:55.953995  1343 solver.cpp:228] Iteration 17300, loss = 3.60418
I0826 09:55:55.954041  1343 solver.cpp:244]     Train net output #0: loss = 3.60418 (* 1 = 3.60418 loss)
I0826 09:55:55.954046  1343 sgd_solver.cpp:106] Iteration 17300, lr = 6.26601e-07
I0826 09:56:04.332166  1343 solver.cpp:228] Iteration 17400, loss = 3.66967
I0826 09:56:04.332211  1343 solver.cpp:244]     Train net output #0: loss = 3.66967 (* 1 = 3.66967 loss)
I0826 09:56:04.332218  1343 sgd_solver.cpp:106] Iteration 17400, lr = 6.25344e-07
I0826 09:56:12.724480  1343 solver.cpp:228] Iteration 17500, loss = 3.69683
I0826 09:56:12.724539  1343 solver.cpp:244]     Train net output #0: loss = 3.69683 (* 1 = 3.69683 loss)
I0826 09:56:12.724550  1343 sgd_solver.cpp:106] Iteration 17500, lr = 6.24093e-07
I0826 09:56:21.123073  1343 solver.cpp:228] Iteration 17600, loss = 3.63948
I0826 09:56:21.123152  1343 solver.cpp:244]     Train net output #0: loss = 3.63948 (* 1 = 3.63948 loss)
I0826 09:56:21.123162  1343 sgd_solver.cpp:106] Iteration 17600, lr = 6.22847e-07
I0826 09:56:29.511239  1343 solver.cpp:228] Iteration 17700, loss = 3.43367
I0826 09:56:29.511284  1343 solver.cpp:244]     Train net output #0: loss = 3.43367 (* 1 = 3.43367 loss)
I0826 09:56:29.511291  1343 sgd_solver.cpp:106] Iteration 17700, lr = 6.21608e-07
I0826 09:56:37.918344  1343 solver.cpp:228] Iteration 17800, loss = 3.63395
I0826 09:56:37.918413  1343 solver.cpp:244]     Train net output #0: loss = 3.63395 (* 1 = 3.63395 loss)
I0826 09:56:37.918424  1343 sgd_solver.cpp:106] Iteration 17800, lr = 6.20374e-07
I0826 09:56:46.323032  1343 solver.cpp:228] Iteration 17900, loss = 3.51086
I0826 09:56:46.323107  1343 solver.cpp:244]     Train net output #0: loss = 3.51086 (* 1 = 3.51086 loss)
I0826 09:56:46.323117  1343 sgd_solver.cpp:106] Iteration 17900, lr = 6.19146e-07
I0826 09:56:54.718619  1343 solver.cpp:228] Iteration 18000, loss = 3.6285
I0826 09:56:54.718688  1343 solver.cpp:244]     Train net output #0: loss = 3.6285 (* 1 = 3.6285 loss)
I0826 09:56:54.718695  1343 sgd_solver.cpp:106] Iteration 18000, lr = 6.17924e-07
I0826 09:57:03.107388  1343 solver.cpp:228] Iteration 18100, loss = 3.68127
I0826 09:57:03.107447  1343 solver.cpp:244]     Train net output #0: loss = 3.68127 (* 1 = 3.68127 loss)
I0826 09:57:03.107460  1343 sgd_solver.cpp:106] Iteration 18100, lr = 6.16707e-07
I0826 09:57:11.520579  1343 solver.cpp:228] Iteration 18200, loss = 3.71522
I0826 09:57:11.520658  1343 solver.cpp:244]     Train net output #0: loss = 3.71522 (* 1 = 3.71522 loss)
I0826 09:57:11.520673  1343 sgd_solver.cpp:106] Iteration 18200, lr = 6.15496e-07
I0826 09:57:19.905971  1343 solver.cpp:228] Iteration 18300, loss = 3.60176
I0826 09:57:19.906031  1343 solver.cpp:244]     Train net output #0: loss = 3.60176 (* 1 = 3.60176 loss)
I0826 09:57:19.906044  1343 sgd_solver.cpp:106] Iteration 18300, lr = 6.1429e-07
I0826 09:57:28.313170  1343 solver.cpp:228] Iteration 18400, loss = 3.54732
I0826 09:57:28.313241  1343 solver.cpp:244]     Train net output #0: loss = 3.54732 (* 1 = 3.54732 loss)
I0826 09:57:28.313254  1343 sgd_solver.cpp:106] Iteration 18400, lr = 6.1309e-07
I0826 09:57:36.707094  1343 solver.cpp:228] Iteration 18500, loss = 3.71034
I0826 09:57:36.707173  1343 solver.cpp:244]     Train net output #0: loss = 3.71034 (* 1 = 3.71034 loss)
I0826 09:57:36.707183  1343 sgd_solver.cpp:106] Iteration 18500, lr = 6.11895e-07
I0826 09:57:45.120792  1343 solver.cpp:228] Iteration 18600, loss = 3.64245
I0826 09:57:45.120880  1343 solver.cpp:244]     Train net output #0: loss = 3.64245 (* 1 = 3.64245 loss)
I0826 09:57:45.120896  1343 sgd_solver.cpp:106] Iteration 18600, lr = 6.10706e-07
I0826 09:57:53.531697  1343 solver.cpp:228] Iteration 18700, loss = 3.56828
I0826 09:57:53.531744  1343 solver.cpp:244]     Train net output #0: loss = 3.56828 (* 1 = 3.56828 loss)
I0826 09:57:53.531749  1343 sgd_solver.cpp:106] Iteration 18700, lr = 6.09522e-07
I0826 09:58:01.260133  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 09:58:01.934219  1343 solver.cpp:228] Iteration 18800, loss = 3.50213
I0826 09:58:01.934280  1343 solver.cpp:244]     Train net output #0: loss = 3.50213 (* 1 = 3.50213 loss)
I0826 09:58:01.934291  1343 sgd_solver.cpp:106] Iteration 18800, lr = 6.08343e-07
I0826 09:58:10.342265  1343 solver.cpp:228] Iteration 18900, loss = 3.57274
I0826 09:58:10.342325  1343 solver.cpp:244]     Train net output #0: loss = 3.57274 (* 1 = 3.57274 loss)
I0826 09:58:10.342335  1343 sgd_solver.cpp:106] Iteration 18900, lr = 6.0717e-07
I0826 09:58:18.747059  1343 solver.cpp:228] Iteration 19000, loss = 3.66
I0826 09:58:18.747123  1343 solver.cpp:244]     Train net output #0: loss = 3.66 (* 1 = 3.66 loss)
I0826 09:58:18.747134  1343 sgd_solver.cpp:106] Iteration 19000, lr = 6.06002e-07
I0826 09:58:27.164254  1343 solver.cpp:228] Iteration 19100, loss = 3.58302
I0826 09:58:27.164329  1343 solver.cpp:244]     Train net output #0: loss = 3.58302 (* 1 = 3.58302 loss)
I0826 09:58:27.164338  1343 sgd_solver.cpp:106] Iteration 19100, lr = 6.04839e-07
I0826 09:58:35.558938  1343 solver.cpp:228] Iteration 19200, loss = 3.62381
I0826 09:58:35.559006  1343 solver.cpp:244]     Train net output #0: loss = 3.62381 (* 1 = 3.62381 loss)
I0826 09:58:35.559018  1343 sgd_solver.cpp:106] Iteration 19200, lr = 6.03682e-07
I0826 09:58:43.969467  1343 solver.cpp:228] Iteration 19300, loss = 3.30857
I0826 09:58:43.969550  1343 solver.cpp:244]     Train net output #0: loss = 3.30857 (* 1 = 3.30857 loss)
I0826 09:58:43.969566  1343 sgd_solver.cpp:106] Iteration 19300, lr = 6.02529e-07
I0826 09:58:52.377423  1343 solver.cpp:228] Iteration 19400, loss = 3.5532
I0826 09:58:52.377471  1343 solver.cpp:244]     Train net output #0: loss = 3.5532 (* 1 = 3.5532 loss)
I0826 09:58:52.377477  1343 sgd_solver.cpp:106] Iteration 19400, lr = 6.01382e-07
I0826 09:59:00.780572  1343 solver.cpp:228] Iteration 19500, loss = 3.68873
I0826 09:59:00.780633  1343 solver.cpp:244]     Train net output #0: loss = 3.68873 (* 1 = 3.68873 loss)
I0826 09:59:00.780645  1343 sgd_solver.cpp:106] Iteration 19500, lr = 6.0024e-07
I0826 09:59:09.194164  1343 solver.cpp:228] Iteration 19600, loss = 3.58645
I0826 09:59:09.194241  1343 solver.cpp:244]     Train net output #0: loss = 3.58645 (* 1 = 3.58645 loss)
I0826 09:59:09.194250  1343 sgd_solver.cpp:106] Iteration 19600, lr = 5.99102e-07
I0826 09:59:17.597554  1343 solver.cpp:228] Iteration 19700, loss = 3.61883
I0826 09:59:17.597599  1343 solver.cpp:244]     Train net output #0: loss = 3.61883 (* 1 = 3.61883 loss)
I0826 09:59:17.597604  1343 sgd_solver.cpp:106] Iteration 19700, lr = 5.9797e-07
I0826 09:59:26.010565  1343 solver.cpp:228] Iteration 19800, loss = 3.61407
I0826 09:59:26.010619  1343 solver.cpp:244]     Train net output #0: loss = 3.61407 (* 1 = 3.61407 loss)
I0826 09:59:26.010627  1343 sgd_solver.cpp:106] Iteration 19800, lr = 5.96843e-07
I0826 09:59:34.424429  1343 solver.cpp:228] Iteration 19900, loss = 3.48105
I0826 09:59:34.424484  1343 solver.cpp:244]     Train net output #0: loss = 3.48105 (* 1 = 3.48105 loss)
I0826 09:59:34.424491  1343 sgd_solver.cpp:106] Iteration 19900, lr = 5.95721e-07
I0826 09:59:42.742378  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_20000.caffemodel
I0826 09:59:43.450000  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_20000.solverstate
I0826 09:59:43.610596  1343 solver.cpp:337] Iteration 20000, Testing net (#0)
I0826 10:00:11.120517  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:00:21.887082  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302055
I0826 10:00:21.887145  1343 solver.cpp:404]     Test net output #1: loss = 3.57147 (* 1 = 3.57147 loss)
I0826 10:00:21.915586  1343 solver.cpp:228] Iteration 20000, loss = 3.54938
I0826 10:00:21.915639  1343 solver.cpp:244]     Train net output #0: loss = 3.54938 (* 1 = 3.54938 loss)
I0826 10:00:21.915653  1343 sgd_solver.cpp:106] Iteration 20000, lr = 5.94604e-07
I0826 10:00:30.345072  1343 solver.cpp:228] Iteration 20100, loss = 3.53505
I0826 10:00:30.345119  1343 solver.cpp:244]     Train net output #0: loss = 3.53505 (* 1 = 3.53505 loss)
I0826 10:00:30.345124  1343 sgd_solver.cpp:106] Iteration 20100, lr = 5.93491e-07
I0826 10:00:38.731644  1343 solver.cpp:228] Iteration 20200, loss = 3.4499
I0826 10:00:38.731714  1343 solver.cpp:244]     Train net output #0: loss = 3.4499 (* 1 = 3.4499 loss)
I0826 10:00:38.731724  1343 sgd_solver.cpp:106] Iteration 20200, lr = 5.92384e-07
I0826 10:00:47.149199  1343 solver.cpp:228] Iteration 20300, loss = 3.60391
I0826 10:00:47.149257  1343 solver.cpp:244]     Train net output #0: loss = 3.60391 (* 1 = 3.60391 loss)
I0826 10:00:47.149263  1343 sgd_solver.cpp:106] Iteration 20300, lr = 5.91281e-07
I0826 10:00:55.546272  1343 solver.cpp:228] Iteration 20400, loss = 3.64358
I0826 10:00:55.546329  1343 solver.cpp:244]     Train net output #0: loss = 3.64358 (* 1 = 3.64358 loss)
I0826 10:00:55.546336  1343 sgd_solver.cpp:106] Iteration 20400, lr = 5.90183e-07
I0826 10:01:03.956540  1343 solver.cpp:228] Iteration 20500, loss = 3.51683
I0826 10:01:03.956619  1343 solver.cpp:244]     Train net output #0: loss = 3.51683 (* 1 = 3.51683 loss)
I0826 10:01:03.956632  1343 sgd_solver.cpp:106] Iteration 20500, lr = 5.89089e-07
I0826 10:01:12.346428  1343 solver.cpp:228] Iteration 20600, loss = 3.59345
I0826 10:01:12.346473  1343 solver.cpp:244]     Train net output #0: loss = 3.59345 (* 1 = 3.59345 loss)
I0826 10:01:12.346479  1343 sgd_solver.cpp:106] Iteration 20600, lr = 5.88001e-07
I0826 10:01:20.765640  1343 solver.cpp:228] Iteration 20700, loss = 3.44629
I0826 10:01:20.765709  1343 solver.cpp:244]     Train net output #0: loss = 3.44629 (* 1 = 3.44629 loss)
I0826 10:01:20.765722  1343 sgd_solver.cpp:106] Iteration 20700, lr = 5.86917e-07
I0826 10:01:29.191778  1343 solver.cpp:228] Iteration 20800, loss = 3.46555
I0826 10:01:29.191846  1343 solver.cpp:244]     Train net output #0: loss = 3.46555 (* 1 = 3.46555 loss)
I0826 10:01:29.191855  1343 sgd_solver.cpp:106] Iteration 20800, lr = 5.85838e-07
I0826 10:01:37.595268  1343 solver.cpp:228] Iteration 20900, loss = 3.50639
I0826 10:01:37.595332  1343 solver.cpp:244]     Train net output #0: loss = 3.50639 (* 1 = 3.50639 loss)
I0826 10:01:37.595345  1343 sgd_solver.cpp:106] Iteration 20900, lr = 5.84763e-07
I0826 10:01:46.008797  1343 solver.cpp:228] Iteration 21000, loss = 3.60323
I0826 10:01:46.008843  1343 solver.cpp:244]     Train net output #0: loss = 3.60323 (* 1 = 3.60323 loss)
I0826 10:01:46.008851  1343 sgd_solver.cpp:106] Iteration 21000, lr = 5.83693e-07
I0826 10:01:54.428659  1343 solver.cpp:228] Iteration 21100, loss = 3.61294
I0826 10:01:54.428740  1343 solver.cpp:244]     Train net output #0: loss = 3.61294 (* 1 = 3.61294 loss)
I0826 10:01:54.428750  1343 sgd_solver.cpp:106] Iteration 21100, lr = 5.82628e-07
I0826 10:02:02.821625  1343 solver.cpp:228] Iteration 21200, loss = 3.54803
I0826 10:02:02.821681  1343 solver.cpp:244]     Train net output #0: loss = 3.54803 (* 1 = 3.54803 loss)
I0826 10:02:02.821688  1343 sgd_solver.cpp:106] Iteration 21200, lr = 5.81567e-07
I0826 10:02:11.236619  1343 solver.cpp:228] Iteration 21300, loss = 3.43519
I0826 10:02:11.236672  1343 solver.cpp:244]     Train net output #0: loss = 3.43519 (* 1 = 3.43519 loss)
I0826 10:02:11.236680  1343 sgd_solver.cpp:106] Iteration 21300, lr = 5.8051e-07
I0826 10:02:19.655464  1343 solver.cpp:228] Iteration 21400, loss = 3.60239
I0826 10:02:19.655520  1343 solver.cpp:244]     Train net output #0: loss = 3.60239 (* 1 = 3.60239 loss)
I0826 10:02:19.655531  1343 sgd_solver.cpp:106] Iteration 21400, lr = 5.79458e-07
I0826 10:02:28.051260  1343 solver.cpp:228] Iteration 21500, loss = 3.56718
I0826 10:02:28.051321  1343 solver.cpp:244]     Train net output #0: loss = 3.56718 (* 1 = 3.56718 loss)
I0826 10:02:28.051333  1343 sgd_solver.cpp:106] Iteration 21500, lr = 5.78411e-07
I0826 10:02:36.473995  1343 solver.cpp:228] Iteration 21600, loss = 3.79242
I0826 10:02:36.474041  1343 solver.cpp:244]     Train net output #0: loss = 3.79242 (* 1 = 3.79242 loss)
I0826 10:02:36.474047  1343 sgd_solver.cpp:106] Iteration 21600, lr = 5.77368e-07
I0826 10:02:44.875675  1343 solver.cpp:228] Iteration 21700, loss = 3.41308
I0826 10:02:44.875731  1343 solver.cpp:244]     Train net output #0: loss = 3.41308 (* 1 = 3.41308 loss)
I0826 10:02:44.875740  1343 sgd_solver.cpp:106] Iteration 21700, lr = 5.76329e-07
I0826 10:02:53.280007  1343 solver.cpp:228] Iteration 21800, loss = 3.48806
I0826 10:02:53.280076  1343 solver.cpp:244]     Train net output #0: loss = 3.48806 (* 1 = 3.48806 loss)
I0826 10:02:53.280086  1343 sgd_solver.cpp:106] Iteration 21800, lr = 5.75295e-07
I0826 10:03:01.675679  1343 solver.cpp:228] Iteration 21900, loss = 3.66628
I0826 10:03:01.675737  1343 solver.cpp:244]     Train net output #0: loss = 3.66628 (* 1 = 3.66628 loss)
I0826 10:03:01.675748  1343 sgd_solver.cpp:106] Iteration 21900, lr = 5.74265e-07
I0826 10:03:10.092452  1343 solver.cpp:228] Iteration 22000, loss = 3.50404
I0826 10:03:10.092512  1343 solver.cpp:244]     Train net output #0: loss = 3.50404 (* 1 = 3.50404 loss)
I0826 10:03:10.092522  1343 sgd_solver.cpp:106] Iteration 22000, lr = 5.73239e-07
I0826 10:03:18.530201  1343 solver.cpp:228] Iteration 22100, loss = 3.56949
I0826 10:03:18.530254  1343 solver.cpp:244]     Train net output #0: loss = 3.56949 (* 1 = 3.56949 loss)
I0826 10:03:18.530261  1343 sgd_solver.cpp:106] Iteration 22100, lr = 5.72217e-07
I0826 10:03:26.931100  1343 solver.cpp:228] Iteration 22200, loss = 3.62781
I0826 10:03:26.931175  1343 solver.cpp:244]     Train net output #0: loss = 3.62781 (* 1 = 3.62781 loss)
I0826 10:03:26.931188  1343 sgd_solver.cpp:106] Iteration 22200, lr = 5.712e-07
I0826 10:03:35.334375  1343 solver.cpp:228] Iteration 22300, loss = 3.48937
I0826 10:03:35.334439  1343 solver.cpp:244]     Train net output #0: loss = 3.48937 (* 1 = 3.48937 loss)
I0826 10:03:35.334450  1343 sgd_solver.cpp:106] Iteration 22300, lr = 5.70187e-07
I0826 10:03:43.751515  1343 solver.cpp:228] Iteration 22400, loss = 3.50096
I0826 10:03:43.751588  1343 solver.cpp:244]     Train net output #0: loss = 3.50096 (* 1 = 3.50096 loss)
I0826 10:03:43.751598  1343 sgd_solver.cpp:106] Iteration 22400, lr = 5.69178e-07
I0826 10:03:52.142213  1343 solver.cpp:228] Iteration 22500, loss = 3.49559
I0826 10:03:52.142258  1343 solver.cpp:244]     Train net output #0: loss = 3.49559 (* 1 = 3.49559 loss)
I0826 10:03:52.142264  1343 sgd_solver.cpp:106] Iteration 22500, lr = 5.68173e-07
I0826 10:04:00.568222  1343 solver.cpp:228] Iteration 22600, loss = 3.53402
I0826 10:04:00.568303  1343 solver.cpp:244]     Train net output #0: loss = 3.53402 (* 1 = 3.53402 loss)
I0826 10:04:00.568325  1343 sgd_solver.cpp:106] Iteration 22600, lr = 5.67173e-07
I0826 10:04:05.937175  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:04:08.978297  1343 solver.cpp:228] Iteration 22700, loss = 3.49715
I0826 10:04:08.978371  1343 solver.cpp:244]     Train net output #0: loss = 3.49715 (* 1 = 3.49715 loss)
I0826 10:04:08.978382  1343 sgd_solver.cpp:106] Iteration 22700, lr = 5.66176e-07
I0826 10:04:17.381862  1343 solver.cpp:228] Iteration 22800, loss = 3.36941
I0826 10:04:17.381908  1343 solver.cpp:244]     Train net output #0: loss = 3.36941 (* 1 = 3.36941 loss)
I0826 10:04:17.381914  1343 sgd_solver.cpp:106] Iteration 22800, lr = 5.65184e-07
I0826 10:04:25.790470  1343 solver.cpp:228] Iteration 22900, loss = 3.57616
I0826 10:04:25.790513  1343 solver.cpp:244]     Train net output #0: loss = 3.57616 (* 1 = 3.57616 loss)
I0826 10:04:25.790518  1343 sgd_solver.cpp:106] Iteration 22900, lr = 5.64195e-07
I0826 10:04:34.190759  1343 solver.cpp:228] Iteration 23000, loss = 3.693
I0826 10:04:34.190845  1343 solver.cpp:244]     Train net output #0: loss = 3.693 (* 1 = 3.693 loss)
I0826 10:04:34.190853  1343 sgd_solver.cpp:106] Iteration 23000, lr = 5.63211e-07
I0826 10:04:42.605356  1343 solver.cpp:228] Iteration 23100, loss = 3.64618
I0826 10:04:42.605415  1343 solver.cpp:244]     Train net output #0: loss = 3.64618 (* 1 = 3.64618 loss)
I0826 10:04:42.605423  1343 sgd_solver.cpp:106] Iteration 23100, lr = 5.62231e-07
I0826 10:04:51.036571  1343 solver.cpp:228] Iteration 23200, loss = 3.6586
I0826 10:04:51.036638  1343 solver.cpp:244]     Train net output #0: loss = 3.6586 (* 1 = 3.6586 loss)
I0826 10:04:51.036649  1343 sgd_solver.cpp:106] Iteration 23200, lr = 5.61254e-07
I0826 10:04:59.432489  1343 solver.cpp:228] Iteration 23300, loss = 3.45112
I0826 10:04:59.432555  1343 solver.cpp:244]     Train net output #0: loss = 3.45112 (* 1 = 3.45112 loss)
I0826 10:04:59.432566  1343 sgd_solver.cpp:106] Iteration 23300, lr = 5.60282e-07
I0826 10:05:07.854275  1343 solver.cpp:228] Iteration 23400, loss = 3.6959
I0826 10:05:07.854332  1343 solver.cpp:244]     Train net output #0: loss = 3.6959 (* 1 = 3.6959 loss)
I0826 10:05:07.854343  1343 sgd_solver.cpp:106] Iteration 23400, lr = 5.59313e-07
I0826 10:05:16.270118  1343 solver.cpp:228] Iteration 23500, loss = 3.51329
I0826 10:05:16.270175  1343 solver.cpp:244]     Train net output #0: loss = 3.51329 (* 1 = 3.51329 loss)
I0826 10:05:16.270181  1343 sgd_solver.cpp:106] Iteration 23500, lr = 5.58349e-07
I0826 10:05:24.665999  1343 solver.cpp:228] Iteration 23600, loss = 3.57426
I0826 10:05:24.666064  1343 solver.cpp:244]     Train net output #0: loss = 3.57426 (* 1 = 3.57426 loss)
I0826 10:05:24.666075  1343 sgd_solver.cpp:106] Iteration 23600, lr = 5.57388e-07
I0826 10:05:33.094178  1343 solver.cpp:228] Iteration 23700, loss = 3.3206
I0826 10:05:33.094256  1343 solver.cpp:244]     Train net output #0: loss = 3.3206 (* 1 = 3.3206 loss)
I0826 10:05:33.094267  1343 sgd_solver.cpp:106] Iteration 23700, lr = 5.56431e-07
I0826 10:05:41.511787  1343 solver.cpp:228] Iteration 23800, loss = 3.55769
I0826 10:05:41.511854  1343 solver.cpp:244]     Train net output #0: loss = 3.55769 (* 1 = 3.55769 loss)
I0826 10:05:41.511863  1343 sgd_solver.cpp:106] Iteration 23800, lr = 5.55478e-07
I0826 10:05:49.914086  1343 solver.cpp:228] Iteration 23900, loss = 3.61203
I0826 10:05:49.914165  1343 solver.cpp:244]     Train net output #0: loss = 3.61203 (* 1 = 3.61203 loss)
I0826 10:05:49.914177  1343 sgd_solver.cpp:106] Iteration 23900, lr = 5.54529e-07
I0826 10:05:58.337692  1343 solver.cpp:228] Iteration 24000, loss = 3.69792
I0826 10:05:58.337756  1343 solver.cpp:244]     Train net output #0: loss = 3.69792 (* 1 = 3.69792 loss)
I0826 10:05:58.337766  1343 sgd_solver.cpp:106] Iteration 24000, lr = 5.53583e-07
I0826 10:06:06.769496  1343 solver.cpp:228] Iteration 24100, loss = 3.41365
I0826 10:06:06.769562  1343 solver.cpp:244]     Train net output #0: loss = 3.41365 (* 1 = 3.41365 loss)
I0826 10:06:06.769572  1343 sgd_solver.cpp:106] Iteration 24100, lr = 5.52642e-07
I0826 10:06:15.188843  1343 solver.cpp:228] Iteration 24200, loss = 3.37856
I0826 10:06:15.188910  1343 solver.cpp:244]     Train net output #0: loss = 3.37856 (* 1 = 3.37856 loss)
I0826 10:06:15.188930  1343 sgd_solver.cpp:106] Iteration 24200, lr = 5.51704e-07
I0826 10:06:23.589505  1343 solver.cpp:228] Iteration 24300, loss = 3.5829
I0826 10:06:23.589570  1343 solver.cpp:244]     Train net output #0: loss = 3.5829 (* 1 = 3.5829 loss)
I0826 10:06:23.589584  1343 sgd_solver.cpp:106] Iteration 24300, lr = 5.50769e-07
I0826 10:06:32.008669  1343 solver.cpp:228] Iteration 24400, loss = 3.61032
I0826 10:06:32.008711  1343 solver.cpp:244]     Train net output #0: loss = 3.61032 (* 1 = 3.61032 loss)
I0826 10:06:32.008716  1343 sgd_solver.cpp:106] Iteration 24400, lr = 5.49839e-07
I0826 10:06:40.404451  1343 solver.cpp:228] Iteration 24500, loss = 3.49395
I0826 10:06:40.404507  1343 solver.cpp:244]     Train net output #0: loss = 3.49395 (* 1 = 3.49395 loss)
I0826 10:06:40.404516  1343 sgd_solver.cpp:106] Iteration 24500, lr = 5.48912e-07
I0826 10:06:48.815753  1343 solver.cpp:228] Iteration 24600, loss = 3.43492
I0826 10:06:48.815814  1343 solver.cpp:244]     Train net output #0: loss = 3.43492 (* 1 = 3.43492 loss)
I0826 10:06:48.815825  1343 sgd_solver.cpp:106] Iteration 24600, lr = 5.47988e-07
I0826 10:06:57.233191  1343 solver.cpp:228] Iteration 24700, loss = 3.61613
I0826 10:06:57.233259  1343 solver.cpp:244]     Train net output #0: loss = 3.61613 (* 1 = 3.61613 loss)
I0826 10:06:57.233271  1343 sgd_solver.cpp:106] Iteration 24700, lr = 5.47069e-07
I0826 10:07:05.640563  1343 solver.cpp:228] Iteration 24800, loss = 3.52795
I0826 10:07:05.640628  1343 solver.cpp:244]     Train net output #0: loss = 3.52795 (* 1 = 3.52795 loss)
I0826 10:07:05.640640  1343 sgd_solver.cpp:106] Iteration 24800, lr = 5.46153e-07
I0826 10:07:14.054165  1343 solver.cpp:228] Iteration 24900, loss = 3.66011
I0826 10:07:14.054234  1343 solver.cpp:244]     Train net output #0: loss = 3.66011 (* 1 = 3.66011 loss)
I0826 10:07:14.054244  1343 sgd_solver.cpp:106] Iteration 24900, lr = 5.4524e-07
I0826 10:07:22.372395  1343 solver.cpp:337] Iteration 25000, Testing net (#0)
I0826 10:07:33.821117  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:08:00.708015  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 10:08:00.708081  1343 solver.cpp:404]     Test net output #1: loss = 3.53764 (* 1 = 3.53764 loss)
I0826 10:08:00.738643  1343 solver.cpp:228] Iteration 25000, loss = 3.50812
I0826 10:08:00.738714  1343 solver.cpp:244]     Train net output #0: loss = 3.50812 (* 1 = 3.50812 loss)
I0826 10:08:00.738734  1343 sgd_solver.cpp:106] Iteration 25000, lr = 5.44331e-07
I0826 10:08:09.161304  1343 solver.cpp:228] Iteration 25100, loss = 3.43906
I0826 10:08:09.161361  1343 solver.cpp:244]     Train net output #0: loss = 3.43906 (* 1 = 3.43906 loss)
I0826 10:08:09.161370  1343 sgd_solver.cpp:106] Iteration 25100, lr = 5.43426e-07
I0826 10:08:17.577931  1343 solver.cpp:228] Iteration 25200, loss = 3.48619
I0826 10:08:17.577993  1343 solver.cpp:244]     Train net output #0: loss = 3.48619 (* 1 = 3.48619 loss)
I0826 10:08:17.577999  1343 sgd_solver.cpp:106] Iteration 25200, lr = 5.42524e-07
I0826 10:08:25.978750  1343 solver.cpp:228] Iteration 25300, loss = 3.74193
I0826 10:08:25.978801  1343 solver.cpp:244]     Train net output #0: loss = 3.74193 (* 1 = 3.74193 loss)
I0826 10:08:25.978807  1343 sgd_solver.cpp:106] Iteration 25300, lr = 5.41625e-07
I0826 10:08:34.404589  1343 solver.cpp:228] Iteration 25400, loss = 3.5327
I0826 10:08:34.404656  1343 solver.cpp:244]     Train net output #0: loss = 3.5327 (* 1 = 3.5327 loss)
I0826 10:08:34.404664  1343 sgd_solver.cpp:106] Iteration 25400, lr = 5.4073e-07
I0826 10:08:42.818122  1343 solver.cpp:228] Iteration 25500, loss = 3.47569
I0826 10:08:42.818172  1343 solver.cpp:244]     Train net output #0: loss = 3.47569 (* 1 = 3.47569 loss)
I0826 10:08:42.818178  1343 sgd_solver.cpp:106] Iteration 25500, lr = 5.39839e-07
I0826 10:08:51.220670  1343 solver.cpp:228] Iteration 25600, loss = 3.5226
I0826 10:08:51.220719  1343 solver.cpp:244]     Train net output #0: loss = 3.5226 (* 1 = 3.5226 loss)
I0826 10:08:51.220726  1343 sgd_solver.cpp:106] Iteration 25600, lr = 5.3895e-07
I0826 10:08:59.637305  1343 solver.cpp:228] Iteration 25700, loss = 3.31417
I0826 10:08:59.637346  1343 solver.cpp:244]     Train net output #0: loss = 3.31417 (* 1 = 3.31417 loss)
I0826 10:08:59.637352  1343 sgd_solver.cpp:106] Iteration 25700, lr = 5.38066e-07
I0826 10:09:08.062304  1343 solver.cpp:228] Iteration 25800, loss = 3.5494
I0826 10:09:08.062353  1343 solver.cpp:244]     Train net output #0: loss = 3.5494 (* 1 = 3.5494 loss)
I0826 10:09:08.062361  1343 sgd_solver.cpp:106] Iteration 25800, lr = 5.37184e-07
I0826 10:09:16.462131  1343 solver.cpp:228] Iteration 25900, loss = 3.57214
I0826 10:09:16.462198  1343 solver.cpp:244]     Train net output #0: loss = 3.57214 (* 1 = 3.57214 loss)
I0826 10:09:16.462216  1343 sgd_solver.cpp:106] Iteration 25900, lr = 5.36306e-07
I0826 10:09:24.885213  1343 solver.cpp:228] Iteration 26000, loss = 3.49221
I0826 10:09:24.885268  1343 solver.cpp:244]     Train net output #0: loss = 3.49221 (* 1 = 3.49221 loss)
I0826 10:09:24.885275  1343 sgd_solver.cpp:106] Iteration 26000, lr = 5.35432e-07
I0826 10:09:33.310199  1343 solver.cpp:228] Iteration 26100, loss = 3.54387
I0826 10:09:33.310259  1343 solver.cpp:244]     Train net output #0: loss = 3.54387 (* 1 = 3.54387 loss)
I0826 10:09:33.310268  1343 sgd_solver.cpp:106] Iteration 26100, lr = 5.3456e-07
I0826 10:09:36.600059  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:09:41.742673  1343 solver.cpp:228] Iteration 26200, loss = 3.59119
I0826 10:09:41.742748  1343 solver.cpp:244]     Train net output #0: loss = 3.59119 (* 1 = 3.59119 loss)
I0826 10:09:41.742758  1343 sgd_solver.cpp:106] Iteration 26200, lr = 5.33692e-07
I0826 10:09:50.140434  1343 solver.cpp:228] Iteration 26300, loss = 3.43915
I0826 10:09:50.140476  1343 solver.cpp:244]     Train net output #0: loss = 3.43915 (* 1 = 3.43915 loss)
I0826 10:09:50.140482  1343 sgd_solver.cpp:106] Iteration 26300, lr = 5.32828e-07
I0826 10:09:58.549326  1343 solver.cpp:228] Iteration 26400, loss = 3.6175
I0826 10:09:58.549379  1343 solver.cpp:244]     Train net output #0: loss = 3.6175 (* 1 = 3.6175 loss)
I0826 10:09:58.549386  1343 sgd_solver.cpp:106] Iteration 26400, lr = 5.31966e-07
I0826 10:10:06.959100  1343 solver.cpp:228] Iteration 26500, loss = 3.41201
I0826 10:10:06.959161  1343 solver.cpp:244]     Train net output #0: loss = 3.41201 (* 1 = 3.41201 loss)
I0826 10:10:06.959167  1343 sgd_solver.cpp:106] Iteration 26500, lr = 5.31108e-07
I0826 10:10:15.357130  1343 solver.cpp:228] Iteration 26600, loss = 3.72485
I0826 10:10:15.357180  1343 solver.cpp:244]     Train net output #0: loss = 3.72485 (* 1 = 3.72485 loss)
I0826 10:10:15.357187  1343 sgd_solver.cpp:106] Iteration 26600, lr = 5.30253e-07
I0826 10:10:23.776684  1343 solver.cpp:228] Iteration 26700, loss = 3.49156
I0826 10:10:23.776753  1343 solver.cpp:244]     Train net output #0: loss = 3.49156 (* 1 = 3.49156 loss)
I0826 10:10:23.776764  1343 sgd_solver.cpp:106] Iteration 26700, lr = 5.29401e-07
I0826 10:10:32.181306  1343 solver.cpp:228] Iteration 26800, loss = 3.6036
I0826 10:10:32.181376  1343 solver.cpp:244]     Train net output #0: loss = 3.6036 (* 1 = 3.6036 loss)
I0826 10:10:32.181386  1343 sgd_solver.cpp:106] Iteration 26800, lr = 5.28553e-07
I0826 10:10:40.591971  1343 solver.cpp:228] Iteration 26900, loss = 3.36675
I0826 10:10:40.592017  1343 solver.cpp:244]     Train net output #0: loss = 3.36675 (* 1 = 3.36675 loss)
I0826 10:10:40.592025  1343 sgd_solver.cpp:106] Iteration 26900, lr = 5.27707e-07
I0826 10:10:49.010252  1343 solver.cpp:228] Iteration 27000, loss = 3.64644
I0826 10:10:49.010313  1343 solver.cpp:244]     Train net output #0: loss = 3.64644 (* 1 = 3.64644 loss)
I0826 10:10:49.010323  1343 sgd_solver.cpp:106] Iteration 27000, lr = 5.26865e-07
I0826 10:10:57.423240  1343 solver.cpp:228] Iteration 27100, loss = 3.4148
I0826 10:10:57.423301  1343 solver.cpp:244]     Train net output #0: loss = 3.4148 (* 1 = 3.4148 loss)
I0826 10:10:57.423308  1343 sgd_solver.cpp:106] Iteration 27100, lr = 5.26026e-07
I0826 10:11:05.832434  1343 solver.cpp:228] Iteration 27200, loss = 3.57109
I0826 10:11:05.832476  1343 solver.cpp:244]     Train net output #0: loss = 3.57109 (* 1 = 3.57109 loss)
I0826 10:11:05.832482  1343 sgd_solver.cpp:106] Iteration 27200, lr = 5.25189e-07
I0826 10:11:14.255858  1343 solver.cpp:228] Iteration 27300, loss = 3.61617
I0826 10:11:14.255946  1343 solver.cpp:244]     Train net output #0: loss = 3.61617 (* 1 = 3.61617 loss)
I0826 10:11:14.255962  1343 sgd_solver.cpp:106] Iteration 27300, lr = 5.24356e-07
I0826 10:11:22.655334  1343 solver.cpp:228] Iteration 27400, loss = 3.46325
I0826 10:11:22.655376  1343 solver.cpp:244]     Train net output #0: loss = 3.46325 (* 1 = 3.46325 loss)
I0826 10:11:22.655382  1343 sgd_solver.cpp:106] Iteration 27400, lr = 5.23527e-07
I0826 10:11:31.070698  1343 solver.cpp:228] Iteration 27500, loss = 3.42836
I0826 10:11:31.070767  1343 solver.cpp:244]     Train net output #0: loss = 3.42836 (* 1 = 3.42836 loss)
I0826 10:11:31.070778  1343 sgd_solver.cpp:106] Iteration 27500, lr = 5.227e-07
I0826 10:11:39.491003  1343 solver.cpp:228] Iteration 27600, loss = 3.56588
I0826 10:11:39.491044  1343 solver.cpp:244]     Train net output #0: loss = 3.56588 (* 1 = 3.56588 loss)
I0826 10:11:39.491050  1343 sgd_solver.cpp:106] Iteration 27600, lr = 5.21876e-07
I0826 10:11:47.896271  1343 solver.cpp:228] Iteration 27700, loss = 3.67051
I0826 10:11:47.896335  1343 solver.cpp:244]     Train net output #0: loss = 3.67051 (* 1 = 3.67051 loss)
I0826 10:11:47.896344  1343 sgd_solver.cpp:106] Iteration 27700, lr = 5.21055e-07
I0826 10:11:56.305557  1343 solver.cpp:228] Iteration 27800, loss = 3.55937
I0826 10:11:56.305604  1343 solver.cpp:244]     Train net output #0: loss = 3.55937 (* 1 = 3.55937 loss)
I0826 10:11:56.305613  1343 sgd_solver.cpp:106] Iteration 27800, lr = 5.20237e-07
I0826 10:12:04.709414  1343 solver.cpp:228] Iteration 27900, loss = 3.37519
I0826 10:12:04.709470  1343 solver.cpp:244]     Train net output #0: loss = 3.37519 (* 1 = 3.37519 loss)
I0826 10:12:04.709477  1343 sgd_solver.cpp:106] Iteration 27900, lr = 5.19423e-07
I0826 10:12:13.124122  1343 solver.cpp:228] Iteration 28000, loss = 3.47367
I0826 10:12:13.124200  1343 solver.cpp:244]     Train net output #0: loss = 3.47367 (* 1 = 3.47367 loss)
I0826 10:12:13.124212  1343 sgd_solver.cpp:106] Iteration 28000, lr = 5.18611e-07
I0826 10:12:21.550173  1343 solver.cpp:228] Iteration 28100, loss = 3.36481
I0826 10:12:21.550240  1343 solver.cpp:244]     Train net output #0: loss = 3.36481 (* 1 = 3.36481 loss)
I0826 10:12:21.550253  1343 sgd_solver.cpp:106] Iteration 28100, lr = 5.17802e-07
I0826 10:12:29.972064  1343 solver.cpp:228] Iteration 28200, loss = 3.43507
I0826 10:12:29.972127  1343 solver.cpp:244]     Train net output #0: loss = 3.43507 (* 1 = 3.43507 loss)
I0826 10:12:29.972136  1343 sgd_solver.cpp:106] Iteration 28200, lr = 5.16996e-07
I0826 10:12:38.374037  1343 solver.cpp:228] Iteration 28300, loss = 3.72543
I0826 10:12:38.374094  1343 solver.cpp:244]     Train net output #0: loss = 3.72543 (* 1 = 3.72543 loss)
I0826 10:12:38.374106  1343 sgd_solver.cpp:106] Iteration 28300, lr = 5.16193e-07
I0826 10:12:46.795771  1343 solver.cpp:228] Iteration 28400, loss = 3.4896
I0826 10:12:46.795820  1343 solver.cpp:244]     Train net output #0: loss = 3.4896 (* 1 = 3.4896 loss)
I0826 10:12:46.795827  1343 sgd_solver.cpp:106] Iteration 28400, lr = 5.15393e-07
I0826 10:12:55.209846  1343 solver.cpp:228] Iteration 28500, loss = 3.51847
I0826 10:12:55.209887  1343 solver.cpp:244]     Train net output #0: loss = 3.51847 (* 1 = 3.51847 loss)
I0826 10:12:55.209892  1343 sgd_solver.cpp:106] Iteration 28500, lr = 5.14596e-07
I0826 10:13:03.633268  1343 solver.cpp:228] Iteration 28600, loss = 3.54727
I0826 10:13:03.633340  1343 solver.cpp:244]     Train net output #0: loss = 3.54727 (* 1 = 3.54727 loss)
I0826 10:13:03.633352  1343 sgd_solver.cpp:106] Iteration 28600, lr = 5.13801e-07
I0826 10:13:12.051707  1343 solver.cpp:228] Iteration 28700, loss = 3.46185
I0826 10:13:12.051755  1343 solver.cpp:244]     Train net output #0: loss = 3.46185 (* 1 = 3.46185 loss)
I0826 10:13:12.051760  1343 sgd_solver.cpp:106] Iteration 28700, lr = 5.1301e-07
I0826 10:13:20.481937  1343 solver.cpp:228] Iteration 28800, loss = 3.5851
I0826 10:13:20.481997  1343 solver.cpp:244]     Train net output #0: loss = 3.5851 (* 1 = 3.5851 loss)
I0826 10:13:20.482007  1343 sgd_solver.cpp:106] Iteration 28800, lr = 5.12221e-07
I0826 10:13:28.898551  1343 solver.cpp:228] Iteration 28900, loss = 3.47694
I0826 10:13:28.898603  1343 solver.cpp:244]     Train net output #0: loss = 3.47694 (* 1 = 3.47694 loss)
I0826 10:13:28.898612  1343 sgd_solver.cpp:106] Iteration 28900, lr = 5.11435e-07
I0826 10:13:37.287156  1343 solver.cpp:228] Iteration 29000, loss = 3.55442
I0826 10:13:37.287235  1343 solver.cpp:244]     Train net output #0: loss = 3.55442 (* 1 = 3.55442 loss)
I0826 10:13:37.287248  1343 sgd_solver.cpp:106] Iteration 29000, lr = 5.10653e-07
I0826 10:13:45.697832  1343 solver.cpp:228] Iteration 29100, loss = 3.59891
I0826 10:13:45.697875  1343 solver.cpp:244]     Train net output #0: loss = 3.59891 (* 1 = 3.59891 loss)
I0826 10:13:45.697881  1343 sgd_solver.cpp:106] Iteration 29100, lr = 5.09872e-07
I0826 10:13:54.097512  1343 solver.cpp:228] Iteration 29200, loss = 3.4791
I0826 10:13:54.097573  1343 solver.cpp:244]     Train net output #0: loss = 3.4791 (* 1 = 3.4791 loss)
I0826 10:13:54.097584  1343 sgd_solver.cpp:106] Iteration 29200, lr = 5.09095e-07
I0826 10:14:02.513037  1343 solver.cpp:228] Iteration 29300, loss = 3.28265
I0826 10:14:02.513098  1343 solver.cpp:244]     Train net output #0: loss = 3.28265 (* 1 = 3.28265 loss)
I0826 10:14:02.513106  1343 sgd_solver.cpp:106] Iteration 29300, lr = 5.0832e-07
I0826 10:14:10.927848  1343 solver.cpp:228] Iteration 29400, loss = 3.48153
I0826 10:14:10.927917  1343 solver.cpp:244]     Train net output #0: loss = 3.48153 (* 1 = 3.48153 loss)
I0826 10:14:10.927928  1343 sgd_solver.cpp:106] Iteration 29400, lr = 5.07548e-07
I0826 10:14:19.330473  1343 solver.cpp:228] Iteration 29500, loss = 3.54512
I0826 10:14:19.330528  1343 solver.cpp:244]     Train net output #0: loss = 3.54512 (* 1 = 3.54512 loss)
I0826 10:14:19.330536  1343 sgd_solver.cpp:106] Iteration 29500, lr = 5.06779e-07
I0826 10:14:27.740104  1343 solver.cpp:228] Iteration 29600, loss = 3.42985
I0826 10:14:27.740159  1343 solver.cpp:244]     Train net output #0: loss = 3.42985 (* 1 = 3.42985 loss)
I0826 10:14:27.740165  1343 sgd_solver.cpp:106] Iteration 29600, lr = 5.06012e-07
I0826 10:14:36.133599  1343 solver.cpp:228] Iteration 29700, loss = 3.40374
I0826 10:14:36.133648  1343 solver.cpp:244]     Train net output #0: loss = 3.40374 (* 1 = 3.40374 loss)
I0826 10:14:36.133656  1343 sgd_solver.cpp:106] Iteration 29700, lr = 5.05249e-07
I0826 10:14:42.197022  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:14:44.549031  1343 solver.cpp:228] Iteration 29800, loss = 3.41924
I0826 10:14:44.549082  1343 solver.cpp:244]     Train net output #0: loss = 3.41924 (* 1 = 3.41924 loss)
I0826 10:14:44.549089  1343 sgd_solver.cpp:106] Iteration 29800, lr = 5.04488e-07
I0826 10:14:52.946004  1343 solver.cpp:228] Iteration 29900, loss = 3.58899
I0826 10:14:52.946063  1343 solver.cpp:244]     Train net output #0: loss = 3.58899 (* 1 = 3.58899 loss)
I0826 10:14:52.946071  1343 sgd_solver.cpp:106] Iteration 29900, lr = 5.03729e-07
I0826 10:15:01.284523  1343 solver.cpp:337] Iteration 30000, Testing net (#0)
I0826 10:15:39.604646  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:15:40.172155  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302041
I0826 10:15:40.172225  1343 solver.cpp:404]     Test net output #1: loss = 3.52197 (* 1 = 3.52197 loss)
I0826 10:15:40.201469  1343 solver.cpp:228] Iteration 30000, loss = 3.59176
I0826 10:15:40.201519  1343 solver.cpp:244]     Train net output #0: loss = 3.59176 (* 1 = 3.59176 loss)
I0826 10:15:40.201531  1343 sgd_solver.cpp:106] Iteration 30000, lr = 5.02973e-07
I0826 10:15:48.633832  1343 solver.cpp:228] Iteration 30100, loss = 3.60501
I0826 10:15:48.633931  1343 solver.cpp:244]     Train net output #0: loss = 3.60501 (* 1 = 3.60501 loss)
I0826 10:15:48.633949  1343 sgd_solver.cpp:106] Iteration 30100, lr = 5.0222e-07
I0826 10:15:57.018407  1343 solver.cpp:228] Iteration 30200, loss = 3.53333
I0826 10:15:57.018450  1343 solver.cpp:244]     Train net output #0: loss = 3.53333 (* 1 = 3.53333 loss)
I0826 10:15:57.018456  1343 sgd_solver.cpp:106] Iteration 30200, lr = 5.0147e-07
I0826 10:16:05.407238  1343 solver.cpp:228] Iteration 30300, loss = 3.47415
I0826 10:16:05.407285  1343 solver.cpp:244]     Train net output #0: loss = 3.47415 (* 1 = 3.47415 loss)
I0826 10:16:05.407292  1343 sgd_solver.cpp:106] Iteration 30300, lr = 5.00722e-07
I0826 10:16:13.821213  1343 solver.cpp:228] Iteration 30400, loss = 3.55651
I0826 10:16:13.821272  1343 solver.cpp:244]     Train net output #0: loss = 3.55651 (* 1 = 3.55651 loss)
I0826 10:16:13.821285  1343 sgd_solver.cpp:106] Iteration 30400, lr = 4.99977e-07
I0826 10:16:22.213008  1343 solver.cpp:228] Iteration 30500, loss = 3.47969
I0826 10:16:22.213068  1343 solver.cpp:244]     Train net output #0: loss = 3.47969 (* 1 = 3.47969 loss)
I0826 10:16:22.213075  1343 sgd_solver.cpp:106] Iteration 30500, lr = 4.99234e-07
I0826 10:16:30.621908  1343 solver.cpp:228] Iteration 30600, loss = 3.49506
I0826 10:16:30.621963  1343 solver.cpp:244]     Train net output #0: loss = 3.49506 (* 1 = 3.49506 loss)
I0826 10:16:30.621969  1343 sgd_solver.cpp:106] Iteration 30600, lr = 4.98494e-07
I0826 10:16:39.022598  1343 solver.cpp:228] Iteration 30700, loss = 3.4294
I0826 10:16:39.022657  1343 solver.cpp:244]     Train net output #0: loss = 3.4294 (* 1 = 3.4294 loss)
I0826 10:16:39.022670  1343 sgd_solver.cpp:106] Iteration 30700, lr = 4.97756e-07
I0826 10:16:47.425619  1343 solver.cpp:228] Iteration 30800, loss = 3.46178
I0826 10:16:47.425662  1343 solver.cpp:244]     Train net output #0: loss = 3.46178 (* 1 = 3.46178 loss)
I0826 10:16:47.425668  1343 sgd_solver.cpp:106] Iteration 30800, lr = 4.97021e-07
I0826 10:16:55.816243  1343 solver.cpp:228] Iteration 30900, loss = 3.5342
I0826 10:16:55.816299  1343 solver.cpp:244]     Train net output #0: loss = 3.5342 (* 1 = 3.5342 loss)
I0826 10:16:55.816306  1343 sgd_solver.cpp:106] Iteration 30900, lr = 4.96288e-07
I0826 10:17:04.219669  1343 solver.cpp:228] Iteration 31000, loss = 3.49248
I0826 10:17:04.219736  1343 solver.cpp:244]     Train net output #0: loss = 3.49248 (* 1 = 3.49248 loss)
I0826 10:17:04.219746  1343 sgd_solver.cpp:106] Iteration 31000, lr = 4.95558e-07
I0826 10:17:12.620573  1343 solver.cpp:228] Iteration 31100, loss = 3.53143
I0826 10:17:12.620635  1343 solver.cpp:244]     Train net output #0: loss = 3.53143 (* 1 = 3.53143 loss)
I0826 10:17:12.620645  1343 sgd_solver.cpp:106] Iteration 31100, lr = 4.94831e-07
I0826 10:17:21.036331  1343 solver.cpp:228] Iteration 31200, loss = 3.59286
I0826 10:17:21.036381  1343 solver.cpp:244]     Train net output #0: loss = 3.59286 (* 1 = 3.59286 loss)
I0826 10:17:21.036386  1343 sgd_solver.cpp:106] Iteration 31200, lr = 4.94106e-07
I0826 10:17:29.447396  1343 solver.cpp:228] Iteration 31300, loss = 3.66469
I0826 10:17:29.447443  1343 solver.cpp:244]     Train net output #0: loss = 3.66469 (* 1 = 3.66469 loss)
I0826 10:17:29.447449  1343 sgd_solver.cpp:106] Iteration 31300, lr = 4.93383e-07
I0826 10:17:37.845825  1343 solver.cpp:228] Iteration 31400, loss = 3.55312
I0826 10:17:37.845882  1343 solver.cpp:244]     Train net output #0: loss = 3.55312 (* 1 = 3.55312 loss)
I0826 10:17:37.845890  1343 sgd_solver.cpp:106] Iteration 31400, lr = 4.92663e-07
I0826 10:17:46.258081  1343 solver.cpp:228] Iteration 31500, loss = 3.49075
I0826 10:17:46.258143  1343 solver.cpp:244]     Train net output #0: loss = 3.49075 (* 1 = 3.49075 loss)
I0826 10:17:46.258157  1343 sgd_solver.cpp:106] Iteration 31500, lr = 4.91946e-07
I0826 10:17:54.678617  1343 solver.cpp:228] Iteration 31600, loss = 3.4884
I0826 10:17:54.678684  1343 solver.cpp:244]     Train net output #0: loss = 3.4884 (* 1 = 3.4884 loss)
I0826 10:17:54.678695  1343 sgd_solver.cpp:106] Iteration 31600, lr = 4.9123e-07
I0826 10:18:03.082821  1343 solver.cpp:228] Iteration 31700, loss = 3.61525
I0826 10:18:03.082876  1343 solver.cpp:244]     Train net output #0: loss = 3.61525 (* 1 = 3.61525 loss)
I0826 10:18:03.082885  1343 sgd_solver.cpp:106] Iteration 31700, lr = 4.90518e-07
I0826 10:18:11.493144  1343 solver.cpp:228] Iteration 31800, loss = 3.40791
I0826 10:18:11.493190  1343 solver.cpp:244]     Train net output #0: loss = 3.40791 (* 1 = 3.40791 loss)
I0826 10:18:11.493196  1343 sgd_solver.cpp:106] Iteration 31800, lr = 4.89807e-07
I0826 10:18:19.910946  1343 solver.cpp:228] Iteration 31900, loss = 3.55843
I0826 10:18:19.911020  1343 solver.cpp:244]     Train net output #0: loss = 3.55843 (* 1 = 3.55843 loss)
I0826 10:18:19.911032  1343 sgd_solver.cpp:106] Iteration 31900, lr = 4.89099e-07
I0826 10:18:28.319007  1343 solver.cpp:228] Iteration 32000, loss = 3.53929
I0826 10:18:28.319059  1343 solver.cpp:244]     Train net output #0: loss = 3.53929 (* 1 = 3.53929 loss)
I0826 10:18:28.319066  1343 sgd_solver.cpp:106] Iteration 32000, lr = 4.88394e-07
I0826 10:18:36.739019  1343 solver.cpp:228] Iteration 32100, loss = 3.39791
I0826 10:18:36.739063  1343 solver.cpp:244]     Train net output #0: loss = 3.39791 (* 1 = 3.39791 loss)
I0826 10:18:36.739068  1343 sgd_solver.cpp:106] Iteration 32100, lr = 4.8769e-07
I0826 10:18:45.145916  1343 solver.cpp:228] Iteration 32200, loss = 3.50107
I0826 10:18:45.145983  1343 solver.cpp:244]     Train net output #0: loss = 3.50107 (* 1 = 3.50107 loss)
I0826 10:18:45.145992  1343 sgd_solver.cpp:106] Iteration 32200, lr = 4.8699e-07
I0826 10:18:53.566040  1343 solver.cpp:228] Iteration 32300, loss = 3.34509
I0826 10:18:53.566108  1343 solver.cpp:244]     Train net output #0: loss = 3.34509 (* 1 = 3.34509 loss)
I0826 10:18:53.566118  1343 sgd_solver.cpp:106] Iteration 32300, lr = 4.86291e-07
I0826 10:19:01.973950  1343 solver.cpp:228] Iteration 32400, loss = 3.52711
I0826 10:19:01.974019  1343 solver.cpp:244]     Train net output #0: loss = 3.52711 (* 1 = 3.52711 loss)
I0826 10:19:01.974033  1343 sgd_solver.cpp:106] Iteration 32400, lr = 4.85595e-07
I0826 10:19:10.379865  1343 solver.cpp:228] Iteration 32500, loss = 3.50438
I0826 10:19:10.379923  1343 solver.cpp:244]     Train net output #0: loss = 3.50438 (* 1 = 3.50438 loss)
I0826 10:19:10.379930  1343 sgd_solver.cpp:106] Iteration 32500, lr = 4.84901e-07
I0826 10:19:18.798547  1343 solver.cpp:228] Iteration 32600, loss = 3.43665
I0826 10:19:18.798596  1343 solver.cpp:244]     Train net output #0: loss = 3.43665 (* 1 = 3.43665 loss)
I0826 10:19:18.798602  1343 sgd_solver.cpp:106] Iteration 32600, lr = 4.84209e-07
I0826 10:19:27.184353  1343 solver.cpp:228] Iteration 32700, loss = 3.663
I0826 10:19:27.184397  1343 solver.cpp:244]     Train net output #0: loss = 3.663 (* 1 = 3.663 loss)
I0826 10:19:27.184403  1343 sgd_solver.cpp:106] Iteration 32700, lr = 4.8352e-07
I0826 10:19:35.606325  1343 solver.cpp:228] Iteration 32800, loss = 3.50424
I0826 10:19:35.606385  1343 solver.cpp:244]     Train net output #0: loss = 3.50424 (* 1 = 3.50424 loss)
I0826 10:19:35.606396  1343 sgd_solver.cpp:106] Iteration 32800, lr = 4.82833e-07
I0826 10:19:44.025822  1343 solver.cpp:228] Iteration 32900, loss = 3.57923
I0826 10:19:44.025892  1343 solver.cpp:244]     Train net output #0: loss = 3.57923 (* 1 = 3.57923 loss)
I0826 10:19:44.025903  1343 sgd_solver.cpp:106] Iteration 32900, lr = 4.82148e-07
I0826 10:19:52.424494  1343 solver.cpp:228] Iteration 33000, loss = 3.43193
I0826 10:19:52.424566  1343 solver.cpp:244]     Train net output #0: loss = 3.43193 (* 1 = 3.43193 loss)
I0826 10:19:52.424573  1343 sgd_solver.cpp:106] Iteration 33000, lr = 4.81466e-07
I0826 10:20:00.843438  1343 solver.cpp:228] Iteration 33100, loss = 3.46021
I0826 10:20:00.843480  1343 solver.cpp:244]     Train net output #0: loss = 3.46021 (* 1 = 3.46021 loss)
I0826 10:20:00.843487  1343 sgd_solver.cpp:106] Iteration 33100, lr = 4.80786e-07
I0826 10:20:09.272006  1343 solver.cpp:228] Iteration 33200, loss = 3.52759
I0826 10:20:09.272075  1343 solver.cpp:244]     Train net output #0: loss = 3.52759 (* 1 = 3.52759 loss)
I0826 10:20:09.272085  1343 sgd_solver.cpp:106] Iteration 33200, lr = 4.80108e-07
I0826 10:20:17.682361  1343 solver.cpp:228] Iteration 33300, loss = 3.42268
I0826 10:20:17.682418  1343 solver.cpp:244]     Train net output #0: loss = 3.42268 (* 1 = 3.42268 loss)
I0826 10:20:17.682426  1343 sgd_solver.cpp:106] Iteration 33300, lr = 4.79432e-07
I0826 10:20:26.094430  1343 solver.cpp:228] Iteration 33400, loss = 3.47687
I0826 10:20:26.094501  1343 solver.cpp:244]     Train net output #0: loss = 3.47687 (* 1 = 3.47687 loss)
I0826 10:20:26.094518  1343 sgd_solver.cpp:106] Iteration 33400, lr = 4.78759e-07
I0826 10:20:34.515748  1343 solver.cpp:228] Iteration 33500, loss = 3.66671
I0826 10:20:34.515802  1343 solver.cpp:244]     Train net output #0: loss = 3.66671 (* 1 = 3.66671 loss)
I0826 10:20:34.515810  1343 sgd_solver.cpp:106] Iteration 33500, lr = 4.78087e-07
I0826 10:20:42.930645  1343 solver.cpp:228] Iteration 33600, loss = 3.32872
I0826 10:20:42.930716  1343 solver.cpp:244]     Train net output #0: loss = 3.32872 (* 1 = 3.32872 loss)
I0826 10:20:42.930728  1343 sgd_solver.cpp:106] Iteration 33600, lr = 4.77418e-07
I0826 10:20:45.285367  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:20:51.335016  1343 solver.cpp:228] Iteration 33700, loss = 3.31104
I0826 10:20:51.335105  1343 solver.cpp:244]     Train net output #0: loss = 3.31104 (* 1 = 3.31104 loss)
I0826 10:20:51.335121  1343 sgd_solver.cpp:106] Iteration 33700, lr = 4.76751e-07
I0826 10:20:59.766330  1343 solver.cpp:228] Iteration 33800, loss = 3.41979
I0826 10:20:59.766389  1343 solver.cpp:244]     Train net output #0: loss = 3.41979 (* 1 = 3.41979 loss)
I0826 10:20:59.766397  1343 sgd_solver.cpp:106] Iteration 33800, lr = 4.76086e-07
I0826 10:21:08.179208  1343 solver.cpp:228] Iteration 33900, loss = 3.40418
I0826 10:21:08.179275  1343 solver.cpp:244]     Train net output #0: loss = 3.40418 (* 1 = 3.40418 loss)
I0826 10:21:08.179286  1343 sgd_solver.cpp:106] Iteration 33900, lr = 4.75424e-07
I0826 10:21:16.601783  1343 solver.cpp:228] Iteration 34000, loss = 3.33776
I0826 10:21:16.601832  1343 solver.cpp:244]     Train net output #0: loss = 3.33776 (* 1 = 3.33776 loss)
I0826 10:21:16.601840  1343 sgd_solver.cpp:106] Iteration 34000, lr = 4.74763e-07
I0826 10:21:25.011189  1343 solver.cpp:228] Iteration 34100, loss = 3.57412
I0826 10:21:25.011256  1343 solver.cpp:244]     Train net output #0: loss = 3.57412 (* 1 = 3.57412 loss)
I0826 10:21:25.011271  1343 sgd_solver.cpp:106] Iteration 34100, lr = 4.74105e-07
I0826 10:21:33.425087  1343 solver.cpp:228] Iteration 34200, loss = 3.51374
I0826 10:21:33.425138  1343 solver.cpp:244]     Train net output #0: loss = 3.51374 (* 1 = 3.51374 loss)
I0826 10:21:33.425146  1343 sgd_solver.cpp:106] Iteration 34200, lr = 4.73449e-07
I0826 10:21:41.841608  1343 solver.cpp:228] Iteration 34300, loss = 3.55724
I0826 10:21:41.841665  1343 solver.cpp:244]     Train net output #0: loss = 3.55724 (* 1 = 3.55724 loss)
I0826 10:21:41.841670  1343 sgd_solver.cpp:106] Iteration 34300, lr = 4.72795e-07
I0826 10:21:50.248139  1343 solver.cpp:228] Iteration 34400, loss = 3.44378
I0826 10:21:50.248195  1343 solver.cpp:244]     Train net output #0: loss = 3.44378 (* 1 = 3.44378 loss)
I0826 10:21:50.248203  1343 sgd_solver.cpp:106] Iteration 34400, lr = 4.72143e-07
I0826 10:21:58.667445  1343 solver.cpp:228] Iteration 34500, loss = 3.4041
I0826 10:21:58.667500  1343 solver.cpp:244]     Train net output #0: loss = 3.4041 (* 1 = 3.4041 loss)
I0826 10:21:58.667511  1343 sgd_solver.cpp:106] Iteration 34500, lr = 4.71493e-07
I0826 10:22:07.054610  1343 solver.cpp:228] Iteration 34600, loss = 3.60653
I0826 10:22:07.054658  1343 solver.cpp:244]     Train net output #0: loss = 3.60653 (* 1 = 3.60653 loss)
I0826 10:22:07.054664  1343 sgd_solver.cpp:106] Iteration 34600, lr = 4.70845e-07
I0826 10:22:15.470953  1343 solver.cpp:228] Iteration 34700, loss = 3.45285
I0826 10:22:15.471009  1343 solver.cpp:244]     Train net output #0: loss = 3.45285 (* 1 = 3.45285 loss)
I0826 10:22:15.471019  1343 sgd_solver.cpp:106] Iteration 34700, lr = 4.70199e-07
I0826 10:22:23.892556  1343 solver.cpp:228] Iteration 34800, loss = 3.58913
I0826 10:22:23.892609  1343 solver.cpp:244]     Train net output #0: loss = 3.58913 (* 1 = 3.58913 loss)
I0826 10:22:23.892618  1343 sgd_solver.cpp:106] Iteration 34800, lr = 4.69556e-07
I0826 10:22:32.287829  1343 solver.cpp:228] Iteration 34900, loss = 3.57627
I0826 10:22:32.287873  1343 solver.cpp:244]     Train net output #0: loss = 3.57627 (* 1 = 3.57627 loss)
I0826 10:22:32.287878  1343 sgd_solver.cpp:106] Iteration 34900, lr = 4.68914e-07
I0826 10:22:40.623024  1343 solver.cpp:337] Iteration 35000, Testing net (#0)
I0826 10:23:06.940481  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:23:20.173527  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302024
I0826 10:23:20.173595  1343 solver.cpp:404]     Test net output #1: loss = 3.51102 (* 1 = 3.51102 loss)
I0826 10:23:20.202021  1343 solver.cpp:228] Iteration 35000, loss = 3.35868
I0826 10:23:20.202095  1343 solver.cpp:244]     Train net output #0: loss = 3.35868 (* 1 = 3.35868 loss)
I0826 10:23:20.202107  1343 sgd_solver.cpp:106] Iteration 35000, lr = 4.68274e-07
I0826 10:23:28.608253  1343 solver.cpp:228] Iteration 35100, loss = 3.6988
I0826 10:23:28.608330  1343 solver.cpp:244]     Train net output #0: loss = 3.6988 (* 1 = 3.6988 loss)
I0826 10:23:28.608340  1343 sgd_solver.cpp:106] Iteration 35100, lr = 4.67637e-07
I0826 10:23:37.010035  1343 solver.cpp:228] Iteration 35200, loss = 3.54504
I0826 10:23:37.010082  1343 solver.cpp:244]     Train net output #0: loss = 3.54504 (* 1 = 3.54504 loss)
I0826 10:23:37.010087  1343 sgd_solver.cpp:106] Iteration 35200, lr = 4.67001e-07
I0826 10:23:45.407251  1343 solver.cpp:228] Iteration 35300, loss = 3.55893
I0826 10:23:45.407291  1343 solver.cpp:244]     Train net output #0: loss = 3.55893 (* 1 = 3.55893 loss)
I0826 10:23:45.407306  1343 sgd_solver.cpp:106] Iteration 35300, lr = 4.66368e-07
I0826 10:23:53.793398  1343 solver.cpp:228] Iteration 35400, loss = 3.36479
I0826 10:23:53.793470  1343 solver.cpp:244]     Train net output #0: loss = 3.36479 (* 1 = 3.36479 loss)
I0826 10:23:53.793488  1343 sgd_solver.cpp:106] Iteration 35400, lr = 4.65736e-07
I0826 10:24:02.215405  1343 solver.cpp:228] Iteration 35500, loss = 3.46339
I0826 10:24:02.215494  1343 solver.cpp:244]     Train net output #0: loss = 3.46339 (* 1 = 3.46339 loss)
I0826 10:24:02.215507  1343 sgd_solver.cpp:106] Iteration 35500, lr = 4.65107e-07
I0826 10:24:10.628235  1343 solver.cpp:228] Iteration 35600, loss = 3.56502
I0826 10:24:10.628289  1343 solver.cpp:244]     Train net output #0: loss = 3.56502 (* 1 = 3.56502 loss)
I0826 10:24:10.628298  1343 sgd_solver.cpp:106] Iteration 35600, lr = 4.64479e-07
I0826 10:24:19.027830  1343 solver.cpp:228] Iteration 35700, loss = 3.44168
I0826 10:24:19.027885  1343 solver.cpp:244]     Train net output #0: loss = 3.44168 (* 1 = 3.44168 loss)
I0826 10:24:19.027894  1343 sgd_solver.cpp:106] Iteration 35700, lr = 4.63854e-07
I0826 10:24:27.437719  1343 solver.cpp:228] Iteration 35800, loss = 3.49564
I0826 10:24:27.437749  1343 solver.cpp:244]     Train net output #0: loss = 3.49564 (* 1 = 3.49564 loss)
I0826 10:24:27.437757  1343 sgd_solver.cpp:106] Iteration 35800, lr = 4.6323e-07
I0826 10:24:35.832433  1343 solver.cpp:228] Iteration 35900, loss = 3.52767
I0826 10:24:35.832494  1343 solver.cpp:244]     Train net output #0: loss = 3.52767 (* 1 = 3.52767 loss)
I0826 10:24:35.832501  1343 sgd_solver.cpp:106] Iteration 35900, lr = 4.62609e-07
I0826 10:24:44.258739  1343 solver.cpp:228] Iteration 36000, loss = 3.35565
I0826 10:24:44.258782  1343 solver.cpp:244]     Train net output #0: loss = 3.35565 (* 1 = 3.35565 loss)
I0826 10:24:44.258787  1343 sgd_solver.cpp:106] Iteration 36000, lr = 4.61989e-07
I0826 10:24:52.670653  1343 solver.cpp:228] Iteration 36100, loss = 3.52067
I0826 10:24:52.670728  1343 solver.cpp:244]     Train net output #0: loss = 3.52067 (* 1 = 3.52067 loss)
I0826 10:24:52.670735  1343 sgd_solver.cpp:106] Iteration 36100, lr = 4.61371e-07
I0826 10:25:01.079818  1343 solver.cpp:228] Iteration 36200, loss = 3.53289
I0826 10:25:01.079875  1343 solver.cpp:244]     Train net output #0: loss = 3.53289 (* 1 = 3.53289 loss)
I0826 10:25:01.079881  1343 sgd_solver.cpp:106] Iteration 36200, lr = 4.60755e-07
I0826 10:25:09.491834  1343 solver.cpp:228] Iteration 36300, loss = 3.54014
I0826 10:25:09.491873  1343 solver.cpp:244]     Train net output #0: loss = 3.54014 (* 1 = 3.54014 loss)
I0826 10:25:09.491879  1343 sgd_solver.cpp:106] Iteration 36300, lr = 4.60141e-07
I0826 10:25:17.908432  1343 solver.cpp:228] Iteration 36400, loss = 3.56181
I0826 10:25:17.908476  1343 solver.cpp:244]     Train net output #0: loss = 3.56181 (* 1 = 3.56181 loss)
I0826 10:25:17.908481  1343 sgd_solver.cpp:106] Iteration 36400, lr = 4.59529e-07
I0826 10:25:26.298162  1343 solver.cpp:228] Iteration 36500, loss = 3.53926
I0826 10:25:26.298207  1343 solver.cpp:244]     Train net output #0: loss = 3.53926 (* 1 = 3.53926 loss)
I0826 10:25:26.298213  1343 sgd_solver.cpp:106] Iteration 36500, lr = 4.58919e-07
I0826 10:25:34.706631  1343 solver.cpp:228] Iteration 36600, loss = 3.54481
I0826 10:25:34.706679  1343 solver.cpp:244]     Train net output #0: loss = 3.54481 (* 1 = 3.54481 loss)
I0826 10:25:34.706686  1343 sgd_solver.cpp:106] Iteration 36600, lr = 4.58311e-07
I0826 10:25:43.100632  1343 solver.cpp:228] Iteration 36700, loss = 3.57942
I0826 10:25:43.100675  1343 solver.cpp:244]     Train net output #0: loss = 3.57942 (* 1 = 3.57942 loss)
I0826 10:25:43.100680  1343 sgd_solver.cpp:106] Iteration 36700, lr = 4.57705e-07
I0826 10:25:51.514179  1343 solver.cpp:228] Iteration 36800, loss = 3.38485
I0826 10:25:51.514220  1343 solver.cpp:244]     Train net output #0: loss = 3.38485 (* 1 = 3.38485 loss)
I0826 10:25:51.514226  1343 sgd_solver.cpp:106] Iteration 36800, lr = 4.571e-07
I0826 10:25:59.900187  1343 solver.cpp:228] Iteration 36900, loss = 3.53627
I0826 10:25:59.900228  1343 solver.cpp:244]     Train net output #0: loss = 3.53627 (* 1 = 3.53627 loss)
I0826 10:25:59.900234  1343 sgd_solver.cpp:106] Iteration 36900, lr = 4.56497e-07
I0826 10:26:08.307963  1343 solver.cpp:228] Iteration 37000, loss = 3.45961
I0826 10:26:08.308003  1343 solver.cpp:244]     Train net output #0: loss = 3.45961 (* 1 = 3.45961 loss)
I0826 10:26:08.308008  1343 sgd_solver.cpp:106] Iteration 37000, lr = 4.55897e-07
I0826 10:26:16.728224  1343 solver.cpp:228] Iteration 37100, loss = 3.53752
I0826 10:26:16.728266  1343 solver.cpp:244]     Train net output #0: loss = 3.53752 (* 1 = 3.53752 loss)
I0826 10:26:16.728271  1343 sgd_solver.cpp:106] Iteration 37100, lr = 4.55298e-07
I0826 10:26:25.149410  1343 solver.cpp:228] Iteration 37200, loss = 3.63286
I0826 10:26:25.149477  1343 solver.cpp:244]     Train net output #0: loss = 3.63286 (* 1 = 3.63286 loss)
I0826 10:26:25.149487  1343 sgd_solver.cpp:106] Iteration 37200, lr = 4.54701e-07
I0826 10:26:33.567068  1343 solver.cpp:228] Iteration 37300, loss = 3.56907
I0826 10:26:33.567111  1343 solver.cpp:244]     Train net output #0: loss = 3.56907 (* 1 = 3.56907 loss)
I0826 10:26:33.567117  1343 sgd_solver.cpp:106] Iteration 37300, lr = 4.54105e-07
I0826 10:26:41.972198  1343 solver.cpp:228] Iteration 37400, loss = 3.41391
I0826 10:26:41.972251  1343 solver.cpp:244]     Train net output #0: loss = 3.41391 (* 1 = 3.41391 loss)
I0826 10:26:41.972259  1343 sgd_solver.cpp:106] Iteration 37400, lr = 4.53512e-07
I0826 10:26:44.159914  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:26:50.374727  1343 solver.cpp:228] Iteration 37500, loss = 3.40821
I0826 10:26:50.374779  1343 solver.cpp:244]     Train net output #0: loss = 3.40821 (* 1 = 3.40821 loss)
I0826 10:26:50.374785  1343 sgd_solver.cpp:106] Iteration 37500, lr = 4.5292e-07
I0826 10:26:58.753892  1343 solver.cpp:228] Iteration 37600, loss = 3.29775
I0826 10:26:58.753968  1343 solver.cpp:244]     Train net output #0: loss = 3.29775 (* 1 = 3.29775 loss)
I0826 10:26:58.753975  1343 sgd_solver.cpp:106] Iteration 37600, lr = 4.5233e-07
I0826 10:27:07.159802  1343 solver.cpp:228] Iteration 37700, loss = 3.65651
I0826 10:27:07.159859  1343 solver.cpp:244]     Train net output #0: loss = 3.65651 (* 1 = 3.65651 loss)
I0826 10:27:07.159865  1343 sgd_solver.cpp:106] Iteration 37700, lr = 4.51742e-07
I0826 10:27:15.571912  1343 solver.cpp:228] Iteration 37800, loss = 3.47496
I0826 10:27:15.571950  1343 solver.cpp:244]     Train net output #0: loss = 3.47496 (* 1 = 3.47496 loss)
I0826 10:27:15.571956  1343 sgd_solver.cpp:106] Iteration 37800, lr = 4.51156e-07
I0826 10:27:23.975497  1343 solver.cpp:228] Iteration 37900, loss = 3.50904
I0826 10:27:23.975555  1343 solver.cpp:244]     Train net output #0: loss = 3.50904 (* 1 = 3.50904 loss)
I0826 10:27:23.975564  1343 sgd_solver.cpp:106] Iteration 37900, lr = 4.50571e-07
I0826 10:27:32.381201  1343 solver.cpp:228] Iteration 38000, loss = 3.39603
I0826 10:27:32.381240  1343 solver.cpp:244]     Train net output #0: loss = 3.39603 (* 1 = 3.39603 loss)
I0826 10:27:32.381245  1343 sgd_solver.cpp:106] Iteration 38000, lr = 4.49989e-07
I0826 10:27:40.781649  1343 solver.cpp:228] Iteration 38100, loss = 3.35975
I0826 10:27:40.781713  1343 solver.cpp:244]     Train net output #0: loss = 3.35975 (* 1 = 3.35975 loss)
I0826 10:27:40.781725  1343 sgd_solver.cpp:106] Iteration 38100, lr = 4.49408e-07
I0826 10:27:49.195952  1343 solver.cpp:228] Iteration 38200, loss = 3.26242
I0826 10:27:49.196005  1343 solver.cpp:244]     Train net output #0: loss = 3.26242 (* 1 = 3.26242 loss)
I0826 10:27:49.196012  1343 sgd_solver.cpp:106] Iteration 38200, lr = 4.48828e-07
I0826 10:27:57.608656  1343 solver.cpp:228] Iteration 38300, loss = 3.44735
I0826 10:27:57.608700  1343 solver.cpp:244]     Train net output #0: loss = 3.44735 (* 1 = 3.44735 loss)
I0826 10:27:57.608705  1343 sgd_solver.cpp:106] Iteration 38300, lr = 4.48251e-07
I0826 10:28:06.030699  1343 solver.cpp:228] Iteration 38400, loss = 3.35239
I0826 10:28:06.030755  1343 solver.cpp:244]     Train net output #0: loss = 3.35239 (* 1 = 3.35239 loss)
I0826 10:28:06.030761  1343 sgd_solver.cpp:106] Iteration 38400, lr = 4.47675e-07
I0826 10:28:14.455920  1343 solver.cpp:228] Iteration 38500, loss = 3.40457
I0826 10:28:14.455986  1343 solver.cpp:244]     Train net output #0: loss = 3.40457 (* 1 = 3.40457 loss)
I0826 10:28:14.455996  1343 sgd_solver.cpp:106] Iteration 38500, lr = 4.47101e-07
I0826 10:28:22.874817  1343 solver.cpp:228] Iteration 38600, loss = 3.48406
I0826 10:28:22.874874  1343 solver.cpp:244]     Train net output #0: loss = 3.48406 (* 1 = 3.48406 loss)
I0826 10:28:22.874883  1343 sgd_solver.cpp:106] Iteration 38600, lr = 4.46529e-07
I0826 10:28:31.283515  1343 solver.cpp:228] Iteration 38700, loss = 3.43679
I0826 10:28:31.283581  1343 solver.cpp:244]     Train net output #0: loss = 3.43679 (* 1 = 3.43679 loss)
I0826 10:28:31.283588  1343 sgd_solver.cpp:106] Iteration 38700, lr = 4.45958e-07
I0826 10:28:39.703410  1343 solver.cpp:228] Iteration 38800, loss = 3.45603
I0826 10:28:39.703470  1343 solver.cpp:244]     Train net output #0: loss = 3.45603 (* 1 = 3.45603 loss)
I0826 10:28:39.703481  1343 sgd_solver.cpp:106] Iteration 38800, lr = 4.45389e-07
I0826 10:28:48.127234  1343 solver.cpp:228] Iteration 38900, loss = 3.37504
I0826 10:28:48.127276  1343 solver.cpp:244]     Train net output #0: loss = 3.37504 (* 1 = 3.37504 loss)
I0826 10:28:48.127282  1343 sgd_solver.cpp:106] Iteration 38900, lr = 4.44822e-07
I0826 10:28:56.532668  1343 solver.cpp:228] Iteration 39000, loss = 3.4002
I0826 10:28:56.532728  1343 solver.cpp:244]     Train net output #0: loss = 3.4002 (* 1 = 3.4002 loss)
I0826 10:28:56.532742  1343 sgd_solver.cpp:106] Iteration 39000, lr = 4.44256e-07
I0826 10:29:04.929924  1343 solver.cpp:228] Iteration 39100, loss = 3.27997
I0826 10:29:04.929971  1343 solver.cpp:244]     Train net output #0: loss = 3.27997 (* 1 = 3.27997 loss)
I0826 10:29:04.929978  1343 sgd_solver.cpp:106] Iteration 39100, lr = 4.43692e-07
I0826 10:29:13.319494  1343 solver.cpp:228] Iteration 39200, loss = 3.50341
I0826 10:29:13.319535  1343 solver.cpp:244]     Train net output #0: loss = 3.50341 (* 1 = 3.50341 loss)
I0826 10:29:13.319540  1343 sgd_solver.cpp:106] Iteration 39200, lr = 4.4313e-07
I0826 10:29:21.733350  1343 solver.cpp:228] Iteration 39300, loss = 3.5869
I0826 10:29:21.733410  1343 solver.cpp:244]     Train net output #0: loss = 3.5869 (* 1 = 3.5869 loss)
I0826 10:29:21.733420  1343 sgd_solver.cpp:106] Iteration 39300, lr = 4.4257e-07
I0826 10:29:30.120215  1343 solver.cpp:228] Iteration 39400, loss = 3.49686
I0826 10:29:30.120259  1343 solver.cpp:244]     Train net output #0: loss = 3.49686 (* 1 = 3.49686 loss)
I0826 10:29:30.120263  1343 sgd_solver.cpp:106] Iteration 39400, lr = 4.42011e-07
I0826 10:29:38.538462  1343 solver.cpp:228] Iteration 39500, loss = 3.56273
I0826 10:29:38.538530  1343 solver.cpp:244]     Train net output #0: loss = 3.56273 (* 1 = 3.56273 loss)
I0826 10:29:38.538538  1343 sgd_solver.cpp:106] Iteration 39500, lr = 4.41453e-07
I0826 10:29:46.951647  1343 solver.cpp:228] Iteration 39600, loss = 3.42204
I0826 10:29:46.951689  1343 solver.cpp:244]     Train net output #0: loss = 3.42204 (* 1 = 3.42204 loss)
I0826 10:29:46.951695  1343 sgd_solver.cpp:106] Iteration 39600, lr = 4.40898e-07
I0826 10:29:55.358342  1343 solver.cpp:228] Iteration 39700, loss = 3.34147
I0826 10:29:55.358394  1343 solver.cpp:244]     Train net output #0: loss = 3.34147 (* 1 = 3.34147 loss)
I0826 10:29:55.358402  1343 sgd_solver.cpp:106] Iteration 39700, lr = 4.40344e-07
I0826 10:30:03.766261  1343 solver.cpp:228] Iteration 39800, loss = 3.56772
I0826 10:30:03.766326  1343 solver.cpp:244]     Train net output #0: loss = 3.56772 (* 1 = 3.56772 loss)
I0826 10:30:03.766335  1343 sgd_solver.cpp:106] Iteration 39800, lr = 4.39791e-07
I0826 10:30:12.151573  1343 solver.cpp:228] Iteration 39900, loss = 3.79899
I0826 10:30:12.151634  1343 solver.cpp:244]     Train net output #0: loss = 3.79899 (* 1 = 3.79899 loss)
I0826 10:30:12.151643  1343 sgd_solver.cpp:106] Iteration 39900, lr = 4.39241e-07
I0826 10:30:20.487071  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_40000.caffemodel
I0826 10:30:21.084873  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_40000.solverstate
I0826 10:30:21.242329  1343 solver.cpp:337] Iteration 40000, Testing net (#0)
I0826 10:30:35.329550  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:30:59.815073  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302017
I0826 10:30:59.815124  1343 solver.cpp:404]     Test net output #1: loss = 3.50176 (* 1 = 3.50176 loss)
I0826 10:30:59.846966  1343 solver.cpp:228] Iteration 40000, loss = 3.49096
I0826 10:30:59.847028  1343 solver.cpp:244]     Train net output #0: loss = 3.49096 (* 1 = 3.49096 loss)
I0826 10:30:59.847045  1343 sgd_solver.cpp:106] Iteration 40000, lr = 4.38691e-07
I0826 10:31:08.234997  1343 solver.cpp:228] Iteration 40100, loss = 3.47702
I0826 10:31:08.235036  1343 solver.cpp:244]     Train net output #0: loss = 3.47702 (* 1 = 3.47702 loss)
I0826 10:31:08.235043  1343 sgd_solver.cpp:106] Iteration 40100, lr = 4.38144e-07
I0826 10:31:16.635166  1343 solver.cpp:228] Iteration 40200, loss = 3.41559
I0826 10:31:16.635210  1343 solver.cpp:244]     Train net output #0: loss = 3.41559 (* 1 = 3.41559 loss)
I0826 10:31:16.635215  1343 sgd_solver.cpp:106] Iteration 40200, lr = 4.37598e-07
I0826 10:31:25.028998  1343 solver.cpp:228] Iteration 40300, loss = 3.5741
I0826 10:31:25.029037  1343 solver.cpp:244]     Train net output #0: loss = 3.5741 (* 1 = 3.5741 loss)
I0826 10:31:25.029042  1343 sgd_solver.cpp:106] Iteration 40300, lr = 4.37053e-07
I0826 10:31:33.454210  1343 solver.cpp:228] Iteration 40400, loss = 3.67973
I0826 10:31:33.454255  1343 solver.cpp:244]     Train net output #0: loss = 3.67973 (* 1 = 3.67973 loss)
I0826 10:31:33.454260  1343 sgd_solver.cpp:106] Iteration 40400, lr = 4.36511e-07
I0826 10:31:41.870043  1343 solver.cpp:228] Iteration 40500, loss = 3.43772
I0826 10:31:41.870087  1343 solver.cpp:244]     Train net output #0: loss = 3.43772 (* 1 = 3.43772 loss)
I0826 10:31:41.870092  1343 sgd_solver.cpp:106] Iteration 40500, lr = 4.35969e-07
I0826 10:31:50.274215  1343 solver.cpp:228] Iteration 40600, loss = 3.34655
I0826 10:31:50.274266  1343 solver.cpp:244]     Train net output #0: loss = 3.34655 (* 1 = 3.34655 loss)
I0826 10:31:50.274273  1343 sgd_solver.cpp:106] Iteration 40600, lr = 4.3543e-07
I0826 10:31:58.702174  1343 solver.cpp:228] Iteration 40700, loss = 3.49061
I0826 10:31:58.702236  1343 solver.cpp:244]     Train net output #0: loss = 3.49061 (* 1 = 3.49061 loss)
I0826 10:31:58.702247  1343 sgd_solver.cpp:106] Iteration 40700, lr = 4.34892e-07
I0826 10:32:07.110256  1343 solver.cpp:228] Iteration 40800, loss = 3.35603
I0826 10:32:07.110322  1343 solver.cpp:244]     Train net output #0: loss = 3.35603 (* 1 = 3.35603 loss)
I0826 10:32:07.110330  1343 sgd_solver.cpp:106] Iteration 40800, lr = 4.34355e-07
I0826 10:32:15.519722  1343 solver.cpp:228] Iteration 40900, loss = 3.47214
I0826 10:32:15.519783  1343 solver.cpp:244]     Train net output #0: loss = 3.47214 (* 1 = 3.47214 loss)
I0826 10:32:15.519793  1343 sgd_solver.cpp:106] Iteration 40900, lr = 4.3382e-07
I0826 10:32:23.939656  1343 solver.cpp:228] Iteration 41000, loss = 3.42075
I0826 10:32:23.939767  1343 solver.cpp:244]     Train net output #0: loss = 3.42075 (* 1 = 3.42075 loss)
I0826 10:32:23.939782  1343 sgd_solver.cpp:106] Iteration 41000, lr = 4.33286e-07
I0826 10:32:32.360781  1343 solver.cpp:228] Iteration 41100, loss = 3.66143
I0826 10:32:32.360851  1343 solver.cpp:244]     Train net output #0: loss = 3.66143 (* 1 = 3.66143 loss)
I0826 10:32:32.360858  1343 sgd_solver.cpp:106] Iteration 41100, lr = 4.32754e-07
I0826 10:32:40.765220  1343 solver.cpp:228] Iteration 41200, loss = 3.44364
I0826 10:32:40.765285  1343 solver.cpp:244]     Train net output #0: loss = 3.44364 (* 1 = 3.44364 loss)
I0826 10:32:40.765292  1343 sgd_solver.cpp:106] Iteration 41200, lr = 4.32224e-07
I0826 10:32:49.194684  1343 solver.cpp:228] Iteration 41300, loss = 3.50021
I0826 10:32:49.194751  1343 solver.cpp:244]     Train net output #0: loss = 3.50021 (* 1 = 3.50021 loss)
I0826 10:32:49.194761  1343 sgd_solver.cpp:106] Iteration 41300, lr = 4.31695e-07
I0826 10:32:54.251576  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:32:57.622205  1343 solver.cpp:228] Iteration 41400, loss = 3.37684
I0826 10:32:57.622263  1343 solver.cpp:244]     Train net output #0: loss = 3.37684 (* 1 = 3.37684 loss)
I0826 10:32:57.622272  1343 sgd_solver.cpp:106] Iteration 41400, lr = 4.31168e-07
I0826 10:33:06.024032  1343 solver.cpp:228] Iteration 41500, loss = 3.47362
I0826 10:33:06.024073  1343 solver.cpp:244]     Train net output #0: loss = 3.47362 (* 1 = 3.47362 loss)
I0826 10:33:06.024080  1343 sgd_solver.cpp:106] Iteration 41500, lr = 4.30642e-07
I0826 10:33:14.436144  1343 solver.cpp:228] Iteration 41600, loss = 3.5182
I0826 10:33:14.436202  1343 solver.cpp:244]     Train net output #0: loss = 3.5182 (* 1 = 3.5182 loss)
I0826 10:33:14.436213  1343 sgd_solver.cpp:106] Iteration 41600, lr = 4.30117e-07
I0826 10:33:22.853219  1343 solver.cpp:228] Iteration 41700, loss = 3.56466
I0826 10:33:22.853260  1343 solver.cpp:244]     Train net output #0: loss = 3.56466 (* 1 = 3.56466 loss)
I0826 10:33:22.853266  1343 sgd_solver.cpp:106] Iteration 41700, lr = 4.29594e-07
I0826 10:33:31.246680  1343 solver.cpp:228] Iteration 41800, loss = 3.39112
I0826 10:33:31.246727  1343 solver.cpp:244]     Train net output #0: loss = 3.39112 (* 1 = 3.39112 loss)
I0826 10:33:31.246733  1343 sgd_solver.cpp:106] Iteration 41800, lr = 4.29073e-07
I0826 10:33:39.661212  1343 solver.cpp:228] Iteration 41900, loss = 3.48898
I0826 10:33:39.661264  1343 solver.cpp:244]     Train net output #0: loss = 3.48898 (* 1 = 3.48898 loss)
I0826 10:33:39.661273  1343 sgd_solver.cpp:106] Iteration 41900, lr = 4.28553e-07
I0826 10:33:48.086241  1343 solver.cpp:228] Iteration 42000, loss = 3.42441
I0826 10:33:48.086294  1343 solver.cpp:244]     Train net output #0: loss = 3.42441 (* 1 = 3.42441 loss)
I0826 10:33:48.086302  1343 sgd_solver.cpp:106] Iteration 42000, lr = 4.28034e-07
I0826 10:33:56.516253  1343 solver.cpp:228] Iteration 42100, loss = 3.55327
I0826 10:33:56.516314  1343 solver.cpp:244]     Train net output #0: loss = 3.55327 (* 1 = 3.55327 loss)
I0826 10:33:56.516324  1343 sgd_solver.cpp:106] Iteration 42100, lr = 4.27517e-07
I0826 10:34:04.940582  1343 solver.cpp:228] Iteration 42200, loss = 3.5901
I0826 10:34:04.940642  1343 solver.cpp:244]     Train net output #0: loss = 3.5901 (* 1 = 3.5901 loss)
I0826 10:34:04.940649  1343 sgd_solver.cpp:106] Iteration 42200, lr = 4.27002e-07
I0826 10:34:13.347473  1343 solver.cpp:228] Iteration 42300, loss = 3.7088
I0826 10:34:13.347528  1343 solver.cpp:244]     Train net output #0: loss = 3.7088 (* 1 = 3.7088 loss)
I0826 10:34:13.347537  1343 sgd_solver.cpp:106] Iteration 42300, lr = 4.26488e-07
I0826 10:34:21.769450  1343 solver.cpp:228] Iteration 42400, loss = 3.41914
I0826 10:34:21.769505  1343 solver.cpp:244]     Train net output #0: loss = 3.41914 (* 1 = 3.41914 loss)
I0826 10:34:21.769515  1343 sgd_solver.cpp:106] Iteration 42400, lr = 4.25975e-07
I0826 10:34:30.185173  1343 solver.cpp:228] Iteration 42500, loss = 3.4812
I0826 10:34:30.185217  1343 solver.cpp:244]     Train net output #0: loss = 3.4812 (* 1 = 3.4812 loss)
I0826 10:34:30.185223  1343 sgd_solver.cpp:106] Iteration 42500, lr = 4.25464e-07
I0826 10:34:38.605128  1343 solver.cpp:228] Iteration 42600, loss = 3.36017
I0826 10:34:38.605172  1343 solver.cpp:244]     Train net output #0: loss = 3.36017 (* 1 = 3.36017 loss)
I0826 10:34:38.605178  1343 sgd_solver.cpp:106] Iteration 42600, lr = 4.24954e-07
I0826 10:34:47.003159  1343 solver.cpp:228] Iteration 42700, loss = 3.51671
I0826 10:34:47.003222  1343 solver.cpp:244]     Train net output #0: loss = 3.51671 (* 1 = 3.51671 loss)
I0826 10:34:47.003231  1343 sgd_solver.cpp:106] Iteration 42700, lr = 4.24445e-07
I0826 10:34:55.415508  1343 solver.cpp:228] Iteration 42800, loss = 3.47905
I0826 10:34:55.415568  1343 solver.cpp:244]     Train net output #0: loss = 3.47905 (* 1 = 3.47905 loss)
I0826 10:34:55.415578  1343 sgd_solver.cpp:106] Iteration 42800, lr = 4.23938e-07
I0826 10:35:03.832480  1343 solver.cpp:228] Iteration 42900, loss = 3.38048
I0826 10:35:03.832532  1343 solver.cpp:244]     Train net output #0: loss = 3.38048 (* 1 = 3.38048 loss)
I0826 10:35:03.832542  1343 sgd_solver.cpp:106] Iteration 42900, lr = 4.23433e-07
I0826 10:35:12.229156  1343 solver.cpp:228] Iteration 43000, loss = 3.30619
I0826 10:35:12.229221  1343 solver.cpp:244]     Train net output #0: loss = 3.30619 (* 1 = 3.30619 loss)
I0826 10:35:12.229240  1343 sgd_solver.cpp:106] Iteration 43000, lr = 4.22929e-07
I0826 10:35:20.649365  1343 solver.cpp:228] Iteration 43100, loss = 3.39175
I0826 10:35:20.649427  1343 solver.cpp:244]     Train net output #0: loss = 3.39175 (* 1 = 3.39175 loss)
I0826 10:35:20.649436  1343 sgd_solver.cpp:106] Iteration 43100, lr = 4.22426e-07
I0826 10:35:29.062882  1343 solver.cpp:228] Iteration 43200, loss = 3.26478
I0826 10:35:29.062921  1343 solver.cpp:244]     Train net output #0: loss = 3.26478 (* 1 = 3.26478 loss)
I0826 10:35:29.062927  1343 sgd_solver.cpp:106] Iteration 43200, lr = 4.21924e-07
I0826 10:35:37.459668  1343 solver.cpp:228] Iteration 43300, loss = 3.50815
I0826 10:35:37.459710  1343 solver.cpp:244]     Train net output #0: loss = 3.50815 (* 1 = 3.50815 loss)
I0826 10:35:37.459715  1343 sgd_solver.cpp:106] Iteration 43300, lr = 4.21424e-07
I0826 10:35:45.885563  1343 solver.cpp:228] Iteration 43400, loss = 3.48153
I0826 10:35:45.885624  1343 solver.cpp:244]     Train net output #0: loss = 3.48153 (* 1 = 3.48153 loss)
I0826 10:35:45.885632  1343 sgd_solver.cpp:106] Iteration 43400, lr = 4.20926e-07
I0826 10:35:54.320680  1343 solver.cpp:228] Iteration 43500, loss = 3.45609
I0826 10:35:54.320734  1343 solver.cpp:244]     Train net output #0: loss = 3.45609 (* 1 = 3.45609 loss)
I0826 10:35:54.320741  1343 sgd_solver.cpp:106] Iteration 43500, lr = 4.20429e-07
I0826 10:36:02.742524  1343 solver.cpp:228] Iteration 43600, loss = 3.55004
I0826 10:36:02.742569  1343 solver.cpp:244]     Train net output #0: loss = 3.55004 (* 1 = 3.55004 loss)
I0826 10:36:02.742574  1343 sgd_solver.cpp:106] Iteration 43600, lr = 4.19933e-07
I0826 10:36:11.144095  1343 solver.cpp:228] Iteration 43700, loss = 3.62026
I0826 10:36:11.144158  1343 solver.cpp:244]     Train net output #0: loss = 3.62026 (* 1 = 3.62026 loss)
I0826 10:36:11.144168  1343 sgd_solver.cpp:106] Iteration 43700, lr = 4.19438e-07
I0826 10:36:19.562825  1343 solver.cpp:228] Iteration 43800, loss = 3.39986
I0826 10:36:19.562880  1343 solver.cpp:244]     Train net output #0: loss = 3.39986 (* 1 = 3.39986 loss)
I0826 10:36:19.562886  1343 sgd_solver.cpp:106] Iteration 43800, lr = 4.18945e-07
I0826 10:36:27.993294  1343 solver.cpp:228] Iteration 43900, loss = 3.56659
I0826 10:36:27.993333  1343 solver.cpp:244]     Train net output #0: loss = 3.56659 (* 1 = 3.56659 loss)
I0826 10:36:27.993340  1343 sgd_solver.cpp:106] Iteration 43900, lr = 4.18453e-07
I0826 10:36:36.436044  1343 solver.cpp:228] Iteration 44000, loss = 3.36833
I0826 10:36:36.436125  1343 solver.cpp:244]     Train net output #0: loss = 3.36833 (* 1 = 3.36833 loss)
I0826 10:36:36.436136  1343 sgd_solver.cpp:106] Iteration 44000, lr = 4.17963e-07
I0826 10:36:44.855304  1343 solver.cpp:228] Iteration 44100, loss = 3.40835
I0826 10:36:44.855366  1343 solver.cpp:244]     Train net output #0: loss = 3.40835 (* 1 = 3.40835 loss)
I0826 10:36:44.855373  1343 sgd_solver.cpp:106] Iteration 44100, lr = 4.17474e-07
I0826 10:36:53.275835  1343 solver.cpp:228] Iteration 44200, loss = 3.4766
I0826 10:36:53.275902  1343 solver.cpp:244]     Train net output #0: loss = 3.4766 (* 1 = 3.4766 loss)
I0826 10:36:53.275913  1343 sgd_solver.cpp:106] Iteration 44200, lr = 4.16986e-07
I0826 10:37:01.693464  1343 solver.cpp:228] Iteration 44300, loss = 3.48215
I0826 10:37:01.693526  1343 solver.cpp:244]     Train net output #0: loss = 3.48215 (* 1 = 3.48215 loss)
I0826 10:37:01.693534  1343 sgd_solver.cpp:106] Iteration 44300, lr = 4.16499e-07
I0826 10:37:10.115614  1343 solver.cpp:228] Iteration 44400, loss = 3.54615
I0826 10:37:10.115689  1343 solver.cpp:244]     Train net output #0: loss = 3.54615 (* 1 = 3.54615 loss)
I0826 10:37:10.115700  1343 sgd_solver.cpp:106] Iteration 44400, lr = 4.16014e-07
I0826 10:37:18.529666  1343 solver.cpp:228] Iteration 44500, loss = 3.51629
I0826 10:37:18.529727  1343 solver.cpp:244]     Train net output #0: loss = 3.51629 (* 1 = 3.51629 loss)
I0826 10:37:18.529734  1343 sgd_solver.cpp:106] Iteration 44500, lr = 4.1553e-07
I0826 10:37:26.933957  1343 solver.cpp:228] Iteration 44600, loss = 3.57327
I0826 10:37:26.934020  1343 solver.cpp:244]     Train net output #0: loss = 3.57327 (* 1 = 3.57327 loss)
I0826 10:37:26.934029  1343 sgd_solver.cpp:106] Iteration 44600, lr = 4.15048e-07
I0826 10:37:35.376049  1343 solver.cpp:228] Iteration 44700, loss = 3.27821
I0826 10:37:35.376098  1343 solver.cpp:244]     Train net output #0: loss = 3.27821 (* 1 = 3.27821 loss)
I0826 10:37:35.376106  1343 sgd_solver.cpp:106] Iteration 44700, lr = 4.14567e-07
I0826 10:37:43.792866  1343 solver.cpp:228] Iteration 44800, loss = 3.56749
I0826 10:37:43.792917  1343 solver.cpp:244]     Train net output #0: loss = 3.56749 (* 1 = 3.56749 loss)
I0826 10:37:43.792925  1343 sgd_solver.cpp:106] Iteration 44800, lr = 4.14087e-07
I0826 10:37:52.211601  1343 solver.cpp:228] Iteration 44900, loss = 3.58185
I0826 10:37:52.211654  1343 solver.cpp:244]     Train net output #0: loss = 3.58185 (* 1 = 3.58185 loss)
I0826 10:37:52.211663  1343 sgd_solver.cpp:106] Iteration 44900, lr = 4.13608e-07
I0826 10:38:00.542791  1343 solver.cpp:337] Iteration 45000, Testing net (#0)
I0826 10:38:01.078738  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:38:37.883285  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:38:39.294436  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302024
I0826 10:38:39.294486  1343 solver.cpp:404]     Test net output #1: loss = 3.49338 (* 1 = 3.49338 loss)
I0826 10:38:39.324089  1343 solver.cpp:228] Iteration 45000, loss = 3.43103
I0826 10:38:39.324146  1343 solver.cpp:244]     Train net output #0: loss = 3.43103 (* 1 = 3.43103 loss)
I0826 10:38:39.324170  1343 sgd_solver.cpp:106] Iteration 45000, lr = 4.13131e-07
I0826 10:38:47.765482  1343 solver.cpp:228] Iteration 45100, loss = 3.36219
I0826 10:38:47.765553  1343 solver.cpp:244]     Train net output #0: loss = 3.36219 (* 1 = 3.36219 loss)
I0826 10:38:47.765568  1343 sgd_solver.cpp:106] Iteration 45100, lr = 4.12655e-07
I0826 10:38:56.175582  1343 solver.cpp:228] Iteration 45200, loss = 3.48037
I0826 10:38:56.175643  1343 solver.cpp:244]     Train net output #0: loss = 3.48037 (* 1 = 3.48037 loss)
I0826 10:38:56.175649  1343 sgd_solver.cpp:106] Iteration 45200, lr = 4.1218e-07
I0826 10:39:04.575742  1343 solver.cpp:228] Iteration 45300, loss = 3.36812
I0826 10:39:04.575803  1343 solver.cpp:244]     Train net output #0: loss = 3.36812 (* 1 = 3.36812 loss)
I0826 10:39:04.575814  1343 sgd_solver.cpp:106] Iteration 45300, lr = 4.11706e-07
I0826 10:39:12.998160  1343 solver.cpp:228] Iteration 45400, loss = 3.44794
I0826 10:39:12.998216  1343 solver.cpp:244]     Train net output #0: loss = 3.44794 (* 1 = 3.44794 loss)
I0826 10:39:12.998225  1343 sgd_solver.cpp:106] Iteration 45400, lr = 4.11234e-07
I0826 10:39:21.422639  1343 solver.cpp:228] Iteration 45500, loss = 3.27921
I0826 10:39:21.422698  1343 solver.cpp:244]     Train net output #0: loss = 3.27921 (* 1 = 3.27921 loss)
I0826 10:39:21.422724  1343 sgd_solver.cpp:106] Iteration 45500, lr = 4.10763e-07
I0826 10:39:29.823935  1343 solver.cpp:228] Iteration 45600, loss = 3.45767
I0826 10:39:29.823997  1343 solver.cpp:244]     Train net output #0: loss = 3.45767 (* 1 = 3.45767 loss)
I0826 10:39:29.824007  1343 sgd_solver.cpp:106] Iteration 45600, lr = 4.10293e-07
I0826 10:39:38.236892  1343 solver.cpp:228] Iteration 45700, loss = 3.43513
I0826 10:39:38.236960  1343 solver.cpp:244]     Train net output #0: loss = 3.43513 (* 1 = 3.43513 loss)
I0826 10:39:38.236970  1343 sgd_solver.cpp:106] Iteration 45700, lr = 4.09825e-07
I0826 10:39:46.660204  1343 solver.cpp:228] Iteration 45800, loss = 3.61167
I0826 10:39:46.660272  1343 solver.cpp:244]     Train net output #0: loss = 3.61167 (* 1 = 3.61167 loss)
I0826 10:39:46.660284  1343 sgd_solver.cpp:106] Iteration 45800, lr = 4.09358e-07
I0826 10:39:55.064895  1343 solver.cpp:228] Iteration 45900, loss = 3.49652
I0826 10:39:55.064960  1343 solver.cpp:244]     Train net output #0: loss = 3.49652 (* 1 = 3.49652 loss)
I0826 10:39:55.064967  1343 sgd_solver.cpp:106] Iteration 45900, lr = 4.08892e-07
I0826 10:40:03.483332  1343 solver.cpp:228] Iteration 46000, loss = 3.51095
I0826 10:40:03.483381  1343 solver.cpp:244]     Train net output #0: loss = 3.51095 (* 1 = 3.51095 loss)
I0826 10:40:03.483386  1343 sgd_solver.cpp:106] Iteration 46000, lr = 4.08427e-07
I0826 10:40:11.908982  1343 solver.cpp:228] Iteration 46100, loss = 3.46073
I0826 10:40:11.909026  1343 solver.cpp:244]     Train net output #0: loss = 3.46073 (* 1 = 3.46073 loss)
I0826 10:40:11.909031  1343 sgd_solver.cpp:106] Iteration 46100, lr = 4.07964e-07
I0826 10:40:20.321828  1343 solver.cpp:228] Iteration 46200, loss = 3.49961
I0826 10:40:20.321877  1343 solver.cpp:244]     Train net output #0: loss = 3.49961 (* 1 = 3.49961 loss)
I0826 10:40:20.321884  1343 sgd_solver.cpp:106] Iteration 46200, lr = 4.07501e-07
I0826 10:40:28.724858  1343 solver.cpp:228] Iteration 46300, loss = 3.49943
I0826 10:40:28.724930  1343 solver.cpp:244]     Train net output #0: loss = 3.49943 (* 1 = 3.49943 loss)
I0826 10:40:28.724941  1343 sgd_solver.cpp:106] Iteration 46300, lr = 4.0704e-07
I0826 10:40:37.146301  1343 solver.cpp:228] Iteration 46400, loss = 3.51428
I0826 10:40:37.146355  1343 solver.cpp:244]     Train net output #0: loss = 3.51428 (* 1 = 3.51428 loss)
I0826 10:40:37.146363  1343 sgd_solver.cpp:106] Iteration 46400, lr = 4.0658e-07
I0826 10:40:45.543787  1343 solver.cpp:228] Iteration 46500, loss = 3.48571
I0826 10:40:45.543843  1343 solver.cpp:244]     Train net output #0: loss = 3.48571 (* 1 = 3.48571 loss)
I0826 10:40:45.543850  1343 sgd_solver.cpp:106] Iteration 46500, lr = 4.06122e-07
I0826 10:40:53.970044  1343 solver.cpp:228] Iteration 46600, loss = 3.47482
I0826 10:40:53.970125  1343 solver.cpp:244]     Train net output #0: loss = 3.47482 (* 1 = 3.47482 loss)
I0826 10:40:53.970140  1343 sgd_solver.cpp:106] Iteration 46600, lr = 4.05664e-07
I0826 10:41:02.392038  1343 solver.cpp:228] Iteration 46700, loss = 3.47626
I0826 10:41:02.392107  1343 solver.cpp:244]     Train net output #0: loss = 3.47626 (* 1 = 3.47626 loss)
I0826 10:41:02.392117  1343 sgd_solver.cpp:106] Iteration 46700, lr = 4.05208e-07
I0826 10:41:10.790719  1343 solver.cpp:228] Iteration 46800, loss = 3.4316
I0826 10:41:10.790786  1343 solver.cpp:244]     Train net output #0: loss = 3.4316 (* 1 = 3.4316 loss)
I0826 10:41:10.790797  1343 sgd_solver.cpp:106] Iteration 46800, lr = 4.04753e-07
I0826 10:41:19.204905  1343 solver.cpp:228] Iteration 46900, loss = 3.48454
I0826 10:41:19.204968  1343 solver.cpp:244]     Train net output #0: loss = 3.48454 (* 1 = 3.48454 loss)
I0826 10:41:19.204980  1343 sgd_solver.cpp:106] Iteration 46900, lr = 4.04299e-07
I0826 10:41:27.631072  1343 solver.cpp:228] Iteration 47000, loss = 3.41212
I0826 10:41:27.631135  1343 solver.cpp:244]     Train net output #0: loss = 3.41212 (* 1 = 3.41212 loss)
I0826 10:41:27.631141  1343 sgd_solver.cpp:106] Iteration 47000, lr = 4.03847e-07
I0826 10:41:36.024088  1343 solver.cpp:228] Iteration 47100, loss = 3.46177
I0826 10:41:36.024147  1343 solver.cpp:244]     Train net output #0: loss = 3.46177 (* 1 = 3.46177 loss)
I0826 10:41:36.024154  1343 sgd_solver.cpp:106] Iteration 47100, lr = 4.03395e-07
I0826 10:41:44.438762  1343 solver.cpp:228] Iteration 47200, loss = 3.59428
I0826 10:41:44.438810  1343 solver.cpp:244]     Train net output #0: loss = 3.59428 (* 1 = 3.59428 loss)
I0826 10:41:44.438817  1343 sgd_solver.cpp:106] Iteration 47200, lr = 4.02945e-07
I0826 10:41:52.834956  1343 solver.cpp:228] Iteration 47300, loss = 3.41654
I0826 10:41:52.835011  1343 solver.cpp:244]     Train net output #0: loss = 3.41654 (* 1 = 3.41654 loss)
I0826 10:41:52.835022  1343 sgd_solver.cpp:106] Iteration 47300, lr = 4.02496e-07
I0826 10:42:01.251890  1343 solver.cpp:228] Iteration 47400, loss = 3.55739
I0826 10:42:01.251958  1343 solver.cpp:244]     Train net output #0: loss = 3.55739 (* 1 = 3.55739 loss)
I0826 10:42:01.251969  1343 sgd_solver.cpp:106] Iteration 47400, lr = 4.02048e-07
I0826 10:42:09.675302  1343 solver.cpp:228] Iteration 47500, loss = 3.49061
I0826 10:42:09.675348  1343 solver.cpp:244]     Train net output #0: loss = 3.49061 (* 1 = 3.49061 loss)
I0826 10:42:09.675354  1343 sgd_solver.cpp:106] Iteration 47500, lr = 4.01601e-07
I0826 10:42:18.099207  1343 solver.cpp:228] Iteration 47600, loss = 3.59467
I0826 10:42:18.099268  1343 solver.cpp:244]     Train net output #0: loss = 3.59467 (* 1 = 3.59467 loss)
I0826 10:42:18.099277  1343 sgd_solver.cpp:106] Iteration 47600, lr = 4.01155e-07
I0826 10:42:26.501423  1343 solver.cpp:228] Iteration 47700, loss = 3.34006
I0826 10:42:26.501479  1343 solver.cpp:244]     Train net output #0: loss = 3.34006 (* 1 = 3.34006 loss)
I0826 10:42:26.501487  1343 sgd_solver.cpp:106] Iteration 47700, lr = 4.00711e-07
I0826 10:42:34.924625  1343 solver.cpp:228] Iteration 47800, loss = 3.48199
I0826 10:42:34.924682  1343 solver.cpp:244]     Train net output #0: loss = 3.48199 (* 1 = 3.48199 loss)
I0826 10:42:34.924690  1343 sgd_solver.cpp:106] Iteration 47800, lr = 4.00267e-07
I0826 10:42:43.349627  1343 solver.cpp:228] Iteration 47900, loss = 3.52421
I0826 10:42:43.349697  1343 solver.cpp:244]     Train net output #0: loss = 3.52421 (* 1 = 3.52421 loss)
I0826 10:42:43.349707  1343 sgd_solver.cpp:106] Iteration 47900, lr = 3.99825e-07
I0826 10:42:51.745499  1343 solver.cpp:228] Iteration 48000, loss = 3.45832
I0826 10:42:51.745556  1343 solver.cpp:244]     Train net output #0: loss = 3.45832 (* 1 = 3.45832 loss)
I0826 10:42:51.745564  1343 sgd_solver.cpp:106] Iteration 48000, lr = 3.99384e-07
I0826 10:43:00.164536  1343 solver.cpp:228] Iteration 48100, loss = 3.40523
I0826 10:43:00.164610  1343 solver.cpp:244]     Train net output #0: loss = 3.40523 (* 1 = 3.40523 loss)
I0826 10:43:00.164620  1343 sgd_solver.cpp:106] Iteration 48100, lr = 3.98944e-07
I0826 10:43:08.577440  1343 solver.cpp:228] Iteration 48200, loss = 3.53096
I0826 10:43:08.577510  1343 solver.cpp:244]     Train net output #0: loss = 3.53096 (* 1 = 3.53096 loss)
I0826 10:43:08.577524  1343 sgd_solver.cpp:106] Iteration 48200, lr = 3.98505e-07
I0826 10:43:16.974956  1343 solver.cpp:228] Iteration 48300, loss = 3.49143
I0826 10:43:16.975003  1343 solver.cpp:244]     Train net output #0: loss = 3.49143 (* 1 = 3.49143 loss)
I0826 10:43:16.975008  1343 sgd_solver.cpp:106] Iteration 48300, lr = 3.98068e-07
I0826 10:43:22.118011  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:43:25.398135  1343 solver.cpp:228] Iteration 48400, loss = 3.46421
I0826 10:43:25.398192  1343 solver.cpp:244]     Train net output #0: loss = 3.46421 (* 1 = 3.46421 loss)
I0826 10:43:25.398200  1343 sgd_solver.cpp:106] Iteration 48400, lr = 3.97631e-07
I0826 10:43:33.815501  1343 solver.cpp:228] Iteration 48500, loss = 3.50957
I0826 10:43:33.815565  1343 solver.cpp:244]     Train net output #0: loss = 3.50957 (* 1 = 3.50957 loss)
I0826 10:43:33.815577  1343 sgd_solver.cpp:106] Iteration 48500, lr = 3.97196e-07
I0826 10:43:42.220356  1343 solver.cpp:228] Iteration 48600, loss = 3.35825
I0826 10:43:42.220415  1343 solver.cpp:244]     Train net output #0: loss = 3.35825 (* 1 = 3.35825 loss)
I0826 10:43:42.220427  1343 sgd_solver.cpp:106] Iteration 48600, lr = 3.96761e-07
I0826 10:43:50.645138  1343 solver.cpp:228] Iteration 48700, loss = 3.4598
I0826 10:43:50.645205  1343 solver.cpp:244]     Train net output #0: loss = 3.4598 (* 1 = 3.4598 loss)
I0826 10:43:50.645213  1343 sgd_solver.cpp:106] Iteration 48700, lr = 3.96328e-07
I0826 10:43:59.065707  1343 solver.cpp:228] Iteration 48800, loss = 3.42592
I0826 10:43:59.065774  1343 solver.cpp:244]     Train net output #0: loss = 3.42592 (* 1 = 3.42592 loss)
I0826 10:43:59.065785  1343 sgd_solver.cpp:106] Iteration 48800, lr = 3.95896e-07
I0826 10:44:07.464223  1343 solver.cpp:228] Iteration 48900, loss = 3.52592
I0826 10:44:07.464282  1343 solver.cpp:244]     Train net output #0: loss = 3.52592 (* 1 = 3.52592 loss)
I0826 10:44:07.464293  1343 sgd_solver.cpp:106] Iteration 48900, lr = 3.95465e-07
I0826 10:44:15.892773  1343 solver.cpp:228] Iteration 49000, loss = 3.42617
I0826 10:44:15.892848  1343 solver.cpp:244]     Train net output #0: loss = 3.42617 (* 1 = 3.42617 loss)
I0826 10:44:15.892859  1343 sgd_solver.cpp:106] Iteration 49000, lr = 3.95035e-07
I0826 10:44:24.318246  1343 solver.cpp:228] Iteration 49100, loss = 3.48585
I0826 10:44:24.318297  1343 solver.cpp:244]     Train net output #0: loss = 3.48585 (* 1 = 3.48585 loss)
I0826 10:44:24.318306  1343 sgd_solver.cpp:106] Iteration 49100, lr = 3.94606e-07
I0826 10:44:32.741322  1343 solver.cpp:228] Iteration 49200, loss = 3.54457
I0826 10:44:32.741381  1343 solver.cpp:244]     Train net output #0: loss = 3.54457 (* 1 = 3.54457 loss)
I0826 10:44:32.741392  1343 sgd_solver.cpp:106] Iteration 49200, lr = 3.94178e-07
I0826 10:44:41.137619  1343 solver.cpp:228] Iteration 49300, loss = 3.49886
I0826 10:44:41.137689  1343 solver.cpp:244]     Train net output #0: loss = 3.49886 (* 1 = 3.49886 loss)
I0826 10:44:41.137699  1343 sgd_solver.cpp:106] Iteration 49300, lr = 3.93752e-07
I0826 10:44:49.566417  1343 solver.cpp:228] Iteration 49400, loss = 3.47313
I0826 10:44:49.566488  1343 solver.cpp:244]     Train net output #0: loss = 3.47313 (* 1 = 3.47313 loss)
I0826 10:44:49.566498  1343 sgd_solver.cpp:106] Iteration 49400, lr = 3.93326e-07
I0826 10:44:58.010179  1343 solver.cpp:228] Iteration 49500, loss = 3.3716
I0826 10:44:58.010221  1343 solver.cpp:244]     Train net output #0: loss = 3.3716 (* 1 = 3.3716 loss)
I0826 10:44:58.010227  1343 sgd_solver.cpp:106] Iteration 49500, lr = 3.92902e-07
I0826 10:45:06.429934  1343 solver.cpp:228] Iteration 49600, loss = 3.38114
I0826 10:45:06.430007  1343 solver.cpp:244]     Train net output #0: loss = 3.38114 (* 1 = 3.38114 loss)
I0826 10:45:06.430021  1343 sgd_solver.cpp:106] Iteration 49600, lr = 3.92478e-07
I0826 10:45:14.847383  1343 solver.cpp:228] Iteration 49700, loss = 3.5179
I0826 10:45:14.847452  1343 solver.cpp:244]     Train net output #0: loss = 3.5179 (* 1 = 3.5179 loss)
I0826 10:45:14.847462  1343 sgd_solver.cpp:106] Iteration 49700, lr = 3.92056e-07
I0826 10:45:23.259896  1343 solver.cpp:228] Iteration 49800, loss = 3.68773
I0826 10:45:23.259953  1343 solver.cpp:244]     Train net output #0: loss = 3.68773 (* 1 = 3.68773 loss)
I0826 10:45:23.259960  1343 sgd_solver.cpp:106] Iteration 49800, lr = 3.91634e-07
I0826 10:45:31.689900  1343 solver.cpp:228] Iteration 49900, loss = 3.42399
I0826 10:45:31.689970  1343 solver.cpp:244]     Train net output #0: loss = 3.42399 (* 1 = 3.42399 loss)
I0826 10:45:31.689986  1343 sgd_solver.cpp:106] Iteration 49900, lr = 3.91214e-07
I0826 10:45:40.028934  1343 solver.cpp:337] Iteration 50000, Testing net (#0)
I0826 10:46:07.750339  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:46:17.812734  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 10:46:17.812788  1343 solver.cpp:404]     Test net output #1: loss = 3.48581 (* 1 = 3.48581 loss)
I0826 10:46:17.843358  1343 solver.cpp:228] Iteration 50000, loss = 3.64338
I0826 10:46:17.843381  1343 solver.cpp:244]     Train net output #0: loss = 3.64338 (* 1 = 3.64338 loss)
I0826 10:46:17.843394  1343 sgd_solver.cpp:106] Iteration 50000, lr = 3.90795e-07
I0826 10:46:26.260820  1343 solver.cpp:228] Iteration 50100, loss = 3.56257
I0826 10:46:26.260869  1343 solver.cpp:244]     Train net output #0: loss = 3.56257 (* 1 = 3.56257 loss)
I0826 10:46:26.260874  1343 sgd_solver.cpp:106] Iteration 50100, lr = 3.90377e-07
I0826 10:46:34.662691  1343 solver.cpp:228] Iteration 50200, loss = 3.34454
I0826 10:46:34.662765  1343 solver.cpp:244]     Train net output #0: loss = 3.34454 (* 1 = 3.34454 loss)
I0826 10:46:34.662777  1343 sgd_solver.cpp:106] Iteration 50200, lr = 3.8996e-07
I0826 10:46:43.089489  1343 solver.cpp:228] Iteration 50300, loss = 3.53471
I0826 10:46:43.089545  1343 solver.cpp:244]     Train net output #0: loss = 3.53471 (* 1 = 3.53471 loss)
I0826 10:46:43.089552  1343 sgd_solver.cpp:106] Iteration 50300, lr = 3.89544e-07
I0826 10:46:51.507300  1343 solver.cpp:228] Iteration 50400, loss = 3.44169
I0826 10:46:51.507349  1343 solver.cpp:244]     Train net output #0: loss = 3.44169 (* 1 = 3.44169 loss)
I0826 10:46:51.507354  1343 sgd_solver.cpp:106] Iteration 50400, lr = 3.89128e-07
I0826 10:46:59.920382  1343 solver.cpp:228] Iteration 50500, loss = 3.41117
I0826 10:46:59.920439  1343 solver.cpp:244]     Train net output #0: loss = 3.41117 (* 1 = 3.41117 loss)
I0826 10:46:59.920446  1343 sgd_solver.cpp:106] Iteration 50500, lr = 3.88714e-07
I0826 10:47:08.325234  1343 solver.cpp:228] Iteration 50600, loss = 3.67068
I0826 10:47:08.325321  1343 solver.cpp:244]     Train net output #0: loss = 3.67068 (* 1 = 3.67068 loss)
I0826 10:47:08.325337  1343 sgd_solver.cpp:106] Iteration 50600, lr = 3.88301e-07
I0826 10:47:16.750730  1343 solver.cpp:228] Iteration 50700, loss = 3.34015
I0826 10:47:16.750790  1343 solver.cpp:244]     Train net output #0: loss = 3.34015 (* 1 = 3.34015 loss)
I0826 10:47:16.750802  1343 sgd_solver.cpp:106] Iteration 50700, lr = 3.87889e-07
I0826 10:47:25.163774  1343 solver.cpp:228] Iteration 50800, loss = 3.47751
I0826 10:47:25.163817  1343 solver.cpp:244]     Train net output #0: loss = 3.47751 (* 1 = 3.47751 loss)
I0826 10:47:25.163823  1343 sgd_solver.cpp:106] Iteration 50800, lr = 3.87478e-07
I0826 10:47:33.556413  1343 solver.cpp:228] Iteration 50900, loss = 3.26669
I0826 10:47:33.556455  1343 solver.cpp:244]     Train net output #0: loss = 3.26669 (* 1 = 3.26669 loss)
I0826 10:47:33.556460  1343 sgd_solver.cpp:106] Iteration 50900, lr = 3.87068e-07
I0826 10:47:41.978744  1343 solver.cpp:228] Iteration 51000, loss = 3.55561
I0826 10:47:41.978796  1343 solver.cpp:244]     Train net output #0: loss = 3.55561 (* 1 = 3.55561 loss)
I0826 10:47:41.978803  1343 sgd_solver.cpp:106] Iteration 51000, lr = 3.8666e-07
I0826 10:47:50.368268  1343 solver.cpp:228] Iteration 51100, loss = 3.44473
I0826 10:47:50.368347  1343 solver.cpp:244]     Train net output #0: loss = 3.44473 (* 1 = 3.44473 loss)
I0826 10:47:50.368355  1343 sgd_solver.cpp:106] Iteration 51100, lr = 3.86252e-07
I0826 10:47:58.779001  1343 solver.cpp:228] Iteration 51200, loss = 3.56374
I0826 10:47:58.779069  1343 solver.cpp:244]     Train net output #0: loss = 3.56374 (* 1 = 3.56374 loss)
I0826 10:47:58.779081  1343 sgd_solver.cpp:106] Iteration 51200, lr = 3.85845e-07
I0826 10:48:07.186381  1343 solver.cpp:228] Iteration 51300, loss = 3.47517
I0826 10:48:07.186451  1343 solver.cpp:244]     Train net output #0: loss = 3.47517 (* 1 = 3.47517 loss)
I0826 10:48:07.186462  1343 sgd_solver.cpp:106] Iteration 51300, lr = 3.85439e-07
I0826 10:48:15.598558  1343 solver.cpp:228] Iteration 51400, loss = 3.3599
I0826 10:48:15.598618  1343 solver.cpp:244]     Train net output #0: loss = 3.3599 (* 1 = 3.3599 loss)
I0826 10:48:15.598624  1343 sgd_solver.cpp:106] Iteration 51400, lr = 3.85034e-07
I0826 10:48:23.996110  1343 solver.cpp:228] Iteration 51500, loss = 3.56853
I0826 10:48:23.996167  1343 solver.cpp:244]     Train net output #0: loss = 3.56853 (* 1 = 3.56853 loss)
I0826 10:48:23.996178  1343 sgd_solver.cpp:106] Iteration 51500, lr = 3.8463e-07
I0826 10:48:32.422780  1343 solver.cpp:228] Iteration 51600, loss = 3.58242
I0826 10:48:32.422849  1343 solver.cpp:244]     Train net output #0: loss = 3.58242 (* 1 = 3.58242 loss)
I0826 10:48:32.422860  1343 sgd_solver.cpp:106] Iteration 51600, lr = 3.84227e-07
I0826 10:48:40.840929  1343 solver.cpp:228] Iteration 51700, loss = 3.55243
I0826 10:48:40.840987  1343 solver.cpp:244]     Train net output #0: loss = 3.55243 (* 1 = 3.55243 loss)
I0826 10:48:40.841003  1343 sgd_solver.cpp:106] Iteration 51700, lr = 3.83825e-07
I0826 10:48:49.254554  1343 solver.cpp:228] Iteration 51800, loss = 3.70884
I0826 10:48:49.254628  1343 solver.cpp:244]     Train net output #0: loss = 3.70884 (* 1 = 3.70884 loss)
I0826 10:48:49.254639  1343 sgd_solver.cpp:106] Iteration 51800, lr = 3.83424e-07
I0826 10:48:57.655094  1343 solver.cpp:228] Iteration 51900, loss = 3.39917
I0826 10:48:57.655156  1343 solver.cpp:244]     Train net output #0: loss = 3.39917 (* 1 = 3.39917 loss)
I0826 10:48:57.655166  1343 sgd_solver.cpp:106] Iteration 51900, lr = 3.83024e-07
I0826 10:49:06.073825  1343 solver.cpp:228] Iteration 52000, loss = 3.56222
I0826 10:49:06.073889  1343 solver.cpp:244]     Train net output #0: loss = 3.56222 (* 1 = 3.56222 loss)
I0826 10:49:06.073899  1343 sgd_solver.cpp:106] Iteration 52000, lr = 3.82625e-07
I0826 10:49:14.485322  1343 solver.cpp:228] Iteration 52100, loss = 3.53408
I0826 10:49:14.485380  1343 solver.cpp:244]     Train net output #0: loss = 3.53408 (* 1 = 3.53408 loss)
I0826 10:49:14.485386  1343 sgd_solver.cpp:106] Iteration 52100, lr = 3.82227e-07
I0826 10:49:22.889457  1343 solver.cpp:228] Iteration 52200, loss = 3.42138
I0826 10:49:22.889516  1343 solver.cpp:244]     Train net output #0: loss = 3.42138 (* 1 = 3.42138 loss)
I0826 10:49:22.889528  1343 sgd_solver.cpp:106] Iteration 52200, lr = 3.8183e-07
I0826 10:49:31.314642  1343 solver.cpp:228] Iteration 52300, loss = 3.51086
I0826 10:49:31.314709  1343 solver.cpp:244]     Train net output #0: loss = 3.51086 (* 1 = 3.51086 loss)
I0826 10:49:31.314724  1343 sgd_solver.cpp:106] Iteration 52300, lr = 3.81433e-07
I0826 10:49:39.703492  1343 solver.cpp:228] Iteration 52400, loss = 3.48704
I0826 10:49:39.703560  1343 solver.cpp:244]     Train net output #0: loss = 3.48704 (* 1 = 3.48704 loss)
I0826 10:49:39.703569  1343 sgd_solver.cpp:106] Iteration 52400, lr = 3.81038e-07
I0826 10:49:48.117364  1343 solver.cpp:228] Iteration 52500, loss = 3.53382
I0826 10:49:48.117430  1343 solver.cpp:244]     Train net output #0: loss = 3.53382 (* 1 = 3.53382 loss)
I0826 10:49:48.117444  1343 sgd_solver.cpp:106] Iteration 52500, lr = 3.80644e-07
I0826 10:49:56.511333  1343 solver.cpp:228] Iteration 52600, loss = 3.36095
I0826 10:49:56.511404  1343 solver.cpp:244]     Train net output #0: loss = 3.36095 (* 1 = 3.36095 loss)
I0826 10:49:56.511411  1343 sgd_solver.cpp:106] Iteration 52600, lr = 3.80251e-07
I0826 10:50:04.167387  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:50:04.922293  1343 solver.cpp:228] Iteration 52700, loss = 3.53884
I0826 10:50:04.922341  1343 solver.cpp:244]     Train net output #0: loss = 3.53884 (* 1 = 3.53884 loss)
I0826 10:50:04.922349  1343 sgd_solver.cpp:106] Iteration 52700, lr = 3.79858e-07
I0826 10:50:13.337723  1343 solver.cpp:228] Iteration 52800, loss = 3.40025
I0826 10:50:13.337790  1343 solver.cpp:244]     Train net output #0: loss = 3.40025 (* 1 = 3.40025 loss)
I0826 10:50:13.337801  1343 sgd_solver.cpp:106] Iteration 52800, lr = 3.79467e-07
I0826 10:50:21.737486  1343 solver.cpp:228] Iteration 52900, loss = 3.49587
I0826 10:50:21.737555  1343 solver.cpp:244]     Train net output #0: loss = 3.49587 (* 1 = 3.49587 loss)
I0826 10:50:21.737566  1343 sgd_solver.cpp:106] Iteration 52900, lr = 3.79076e-07
I0826 10:50:30.158895  1343 solver.cpp:228] Iteration 53000, loss = 3.34609
I0826 10:50:30.158967  1343 solver.cpp:244]     Train net output #0: loss = 3.34609 (* 1 = 3.34609 loss)
I0826 10:50:30.158977  1343 sgd_solver.cpp:106] Iteration 53000, lr = 3.78687e-07
I0826 10:50:38.562317  1343 solver.cpp:228] Iteration 53100, loss = 3.41443
I0826 10:50:38.562394  1343 solver.cpp:244]     Train net output #0: loss = 3.41443 (* 1 = 3.41443 loss)
I0826 10:50:38.562408  1343 sgd_solver.cpp:106] Iteration 53100, lr = 3.78298e-07
I0826 10:50:46.978183  1343 solver.cpp:228] Iteration 53200, loss = 3.48515
I0826 10:50:46.978243  1343 solver.cpp:244]     Train net output #0: loss = 3.48515 (* 1 = 3.48515 loss)
I0826 10:50:46.978255  1343 sgd_solver.cpp:106] Iteration 53200, lr = 3.77911e-07
I0826 10:50:55.394991  1343 solver.cpp:228] Iteration 53300, loss = 3.4819
I0826 10:50:55.395047  1343 solver.cpp:244]     Train net output #0: loss = 3.4819 (* 1 = 3.4819 loss)
I0826 10:50:55.395059  1343 sgd_solver.cpp:106] Iteration 53300, lr = 3.77524e-07
I0826 10:51:03.806689  1343 solver.cpp:228] Iteration 53400, loss = 3.4893
I0826 10:51:03.806756  1343 solver.cpp:244]     Train net output #0: loss = 3.4893 (* 1 = 3.4893 loss)
I0826 10:51:03.806764  1343 sgd_solver.cpp:106] Iteration 53400, lr = 3.77138e-07
I0826 10:51:12.216289  1343 solver.cpp:228] Iteration 53500, loss = 3.62921
I0826 10:51:12.216356  1343 solver.cpp:244]     Train net output #0: loss = 3.62921 (* 1 = 3.62921 loss)
I0826 10:51:12.216367  1343 sgd_solver.cpp:106] Iteration 53500, lr = 3.76753e-07
I0826 10:51:20.640283  1343 solver.cpp:228] Iteration 53600, loss = 3.48248
I0826 10:51:20.640337  1343 solver.cpp:244]     Train net output #0: loss = 3.48248 (* 1 = 3.48248 loss)
I0826 10:51:20.640346  1343 sgd_solver.cpp:106] Iteration 53600, lr = 3.76369e-07
I0826 10:51:29.056190  1343 solver.cpp:228] Iteration 53700, loss = 3.55689
I0826 10:51:29.056233  1343 solver.cpp:244]     Train net output #0: loss = 3.55689 (* 1 = 3.55689 loss)
I0826 10:51:29.056253  1343 sgd_solver.cpp:106] Iteration 53700, lr = 3.75986e-07
I0826 10:51:37.468740  1343 solver.cpp:228] Iteration 53800, loss = 3.62923
I0826 10:51:37.468814  1343 solver.cpp:244]     Train net output #0: loss = 3.62923 (* 1 = 3.62923 loss)
I0826 10:51:37.468829  1343 sgd_solver.cpp:106] Iteration 53800, lr = 3.75604e-07
I0826 10:51:45.882876  1343 solver.cpp:228] Iteration 53900, loss = 3.32381
I0826 10:51:45.882943  1343 solver.cpp:244]     Train net output #0: loss = 3.32381 (* 1 = 3.32381 loss)
I0826 10:51:45.882953  1343 sgd_solver.cpp:106] Iteration 53900, lr = 3.75223e-07
I0826 10:51:54.297379  1343 solver.cpp:228] Iteration 54000, loss = 3.46433
I0826 10:51:54.297436  1343 solver.cpp:244]     Train net output #0: loss = 3.46433 (* 1 = 3.46433 loss)
I0826 10:51:54.297446  1343 sgd_solver.cpp:106] Iteration 54000, lr = 3.74842e-07
I0826 10:52:02.709739  1343 solver.cpp:228] Iteration 54100, loss = 3.57585
I0826 10:52:02.709784  1343 solver.cpp:244]     Train net output #0: loss = 3.57585 (* 1 = 3.57585 loss)
I0826 10:52:02.709789  1343 sgd_solver.cpp:106] Iteration 54100, lr = 3.74463e-07
I0826 10:52:11.135982  1343 solver.cpp:228] Iteration 54200, loss = 3.27408
I0826 10:52:11.136037  1343 solver.cpp:244]     Train net output #0: loss = 3.27408 (* 1 = 3.27408 loss)
I0826 10:52:11.136045  1343 sgd_solver.cpp:106] Iteration 54200, lr = 3.74084e-07
I0826 10:52:19.539387  1343 solver.cpp:228] Iteration 54300, loss = 3.44394
I0826 10:52:19.539445  1343 solver.cpp:244]     Train net output #0: loss = 3.44394 (* 1 = 3.44394 loss)
I0826 10:52:19.539451  1343 sgd_solver.cpp:106] Iteration 54300, lr = 3.73707e-07
I0826 10:52:27.956013  1343 solver.cpp:228] Iteration 54400, loss = 3.37665
I0826 10:52:27.956084  1343 solver.cpp:244]     Train net output #0: loss = 3.37665 (* 1 = 3.37665 loss)
I0826 10:52:27.956099  1343 sgd_solver.cpp:106] Iteration 54400, lr = 3.7333e-07
I0826 10:52:36.365483  1343 solver.cpp:228] Iteration 54500, loss = 3.48357
I0826 10:52:36.365530  1343 solver.cpp:244]     Train net output #0: loss = 3.48357 (* 1 = 3.48357 loss)
I0826 10:52:36.365536  1343 sgd_solver.cpp:106] Iteration 54500, lr = 3.72954e-07
I0826 10:52:44.774989  1343 solver.cpp:228] Iteration 54600, loss = 3.42554
I0826 10:52:44.775048  1343 solver.cpp:244]     Train net output #0: loss = 3.42554 (* 1 = 3.42554 loss)
I0826 10:52:44.775058  1343 sgd_solver.cpp:106] Iteration 54600, lr = 3.72579e-07
I0826 10:52:53.199023  1343 solver.cpp:228] Iteration 54700, loss = 3.63005
I0826 10:52:53.199079  1343 solver.cpp:244]     Train net output #0: loss = 3.63005 (* 1 = 3.63005 loss)
I0826 10:52:53.199086  1343 sgd_solver.cpp:106] Iteration 54700, lr = 3.72205e-07
I0826 10:53:01.618666  1343 solver.cpp:228] Iteration 54800, loss = 3.47505
I0826 10:53:01.618746  1343 solver.cpp:244]     Train net output #0: loss = 3.47505 (* 1 = 3.47505 loss)
I0826 10:53:01.618757  1343 sgd_solver.cpp:106] Iteration 54800, lr = 3.71832e-07
I0826 10:53:10.045105  1343 solver.cpp:228] Iteration 54900, loss = 3.47841
I0826 10:53:10.045186  1343 solver.cpp:244]     Train net output #0: loss = 3.47841 (* 1 = 3.47841 loss)
I0826 10:53:10.045200  1343 sgd_solver.cpp:106] Iteration 54900, lr = 3.71459e-07
I0826 10:53:18.365142  1343 solver.cpp:337] Iteration 55000, Testing net (#0)
I0826 10:53:37.136474  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:53:56.350057  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302079
I0826 10:53:56.350113  1343 solver.cpp:404]     Test net output #1: loss = 3.47924 (* 1 = 3.47924 loss)
I0826 10:53:56.381580  1343 solver.cpp:228] Iteration 55000, loss = 3.7315
I0826 10:53:56.381635  1343 solver.cpp:244]     Train net output #0: loss = 3.7315 (* 1 = 3.7315 loss)
I0826 10:53:56.381650  1343 sgd_solver.cpp:106] Iteration 55000, lr = 3.71088e-07
I0826 10:54:04.808354  1343 solver.cpp:228] Iteration 55100, loss = 3.46342
I0826 10:54:04.808409  1343 solver.cpp:244]     Train net output #0: loss = 3.46342 (* 1 = 3.46342 loss)
I0826 10:54:04.808418  1343 sgd_solver.cpp:106] Iteration 55100, lr = 3.70717e-07
I0826 10:54:13.222543  1343 solver.cpp:228] Iteration 55200, loss = 3.25646
I0826 10:54:13.222618  1343 solver.cpp:244]     Train net output #0: loss = 3.25646 (* 1 = 3.25646 loss)
I0826 10:54:13.222625  1343 sgd_solver.cpp:106] Iteration 55200, lr = 3.70347e-07
I0826 10:54:21.649276  1343 solver.cpp:228] Iteration 55300, loss = 3.53252
I0826 10:54:21.649325  1343 solver.cpp:244]     Train net output #0: loss = 3.53252 (* 1 = 3.53252 loss)
I0826 10:54:21.649333  1343 sgd_solver.cpp:106] Iteration 55300, lr = 3.69978e-07
I0826 10:54:30.062508  1343 solver.cpp:228] Iteration 55400, loss = 3.40465
I0826 10:54:30.062567  1343 solver.cpp:244]     Train net output #0: loss = 3.40465 (* 1 = 3.40465 loss)
I0826 10:54:30.062577  1343 sgd_solver.cpp:106] Iteration 55400, lr = 3.6961e-07
I0826 10:54:38.507264  1343 solver.cpp:228] Iteration 55500, loss = 3.3062
I0826 10:54:38.507345  1343 solver.cpp:244]     Train net output #0: loss = 3.3062 (* 1 = 3.3062 loss)
I0826 10:54:38.507354  1343 sgd_solver.cpp:106] Iteration 55500, lr = 3.69243e-07
I0826 10:54:46.927498  1343 solver.cpp:228] Iteration 55600, loss = 3.3547
I0826 10:54:46.927547  1343 solver.cpp:244]     Train net output #0: loss = 3.3547 (* 1 = 3.3547 loss)
I0826 10:54:46.927554  1343 sgd_solver.cpp:106] Iteration 55600, lr = 3.68877e-07
I0826 10:54:55.350723  1343 solver.cpp:228] Iteration 55700, loss = 3.32398
I0826 10:54:55.350785  1343 solver.cpp:244]     Train net output #0: loss = 3.32398 (* 1 = 3.32398 loss)
I0826 10:54:55.350792  1343 sgd_solver.cpp:106] Iteration 55700, lr = 3.68511e-07
I0826 10:55:03.776798  1343 solver.cpp:228] Iteration 55800, loss = 3.39309
I0826 10:55:03.776860  1343 solver.cpp:244]     Train net output #0: loss = 3.39309 (* 1 = 3.39309 loss)
I0826 10:55:03.776870  1343 sgd_solver.cpp:106] Iteration 55800, lr = 3.68146e-07
I0826 10:55:12.173108  1343 solver.cpp:228] Iteration 55900, loss = 3.43433
I0826 10:55:12.173147  1343 solver.cpp:244]     Train net output #0: loss = 3.43433 (* 1 = 3.43433 loss)
I0826 10:55:12.173152  1343 sgd_solver.cpp:106] Iteration 55900, lr = 3.67783e-07
I0826 10:55:20.595124  1343 solver.cpp:228] Iteration 56000, loss = 3.5687
I0826 10:55:20.595177  1343 solver.cpp:244]     Train net output #0: loss = 3.5687 (* 1 = 3.5687 loss)
I0826 10:55:20.595183  1343 sgd_solver.cpp:106] Iteration 56000, lr = 3.6742e-07
I0826 10:55:28.997412  1343 solver.cpp:228] Iteration 56100, loss = 3.49961
I0826 10:55:28.997454  1343 solver.cpp:244]     Train net output #0: loss = 3.49961 (* 1 = 3.49961 loss)
I0826 10:55:28.997459  1343 sgd_solver.cpp:106] Iteration 56100, lr = 3.67057e-07
I0826 10:55:37.410758  1343 solver.cpp:228] Iteration 56200, loss = 3.46114
I0826 10:55:37.410830  1343 solver.cpp:244]     Train net output #0: loss = 3.46114 (* 1 = 3.46114 loss)
I0826 10:55:37.410843  1343 sgd_solver.cpp:106] Iteration 56200, lr = 3.66696e-07
I0826 10:55:45.849113  1343 solver.cpp:228] Iteration 56300, loss = 3.48202
I0826 10:55:45.849174  1343 solver.cpp:244]     Train net output #0: loss = 3.48202 (* 1 = 3.48202 loss)
I0826 10:55:45.849181  1343 sgd_solver.cpp:106] Iteration 56300, lr = 3.66336e-07
I0826 10:55:54.271729  1343 solver.cpp:228] Iteration 56400, loss = 3.46944
I0826 10:55:54.271771  1343 solver.cpp:244]     Train net output #0: loss = 3.46944 (* 1 = 3.46944 loss)
I0826 10:55:54.271776  1343 sgd_solver.cpp:106] Iteration 56400, lr = 3.65976e-07
I0826 10:56:02.697293  1343 solver.cpp:228] Iteration 56500, loss = 3.47654
I0826 10:56:02.697357  1343 solver.cpp:244]     Train net output #0: loss = 3.47654 (* 1 = 3.47654 loss)
I0826 10:56:02.697365  1343 sgd_solver.cpp:106] Iteration 56500, lr = 3.65617e-07
I0826 10:56:11.146854  1343 solver.cpp:228] Iteration 56600, loss = 3.34306
I0826 10:56:11.146909  1343 solver.cpp:244]     Train net output #0: loss = 3.34306 (* 1 = 3.34306 loss)
I0826 10:56:11.146915  1343 sgd_solver.cpp:106] Iteration 56600, lr = 3.65259e-07
I0826 10:56:19.564952  1343 solver.cpp:228] Iteration 56700, loss = 3.54542
I0826 10:56:19.565017  1343 solver.cpp:244]     Train net output #0: loss = 3.54542 (* 1 = 3.54542 loss)
I0826 10:56:19.565026  1343 sgd_solver.cpp:106] Iteration 56700, lr = 3.64902e-07
I0826 10:56:25.959286  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 10:56:27.976644  1343 solver.cpp:228] Iteration 56800, loss = 3.50267
I0826 10:56:27.976698  1343 solver.cpp:244]     Train net output #0: loss = 3.50267 (* 1 = 3.50267 loss)
I0826 10:56:27.976707  1343 sgd_solver.cpp:106] Iteration 56800, lr = 3.64545e-07
I0826 10:56:36.417408  1343 solver.cpp:228] Iteration 56900, loss = 3.49203
I0826 10:56:36.417464  1343 solver.cpp:244]     Train net output #0: loss = 3.49203 (* 1 = 3.49203 loss)
I0826 10:56:36.417471  1343 sgd_solver.cpp:106] Iteration 56900, lr = 3.6419e-07
I0826 10:56:44.830777  1343 solver.cpp:228] Iteration 57000, loss = 3.19022
I0826 10:56:44.830819  1343 solver.cpp:244]     Train net output #0: loss = 3.19022 (* 1 = 3.19022 loss)
I0826 10:56:44.830826  1343 sgd_solver.cpp:106] Iteration 57000, lr = 3.63835e-07
I0826 10:56:53.260918  1343 solver.cpp:228] Iteration 57100, loss = 3.67839
I0826 10:56:53.260968  1343 solver.cpp:244]     Train net output #0: loss = 3.67839 (* 1 = 3.67839 loss)
I0826 10:56:53.260977  1343 sgd_solver.cpp:106] Iteration 57100, lr = 3.63481e-07
I0826 10:57:01.669150  1343 solver.cpp:228] Iteration 57200, loss = 3.47895
I0826 10:57:01.669211  1343 solver.cpp:244]     Train net output #0: loss = 3.47895 (* 1 = 3.47895 loss)
I0826 10:57:01.669219  1343 sgd_solver.cpp:106] Iteration 57200, lr = 3.63128e-07
I0826 10:57:10.104146  1343 solver.cpp:228] Iteration 57300, loss = 3.48612
I0826 10:57:10.104205  1343 solver.cpp:244]     Train net output #0: loss = 3.48612 (* 1 = 3.48612 loss)
I0826 10:57:10.104214  1343 sgd_solver.cpp:106] Iteration 57300, lr = 3.62775e-07
I0826 10:57:18.530093  1343 solver.cpp:228] Iteration 57400, loss = 3.57042
I0826 10:57:18.530135  1343 solver.cpp:244]     Train net output #0: loss = 3.57042 (* 1 = 3.57042 loss)
I0826 10:57:18.530141  1343 sgd_solver.cpp:106] Iteration 57400, lr = 3.62424e-07
I0826 10:57:26.966282  1343 solver.cpp:228] Iteration 57500, loss = 3.33818
I0826 10:57:26.966336  1343 solver.cpp:244]     Train net output #0: loss = 3.33818 (* 1 = 3.33818 loss)
I0826 10:57:26.966344  1343 sgd_solver.cpp:106] Iteration 57500, lr = 3.62073e-07
I0826 10:57:35.380484  1343 solver.cpp:228] Iteration 57600, loss = 3.45988
I0826 10:57:35.380537  1343 solver.cpp:244]     Train net output #0: loss = 3.45988 (* 1 = 3.45988 loss)
I0826 10:57:35.380542  1343 sgd_solver.cpp:106] Iteration 57600, lr = 3.61723e-07
I0826 10:57:43.805564  1343 solver.cpp:228] Iteration 57700, loss = 3.5003
I0826 10:57:43.805624  1343 solver.cpp:244]     Train net output #0: loss = 3.5003 (* 1 = 3.5003 loss)
I0826 10:57:43.805631  1343 sgd_solver.cpp:106] Iteration 57700, lr = 3.61374e-07
I0826 10:57:52.222621  1343 solver.cpp:228] Iteration 57800, loss = 3.44609
I0826 10:57:52.222666  1343 solver.cpp:244]     Train net output #0: loss = 3.44609 (* 1 = 3.44609 loss)
I0826 10:57:52.222672  1343 sgd_solver.cpp:106] Iteration 57800, lr = 3.61025e-07
I0826 10:58:00.647285  1343 solver.cpp:228] Iteration 57900, loss = 3.37681
I0826 10:58:00.647344  1343 solver.cpp:244]     Train net output #0: loss = 3.37681 (* 1 = 3.37681 loss)
I0826 10:58:00.647354  1343 sgd_solver.cpp:106] Iteration 57900, lr = 3.60678e-07
I0826 10:58:09.090867  1343 solver.cpp:228] Iteration 58000, loss = 3.35623
I0826 10:58:09.090929  1343 solver.cpp:244]     Train net output #0: loss = 3.35623 (* 1 = 3.35623 loss)
I0826 10:58:09.090939  1343 sgd_solver.cpp:106] Iteration 58000, lr = 3.60331e-07
I0826 10:58:17.500057  1343 solver.cpp:228] Iteration 58100, loss = 3.5041
I0826 10:58:17.500100  1343 solver.cpp:244]     Train net output #0: loss = 3.5041 (* 1 = 3.5041 loss)
I0826 10:58:17.500107  1343 sgd_solver.cpp:106] Iteration 58100, lr = 3.59985e-07
I0826 10:58:25.907739  1343 solver.cpp:228] Iteration 58200, loss = 3.46645
I0826 10:58:25.907802  1343 solver.cpp:244]     Train net output #0: loss = 3.46645 (* 1 = 3.46645 loss)
I0826 10:58:25.907814  1343 sgd_solver.cpp:106] Iteration 58200, lr = 3.5964e-07
I0826 10:58:34.332427  1343 solver.cpp:228] Iteration 58300, loss = 3.39362
I0826 10:58:34.332489  1343 solver.cpp:244]     Train net output #0: loss = 3.39362 (* 1 = 3.39362 loss)
I0826 10:58:34.332495  1343 sgd_solver.cpp:106] Iteration 58300, lr = 3.59295e-07
I0826 10:58:42.725617  1343 solver.cpp:228] Iteration 58400, loss = 3.47501
I0826 10:58:42.725672  1343 solver.cpp:244]     Train net output #0: loss = 3.47501 (* 1 = 3.47501 loss)
I0826 10:58:42.725680  1343 sgd_solver.cpp:106] Iteration 58400, lr = 3.58951e-07
I0826 10:58:51.151527  1343 solver.cpp:228] Iteration 58500, loss = 3.3795
I0826 10:58:51.151582  1343 solver.cpp:244]     Train net output #0: loss = 3.3795 (* 1 = 3.3795 loss)
I0826 10:58:51.151589  1343 sgd_solver.cpp:106] Iteration 58500, lr = 3.58608e-07
I0826 10:58:59.576277  1343 solver.cpp:228] Iteration 58600, loss = 3.33209
I0826 10:58:59.576320  1343 solver.cpp:244]     Train net output #0: loss = 3.33209 (* 1 = 3.33209 loss)
I0826 10:58:59.576326  1343 sgd_solver.cpp:106] Iteration 58600, lr = 3.58266e-07
I0826 10:59:07.994987  1343 solver.cpp:228] Iteration 58700, loss = 3.51329
I0826 10:59:07.995046  1343 solver.cpp:244]     Train net output #0: loss = 3.51329 (* 1 = 3.51329 loss)
I0826 10:59:07.995055  1343 sgd_solver.cpp:106] Iteration 58700, lr = 3.57925e-07
I0826 10:59:16.412693  1343 solver.cpp:228] Iteration 58800, loss = 3.32889
I0826 10:59:16.412760  1343 solver.cpp:244]     Train net output #0: loss = 3.32889 (* 1 = 3.32889 loss)
I0826 10:59:16.412770  1343 sgd_solver.cpp:106] Iteration 58800, lr = 3.57584e-07
I0826 10:59:24.836606  1343 solver.cpp:228] Iteration 58900, loss = 3.39743
I0826 10:59:24.836676  1343 solver.cpp:244]     Train net output #0: loss = 3.39743 (* 1 = 3.39743 loss)
I0826 10:59:24.836686  1343 sgd_solver.cpp:106] Iteration 58900, lr = 3.57244e-07
I0826 10:59:33.266420  1343 solver.cpp:228] Iteration 59000, loss = 3.5139
I0826 10:59:33.266482  1343 solver.cpp:244]     Train net output #0: loss = 3.5139 (* 1 = 3.5139 loss)
I0826 10:59:33.266489  1343 sgd_solver.cpp:106] Iteration 59000, lr = 3.56905e-07
I0826 10:59:41.689540  1343 solver.cpp:228] Iteration 59100, loss = 3.48018
I0826 10:59:41.689584  1343 solver.cpp:244]     Train net output #0: loss = 3.48018 (* 1 = 3.48018 loss)
I0826 10:59:41.689590  1343 sgd_solver.cpp:106] Iteration 59100, lr = 3.56566e-07
I0826 10:59:50.125512  1343 solver.cpp:228] Iteration 59200, loss = 3.47981
I0826 10:59:50.125556  1343 solver.cpp:244]     Train net output #0: loss = 3.47981 (* 1 = 3.47981 loss)
I0826 10:59:50.125561  1343 sgd_solver.cpp:106] Iteration 59200, lr = 3.56228e-07
I0826 10:59:58.529175  1343 solver.cpp:228] Iteration 59300, loss = 3.43743
I0826 10:59:58.529237  1343 solver.cpp:244]     Train net output #0: loss = 3.43743 (* 1 = 3.43743 loss)
I0826 10:59:58.529244  1343 sgd_solver.cpp:106] Iteration 59300, lr = 3.55892e-07
I0826 11:00:06.942081  1343 solver.cpp:228] Iteration 59400, loss = 3.38213
I0826 11:00:06.942143  1343 solver.cpp:244]     Train net output #0: loss = 3.38213 (* 1 = 3.38213 loss)
I0826 11:00:06.942152  1343 sgd_solver.cpp:106] Iteration 59400, lr = 3.55555e-07
I0826 11:00:15.376322  1343 solver.cpp:228] Iteration 59500, loss = 3.53031
I0826 11:00:15.376385  1343 solver.cpp:244]     Train net output #0: loss = 3.53031 (* 1 = 3.53031 loss)
I0826 11:00:15.376396  1343 sgd_solver.cpp:106] Iteration 59500, lr = 3.5522e-07
I0826 11:00:23.806186  1343 solver.cpp:228] Iteration 59600, loss = 3.33494
I0826 11:00:23.806243  1343 solver.cpp:244]     Train net output #0: loss = 3.33494 (* 1 = 3.33494 loss)
I0826 11:00:23.806252  1343 sgd_solver.cpp:106] Iteration 59600, lr = 3.54885e-07
I0826 11:00:32.206431  1343 solver.cpp:228] Iteration 59700, loss = 3.43226
I0826 11:00:32.206473  1343 solver.cpp:244]     Train net output #0: loss = 3.43226 (* 1 = 3.43226 loss)
I0826 11:00:32.206480  1343 sgd_solver.cpp:106] Iteration 59700, lr = 3.54551e-07
I0826 11:00:40.634228  1343 solver.cpp:228] Iteration 59800, loss = 3.47428
I0826 11:00:40.634284  1343 solver.cpp:244]     Train net output #0: loss = 3.47428 (* 1 = 3.47428 loss)
I0826 11:00:40.634294  1343 sgd_solver.cpp:106] Iteration 59800, lr = 3.54218e-07
I0826 11:00:49.053795  1343 solver.cpp:228] Iteration 59900, loss = 3.5096
I0826 11:00:49.053845  1343 solver.cpp:244]     Train net output #0: loss = 3.5096 (* 1 = 3.5096 loss)
I0826 11:00:49.053851  1343 sgd_solver.cpp:106] Iteration 59900, lr = 3.53885e-07
I0826 11:00:57.385684  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_60000.caffemodel
I0826 11:00:57.883942  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_60000.solverstate
I0826 11:00:58.041040  1343 solver.cpp:337] Iteration 60000, Testing net (#0)
I0826 11:01:02.331157  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:01:37.979142  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 11:01:37.979197  1343 solver.cpp:404]     Test net output #1: loss = 3.47323 (* 1 = 3.47323 loss)
I0826 11:01:38.007984  1343 solver.cpp:228] Iteration 60000, loss = 3.33974
I0826 11:01:38.008043  1343 solver.cpp:244]     Train net output #0: loss = 3.33974 (* 1 = 3.33974 loss)
I0826 11:01:38.008062  1343 sgd_solver.cpp:106] Iteration 60000, lr = 3.53553e-07
I0826 11:01:46.422919  1343 solver.cpp:228] Iteration 60100, loss = 3.34527
I0826 11:01:46.422987  1343 solver.cpp:244]     Train net output #0: loss = 3.34527 (* 1 = 3.34527 loss)
I0826 11:01:46.422999  1343 sgd_solver.cpp:106] Iteration 60100, lr = 3.53222e-07
I0826 11:01:54.822423  1343 solver.cpp:228] Iteration 60200, loss = 3.55446
I0826 11:01:54.822504  1343 solver.cpp:244]     Train net output #0: loss = 3.55446 (* 1 = 3.55446 loss)
I0826 11:01:54.822515  1343 sgd_solver.cpp:106] Iteration 60200, lr = 3.52892e-07
I0826 11:02:03.221037  1343 solver.cpp:228] Iteration 60300, loss = 3.4161
I0826 11:02:03.221102  1343 solver.cpp:244]     Train net output #0: loss = 3.4161 (* 1 = 3.4161 loss)
I0826 11:02:03.221114  1343 sgd_solver.cpp:106] Iteration 60300, lr = 3.52562e-07
I0826 11:02:11.622067  1343 solver.cpp:228] Iteration 60400, loss = 3.57638
I0826 11:02:11.622124  1343 solver.cpp:244]     Train net output #0: loss = 3.57638 (* 1 = 3.57638 loss)
I0826 11:02:11.622133  1343 sgd_solver.cpp:106] Iteration 60400, lr = 3.52233e-07
I0826 11:02:20.013768  1343 solver.cpp:228] Iteration 60500, loss = 3.38292
I0826 11:02:20.013824  1343 solver.cpp:244]     Train net output #0: loss = 3.38292 (* 1 = 3.38292 loss)
I0826 11:02:20.013833  1343 sgd_solver.cpp:106] Iteration 60500, lr = 3.51905e-07
I0826 11:02:25.818461  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:02:28.429684  1343 solver.cpp:228] Iteration 60600, loss = 3.44636
I0826 11:02:28.429751  1343 solver.cpp:244]     Train net output #0: loss = 3.44636 (* 1 = 3.44636 loss)
I0826 11:02:28.429764  1343 sgd_solver.cpp:106] Iteration 60600, lr = 3.51578e-07
I0826 11:02:36.818405  1343 solver.cpp:228] Iteration 60700, loss = 3.49588
I0826 11:02:36.818467  1343 solver.cpp:244]     Train net output #0: loss = 3.49588 (* 1 = 3.49588 loss)
I0826 11:02:36.818477  1343 sgd_solver.cpp:106] Iteration 60700, lr = 3.51251e-07
I0826 11:02:45.237349  1343 solver.cpp:228] Iteration 60800, loss = 3.35581
I0826 11:02:45.237399  1343 solver.cpp:244]     Train net output #0: loss = 3.35581 (* 1 = 3.35581 loss)
I0826 11:02:45.237406  1343 sgd_solver.cpp:106] Iteration 60800, lr = 3.50925e-07
I0826 11:02:53.664268  1343 solver.cpp:228] Iteration 60900, loss = 3.32687
I0826 11:02:53.664326  1343 solver.cpp:244]     Train net output #0: loss = 3.32687 (* 1 = 3.32687 loss)
I0826 11:02:53.664340  1343 sgd_solver.cpp:106] Iteration 60900, lr = 3.50599e-07
I0826 11:03:02.070133  1343 solver.cpp:228] Iteration 61000, loss = 3.54212
I0826 11:03:02.070217  1343 solver.cpp:244]     Train net output #0: loss = 3.54212 (* 1 = 3.54212 loss)
I0826 11:03:02.070232  1343 sgd_solver.cpp:106] Iteration 61000, lr = 3.50275e-07
I0826 11:03:10.487227  1343 solver.cpp:228] Iteration 61100, loss = 3.40823
I0826 11:03:10.487282  1343 solver.cpp:244]     Train net output #0: loss = 3.40823 (* 1 = 3.40823 loss)
I0826 11:03:10.487290  1343 sgd_solver.cpp:106] Iteration 61100, lr = 3.49951e-07
I0826 11:03:18.874624  1343 solver.cpp:228] Iteration 61200, loss = 3.49483
I0826 11:03:18.874672  1343 solver.cpp:244]     Train net output #0: loss = 3.49483 (* 1 = 3.49483 loss)
I0826 11:03:18.874678  1343 sgd_solver.cpp:106] Iteration 61200, lr = 3.49627e-07
I0826 11:03:27.288911  1343 solver.cpp:228] Iteration 61300, loss = 3.43159
I0826 11:03:27.288977  1343 solver.cpp:244]     Train net output #0: loss = 3.43159 (* 1 = 3.43159 loss)
I0826 11:03:27.288988  1343 sgd_solver.cpp:106] Iteration 61300, lr = 3.49305e-07
I0826 11:03:35.675034  1343 solver.cpp:228] Iteration 61400, loss = 3.62274
I0826 11:03:35.675088  1343 solver.cpp:244]     Train net output #0: loss = 3.62274 (* 1 = 3.62274 loss)
I0826 11:03:35.675096  1343 sgd_solver.cpp:106] Iteration 61400, lr = 3.48983e-07
I0826 11:03:44.095441  1343 solver.cpp:228] Iteration 61500, loss = 3.41929
I0826 11:03:44.095501  1343 solver.cpp:244]     Train net output #0: loss = 3.41929 (* 1 = 3.41929 loss)
I0826 11:03:44.095515  1343 sgd_solver.cpp:106] Iteration 61500, lr = 3.48662e-07
I0826 11:03:52.535256  1343 solver.cpp:228] Iteration 61600, loss = 3.45512
I0826 11:03:52.535322  1343 solver.cpp:244]     Train net output #0: loss = 3.45512 (* 1 = 3.45512 loss)
I0826 11:03:52.535332  1343 sgd_solver.cpp:106] Iteration 61600, lr = 3.48341e-07
I0826 11:04:00.958966  1343 solver.cpp:228] Iteration 61700, loss = 3.53285
I0826 11:04:00.959033  1343 solver.cpp:244]     Train net output #0: loss = 3.53285 (* 1 = 3.53285 loss)
I0826 11:04:00.959043  1343 sgd_solver.cpp:106] Iteration 61700, lr = 3.48021e-07
I0826 11:04:09.358989  1343 solver.cpp:228] Iteration 61800, loss = 3.72384
I0826 11:04:09.359055  1343 solver.cpp:244]     Train net output #0: loss = 3.72384 (* 1 = 3.72384 loss)
I0826 11:04:09.359063  1343 sgd_solver.cpp:106] Iteration 61800, lr = 3.47702e-07
I0826 11:04:17.780161  1343 solver.cpp:228] Iteration 61900, loss = 3.46445
I0826 11:04:17.780223  1343 solver.cpp:244]     Train net output #0: loss = 3.46445 (* 1 = 3.46445 loss)
I0826 11:04:17.780232  1343 sgd_solver.cpp:106] Iteration 61900, lr = 3.47384e-07
I0826 11:04:26.211110  1343 solver.cpp:228] Iteration 62000, loss = 3.2159
I0826 11:04:26.211156  1343 solver.cpp:244]     Train net output #0: loss = 3.2159 (* 1 = 3.2159 loss)
I0826 11:04:26.211163  1343 sgd_solver.cpp:106] Iteration 62000, lr = 3.47066e-07
I0826 11:04:34.631721  1343 solver.cpp:228] Iteration 62100, loss = 3.44277
I0826 11:04:34.631777  1343 solver.cpp:244]     Train net output #0: loss = 3.44277 (* 1 = 3.44277 loss)
I0826 11:04:34.631783  1343 sgd_solver.cpp:106] Iteration 62100, lr = 3.46749e-07
I0826 11:04:43.046756  1343 solver.cpp:228] Iteration 62200, loss = 3.53717
I0826 11:04:43.046808  1343 solver.cpp:244]     Train net output #0: loss = 3.53717 (* 1 = 3.53717 loss)
I0826 11:04:43.046818  1343 sgd_solver.cpp:106] Iteration 62200, lr = 3.46433e-07
I0826 11:04:51.472050  1343 solver.cpp:228] Iteration 62300, loss = 3.46018
I0826 11:04:51.472117  1343 solver.cpp:244]     Train net output #0: loss = 3.46018 (* 1 = 3.46018 loss)
I0826 11:04:51.472128  1343 sgd_solver.cpp:106] Iteration 62300, lr = 3.46117e-07
I0826 11:04:59.899011  1343 solver.cpp:228] Iteration 62400, loss = 3.27162
I0826 11:04:59.899078  1343 solver.cpp:244]     Train net output #0: loss = 3.27162 (* 1 = 3.27162 loss)
I0826 11:04:59.899088  1343 sgd_solver.cpp:106] Iteration 62400, lr = 3.45802e-07
I0826 11:05:08.329593  1343 solver.cpp:228] Iteration 62500, loss = 3.63304
I0826 11:05:08.329645  1343 solver.cpp:244]     Train net output #0: loss = 3.63304 (* 1 = 3.63304 loss)
I0826 11:05:08.329653  1343 sgd_solver.cpp:106] Iteration 62500, lr = 3.45487e-07
I0826 11:05:16.741072  1343 solver.cpp:228] Iteration 62600, loss = 3.54578
I0826 11:05:16.741116  1343 solver.cpp:244]     Train net output #0: loss = 3.54578 (* 1 = 3.54578 loss)
I0826 11:05:16.741122  1343 sgd_solver.cpp:106] Iteration 62600, lr = 3.45174e-07
I0826 11:05:25.169282  1343 solver.cpp:228] Iteration 62700, loss = 3.60742
I0826 11:05:25.169350  1343 solver.cpp:244]     Train net output #0: loss = 3.60742 (* 1 = 3.60742 loss)
I0826 11:05:25.169360  1343 sgd_solver.cpp:106] Iteration 62700, lr = 3.4486e-07
I0826 11:05:33.604409  1343 solver.cpp:228] Iteration 62800, loss = 3.44872
I0826 11:05:33.604466  1343 solver.cpp:244]     Train net output #0: loss = 3.44872 (* 1 = 3.44872 loss)
I0826 11:05:33.604477  1343 sgd_solver.cpp:106] Iteration 62800, lr = 3.44548e-07
I0826 11:05:42.027266  1343 solver.cpp:228] Iteration 62900, loss = 3.38271
I0826 11:05:42.027334  1343 solver.cpp:244]     Train net output #0: loss = 3.38271 (* 1 = 3.38271 loss)
I0826 11:05:42.027344  1343 sgd_solver.cpp:106] Iteration 62900, lr = 3.44236e-07
I0826 11:05:50.457031  1343 solver.cpp:228] Iteration 63000, loss = 3.26141
I0826 11:05:50.457090  1343 solver.cpp:244]     Train net output #0: loss = 3.26141 (* 1 = 3.26141 loss)
I0826 11:05:50.457103  1343 sgd_solver.cpp:106] Iteration 63000, lr = 3.43925e-07
I0826 11:05:58.878788  1343 solver.cpp:228] Iteration 63100, loss = 3.65036
I0826 11:05:58.878836  1343 solver.cpp:244]     Train net output #0: loss = 3.65036 (* 1 = 3.65036 loss)
I0826 11:05:58.878842  1343 sgd_solver.cpp:106] Iteration 63100, lr = 3.43615e-07
I0826 11:06:07.284312  1343 solver.cpp:228] Iteration 63200, loss = 3.4805
I0826 11:06:07.284365  1343 solver.cpp:244]     Train net output #0: loss = 3.4805 (* 1 = 3.4805 loss)
I0826 11:06:07.284375  1343 sgd_solver.cpp:106] Iteration 63200, lr = 3.43305e-07
I0826 11:06:15.710016  1343 solver.cpp:228] Iteration 63300, loss = 3.52364
I0826 11:06:15.710079  1343 solver.cpp:244]     Train net output #0: loss = 3.52364 (* 1 = 3.52364 loss)
I0826 11:06:15.710089  1343 sgd_solver.cpp:106] Iteration 63300, lr = 3.42996e-07
I0826 11:06:24.137518  1343 solver.cpp:228] Iteration 63400, loss = 3.50121
I0826 11:06:24.137595  1343 solver.cpp:244]     Train net output #0: loss = 3.50121 (* 1 = 3.50121 loss)
I0826 11:06:24.137604  1343 sgd_solver.cpp:106] Iteration 63400, lr = 3.42687e-07
I0826 11:06:32.568583  1343 solver.cpp:228] Iteration 63500, loss = 3.45727
I0826 11:06:32.568646  1343 solver.cpp:244]     Train net output #0: loss = 3.45727 (* 1 = 3.45727 loss)
I0826 11:06:32.568655  1343 sgd_solver.cpp:106] Iteration 63500, lr = 3.42379e-07
I0826 11:06:40.997658  1343 solver.cpp:228] Iteration 63600, loss = 3.5232
I0826 11:06:40.997700  1343 solver.cpp:244]     Train net output #0: loss = 3.5232 (* 1 = 3.5232 loss)
I0826 11:06:40.997705  1343 sgd_solver.cpp:106] Iteration 63600, lr = 3.42072e-07
I0826 11:06:49.433966  1343 solver.cpp:228] Iteration 63700, loss = 3.46393
I0826 11:06:49.434037  1343 solver.cpp:244]     Train net output #0: loss = 3.46393 (* 1 = 3.46393 loss)
I0826 11:06:49.434051  1343 sgd_solver.cpp:106] Iteration 63700, lr = 3.41766e-07
I0826 11:06:57.860551  1343 solver.cpp:228] Iteration 63800, loss = 3.4821
I0826 11:06:57.860620  1343 solver.cpp:244]     Train net output #0: loss = 3.4821 (* 1 = 3.4821 loss)
I0826 11:06:57.860631  1343 sgd_solver.cpp:106] Iteration 63800, lr = 3.4146e-07
I0826 11:07:06.285578  1343 solver.cpp:228] Iteration 63900, loss = 3.35225
I0826 11:07:06.285643  1343 solver.cpp:244]     Train net output #0: loss = 3.35225 (* 1 = 3.35225 loss)
I0826 11:07:06.285652  1343 sgd_solver.cpp:106] Iteration 63900, lr = 3.41154e-07
I0826 11:07:14.716593  1343 solver.cpp:228] Iteration 64000, loss = 3.50189
I0826 11:07:14.716653  1343 solver.cpp:244]     Train net output #0: loss = 3.50189 (* 1 = 3.50189 loss)
I0826 11:07:14.716665  1343 sgd_solver.cpp:106] Iteration 64000, lr = 3.4085e-07
I0826 11:07:23.143666  1343 solver.cpp:228] Iteration 64100, loss = 3.27011
I0826 11:07:23.143731  1343 solver.cpp:244]     Train net output #0: loss = 3.27011 (* 1 = 3.27011 loss)
I0826 11:07:23.143739  1343 sgd_solver.cpp:106] Iteration 64100, lr = 3.40546e-07
I0826 11:07:24.660702  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:07:31.572073  1343 solver.cpp:228] Iteration 64200, loss = 3.52258
I0826 11:07:31.572116  1343 solver.cpp:244]     Train net output #0: loss = 3.52258 (* 1 = 3.52258 loss)
I0826 11:07:31.572124  1343 sgd_solver.cpp:106] Iteration 64200, lr = 3.40242e-07
I0826 11:07:39.984943  1343 solver.cpp:228] Iteration 64300, loss = 3.4854
I0826 11:07:39.984997  1343 solver.cpp:244]     Train net output #0: loss = 3.4854 (* 1 = 3.4854 loss)
I0826 11:07:39.985003  1343 sgd_solver.cpp:106] Iteration 64300, lr = 3.3994e-07
I0826 11:07:48.411999  1343 solver.cpp:228] Iteration 64400, loss = 3.41605
I0826 11:07:48.412075  1343 solver.cpp:244]     Train net output #0: loss = 3.41605 (* 1 = 3.41605 loss)
I0826 11:07:48.412089  1343 sgd_solver.cpp:106] Iteration 64400, lr = 3.39637e-07
I0826 11:07:56.835633  1343 solver.cpp:228] Iteration 64500, loss = 3.41027
I0826 11:07:56.835677  1343 solver.cpp:244]     Train net output #0: loss = 3.41027 (* 1 = 3.41027 loss)
I0826 11:07:56.835683  1343 sgd_solver.cpp:106] Iteration 64500, lr = 3.39336e-07
I0826 11:08:05.269489  1343 solver.cpp:228] Iteration 64600, loss = 3.2627
I0826 11:08:05.269537  1343 solver.cpp:244]     Train net output #0: loss = 3.2627 (* 1 = 3.2627 loss)
I0826 11:08:05.269549  1343 sgd_solver.cpp:106] Iteration 64600, lr = 3.39035e-07
I0826 11:08:13.673084  1343 solver.cpp:228] Iteration 64700, loss = 3.52001
I0826 11:08:13.673130  1343 solver.cpp:244]     Train net output #0: loss = 3.52001 (* 1 = 3.52001 loss)
I0826 11:08:13.673135  1343 sgd_solver.cpp:106] Iteration 64700, lr = 3.38735e-07
I0826 11:08:22.095427  1343 solver.cpp:228] Iteration 64800, loss = 3.44605
I0826 11:08:22.095489  1343 solver.cpp:244]     Train net output #0: loss = 3.44605 (* 1 = 3.44605 loss)
I0826 11:08:22.095502  1343 sgd_solver.cpp:106] Iteration 64800, lr = 3.38435e-07
I0826 11:08:30.531081  1343 solver.cpp:228] Iteration 64900, loss = 3.47746
I0826 11:08:30.531146  1343 solver.cpp:244]     Train net output #0: loss = 3.47746 (* 1 = 3.47746 loss)
I0826 11:08:30.531167  1343 sgd_solver.cpp:106] Iteration 64900, lr = 3.38136e-07
I0826 11:08:38.863608  1343 solver.cpp:337] Iteration 65000, Testing net (#0)
I0826 11:09:15.790477  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 11:09:15.790525  1343 solver.cpp:404]     Test net output #1: loss = 3.46773 (* 1 = 3.46773 loss)
I0826 11:09:15.822109  1343 solver.cpp:228] Iteration 65000, loss = 3.40978
I0826 11:09:15.822161  1343 solver.cpp:244]     Train net output #0: loss = 3.40978 (* 1 = 3.40978 loss)
I0826 11:09:15.822172  1343 sgd_solver.cpp:106] Iteration 65000, lr = 3.37838e-07
I0826 11:09:24.257719  1343 solver.cpp:228] Iteration 65100, loss = 3.36204
I0826 11:09:24.257776  1343 solver.cpp:244]     Train net output #0: loss = 3.36204 (* 1 = 3.36204 loss)
I0826 11:09:24.257786  1343 sgd_solver.cpp:106] Iteration 65100, lr = 3.3754e-07
I0826 11:09:32.664917  1343 solver.cpp:228] Iteration 65200, loss = 3.21583
I0826 11:09:32.664970  1343 solver.cpp:244]     Train net output #0: loss = 3.21583 (* 1 = 3.21583 loss)
I0826 11:09:32.664979  1343 sgd_solver.cpp:106] Iteration 65200, lr = 3.37243e-07
I0826 11:09:41.071355  1343 solver.cpp:228] Iteration 65300, loss = 3.46119
I0826 11:09:41.071436  1343 solver.cpp:244]     Train net output #0: loss = 3.46119 (* 1 = 3.46119 loss)
I0826 11:09:41.071449  1343 sgd_solver.cpp:106] Iteration 65300, lr = 3.36946e-07
I0826 11:09:48.822031  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:09:49.493079  1343 solver.cpp:228] Iteration 65400, loss = 3.54091
I0826 11:09:49.493150  1343 solver.cpp:244]     Train net output #0: loss = 3.54091 (* 1 = 3.54091 loss)
I0826 11:09:49.493158  1343 sgd_solver.cpp:106] Iteration 65400, lr = 3.3665e-07
I0826 11:09:57.893298  1343 solver.cpp:228] Iteration 65500, loss = 3.41354
I0826 11:09:57.893347  1343 solver.cpp:244]     Train net output #0: loss = 3.41354 (* 1 = 3.41354 loss)
I0826 11:09:57.893354  1343 sgd_solver.cpp:106] Iteration 65500, lr = 3.36355e-07
I0826 11:10:06.311455  1343 solver.cpp:228] Iteration 65600, loss = 3.49247
I0826 11:10:06.311511  1343 solver.cpp:244]     Train net output #0: loss = 3.49247 (* 1 = 3.49247 loss)
I0826 11:10:06.311517  1343 sgd_solver.cpp:106] Iteration 65600, lr = 3.3606e-07
I0826 11:10:14.730046  1343 solver.cpp:228] Iteration 65700, loss = 3.45922
I0826 11:10:14.730099  1343 solver.cpp:244]     Train net output #0: loss = 3.45922 (* 1 = 3.45922 loss)
I0826 11:10:14.730108  1343 sgd_solver.cpp:106] Iteration 65700, lr = 3.35766e-07
I0826 11:10:23.137020  1343 solver.cpp:228] Iteration 65800, loss = 3.4422
I0826 11:10:23.137089  1343 solver.cpp:244]     Train net output #0: loss = 3.4422 (* 1 = 3.4422 loss)
I0826 11:10:23.137105  1343 sgd_solver.cpp:106] Iteration 65800, lr = 3.35473e-07
I0826 11:10:31.551931  1343 solver.cpp:228] Iteration 65900, loss = 3.3985
I0826 11:10:31.552014  1343 solver.cpp:244]     Train net output #0: loss = 3.3985 (* 1 = 3.3985 loss)
I0826 11:10:31.552031  1343 sgd_solver.cpp:106] Iteration 65900, lr = 3.3518e-07
I0826 11:10:39.976567  1343 solver.cpp:228] Iteration 66000, loss = 3.65816
I0826 11:10:39.976629  1343 solver.cpp:244]     Train net output #0: loss = 3.65816 (* 1 = 3.65816 loss)
I0826 11:10:39.976644  1343 sgd_solver.cpp:106] Iteration 66000, lr = 3.34887e-07
I0826 11:10:48.361871  1343 solver.cpp:228] Iteration 66100, loss = 3.39057
I0826 11:10:48.361927  1343 solver.cpp:244]     Train net output #0: loss = 3.39057 (* 1 = 3.39057 loss)
I0826 11:10:48.361935  1343 sgd_solver.cpp:106] Iteration 66100, lr = 3.34596e-07
I0826 11:10:56.781322  1343 solver.cpp:228] Iteration 66200, loss = 3.29896
I0826 11:10:56.781378  1343 solver.cpp:244]     Train net output #0: loss = 3.29896 (* 1 = 3.29896 loss)
I0826 11:10:56.781388  1343 sgd_solver.cpp:106] Iteration 66200, lr = 3.34304e-07
I0826 11:11:05.190148  1343 solver.cpp:228] Iteration 66300, loss = 3.42638
I0826 11:11:05.190207  1343 solver.cpp:244]     Train net output #0: loss = 3.42638 (* 1 = 3.42638 loss)
I0826 11:11:05.190212  1343 sgd_solver.cpp:106] Iteration 66300, lr = 3.34014e-07
I0826 11:11:13.594009  1343 solver.cpp:228] Iteration 66400, loss = 3.62323
I0826 11:11:13.594075  1343 solver.cpp:244]     Train net output #0: loss = 3.62323 (* 1 = 3.62323 loss)
I0826 11:11:13.594089  1343 sgd_solver.cpp:106] Iteration 66400, lr = 3.33724e-07
I0826 11:11:22.017618  1343 solver.cpp:228] Iteration 66500, loss = 3.49176
I0826 11:11:22.017685  1343 solver.cpp:244]     Train net output #0: loss = 3.49176 (* 1 = 3.49176 loss)
I0826 11:11:22.017694  1343 sgd_solver.cpp:106] Iteration 66500, lr = 3.33434e-07
I0826 11:11:30.442875  1343 solver.cpp:228] Iteration 66600, loss = 3.48006
I0826 11:11:30.442936  1343 solver.cpp:244]     Train net output #0: loss = 3.48006 (* 1 = 3.48006 loss)
I0826 11:11:30.442946  1343 sgd_solver.cpp:106] Iteration 66600, lr = 3.33146e-07
I0826 11:11:38.834663  1343 solver.cpp:228] Iteration 66700, loss = 3.59624
I0826 11:11:38.834727  1343 solver.cpp:244]     Train net output #0: loss = 3.59624 (* 1 = 3.59624 loss)
I0826 11:11:38.834734  1343 sgd_solver.cpp:106] Iteration 66700, lr = 3.32857e-07
I0826 11:11:47.251595  1343 solver.cpp:228] Iteration 66800, loss = 3.44044
I0826 11:11:47.251638  1343 solver.cpp:244]     Train net output #0: loss = 3.44044 (* 1 = 3.44044 loss)
I0826 11:11:47.251644  1343 sgd_solver.cpp:106] Iteration 66800, lr = 3.3257e-07
I0826 11:11:55.636118  1343 solver.cpp:228] Iteration 66900, loss = 3.4838
I0826 11:11:55.636183  1343 solver.cpp:244]     Train net output #0: loss = 3.4838 (* 1 = 3.4838 loss)
I0826 11:11:55.636193  1343 sgd_solver.cpp:106] Iteration 66900, lr = 3.32283e-07
I0826 11:12:04.050256  1343 solver.cpp:228] Iteration 67000, loss = 3.35025
I0826 11:12:04.050323  1343 solver.cpp:244]     Train net output #0: loss = 3.35025 (* 1 = 3.35025 loss)
I0826 11:12:04.050330  1343 sgd_solver.cpp:106] Iteration 67000, lr = 3.31996e-07
I0826 11:12:12.440207  1343 solver.cpp:228] Iteration 67100, loss = 3.57161
I0826 11:12:12.440276  1343 solver.cpp:244]     Train net output #0: loss = 3.57161 (* 1 = 3.57161 loss)
I0826 11:12:12.440286  1343 sgd_solver.cpp:106] Iteration 67100, lr = 3.3171e-07
I0826 11:12:20.858412  1343 solver.cpp:228] Iteration 67200, loss = 3.4603
I0826 11:12:20.858479  1343 solver.cpp:244]     Train net output #0: loss = 3.4603 (* 1 = 3.4603 loss)
I0826 11:12:20.858490  1343 sgd_solver.cpp:106] Iteration 67200, lr = 3.31425e-07
I0826 11:12:29.275274  1343 solver.cpp:228] Iteration 67300, loss = 3.5372
I0826 11:12:29.275338  1343 solver.cpp:244]     Train net output #0: loss = 3.5372 (* 1 = 3.5372 loss)
I0826 11:12:29.275357  1343 sgd_solver.cpp:106] Iteration 67300, lr = 3.3114e-07
I0826 11:12:37.680488  1343 solver.cpp:228] Iteration 67400, loss = 3.30828
I0826 11:12:37.680559  1343 solver.cpp:244]     Train net output #0: loss = 3.30828 (* 1 = 3.30828 loss)
I0826 11:12:37.680570  1343 sgd_solver.cpp:106] Iteration 67400, lr = 3.30856e-07
I0826 11:12:46.107570  1343 solver.cpp:228] Iteration 67500, loss = 3.36073
I0826 11:12:46.107642  1343 solver.cpp:244]     Train net output #0: loss = 3.36073 (* 1 = 3.36073 loss)
I0826 11:12:46.107657  1343 sgd_solver.cpp:106] Iteration 67500, lr = 3.30572e-07
I0826 11:12:54.511641  1343 solver.cpp:228] Iteration 67600, loss = 3.36911
I0826 11:12:54.511693  1343 solver.cpp:244]     Train net output #0: loss = 3.36911 (* 1 = 3.36911 loss)
I0826 11:12:54.511701  1343 sgd_solver.cpp:106] Iteration 67600, lr = 3.30289e-07
I0826 11:13:02.913805  1343 solver.cpp:228] Iteration 67700, loss = 3.28367
I0826 11:13:02.913869  1343 solver.cpp:244]     Train net output #0: loss = 3.28367 (* 1 = 3.28367 loss)
I0826 11:13:02.913879  1343 sgd_solver.cpp:106] Iteration 67700, lr = 3.30007e-07
I0826 11:13:11.337362  1343 solver.cpp:228] Iteration 67800, loss = 3.41051
I0826 11:13:11.337426  1343 solver.cpp:244]     Train net output #0: loss = 3.41051 (* 1 = 3.41051 loss)
I0826 11:13:11.337436  1343 sgd_solver.cpp:106] Iteration 67800, lr = 3.29725e-07
I0826 11:13:19.736680  1343 solver.cpp:228] Iteration 67900, loss = 3.26374
I0826 11:13:19.736752  1343 solver.cpp:244]     Train net output #0: loss = 3.26374 (* 1 = 3.26374 loss)
I0826 11:13:19.736760  1343 sgd_solver.cpp:106] Iteration 67900, lr = 3.29443e-07
I0826 11:13:28.155501  1343 solver.cpp:228] Iteration 68000, loss = 3.45054
I0826 11:13:28.155563  1343 solver.cpp:244]     Train net output #0: loss = 3.45054 (* 1 = 3.45054 loss)
I0826 11:13:28.155575  1343 sgd_solver.cpp:106] Iteration 68000, lr = 3.29163e-07
I0826 11:13:36.573047  1343 solver.cpp:228] Iteration 68100, loss = 3.4684
I0826 11:13:36.573117  1343 solver.cpp:244]     Train net output #0: loss = 3.4684 (* 1 = 3.4684 loss)
I0826 11:13:36.573128  1343 sgd_solver.cpp:106] Iteration 68100, lr = 3.28882e-07
I0826 11:13:44.979578  1343 solver.cpp:228] Iteration 68200, loss = 3.4495
I0826 11:13:44.979640  1343 solver.cpp:244]     Train net output #0: loss = 3.4495 (* 1 = 3.4495 loss)
I0826 11:13:44.979655  1343 sgd_solver.cpp:106] Iteration 68200, lr = 3.28603e-07
I0826 11:13:53.399782  1343 solver.cpp:228] Iteration 68300, loss = 3.59949
I0826 11:13:53.399850  1343 solver.cpp:244]     Train net output #0: loss = 3.59949 (* 1 = 3.59949 loss)
I0826 11:13:53.399859  1343 sgd_solver.cpp:106] Iteration 68300, lr = 3.28323e-07
I0826 11:14:01.826740  1343 solver.cpp:228] Iteration 68400, loss = 3.40765
I0826 11:14:01.826799  1343 solver.cpp:244]     Train net output #0: loss = 3.40765 (* 1 = 3.40765 loss)
I0826 11:14:01.826807  1343 sgd_solver.cpp:106] Iteration 68400, lr = 3.28045e-07
I0826 11:14:10.246397  1343 solver.cpp:228] Iteration 68500, loss = 3.4474
I0826 11:14:10.246443  1343 solver.cpp:244]     Train net output #0: loss = 3.4474 (* 1 = 3.4474 loss)
I0826 11:14:10.246449  1343 sgd_solver.cpp:106] Iteration 68500, lr = 3.27767e-07
I0826 11:14:18.644228  1343 solver.cpp:228] Iteration 68600, loss = 3.39331
I0826 11:14:18.644295  1343 solver.cpp:244]     Train net output #0: loss = 3.39331 (* 1 = 3.39331 loss)
I0826 11:14:18.644304  1343 sgd_solver.cpp:106] Iteration 68600, lr = 3.27489e-07
I0826 11:14:27.070811  1343 solver.cpp:228] Iteration 68700, loss = 3.51957
I0826 11:14:27.070855  1343 solver.cpp:244]     Train net output #0: loss = 3.51957 (* 1 = 3.51957 loss)
I0826 11:14:27.070860  1343 sgd_solver.cpp:106] Iteration 68700, lr = 3.27212e-07
I0826 11:14:35.476609  1343 solver.cpp:228] Iteration 68800, loss = 3.45502
I0826 11:14:35.476671  1343 solver.cpp:244]     Train net output #0: loss = 3.45502 (* 1 = 3.45502 loss)
I0826 11:14:35.476680  1343 sgd_solver.cpp:106] Iteration 68800, lr = 3.26936e-07
I0826 11:14:43.883160  1343 solver.cpp:228] Iteration 68900, loss = 3.40871
I0826 11:14:43.883249  1343 solver.cpp:244]     Train net output #0: loss = 3.40871 (* 1 = 3.40871 loss)
I0826 11:14:43.883265  1343 sgd_solver.cpp:106] Iteration 68900, lr = 3.2666e-07
I0826 11:14:52.288897  1343 solver.cpp:228] Iteration 69000, loss = 3.32025
I0826 11:14:52.288954  1343 solver.cpp:244]     Train net output #0: loss = 3.32025 (* 1 = 3.32025 loss)
I0826 11:14:52.288962  1343 sgd_solver.cpp:106] Iteration 69000, lr = 3.26385e-07
I0826 11:15:00.697284  1343 solver.cpp:228] Iteration 69100, loss = 3.52668
I0826 11:15:00.697340  1343 solver.cpp:244]     Train net output #0: loss = 3.52668 (* 1 = 3.52668 loss)
I0826 11:15:00.697347  1343 sgd_solver.cpp:106] Iteration 69100, lr = 3.2611e-07
I0826 11:15:03.307602  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:15:09.118139  1343 solver.cpp:228] Iteration 69200, loss = 3.43211
I0826 11:15:09.118211  1343 solver.cpp:244]     Train net output #0: loss = 3.43211 (* 1 = 3.43211 loss)
I0826 11:15:09.118229  1343 sgd_solver.cpp:106] Iteration 69200, lr = 3.25836e-07
I0826 11:15:17.525174  1343 solver.cpp:228] Iteration 69300, loss = 3.51846
I0826 11:15:17.525220  1343 solver.cpp:244]     Train net output #0: loss = 3.51846 (* 1 = 3.51846 loss)
I0826 11:15:17.525225  1343 sgd_solver.cpp:106] Iteration 69300, lr = 3.25562e-07
I0826 11:15:25.946234  1343 solver.cpp:228] Iteration 69400, loss = 3.34354
I0826 11:15:25.946308  1343 solver.cpp:244]     Train net output #0: loss = 3.34354 (* 1 = 3.34354 loss)
I0826 11:15:25.946321  1343 sgd_solver.cpp:106] Iteration 69400, lr = 3.25289e-07
I0826 11:15:34.362886  1343 solver.cpp:228] Iteration 69500, loss = 3.52743
I0826 11:15:34.362942  1343 solver.cpp:244]     Train net output #0: loss = 3.52743 (* 1 = 3.52743 loss)
I0826 11:15:34.362953  1343 sgd_solver.cpp:106] Iteration 69500, lr = 3.25016e-07
I0826 11:15:42.781896  1343 solver.cpp:228] Iteration 69600, loss = 3.34645
I0826 11:15:42.781966  1343 solver.cpp:244]     Train net output #0: loss = 3.34645 (* 1 = 3.34645 loss)
I0826 11:15:42.781980  1343 sgd_solver.cpp:106] Iteration 69600, lr = 3.24744e-07
I0826 11:15:51.187182  1343 solver.cpp:228] Iteration 69700, loss = 3.31963
I0826 11:15:51.187255  1343 solver.cpp:244]     Train net output #0: loss = 3.31963 (* 1 = 3.31963 loss)
I0826 11:15:51.187271  1343 sgd_solver.cpp:106] Iteration 69700, lr = 3.24473e-07
I0826 11:15:59.604828  1343 solver.cpp:228] Iteration 69800, loss = 3.38562
I0826 11:15:59.604882  1343 solver.cpp:244]     Train net output #0: loss = 3.38562 (* 1 = 3.38562 loss)
I0826 11:15:59.604890  1343 sgd_solver.cpp:106] Iteration 69800, lr = 3.24202e-07
I0826 11:16:08.018851  1343 solver.cpp:228] Iteration 69900, loss = 3.46181
I0826 11:16:08.018908  1343 solver.cpp:244]     Train net output #0: loss = 3.46181 (* 1 = 3.46181 loss)
I0826 11:16:08.018914  1343 sgd_solver.cpp:106] Iteration 69900, lr = 3.23931e-07
I0826 11:16:16.359359  1343 solver.cpp:337] Iteration 70000, Testing net (#0)
I0826 11:16:53.380240  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302045
I0826 11:16:53.380295  1343 solver.cpp:404]     Test net output #1: loss = 3.46281 (* 1 = 3.46281 loss)
I0826 11:16:53.410291  1343 solver.cpp:228] Iteration 70000, loss = 3.63873
I0826 11:16:53.410315  1343 solver.cpp:244]     Train net output #0: loss = 3.63873 (* 1 = 3.63873 loss)
I0826 11:16:53.410326  1343 sgd_solver.cpp:106] Iteration 70000, lr = 3.23661e-07
I0826 11:17:01.834450  1343 solver.cpp:228] Iteration 70100, loss = 3.53898
I0826 11:17:01.834496  1343 solver.cpp:244]     Train net output #0: loss = 3.53898 (* 1 = 3.53898 loss)
I0826 11:17:01.834501  1343 sgd_solver.cpp:106] Iteration 70100, lr = 3.23392e-07
I0826 11:17:04.453583  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:17:10.251560  1343 solver.cpp:228] Iteration 70200, loss = 3.52589
I0826 11:17:10.251633  1343 solver.cpp:244]     Train net output #0: loss = 3.52589 (* 1 = 3.52589 loss)
I0826 11:17:10.251649  1343 sgd_solver.cpp:106] Iteration 70200, lr = 3.23123e-07
I0826 11:17:18.681112  1343 solver.cpp:228] Iteration 70300, loss = 3.47237
I0826 11:17:18.681179  1343 solver.cpp:244]     Train net output #0: loss = 3.47237 (* 1 = 3.47237 loss)
I0826 11:17:18.681190  1343 sgd_solver.cpp:106] Iteration 70300, lr = 3.22854e-07
I0826 11:17:27.104101  1343 solver.cpp:228] Iteration 70400, loss = 3.44156
I0826 11:17:27.104147  1343 solver.cpp:244]     Train net output #0: loss = 3.44156 (* 1 = 3.44156 loss)
I0826 11:17:27.104152  1343 sgd_solver.cpp:106] Iteration 70400, lr = 3.22586e-07
I0826 11:17:35.497962  1343 solver.cpp:228] Iteration 70500, loss = 3.51027
I0826 11:17:35.498014  1343 solver.cpp:244]     Train net output #0: loss = 3.51027 (* 1 = 3.51027 loss)
I0826 11:17:35.498021  1343 sgd_solver.cpp:106] Iteration 70500, lr = 3.22319e-07
I0826 11:17:43.928191  1343 solver.cpp:228] Iteration 70600, loss = 3.52009
I0826 11:17:43.928257  1343 solver.cpp:244]     Train net output #0: loss = 3.52009 (* 1 = 3.52009 loss)
I0826 11:17:43.928272  1343 sgd_solver.cpp:106] Iteration 70600, lr = 3.22052e-07
I0826 11:17:52.353657  1343 solver.cpp:228] Iteration 70700, loss = 3.31251
I0826 11:17:52.353713  1343 solver.cpp:244]     Train net output #0: loss = 3.31251 (* 1 = 3.31251 loss)
I0826 11:17:52.353725  1343 sgd_solver.cpp:106] Iteration 70700, lr = 3.21786e-07
I0826 11:18:00.775745  1343 solver.cpp:228] Iteration 70800, loss = 3.51347
I0826 11:18:00.775790  1343 solver.cpp:244]     Train net output #0: loss = 3.51347 (* 1 = 3.51347 loss)
I0826 11:18:00.775796  1343 sgd_solver.cpp:106] Iteration 70800, lr = 3.2152e-07
I0826 11:18:09.181124  1343 solver.cpp:228] Iteration 70900, loss = 3.4606
I0826 11:18:09.181171  1343 solver.cpp:244]     Train net output #0: loss = 3.4606 (* 1 = 3.4606 loss)
I0826 11:18:09.181180  1343 sgd_solver.cpp:106] Iteration 70900, lr = 3.21255e-07
I0826 11:18:17.602484  1343 solver.cpp:228] Iteration 71000, loss = 3.49582
I0826 11:18:17.602553  1343 solver.cpp:244]     Train net output #0: loss = 3.49582 (* 1 = 3.49582 loss)
I0826 11:18:17.602563  1343 sgd_solver.cpp:106] Iteration 71000, lr = 3.2099e-07
I0826 11:18:26.033236  1343 solver.cpp:228] Iteration 71100, loss = 3.49665
I0826 11:18:26.033301  1343 solver.cpp:244]     Train net output #0: loss = 3.49665 (* 1 = 3.49665 loss)
I0826 11:18:26.033310  1343 sgd_solver.cpp:106] Iteration 71100, lr = 3.20726e-07
I0826 11:18:34.425659  1343 solver.cpp:228] Iteration 71200, loss = 3.58132
I0826 11:18:34.425730  1343 solver.cpp:244]     Train net output #0: loss = 3.58132 (* 1 = 3.58132 loss)
I0826 11:18:34.425737  1343 sgd_solver.cpp:106] Iteration 71200, lr = 3.20462e-07
I0826 11:18:42.843780  1343 solver.cpp:228] Iteration 71300, loss = 3.23011
I0826 11:18:42.843835  1343 solver.cpp:244]     Train net output #0: loss = 3.23011 (* 1 = 3.23011 loss)
I0826 11:18:42.843845  1343 sgd_solver.cpp:106] Iteration 71300, lr = 3.20199e-07
I0826 11:18:51.256803  1343 solver.cpp:228] Iteration 71400, loss = 3.34307
I0826 11:18:51.256866  1343 solver.cpp:244]     Train net output #0: loss = 3.34307 (* 1 = 3.34307 loss)
I0826 11:18:51.256875  1343 sgd_solver.cpp:106] Iteration 71400, lr = 3.19936e-07
I0826 11:18:59.673009  1343 solver.cpp:228] Iteration 71500, loss = 3.37847
I0826 11:18:59.673056  1343 solver.cpp:244]     Train net output #0: loss = 3.37847 (* 1 = 3.37847 loss)
I0826 11:18:59.673061  1343 sgd_solver.cpp:106] Iteration 71500, lr = 3.19674e-07
I0826 11:19:08.085533  1343 solver.cpp:228] Iteration 71600, loss = 3.50142
I0826 11:19:08.085598  1343 solver.cpp:244]     Train net output #0: loss = 3.50142 (* 1 = 3.50142 loss)
I0826 11:19:08.085608  1343 sgd_solver.cpp:106] Iteration 71600, lr = 3.19412e-07
I0826 11:19:16.505273  1343 solver.cpp:228] Iteration 71700, loss = 3.47375
I0826 11:19:16.505336  1343 solver.cpp:244]     Train net output #0: loss = 3.47375 (* 1 = 3.47375 loss)
I0826 11:19:16.505347  1343 sgd_solver.cpp:106] Iteration 71700, lr = 3.1915e-07
I0826 11:19:24.918551  1343 solver.cpp:228] Iteration 71800, loss = 3.40318
I0826 11:19:24.918617  1343 solver.cpp:244]     Train net output #0: loss = 3.40318 (* 1 = 3.40318 loss)
I0826 11:19:24.918634  1343 sgd_solver.cpp:106] Iteration 71800, lr = 3.1889e-07
I0826 11:19:33.339820  1343 solver.cpp:228] Iteration 71900, loss = 3.25477
I0826 11:19:33.339887  1343 solver.cpp:244]     Train net output #0: loss = 3.25477 (* 1 = 3.25477 loss)
I0826 11:19:33.339898  1343 sgd_solver.cpp:106] Iteration 71900, lr = 3.18629e-07
I0826 11:19:41.774513  1343 solver.cpp:228] Iteration 72000, loss = 3.52946
I0826 11:19:41.774574  1343 solver.cpp:244]     Train net output #0: loss = 3.52946 (* 1 = 3.52946 loss)
I0826 11:19:41.774587  1343 sgd_solver.cpp:106] Iteration 72000, lr = 3.1837e-07
I0826 11:19:50.190345  1343 solver.cpp:228] Iteration 72100, loss = 3.51614
I0826 11:19:50.190389  1343 solver.cpp:244]     Train net output #0: loss = 3.51614 (* 1 = 3.51614 loss)
I0826 11:19:50.190397  1343 sgd_solver.cpp:106] Iteration 72100, lr = 3.1811e-07
I0826 11:19:58.606966  1343 solver.cpp:228] Iteration 72200, loss = 3.41855
I0826 11:19:58.607026  1343 solver.cpp:244]     Train net output #0: loss = 3.41855 (* 1 = 3.41855 loss)
I0826 11:19:58.607034  1343 sgd_solver.cpp:106] Iteration 72200, lr = 3.17852e-07
I0826 11:20:07.007526  1343 solver.cpp:228] Iteration 72300, loss = 3.44112
I0826 11:20:07.007594  1343 solver.cpp:244]     Train net output #0: loss = 3.44112 (* 1 = 3.44112 loss)
I0826 11:20:07.007606  1343 sgd_solver.cpp:106] Iteration 72300, lr = 3.17593e-07
I0826 11:20:15.429153  1343 solver.cpp:228] Iteration 72400, loss = 3.46072
I0826 11:20:15.429234  1343 solver.cpp:244]     Train net output #0: loss = 3.46072 (* 1 = 3.46072 loss)
I0826 11:20:15.429246  1343 sgd_solver.cpp:106] Iteration 72400, lr = 3.17335e-07
I0826 11:20:23.823318  1343 solver.cpp:228] Iteration 72500, loss = 3.52595
I0826 11:20:23.823366  1343 solver.cpp:244]     Train net output #0: loss = 3.52595 (* 1 = 3.52595 loss)
I0826 11:20:23.823371  1343 sgd_solver.cpp:106] Iteration 72500, lr = 3.17078e-07
I0826 11:20:32.245817  1343 solver.cpp:228] Iteration 72600, loss = 3.33921
I0826 11:20:32.245894  1343 solver.cpp:244]     Train net output #0: loss = 3.33921 (* 1 = 3.33921 loss)
I0826 11:20:32.245910  1343 sgd_solver.cpp:106] Iteration 72600, lr = 3.16821e-07
I0826 11:20:40.644707  1343 solver.cpp:228] Iteration 72700, loss = 3.61168
I0826 11:20:40.644774  1343 solver.cpp:244]     Train net output #0: loss = 3.61168 (* 1 = 3.61168 loss)
I0826 11:20:40.644783  1343 sgd_solver.cpp:106] Iteration 72700, lr = 3.16565e-07
I0826 11:20:49.059365  1343 solver.cpp:228] Iteration 72800, loss = 3.37327
I0826 11:20:49.059433  1343 solver.cpp:244]     Train net output #0: loss = 3.37327 (* 1 = 3.37327 loss)
I0826 11:20:49.059448  1343 sgd_solver.cpp:106] Iteration 72800, lr = 3.16309e-07
I0826 11:20:57.484452  1343 solver.cpp:228] Iteration 72900, loss = 3.58587
I0826 11:20:57.484513  1343 solver.cpp:244]     Train net output #0: loss = 3.58587 (* 1 = 3.58587 loss)
I0826 11:20:57.484526  1343 sgd_solver.cpp:106] Iteration 72900, lr = 3.16054e-07
I0826 11:21:05.917651  1343 solver.cpp:228] Iteration 73000, loss = 3.51409
I0826 11:21:05.917695  1343 solver.cpp:244]     Train net output #0: loss = 3.51409 (* 1 = 3.51409 loss)
I0826 11:21:05.917701  1343 sgd_solver.cpp:106] Iteration 73000, lr = 3.15799e-07
I0826 11:21:14.335556  1343 solver.cpp:228] Iteration 73100, loss = 3.51198
I0826 11:21:14.335615  1343 solver.cpp:244]     Train net output #0: loss = 3.51198 (* 1 = 3.51198 loss)
I0826 11:21:14.335623  1343 sgd_solver.cpp:106] Iteration 73100, lr = 3.15544e-07
I0826 11:21:22.743809  1343 solver.cpp:228] Iteration 73200, loss = 3.41119
I0826 11:21:22.743880  1343 solver.cpp:244]     Train net output #0: loss = 3.41119 (* 1 = 3.41119 loss)
I0826 11:21:22.743894  1343 sgd_solver.cpp:106] Iteration 73200, lr = 3.1529e-07
I0826 11:21:31.169811  1343 solver.cpp:228] Iteration 73300, loss = 3.56358
I0826 11:21:31.169872  1343 solver.cpp:244]     Train net output #0: loss = 3.56358 (* 1 = 3.56358 loss)
I0826 11:21:31.169880  1343 sgd_solver.cpp:106] Iteration 73300, lr = 3.15037e-07
I0826 11:21:39.595211  1343 solver.cpp:228] Iteration 73400, loss = 3.52704
I0826 11:21:39.595265  1343 solver.cpp:244]     Train net output #0: loss = 3.52704 (* 1 = 3.52704 loss)
I0826 11:21:39.595273  1343 sgd_solver.cpp:106] Iteration 73400, lr = 3.14784e-07
I0826 11:21:48.019258  1343 solver.cpp:228] Iteration 73500, loss = 3.30361
I0826 11:21:48.019318  1343 solver.cpp:244]     Train net output #0: loss = 3.30361 (* 1 = 3.30361 loss)
I0826 11:21:48.019327  1343 sgd_solver.cpp:106] Iteration 73500, lr = 3.14531e-07
I0826 11:21:56.445451  1343 solver.cpp:228] Iteration 73600, loss = 3.49674
I0826 11:21:56.445513  1343 solver.cpp:244]     Train net output #0: loss = 3.49674 (* 1 = 3.49674 loss)
I0826 11:21:56.445524  1343 sgd_solver.cpp:106] Iteration 73600, lr = 3.14279e-07
I0826 11:22:04.866924  1343 solver.cpp:228] Iteration 73700, loss = 3.36284
I0826 11:22:04.866997  1343 solver.cpp:244]     Train net output #0: loss = 3.36284 (* 1 = 3.36284 loss)
I0826 11:22:04.867007  1343 sgd_solver.cpp:106] Iteration 73700, lr = 3.14028e-07
I0826 11:22:13.289602  1343 solver.cpp:228] Iteration 73800, loss = 3.51478
I0826 11:22:13.289669  1343 solver.cpp:244]     Train net output #0: loss = 3.51478 (* 1 = 3.51478 loss)
I0826 11:22:13.289682  1343 sgd_solver.cpp:106] Iteration 73800, lr = 3.13776e-07
I0826 11:22:17.659273  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:22:21.711742  1343 solver.cpp:228] Iteration 73900, loss = 3.43369
I0826 11:22:21.711799  1343 solver.cpp:244]     Train net output #0: loss = 3.43369 (* 1 = 3.43369 loss)
I0826 11:22:21.711807  1343 sgd_solver.cpp:106] Iteration 73900, lr = 3.13526e-07
I0826 11:22:30.109818  1343 solver.cpp:228] Iteration 74000, loss = 3.44829
I0826 11:22:30.109860  1343 solver.cpp:244]     Train net output #0: loss = 3.44829 (* 1 = 3.44829 loss)
I0826 11:22:30.109866  1343 sgd_solver.cpp:106] Iteration 74000, lr = 3.13276e-07
I0826 11:22:38.528429  1343 solver.cpp:228] Iteration 74100, loss = 3.41324
I0826 11:22:38.528481  1343 solver.cpp:244]     Train net output #0: loss = 3.41324 (* 1 = 3.41324 loss)
I0826 11:22:38.528488  1343 sgd_solver.cpp:106] Iteration 74100, lr = 3.13026e-07
I0826 11:22:46.946358  1343 solver.cpp:228] Iteration 74200, loss = 3.50722
I0826 11:22:46.946426  1343 solver.cpp:244]     Train net output #0: loss = 3.50722 (* 1 = 3.50722 loss)
I0826 11:22:46.946435  1343 sgd_solver.cpp:106] Iteration 74200, lr = 3.12777e-07
I0826 11:22:55.365233  1343 solver.cpp:228] Iteration 74300, loss = 3.29667
I0826 11:22:55.365290  1343 solver.cpp:244]     Train net output #0: loss = 3.29667 (* 1 = 3.29667 loss)
I0826 11:22:55.365301  1343 sgd_solver.cpp:106] Iteration 74300, lr = 3.12528e-07
I0826 11:23:03.794273  1343 solver.cpp:228] Iteration 74400, loss = 3.54934
I0826 11:23:03.794342  1343 solver.cpp:244]     Train net output #0: loss = 3.54934 (* 1 = 3.54934 loss)
I0826 11:23:03.794353  1343 sgd_solver.cpp:106] Iteration 74400, lr = 3.1228e-07
I0826 11:23:12.214488  1343 solver.cpp:228] Iteration 74500, loss = 3.53744
I0826 11:23:12.214545  1343 solver.cpp:244]     Train net output #0: loss = 3.53744 (* 1 = 3.53744 loss)
I0826 11:23:12.214555  1343 sgd_solver.cpp:106] Iteration 74500, lr = 3.12032e-07
I0826 11:23:20.636514  1343 solver.cpp:228] Iteration 74600, loss = 3.60833
I0826 11:23:20.636569  1343 solver.cpp:244]     Train net output #0: loss = 3.60833 (* 1 = 3.60833 loss)
I0826 11:23:20.636577  1343 sgd_solver.cpp:106] Iteration 74600, lr = 3.11784e-07
I0826 11:23:29.045255  1343 solver.cpp:228] Iteration 74700, loss = 3.4908
I0826 11:23:29.045310  1343 solver.cpp:244]     Train net output #0: loss = 3.4908 (* 1 = 3.4908 loss)
I0826 11:23:29.045316  1343 sgd_solver.cpp:106] Iteration 74700, lr = 3.11537e-07
I0826 11:23:37.463217  1343 solver.cpp:228] Iteration 74800, loss = 3.34585
I0826 11:23:37.463259  1343 solver.cpp:244]     Train net output #0: loss = 3.34585 (* 1 = 3.34585 loss)
I0826 11:23:37.463265  1343 sgd_solver.cpp:106] Iteration 74800, lr = 3.11291e-07
I0826 11:23:45.882315  1343 solver.cpp:228] Iteration 74900, loss = 3.42007
I0826 11:23:45.882375  1343 solver.cpp:244]     Train net output #0: loss = 3.42007 (* 1 = 3.42007 loss)
I0826 11:23:45.882386  1343 sgd_solver.cpp:106] Iteration 74900, lr = 3.11045e-07
I0826 11:23:54.213933  1343 solver.cpp:337] Iteration 75000, Testing net (#0)
I0826 11:24:20.873425  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:24:32.037456  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302051
I0826 11:24:32.037521  1343 solver.cpp:404]     Test net output #1: loss = 3.45868 (* 1 = 3.45868 loss)
I0826 11:24:32.067723  1343 solver.cpp:228] Iteration 75000, loss = 3.27962
I0826 11:24:32.067770  1343 solver.cpp:244]     Train net output #0: loss = 3.27962 (* 1 = 3.27962 loss)
I0826 11:24:32.067785  1343 sgd_solver.cpp:106] Iteration 75000, lr = 3.10799e-07
I0826 11:24:40.484786  1343 solver.cpp:228] Iteration 75100, loss = 3.41224
I0826 11:24:40.484863  1343 solver.cpp:244]     Train net output #0: loss = 3.41224 (* 1 = 3.41224 loss)
I0826 11:24:40.484874  1343 sgd_solver.cpp:106] Iteration 75100, lr = 3.10554e-07
I0826 11:24:48.911160  1343 solver.cpp:228] Iteration 75200, loss = 3.52869
I0826 11:24:48.911217  1343 solver.cpp:244]     Train net output #0: loss = 3.52869 (* 1 = 3.52869 loss)
I0826 11:24:48.911224  1343 sgd_solver.cpp:106] Iteration 75200, lr = 3.10309e-07
I0826 11:24:57.312230  1343 solver.cpp:228] Iteration 75300, loss = 3.58217
I0826 11:24:57.312292  1343 solver.cpp:244]     Train net output #0: loss = 3.58217 (* 1 = 3.58217 loss)
I0826 11:24:57.312302  1343 sgd_solver.cpp:106] Iteration 75300, lr = 3.10065e-07
I0826 11:25:05.731542  1343 solver.cpp:228] Iteration 75400, loss = 3.452
I0826 11:25:05.731606  1343 solver.cpp:244]     Train net output #0: loss = 3.452 (* 1 = 3.452 loss)
I0826 11:25:05.731621  1343 sgd_solver.cpp:106] Iteration 75400, lr = 3.09821e-07
I0826 11:25:14.138891  1343 solver.cpp:228] Iteration 75500, loss = 3.49801
I0826 11:25:14.138970  1343 solver.cpp:244]     Train net output #0: loss = 3.49801 (* 1 = 3.49801 loss)
I0826 11:25:14.138979  1343 sgd_solver.cpp:106] Iteration 75500, lr = 3.09578e-07
I0826 11:25:22.541890  1343 solver.cpp:228] Iteration 75600, loss = 3.34601
I0826 11:25:22.541934  1343 solver.cpp:244]     Train net output #0: loss = 3.34601 (* 1 = 3.34601 loss)
I0826 11:25:22.541939  1343 sgd_solver.cpp:106] Iteration 75600, lr = 3.09335e-07
I0826 11:25:30.950911  1343 solver.cpp:228] Iteration 75700, loss = 3.39624
I0826 11:25:30.950953  1343 solver.cpp:244]     Train net output #0: loss = 3.39624 (* 1 = 3.39624 loss)
I0826 11:25:30.950958  1343 sgd_solver.cpp:106] Iteration 75700, lr = 3.09093e-07
I0826 11:25:39.346930  1343 solver.cpp:228] Iteration 75800, loss = 3.30854
I0826 11:25:39.346992  1343 solver.cpp:244]     Train net output #0: loss = 3.30854 (* 1 = 3.30854 loss)
I0826 11:25:39.347002  1343 sgd_solver.cpp:106] Iteration 75800, lr = 3.08851e-07
I0826 11:25:47.762609  1343 solver.cpp:228] Iteration 75900, loss = 3.47674
I0826 11:25:47.762676  1343 solver.cpp:244]     Train net output #0: loss = 3.47674 (* 1 = 3.47674 loss)
I0826 11:25:47.762684  1343 sgd_solver.cpp:106] Iteration 75900, lr = 3.08609e-07
I0826 11:25:56.172161  1343 solver.cpp:228] Iteration 76000, loss = 3.42516
I0826 11:25:56.172235  1343 solver.cpp:244]     Train net output #0: loss = 3.42516 (* 1 = 3.42516 loss)
I0826 11:25:56.172245  1343 sgd_solver.cpp:106] Iteration 76000, lr = 3.08368e-07
I0826 11:26:04.571873  1343 solver.cpp:228] Iteration 76100, loss = 3.46315
I0826 11:26:04.571956  1343 solver.cpp:244]     Train net output #0: loss = 3.46315 (* 1 = 3.46315 loss)
I0826 11:26:04.571975  1343 sgd_solver.cpp:106] Iteration 76100, lr = 3.08127e-07
I0826 11:26:13.002323  1343 solver.cpp:228] Iteration 76200, loss = 3.40685
I0826 11:26:13.002384  1343 solver.cpp:244]     Train net output #0: loss = 3.40685 (* 1 = 3.40685 loss)
I0826 11:26:13.002395  1343 sgd_solver.cpp:106] Iteration 76200, lr = 3.07887e-07
I0826 11:26:21.414108  1343 solver.cpp:228] Iteration 76300, loss = 3.33056
I0826 11:26:21.414175  1343 solver.cpp:244]     Train net output #0: loss = 3.33056 (* 1 = 3.33056 loss)
I0826 11:26:21.414186  1343 sgd_solver.cpp:106] Iteration 76300, lr = 3.07647e-07
I0826 11:26:29.822690  1343 solver.cpp:228] Iteration 76400, loss = 3.48962
I0826 11:26:29.822779  1343 solver.cpp:244]     Train net output #0: loss = 3.48962 (* 1 = 3.48962 loss)
I0826 11:26:29.822793  1343 sgd_solver.cpp:106] Iteration 76400, lr = 3.07408e-07
I0826 11:26:38.241765  1343 solver.cpp:228] Iteration 76500, loss = 3.57278
I0826 11:26:38.241835  1343 solver.cpp:244]     Train net output #0: loss = 3.57278 (* 1 = 3.57278 loss)
I0826 11:26:38.241845  1343 sgd_solver.cpp:106] Iteration 76500, lr = 3.07169e-07
I0826 11:26:46.647023  1343 solver.cpp:228] Iteration 76600, loss = 3.47323
I0826 11:26:46.647068  1343 solver.cpp:244]     Train net output #0: loss = 3.47323 (* 1 = 3.47323 loss)
I0826 11:26:46.647074  1343 sgd_solver.cpp:106] Iteration 76600, lr = 3.0693e-07
I0826 11:26:55.062927  1343 solver.cpp:228] Iteration 76700, loss = 3.51734
I0826 11:26:55.063001  1343 solver.cpp:244]     Train net output #0: loss = 3.51734 (* 1 = 3.51734 loss)
I0826 11:26:55.063010  1343 sgd_solver.cpp:106] Iteration 76700, lr = 3.06692e-07
I0826 11:27:03.494596  1343 solver.cpp:228] Iteration 76800, loss = 3.41665
I0826 11:27:03.494642  1343 solver.cpp:244]     Train net output #0: loss = 3.41665 (* 1 = 3.41665 loss)
I0826 11:27:03.494647  1343 sgd_solver.cpp:106] Iteration 76800, lr = 3.06454e-07
I0826 11:27:11.918754  1343 solver.cpp:228] Iteration 76900, loss = 3.629
I0826 11:27:11.918817  1343 solver.cpp:244]     Train net output #0: loss = 3.629 (* 1 = 3.629 loss)
I0826 11:27:11.918828  1343 sgd_solver.cpp:106] Iteration 76900, lr = 3.06217e-07
I0826 11:27:20.319542  1343 solver.cpp:228] Iteration 77000, loss = 3.456
I0826 11:27:20.319589  1343 solver.cpp:244]     Train net output #0: loss = 3.456 (* 1 = 3.456 loss)
I0826 11:27:20.319594  1343 sgd_solver.cpp:106] Iteration 77000, lr = 3.0598e-07
I0826 11:27:28.740470  1343 solver.cpp:228] Iteration 77100, loss = 3.51886
I0826 11:27:28.740537  1343 solver.cpp:244]     Train net output #0: loss = 3.51886 (* 1 = 3.51886 loss)
I0826 11:27:28.740550  1343 sgd_solver.cpp:106] Iteration 77100, lr = 3.05744e-07
I0826 11:27:37.163090  1343 solver.cpp:228] Iteration 77200, loss = 3.53948
I0826 11:27:37.163142  1343 solver.cpp:244]     Train net output #0: loss = 3.53948 (* 1 = 3.53948 loss)
I0826 11:27:37.163151  1343 sgd_solver.cpp:106] Iteration 77200, lr = 3.05508e-07
I0826 11:27:45.582022  1343 solver.cpp:228] Iteration 77300, loss = 3.57598
I0826 11:27:45.582077  1343 solver.cpp:244]     Train net output #0: loss = 3.57598 (* 1 = 3.57598 loss)
I0826 11:27:45.582083  1343 sgd_solver.cpp:106] Iteration 77300, lr = 3.05273e-07
I0826 11:27:54.001628  1343 solver.cpp:228] Iteration 77400, loss = 3.51668
I0826 11:27:54.001703  1343 solver.cpp:244]     Train net output #0: loss = 3.51668 (* 1 = 3.51668 loss)
I0826 11:27:54.001715  1343 sgd_solver.cpp:106] Iteration 77400, lr = 3.05038e-07
I0826 11:28:02.432711  1343 solver.cpp:228] Iteration 77500, loss = 3.47125
I0826 11:28:02.432781  1343 solver.cpp:244]     Train net output #0: loss = 3.47125 (* 1 = 3.47125 loss)
I0826 11:28:02.432792  1343 sgd_solver.cpp:106] Iteration 77500, lr = 3.04803e-07
I0826 11:28:10.852309  1343 solver.cpp:228] Iteration 77600, loss = 3.60892
I0826 11:28:10.852372  1343 solver.cpp:244]     Train net output #0: loss = 3.60892 (* 1 = 3.60892 loss)
I0826 11:28:10.852386  1343 sgd_solver.cpp:106] Iteration 77600, lr = 3.04569e-07
I0826 11:28:19.253723  1343 solver.cpp:228] Iteration 77700, loss = 3.39156
I0826 11:28:19.253793  1343 solver.cpp:244]     Train net output #0: loss = 3.39156 (* 1 = 3.39156 loss)
I0826 11:28:19.253801  1343 sgd_solver.cpp:106] Iteration 77700, lr = 3.04335e-07
I0826 11:28:27.676152  1343 solver.cpp:228] Iteration 77800, loss = 3.36272
I0826 11:28:27.676220  1343 solver.cpp:244]     Train net output #0: loss = 3.36272 (* 1 = 3.36272 loss)
I0826 11:28:27.676229  1343 sgd_solver.cpp:106] Iteration 77800, lr = 3.04101e-07
I0826 11:28:36.103338  1343 solver.cpp:228] Iteration 77900, loss = 3.47666
I0826 11:28:36.103407  1343 solver.cpp:244]     Train net output #0: loss = 3.47666 (* 1 = 3.47666 loss)
I0826 11:28:36.103417  1343 sgd_solver.cpp:106] Iteration 77900, lr = 3.03868e-07
I0826 11:28:44.513782  1343 solver.cpp:228] Iteration 78000, loss = 3.55911
I0826 11:28:44.513849  1343 solver.cpp:244]     Train net output #0: loss = 3.55911 (* 1 = 3.55911 loss)
I0826 11:28:44.513860  1343 sgd_solver.cpp:106] Iteration 78000, lr = 3.03636e-07
I0826 11:28:47.705711  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:28:52.921937  1343 solver.cpp:228] Iteration 78100, loss = 3.47605
I0826 11:28:52.921998  1343 solver.cpp:244]     Train net output #0: loss = 3.47605 (* 1 = 3.47605 loss)
I0826 11:28:52.922010  1343 sgd_solver.cpp:106] Iteration 78100, lr = 3.03404e-07
I0826 11:29:01.349092  1343 solver.cpp:228] Iteration 78200, loss = 3.57633
I0826 11:29:01.349160  1343 solver.cpp:244]     Train net output #0: loss = 3.57633 (* 1 = 3.57633 loss)
I0826 11:29:01.349174  1343 sgd_solver.cpp:106] Iteration 78200, lr = 3.03172e-07
I0826 11:29:09.762796  1343 solver.cpp:228] Iteration 78300, loss = 3.4883
I0826 11:29:09.762836  1343 solver.cpp:244]     Train net output #0: loss = 3.4883 (* 1 = 3.4883 loss)
I0826 11:29:09.762842  1343 sgd_solver.cpp:106] Iteration 78300, lr = 3.02941e-07
I0826 11:29:18.157874  1343 solver.cpp:228] Iteration 78400, loss = 3.38637
I0826 11:29:18.157920  1343 solver.cpp:244]     Train net output #0: loss = 3.38637 (* 1 = 3.38637 loss)
I0826 11:29:18.157927  1343 sgd_solver.cpp:106] Iteration 78400, lr = 3.0271e-07
I0826 11:29:26.580971  1343 solver.cpp:228] Iteration 78500, loss = 3.64887
I0826 11:29:26.581039  1343 solver.cpp:244]     Train net output #0: loss = 3.64887 (* 1 = 3.64887 loss)
I0826 11:29:26.581049  1343 sgd_solver.cpp:106] Iteration 78500, lr = 3.02479e-07
I0826 11:29:35.009205  1343 solver.cpp:228] Iteration 78600, loss = 3.43011
I0826 11:29:35.009260  1343 solver.cpp:244]     Train net output #0: loss = 3.43011 (* 1 = 3.43011 loss)
I0826 11:29:35.009268  1343 sgd_solver.cpp:106] Iteration 78600, lr = 3.02249e-07
I0826 11:29:43.407438  1343 solver.cpp:228] Iteration 78700, loss = 3.529
I0826 11:29:43.407483  1343 solver.cpp:244]     Train net output #0: loss = 3.529 (* 1 = 3.529 loss)
I0826 11:29:43.407488  1343 sgd_solver.cpp:106] Iteration 78700, lr = 3.02019e-07
I0826 11:29:51.827350  1343 solver.cpp:228] Iteration 78800, loss = 3.48491
I0826 11:29:51.827410  1343 solver.cpp:244]     Train net output #0: loss = 3.48491 (* 1 = 3.48491 loss)
I0826 11:29:51.827421  1343 sgd_solver.cpp:106] Iteration 78800, lr = 3.0179e-07
I0826 11:30:00.243788  1343 solver.cpp:228] Iteration 78900, loss = 3.26726
I0826 11:30:00.243849  1343 solver.cpp:244]     Train net output #0: loss = 3.26726 (* 1 = 3.26726 loss)
I0826 11:30:00.243870  1343 sgd_solver.cpp:106] Iteration 78900, lr = 3.01561e-07
I0826 11:30:08.642815  1343 solver.cpp:228] Iteration 79000, loss = 3.63549
I0826 11:30:08.642870  1343 solver.cpp:244]     Train net output #0: loss = 3.63549 (* 1 = 3.63549 loss)
I0826 11:30:08.642882  1343 sgd_solver.cpp:106] Iteration 79000, lr = 3.01333e-07
I0826 11:30:17.068364  1343 solver.cpp:228] Iteration 79100, loss = 3.6344
I0826 11:30:17.068423  1343 solver.cpp:244]     Train net output #0: loss = 3.6344 (* 1 = 3.6344 loss)
I0826 11:30:17.068430  1343 sgd_solver.cpp:106] Iteration 79100, lr = 3.01105e-07
I0826 11:30:25.463400  1343 solver.cpp:228] Iteration 79200, loss = 3.5215
I0826 11:30:25.463474  1343 solver.cpp:244]     Train net output #0: loss = 3.5215 (* 1 = 3.5215 loss)
I0826 11:30:25.463484  1343 sgd_solver.cpp:106] Iteration 79200, lr = 3.00877e-07
I0826 11:30:33.872364  1343 solver.cpp:228] Iteration 79300, loss = 3.44565
I0826 11:30:33.872421  1343 solver.cpp:244]     Train net output #0: loss = 3.44565 (* 1 = 3.44565 loss)
I0826 11:30:33.872429  1343 sgd_solver.cpp:106] Iteration 79300, lr = 3.0065e-07
I0826 11:30:42.292332  1343 solver.cpp:228] Iteration 79400, loss = 3.3283
I0826 11:30:42.292384  1343 solver.cpp:244]     Train net output #0: loss = 3.3283 (* 1 = 3.3283 loss)
I0826 11:30:42.292395  1343 sgd_solver.cpp:106] Iteration 79400, lr = 3.00423e-07
I0826 11:30:50.712388  1343 solver.cpp:228] Iteration 79500, loss = 3.42287
I0826 11:30:50.712460  1343 solver.cpp:244]     Train net output #0: loss = 3.42287 (* 1 = 3.42287 loss)
I0826 11:30:50.712474  1343 sgd_solver.cpp:106] Iteration 79500, lr = 3.00196e-07
I0826 11:30:59.125159  1343 solver.cpp:228] Iteration 79600, loss = 3.43681
I0826 11:30:59.125216  1343 solver.cpp:244]     Train net output #0: loss = 3.43681 (* 1 = 3.43681 loss)
I0826 11:30:59.125224  1343 sgd_solver.cpp:106] Iteration 79600, lr = 2.9997e-07
I0826 11:31:07.545922  1343 solver.cpp:228] Iteration 79700, loss = 3.34824
I0826 11:31:07.545994  1343 solver.cpp:244]     Train net output #0: loss = 3.34824 (* 1 = 3.34824 loss)
I0826 11:31:07.546015  1343 sgd_solver.cpp:106] Iteration 79700, lr = 2.99744e-07
I0826 11:31:15.980909  1343 solver.cpp:228] Iteration 79800, loss = 3.58318
I0826 11:31:15.980983  1343 solver.cpp:244]     Train net output #0: loss = 3.58318 (* 1 = 3.58318 loss)
I0826 11:31:15.980993  1343 sgd_solver.cpp:106] Iteration 79800, lr = 2.99519e-07
I0826 11:31:24.399200  1343 solver.cpp:228] Iteration 79900, loss = 3.35982
I0826 11:31:24.399271  1343 solver.cpp:244]     Train net output #0: loss = 3.35982 (* 1 = 3.35982 loss)
I0826 11:31:24.399279  1343 sgd_solver.cpp:106] Iteration 79900, lr = 2.99294e-07
I0826 11:31:32.722398  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_80000.caffemodel
I0826 11:31:33.368499  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_80000.solverstate
I0826 11:31:33.575727  1343 solver.cpp:337] Iteration 80000, Testing net (#0)
I0826 11:31:54.577646  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:32:12.568799  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302021
I0826 11:32:12.568852  1343 solver.cpp:404]     Test net output #1: loss = 3.45493 (* 1 = 3.45493 loss)
I0826 11:32:12.601368  1343 solver.cpp:228] Iteration 80000, loss = 3.49366
I0826 11:32:12.601433  1343 solver.cpp:244]     Train net output #0: loss = 3.49366 (* 1 = 3.49366 loss)
I0826 11:32:12.601451  1343 sgd_solver.cpp:106] Iteration 80000, lr = 2.9907e-07
I0826 11:32:21.014484  1343 solver.cpp:228] Iteration 80100, loss = 3.44505
I0826 11:32:21.014544  1343 solver.cpp:244]     Train net output #0: loss = 3.44505 (* 1 = 3.44505 loss)
I0826 11:32:21.014552  1343 sgd_solver.cpp:106] Iteration 80100, lr = 2.98846e-07
I0826 11:32:29.436422  1343 solver.cpp:228] Iteration 80200, loss = 3.46686
I0826 11:32:29.436482  1343 solver.cpp:244]     Train net output #0: loss = 3.46686 (* 1 = 3.46686 loss)
I0826 11:32:29.436488  1343 sgd_solver.cpp:106] Iteration 80200, lr = 2.98622e-07
I0826 11:32:37.825089  1343 solver.cpp:228] Iteration 80300, loss = 3.44588
I0826 11:32:37.825177  1343 solver.cpp:244]     Train net output #0: loss = 3.44588 (* 1 = 3.44588 loss)
I0826 11:32:37.825201  1343 sgd_solver.cpp:106] Iteration 80300, lr = 2.98399e-07
I0826 11:32:46.244727  1343 solver.cpp:228] Iteration 80400, loss = 3.49372
I0826 11:32:46.244796  1343 solver.cpp:244]     Train net output #0: loss = 3.49372 (* 1 = 3.49372 loss)
I0826 11:32:46.244802  1343 sgd_solver.cpp:106] Iteration 80400, lr = 2.98176e-07
I0826 11:32:54.646370  1343 solver.cpp:228] Iteration 80500, loss = 3.64391
I0826 11:32:54.646441  1343 solver.cpp:244]     Train net output #0: loss = 3.64391 (* 1 = 3.64391 loss)
I0826 11:32:54.646452  1343 sgd_solver.cpp:106] Iteration 80500, lr = 2.97953e-07
I0826 11:33:03.067473  1343 solver.cpp:228] Iteration 80600, loss = 3.36333
I0826 11:33:03.067528  1343 solver.cpp:244]     Train net output #0: loss = 3.36333 (* 1 = 3.36333 loss)
I0826 11:33:03.067536  1343 sgd_solver.cpp:106] Iteration 80600, lr = 2.97731e-07
I0826 11:33:11.491787  1343 solver.cpp:228] Iteration 80700, loss = 3.68813
I0826 11:33:11.491840  1343 solver.cpp:244]     Train net output #0: loss = 3.68813 (* 1 = 3.68813 loss)
I0826 11:33:11.491847  1343 sgd_solver.cpp:106] Iteration 80700, lr = 2.97509e-07
I0826 11:33:19.917773  1343 solver.cpp:228] Iteration 80800, loss = 3.39932
I0826 11:33:19.917834  1343 solver.cpp:244]     Train net output #0: loss = 3.39932 (* 1 = 3.39932 loss)
I0826 11:33:19.917842  1343 sgd_solver.cpp:106] Iteration 80800, lr = 2.97288e-07
I0826 11:33:28.334825  1343 solver.cpp:228] Iteration 80900, loss = 3.29586
I0826 11:33:28.334868  1343 solver.cpp:244]     Train net output #0: loss = 3.29586 (* 1 = 3.29586 loss)
I0826 11:33:28.334874  1343 sgd_solver.cpp:106] Iteration 80900, lr = 2.97067e-07
I0826 11:33:36.754963  1343 solver.cpp:228] Iteration 81000, loss = 3.52531
I0826 11:33:36.755007  1343 solver.cpp:244]     Train net output #0: loss = 3.52531 (* 1 = 3.52531 loss)
I0826 11:33:36.755013  1343 sgd_solver.cpp:106] Iteration 81000, lr = 2.96846e-07
I0826 11:33:45.187613  1343 solver.cpp:228] Iteration 81100, loss = 3.41689
I0826 11:33:45.187685  1343 solver.cpp:244]     Train net output #0: loss = 3.41689 (* 1 = 3.41689 loss)
I0826 11:33:45.187705  1343 sgd_solver.cpp:106] Iteration 81100, lr = 2.96626e-07
I0826 11:33:53.618458  1343 solver.cpp:228] Iteration 81200, loss = 3.3858
I0826 11:33:53.618499  1343 solver.cpp:244]     Train net output #0: loss = 3.3858 (* 1 = 3.3858 loss)
I0826 11:33:53.618505  1343 sgd_solver.cpp:106] Iteration 81200, lr = 2.96406e-07
I0826 11:34:02.055186  1343 solver.cpp:228] Iteration 81300, loss = 3.51098
I0826 11:34:02.055258  1343 solver.cpp:244]     Train net output #0: loss = 3.51098 (* 1 = 3.51098 loss)
I0826 11:34:02.055276  1343 sgd_solver.cpp:106] Iteration 81300, lr = 2.96187e-07
I0826 11:34:10.489250  1343 solver.cpp:228] Iteration 81400, loss = 3.29695
I0826 11:34:10.489341  1343 solver.cpp:244]     Train net output #0: loss = 3.29695 (* 1 = 3.29695 loss)
I0826 11:34:10.489353  1343 sgd_solver.cpp:106] Iteration 81400, lr = 2.95968e-07
I0826 11:34:18.897413  1343 solver.cpp:228] Iteration 81500, loss = 3.41029
I0826 11:34:18.897472  1343 solver.cpp:244]     Train net output #0: loss = 3.41029 (* 1 = 3.41029 loss)
I0826 11:34:18.897481  1343 sgd_solver.cpp:106] Iteration 81500, lr = 2.95749e-07
I0826 11:34:27.315994  1343 solver.cpp:228] Iteration 81600, loss = 3.38771
I0826 11:34:27.316071  1343 solver.cpp:244]     Train net output #0: loss = 3.38771 (* 1 = 3.38771 loss)
I0826 11:34:27.316081  1343 sgd_solver.cpp:106] Iteration 81600, lr = 2.9553e-07
I0826 11:34:35.732312  1343 solver.cpp:228] Iteration 81700, loss = 3.44489
I0826 11:34:35.732374  1343 solver.cpp:244]     Train net output #0: loss = 3.44489 (* 1 = 3.44489 loss)
I0826 11:34:35.732385  1343 sgd_solver.cpp:106] Iteration 81700, lr = 2.95312e-07
I0826 11:34:44.147864  1343 solver.cpp:228] Iteration 81800, loss = 3.31702
I0826 11:34:44.147907  1343 solver.cpp:244]     Train net output #0: loss = 3.31702 (* 1 = 3.31702 loss)
I0826 11:34:44.147913  1343 sgd_solver.cpp:106] Iteration 81800, lr = 2.95095e-07
I0826 11:34:52.568061  1343 solver.cpp:228] Iteration 81900, loss = 3.38418
I0826 11:34:52.568114  1343 solver.cpp:244]     Train net output #0: loss = 3.38418 (* 1 = 3.38418 loss)
I0826 11:34:52.568120  1343 sgd_solver.cpp:106] Iteration 81900, lr = 2.94878e-07
I0826 11:35:00.994464  1343 solver.cpp:228] Iteration 82000, loss = 3.31593
I0826 11:35:00.994524  1343 solver.cpp:244]     Train net output #0: loss = 3.31593 (* 1 = 3.31593 loss)
I0826 11:35:00.994531  1343 sgd_solver.cpp:106] Iteration 82000, lr = 2.94661e-07
I0826 11:35:04.114116  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:35:09.425060  1343 solver.cpp:228] Iteration 82100, loss = 3.34214
I0826 11:35:09.425101  1343 solver.cpp:244]     Train net output #0: loss = 3.34214 (* 1 = 3.34214 loss)
I0826 11:35:09.425107  1343 sgd_solver.cpp:106] Iteration 82100, lr = 2.94444e-07
I0826 11:35:17.842450  1343 solver.cpp:228] Iteration 82200, loss = 3.54718
I0826 11:35:17.842519  1343 solver.cpp:244]     Train net output #0: loss = 3.54718 (* 1 = 3.54718 loss)
I0826 11:35:17.842530  1343 sgd_solver.cpp:106] Iteration 82200, lr = 2.94228e-07
I0826 11:35:26.266824  1343 solver.cpp:228] Iteration 82300, loss = 3.35245
I0826 11:35:26.266872  1343 solver.cpp:244]     Train net output #0: loss = 3.35245 (* 1 = 3.35245 loss)
I0826 11:35:26.266880  1343 sgd_solver.cpp:106] Iteration 82300, lr = 2.94012e-07
I0826 11:35:34.693254  1343 solver.cpp:228] Iteration 82400, loss = 3.43411
I0826 11:35:34.693310  1343 solver.cpp:244]     Train net output #0: loss = 3.43411 (* 1 = 3.43411 loss)
I0826 11:35:34.693315  1343 sgd_solver.cpp:106] Iteration 82400, lr = 2.93797e-07
I0826 11:35:43.106086  1343 solver.cpp:228] Iteration 82500, loss = 3.39294
I0826 11:35:43.106127  1343 solver.cpp:244]     Train net output #0: loss = 3.39294 (* 1 = 3.39294 loss)
I0826 11:35:43.106133  1343 sgd_solver.cpp:106] Iteration 82500, lr = 2.93582e-07
I0826 11:35:51.543354  1343 solver.cpp:228] Iteration 82600, loss = 3.40166
I0826 11:35:51.543396  1343 solver.cpp:244]     Train net output #0: loss = 3.40166 (* 1 = 3.40166 loss)
I0826 11:35:51.543402  1343 sgd_solver.cpp:106] Iteration 82600, lr = 2.93367e-07
I0826 11:35:59.963537  1343 solver.cpp:228] Iteration 82700, loss = 3.39892
I0826 11:35:59.963582  1343 solver.cpp:244]     Train net output #0: loss = 3.39892 (* 1 = 3.39892 loss)
I0826 11:35:59.963587  1343 sgd_solver.cpp:106] Iteration 82700, lr = 2.93153e-07
I0826 11:36:08.382607  1343 solver.cpp:228] Iteration 82800, loss = 3.4174
I0826 11:36:08.382674  1343 solver.cpp:244]     Train net output #0: loss = 3.4174 (* 1 = 3.4174 loss)
I0826 11:36:08.382685  1343 sgd_solver.cpp:106] Iteration 82800, lr = 2.92939e-07
I0826 11:36:16.816128  1343 solver.cpp:228] Iteration 82900, loss = 3.64194
I0826 11:36:16.816187  1343 solver.cpp:244]     Train net output #0: loss = 3.64194 (* 1 = 3.64194 loss)
I0826 11:36:16.816197  1343 sgd_solver.cpp:106] Iteration 82900, lr = 2.92726e-07
I0826 11:36:25.245839  1343 solver.cpp:228] Iteration 83000, loss = 3.5045
I0826 11:36:25.245892  1343 solver.cpp:244]     Train net output #0: loss = 3.5045 (* 1 = 3.5045 loss)
I0826 11:36:25.245899  1343 sgd_solver.cpp:106] Iteration 83000, lr = 2.92513e-07
I0826 11:36:33.684059  1343 solver.cpp:228] Iteration 83100, loss = 3.43929
I0826 11:36:33.684118  1343 solver.cpp:244]     Train net output #0: loss = 3.43929 (* 1 = 3.43929 loss)
I0826 11:36:33.684126  1343 sgd_solver.cpp:106] Iteration 83100, lr = 2.923e-07
I0826 11:36:42.114182  1343 solver.cpp:228] Iteration 83200, loss = 3.56758
I0826 11:36:42.114258  1343 solver.cpp:244]     Train net output #0: loss = 3.56758 (* 1 = 3.56758 loss)
I0826 11:36:42.114269  1343 sgd_solver.cpp:106] Iteration 83200, lr = 2.92087e-07
I0826 11:36:50.515439  1343 solver.cpp:228] Iteration 83300, loss = 3.37395
I0826 11:36:50.515488  1343 solver.cpp:244]     Train net output #0: loss = 3.37395 (* 1 = 3.37395 loss)
I0826 11:36:50.515496  1343 sgd_solver.cpp:106] Iteration 83300, lr = 2.91875e-07
I0826 11:36:58.939005  1343 solver.cpp:228] Iteration 83400, loss = 3.4906
I0826 11:36:58.939065  1343 solver.cpp:244]     Train net output #0: loss = 3.4906 (* 1 = 3.4906 loss)
I0826 11:36:58.939072  1343 sgd_solver.cpp:106] Iteration 83400, lr = 2.91663e-07
I0826 11:37:07.367040  1343 solver.cpp:228] Iteration 83500, loss = 3.26936
I0826 11:37:07.367097  1343 solver.cpp:244]     Train net output #0: loss = 3.26936 (* 1 = 3.26936 loss)
I0826 11:37:07.367113  1343 sgd_solver.cpp:106] Iteration 83500, lr = 2.91452e-07
I0826 11:37:15.789247  1343 solver.cpp:228] Iteration 83600, loss = 3.50518
I0826 11:37:15.789309  1343 solver.cpp:244]     Train net output #0: loss = 3.50518 (* 1 = 3.50518 loss)
I0826 11:37:15.789319  1343 sgd_solver.cpp:106] Iteration 83600, lr = 2.91241e-07
I0826 11:37:24.192330  1343 solver.cpp:228] Iteration 83700, loss = 3.46652
I0826 11:37:24.192384  1343 solver.cpp:244]     Train net output #0: loss = 3.46652 (* 1 = 3.46652 loss)
I0826 11:37:24.192392  1343 sgd_solver.cpp:106] Iteration 83700, lr = 2.9103e-07
I0826 11:37:32.614249  1343 solver.cpp:228] Iteration 83800, loss = 3.51991
I0826 11:37:32.614292  1343 solver.cpp:244]     Train net output #0: loss = 3.51991 (* 1 = 3.51991 loss)
I0826 11:37:32.614298  1343 sgd_solver.cpp:106] Iteration 83800, lr = 2.9082e-07
I0826 11:37:41.042533  1343 solver.cpp:228] Iteration 83900, loss = 3.2806
I0826 11:37:41.042575  1343 solver.cpp:244]     Train net output #0: loss = 3.2806 (* 1 = 3.2806 loss)
I0826 11:37:41.042582  1343 sgd_solver.cpp:106] Iteration 83900, lr = 2.9061e-07
I0826 11:37:49.463760  1343 solver.cpp:228] Iteration 84000, loss = 3.51512
I0826 11:37:49.463814  1343 solver.cpp:244]     Train net output #0: loss = 3.51512 (* 1 = 3.51512 loss)
I0826 11:37:49.463820  1343 sgd_solver.cpp:106] Iteration 84000, lr = 2.90401e-07
I0826 11:37:57.863517  1343 solver.cpp:228] Iteration 84100, loss = 3.34271
I0826 11:37:57.863557  1343 solver.cpp:244]     Train net output #0: loss = 3.34271 (* 1 = 3.34271 loss)
I0826 11:37:57.863564  1343 sgd_solver.cpp:106] Iteration 84100, lr = 2.90191e-07
I0826 11:38:06.278388  1343 solver.cpp:228] Iteration 84200, loss = 3.48395
I0826 11:38:06.278434  1343 solver.cpp:244]     Train net output #0: loss = 3.48395 (* 1 = 3.48395 loss)
I0826 11:38:06.278439  1343 sgd_solver.cpp:106] Iteration 84200, lr = 2.89982e-07
I0826 11:38:14.712920  1343 solver.cpp:228] Iteration 84300, loss = 3.23187
I0826 11:38:14.712973  1343 solver.cpp:244]     Train net output #0: loss = 3.23187 (* 1 = 3.23187 loss)
I0826 11:38:14.712983  1343 sgd_solver.cpp:106] Iteration 84300, lr = 2.89774e-07
I0826 11:38:23.126816  1343 solver.cpp:228] Iteration 84400, loss = 3.48653
I0826 11:38:23.126868  1343 solver.cpp:244]     Train net output #0: loss = 3.48653 (* 1 = 3.48653 loss)
I0826 11:38:23.126875  1343 sgd_solver.cpp:106] Iteration 84400, lr = 2.89566e-07
I0826 11:38:31.572166  1343 solver.cpp:228] Iteration 84500, loss = 3.43196
I0826 11:38:31.572227  1343 solver.cpp:244]     Train net output #0: loss = 3.43196 (* 1 = 3.43196 loss)
I0826 11:38:31.572235  1343 sgd_solver.cpp:106] Iteration 84500, lr = 2.89358e-07
I0826 11:38:40.008805  1343 solver.cpp:228] Iteration 84600, loss = 3.54245
I0826 11:38:40.008868  1343 solver.cpp:244]     Train net output #0: loss = 3.54245 (* 1 = 3.54245 loss)
I0826 11:38:40.008880  1343 sgd_solver.cpp:106] Iteration 84600, lr = 2.8915e-07
I0826 11:38:48.433365  1343 solver.cpp:228] Iteration 84700, loss = 3.4425
I0826 11:38:48.433408  1343 solver.cpp:244]     Train net output #0: loss = 3.4425 (* 1 = 3.4425 loss)
I0826 11:38:48.433413  1343 sgd_solver.cpp:106] Iteration 84700, lr = 2.88943e-07
I0826 11:38:56.852766  1343 solver.cpp:228] Iteration 84800, loss = 3.44909
I0826 11:38:56.852826  1343 solver.cpp:244]     Train net output #0: loss = 3.44909 (* 1 = 3.44909 loss)
I0826 11:38:56.852834  1343 sgd_solver.cpp:106] Iteration 84800, lr = 2.88736e-07
I0826 11:39:05.277107  1343 solver.cpp:228] Iteration 84900, loss = 3.36237
I0826 11:39:05.277155  1343 solver.cpp:244]     Train net output #0: loss = 3.36237 (* 1 = 3.36237 loss)
I0826 11:39:05.277163  1343 sgd_solver.cpp:106] Iteration 84900, lr = 2.8853e-07
I0826 11:39:13.602991  1343 solver.cpp:337] Iteration 85000, Testing net (#0)
I0826 11:39:20.082729  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:39:53.121240  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302045
I0826 11:39:53.121320  1343 solver.cpp:404]     Test net output #1: loss = 3.45108 (* 1 = 3.45108 loss)
I0826 11:39:53.150564  1343 solver.cpp:228] Iteration 85000, loss = 3.25674
I0826 11:39:53.150619  1343 solver.cpp:244]     Train net output #0: loss = 3.25674 (* 1 = 3.25674 loss)
I0826 11:39:53.150634  1343 sgd_solver.cpp:106] Iteration 85000, lr = 2.88324e-07
I0826 11:40:01.560396  1343 solver.cpp:228] Iteration 85100, loss = 3.47124
I0826 11:40:01.560506  1343 solver.cpp:244]     Train net output #0: loss = 3.47124 (* 1 = 3.47124 loss)
I0826 11:40:01.560518  1343 sgd_solver.cpp:106] Iteration 85100, lr = 2.88118e-07
I0826 11:40:09.977416  1343 solver.cpp:228] Iteration 85200, loss = 3.41072
I0826 11:40:09.977486  1343 solver.cpp:244]     Train net output #0: loss = 3.41072 (* 1 = 3.41072 loss)
I0826 11:40:09.977495  1343 sgd_solver.cpp:106] Iteration 85200, lr = 2.87913e-07
I0826 11:40:18.394022  1343 solver.cpp:228] Iteration 85300, loss = 3.4112
I0826 11:40:18.394076  1343 solver.cpp:244]     Train net output #0: loss = 3.4112 (* 1 = 3.4112 loss)
I0826 11:40:18.394084  1343 sgd_solver.cpp:106] Iteration 85300, lr = 2.87708e-07
I0826 11:40:26.721297  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:40:26.806692  1343 solver.cpp:228] Iteration 85400, loss = 3.54046
I0826 11:40:26.806777  1343 solver.cpp:244]     Train net output #0: loss = 3.54046 (* 1 = 3.54046 loss)
I0826 11:40:26.806792  1343 sgd_solver.cpp:106] Iteration 85400, lr = 2.87503e-07
I0826 11:40:35.223204  1343 solver.cpp:228] Iteration 85500, loss = 3.39637
I0826 11:40:35.223261  1343 solver.cpp:244]     Train net output #0: loss = 3.39637 (* 1 = 3.39637 loss)
I0826 11:40:35.223268  1343 sgd_solver.cpp:106] Iteration 85500, lr = 2.87298e-07
I0826 11:40:43.644846  1343 solver.cpp:228] Iteration 85600, loss = 3.29026
I0826 11:40:43.644912  1343 solver.cpp:244]     Train net output #0: loss = 3.29026 (* 1 = 3.29026 loss)
I0826 11:40:43.644920  1343 sgd_solver.cpp:106] Iteration 85600, lr = 2.87094e-07
I0826 11:40:52.048517  1343 solver.cpp:228] Iteration 85700, loss = 3.42675
I0826 11:40:52.048578  1343 solver.cpp:244]     Train net output #0: loss = 3.42675 (* 1 = 3.42675 loss)
I0826 11:40:52.048589  1343 sgd_solver.cpp:106] Iteration 85700, lr = 2.86891e-07
I0826 11:41:00.472115  1343 solver.cpp:228] Iteration 85800, loss = 3.31642
I0826 11:41:00.472185  1343 solver.cpp:244]     Train net output #0: loss = 3.31642 (* 1 = 3.31642 loss)
I0826 11:41:00.472198  1343 sgd_solver.cpp:106] Iteration 85800, lr = 2.86687e-07
I0826 11:41:08.878796  1343 solver.cpp:228] Iteration 85900, loss = 3.57779
I0826 11:41:08.878854  1343 solver.cpp:244]     Train net output #0: loss = 3.57779 (* 1 = 3.57779 loss)
I0826 11:41:08.878867  1343 sgd_solver.cpp:106] Iteration 85900, lr = 2.86484e-07
I0826 11:41:17.294015  1343 solver.cpp:228] Iteration 86000, loss = 3.53747
I0826 11:41:17.294080  1343 solver.cpp:244]     Train net output #0: loss = 3.53747 (* 1 = 3.53747 loss)
I0826 11:41:17.294092  1343 sgd_solver.cpp:106] Iteration 86000, lr = 2.86281e-07
I0826 11:41:25.722184  1343 solver.cpp:228] Iteration 86100, loss = 3.38665
I0826 11:41:25.722259  1343 solver.cpp:244]     Train net output #0: loss = 3.38665 (* 1 = 3.38665 loss)
I0826 11:41:25.722268  1343 sgd_solver.cpp:106] Iteration 86100, lr = 2.86079e-07
I0826 11:41:34.143715  1343 solver.cpp:228] Iteration 86200, loss = 3.39787
I0826 11:41:34.143780  1343 solver.cpp:244]     Train net output #0: loss = 3.39787 (* 1 = 3.39787 loss)
I0826 11:41:34.143792  1343 sgd_solver.cpp:106] Iteration 86200, lr = 2.85877e-07
I0826 11:41:42.563110  1343 solver.cpp:228] Iteration 86300, loss = 3.48518
I0826 11:41:42.563174  1343 solver.cpp:244]     Train net output #0: loss = 3.48518 (* 1 = 3.48518 loss)
I0826 11:41:42.563182  1343 sgd_solver.cpp:106] Iteration 86300, lr = 2.85675e-07
I0826 11:41:50.983539  1343 solver.cpp:228] Iteration 86400, loss = 3.31951
I0826 11:41:50.983592  1343 solver.cpp:244]     Train net output #0: loss = 3.31951 (* 1 = 3.31951 loss)
I0826 11:41:50.983602  1343 sgd_solver.cpp:106] Iteration 86400, lr = 2.85474e-07
I0826 11:41:59.393265  1343 solver.cpp:228] Iteration 86500, loss = 3.40593
I0826 11:41:59.393313  1343 solver.cpp:244]     Train net output #0: loss = 3.40593 (* 1 = 3.40593 loss)
I0826 11:41:59.393319  1343 sgd_solver.cpp:106] Iteration 86500, lr = 2.85273e-07
I0826 11:42:07.784555  1343 solver.cpp:228] Iteration 86600, loss = 3.48011
I0826 11:42:07.784633  1343 solver.cpp:244]     Train net output #0: loss = 3.48011 (* 1 = 3.48011 loss)
I0826 11:42:07.784647  1343 sgd_solver.cpp:106] Iteration 86600, lr = 2.85072e-07
I0826 11:42:16.202589  1343 solver.cpp:228] Iteration 86700, loss = 3.62634
I0826 11:42:16.202679  1343 solver.cpp:244]     Train net output #0: loss = 3.62634 (* 1 = 3.62634 loss)
I0826 11:42:16.202695  1343 sgd_solver.cpp:106] Iteration 86700, lr = 2.84872e-07
I0826 11:42:24.609689  1343 solver.cpp:228] Iteration 86800, loss = 3.3622
I0826 11:42:24.609764  1343 solver.cpp:244]     Train net output #0: loss = 3.3622 (* 1 = 3.3622 loss)
I0826 11:42:24.609774  1343 sgd_solver.cpp:106] Iteration 86800, lr = 2.84672e-07
I0826 11:42:33.014683  1343 solver.cpp:228] Iteration 86900, loss = 3.49326
I0826 11:42:33.014749  1343 solver.cpp:244]     Train net output #0: loss = 3.49326 (* 1 = 3.49326 loss)
I0826 11:42:33.014757  1343 sgd_solver.cpp:106] Iteration 86900, lr = 2.84472e-07
I0826 11:42:41.429600  1343 solver.cpp:228] Iteration 87000, loss = 3.32682
I0826 11:42:41.429643  1343 solver.cpp:244]     Train net output #0: loss = 3.32682 (* 1 = 3.32682 loss)
I0826 11:42:41.429652  1343 sgd_solver.cpp:106] Iteration 87000, lr = 2.84272e-07
I0826 11:42:49.828449  1343 solver.cpp:228] Iteration 87100, loss = 3.62656
I0826 11:42:49.828492  1343 solver.cpp:244]     Train net output #0: loss = 3.62656 (* 1 = 3.62656 loss)
I0826 11:42:49.828498  1343 sgd_solver.cpp:106] Iteration 87100, lr = 2.84073e-07
I0826 11:42:58.260205  1343 solver.cpp:228] Iteration 87200, loss = 3.41575
I0826 11:42:58.260268  1343 solver.cpp:244]     Train net output #0: loss = 3.41575 (* 1 = 3.41575 loss)
I0826 11:42:58.260278  1343 sgd_solver.cpp:106] Iteration 87200, lr = 2.83875e-07
I0826 11:43:06.686774  1343 solver.cpp:228] Iteration 87300, loss = 3.52373
I0826 11:43:06.686841  1343 solver.cpp:244]     Train net output #0: loss = 3.52373 (* 1 = 3.52373 loss)
I0826 11:43:06.686852  1343 sgd_solver.cpp:106] Iteration 87300, lr = 2.83676e-07
I0826 11:43:15.108191  1343 solver.cpp:228] Iteration 87400, loss = 3.52215
I0826 11:43:15.108258  1343 solver.cpp:244]     Train net output #0: loss = 3.52215 (* 1 = 3.52215 loss)
I0826 11:43:15.108268  1343 sgd_solver.cpp:106] Iteration 87400, lr = 2.83478e-07
I0826 11:43:23.504959  1343 solver.cpp:228] Iteration 87500, loss = 3.38293
I0826 11:43:23.505014  1343 solver.cpp:244]     Train net output #0: loss = 3.38293 (* 1 = 3.38293 loss)
I0826 11:43:23.505024  1343 sgd_solver.cpp:106] Iteration 87500, lr = 2.8328e-07
I0826 11:43:31.924913  1343 solver.cpp:228] Iteration 87600, loss = 3.46287
I0826 11:43:31.924983  1343 solver.cpp:244]     Train net output #0: loss = 3.46287 (* 1 = 3.46287 loss)
I0826 11:43:31.924994  1343 sgd_solver.cpp:106] Iteration 87600, lr = 2.83083e-07
I0826 11:43:40.358120  1343 solver.cpp:228] Iteration 87700, loss = 3.57664
I0826 11:43:40.358173  1343 solver.cpp:244]     Train net output #0: loss = 3.57664 (* 1 = 3.57664 loss)
I0826 11:43:40.358181  1343 sgd_solver.cpp:106] Iteration 87700, lr = 2.82886e-07
I0826 11:43:48.780503  1343 solver.cpp:228] Iteration 87800, loss = 3.30793
I0826 11:43:48.780561  1343 solver.cpp:244]     Train net output #0: loss = 3.30793 (* 1 = 3.30793 loss)
I0826 11:43:48.780570  1343 sgd_solver.cpp:106] Iteration 87800, lr = 2.82689e-07
I0826 11:43:57.192775  1343 solver.cpp:228] Iteration 87900, loss = 3.42909
I0826 11:43:57.192836  1343 solver.cpp:244]     Train net output #0: loss = 3.42909 (* 1 = 3.42909 loss)
I0826 11:43:57.192848  1343 sgd_solver.cpp:106] Iteration 87900, lr = 2.82492e-07
I0826 11:44:05.615948  1343 solver.cpp:228] Iteration 88000, loss = 3.50213
I0826 11:44:05.616029  1343 solver.cpp:244]     Train net output #0: loss = 3.50213 (* 1 = 3.50213 loss)
I0826 11:44:05.616040  1343 sgd_solver.cpp:106] Iteration 88000, lr = 2.82296e-07
I0826 11:44:14.030988  1343 solver.cpp:228] Iteration 88100, loss = 3.43231
I0826 11:44:14.031056  1343 solver.cpp:244]     Train net output #0: loss = 3.43231 (* 1 = 3.43231 loss)
I0826 11:44:14.031064  1343 sgd_solver.cpp:106] Iteration 88100, lr = 2.821e-07
I0826 11:44:22.434270  1343 solver.cpp:228] Iteration 88200, loss = 3.58376
I0826 11:44:22.434340  1343 solver.cpp:244]     Train net output #0: loss = 3.58376 (* 1 = 3.58376 loss)
I0826 11:44:22.434350  1343 sgd_solver.cpp:106] Iteration 88200, lr = 2.81905e-07
I0826 11:44:30.851662  1343 solver.cpp:228] Iteration 88300, loss = 3.39937
I0826 11:44:30.851734  1343 solver.cpp:244]     Train net output #0: loss = 3.39937 (* 1 = 3.39937 loss)
I0826 11:44:30.851742  1343 sgd_solver.cpp:106] Iteration 88300, lr = 2.81709e-07
I0826 11:44:39.272467  1343 solver.cpp:228] Iteration 88400, loss = 3.44483
I0826 11:44:39.272541  1343 solver.cpp:244]     Train net output #0: loss = 3.44483 (* 1 = 3.44483 loss)
I0826 11:44:39.272552  1343 sgd_solver.cpp:106] Iteration 88400, lr = 2.81514e-07
I0826 11:44:47.676093  1343 solver.cpp:228] Iteration 88500, loss = 3.45536
I0826 11:44:47.676151  1343 solver.cpp:244]     Train net output #0: loss = 3.45536 (* 1 = 3.45536 loss)
I0826 11:44:47.676158  1343 sgd_solver.cpp:106] Iteration 88500, lr = 2.8132e-07
I0826 11:44:56.084705  1343 solver.cpp:228] Iteration 88600, loss = 3.26569
I0826 11:44:56.084770  1343 solver.cpp:244]     Train net output #0: loss = 3.26569 (* 1 = 3.26569 loss)
I0826 11:44:56.084780  1343 sgd_solver.cpp:106] Iteration 88600, lr = 2.81125e-07
I0826 11:45:04.492413  1343 solver.cpp:228] Iteration 88700, loss = 3.36375
I0826 11:45:04.492481  1343 solver.cpp:244]     Train net output #0: loss = 3.36375 (* 1 = 3.36375 loss)
I0826 11:45:04.492492  1343 sgd_solver.cpp:106] Iteration 88700, lr = 2.80931e-07
I0826 11:45:12.899175  1343 solver.cpp:228] Iteration 88800, loss = 3.38227
I0826 11:45:12.899246  1343 solver.cpp:244]     Train net output #0: loss = 3.38227 (* 1 = 3.38227 loss)
I0826 11:45:12.899255  1343 sgd_solver.cpp:106] Iteration 88800, lr = 2.80738e-07
I0826 11:45:21.319514  1343 solver.cpp:228] Iteration 88900, loss = 3.55211
I0826 11:45:21.319571  1343 solver.cpp:244]     Train net output #0: loss = 3.55211 (* 1 = 3.55211 loss)
I0826 11:45:21.319581  1343 sgd_solver.cpp:106] Iteration 88900, lr = 2.80544e-07
I0826 11:45:28.715659  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:45:29.726413  1343 solver.cpp:228] Iteration 89000, loss = 3.24501
I0826 11:45:29.726450  1343 solver.cpp:244]     Train net output #0: loss = 3.24501 (* 1 = 3.24501 loss)
I0826 11:45:29.726457  1343 sgd_solver.cpp:106] Iteration 89000, lr = 2.80351e-07
I0826 11:45:38.146001  1343 solver.cpp:228] Iteration 89100, loss = 3.20262
I0826 11:45:38.146072  1343 solver.cpp:244]     Train net output #0: loss = 3.20262 (* 1 = 3.20262 loss)
I0826 11:45:38.146080  1343 sgd_solver.cpp:106] Iteration 89100, lr = 2.80159e-07
I0826 11:45:46.570713  1343 solver.cpp:228] Iteration 89200, loss = 3.47298
I0826 11:45:46.570780  1343 solver.cpp:244]     Train net output #0: loss = 3.47298 (* 1 = 3.47298 loss)
I0826 11:45:46.570790  1343 sgd_solver.cpp:106] Iteration 89200, lr = 2.79966e-07
I0826 11:45:54.975078  1343 solver.cpp:228] Iteration 89300, loss = 3.45216
I0826 11:45:54.975132  1343 solver.cpp:244]     Train net output #0: loss = 3.45216 (* 1 = 3.45216 loss)
I0826 11:45:54.975147  1343 sgd_solver.cpp:106] Iteration 89300, lr = 2.79774e-07
I0826 11:46:03.398732  1343 solver.cpp:228] Iteration 89400, loss = 3.46454
I0826 11:46:03.398777  1343 solver.cpp:244]     Train net output #0: loss = 3.46454 (* 1 = 3.46454 loss)
I0826 11:46:03.398783  1343 sgd_solver.cpp:106] Iteration 89400, lr = 2.79582e-07
I0826 11:46:11.816330  1343 solver.cpp:228] Iteration 89500, loss = 3.46646
I0826 11:46:11.816411  1343 solver.cpp:244]     Train net output #0: loss = 3.46646 (* 1 = 3.46646 loss)
I0826 11:46:11.816427  1343 sgd_solver.cpp:106] Iteration 89500, lr = 2.79391e-07
I0826 11:46:20.237210  1343 solver.cpp:228] Iteration 89600, loss = 3.3516
I0826 11:46:20.237279  1343 solver.cpp:244]     Train net output #0: loss = 3.3516 (* 1 = 3.3516 loss)
I0826 11:46:20.237292  1343 sgd_solver.cpp:106] Iteration 89600, lr = 2.79199e-07
I0826 11:46:28.658519  1343 solver.cpp:228] Iteration 89700, loss = 3.38951
I0826 11:46:28.658591  1343 solver.cpp:244]     Train net output #0: loss = 3.38951 (* 1 = 3.38951 loss)
I0826 11:46:28.658598  1343 sgd_solver.cpp:106] Iteration 89700, lr = 2.79009e-07
I0826 11:46:37.070452  1343 solver.cpp:228] Iteration 89800, loss = 3.51763
I0826 11:46:37.070500  1343 solver.cpp:244]     Train net output #0: loss = 3.51763 (* 1 = 3.51763 loss)
I0826 11:46:37.070507  1343 sgd_solver.cpp:106] Iteration 89800, lr = 2.78818e-07
I0826 11:46:45.486268  1343 solver.cpp:228] Iteration 89900, loss = 3.4264
I0826 11:46:45.486331  1343 solver.cpp:244]     Train net output #0: loss = 3.4264 (* 1 = 3.4264 loss)
I0826 11:46:45.486343  1343 sgd_solver.cpp:106] Iteration 89900, lr = 2.78628e-07
I0826 11:46:53.817641  1343 solver.cpp:337] Iteration 90000, Testing net (#0)
I0826 11:47:22.836313  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:47:32.117883  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302007
I0826 11:47:32.117940  1343 solver.cpp:404]     Test net output #1: loss = 3.44773 (* 1 = 3.44773 loss)
I0826 11:47:32.147017  1343 solver.cpp:228] Iteration 90000, loss = 3.53832
I0826 11:47:32.147073  1343 solver.cpp:244]     Train net output #0: loss = 3.53832 (* 1 = 3.53832 loss)
I0826 11:47:32.147091  1343 sgd_solver.cpp:106] Iteration 90000, lr = 2.78438e-07
I0826 11:47:40.590030  1343 solver.cpp:228] Iteration 90100, loss = 3.4564
I0826 11:47:40.590098  1343 solver.cpp:244]     Train net output #0: loss = 3.4564 (* 1 = 3.4564 loss)
I0826 11:47:40.590108  1343 sgd_solver.cpp:106] Iteration 90100, lr = 2.78248e-07
I0826 11:47:49.028632  1343 solver.cpp:228] Iteration 90200, loss = 3.29368
I0826 11:47:49.028692  1343 solver.cpp:244]     Train net output #0: loss = 3.29368 (* 1 = 3.29368 loss)
I0826 11:47:49.028698  1343 sgd_solver.cpp:106] Iteration 90200, lr = 2.78059e-07
I0826 11:47:57.444722  1343 solver.cpp:228] Iteration 90300, loss = 3.5053
I0826 11:47:57.444771  1343 solver.cpp:244]     Train net output #0: loss = 3.5053 (* 1 = 3.5053 loss)
I0826 11:47:57.444779  1343 sgd_solver.cpp:106] Iteration 90300, lr = 2.7787e-07
I0826 11:48:05.850102  1343 solver.cpp:228] Iteration 90400, loss = 3.45442
I0826 11:48:05.850168  1343 solver.cpp:244]     Train net output #0: loss = 3.45442 (* 1 = 3.45442 loss)
I0826 11:48:05.850180  1343 sgd_solver.cpp:106] Iteration 90400, lr = 2.77681e-07
I0826 11:48:14.276641  1343 solver.cpp:228] Iteration 90500, loss = 3.33563
I0826 11:48:14.276705  1343 solver.cpp:244]     Train net output #0: loss = 3.33563 (* 1 = 3.33563 loss)
I0826 11:48:14.276717  1343 sgd_solver.cpp:106] Iteration 90500, lr = 2.77492e-07
I0826 11:48:22.714031  1343 solver.cpp:228] Iteration 90600, loss = 3.43326
I0826 11:48:22.714107  1343 solver.cpp:244]     Train net output #0: loss = 3.43326 (* 1 = 3.43326 loss)
I0826 11:48:22.714121  1343 sgd_solver.cpp:106] Iteration 90600, lr = 2.77304e-07
I0826 11:48:31.143007  1343 solver.cpp:228] Iteration 90700, loss = 3.33763
I0826 11:48:31.143062  1343 solver.cpp:244]     Train net output #0: loss = 3.33763 (* 1 = 3.33763 loss)
I0826 11:48:31.143070  1343 sgd_solver.cpp:106] Iteration 90700, lr = 2.77116e-07
I0826 11:48:39.563002  1343 solver.cpp:228] Iteration 90800, loss = 3.36318
I0826 11:48:39.563056  1343 solver.cpp:244]     Train net output #0: loss = 3.36318 (* 1 = 3.36318 loss)
I0826 11:48:39.563065  1343 sgd_solver.cpp:106] Iteration 90800, lr = 2.76929e-07
I0826 11:48:47.977051  1343 solver.cpp:228] Iteration 90900, loss = 3.50639
I0826 11:48:47.977126  1343 solver.cpp:244]     Train net output #0: loss = 3.50639 (* 1 = 3.50639 loss)
I0826 11:48:47.977140  1343 sgd_solver.cpp:106] Iteration 90900, lr = 2.76741e-07
I0826 11:48:56.404968  1343 solver.cpp:228] Iteration 91000, loss = 3.48664
I0826 11:48:56.405031  1343 solver.cpp:244]     Train net output #0: loss = 3.48664 (* 1 = 3.48664 loss)
I0826 11:48:56.405045  1343 sgd_solver.cpp:106] Iteration 91000, lr = 2.76554e-07
I0826 11:49:04.825129  1343 solver.cpp:228] Iteration 91100, loss = 3.48537
I0826 11:49:04.825206  1343 solver.cpp:244]     Train net output #0: loss = 3.48537 (* 1 = 3.48537 loss)
I0826 11:49:04.825220  1343 sgd_solver.cpp:106] Iteration 91100, lr = 2.76368e-07
I0826 11:49:13.246584  1343 solver.cpp:228] Iteration 91200, loss = 3.31526
I0826 11:49:13.246662  1343 solver.cpp:244]     Train net output #0: loss = 3.31526 (* 1 = 3.31526 loss)
I0826 11:49:13.246672  1343 sgd_solver.cpp:106] Iteration 91200, lr = 2.76181e-07
I0826 11:49:21.641403  1343 solver.cpp:228] Iteration 91300, loss = 3.48207
I0826 11:49:21.641453  1343 solver.cpp:244]     Train net output #0: loss = 3.48207 (* 1 = 3.48207 loss)
I0826 11:49:21.641460  1343 sgd_solver.cpp:106] Iteration 91300, lr = 2.75995e-07
I0826 11:49:30.070188  1343 solver.cpp:228] Iteration 91400, loss = 3.5083
I0826 11:49:30.070256  1343 solver.cpp:244]     Train net output #0: loss = 3.5083 (* 1 = 3.5083 loss)
I0826 11:49:30.070266  1343 sgd_solver.cpp:106] Iteration 91400, lr = 2.75809e-07
I0826 11:49:38.465447  1343 solver.cpp:228] Iteration 91500, loss = 3.50758
I0826 11:49:38.465515  1343 solver.cpp:244]     Train net output #0: loss = 3.50758 (* 1 = 3.50758 loss)
I0826 11:49:38.465526  1343 sgd_solver.cpp:106] Iteration 91500, lr = 2.75624e-07
I0826 11:49:46.884824  1343 solver.cpp:228] Iteration 91600, loss = 3.51515
I0826 11:49:46.884898  1343 solver.cpp:244]     Train net output #0: loss = 3.51515 (* 1 = 3.51515 loss)
I0826 11:49:46.884909  1343 sgd_solver.cpp:106] Iteration 91600, lr = 2.75438e-07
I0826 11:49:55.302903  1343 solver.cpp:228] Iteration 91700, loss = 3.47149
I0826 11:49:55.302958  1343 solver.cpp:244]     Train net output #0: loss = 3.47149 (* 1 = 3.47149 loss)
I0826 11:49:55.302964  1343 sgd_solver.cpp:106] Iteration 91700, lr = 2.75253e-07
I0826 11:50:03.718386  1343 solver.cpp:228] Iteration 91800, loss = 3.61412
I0826 11:50:03.718454  1343 solver.cpp:244]     Train net output #0: loss = 3.61412 (* 1 = 3.61412 loss)
I0826 11:50:03.718461  1343 sgd_solver.cpp:106] Iteration 91800, lr = 2.75069e-07
I0826 11:50:12.131896  1343 solver.cpp:228] Iteration 91900, loss = 3.25702
I0826 11:50:12.131959  1343 solver.cpp:244]     Train net output #0: loss = 3.25702 (* 1 = 3.25702 loss)
I0826 11:50:12.131971  1343 sgd_solver.cpp:106] Iteration 91900, lr = 2.74884e-07
I0826 11:50:20.545706  1343 solver.cpp:228] Iteration 92000, loss = 3.49264
I0826 11:50:20.545753  1343 solver.cpp:244]     Train net output #0: loss = 3.49264 (* 1 = 3.49264 loss)
I0826 11:50:20.545758  1343 sgd_solver.cpp:106] Iteration 92000, lr = 2.747e-07
I0826 11:50:28.930876  1343 solver.cpp:228] Iteration 92100, loss = 3.29885
I0826 11:50:28.930950  1343 solver.cpp:244]     Train net output #0: loss = 3.29885 (* 1 = 3.29885 loss)
I0826 11:50:28.930958  1343 sgd_solver.cpp:106] Iteration 92100, lr = 2.74516e-07
I0826 11:50:37.354827  1343 solver.cpp:228] Iteration 92200, loss = 3.42825
I0826 11:50:37.354873  1343 solver.cpp:244]     Train net output #0: loss = 3.42825 (* 1 = 3.42825 loss)
I0826 11:50:37.354879  1343 sgd_solver.cpp:106] Iteration 92200, lr = 2.74333e-07
I0826 11:50:45.749125  1343 solver.cpp:228] Iteration 92300, loss = 3.46402
I0826 11:50:45.749183  1343 solver.cpp:244]     Train net output #0: loss = 3.46402 (* 1 = 3.46402 loss)
I0826 11:50:45.749196  1343 sgd_solver.cpp:106] Iteration 92300, lr = 2.7415e-07
I0826 11:50:54.160466  1343 solver.cpp:228] Iteration 92400, loss = 3.54562
I0826 11:50:54.160533  1343 solver.cpp:244]     Train net output #0: loss = 3.54562 (* 1 = 3.54562 loss)
I0826 11:50:54.160545  1343 sgd_solver.cpp:106] Iteration 92400, lr = 2.73967e-07
I0826 11:51:02.543972  1343 solver.cpp:228] Iteration 92500, loss = 3.3673
I0826 11:51:02.544025  1343 solver.cpp:244]     Train net output #0: loss = 3.3673 (* 1 = 3.3673 loss)
I0826 11:51:02.544033  1343 sgd_solver.cpp:106] Iteration 92500, lr = 2.73784e-07
I0826 11:51:10.968200  1343 solver.cpp:228] Iteration 92600, loss = 3.4351
I0826 11:51:10.968268  1343 solver.cpp:244]     Train net output #0: loss = 3.4351 (* 1 = 3.4351 loss)
I0826 11:51:10.968279  1343 sgd_solver.cpp:106] Iteration 92600, lr = 2.73602e-07
I0826 11:51:19.392419  1343 solver.cpp:228] Iteration 92700, loss = 3.58351
I0826 11:51:19.392489  1343 solver.cpp:244]     Train net output #0: loss = 3.58351 (* 1 = 3.58351 loss)
I0826 11:51:19.392499  1343 sgd_solver.cpp:106] Iteration 92700, lr = 2.7342e-07
I0826 11:51:22.754380  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:51:27.815331  1343 solver.cpp:228] Iteration 92800, loss = 3.44362
I0826 11:51:27.815398  1343 solver.cpp:244]     Train net output #0: loss = 3.44362 (* 1 = 3.44362 loss)
I0826 11:51:27.815408  1343 sgd_solver.cpp:106] Iteration 92800, lr = 2.73238e-07
I0826 11:51:36.234920  1343 solver.cpp:228] Iteration 92900, loss = 3.25489
I0826 11:51:36.234990  1343 solver.cpp:244]     Train net output #0: loss = 3.25489 (* 1 = 3.25489 loss)
I0826 11:51:36.235000  1343 sgd_solver.cpp:106] Iteration 92900, lr = 2.73056e-07
I0826 11:51:44.654994  1343 solver.cpp:228] Iteration 93000, loss = 3.5428
I0826 11:51:44.655062  1343 solver.cpp:244]     Train net output #0: loss = 3.5428 (* 1 = 3.5428 loss)
I0826 11:51:44.655076  1343 sgd_solver.cpp:106] Iteration 93000, lr = 2.72875e-07
I0826 11:51:53.073487  1343 solver.cpp:228] Iteration 93100, loss = 3.40501
I0826 11:51:53.073556  1343 solver.cpp:244]     Train net output #0: loss = 3.40501 (* 1 = 3.40501 loss)
I0826 11:51:53.073565  1343 sgd_solver.cpp:106] Iteration 93100, lr = 2.72694e-07
I0826 11:52:01.507755  1343 solver.cpp:228] Iteration 93200, loss = 3.44632
I0826 11:52:01.507827  1343 solver.cpp:244]     Train net output #0: loss = 3.44632 (* 1 = 3.44632 loss)
I0826 11:52:01.507836  1343 sgd_solver.cpp:106] Iteration 93200, lr = 2.72513e-07
I0826 11:52:09.918320  1343 solver.cpp:228] Iteration 93300, loss = 3.40342
I0826 11:52:09.918370  1343 solver.cpp:244]     Train net output #0: loss = 3.40342 (* 1 = 3.40342 loss)
I0826 11:52:09.918378  1343 sgd_solver.cpp:106] Iteration 93300, lr = 2.72333e-07
I0826 11:52:18.330395  1343 solver.cpp:228] Iteration 93400, loss = 3.3141
I0826 11:52:18.330452  1343 solver.cpp:244]     Train net output #0: loss = 3.3141 (* 1 = 3.3141 loss)
I0826 11:52:18.330461  1343 sgd_solver.cpp:106] Iteration 93400, lr = 2.72153e-07
I0826 11:52:26.743885  1343 solver.cpp:228] Iteration 93500, loss = 3.48666
I0826 11:52:26.743928  1343 solver.cpp:244]     Train net output #0: loss = 3.48666 (* 1 = 3.48666 loss)
I0826 11:52:26.743934  1343 sgd_solver.cpp:106] Iteration 93500, lr = 2.71973e-07
I0826 11:52:35.180405  1343 solver.cpp:228] Iteration 93600, loss = 3.41837
I0826 11:52:35.180480  1343 solver.cpp:244]     Train net output #0: loss = 3.41837 (* 1 = 3.41837 loss)
I0826 11:52:35.180490  1343 sgd_solver.cpp:106] Iteration 93600, lr = 2.71793e-07
I0826 11:52:43.616786  1343 solver.cpp:228] Iteration 93700, loss = 3.48184
I0826 11:52:43.616837  1343 solver.cpp:244]     Train net output #0: loss = 3.48184 (* 1 = 3.48184 loss)
I0826 11:52:43.616842  1343 sgd_solver.cpp:106] Iteration 93700, lr = 2.71614e-07
I0826 11:52:52.039116  1343 solver.cpp:228] Iteration 93800, loss = 3.5298
I0826 11:52:52.039201  1343 solver.cpp:244]     Train net output #0: loss = 3.5298 (* 1 = 3.5298 loss)
I0826 11:52:52.039212  1343 sgd_solver.cpp:106] Iteration 93800, lr = 2.71435e-07
I0826 11:53:00.466644  1343 solver.cpp:228] Iteration 93900, loss = 3.43084
I0826 11:53:00.466720  1343 solver.cpp:244]     Train net output #0: loss = 3.43084 (* 1 = 3.43084 loss)
I0826 11:53:00.466732  1343 sgd_solver.cpp:106] Iteration 93900, lr = 2.71256e-07
I0826 11:53:08.892985  1343 solver.cpp:228] Iteration 94000, loss = 3.38311
I0826 11:53:08.893049  1343 solver.cpp:244]     Train net output #0: loss = 3.38311 (* 1 = 3.38311 loss)
I0826 11:53:08.893059  1343 sgd_solver.cpp:106] Iteration 94000, lr = 2.71078e-07
I0826 11:53:17.302901  1343 solver.cpp:228] Iteration 94100, loss = 3.55173
I0826 11:53:17.302963  1343 solver.cpp:244]     Train net output #0: loss = 3.55173 (* 1 = 3.55173 loss)
I0826 11:53:17.302969  1343 sgd_solver.cpp:106] Iteration 94100, lr = 2.709e-07
I0826 11:53:25.725728  1343 solver.cpp:228] Iteration 94200, loss = 3.38508
I0826 11:53:25.725780  1343 solver.cpp:244]     Train net output #0: loss = 3.38508 (* 1 = 3.38508 loss)
I0826 11:53:25.725788  1343 sgd_solver.cpp:106] Iteration 94200, lr = 2.70722e-07
I0826 11:53:34.158599  1343 solver.cpp:228] Iteration 94300, loss = 3.51319
I0826 11:53:34.158660  1343 solver.cpp:244]     Train net output #0: loss = 3.51319 (* 1 = 3.51319 loss)
I0826 11:53:34.158674  1343 sgd_solver.cpp:106] Iteration 94300, lr = 2.70544e-07
I0826 11:53:42.579397  1343 solver.cpp:228] Iteration 94400, loss = 3.47247
I0826 11:53:42.579471  1343 solver.cpp:244]     Train net output #0: loss = 3.47247 (* 1 = 3.47247 loss)
I0826 11:53:42.579488  1343 sgd_solver.cpp:106] Iteration 94400, lr = 2.70367e-07
I0826 11:53:50.979483  1343 solver.cpp:228] Iteration 94500, loss = 3.55207
I0826 11:53:50.979542  1343 solver.cpp:244]     Train net output #0: loss = 3.55207 (* 1 = 3.55207 loss)
I0826 11:53:50.979552  1343 sgd_solver.cpp:106] Iteration 94500, lr = 2.70189e-07
I0826 11:53:59.389313  1343 solver.cpp:228] Iteration 94600, loss = 3.43189
I0826 11:53:59.389381  1343 solver.cpp:244]     Train net output #0: loss = 3.43189 (* 1 = 3.43189 loss)
I0826 11:53:59.389390  1343 sgd_solver.cpp:106] Iteration 94600, lr = 2.70013e-07
I0826 11:54:07.815659  1343 solver.cpp:228] Iteration 94700, loss = 3.37944
I0826 11:54:07.815727  1343 solver.cpp:244]     Train net output #0: loss = 3.37944 (* 1 = 3.37944 loss)
I0826 11:54:07.815737  1343 sgd_solver.cpp:106] Iteration 94700, lr = 2.69836e-07
I0826 11:54:16.242445  1343 solver.cpp:228] Iteration 94800, loss = 3.50197
I0826 11:54:16.242513  1343 solver.cpp:244]     Train net output #0: loss = 3.50197 (* 1 = 3.50197 loss)
I0826 11:54:16.242525  1343 sgd_solver.cpp:106] Iteration 94800, lr = 2.6966e-07
I0826 11:54:24.643892  1343 solver.cpp:228] Iteration 94900, loss = 3.3285
I0826 11:54:24.643947  1343 solver.cpp:244]     Train net output #0: loss = 3.3285 (* 1 = 3.3285 loss)
I0826 11:54:24.643955  1343 sgd_solver.cpp:106] Iteration 94900, lr = 2.69484e-07
I0826 11:54:32.977421  1343 solver.cpp:337] Iteration 95000, Testing net (#0)
I0826 11:54:50.007300  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:55:10.063343  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302
I0826 11:55:10.063391  1343 solver.cpp:404]     Test net output #1: loss = 3.44488 (* 1 = 3.44488 loss)
I0826 11:55:10.092747  1343 solver.cpp:228] Iteration 95000, loss = 3.3492
I0826 11:55:10.092808  1343 solver.cpp:244]     Train net output #0: loss = 3.3492 (* 1 = 3.3492 loss)
I0826 11:55:10.092820  1343 sgd_solver.cpp:106] Iteration 95000, lr = 2.69308e-07
I0826 11:55:18.528350  1343 solver.cpp:228] Iteration 95100, loss = 3.45297
I0826 11:55:18.528434  1343 solver.cpp:244]     Train net output #0: loss = 3.45297 (* 1 = 3.45297 loss)
I0826 11:55:18.528446  1343 sgd_solver.cpp:106] Iteration 95100, lr = 2.69132e-07
I0826 11:55:26.938983  1343 solver.cpp:228] Iteration 95200, loss = 3.45797
I0826 11:55:26.939028  1343 solver.cpp:244]     Train net output #0: loss = 3.45797 (* 1 = 3.45797 loss)
I0826 11:55:26.939034  1343 sgd_solver.cpp:106] Iteration 95200, lr = 2.68957e-07
I0826 11:55:35.362469  1343 solver.cpp:228] Iteration 95300, loss = 3.47803
I0826 11:55:35.362535  1343 solver.cpp:244]     Train net output #0: loss = 3.47803 (* 1 = 3.47803 loss)
I0826 11:55:35.362550  1343 sgd_solver.cpp:106] Iteration 95300, lr = 2.68782e-07
I0826 11:55:43.787451  1343 solver.cpp:228] Iteration 95400, loss = 3.43126
I0826 11:55:43.787506  1343 solver.cpp:244]     Train net output #0: loss = 3.43126 (* 1 = 3.43126 loss)
I0826 11:55:43.787513  1343 sgd_solver.cpp:106] Iteration 95400, lr = 2.68607e-07
I0826 11:55:52.202198  1343 solver.cpp:228] Iteration 95500, loss = 3.30721
I0826 11:55:52.202237  1343 solver.cpp:244]     Train net output #0: loss = 3.30721 (* 1 = 3.30721 loss)
I0826 11:55:52.202244  1343 sgd_solver.cpp:106] Iteration 95500, lr = 2.68433e-07
I0826 11:56:00.616922  1343 solver.cpp:228] Iteration 95600, loss = 3.33016
I0826 11:56:00.616978  1343 solver.cpp:244]     Train net output #0: loss = 3.33016 (* 1 = 3.33016 loss)
I0826 11:56:00.616986  1343 sgd_solver.cpp:106] Iteration 95600, lr = 2.68259e-07
I0826 11:56:09.043618  1343 solver.cpp:228] Iteration 95700, loss = 3.46894
I0826 11:56:09.043678  1343 solver.cpp:244]     Train net output #0: loss = 3.46894 (* 1 = 3.46894 loss)
I0826 11:56:09.043686  1343 sgd_solver.cpp:106] Iteration 95700, lr = 2.68085e-07
I0826 11:56:17.461586  1343 solver.cpp:228] Iteration 95800, loss = 3.41375
I0826 11:56:17.461652  1343 solver.cpp:244]     Train net output #0: loss = 3.41375 (* 1 = 3.41375 loss)
I0826 11:56:17.461663  1343 sgd_solver.cpp:106] Iteration 95800, lr = 2.67911e-07
I0826 11:56:25.888294  1343 solver.cpp:228] Iteration 95900, loss = 3.47128
I0826 11:56:25.888355  1343 solver.cpp:244]     Train net output #0: loss = 3.47128 (* 1 = 3.47128 loss)
I0826 11:56:25.888362  1343 sgd_solver.cpp:106] Iteration 95900, lr = 2.67738e-07
I0826 11:56:34.296667  1343 solver.cpp:228] Iteration 96000, loss = 3.35529
I0826 11:56:34.296728  1343 solver.cpp:244]     Train net output #0: loss = 3.35529 (* 1 = 3.35529 loss)
I0826 11:56:34.296736  1343 sgd_solver.cpp:106] Iteration 96000, lr = 2.67565e-07
I0826 11:56:42.720587  1343 solver.cpp:228] Iteration 96100, loss = 3.42781
I0826 11:56:42.720630  1343 solver.cpp:244]     Train net output #0: loss = 3.42781 (* 1 = 3.42781 loss)
I0826 11:56:42.720635  1343 sgd_solver.cpp:106] Iteration 96100, lr = 2.67392e-07
I0826 11:56:51.153084  1343 solver.cpp:228] Iteration 96200, loss = 3.51588
I0826 11:56:51.153126  1343 solver.cpp:244]     Train net output #0: loss = 3.51588 (* 1 = 3.51588 loss)
I0826 11:56:51.153131  1343 sgd_solver.cpp:106] Iteration 96200, lr = 2.67219e-07
I0826 11:56:59.579530  1343 solver.cpp:228] Iteration 96300, loss = 3.39051
I0826 11:56:59.579586  1343 solver.cpp:244]     Train net output #0: loss = 3.39051 (* 1 = 3.39051 loss)
I0826 11:56:59.579594  1343 sgd_solver.cpp:106] Iteration 96300, lr = 2.67047e-07
I0826 11:57:07.984350  1343 solver.cpp:228] Iteration 96400, loss = 3.32959
I0826 11:57:07.984387  1343 solver.cpp:244]     Train net output #0: loss = 3.32959 (* 1 = 3.32959 loss)
I0826 11:57:07.984393  1343 sgd_solver.cpp:106] Iteration 96400, lr = 2.66875e-07
I0826 11:57:16.395673  1343 solver.cpp:228] Iteration 96500, loss = 3.47439
I0826 11:57:16.395745  1343 solver.cpp:244]     Train net output #0: loss = 3.47439 (* 1 = 3.47439 loss)
I0826 11:57:16.395756  1343 sgd_solver.cpp:106] Iteration 96500, lr = 2.66703e-07
I0826 11:57:24.818634  1343 solver.cpp:228] Iteration 96600, loss = 3.44214
I0826 11:57:24.818712  1343 solver.cpp:244]     Train net output #0: loss = 3.44214 (* 1 = 3.44214 loss)
I0826 11:57:24.818724  1343 sgd_solver.cpp:106] Iteration 96600, lr = 2.66532e-07
I0826 11:57:33.228848  1343 solver.cpp:228] Iteration 96700, loss = 3.37896
I0826 11:57:33.228893  1343 solver.cpp:244]     Train net output #0: loss = 3.37896 (* 1 = 3.37896 loss)
I0826 11:57:33.228898  1343 sgd_solver.cpp:106] Iteration 96700, lr = 2.6636e-07
I0826 11:57:41.645879  1343 solver.cpp:228] Iteration 96800, loss = 3.46988
I0826 11:57:41.645927  1343 solver.cpp:244]     Train net output #0: loss = 3.46988 (* 1 = 3.46988 loss)
I0826 11:57:41.645933  1343 sgd_solver.cpp:106] Iteration 96800, lr = 2.66189e-07
I0826 11:57:50.078753  1343 solver.cpp:228] Iteration 96900, loss = 3.49221
I0826 11:57:50.078810  1343 solver.cpp:244]     Train net output #0: loss = 3.49221 (* 1 = 3.49221 loss)
I0826 11:57:50.078821  1343 sgd_solver.cpp:106] Iteration 96900, lr = 2.66018e-07
I0826 11:57:58.242009  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 11:57:58.496924  1343 solver.cpp:228] Iteration 97000, loss = 3.44282
I0826 11:57:58.496970  1343 solver.cpp:244]     Train net output #0: loss = 3.44282 (* 1 = 3.44282 loss)
I0826 11:57:58.496981  1343 sgd_solver.cpp:106] Iteration 97000, lr = 2.65848e-07
I0826 11:58:06.925623  1343 solver.cpp:228] Iteration 97100, loss = 3.54961
I0826 11:58:06.925681  1343 solver.cpp:244]     Train net output #0: loss = 3.54961 (* 1 = 3.54961 loss)
I0826 11:58:06.925690  1343 sgd_solver.cpp:106] Iteration 97100, lr = 2.65678e-07
I0826 11:58:15.340111  1343 solver.cpp:228] Iteration 97200, loss = 3.57096
I0826 11:58:15.340173  1343 solver.cpp:244]     Train net output #0: loss = 3.57096 (* 1 = 3.57096 loss)
I0826 11:58:15.340180  1343 sgd_solver.cpp:106] Iteration 97200, lr = 2.65508e-07
I0826 11:58:23.771905  1343 solver.cpp:228] Iteration 97300, loss = 3.31813
I0826 11:58:23.771947  1343 solver.cpp:244]     Train net output #0: loss = 3.31813 (* 1 = 3.31813 loss)
I0826 11:58:23.771952  1343 sgd_solver.cpp:106] Iteration 97300, lr = 2.65338e-07
I0826 11:58:32.207739  1343 solver.cpp:228] Iteration 97400, loss = 3.4595
I0826 11:58:32.207813  1343 solver.cpp:244]     Train net output #0: loss = 3.4595 (* 1 = 3.4595 loss)
I0826 11:58:32.207826  1343 sgd_solver.cpp:106] Iteration 97400, lr = 2.65168e-07
I0826 11:58:40.640660  1343 solver.cpp:228] Iteration 97500, loss = 3.4164
I0826 11:58:40.640709  1343 solver.cpp:244]     Train net output #0: loss = 3.4164 (* 1 = 3.4164 loss)
I0826 11:58:40.640717  1343 sgd_solver.cpp:106] Iteration 97500, lr = 2.64999e-07
I0826 11:58:49.058907  1343 solver.cpp:228] Iteration 97600, loss = 3.46703
I0826 11:58:49.058971  1343 solver.cpp:244]     Train net output #0: loss = 3.46703 (* 1 = 3.46703 loss)
I0826 11:58:49.058982  1343 sgd_solver.cpp:106] Iteration 97600, lr = 2.6483e-07
I0826 11:58:57.455027  1343 solver.cpp:228] Iteration 97700, loss = 3.38807
I0826 11:58:57.455072  1343 solver.cpp:244]     Train net output #0: loss = 3.38807 (* 1 = 3.38807 loss)
I0826 11:58:57.455078  1343 sgd_solver.cpp:106] Iteration 97700, lr = 2.64661e-07
I0826 11:59:05.882504  1343 solver.cpp:228] Iteration 97800, loss = 3.44878
I0826 11:59:05.882565  1343 solver.cpp:244]     Train net output #0: loss = 3.44878 (* 1 = 3.44878 loss)
I0826 11:59:05.882575  1343 sgd_solver.cpp:106] Iteration 97800, lr = 2.64493e-07
I0826 11:59:14.303256  1343 solver.cpp:228] Iteration 97900, loss = 3.45069
I0826 11:59:14.303305  1343 solver.cpp:244]     Train net output #0: loss = 3.45069 (* 1 = 3.45069 loss)
I0826 11:59:14.303313  1343 sgd_solver.cpp:106] Iteration 97900, lr = 2.64324e-07
I0826 11:59:22.706948  1343 solver.cpp:228] Iteration 98000, loss = 3.44509
I0826 11:59:22.706998  1343 solver.cpp:244]     Train net output #0: loss = 3.44509 (* 1 = 3.44509 loss)
I0826 11:59:22.707005  1343 sgd_solver.cpp:106] Iteration 98000, lr = 2.64156e-07
I0826 11:59:31.125401  1343 solver.cpp:228] Iteration 98100, loss = 3.4356
I0826 11:59:31.125444  1343 solver.cpp:244]     Train net output #0: loss = 3.4356 (* 1 = 3.4356 loss)
I0826 11:59:31.125450  1343 sgd_solver.cpp:106] Iteration 98100, lr = 2.63989e-07
I0826 11:59:39.539053  1343 solver.cpp:228] Iteration 98200, loss = 3.4885
I0826 11:59:39.539096  1343 solver.cpp:244]     Train net output #0: loss = 3.4885 (* 1 = 3.4885 loss)
I0826 11:59:39.539103  1343 sgd_solver.cpp:106] Iteration 98200, lr = 2.63821e-07
I0826 11:59:47.969334  1343 solver.cpp:228] Iteration 98300, loss = 3.60728
I0826 11:59:47.969386  1343 solver.cpp:244]     Train net output #0: loss = 3.60728 (* 1 = 3.60728 loss)
I0826 11:59:47.969395  1343 sgd_solver.cpp:106] Iteration 98300, lr = 2.63654e-07
I0826 11:59:56.390331  1343 solver.cpp:228] Iteration 98400, loss = 3.67424
I0826 11:59:56.390409  1343 solver.cpp:244]     Train net output #0: loss = 3.67424 (* 1 = 3.67424 loss)
I0826 11:59:56.390424  1343 sgd_solver.cpp:106] Iteration 98400, lr = 2.63487e-07
I0826 12:00:04.815408  1343 solver.cpp:228] Iteration 98500, loss = 3.6342
I0826 12:00:04.815466  1343 solver.cpp:244]     Train net output #0: loss = 3.6342 (* 1 = 3.6342 loss)
I0826 12:00:04.815474  1343 sgd_solver.cpp:106] Iteration 98500, lr = 2.6332e-07
I0826 12:00:13.242470  1343 solver.cpp:228] Iteration 98600, loss = 3.40137
I0826 12:00:13.242552  1343 solver.cpp:244]     Train net output #0: loss = 3.40137 (* 1 = 3.40137 loss)
I0826 12:00:13.242563  1343 sgd_solver.cpp:106] Iteration 98600, lr = 2.63153e-07
I0826 12:00:21.664739  1343 solver.cpp:228] Iteration 98700, loss = 3.33902
I0826 12:00:21.664820  1343 solver.cpp:244]     Train net output #0: loss = 3.33902 (* 1 = 3.33902 loss)
I0826 12:00:21.664829  1343 sgd_solver.cpp:106] Iteration 98700, lr = 2.62987e-07
I0826 12:00:30.076983  1343 solver.cpp:228] Iteration 98800, loss = 3.46889
I0826 12:00:30.077044  1343 solver.cpp:244]     Train net output #0: loss = 3.46889 (* 1 = 3.46889 loss)
I0826 12:00:30.077052  1343 sgd_solver.cpp:106] Iteration 98800, lr = 2.62821e-07
I0826 12:00:38.491542  1343 solver.cpp:228] Iteration 98900, loss = 3.35928
I0826 12:00:38.491582  1343 solver.cpp:244]     Train net output #0: loss = 3.35928 (* 1 = 3.35928 loss)
I0826 12:00:38.491587  1343 sgd_solver.cpp:106] Iteration 98900, lr = 2.62655e-07
I0826 12:00:46.905428  1343 solver.cpp:228] Iteration 99000, loss = 3.59062
I0826 12:00:46.905488  1343 solver.cpp:244]     Train net output #0: loss = 3.59062 (* 1 = 3.59062 loss)
I0826 12:00:46.905496  1343 sgd_solver.cpp:106] Iteration 99000, lr = 2.6249e-07
I0826 12:00:55.310670  1343 solver.cpp:228] Iteration 99100, loss = 3.53611
I0826 12:00:55.310729  1343 solver.cpp:244]     Train net output #0: loss = 3.53611 (* 1 = 3.53611 loss)
I0826 12:00:55.310736  1343 sgd_solver.cpp:106] Iteration 99100, lr = 2.62324e-07
I0826 12:01:03.734881  1343 solver.cpp:228] Iteration 99200, loss = 3.46421
I0826 12:01:03.734938  1343 solver.cpp:244]     Train net output #0: loss = 3.46421 (* 1 = 3.46421 loss)
I0826 12:01:03.734946  1343 sgd_solver.cpp:106] Iteration 99200, lr = 2.62159e-07
I0826 12:01:12.172206  1343 solver.cpp:228] Iteration 99300, loss = 3.43803
I0826 12:01:12.172276  1343 solver.cpp:244]     Train net output #0: loss = 3.43803 (* 1 = 3.43803 loss)
I0826 12:01:12.172286  1343 sgd_solver.cpp:106] Iteration 99300, lr = 2.61995e-07
I0826 12:01:20.596812  1343 solver.cpp:228] Iteration 99400, loss = 3.44584
I0826 12:01:20.596873  1343 solver.cpp:244]     Train net output #0: loss = 3.44584 (* 1 = 3.44584 loss)
I0826 12:01:20.596880  1343 sgd_solver.cpp:106] Iteration 99400, lr = 2.6183e-07
I0826 12:01:29.007040  1343 solver.cpp:228] Iteration 99500, loss = 3.42598
I0826 12:01:29.007096  1343 solver.cpp:244]     Train net output #0: loss = 3.42598 (* 1 = 3.42598 loss)
I0826 12:01:29.007104  1343 sgd_solver.cpp:106] Iteration 99500, lr = 2.61666e-07
I0826 12:01:37.432374  1343 solver.cpp:228] Iteration 99600, loss = 3.63717
I0826 12:01:37.432432  1343 solver.cpp:244]     Train net output #0: loss = 3.63717 (* 1 = 3.63717 loss)
I0826 12:01:37.432440  1343 sgd_solver.cpp:106] Iteration 99600, lr = 2.61501e-07
I0826 12:01:45.859632  1343 solver.cpp:228] Iteration 99700, loss = 3.46482
I0826 12:01:45.859693  1343 solver.cpp:244]     Train net output #0: loss = 3.46482 (* 1 = 3.46482 loss)
I0826 12:01:45.859700  1343 sgd_solver.cpp:106] Iteration 99700, lr = 2.61338e-07
I0826 12:01:54.287263  1343 solver.cpp:228] Iteration 99800, loss = 3.61838
I0826 12:01:54.287307  1343 solver.cpp:244]     Train net output #0: loss = 3.61838 (* 1 = 3.61838 loss)
I0826 12:01:54.287313  1343 sgd_solver.cpp:106] Iteration 99800, lr = 2.61174e-07
I0826 12:02:02.691717  1343 solver.cpp:228] Iteration 99900, loss = 3.56113
I0826 12:02:02.691797  1343 solver.cpp:244]     Train net output #0: loss = 3.56113 (* 1 = 3.56113 loss)
I0826 12:02:02.691812  1343 sgd_solver.cpp:106] Iteration 99900, lr = 2.61011e-07
I0826 12:02:11.024828  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_100000.caffemodel
I0826 12:02:11.532615  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_100000.solverstate
I0826 12:02:11.693725  1343 solver.cpp:337] Iteration 100000, Testing net (#0)
I0826 12:02:15.447433  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:02:49.431320  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302058
I0826 12:02:49.431367  1343 solver.cpp:404]     Test net output #1: loss = 3.44182 (* 1 = 3.44182 loss)
I0826 12:02:49.460507  1343 solver.cpp:228] Iteration 100000, loss = 3.29976
I0826 12:02:49.460566  1343 solver.cpp:244]     Train net output #0: loss = 3.29976 (* 1 = 3.29976 loss)
I0826 12:02:49.460587  1343 sgd_solver.cpp:106] Iteration 100000, lr = 2.60847e-07
I0826 12:02:57.888176  1343 solver.cpp:228] Iteration 100100, loss = 3.49824
I0826 12:02:57.888234  1343 solver.cpp:244]     Train net output #0: loss = 3.49824 (* 1 = 3.49824 loss)
I0826 12:02:57.888247  1343 sgd_solver.cpp:106] Iteration 100100, lr = 2.60685e-07
I0826 12:03:06.277513  1343 solver.cpp:228] Iteration 100200, loss = 3.38027
I0826 12:03:06.277602  1343 solver.cpp:244]     Train net output #0: loss = 3.38027 (* 1 = 3.38027 loss)
I0826 12:03:06.277611  1343 sgd_solver.cpp:106] Iteration 100200, lr = 2.60522e-07
I0826 12:03:14.696554  1343 solver.cpp:228] Iteration 100300, loss = 3.49172
I0826 12:03:14.696610  1343 solver.cpp:244]     Train net output #0: loss = 3.49172 (* 1 = 3.49172 loss)
I0826 12:03:14.696617  1343 sgd_solver.cpp:106] Iteration 100300, lr = 2.60359e-07
I0826 12:03:23.117550  1343 solver.cpp:228] Iteration 100400, loss = 3.27134
I0826 12:03:23.117633  1343 solver.cpp:244]     Train net output #0: loss = 3.27134 (* 1 = 3.27134 loss)
I0826 12:03:23.117645  1343 sgd_solver.cpp:106] Iteration 100400, lr = 2.60197e-07
I0826 12:03:27.830840  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:03:31.528005  1343 solver.cpp:228] Iteration 100500, loss = 3.59367
I0826 12:03:31.528079  1343 solver.cpp:244]     Train net output #0: loss = 3.59367 (* 1 = 3.59367 loss)
I0826 12:03:31.528087  1343 sgd_solver.cpp:106] Iteration 100500, lr = 2.60035e-07
I0826 12:03:39.942736  1343 solver.cpp:228] Iteration 100600, loss = 3.43928
I0826 12:03:39.942781  1343 solver.cpp:244]     Train net output #0: loss = 3.43928 (* 1 = 3.43928 loss)
I0826 12:03:39.942786  1343 sgd_solver.cpp:106] Iteration 100600, lr = 2.59874e-07
I0826 12:03:48.343636  1343 solver.cpp:228] Iteration 100700, loss = 3.55006
I0826 12:03:48.343685  1343 solver.cpp:244]     Train net output #0: loss = 3.55006 (* 1 = 3.55006 loss)
I0826 12:03:48.343691  1343 sgd_solver.cpp:106] Iteration 100700, lr = 2.59712e-07
I0826 12:03:56.766324  1343 solver.cpp:228] Iteration 100800, loss = 3.67086
I0826 12:03:56.766382  1343 solver.cpp:244]     Train net output #0: loss = 3.67086 (* 1 = 3.67086 loss)
I0826 12:03:56.766391  1343 sgd_solver.cpp:106] Iteration 100800, lr = 2.59551e-07
I0826 12:04:05.182873  1343 solver.cpp:228] Iteration 100900, loss = 3.5134
I0826 12:04:05.182929  1343 solver.cpp:244]     Train net output #0: loss = 3.5134 (* 1 = 3.5134 loss)
I0826 12:04:05.182950  1343 sgd_solver.cpp:106] Iteration 100900, lr = 2.5939e-07
I0826 12:04:13.585117  1343 solver.cpp:228] Iteration 101000, loss = 3.40495
I0826 12:04:13.585166  1343 solver.cpp:244]     Train net output #0: loss = 3.40495 (* 1 = 3.40495 loss)
I0826 12:04:13.585171  1343 sgd_solver.cpp:106] Iteration 101000, lr = 2.59229e-07
I0826 12:04:22.003473  1343 solver.cpp:228] Iteration 101100, loss = 3.43747
I0826 12:04:22.003532  1343 solver.cpp:244]     Train net output #0: loss = 3.43747 (* 1 = 3.43747 loss)
I0826 12:04:22.003545  1343 sgd_solver.cpp:106] Iteration 101100, lr = 2.59068e-07
I0826 12:04:30.424412  1343 solver.cpp:228] Iteration 101200, loss = 3.46107
I0826 12:04:30.424466  1343 solver.cpp:244]     Train net output #0: loss = 3.46107 (* 1 = 3.46107 loss)
I0826 12:04:30.424480  1343 sgd_solver.cpp:106] Iteration 101200, lr = 2.58908e-07
I0826 12:04:38.850116  1343 solver.cpp:228] Iteration 101300, loss = 3.50513
I0826 12:04:38.850168  1343 solver.cpp:244]     Train net output #0: loss = 3.50513 (* 1 = 3.50513 loss)
I0826 12:04:38.850175  1343 sgd_solver.cpp:106] Iteration 101300, lr = 2.58748e-07
I0826 12:04:47.257997  1343 solver.cpp:228] Iteration 101400, loss = 3.3512
I0826 12:04:47.258059  1343 solver.cpp:244]     Train net output #0: loss = 3.3512 (* 1 = 3.3512 loss)
I0826 12:04:47.258066  1343 sgd_solver.cpp:106] Iteration 101400, lr = 2.58588e-07
I0826 12:04:55.684267  1343 solver.cpp:228] Iteration 101500, loss = 3.35246
I0826 12:04:55.684321  1343 solver.cpp:244]     Train net output #0: loss = 3.35246 (* 1 = 3.35246 loss)
I0826 12:04:55.684329  1343 sgd_solver.cpp:106] Iteration 101500, lr = 2.58428e-07
I0826 12:05:04.118471  1343 solver.cpp:228] Iteration 101600, loss = 3.48543
I0826 12:05:04.118541  1343 solver.cpp:244]     Train net output #0: loss = 3.48543 (* 1 = 3.48543 loss)
I0826 12:05:04.118549  1343 sgd_solver.cpp:106] Iteration 101600, lr = 2.58269e-07
I0826 12:05:12.536077  1343 solver.cpp:228] Iteration 101700, loss = 3.60385
I0826 12:05:12.536134  1343 solver.cpp:244]     Train net output #0: loss = 3.60385 (* 1 = 3.60385 loss)
I0826 12:05:12.536144  1343 sgd_solver.cpp:106] Iteration 101700, lr = 2.5811e-07
I0826 12:05:20.950577  1343 solver.cpp:228] Iteration 101800, loss = 3.58241
I0826 12:05:20.950652  1343 solver.cpp:244]     Train net output #0: loss = 3.58241 (* 1 = 3.58241 loss)
I0826 12:05:20.950662  1343 sgd_solver.cpp:106] Iteration 101800, lr = 2.57951e-07
I0826 12:05:29.375692  1343 solver.cpp:228] Iteration 101900, loss = 3.45588
I0826 12:05:29.375751  1343 solver.cpp:244]     Train net output #0: loss = 3.45588 (* 1 = 3.45588 loss)
I0826 12:05:29.375758  1343 sgd_solver.cpp:106] Iteration 101900, lr = 2.57792e-07
I0826 12:05:37.795984  1343 solver.cpp:228] Iteration 102000, loss = 3.31797
I0826 12:05:37.796043  1343 solver.cpp:244]     Train net output #0: loss = 3.31797 (* 1 = 3.31797 loss)
I0826 12:05:37.796051  1343 sgd_solver.cpp:106] Iteration 102000, lr = 2.57634e-07
I0826 12:05:46.213802  1343 solver.cpp:228] Iteration 102100, loss = 3.4968
I0826 12:05:46.213860  1343 solver.cpp:244]     Train net output #0: loss = 3.4968 (* 1 = 3.4968 loss)
I0826 12:05:46.213867  1343 sgd_solver.cpp:106] Iteration 102100, lr = 2.57475e-07
I0826 12:05:54.620466  1343 solver.cpp:228] Iteration 102200, loss = 3.52993
I0826 12:05:54.620533  1343 solver.cpp:244]     Train net output #0: loss = 3.52993 (* 1 = 3.52993 loss)
I0826 12:05:54.620543  1343 sgd_solver.cpp:106] Iteration 102200, lr = 2.57317e-07
I0826 12:06:03.044639  1343 solver.cpp:228] Iteration 102300, loss = 3.39209
I0826 12:06:03.044683  1343 solver.cpp:244]     Train net output #0: loss = 3.39209 (* 1 = 3.39209 loss)
I0826 12:06:03.044688  1343 sgd_solver.cpp:106] Iteration 102300, lr = 2.5716e-07
I0826 12:06:11.478292  1343 solver.cpp:228] Iteration 102400, loss = 3.44586
I0826 12:06:11.478359  1343 solver.cpp:244]     Train net output #0: loss = 3.44586 (* 1 = 3.44586 loss)
I0826 12:06:11.478368  1343 sgd_solver.cpp:106] Iteration 102400, lr = 2.57002e-07
I0826 12:06:19.898955  1343 solver.cpp:228] Iteration 102500, loss = 3.44678
I0826 12:06:19.899016  1343 solver.cpp:244]     Train net output #0: loss = 3.44678 (* 1 = 3.44678 loss)
I0826 12:06:19.899029  1343 sgd_solver.cpp:106] Iteration 102500, lr = 2.56845e-07
I0826 12:06:28.303614  1343 solver.cpp:228] Iteration 102600, loss = 3.42962
I0826 12:06:28.303669  1343 solver.cpp:244]     Train net output #0: loss = 3.42962 (* 1 = 3.42962 loss)
I0826 12:06:28.303678  1343 sgd_solver.cpp:106] Iteration 102600, lr = 2.56687e-07
I0826 12:06:36.718848  1343 solver.cpp:228] Iteration 102700, loss = 3.2967
I0826 12:06:36.718904  1343 solver.cpp:244]     Train net output #0: loss = 3.2967 (* 1 = 3.2967 loss)
I0826 12:06:36.718915  1343 sgd_solver.cpp:106] Iteration 102700, lr = 2.56531e-07
I0826 12:06:45.146306  1343 solver.cpp:228] Iteration 102800, loss = 3.53193
I0826 12:06:45.146353  1343 solver.cpp:244]     Train net output #0: loss = 3.53193 (* 1 = 3.53193 loss)
I0826 12:06:45.146358  1343 sgd_solver.cpp:106] Iteration 102800, lr = 2.56374e-07
I0826 12:06:53.544594  1343 solver.cpp:228] Iteration 102900, loss = 3.32629
I0826 12:06:53.544639  1343 solver.cpp:244]     Train net output #0: loss = 3.32629 (* 1 = 3.32629 loss)
I0826 12:06:53.544649  1343 sgd_solver.cpp:106] Iteration 102900, lr = 2.56217e-07
I0826 12:07:01.963274  1343 solver.cpp:228] Iteration 103000, loss = 3.50253
I0826 12:07:01.963318  1343 solver.cpp:244]     Train net output #0: loss = 3.50253 (* 1 = 3.50253 loss)
I0826 12:07:01.963325  1343 sgd_solver.cpp:106] Iteration 103000, lr = 2.56061e-07
I0826 12:07:10.385941  1343 solver.cpp:228] Iteration 103100, loss = 3.52096
I0826 12:07:10.386010  1343 solver.cpp:244]     Train net output #0: loss = 3.52096 (* 1 = 3.52096 loss)
I0826 12:07:10.386021  1343 sgd_solver.cpp:106] Iteration 103100, lr = 2.55905e-07
I0826 12:07:18.801568  1343 solver.cpp:228] Iteration 103200, loss = 3.34065
I0826 12:07:18.801614  1343 solver.cpp:244]     Train net output #0: loss = 3.34065 (* 1 = 3.34065 loss)
I0826 12:07:18.801620  1343 sgd_solver.cpp:106] Iteration 103200, lr = 2.55749e-07
I0826 12:07:27.226105  1343 solver.cpp:228] Iteration 103300, loss = 3.48871
I0826 12:07:27.226167  1343 solver.cpp:244]     Train net output #0: loss = 3.48871 (* 1 = 3.48871 loss)
I0826 12:07:27.226177  1343 sgd_solver.cpp:106] Iteration 103300, lr = 2.55594e-07
I0826 12:07:35.651082  1343 solver.cpp:228] Iteration 103400, loss = 3.44178
I0826 12:07:35.651130  1343 solver.cpp:244]     Train net output #0: loss = 3.44178 (* 1 = 3.44178 loss)
I0826 12:07:35.651139  1343 sgd_solver.cpp:106] Iteration 103400, lr = 2.55438e-07
I0826 12:07:44.065968  1343 solver.cpp:228] Iteration 103500, loss = 3.32236
I0826 12:07:44.066015  1343 solver.cpp:244]     Train net output #0: loss = 3.32236 (* 1 = 3.32236 loss)
I0826 12:07:44.066020  1343 sgd_solver.cpp:106] Iteration 103500, lr = 2.55283e-07
I0826 12:07:52.474597  1343 solver.cpp:228] Iteration 103600, loss = 3.51484
I0826 12:07:52.474666  1343 solver.cpp:244]     Train net output #0: loss = 3.51484 (* 1 = 3.51484 loss)
I0826 12:07:52.474675  1343 sgd_solver.cpp:106] Iteration 103600, lr = 2.55128e-07
I0826 12:08:00.899371  1343 solver.cpp:228] Iteration 103700, loss = 3.44831
I0826 12:08:00.899442  1343 solver.cpp:244]     Train net output #0: loss = 3.44831 (* 1 = 3.44831 loss)
I0826 12:08:00.899451  1343 sgd_solver.cpp:106] Iteration 103700, lr = 2.54974e-07
I0826 12:08:09.321833  1343 solver.cpp:228] Iteration 103800, loss = 3.39178
I0826 12:08:09.321913  1343 solver.cpp:244]     Train net output #0: loss = 3.39178 (* 1 = 3.39178 loss)
I0826 12:08:09.321924  1343 sgd_solver.cpp:106] Iteration 103800, lr = 2.54819e-07
I0826 12:08:17.755728  1343 solver.cpp:228] Iteration 103900, loss = 3.29828
I0826 12:08:17.755806  1343 solver.cpp:244]     Train net output #0: loss = 3.29828 (* 1 = 3.29828 loss)
I0826 12:08:17.755822  1343 sgd_solver.cpp:106] Iteration 103900, lr = 2.54665e-07
I0826 12:08:26.177139  1343 solver.cpp:228] Iteration 104000, loss = 3.47055
I0826 12:08:26.177217  1343 solver.cpp:244]     Train net output #0: loss = 3.47055 (* 1 = 3.47055 loss)
I0826 12:08:26.177228  1343 sgd_solver.cpp:106] Iteration 104000, lr = 2.54511e-07
I0826 12:08:34.591641  1343 solver.cpp:228] Iteration 104100, loss = 3.5017
I0826 12:08:34.591688  1343 solver.cpp:244]     Train net output #0: loss = 3.5017 (* 1 = 3.5017 loss)
I0826 12:08:34.591694  1343 sgd_solver.cpp:106] Iteration 104100, lr = 2.54357e-07
I0826 12:08:43.011104  1343 solver.cpp:228] Iteration 104200, loss = 3.4638
I0826 12:08:43.011178  1343 solver.cpp:244]     Train net output #0: loss = 3.4638 (* 1 = 3.4638 loss)
I0826 12:08:43.011186  1343 sgd_solver.cpp:106] Iteration 104200, lr = 2.54203e-07
I0826 12:08:51.436197  1343 solver.cpp:228] Iteration 104300, loss = 3.41122
I0826 12:08:51.436251  1343 solver.cpp:244]     Train net output #0: loss = 3.41122 (* 1 = 3.41122 loss)
I0826 12:08:51.436260  1343 sgd_solver.cpp:106] Iteration 104300, lr = 2.5405e-07
I0826 12:08:54.882383  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:08:59.845722  1343 solver.cpp:228] Iteration 104400, loss = 3.43222
I0826 12:08:59.845791  1343 solver.cpp:244]     Train net output #0: loss = 3.43222 (* 1 = 3.43222 loss)
I0826 12:08:59.845804  1343 sgd_solver.cpp:106] Iteration 104400, lr = 2.53897e-07
I0826 12:09:08.270427  1343 solver.cpp:228] Iteration 104500, loss = 3.47863
I0826 12:09:08.270521  1343 solver.cpp:244]     Train net output #0: loss = 3.47863 (* 1 = 3.47863 loss)
I0826 12:09:08.270539  1343 sgd_solver.cpp:106] Iteration 104500, lr = 2.53744e-07
I0826 12:09:16.693176  1343 solver.cpp:228] Iteration 104600, loss = 3.70962
I0826 12:09:16.693245  1343 solver.cpp:244]     Train net output #0: loss = 3.70962 (* 1 = 3.70962 loss)
I0826 12:09:16.693254  1343 sgd_solver.cpp:106] Iteration 104600, lr = 2.53591e-07
I0826 12:09:25.115077  1343 solver.cpp:228] Iteration 104700, loss = 3.28046
I0826 12:09:25.115130  1343 solver.cpp:244]     Train net output #0: loss = 3.28046 (* 1 = 3.28046 loss)
I0826 12:09:25.115139  1343 sgd_solver.cpp:106] Iteration 104700, lr = 2.53439e-07
I0826 12:09:33.510186  1343 solver.cpp:228] Iteration 104800, loss = 3.42793
I0826 12:09:33.510229  1343 solver.cpp:244]     Train net output #0: loss = 3.42793 (* 1 = 3.42793 loss)
I0826 12:09:33.510236  1343 sgd_solver.cpp:106] Iteration 104800, lr = 2.53286e-07
I0826 12:09:41.929392  1343 solver.cpp:228] Iteration 104900, loss = 3.41081
I0826 12:09:41.929451  1343 solver.cpp:244]     Train net output #0: loss = 3.41081 (* 1 = 3.41081 loss)
I0826 12:09:41.929458  1343 sgd_solver.cpp:106] Iteration 104900, lr = 2.53134e-07
I0826 12:09:50.258280  1343 solver.cpp:337] Iteration 105000, Testing net (#0)
I0826 12:10:25.184880  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:10:29.451292  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302051
I0826 12:10:29.451354  1343 solver.cpp:404]     Test net output #1: loss = 3.43958 (* 1 = 3.43958 loss)
I0826 12:10:29.480800  1343 solver.cpp:228] Iteration 105000, loss = 3.40067
I0826 12:10:29.480855  1343 solver.cpp:244]     Train net output #0: loss = 3.40067 (* 1 = 3.40067 loss)
I0826 12:10:29.480882  1343 sgd_solver.cpp:106] Iteration 105000, lr = 2.52982e-07
I0826 12:10:37.884459  1343 solver.cpp:228] Iteration 105100, loss = 3.20418
I0826 12:10:37.884539  1343 solver.cpp:244]     Train net output #0: loss = 3.20418 (* 1 = 3.20418 loss)
I0826 12:10:37.884562  1343 sgd_solver.cpp:106] Iteration 105100, lr = 2.52831e-07
I0826 12:10:46.301321  1343 solver.cpp:228] Iteration 105200, loss = 3.34274
I0826 12:10:46.301383  1343 solver.cpp:244]     Train net output #0: loss = 3.34274 (* 1 = 3.34274 loss)
I0826 12:10:46.301391  1343 sgd_solver.cpp:106] Iteration 105200, lr = 2.52679e-07
I0826 12:10:54.708379  1343 solver.cpp:228] Iteration 105300, loss = 3.33621
I0826 12:10:54.708425  1343 solver.cpp:244]     Train net output #0: loss = 3.33621 (* 1 = 3.33621 loss)
I0826 12:10:54.708431  1343 sgd_solver.cpp:106] Iteration 105300, lr = 2.52528e-07
I0826 12:11:03.127918  1343 solver.cpp:228] Iteration 105400, loss = 3.53915
I0826 12:11:03.127985  1343 solver.cpp:244]     Train net output #0: loss = 3.53915 (* 1 = 3.53915 loss)
I0826 12:11:03.127997  1343 sgd_solver.cpp:106] Iteration 105400, lr = 2.52377e-07
I0826 12:11:11.546828  1343 solver.cpp:228] Iteration 105500, loss = 3.29724
I0826 12:11:11.546885  1343 solver.cpp:244]     Train net output #0: loss = 3.29724 (* 1 = 3.29724 loss)
I0826 12:11:11.546890  1343 sgd_solver.cpp:106] Iteration 105500, lr = 2.52226e-07
I0826 12:11:19.950717  1343 solver.cpp:228] Iteration 105600, loss = 3.27313
I0826 12:11:19.950762  1343 solver.cpp:244]     Train net output #0: loss = 3.27313 (* 1 = 3.27313 loss)
I0826 12:11:19.950767  1343 sgd_solver.cpp:106] Iteration 105600, lr = 2.52075e-07
I0826 12:11:28.361441  1343 solver.cpp:228] Iteration 105700, loss = 3.3177
I0826 12:11:28.361506  1343 solver.cpp:244]     Train net output #0: loss = 3.3177 (* 1 = 3.3177 loss)
I0826 12:11:28.361517  1343 sgd_solver.cpp:106] Iteration 105700, lr = 2.51925e-07
I0826 12:11:36.786837  1343 solver.cpp:228] Iteration 105800, loss = 3.52401
I0826 12:11:36.786900  1343 solver.cpp:244]     Train net output #0: loss = 3.52401 (* 1 = 3.52401 loss)
I0826 12:11:36.786913  1343 sgd_solver.cpp:106] Iteration 105800, lr = 2.51775e-07
I0826 12:11:45.202523  1343 solver.cpp:228] Iteration 105900, loss = 3.43429
I0826 12:11:45.202602  1343 solver.cpp:244]     Train net output #0: loss = 3.43429 (* 1 = 3.43429 loss)
I0826 12:11:45.202611  1343 sgd_solver.cpp:106] Iteration 105900, lr = 2.51625e-07
I0826 12:11:53.618798  1343 solver.cpp:228] Iteration 106000, loss = 3.33105
I0826 12:11:53.618870  1343 solver.cpp:244]     Train net output #0: loss = 3.33105 (* 1 = 3.33105 loss)
I0826 12:11:53.618880  1343 sgd_solver.cpp:106] Iteration 106000, lr = 2.51475e-07
I0826 12:12:02.039577  1343 solver.cpp:228] Iteration 106100, loss = 3.64683
I0826 12:12:02.039635  1343 solver.cpp:244]     Train net output #0: loss = 3.64683 (* 1 = 3.64683 loss)
I0826 12:12:02.039646  1343 sgd_solver.cpp:106] Iteration 106100, lr = 2.51325e-07
I0826 12:12:10.455802  1343 solver.cpp:228] Iteration 106200, loss = 3.36949
I0826 12:12:10.455855  1343 solver.cpp:244]     Train net output #0: loss = 3.36949 (* 1 = 3.36949 loss)
I0826 12:12:10.455863  1343 sgd_solver.cpp:106] Iteration 106200, lr = 2.51176e-07
I0826 12:12:18.882794  1343 solver.cpp:228] Iteration 106300, loss = 3.52552
I0826 12:12:18.882863  1343 solver.cpp:244]     Train net output #0: loss = 3.52552 (* 1 = 3.52552 loss)
I0826 12:12:18.882874  1343 sgd_solver.cpp:106] Iteration 106300, lr = 2.51027e-07
I0826 12:12:27.295039  1343 solver.cpp:228] Iteration 106400, loss = 3.47651
I0826 12:12:27.295116  1343 solver.cpp:244]     Train net output #0: loss = 3.47651 (* 1 = 3.47651 loss)
I0826 12:12:27.295132  1343 sgd_solver.cpp:106] Iteration 106400, lr = 2.50878e-07
I0826 12:12:35.727013  1343 solver.cpp:228] Iteration 106500, loss = 3.38707
I0826 12:12:35.727069  1343 solver.cpp:244]     Train net output #0: loss = 3.38707 (* 1 = 3.38707 loss)
I0826 12:12:35.727077  1343 sgd_solver.cpp:106] Iteration 106500, lr = 2.50729e-07
I0826 12:12:44.152572  1343 solver.cpp:228] Iteration 106600, loss = 3.50487
I0826 12:12:44.152626  1343 solver.cpp:244]     Train net output #0: loss = 3.50487 (* 1 = 3.50487 loss)
I0826 12:12:44.152633  1343 sgd_solver.cpp:106] Iteration 106600, lr = 2.5058e-07
I0826 12:12:52.586329  1343 solver.cpp:228] Iteration 106700, loss = 3.43722
I0826 12:12:52.586400  1343 solver.cpp:244]     Train net output #0: loss = 3.43722 (* 1 = 3.43722 loss)
I0826 12:12:52.586411  1343 sgd_solver.cpp:106] Iteration 106700, lr = 2.50432e-07
I0826 12:13:00.979375  1343 solver.cpp:228] Iteration 106800, loss = 3.47184
I0826 12:13:00.979430  1343 solver.cpp:244]     Train net output #0: loss = 3.47184 (* 1 = 3.47184 loss)
I0826 12:13:00.979439  1343 sgd_solver.cpp:106] Iteration 106800, lr = 2.50284e-07
I0826 12:13:09.393805  1343 solver.cpp:228] Iteration 106900, loss = 3.34012
I0826 12:13:09.393867  1343 solver.cpp:244]     Train net output #0: loss = 3.34012 (* 1 = 3.34012 loss)
I0826 12:13:09.393877  1343 sgd_solver.cpp:106] Iteration 106900, lr = 2.50136e-07
I0826 12:13:17.809357  1343 solver.cpp:228] Iteration 107000, loss = 3.44142
I0826 12:13:17.809412  1343 solver.cpp:244]     Train net output #0: loss = 3.44142 (* 1 = 3.44142 loss)
I0826 12:13:17.809422  1343 sgd_solver.cpp:106] Iteration 107000, lr = 2.49988e-07
I0826 12:13:26.222128  1343 solver.cpp:228] Iteration 107100, loss = 3.39264
I0826 12:13:26.222179  1343 solver.cpp:244]     Train net output #0: loss = 3.39264 (* 1 = 3.39264 loss)
I0826 12:13:26.222188  1343 sgd_solver.cpp:106] Iteration 107100, lr = 2.49841e-07
I0826 12:13:34.646865  1343 solver.cpp:228] Iteration 107200, loss = 3.31045
I0826 12:13:34.646914  1343 solver.cpp:244]     Train net output #0: loss = 3.31045 (* 1 = 3.31045 loss)
I0826 12:13:34.646922  1343 sgd_solver.cpp:106] Iteration 107200, lr = 2.49693e-07
I0826 12:13:43.087039  1343 solver.cpp:228] Iteration 107300, loss = 3.59852
I0826 12:13:43.087101  1343 solver.cpp:244]     Train net output #0: loss = 3.59852 (* 1 = 3.59852 loss)
I0826 12:13:43.087112  1343 sgd_solver.cpp:106] Iteration 107300, lr = 2.49546e-07
I0826 12:13:51.526921  1343 solver.cpp:228] Iteration 107400, loss = 3.32865
I0826 12:13:51.526976  1343 solver.cpp:244]     Train net output #0: loss = 3.32865 (* 1 = 3.32865 loss)
I0826 12:13:51.526984  1343 sgd_solver.cpp:106] Iteration 107400, lr = 2.49399e-07
I0826 12:13:59.953824  1343 solver.cpp:228] Iteration 107500, loss = 3.5562
I0826 12:13:59.953871  1343 solver.cpp:244]     Train net output #0: loss = 3.5562 (* 1 = 3.5562 loss)
I0826 12:13:59.953877  1343 sgd_solver.cpp:106] Iteration 107500, lr = 2.49253e-07
I0826 12:14:08.377234  1343 solver.cpp:228] Iteration 107600, loss = 3.32596
I0826 12:14:08.377292  1343 solver.cpp:244]     Train net output #0: loss = 3.32596 (* 1 = 3.32596 loss)
I0826 12:14:08.377301  1343 sgd_solver.cpp:106] Iteration 107600, lr = 2.49106e-07
I0826 12:14:16.797425  1343 solver.cpp:228] Iteration 107700, loss = 3.36238
I0826 12:14:16.797485  1343 solver.cpp:244]     Train net output #0: loss = 3.36238 (* 1 = 3.36238 loss)
I0826 12:14:16.797499  1343 sgd_solver.cpp:106] Iteration 107700, lr = 2.4896e-07
I0826 12:14:25.227921  1343 solver.cpp:228] Iteration 107800, loss = 3.58397
I0826 12:14:25.227990  1343 solver.cpp:244]     Train net output #0: loss = 3.58397 (* 1 = 3.58397 loss)
I0826 12:14:25.227999  1343 sgd_solver.cpp:106] Iteration 107800, lr = 2.48814e-07
I0826 12:14:33.659296  1343 solver.cpp:228] Iteration 107900, loss = 3.4071
I0826 12:14:33.659353  1343 solver.cpp:244]     Train net output #0: loss = 3.4071 (* 1 = 3.4071 loss)
I0826 12:14:33.659361  1343 sgd_solver.cpp:106] Iteration 107900, lr = 2.48668e-07
I0826 12:14:42.090847  1343 solver.cpp:228] Iteration 108000, loss = 3.52443
I0826 12:14:42.090910  1343 solver.cpp:244]     Train net output #0: loss = 3.52443 (* 1 = 3.52443 loss)
I0826 12:14:42.090924  1343 sgd_solver.cpp:106] Iteration 108000, lr = 2.48522e-07
I0826 12:14:50.514972  1343 solver.cpp:228] Iteration 108100, loss = 3.50097
I0826 12:14:50.515029  1343 solver.cpp:244]     Train net output #0: loss = 3.50097 (* 1 = 3.50097 loss)
I0826 12:14:50.515038  1343 sgd_solver.cpp:106] Iteration 108100, lr = 2.48377e-07
I0826 12:14:58.935086  1343 solver.cpp:228] Iteration 108200, loss = 3.42142
I0826 12:14:58.935148  1343 solver.cpp:244]     Train net output #0: loss = 3.42142 (* 1 = 3.42142 loss)
I0826 12:14:58.935154  1343 sgd_solver.cpp:106] Iteration 108200, lr = 2.48231e-07
I0826 12:15:07.364287  1343 solver.cpp:228] Iteration 108300, loss = 3.35396
I0826 12:15:07.364341  1343 solver.cpp:244]     Train net output #0: loss = 3.35396 (* 1 = 3.35396 loss)
I0826 12:15:07.364349  1343 sgd_solver.cpp:106] Iteration 108300, lr = 2.48086e-07
I0826 12:15:07.617346  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:15:15.798163  1343 solver.cpp:228] Iteration 108400, loss = 3.19781
I0826 12:15:15.798223  1343 solver.cpp:244]     Train net output #0: loss = 3.19781 (* 1 = 3.19781 loss)
I0826 12:15:15.798233  1343 sgd_solver.cpp:106] Iteration 108400, lr = 2.47941e-07
I0826 12:15:24.225690  1343 solver.cpp:228] Iteration 108500, loss = 3.45775
I0826 12:15:24.225764  1343 solver.cpp:244]     Train net output #0: loss = 3.45775 (* 1 = 3.45775 loss)
I0826 12:15:24.225775  1343 sgd_solver.cpp:106] Iteration 108500, lr = 2.47796e-07
I0826 12:15:32.665221  1343 solver.cpp:228] Iteration 108600, loss = 3.55415
I0826 12:15:32.665282  1343 solver.cpp:244]     Train net output #0: loss = 3.55415 (* 1 = 3.55415 loss)
I0826 12:15:32.665288  1343 sgd_solver.cpp:106] Iteration 108600, lr = 2.47652e-07
I0826 12:15:41.098240  1343 solver.cpp:228] Iteration 108700, loss = 3.38591
I0826 12:15:41.098304  1343 solver.cpp:244]     Train net output #0: loss = 3.38591 (* 1 = 3.38591 loss)
I0826 12:15:41.098315  1343 sgd_solver.cpp:106] Iteration 108700, lr = 2.47508e-07
I0826 12:15:49.532850  1343 solver.cpp:228] Iteration 108800, loss = 3.5561
I0826 12:15:49.532915  1343 solver.cpp:244]     Train net output #0: loss = 3.5561 (* 1 = 3.5561 loss)
I0826 12:15:49.532925  1343 sgd_solver.cpp:106] Iteration 108800, lr = 2.47363e-07
I0826 12:15:57.967689  1343 solver.cpp:228] Iteration 108900, loss = 3.47818
I0826 12:15:57.967754  1343 solver.cpp:244]     Train net output #0: loss = 3.47818 (* 1 = 3.47818 loss)
I0826 12:15:57.967763  1343 sgd_solver.cpp:106] Iteration 108900, lr = 2.4722e-07
I0826 12:16:06.369704  1343 solver.cpp:228] Iteration 109000, loss = 3.28726
I0826 12:16:06.369755  1343 solver.cpp:244]     Train net output #0: loss = 3.28726 (* 1 = 3.28726 loss)
I0826 12:16:06.369762  1343 sgd_solver.cpp:106] Iteration 109000, lr = 2.47076e-07
I0826 12:16:14.790194  1343 solver.cpp:228] Iteration 109100, loss = 3.48653
I0826 12:16:14.790261  1343 solver.cpp:244]     Train net output #0: loss = 3.48653 (* 1 = 3.48653 loss)
I0826 12:16:14.790269  1343 sgd_solver.cpp:106] Iteration 109100, lr = 2.46932e-07
I0826 12:16:23.211180  1343 solver.cpp:228] Iteration 109200, loss = 3.36285
I0826 12:16:23.211249  1343 solver.cpp:244]     Train net output #0: loss = 3.36285 (* 1 = 3.36285 loss)
I0826 12:16:23.211259  1343 sgd_solver.cpp:106] Iteration 109200, lr = 2.46789e-07
I0826 12:16:31.641624  1343 solver.cpp:228] Iteration 109300, loss = 3.51662
I0826 12:16:31.641690  1343 solver.cpp:244]     Train net output #0: loss = 3.51662 (* 1 = 3.51662 loss)
I0826 12:16:31.641703  1343 sgd_solver.cpp:106] Iteration 109300, lr = 2.46646e-07
I0826 12:16:40.072283  1343 solver.cpp:228] Iteration 109400, loss = 3.43855
I0826 12:16:40.072337  1343 solver.cpp:244]     Train net output #0: loss = 3.43855 (* 1 = 3.43855 loss)
I0826 12:16:40.072345  1343 sgd_solver.cpp:106] Iteration 109400, lr = 2.46503e-07
I0826 12:16:48.487905  1343 solver.cpp:228] Iteration 109500, loss = 3.50733
I0826 12:16:48.487975  1343 solver.cpp:244]     Train net output #0: loss = 3.50733 (* 1 = 3.50733 loss)
I0826 12:16:48.487987  1343 sgd_solver.cpp:106] Iteration 109500, lr = 2.4636e-07
I0826 12:16:56.919819  1343 solver.cpp:228] Iteration 109600, loss = 3.34495
I0826 12:16:56.919879  1343 solver.cpp:244]     Train net output #0: loss = 3.34495 (* 1 = 3.34495 loss)
I0826 12:16:56.919890  1343 sgd_solver.cpp:106] Iteration 109600, lr = 2.46217e-07
I0826 12:17:05.343983  1343 solver.cpp:228] Iteration 109700, loss = 3.53182
I0826 12:17:05.344022  1343 solver.cpp:244]     Train net output #0: loss = 3.53182 (* 1 = 3.53182 loss)
I0826 12:17:05.344027  1343 sgd_solver.cpp:106] Iteration 109700, lr = 2.46075e-07
I0826 12:17:13.772434  1343 solver.cpp:228] Iteration 109800, loss = 3.34727
I0826 12:17:13.772477  1343 solver.cpp:244]     Train net output #0: loss = 3.34727 (* 1 = 3.34727 loss)
I0826 12:17:13.772483  1343 sgd_solver.cpp:106] Iteration 109800, lr = 2.45933e-07
I0826 12:17:22.196496  1343 solver.cpp:228] Iteration 109900, loss = 3.51215
I0826 12:17:22.196552  1343 solver.cpp:244]     Train net output #0: loss = 3.51215 (* 1 = 3.51215 loss)
I0826 12:17:22.196562  1343 sgd_solver.cpp:106] Iteration 109900, lr = 2.45791e-07
I0826 12:17:30.529727  1343 solver.cpp:337] Iteration 110000, Testing net (#0)
I0826 12:17:50.192356  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:18:07.292176  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302031
I0826 12:18:07.292232  1343 solver.cpp:404]     Test net output #1: loss = 3.43724 (* 1 = 3.43724 loss)
I0826 12:18:07.321530  1343 solver.cpp:228] Iteration 110000, loss = 3.43757
I0826 12:18:07.321573  1343 solver.cpp:244]     Train net output #0: loss = 3.43757 (* 1 = 3.43757 loss)
I0826 12:18:07.321595  1343 sgd_solver.cpp:106] Iteration 110000, lr = 2.45649e-07
I0826 12:18:15.737681  1343 solver.cpp:228] Iteration 110100, loss = 3.38737
I0826 12:18:15.737740  1343 solver.cpp:244]     Train net output #0: loss = 3.38737 (* 1 = 3.38737 loss)
I0826 12:18:15.737746  1343 sgd_solver.cpp:106] Iteration 110100, lr = 2.45507e-07
I0826 12:18:24.163154  1343 solver.cpp:228] Iteration 110200, loss = 3.46139
I0826 12:18:24.163199  1343 solver.cpp:244]     Train net output #0: loss = 3.46139 (* 1 = 3.46139 loss)
I0826 12:18:24.163205  1343 sgd_solver.cpp:106] Iteration 110200, lr = 2.45366e-07
I0826 12:18:32.559185  1343 solver.cpp:228] Iteration 110300, loss = 3.53989
I0826 12:18:32.559231  1343 solver.cpp:244]     Train net output #0: loss = 3.53989 (* 1 = 3.53989 loss)
I0826 12:18:32.559236  1343 sgd_solver.cpp:106] Iteration 110300, lr = 2.45225e-07
I0826 12:18:40.977427  1343 solver.cpp:228] Iteration 110400, loss = 3.49306
I0826 12:18:40.977473  1343 solver.cpp:244]     Train net output #0: loss = 3.49306 (* 1 = 3.49306 loss)
I0826 12:18:40.977478  1343 sgd_solver.cpp:106] Iteration 110400, lr = 2.45084e-07
I0826 12:18:49.387471  1343 solver.cpp:228] Iteration 110500, loss = 3.38101
I0826 12:18:49.387543  1343 solver.cpp:244]     Train net output #0: loss = 3.38101 (* 1 = 3.38101 loss)
I0826 12:18:49.387557  1343 sgd_solver.cpp:106] Iteration 110500, lr = 2.44943e-07
I0826 12:18:57.782660  1343 solver.cpp:228] Iteration 110600, loss = 3.32134
I0826 12:18:57.782711  1343 solver.cpp:244]     Train net output #0: loss = 3.32134 (* 1 = 3.32134 loss)
I0826 12:18:57.782717  1343 sgd_solver.cpp:106] Iteration 110600, lr = 2.44802e-07
I0826 12:19:06.202039  1343 solver.cpp:228] Iteration 110700, loss = 3.54795
I0826 12:19:06.202111  1343 solver.cpp:244]     Train net output #0: loss = 3.54795 (* 1 = 3.54795 loss)
I0826 12:19:06.202121  1343 sgd_solver.cpp:106] Iteration 110700, lr = 2.44662e-07
I0826 12:19:14.617665  1343 solver.cpp:228] Iteration 110800, loss = 3.28616
I0826 12:19:14.617730  1343 solver.cpp:244]     Train net output #0: loss = 3.28616 (* 1 = 3.28616 loss)
I0826 12:19:14.617741  1343 sgd_solver.cpp:106] Iteration 110800, lr = 2.44521e-07
I0826 12:19:23.034098  1343 solver.cpp:228] Iteration 110900, loss = 3.47787
I0826 12:19:23.034168  1343 solver.cpp:244]     Train net output #0: loss = 3.47787 (* 1 = 3.47787 loss)
I0826 12:19:23.034179  1343 sgd_solver.cpp:106] Iteration 110900, lr = 2.44381e-07
I0826 12:19:31.455790  1343 solver.cpp:228] Iteration 111000, loss = 3.63706
I0826 12:19:31.455847  1343 solver.cpp:244]     Train net output #0: loss = 3.63706 (* 1 = 3.63706 loss)
I0826 12:19:31.455855  1343 sgd_solver.cpp:106] Iteration 111000, lr = 2.44241e-07
I0826 12:19:39.871898  1343 solver.cpp:228] Iteration 111100, loss = 3.4178
I0826 12:19:39.871959  1343 solver.cpp:244]     Train net output #0: loss = 3.4178 (* 1 = 3.4178 loss)
I0826 12:19:39.871971  1343 sgd_solver.cpp:106] Iteration 111100, lr = 2.44102e-07
I0826 12:19:48.283442  1343 solver.cpp:228] Iteration 111200, loss = 3.53986
I0826 12:19:48.283494  1343 solver.cpp:244]     Train net output #0: loss = 3.53986 (* 1 = 3.53986 loss)
I0826 12:19:48.283504  1343 sgd_solver.cpp:106] Iteration 111200, lr = 2.43962e-07
I0826 12:19:56.710502  1343 solver.cpp:228] Iteration 111300, loss = 3.39767
I0826 12:19:56.710572  1343 solver.cpp:244]     Train net output #0: loss = 3.39767 (* 1 = 3.39767 loss)
I0826 12:19:56.710587  1343 sgd_solver.cpp:106] Iteration 111300, lr = 2.43823e-07
I0826 12:20:05.137745  1343 solver.cpp:228] Iteration 111400, loss = 3.57621
I0826 12:20:05.137800  1343 solver.cpp:244]     Train net output #0: loss = 3.57621 (* 1 = 3.57621 loss)
I0826 12:20:05.137809  1343 sgd_solver.cpp:106] Iteration 111400, lr = 2.43683e-07
I0826 12:20:13.559715  1343 solver.cpp:228] Iteration 111500, loss = 3.26083
I0826 12:20:13.559784  1343 solver.cpp:244]     Train net output #0: loss = 3.26083 (* 1 = 3.26083 loss)
I0826 12:20:13.559794  1343 sgd_solver.cpp:106] Iteration 111500, lr = 2.43544e-07
I0826 12:20:21.978057  1343 solver.cpp:228] Iteration 111600, loss = 3.39463
I0826 12:20:21.978127  1343 solver.cpp:244]     Train net output #0: loss = 3.39463 (* 1 = 3.39463 loss)
I0826 12:20:21.978135  1343 sgd_solver.cpp:106] Iteration 111600, lr = 2.43406e-07
I0826 12:20:30.381394  1343 solver.cpp:228] Iteration 111700, loss = 3.49618
I0826 12:20:30.381464  1343 solver.cpp:244]     Train net output #0: loss = 3.49618 (* 1 = 3.49618 loss)
I0826 12:20:30.381472  1343 sgd_solver.cpp:106] Iteration 111700, lr = 2.43267e-07
I0826 12:20:38.786980  1343 solver.cpp:228] Iteration 111800, loss = 3.47642
I0826 12:20:38.787029  1343 solver.cpp:244]     Train net output #0: loss = 3.47642 (* 1 = 3.47642 loss)
I0826 12:20:38.787040  1343 sgd_solver.cpp:106] Iteration 111800, lr = 2.43129e-07
I0826 12:20:47.203621  1343 solver.cpp:228] Iteration 111900, loss = 3.55074
I0826 12:20:47.203675  1343 solver.cpp:244]     Train net output #0: loss = 3.55074 (* 1 = 3.55074 loss)
I0826 12:20:47.203683  1343 sgd_solver.cpp:106] Iteration 111900, lr = 2.4299e-07
I0826 12:20:55.630002  1343 solver.cpp:228] Iteration 112000, loss = 3.34813
I0826 12:20:55.630044  1343 solver.cpp:244]     Train net output #0: loss = 3.34813 (* 1 = 3.34813 loss)
I0826 12:20:55.630050  1343 sgd_solver.cpp:106] Iteration 112000, lr = 2.42852e-07
I0826 12:21:03.023041  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:21:04.035084  1343 solver.cpp:228] Iteration 112100, loss = 3.39297
I0826 12:21:04.035130  1343 solver.cpp:244]     Train net output #0: loss = 3.39297 (* 1 = 3.39297 loss)
I0826 12:21:04.035135  1343 sgd_solver.cpp:106] Iteration 112100, lr = 2.42714e-07
I0826 12:21:12.426409  1343 solver.cpp:228] Iteration 112200, loss = 3.6063
I0826 12:21:12.426453  1343 solver.cpp:244]     Train net output #0: loss = 3.6063 (* 1 = 3.6063 loss)
I0826 12:21:12.426460  1343 sgd_solver.cpp:106] Iteration 112200, lr = 2.42577e-07
I0826 12:21:20.842607  1343 solver.cpp:228] Iteration 112300, loss = 3.37142
I0826 12:21:20.842669  1343 solver.cpp:244]     Train net output #0: loss = 3.37142 (* 1 = 3.37142 loss)
I0826 12:21:20.842682  1343 sgd_solver.cpp:106] Iteration 112300, lr = 2.42439e-07
I0826 12:21:29.259462  1343 solver.cpp:228] Iteration 112400, loss = 3.34463
I0826 12:21:29.259522  1343 solver.cpp:244]     Train net output #0: loss = 3.34463 (* 1 = 3.34463 loss)
I0826 12:21:29.259528  1343 sgd_solver.cpp:106] Iteration 112400, lr = 2.42302e-07
I0826 12:21:37.660483  1343 solver.cpp:228] Iteration 112500, loss = 3.42604
I0826 12:21:37.660542  1343 solver.cpp:244]     Train net output #0: loss = 3.42604 (* 1 = 3.42604 loss)
I0826 12:21:37.660553  1343 sgd_solver.cpp:106] Iteration 112500, lr = 2.42165e-07
I0826 12:21:46.068989  1343 solver.cpp:228] Iteration 112600, loss = 3.57577
I0826 12:21:46.069053  1343 solver.cpp:244]     Train net output #0: loss = 3.57577 (* 1 = 3.57577 loss)
I0826 12:21:46.069059  1343 sgd_solver.cpp:106] Iteration 112600, lr = 2.42028e-07
I0826 12:21:54.475723  1343 solver.cpp:228] Iteration 112700, loss = 3.43049
I0826 12:21:54.475777  1343 solver.cpp:244]     Train net output #0: loss = 3.43049 (* 1 = 3.43049 loss)
I0826 12:21:54.475783  1343 sgd_solver.cpp:106] Iteration 112700, lr = 2.41891e-07
I0826 12:22:02.892547  1343 solver.cpp:228] Iteration 112800, loss = 3.49624
I0826 12:22:02.892588  1343 solver.cpp:244]     Train net output #0: loss = 3.49624 (* 1 = 3.49624 loss)
I0826 12:22:02.892594  1343 sgd_solver.cpp:106] Iteration 112800, lr = 2.41754e-07
I0826 12:22:11.279377  1343 solver.cpp:228] Iteration 112900, loss = 3.45945
I0826 12:22:11.279419  1343 solver.cpp:244]     Train net output #0: loss = 3.45945 (* 1 = 3.45945 loss)
I0826 12:22:11.279425  1343 sgd_solver.cpp:106] Iteration 112900, lr = 2.41618e-07
I0826 12:22:19.701859  1343 solver.cpp:228] Iteration 113000, loss = 3.39099
I0826 12:22:19.701931  1343 solver.cpp:244]     Train net output #0: loss = 3.39099 (* 1 = 3.39099 loss)
I0826 12:22:19.701942  1343 sgd_solver.cpp:106] Iteration 113000, lr = 2.41481e-07
I0826 12:22:28.101877  1343 solver.cpp:228] Iteration 113100, loss = 3.38472
I0826 12:22:28.101953  1343 solver.cpp:244]     Train net output #0: loss = 3.38472 (* 1 = 3.38472 loss)
I0826 12:22:28.101961  1343 sgd_solver.cpp:106] Iteration 113100, lr = 2.41345e-07
I0826 12:22:36.522564  1343 solver.cpp:228] Iteration 113200, loss = 3.48291
I0826 12:22:36.522622  1343 solver.cpp:244]     Train net output #0: loss = 3.48291 (* 1 = 3.48291 loss)
I0826 12:22:36.522636  1343 sgd_solver.cpp:106] Iteration 113200, lr = 2.41209e-07
I0826 12:22:44.944380  1343 solver.cpp:228] Iteration 113300, loss = 3.28839
I0826 12:22:44.944447  1343 solver.cpp:244]     Train net output #0: loss = 3.28839 (* 1 = 3.28839 loss)
I0826 12:22:44.944458  1343 sgd_solver.cpp:106] Iteration 113300, lr = 2.41074e-07
I0826 12:22:53.351079  1343 solver.cpp:228] Iteration 113400, loss = 3.41478
I0826 12:22:53.351152  1343 solver.cpp:244]     Train net output #0: loss = 3.41478 (* 1 = 3.41478 loss)
I0826 12:22:53.351164  1343 sgd_solver.cpp:106] Iteration 113400, lr = 2.40938e-07
I0826 12:23:01.773322  1343 solver.cpp:228] Iteration 113500, loss = 3.36349
I0826 12:23:01.773386  1343 solver.cpp:244]     Train net output #0: loss = 3.36349 (* 1 = 3.36349 loss)
I0826 12:23:01.773396  1343 sgd_solver.cpp:106] Iteration 113500, lr = 2.40803e-07
I0826 12:23:10.194986  1343 solver.cpp:228] Iteration 113600, loss = 3.50532
I0826 12:23:10.195052  1343 solver.cpp:244]     Train net output #0: loss = 3.50532 (* 1 = 3.50532 loss)
I0826 12:23:10.195065  1343 sgd_solver.cpp:106] Iteration 113600, lr = 2.40668e-07
I0826 12:23:18.599742  1343 solver.cpp:228] Iteration 113700, loss = 3.46201
I0826 12:23:18.599807  1343 solver.cpp:244]     Train net output #0: loss = 3.46201 (* 1 = 3.46201 loss)
I0826 12:23:18.599817  1343 sgd_solver.cpp:106] Iteration 113700, lr = 2.40533e-07
I0826 12:23:27.013384  1343 solver.cpp:228] Iteration 113800, loss = 3.34439
I0826 12:23:27.013444  1343 solver.cpp:244]     Train net output #0: loss = 3.34439 (* 1 = 3.34439 loss)
I0826 12:23:27.013450  1343 sgd_solver.cpp:106] Iteration 113800, lr = 2.40398e-07
I0826 12:23:35.439610  1343 solver.cpp:228] Iteration 113900, loss = 3.57574
I0826 12:23:35.439677  1343 solver.cpp:244]     Train net output #0: loss = 3.57574 (* 1 = 3.57574 loss)
I0826 12:23:35.439687  1343 sgd_solver.cpp:106] Iteration 113900, lr = 2.40263e-07
I0826 12:23:43.834779  1343 solver.cpp:228] Iteration 114000, loss = 3.44583
I0826 12:23:43.834857  1343 solver.cpp:244]     Train net output #0: loss = 3.44583 (* 1 = 3.44583 loss)
I0826 12:23:43.834869  1343 sgd_solver.cpp:106] Iteration 114000, lr = 2.40129e-07
I0826 12:23:52.240037  1343 solver.cpp:228] Iteration 114100, loss = 3.48149
I0826 12:23:52.240106  1343 solver.cpp:244]     Train net output #0: loss = 3.48149 (* 1 = 3.48149 loss)
I0826 12:23:52.240114  1343 sgd_solver.cpp:106] Iteration 114100, lr = 2.39994e-07
I0826 12:24:00.648229  1343 solver.cpp:228] Iteration 114200, loss = 3.36871
I0826 12:24:00.648296  1343 solver.cpp:244]     Train net output #0: loss = 3.36871 (* 1 = 3.36871 loss)
I0826 12:24:00.648305  1343 sgd_solver.cpp:106] Iteration 114200, lr = 2.3986e-07
I0826 12:24:09.047240  1343 solver.cpp:228] Iteration 114300, loss = 3.61508
I0826 12:24:09.047297  1343 solver.cpp:244]     Train net output #0: loss = 3.61508 (* 1 = 3.61508 loss)
I0826 12:24:09.047302  1343 sgd_solver.cpp:106] Iteration 114300, lr = 2.39726e-07
I0826 12:24:17.455749  1343 solver.cpp:228] Iteration 114400, loss = 3.63545
I0826 12:24:17.455801  1343 solver.cpp:244]     Train net output #0: loss = 3.63545 (* 1 = 3.63545 loss)
I0826 12:24:17.455808  1343 sgd_solver.cpp:106] Iteration 114400, lr = 2.39592e-07
I0826 12:24:25.858095  1343 solver.cpp:228] Iteration 114500, loss = 3.5046
I0826 12:24:25.858145  1343 solver.cpp:244]     Train net output #0: loss = 3.5046 (* 1 = 3.5046 loss)
I0826 12:24:25.858153  1343 sgd_solver.cpp:106] Iteration 114500, lr = 2.39459e-07
I0826 12:24:34.271837  1343 solver.cpp:228] Iteration 114600, loss = 3.46162
I0826 12:24:34.271881  1343 solver.cpp:244]     Train net output #0: loss = 3.46162 (* 1 = 3.46162 loss)
I0826 12:24:34.271888  1343 sgd_solver.cpp:106] Iteration 114600, lr = 2.39325e-07
I0826 12:24:42.685391  1343 solver.cpp:228] Iteration 114700, loss = 3.46615
I0826 12:24:42.685434  1343 solver.cpp:244]     Train net output #0: loss = 3.46615 (* 1 = 3.46615 loss)
I0826 12:24:42.685441  1343 sgd_solver.cpp:106] Iteration 114700, lr = 2.39192e-07
I0826 12:24:51.096014  1343 solver.cpp:228] Iteration 114800, loss = 3.42081
I0826 12:24:51.096089  1343 solver.cpp:244]     Train net output #0: loss = 3.42081 (* 1 = 3.42081 loss)
I0826 12:24:51.096102  1343 sgd_solver.cpp:106] Iteration 114800, lr = 2.39059e-07
I0826 12:24:59.517104  1343 solver.cpp:228] Iteration 114900, loss = 3.45981
I0826 12:24:59.517160  1343 solver.cpp:244]     Train net output #0: loss = 3.45981 (* 1 = 3.45981 loss)
I0826 12:24:59.517168  1343 sgd_solver.cpp:106] Iteration 114900, lr = 2.38926e-07
I0826 12:25:07.833216  1343 solver.cpp:337] Iteration 115000, Testing net (#0)
I0826 12:25:15.825682  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:25:46.014397  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302082
I0826 12:25:46.014472  1343 solver.cpp:404]     Test net output #1: loss = 3.43508 (* 1 = 3.43508 loss)
I0826 12:25:46.044761  1343 solver.cpp:228] Iteration 115000, loss = 3.28801
I0826 12:25:46.044817  1343 solver.cpp:244]     Train net output #0: loss = 3.28801 (* 1 = 3.28801 loss)
I0826 12:25:46.044832  1343 sgd_solver.cpp:106] Iteration 115000, lr = 2.38793e-07
I0826 12:25:54.450798  1343 solver.cpp:228] Iteration 115100, loss = 3.33237
I0826 12:25:54.450875  1343 solver.cpp:244]     Train net output #0: loss = 3.33237 (* 1 = 3.33237 loss)
I0826 12:25:54.450882  1343 sgd_solver.cpp:106] Iteration 115100, lr = 2.38661e-07
I0826 12:26:02.875767  1343 solver.cpp:228] Iteration 115200, loss = 3.44874
I0826 12:26:02.875829  1343 solver.cpp:244]     Train net output #0: loss = 3.44874 (* 1 = 3.44874 loss)
I0826 12:26:02.875841  1343 sgd_solver.cpp:106] Iteration 115200, lr = 2.38528e-07
I0826 12:26:11.313129  1343 solver.cpp:228] Iteration 115300, loss = 3.4477
I0826 12:26:11.313186  1343 solver.cpp:244]     Train net output #0: loss = 3.4477 (* 1 = 3.4477 loss)
I0826 12:26:11.313195  1343 sgd_solver.cpp:106] Iteration 115300, lr = 2.38396e-07
I0826 12:26:19.721235  1343 solver.cpp:228] Iteration 115400, loss = 3.46378
I0826 12:26:19.721276  1343 solver.cpp:244]     Train net output #0: loss = 3.46378 (* 1 = 3.46378 loss)
I0826 12:26:19.721282  1343 sgd_solver.cpp:106] Iteration 115400, lr = 2.38264e-07
I0826 12:26:28.127553  1343 solver.cpp:228] Iteration 115500, loss = 3.61445
I0826 12:26:28.127614  1343 solver.cpp:244]     Train net output #0: loss = 3.61445 (* 1 = 3.61445 loss)
I0826 12:26:28.127622  1343 sgd_solver.cpp:106] Iteration 115500, lr = 2.38132e-07
I0826 12:26:36.538331  1343 solver.cpp:228] Iteration 115600, loss = 3.42631
I0826 12:26:36.538393  1343 solver.cpp:244]     Train net output #0: loss = 3.42631 (* 1 = 3.42631 loss)
I0826 12:26:36.538401  1343 sgd_solver.cpp:106] Iteration 115600, lr = 2.38e-07
I0826 12:26:44.939512  1343 solver.cpp:228] Iteration 115700, loss = 3.30447
I0826 12:26:44.939611  1343 solver.cpp:244]     Train net output #0: loss = 3.30447 (* 1 = 3.30447 loss)
I0826 12:26:44.939630  1343 sgd_solver.cpp:106] Iteration 115700, lr = 2.37869e-07
I0826 12:26:53.361198  1343 solver.cpp:228] Iteration 115800, loss = 3.30358
I0826 12:26:53.361275  1343 solver.cpp:244]     Train net output #0: loss = 3.30358 (* 1 = 3.30358 loss)
I0826 12:26:53.361289  1343 sgd_solver.cpp:106] Iteration 115800, lr = 2.37737e-07
I0826 12:27:01.777712  1343 solver.cpp:228] Iteration 115900, loss = 3.24851
I0826 12:27:01.777776  1343 solver.cpp:244]     Train net output #0: loss = 3.24851 (* 1 = 3.24851 loss)
I0826 12:27:01.777783  1343 sgd_solver.cpp:106] Iteration 115900, lr = 2.37606e-07
I0826 12:27:10.205090  1343 solver.cpp:228] Iteration 116000, loss = 3.2951
I0826 12:27:10.205160  1343 solver.cpp:244]     Train net output #0: loss = 3.2951 (* 1 = 3.2951 loss)
I0826 12:27:10.205173  1343 sgd_solver.cpp:106] Iteration 116000, lr = 2.37475e-07
I0826 12:27:18.631422  1343 solver.cpp:228] Iteration 116100, loss = 3.31933
I0826 12:27:18.631485  1343 solver.cpp:244]     Train net output #0: loss = 3.31933 (* 1 = 3.31933 loss)
I0826 12:27:18.631496  1343 sgd_solver.cpp:106] Iteration 116100, lr = 2.37344e-07
I0826 12:27:18.631923  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:27:27.058478  1343 solver.cpp:228] Iteration 116200, loss = 3.52217
I0826 12:27:27.058521  1343 solver.cpp:244]     Train net output #0: loss = 3.52217 (* 1 = 3.52217 loss)
I0826 12:27:27.058526  1343 sgd_solver.cpp:106] Iteration 116200, lr = 2.37214e-07
I0826 12:27:35.476384  1343 solver.cpp:228] Iteration 116300, loss = 3.21105
I0826 12:27:35.476423  1343 solver.cpp:244]     Train net output #0: loss = 3.21105 (* 1 = 3.21105 loss)
I0826 12:27:35.476430  1343 sgd_solver.cpp:106] Iteration 116300, lr = 2.37083e-07
I0826 12:27:43.862017  1343 solver.cpp:228] Iteration 116400, loss = 3.28369
I0826 12:27:43.862061  1343 solver.cpp:244]     Train net output #0: loss = 3.28369 (* 1 = 3.28369 loss)
I0826 12:27:43.862066  1343 sgd_solver.cpp:106] Iteration 116400, lr = 2.36953e-07
I0826 12:27:52.276828  1343 solver.cpp:228] Iteration 116500, loss = 3.40549
I0826 12:27:52.276870  1343 solver.cpp:244]     Train net output #0: loss = 3.40549 (* 1 = 3.40549 loss)
I0826 12:27:52.276875  1343 sgd_solver.cpp:106] Iteration 116500, lr = 2.36823e-07
I0826 12:28:00.676111  1343 solver.cpp:228] Iteration 116600, loss = 3.24506
I0826 12:28:00.676154  1343 solver.cpp:244]     Train net output #0: loss = 3.24506 (* 1 = 3.24506 loss)
I0826 12:28:00.676161  1343 sgd_solver.cpp:106] Iteration 116600, lr = 2.36692e-07
I0826 12:28:09.093111  1343 solver.cpp:228] Iteration 116700, loss = 3.35389
I0826 12:28:09.093168  1343 solver.cpp:244]     Train net output #0: loss = 3.35389 (* 1 = 3.35389 loss)
I0826 12:28:09.093175  1343 sgd_solver.cpp:106] Iteration 116700, lr = 2.36563e-07
I0826 12:28:17.481870  1343 solver.cpp:228] Iteration 116800, loss = 3.42845
I0826 12:28:17.481932  1343 solver.cpp:244]     Train net output #0: loss = 3.42845 (* 1 = 3.42845 loss)
I0826 12:28:17.481941  1343 sgd_solver.cpp:106] Iteration 116800, lr = 2.36433e-07
I0826 12:28:25.900499  1343 solver.cpp:228] Iteration 116900, loss = 3.44633
I0826 12:28:25.900543  1343 solver.cpp:244]     Train net output #0: loss = 3.44633 (* 1 = 3.44633 loss)
I0826 12:28:25.900548  1343 sgd_solver.cpp:106] Iteration 116900, lr = 2.36303e-07
I0826 12:28:34.317637  1343 solver.cpp:228] Iteration 117000, loss = 3.5408
I0826 12:28:34.317693  1343 solver.cpp:244]     Train net output #0: loss = 3.5408 (* 1 = 3.5408 loss)
I0826 12:28:34.317701  1343 sgd_solver.cpp:106] Iteration 117000, lr = 2.36174e-07
I0826 12:28:42.720371  1343 solver.cpp:228] Iteration 117100, loss = 3.52086
I0826 12:28:42.720422  1343 solver.cpp:244]     Train net output #0: loss = 3.52086 (* 1 = 3.52086 loss)
I0826 12:28:42.720430  1343 sgd_solver.cpp:106] Iteration 117100, lr = 2.36045e-07
I0826 12:28:51.141677  1343 solver.cpp:228] Iteration 117200, loss = 3.28837
I0826 12:28:51.141727  1343 solver.cpp:244]     Train net output #0: loss = 3.28837 (* 1 = 3.28837 loss)
I0826 12:28:51.141736  1343 sgd_solver.cpp:106] Iteration 117200, lr = 2.35916e-07
I0826 12:28:59.574306  1343 solver.cpp:228] Iteration 117300, loss = 3.44823
I0826 12:28:59.574371  1343 solver.cpp:244]     Train net output #0: loss = 3.44823 (* 1 = 3.44823 loss)
I0826 12:28:59.574378  1343 sgd_solver.cpp:106] Iteration 117300, lr = 2.35787e-07
I0826 12:29:07.994448  1343 solver.cpp:228] Iteration 117400, loss = 3.34257
I0826 12:29:07.994488  1343 solver.cpp:244]     Train net output #0: loss = 3.34257 (* 1 = 3.34257 loss)
I0826 12:29:07.994494  1343 sgd_solver.cpp:106] Iteration 117400, lr = 2.35658e-07
I0826 12:29:16.384951  1343 solver.cpp:228] Iteration 117500, loss = 3.28308
I0826 12:29:16.384989  1343 solver.cpp:244]     Train net output #0: loss = 3.28308 (* 1 = 3.28308 loss)
I0826 12:29:16.384994  1343 sgd_solver.cpp:106] Iteration 117500, lr = 2.3553e-07
I0826 12:29:24.810789  1343 solver.cpp:228] Iteration 117600, loss = 3.52779
I0826 12:29:24.810832  1343 solver.cpp:244]     Train net output #0: loss = 3.52779 (* 1 = 3.52779 loss)
I0826 12:29:24.810837  1343 sgd_solver.cpp:106] Iteration 117600, lr = 2.35401e-07
I0826 12:29:33.247109  1343 solver.cpp:228] Iteration 117700, loss = 3.41877
I0826 12:29:33.247179  1343 solver.cpp:244]     Train net output #0: loss = 3.41877 (* 1 = 3.41877 loss)
I0826 12:29:33.247189  1343 sgd_solver.cpp:106] Iteration 117700, lr = 2.35273e-07
I0826 12:29:41.681159  1343 solver.cpp:228] Iteration 117800, loss = 3.60284
I0826 12:29:41.681201  1343 solver.cpp:244]     Train net output #0: loss = 3.60284 (* 1 = 3.60284 loss)
I0826 12:29:41.681208  1343 sgd_solver.cpp:106] Iteration 117800, lr = 2.35145e-07
I0826 12:29:50.115141  1343 solver.cpp:228] Iteration 117900, loss = 3.45876
I0826 12:29:50.115195  1343 solver.cpp:244]     Train net output #0: loss = 3.45876 (* 1 = 3.45876 loss)
I0826 12:29:50.115201  1343 sgd_solver.cpp:106] Iteration 117900, lr = 2.35017e-07
I0826 12:29:58.524129  1343 solver.cpp:228] Iteration 118000, loss = 3.51377
I0826 12:29:58.524183  1343 solver.cpp:244]     Train net output #0: loss = 3.51377 (* 1 = 3.51377 loss)
I0826 12:29:58.524189  1343 sgd_solver.cpp:106] Iteration 118000, lr = 2.34889e-07
I0826 12:30:06.939019  1343 solver.cpp:228] Iteration 118100, loss = 3.43359
I0826 12:30:06.939075  1343 solver.cpp:244]     Train net output #0: loss = 3.43359 (* 1 = 3.43359 loss)
I0826 12:30:06.939083  1343 sgd_solver.cpp:106] Iteration 118100, lr = 2.34762e-07
I0826 12:30:15.325079  1343 solver.cpp:228] Iteration 118200, loss = 3.42539
I0826 12:30:15.325134  1343 solver.cpp:244]     Train net output #0: loss = 3.42539 (* 1 = 3.42539 loss)
I0826 12:30:15.325141  1343 sgd_solver.cpp:106] Iteration 118200, lr = 2.34634e-07
I0826 12:30:23.739948  1343 solver.cpp:228] Iteration 118300, loss = 3.61086
I0826 12:30:23.740003  1343 solver.cpp:244]     Train net output #0: loss = 3.61086 (* 1 = 3.61086 loss)
I0826 12:30:23.740010  1343 sgd_solver.cpp:106] Iteration 118300, lr = 2.34507e-07
I0826 12:30:32.136502  1343 solver.cpp:228] Iteration 118400, loss = 3.40005
I0826 12:30:32.136544  1343 solver.cpp:244]     Train net output #0: loss = 3.40005 (* 1 = 3.40005 loss)
I0826 12:30:32.136550  1343 sgd_solver.cpp:106] Iteration 118400, lr = 2.3438e-07
I0826 12:30:40.557664  1343 solver.cpp:228] Iteration 118500, loss = 3.42132
I0826 12:30:40.557709  1343 solver.cpp:244]     Train net output #0: loss = 3.42132 (* 1 = 3.42132 loss)
I0826 12:30:40.557715  1343 sgd_solver.cpp:106] Iteration 118500, lr = 2.34253e-07
I0826 12:30:48.980080  1343 solver.cpp:228] Iteration 118600, loss = 3.35786
I0826 12:30:48.980145  1343 solver.cpp:244]     Train net output #0: loss = 3.35786 (* 1 = 3.35786 loss)
I0826 12:30:48.980156  1343 sgd_solver.cpp:106] Iteration 118600, lr = 2.34126e-07
I0826 12:30:57.399360  1343 solver.cpp:228] Iteration 118700, loss = 3.53006
I0826 12:30:57.399412  1343 solver.cpp:244]     Train net output #0: loss = 3.53006 (* 1 = 3.53006 loss)
I0826 12:30:57.399423  1343 sgd_solver.cpp:106] Iteration 118700, lr = 2.34e-07
I0826 12:31:05.792127  1343 solver.cpp:228] Iteration 118800, loss = 3.50204
I0826 12:31:05.792187  1343 solver.cpp:244]     Train net output #0: loss = 3.50204 (* 1 = 3.50204 loss)
I0826 12:31:05.792197  1343 sgd_solver.cpp:106] Iteration 118800, lr = 2.33873e-07
I0826 12:31:14.213600  1343 solver.cpp:228] Iteration 118900, loss = 3.45977
I0826 12:31:14.213663  1343 solver.cpp:244]     Train net output #0: loss = 3.45977 (* 1 = 3.45977 loss)
I0826 12:31:14.213671  1343 sgd_solver.cpp:106] Iteration 118900, lr = 2.33747e-07
I0826 12:31:22.621078  1343 solver.cpp:228] Iteration 119000, loss = 3.53058
I0826 12:31:22.621166  1343 solver.cpp:244]     Train net output #0: loss = 3.53058 (* 1 = 3.53058 loss)
I0826 12:31:22.621192  1343 sgd_solver.cpp:106] Iteration 119000, lr = 2.33621e-07
I0826 12:31:31.057708  1343 solver.cpp:228] Iteration 119100, loss = 3.42516
I0826 12:31:31.057755  1343 solver.cpp:244]     Train net output #0: loss = 3.42516 (* 1 = 3.42516 loss)
I0826 12:31:31.057763  1343 sgd_solver.cpp:106] Iteration 119100, lr = 2.33495e-07
I0826 12:31:39.474566  1343 solver.cpp:228] Iteration 119200, loss = 3.5878
I0826 12:31:39.474611  1343 solver.cpp:244]     Train net output #0: loss = 3.5878 (* 1 = 3.5878 loss)
I0826 12:31:39.474616  1343 sgd_solver.cpp:106] Iteration 119200, lr = 2.33369e-07
I0826 12:31:47.857199  1343 solver.cpp:228] Iteration 119300, loss = 3.44378
I0826 12:31:47.857242  1343 solver.cpp:244]     Train net output #0: loss = 3.44378 (* 1 = 3.44378 loss)
I0826 12:31:47.857247  1343 sgd_solver.cpp:106] Iteration 119300, lr = 2.33243e-07
I0826 12:31:56.278138  1343 solver.cpp:228] Iteration 119400, loss = 3.48352
I0826 12:31:56.278180  1343 solver.cpp:244]     Train net output #0: loss = 3.48352 (* 1 = 3.48352 loss)
I0826 12:31:56.278185  1343 sgd_solver.cpp:106] Iteration 119400, lr = 2.33118e-07
I0826 12:32:03.934101  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:32:04.693794  1343 solver.cpp:228] Iteration 119500, loss = 3.26341
I0826 12:32:04.693866  1343 solver.cpp:244]     Train net output #0: loss = 3.26341 (* 1 = 3.26341 loss)
I0826 12:32:04.693879  1343 sgd_solver.cpp:106] Iteration 119500, lr = 2.32992e-07
I0826 12:32:13.101518  1343 solver.cpp:228] Iteration 119600, loss = 3.56102
I0826 12:32:13.101583  1343 solver.cpp:244]     Train net output #0: loss = 3.56102 (* 1 = 3.56102 loss)
I0826 12:32:13.101593  1343 sgd_solver.cpp:106] Iteration 119600, lr = 2.32867e-07
I0826 12:32:21.518085  1343 solver.cpp:228] Iteration 119700, loss = 3.40417
I0826 12:32:21.518146  1343 solver.cpp:244]     Train net output #0: loss = 3.40417 (* 1 = 3.40417 loss)
I0826 12:32:21.518157  1343 sgd_solver.cpp:106] Iteration 119700, lr = 2.32742e-07
I0826 12:32:29.950136  1343 solver.cpp:228] Iteration 119800, loss = 3.36021
I0826 12:32:29.950191  1343 solver.cpp:244]     Train net output #0: loss = 3.36021 (* 1 = 3.36021 loss)
I0826 12:32:29.950199  1343 sgd_solver.cpp:106] Iteration 119800, lr = 2.32617e-07
I0826 12:32:38.369446  1343 solver.cpp:228] Iteration 119900, loss = 3.3905
I0826 12:32:38.369506  1343 solver.cpp:244]     Train net output #0: loss = 3.3905 (* 1 = 3.3905 loss)
I0826 12:32:38.369515  1343 sgd_solver.cpp:106] Iteration 119900, lr = 2.32493e-07
I0826 12:32:46.694206  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_120000.caffemodel
I0826 12:32:47.209484  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_120000.solverstate
I0826 12:32:47.370543  1343 solver.cpp:337] Iteration 120000, Testing net (#0)
I0826 12:33:23.437866  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:33:25.913173  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302055
I0826 12:33:25.913226  1343 solver.cpp:404]     Test net output #1: loss = 3.43313 (* 1 = 3.43313 loss)
I0826 12:33:25.942845  1343 solver.cpp:228] Iteration 120000, loss = 3.49212
I0826 12:33:25.942906  1343 solver.cpp:244]     Train net output #0: loss = 3.49212 (* 1 = 3.49212 loss)
I0826 12:33:25.942927  1343 sgd_solver.cpp:106] Iteration 120000, lr = 2.32368e-07
I0826 12:33:34.340312  1343 solver.cpp:228] Iteration 120100, loss = 3.39496
I0826 12:33:34.340399  1343 solver.cpp:244]     Train net output #0: loss = 3.39496 (* 1 = 3.39496 loss)
I0826 12:33:34.340425  1343 sgd_solver.cpp:106] Iteration 120100, lr = 2.32244e-07
I0826 12:33:42.760049  1343 solver.cpp:228] Iteration 120200, loss = 3.50942
I0826 12:33:42.760093  1343 solver.cpp:244]     Train net output #0: loss = 3.50942 (* 1 = 3.50942 loss)
I0826 12:33:42.760098  1343 sgd_solver.cpp:106] Iteration 120200, lr = 2.32119e-07
I0826 12:33:51.180393  1343 solver.cpp:228] Iteration 120300, loss = 3.39301
I0826 12:33:51.180436  1343 solver.cpp:244]     Train net output #0: loss = 3.39301 (* 1 = 3.39301 loss)
I0826 12:33:51.180441  1343 sgd_solver.cpp:106] Iteration 120300, lr = 2.31995e-07
I0826 12:33:59.599875  1343 solver.cpp:228] Iteration 120400, loss = 3.41924
I0826 12:33:59.599937  1343 solver.cpp:244]     Train net output #0: loss = 3.41924 (* 1 = 3.41924 loss)
I0826 12:33:59.599946  1343 sgd_solver.cpp:106] Iteration 120400, lr = 2.31871e-07
I0826 12:34:08.005228  1343 solver.cpp:228] Iteration 120500, loss = 3.24688
I0826 12:34:08.005272  1343 solver.cpp:244]     Train net output #0: loss = 3.24688 (* 1 = 3.24688 loss)
I0826 12:34:08.005277  1343 sgd_solver.cpp:106] Iteration 120500, lr = 2.31748e-07
I0826 12:34:16.423262  1343 solver.cpp:228] Iteration 120600, loss = 3.27987
I0826 12:34:16.423302  1343 solver.cpp:244]     Train net output #0: loss = 3.27987 (* 1 = 3.27987 loss)
I0826 12:34:16.423307  1343 sgd_solver.cpp:106] Iteration 120600, lr = 2.31624e-07
I0826 12:34:24.815423  1343 solver.cpp:228] Iteration 120700, loss = 3.53032
I0826 12:34:24.815485  1343 solver.cpp:244]     Train net output #0: loss = 3.53032 (* 1 = 3.53032 loss)
I0826 12:34:24.815491  1343 sgd_solver.cpp:106] Iteration 120700, lr = 2.315e-07
I0826 12:34:33.235369  1343 solver.cpp:228] Iteration 120800, loss = 3.46579
I0826 12:34:33.235414  1343 solver.cpp:244]     Train net output #0: loss = 3.46579 (* 1 = 3.46579 loss)
I0826 12:34:33.235420  1343 sgd_solver.cpp:106] Iteration 120800, lr = 2.31377e-07
I0826 12:34:41.659184  1343 solver.cpp:228] Iteration 120900, loss = 3.32317
I0826 12:34:41.659225  1343 solver.cpp:244]     Train net output #0: loss = 3.32317 (* 1 = 3.32317 loss)
I0826 12:34:41.659230  1343 sgd_solver.cpp:106] Iteration 120900, lr = 2.31254e-07
I0826 12:34:50.071002  1343 solver.cpp:228] Iteration 121000, loss = 3.53594
I0826 12:34:50.071068  1343 solver.cpp:244]     Train net output #0: loss = 3.53594 (* 1 = 3.53594 loss)
I0826 12:34:50.071077  1343 sgd_solver.cpp:106] Iteration 121000, lr = 2.31131e-07
I0826 12:34:58.492622  1343 solver.cpp:228] Iteration 121100, loss = 3.39793
I0826 12:34:58.492682  1343 solver.cpp:244]     Train net output #0: loss = 3.39793 (* 1 = 3.39793 loss)
I0826 12:34:58.492689  1343 sgd_solver.cpp:106] Iteration 121100, lr = 2.31008e-07
I0826 12:35:06.905941  1343 solver.cpp:228] Iteration 121200, loss = 3.34387
I0826 12:35:06.905989  1343 solver.cpp:244]     Train net output #0: loss = 3.34387 (* 1 = 3.34387 loss)
I0826 12:35:06.905998  1343 sgd_solver.cpp:106] Iteration 121200, lr = 2.30885e-07
I0826 12:35:15.306421  1343 solver.cpp:228] Iteration 121300, loss = 3.53701
I0826 12:35:15.306469  1343 solver.cpp:244]     Train net output #0: loss = 3.53701 (* 1 = 3.53701 loss)
I0826 12:35:15.306478  1343 sgd_solver.cpp:106] Iteration 121300, lr = 2.30763e-07
I0826 12:35:23.730970  1343 solver.cpp:228] Iteration 121400, loss = 3.29123
I0826 12:35:23.731029  1343 solver.cpp:244]     Train net output #0: loss = 3.29123 (* 1 = 3.29123 loss)
I0826 12:35:23.731039  1343 sgd_solver.cpp:106] Iteration 121400, lr = 2.3064e-07
I0826 12:35:32.160377  1343 solver.cpp:228] Iteration 121500, loss = 3.46054
I0826 12:35:32.160435  1343 solver.cpp:244]     Train net output #0: loss = 3.46054 (* 1 = 3.46054 loss)
I0826 12:35:32.160444  1343 sgd_solver.cpp:106] Iteration 121500, lr = 2.30518e-07
I0826 12:35:40.578194  1343 solver.cpp:228] Iteration 121600, loss = 3.44763
I0826 12:35:40.578258  1343 solver.cpp:244]     Train net output #0: loss = 3.44763 (* 1 = 3.44763 loss)
I0826 12:35:40.578268  1343 sgd_solver.cpp:106] Iteration 121600, lr = 2.30396e-07
I0826 12:35:49.022434  1343 solver.cpp:228] Iteration 121700, loss = 3.3811
I0826 12:35:49.022502  1343 solver.cpp:244]     Train net output #0: loss = 3.3811 (* 1 = 3.3811 loss)
I0826 12:35:49.022513  1343 sgd_solver.cpp:106] Iteration 121700, lr = 2.30274e-07
I0826 12:35:57.447173  1343 solver.cpp:228] Iteration 121800, loss = 3.22661
I0826 12:35:57.447216  1343 solver.cpp:244]     Train net output #0: loss = 3.22661 (* 1 = 3.22661 loss)
I0826 12:35:57.447221  1343 sgd_solver.cpp:106] Iteration 121800, lr = 2.30152e-07
I0826 12:36:05.855124  1343 solver.cpp:228] Iteration 121900, loss = 3.45014
I0826 12:36:05.855190  1343 solver.cpp:244]     Train net output #0: loss = 3.45014 (* 1 = 3.45014 loss)
I0826 12:36:05.855198  1343 sgd_solver.cpp:106] Iteration 121900, lr = 2.30031e-07
I0826 12:36:14.288645  1343 solver.cpp:228] Iteration 122000, loss = 3.61837
I0826 12:36:14.288707  1343 solver.cpp:244]     Train net output #0: loss = 3.61837 (* 1 = 3.61837 loss)
I0826 12:36:14.288715  1343 sgd_solver.cpp:106] Iteration 122000, lr = 2.29909e-07
I0826 12:36:22.699203  1343 solver.cpp:228] Iteration 122100, loss = 3.58058
I0826 12:36:22.699283  1343 solver.cpp:244]     Train net output #0: loss = 3.58058 (* 1 = 3.58058 loss)
I0826 12:36:22.699295  1343 sgd_solver.cpp:106] Iteration 122100, lr = 2.29788e-07
I0826 12:36:31.113214  1343 solver.cpp:228] Iteration 122200, loss = 3.60183
I0826 12:36:31.113275  1343 solver.cpp:244]     Train net output #0: loss = 3.60183 (* 1 = 3.60183 loss)
I0826 12:36:31.113282  1343 sgd_solver.cpp:106] Iteration 122200, lr = 2.29667e-07
I0826 12:36:39.537212  1343 solver.cpp:228] Iteration 122300, loss = 3.46227
I0826 12:36:39.537273  1343 solver.cpp:244]     Train net output #0: loss = 3.46227 (* 1 = 3.46227 loss)
I0826 12:36:39.537282  1343 sgd_solver.cpp:106] Iteration 122300, lr = 2.29546e-07
I0826 12:36:47.955581  1343 solver.cpp:228] Iteration 122400, loss = 3.25377
I0826 12:36:47.955642  1343 solver.cpp:244]     Train net output #0: loss = 3.25377 (* 1 = 3.25377 loss)
I0826 12:36:47.955651  1343 sgd_solver.cpp:106] Iteration 122400, lr = 2.29425e-07
I0826 12:36:56.362825  1343 solver.cpp:228] Iteration 122500, loss = 3.52924
I0826 12:36:56.362879  1343 solver.cpp:244]     Train net output #0: loss = 3.52924 (* 1 = 3.52924 loss)
I0826 12:36:56.362885  1343 sgd_solver.cpp:106] Iteration 122500, lr = 2.29304e-07
I0826 12:37:04.788728  1343 solver.cpp:228] Iteration 122600, loss = 3.5988
I0826 12:37:04.788789  1343 solver.cpp:244]     Train net output #0: loss = 3.5988 (* 1 = 3.5988 loss)
I0826 12:37:04.788800  1343 sgd_solver.cpp:106] Iteration 122600, lr = 2.29183e-07
I0826 12:37:13.222167  1343 solver.cpp:228] Iteration 122700, loss = 3.47089
I0826 12:37:13.222210  1343 solver.cpp:244]     Train net output #0: loss = 3.47089 (* 1 = 3.47089 loss)
I0826 12:37:13.222216  1343 sgd_solver.cpp:106] Iteration 122700, lr = 2.29063e-07
I0826 12:37:21.649618  1343 solver.cpp:228] Iteration 122800, loss = 3.40078
I0826 12:37:21.649673  1343 solver.cpp:244]     Train net output #0: loss = 3.40078 (* 1 = 3.40078 loss)
I0826 12:37:21.649679  1343 sgd_solver.cpp:106] Iteration 122800, lr = 2.28942e-07
I0826 12:37:30.054741  1343 solver.cpp:228] Iteration 122900, loss = 3.50025
I0826 12:37:30.054785  1343 solver.cpp:244]     Train net output #0: loss = 3.50025 (* 1 = 3.50025 loss)
I0826 12:37:30.054790  1343 sgd_solver.cpp:106] Iteration 122900, lr = 2.28822e-07
I0826 12:37:38.466943  1343 solver.cpp:228] Iteration 123000, loss = 3.44657
I0826 12:37:38.466990  1343 solver.cpp:244]     Train net output #0: loss = 3.44657 (* 1 = 3.44657 loss)
I0826 12:37:38.467000  1343 sgd_solver.cpp:106] Iteration 123000, lr = 2.28702e-07
I0826 12:37:46.884521  1343 solver.cpp:228] Iteration 123100, loss = 3.46496
I0826 12:37:46.884559  1343 solver.cpp:244]     Train net output #0: loss = 3.46496 (* 1 = 3.46496 loss)
I0826 12:37:46.884565  1343 sgd_solver.cpp:106] Iteration 123100, lr = 2.28582e-07
I0826 12:37:55.278213  1343 solver.cpp:228] Iteration 123200, loss = 3.34134
I0826 12:37:55.278252  1343 solver.cpp:244]     Train net output #0: loss = 3.34134 (* 1 = 3.34134 loss)
I0826 12:37:55.278259  1343 sgd_solver.cpp:106] Iteration 123200, lr = 2.28463e-07
I0826 12:37:56.705287  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:38:03.695900  1343 solver.cpp:228] Iteration 123300, loss = 3.27828
I0826 12:38:03.695945  1343 solver.cpp:244]     Train net output #0: loss = 3.27828 (* 1 = 3.27828 loss)
I0826 12:38:03.695951  1343 sgd_solver.cpp:106] Iteration 123300, lr = 2.28343e-07
I0826 12:38:12.086346  1343 solver.cpp:228] Iteration 123400, loss = 3.51379
I0826 12:38:12.086390  1343 solver.cpp:244]     Train net output #0: loss = 3.51379 (* 1 = 3.51379 loss)
I0826 12:38:12.086396  1343 sgd_solver.cpp:106] Iteration 123400, lr = 2.28224e-07
I0826 12:38:20.506958  1343 solver.cpp:228] Iteration 123500, loss = 3.39749
I0826 12:38:20.506999  1343 solver.cpp:244]     Train net output #0: loss = 3.39749 (* 1 = 3.39749 loss)
I0826 12:38:20.507004  1343 sgd_solver.cpp:106] Iteration 123500, lr = 2.28104e-07
I0826 12:38:28.934156  1343 solver.cpp:228] Iteration 123600, loss = 3.19653
I0826 12:38:28.934228  1343 solver.cpp:244]     Train net output #0: loss = 3.19653 (* 1 = 3.19653 loss)
I0826 12:38:28.934248  1343 sgd_solver.cpp:106] Iteration 123600, lr = 2.27985e-07
I0826 12:38:37.355656  1343 solver.cpp:228] Iteration 123700, loss = 3.38851
I0826 12:38:37.355705  1343 solver.cpp:244]     Train net output #0: loss = 3.38851 (* 1 = 3.38851 loss)
I0826 12:38:37.355710  1343 sgd_solver.cpp:106] Iteration 123700, lr = 2.27866e-07
I0826 12:38:45.764263  1343 solver.cpp:228] Iteration 123800, loss = 3.46582
I0826 12:38:45.764320  1343 solver.cpp:244]     Train net output #0: loss = 3.46582 (* 1 = 3.46582 loss)
I0826 12:38:45.764329  1343 sgd_solver.cpp:106] Iteration 123800, lr = 2.27747e-07
I0826 12:38:54.189780  1343 solver.cpp:228] Iteration 123900, loss = 3.5271
I0826 12:38:54.189848  1343 solver.cpp:244]     Train net output #0: loss = 3.5271 (* 1 = 3.5271 loss)
I0826 12:38:54.189862  1343 sgd_solver.cpp:106] Iteration 123900, lr = 2.27629e-07
I0826 12:39:02.615042  1343 solver.cpp:228] Iteration 124000, loss = 3.34794
I0826 12:39:02.615088  1343 solver.cpp:244]     Train net output #0: loss = 3.34794 (* 1 = 3.34794 loss)
I0826 12:39:02.615093  1343 sgd_solver.cpp:106] Iteration 124000, lr = 2.2751e-07
I0826 12:39:11.012275  1343 solver.cpp:228] Iteration 124100, loss = 3.308
I0826 12:39:11.012336  1343 solver.cpp:244]     Train net output #0: loss = 3.308 (* 1 = 3.308 loss)
I0826 12:39:11.012352  1343 sgd_solver.cpp:106] Iteration 124100, lr = 2.27392e-07
I0826 12:39:19.429563  1343 solver.cpp:228] Iteration 124200, loss = 3.52214
I0826 12:39:19.429625  1343 solver.cpp:244]     Train net output #0: loss = 3.52214 (* 1 = 3.52214 loss)
I0826 12:39:19.429632  1343 sgd_solver.cpp:106] Iteration 124200, lr = 2.27273e-07
I0826 12:39:27.838059  1343 solver.cpp:228] Iteration 124300, loss = 3.40292
I0826 12:39:27.838136  1343 solver.cpp:244]     Train net output #0: loss = 3.40292 (* 1 = 3.40292 loss)
I0826 12:39:27.838145  1343 sgd_solver.cpp:106] Iteration 124300, lr = 2.27155e-07
I0826 12:39:36.249171  1343 solver.cpp:228] Iteration 124400, loss = 3.6198
I0826 12:39:36.249208  1343 solver.cpp:244]     Train net output #0: loss = 3.6198 (* 1 = 3.6198 loss)
I0826 12:39:36.249214  1343 sgd_solver.cpp:106] Iteration 124400, lr = 2.27037e-07
I0826 12:39:44.686108  1343 solver.cpp:228] Iteration 124500, loss = 3.27189
I0826 12:39:44.686184  1343 solver.cpp:244]     Train net output #0: loss = 3.27189 (* 1 = 3.27189 loss)
I0826 12:39:44.686197  1343 sgd_solver.cpp:106] Iteration 124500, lr = 2.26919e-07
I0826 12:39:53.095949  1343 solver.cpp:228] Iteration 124600, loss = 3.44407
I0826 12:39:53.096011  1343 solver.cpp:244]     Train net output #0: loss = 3.44407 (* 1 = 3.44407 loss)
I0826 12:39:53.096019  1343 sgd_solver.cpp:106] Iteration 124600, lr = 2.26802e-07
I0826 12:40:01.517590  1343 solver.cpp:228] Iteration 124700, loss = 3.37006
I0826 12:40:01.517668  1343 solver.cpp:244]     Train net output #0: loss = 3.37006 (* 1 = 3.37006 loss)
I0826 12:40:01.517678  1343 sgd_solver.cpp:106] Iteration 124700, lr = 2.26684e-07
I0826 12:40:09.939004  1343 solver.cpp:228] Iteration 124800, loss = 3.51689
I0826 12:40:09.939057  1343 solver.cpp:244]     Train net output #0: loss = 3.51689 (* 1 = 3.51689 loss)
I0826 12:40:09.939064  1343 sgd_solver.cpp:106] Iteration 124800, lr = 2.26567e-07
I0826 12:40:18.359483  1343 solver.cpp:228] Iteration 124900, loss = 3.42522
I0826 12:40:18.359549  1343 solver.cpp:244]     Train net output #0: loss = 3.42522 (* 1 = 3.42522 loss)
I0826 12:40:18.359557  1343 sgd_solver.cpp:106] Iteration 124900, lr = 2.26449e-07
I0826 12:40:26.700978  1343 solver.cpp:337] Iteration 125000, Testing net (#0)
I0826 12:40:46.547986  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:41:03.838297  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302041
I0826 12:41:03.838362  1343 solver.cpp:404]     Test net output #1: loss = 3.43118 (* 1 = 3.43118 loss)
I0826 12:41:03.868815  1343 solver.cpp:228] Iteration 125000, loss = 3.38173
I0826 12:41:03.868862  1343 solver.cpp:244]     Train net output #0: loss = 3.38173 (* 1 = 3.38173 loss)
I0826 12:41:03.868876  1343 sgd_solver.cpp:106] Iteration 125000, lr = 2.26332e-07
I0826 12:41:12.283761  1343 solver.cpp:228] Iteration 125100, loss = 3.329
I0826 12:41:12.283849  1343 solver.cpp:244]     Train net output #0: loss = 3.329 (* 1 = 3.329 loss)
I0826 12:41:12.283857  1343 sgd_solver.cpp:106] Iteration 125100, lr = 2.26215e-07
I0826 12:41:20.703074  1343 solver.cpp:228] Iteration 125200, loss = 3.43548
I0826 12:41:20.703141  1343 solver.cpp:244]     Train net output #0: loss = 3.43548 (* 1 = 3.43548 loss)
I0826 12:41:20.703151  1343 sgd_solver.cpp:106] Iteration 125200, lr = 2.26098e-07
I0826 12:41:29.115520  1343 solver.cpp:228] Iteration 125300, loss = 3.35886
I0826 12:41:29.115566  1343 solver.cpp:244]     Train net output #0: loss = 3.35886 (* 1 = 3.35886 loss)
I0826 12:41:29.115571  1343 sgd_solver.cpp:106] Iteration 125300, lr = 2.25982e-07
I0826 12:41:37.518148  1343 solver.cpp:228] Iteration 125400, loss = 3.49438
I0826 12:41:37.518193  1343 solver.cpp:244]     Train net output #0: loss = 3.49438 (* 1 = 3.49438 loss)
I0826 12:41:37.518198  1343 sgd_solver.cpp:106] Iteration 125400, lr = 2.25865e-07
I0826 12:41:45.932952  1343 solver.cpp:228] Iteration 125500, loss = 3.48197
I0826 12:41:45.933012  1343 solver.cpp:244]     Train net output #0: loss = 3.48197 (* 1 = 3.48197 loss)
I0826 12:41:45.933022  1343 sgd_solver.cpp:106] Iteration 125500, lr = 2.25749e-07
I0826 12:41:54.351069  1343 solver.cpp:228] Iteration 125600, loss = 3.35886
I0826 12:41:54.351138  1343 solver.cpp:244]     Train net output #0: loss = 3.35886 (* 1 = 3.35886 loss)
I0826 12:41:54.351148  1343 sgd_solver.cpp:106] Iteration 125600, lr = 2.25632e-07
I0826 12:42:02.760342  1343 solver.cpp:228] Iteration 125700, loss = 3.49626
I0826 12:42:02.760432  1343 solver.cpp:244]     Train net output #0: loss = 3.49626 (* 1 = 3.49626 loss)
I0826 12:42:02.760452  1343 sgd_solver.cpp:106] Iteration 125700, lr = 2.25516e-07
I0826 12:42:11.168000  1343 solver.cpp:228] Iteration 125800, loss = 3.30288
I0826 12:42:11.168043  1343 solver.cpp:244]     Train net output #0: loss = 3.30288 (* 1 = 3.30288 loss)
I0826 12:42:11.168050  1343 sgd_solver.cpp:106] Iteration 125800, lr = 2.254e-07
I0826 12:42:19.587074  1343 solver.cpp:228] Iteration 125900, loss = 3.36054
I0826 12:42:19.587136  1343 solver.cpp:244]     Train net output #0: loss = 3.36054 (* 1 = 3.36054 loss)
I0826 12:42:19.587144  1343 sgd_solver.cpp:106] Iteration 125900, lr = 2.25284e-07
I0826 12:42:28.001456  1343 solver.cpp:228] Iteration 126000, loss = 3.47799
I0826 12:42:28.001528  1343 solver.cpp:244]     Train net output #0: loss = 3.47799 (* 1 = 3.47799 loss)
I0826 12:42:28.001539  1343 sgd_solver.cpp:106] Iteration 126000, lr = 2.25169e-07
I0826 12:42:36.421026  1343 solver.cpp:228] Iteration 126100, loss = 3.55821
I0826 12:42:36.421087  1343 solver.cpp:244]     Train net output #0: loss = 3.55821 (* 1 = 3.55821 loss)
I0826 12:42:36.421108  1343 sgd_solver.cpp:106] Iteration 126100, lr = 2.25053e-07
I0826 12:42:44.831331  1343 solver.cpp:228] Iteration 126200, loss = 3.39564
I0826 12:42:44.831375  1343 solver.cpp:244]     Train net output #0: loss = 3.39564 (* 1 = 3.39564 loss)
I0826 12:42:44.831380  1343 sgd_solver.cpp:106] Iteration 126200, lr = 2.24938e-07
I0826 12:42:53.241439  1343 solver.cpp:228] Iteration 126300, loss = 3.3561
I0826 12:42:53.241502  1343 solver.cpp:244]     Train net output #0: loss = 3.3561 (* 1 = 3.3561 loss)
I0826 12:42:53.241510  1343 sgd_solver.cpp:106] Iteration 126300, lr = 2.24822e-07
I0826 12:43:01.645714  1343 solver.cpp:228] Iteration 126400, loss = 3.35874
I0826 12:43:01.645757  1343 solver.cpp:244]     Train net output #0: loss = 3.35874 (* 1 = 3.35874 loss)
I0826 12:43:01.645763  1343 sgd_solver.cpp:106] Iteration 126400, lr = 2.24707e-07
I0826 12:43:10.040387  1343 solver.cpp:228] Iteration 126500, loss = 3.37964
I0826 12:43:10.040431  1343 solver.cpp:244]     Train net output #0: loss = 3.37964 (* 1 = 3.37964 loss)
I0826 12:43:10.040436  1343 sgd_solver.cpp:106] Iteration 126500, lr = 2.24592e-07
I0826 12:43:18.454550  1343 solver.cpp:228] Iteration 126600, loss = 3.48622
I0826 12:43:18.454602  1343 solver.cpp:244]     Train net output #0: loss = 3.48622 (* 1 = 3.48622 loss)
I0826 12:43:18.454610  1343 sgd_solver.cpp:106] Iteration 126600, lr = 2.24477e-07
I0826 12:43:26.852927  1343 solver.cpp:228] Iteration 126700, loss = 3.41782
I0826 12:43:26.852998  1343 solver.cpp:244]     Train net output #0: loss = 3.41782 (* 1 = 3.41782 loss)
I0826 12:43:26.853008  1343 sgd_solver.cpp:106] Iteration 126700, lr = 2.24362e-07
I0826 12:43:35.273214  1343 solver.cpp:228] Iteration 126800, loss = 3.39935
I0826 12:43:35.273277  1343 solver.cpp:244]     Train net output #0: loss = 3.39935 (* 1 = 3.39935 loss)
I0826 12:43:35.273289  1343 sgd_solver.cpp:106] Iteration 126800, lr = 2.24248e-07
I0826 12:43:43.690202  1343 solver.cpp:228] Iteration 126900, loss = 3.40997
I0826 12:43:43.690256  1343 solver.cpp:244]     Train net output #0: loss = 3.40997 (* 1 = 3.40997 loss)
I0826 12:43:43.690264  1343 sgd_solver.cpp:106] Iteration 126900, lr = 2.24133e-07
I0826 12:43:52.095276  1343 solver.cpp:228] Iteration 127000, loss = 3.43093
I0826 12:43:52.095333  1343 solver.cpp:244]     Train net output #0: loss = 3.43093 (* 1 = 3.43093 loss)
I0826 12:43:52.095340  1343 sgd_solver.cpp:106] Iteration 127000, lr = 2.24019e-07
I0826 12:44:00.522882  1343 solver.cpp:228] Iteration 127100, loss = 3.5773
I0826 12:44:00.522940  1343 solver.cpp:244]     Train net output #0: loss = 3.5773 (* 1 = 3.5773 loss)
I0826 12:44:00.522948  1343 sgd_solver.cpp:106] Iteration 127100, lr = 2.23905e-07
I0826 12:44:08.943143  1343 solver.cpp:228] Iteration 127200, loss = 3.42986
I0826 12:44:08.943217  1343 solver.cpp:244]     Train net output #0: loss = 3.42986 (* 1 = 3.42986 loss)
I0826 12:44:08.943248  1343 sgd_solver.cpp:106] Iteration 127200, lr = 2.23791e-07
I0826 12:44:17.357583  1343 solver.cpp:228] Iteration 127300, loss = 3.48968
I0826 12:44:17.357647  1343 solver.cpp:244]     Train net output #0: loss = 3.48968 (* 1 = 3.48968 loss)
I0826 12:44:17.357658  1343 sgd_solver.cpp:106] Iteration 127300, lr = 2.23677e-07
I0826 12:44:25.778118  1343 solver.cpp:228] Iteration 127400, loss = 3.27818
I0826 12:44:25.778199  1343 solver.cpp:244]     Train net output #0: loss = 3.27818 (* 1 = 3.27818 loss)
I0826 12:44:25.778218  1343 sgd_solver.cpp:106] Iteration 127400, lr = 2.23563e-07
I0826 12:44:34.197486  1343 solver.cpp:228] Iteration 127500, loss = 3.57996
I0826 12:44:34.197536  1343 solver.cpp:244]     Train net output #0: loss = 3.57996 (* 1 = 3.57996 loss)
I0826 12:44:34.197543  1343 sgd_solver.cpp:106] Iteration 127500, lr = 2.23449e-07
I0826 12:44:42.588932  1343 solver.cpp:228] Iteration 127600, loss = 3.39881
I0826 12:44:42.589004  1343 solver.cpp:244]     Train net output #0: loss = 3.39881 (* 1 = 3.39881 loss)
I0826 12:44:42.589011  1343 sgd_solver.cpp:106] Iteration 127600, lr = 2.23335e-07
I0826 12:44:51.001497  1343 solver.cpp:228] Iteration 127700, loss = 3.24843
I0826 12:44:51.001551  1343 solver.cpp:244]     Train net output #0: loss = 3.24843 (* 1 = 3.24843 loss)
I0826 12:44:51.001559  1343 sgd_solver.cpp:106] Iteration 127700, lr = 2.23222e-07
I0826 12:44:59.396059  1343 solver.cpp:228] Iteration 127800, loss = 3.47813
I0826 12:44:59.396116  1343 solver.cpp:244]     Train net output #0: loss = 3.47813 (* 1 = 3.47813 loss)
I0826 12:44:59.396127  1343 sgd_solver.cpp:106] Iteration 127800, lr = 2.23109e-07
I0826 12:45:07.823212  1343 solver.cpp:228] Iteration 127900, loss = 3.51166
I0826 12:45:07.823281  1343 solver.cpp:244]     Train net output #0: loss = 3.51166 (* 1 = 3.51166 loss)
I0826 12:45:07.823292  1343 sgd_solver.cpp:106] Iteration 127900, lr = 2.22996e-07
I0826 12:45:10.188230  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:45:16.259183  1343 solver.cpp:228] Iteration 128000, loss = 3.36559
I0826 12:45:16.259253  1343 solver.cpp:244]     Train net output #0: loss = 3.36559 (* 1 = 3.36559 loss)
I0826 12:45:16.259263  1343 sgd_solver.cpp:106] Iteration 128000, lr = 2.22883e-07
I0826 12:45:24.681984  1343 solver.cpp:228] Iteration 128100, loss = 3.33425
I0826 12:45:24.682046  1343 solver.cpp:244]     Train net output #0: loss = 3.33425 (* 1 = 3.33425 loss)
I0826 12:45:24.682057  1343 sgd_solver.cpp:106] Iteration 128100, lr = 2.2277e-07
I0826 12:45:33.100460  1343 solver.cpp:228] Iteration 128200, loss = 3.24121
I0826 12:45:33.100527  1343 solver.cpp:244]     Train net output #0: loss = 3.24121 (* 1 = 3.24121 loss)
I0826 12:45:33.100535  1343 sgd_solver.cpp:106] Iteration 128200, lr = 2.22657e-07
I0826 12:45:41.513667  1343 solver.cpp:228] Iteration 128300, loss = 3.37266
I0826 12:45:41.513743  1343 solver.cpp:244]     Train net output #0: loss = 3.37266 (* 1 = 3.37266 loss)
I0826 12:45:41.513752  1343 sgd_solver.cpp:106] Iteration 128300, lr = 2.22544e-07
I0826 12:45:49.929196  1343 solver.cpp:228] Iteration 128400, loss = 3.38055
I0826 12:45:49.929255  1343 solver.cpp:244]     Train net output #0: loss = 3.38055 (* 1 = 3.38055 loss)
I0826 12:45:49.929265  1343 sgd_solver.cpp:106] Iteration 128400, lr = 2.22432e-07
I0826 12:45:58.359386  1343 solver.cpp:228] Iteration 128500, loss = 3.46444
I0826 12:45:58.359449  1343 solver.cpp:244]     Train net output #0: loss = 3.46444 (* 1 = 3.46444 loss)
I0826 12:45:58.359462  1343 sgd_solver.cpp:106] Iteration 128500, lr = 2.2232e-07
I0826 12:46:06.794603  1343 solver.cpp:228] Iteration 128600, loss = 3.54356
I0826 12:46:06.794666  1343 solver.cpp:244]     Train net output #0: loss = 3.54356 (* 1 = 3.54356 loss)
I0826 12:46:06.794679  1343 sgd_solver.cpp:106] Iteration 128600, lr = 2.22207e-07
I0826 12:46:15.203017  1343 solver.cpp:228] Iteration 128700, loss = 3.49095
I0826 12:46:15.203075  1343 solver.cpp:244]     Train net output #0: loss = 3.49095 (* 1 = 3.49095 loss)
I0826 12:46:15.203084  1343 sgd_solver.cpp:106] Iteration 128700, lr = 2.22095e-07
I0826 12:46:23.633915  1343 solver.cpp:228] Iteration 128800, loss = 3.45761
I0826 12:46:23.633977  1343 solver.cpp:244]     Train net output #0: loss = 3.45761 (* 1 = 3.45761 loss)
I0826 12:46:23.633988  1343 sgd_solver.cpp:106] Iteration 128800, lr = 2.21983e-07
I0826 12:46:32.049294  1343 solver.cpp:228] Iteration 128900, loss = 3.56855
I0826 12:46:32.049362  1343 solver.cpp:244]     Train net output #0: loss = 3.56855 (* 1 = 3.56855 loss)
I0826 12:46:32.049373  1343 sgd_solver.cpp:106] Iteration 128900, lr = 2.21871e-07
I0826 12:46:40.447520  1343 solver.cpp:228] Iteration 129000, loss = 3.42849
I0826 12:46:40.447587  1343 solver.cpp:244]     Train net output #0: loss = 3.42849 (* 1 = 3.42849 loss)
I0826 12:46:40.447599  1343 sgd_solver.cpp:106] Iteration 129000, lr = 2.2176e-07
I0826 12:46:48.865442  1343 solver.cpp:228] Iteration 129100, loss = 3.41367
I0826 12:46:48.865506  1343 solver.cpp:244]     Train net output #0: loss = 3.41367 (* 1 = 3.41367 loss)
I0826 12:46:48.865519  1343 sgd_solver.cpp:106] Iteration 129100, lr = 2.21648e-07
I0826 12:46:57.269242  1343 solver.cpp:228] Iteration 129200, loss = 3.62184
I0826 12:46:57.269284  1343 solver.cpp:244]     Train net output #0: loss = 3.62184 (* 1 = 3.62184 loss)
I0826 12:46:57.269289  1343 sgd_solver.cpp:106] Iteration 129200, lr = 2.21537e-07
I0826 12:47:05.679858  1343 solver.cpp:228] Iteration 129300, loss = 3.38254
I0826 12:47:05.679918  1343 solver.cpp:244]     Train net output #0: loss = 3.38254 (* 1 = 3.38254 loss)
I0826 12:47:05.679929  1343 sgd_solver.cpp:106] Iteration 129300, lr = 2.21426e-07
I0826 12:47:14.101307  1343 solver.cpp:228] Iteration 129400, loss = 3.52098
I0826 12:47:14.101388  1343 solver.cpp:244]     Train net output #0: loss = 3.52098 (* 1 = 3.52098 loss)
I0826 12:47:14.101407  1343 sgd_solver.cpp:106] Iteration 129400, lr = 2.21314e-07
I0826 12:47:22.505885  1343 solver.cpp:228] Iteration 129500, loss = 3.25743
I0826 12:47:22.505935  1343 solver.cpp:244]     Train net output #0: loss = 3.25743 (* 1 = 3.25743 loss)
I0826 12:47:22.505941  1343 sgd_solver.cpp:106] Iteration 129500, lr = 2.21203e-07
I0826 12:47:30.921339  1343 solver.cpp:228] Iteration 129600, loss = 3.55982
I0826 12:47:30.921397  1343 solver.cpp:244]     Train net output #0: loss = 3.55982 (* 1 = 3.55982 loss)
I0826 12:47:30.921406  1343 sgd_solver.cpp:106] Iteration 129600, lr = 2.21092e-07
I0826 12:47:39.341630  1343 solver.cpp:228] Iteration 129700, loss = 3.4803
I0826 12:47:39.341697  1343 solver.cpp:244]     Train net output #0: loss = 3.4803 (* 1 = 3.4803 loss)
I0826 12:47:39.341704  1343 sgd_solver.cpp:106] Iteration 129700, lr = 2.20982e-07
I0826 12:47:47.768431  1343 solver.cpp:228] Iteration 129800, loss = 3.44947
I0826 12:47:47.768504  1343 solver.cpp:244]     Train net output #0: loss = 3.44947 (* 1 = 3.44947 loss)
I0826 12:47:47.768514  1343 sgd_solver.cpp:106] Iteration 129800, lr = 2.20871e-07
I0826 12:47:56.179755  1343 solver.cpp:228] Iteration 129900, loss = 3.54
I0826 12:47:56.179811  1343 solver.cpp:244]     Train net output #0: loss = 3.54 (* 1 = 3.54 loss)
I0826 12:47:56.179819  1343 sgd_solver.cpp:106] Iteration 129900, lr = 2.2076e-07
I0826 12:48:04.522084  1343 solver.cpp:337] Iteration 130000, Testing net (#0)
I0826 12:48:21.291337  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:48:41.899992  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302058
I0826 12:48:41.900059  1343 solver.cpp:404]     Test net output #1: loss = 3.42951 (* 1 = 3.42951 loss)
I0826 12:48:41.930850  1343 solver.cpp:228] Iteration 130000, loss = 3.23942
I0826 12:48:41.930914  1343 solver.cpp:244]     Train net output #0: loss = 3.23942 (* 1 = 3.23942 loss)
I0826 12:48:41.930937  1343 sgd_solver.cpp:106] Iteration 130000, lr = 2.2065e-07
I0826 12:48:50.334308  1343 solver.cpp:228] Iteration 130100, loss = 3.65544
I0826 12:48:50.334365  1343 solver.cpp:244]     Train net output #0: loss = 3.65544 (* 1 = 3.65544 loss)
I0826 12:48:50.334375  1343 sgd_solver.cpp:106] Iteration 130100, lr = 2.2054e-07
I0826 12:48:58.750494  1343 solver.cpp:228] Iteration 130200, loss = 3.43954
I0826 12:48:58.750565  1343 solver.cpp:244]     Train net output #0: loss = 3.43954 (* 1 = 3.43954 loss)
I0826 12:48:58.750572  1343 sgd_solver.cpp:106] Iteration 130200, lr = 2.2043e-07
I0826 12:49:07.175071  1343 solver.cpp:228] Iteration 130300, loss = 3.36726
I0826 12:49:07.175134  1343 solver.cpp:244]     Train net output #0: loss = 3.36726 (* 1 = 3.36726 loss)
I0826 12:49:07.175143  1343 sgd_solver.cpp:106] Iteration 130300, lr = 2.2032e-07
I0826 12:49:15.564322  1343 solver.cpp:228] Iteration 130400, loss = 3.49817
I0826 12:49:15.564391  1343 solver.cpp:244]     Train net output #0: loss = 3.49817 (* 1 = 3.49817 loss)
I0826 12:49:15.564399  1343 sgd_solver.cpp:106] Iteration 130400, lr = 2.2021e-07
I0826 12:49:23.992796  1343 solver.cpp:228] Iteration 130500, loss = 3.3587
I0826 12:49:23.992851  1343 solver.cpp:244]     Train net output #0: loss = 3.3587 (* 1 = 3.3587 loss)
I0826 12:49:23.992859  1343 sgd_solver.cpp:106] Iteration 130500, lr = 2.201e-07
I0826 12:49:32.413445  1343 solver.cpp:228] Iteration 130600, loss = 3.44181
I0826 12:49:32.413486  1343 solver.cpp:244]     Train net output #0: loss = 3.44181 (* 1 = 3.44181 loss)
I0826 12:49:32.413491  1343 sgd_solver.cpp:106] Iteration 130600, lr = 2.1999e-07
I0826 12:49:40.807757  1343 solver.cpp:228] Iteration 130700, loss = 3.28977
I0826 12:49:40.807827  1343 solver.cpp:244]     Train net output #0: loss = 3.28977 (* 1 = 3.28977 loss)
I0826 12:49:40.807837  1343 sgd_solver.cpp:106] Iteration 130700, lr = 2.19881e-07
I0826 12:49:49.228610  1343 solver.cpp:228] Iteration 130800, loss = 3.36288
I0826 12:49:49.228672  1343 solver.cpp:244]     Train net output #0: loss = 3.36288 (* 1 = 3.36288 loss)
I0826 12:49:49.228682  1343 sgd_solver.cpp:106] Iteration 130800, lr = 2.19772e-07
I0826 12:49:57.650741  1343 solver.cpp:228] Iteration 130900, loss = 3.38428
I0826 12:49:57.650800  1343 solver.cpp:244]     Train net output #0: loss = 3.38428 (* 1 = 3.38428 loss)
I0826 12:49:57.650807  1343 sgd_solver.cpp:106] Iteration 130900, lr = 2.19662e-07
I0826 12:50:06.048363  1343 solver.cpp:228] Iteration 131000, loss = 3.49425
I0826 12:50:06.048427  1343 solver.cpp:244]     Train net output #0: loss = 3.49425 (* 1 = 3.49425 loss)
I0826 12:50:06.048437  1343 sgd_solver.cpp:106] Iteration 131000, lr = 2.19553e-07
I0826 12:50:14.464210  1343 solver.cpp:228] Iteration 131100, loss = 3.42921
I0826 12:50:14.464267  1343 solver.cpp:244]     Train net output #0: loss = 3.42921 (* 1 = 3.42921 loss)
I0826 12:50:14.464272  1343 sgd_solver.cpp:106] Iteration 131100, lr = 2.19444e-07
I0826 12:50:22.886677  1343 solver.cpp:228] Iteration 131200, loss = 3.44339
I0826 12:50:22.886744  1343 solver.cpp:244]     Train net output #0: loss = 3.44339 (* 1 = 3.44339 loss)
I0826 12:50:22.886749  1343 sgd_solver.cpp:106] Iteration 131200, lr = 2.19335e-07
I0826 12:50:31.317638  1343 solver.cpp:228] Iteration 131300, loss = 3.45433
I0826 12:50:31.317706  1343 solver.cpp:244]     Train net output #0: loss = 3.45433 (* 1 = 3.45433 loss)
I0826 12:50:31.317715  1343 sgd_solver.cpp:106] Iteration 131300, lr = 2.19227e-07
I0826 12:50:39.724062  1343 solver.cpp:228] Iteration 131400, loss = 3.43141
I0826 12:50:39.724118  1343 solver.cpp:244]     Train net output #0: loss = 3.43141 (* 1 = 3.43141 loss)
I0826 12:50:39.724126  1343 sgd_solver.cpp:106] Iteration 131400, lr = 2.19118e-07
I0826 12:50:48.139308  1343 solver.cpp:228] Iteration 131500, loss = 3.37001
I0826 12:50:48.139354  1343 solver.cpp:244]     Train net output #0: loss = 3.37001 (* 1 = 3.37001 loss)
I0826 12:50:48.139360  1343 sgd_solver.cpp:106] Iteration 131500, lr = 2.1901e-07
I0826 12:50:56.558547  1343 solver.cpp:228] Iteration 131600, loss = 3.43056
I0826 12:50:56.558616  1343 solver.cpp:244]     Train net output #0: loss = 3.43056 (* 1 = 3.43056 loss)
I0826 12:50:56.558624  1343 sgd_solver.cpp:106] Iteration 131600, lr = 2.18901e-07
I0826 12:51:04.968852  1343 solver.cpp:228] Iteration 131700, loss = 3.4481
I0826 12:51:04.968912  1343 solver.cpp:244]     Train net output #0: loss = 3.4481 (* 1 = 3.4481 loss)
I0826 12:51:04.968922  1343 sgd_solver.cpp:106] Iteration 131700, lr = 2.18793e-07
I0826 12:51:13.400758  1343 solver.cpp:228] Iteration 131800, loss = 3.46829
I0826 12:51:13.400810  1343 solver.cpp:244]     Train net output #0: loss = 3.46829 (* 1 = 3.46829 loss)
I0826 12:51:13.400818  1343 sgd_solver.cpp:106] Iteration 131800, lr = 2.18685e-07
I0826 12:51:21.825381  1343 solver.cpp:228] Iteration 131900, loss = 3.33229
I0826 12:51:21.825426  1343 solver.cpp:244]     Train net output #0: loss = 3.33229 (* 1 = 3.33229 loss)
I0826 12:51:21.825431  1343 sgd_solver.cpp:106] Iteration 131900, lr = 2.18577e-07
I0826 12:51:30.241550  1343 solver.cpp:228] Iteration 132000, loss = 3.48146
I0826 12:51:30.241608  1343 solver.cpp:244]     Train net output #0: loss = 3.48146 (* 1 = 3.48146 loss)
I0826 12:51:30.241617  1343 sgd_solver.cpp:106] Iteration 132000, lr = 2.18469e-07
I0826 12:51:38.653774  1343 solver.cpp:228] Iteration 132100, loss = 3.31998
I0826 12:51:38.653820  1343 solver.cpp:244]     Train net output #0: loss = 3.31998 (* 1 = 3.31998 loss)
I0826 12:51:38.653825  1343 sgd_solver.cpp:106] Iteration 132100, lr = 2.18361e-07
I0826 12:51:47.073460  1343 solver.cpp:228] Iteration 132200, loss = 3.22744
I0826 12:51:47.073529  1343 solver.cpp:244]     Train net output #0: loss = 3.22744 (* 1 = 3.22744 loss)
I0826 12:51:47.073541  1343 sgd_solver.cpp:106] Iteration 132200, lr = 2.18254e-07
I0826 12:51:55.492152  1343 solver.cpp:228] Iteration 132300, loss = 3.26315
I0826 12:51:55.492219  1343 solver.cpp:244]     Train net output #0: loss = 3.26315 (* 1 = 3.26315 loss)
I0826 12:51:55.492228  1343 sgd_solver.cpp:106] Iteration 132300, lr = 2.18146e-07
I0826 12:52:03.899443  1343 solver.cpp:228] Iteration 132400, loss = 3.53956
I0826 12:52:03.899507  1343 solver.cpp:244]     Train net output #0: loss = 3.53956 (* 1 = 3.53956 loss)
I0826 12:52:03.899515  1343 sgd_solver.cpp:106] Iteration 132400, lr = 2.18039e-07
I0826 12:52:08.791870  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:52:12.312940  1343 solver.cpp:228] Iteration 132500, loss = 3.57852
I0826 12:52:12.312994  1343 solver.cpp:244]     Train net output #0: loss = 3.57852 (* 1 = 3.57852 loss)
I0826 12:52:12.313002  1343 sgd_solver.cpp:106] Iteration 132500, lr = 2.17932e-07
I0826 12:52:20.731147  1343 solver.cpp:228] Iteration 132600, loss = 3.44014
I0826 12:52:20.731196  1343 solver.cpp:244]     Train net output #0: loss = 3.44014 (* 1 = 3.44014 loss)
I0826 12:52:20.731202  1343 sgd_solver.cpp:106] Iteration 132600, lr = 2.17824e-07
I0826 12:52:29.143910  1343 solver.cpp:228] Iteration 132700, loss = 3.67669
I0826 12:52:29.143975  1343 solver.cpp:244]     Train net output #0: loss = 3.67669 (* 1 = 3.67669 loss)
I0826 12:52:29.143983  1343 sgd_solver.cpp:106] Iteration 132700, lr = 2.17717e-07
I0826 12:52:37.555655  1343 solver.cpp:228] Iteration 132800, loss = 3.33175
I0826 12:52:37.555716  1343 solver.cpp:244]     Train net output #0: loss = 3.33175 (* 1 = 3.33175 loss)
I0826 12:52:37.555726  1343 sgd_solver.cpp:106] Iteration 132800, lr = 2.17611e-07
I0826 12:52:45.977658  1343 solver.cpp:228] Iteration 132900, loss = 3.3583
I0826 12:52:45.977710  1343 solver.cpp:244]     Train net output #0: loss = 3.3583 (* 1 = 3.3583 loss)
I0826 12:52:45.977720  1343 sgd_solver.cpp:106] Iteration 132900, lr = 2.17504e-07
I0826 12:52:54.395171  1343 solver.cpp:228] Iteration 133000, loss = 3.36976
I0826 12:52:54.395237  1343 solver.cpp:244]     Train net output #0: loss = 3.36976 (* 1 = 3.36976 loss)
I0826 12:52:54.395246  1343 sgd_solver.cpp:106] Iteration 133000, lr = 2.17397e-07
I0826 12:53:02.809854  1343 solver.cpp:228] Iteration 133100, loss = 3.36975
I0826 12:53:02.809911  1343 solver.cpp:244]     Train net output #0: loss = 3.36975 (* 1 = 3.36975 loss)
I0826 12:53:02.809924  1343 sgd_solver.cpp:106] Iteration 133100, lr = 2.17291e-07
I0826 12:53:11.224200  1343 solver.cpp:228] Iteration 133200, loss = 3.30872
I0826 12:53:11.224252  1343 solver.cpp:244]     Train net output #0: loss = 3.30872 (* 1 = 3.30872 loss)
I0826 12:53:11.224261  1343 sgd_solver.cpp:106] Iteration 133200, lr = 2.17184e-07
I0826 12:53:19.641232  1343 solver.cpp:228] Iteration 133300, loss = 3.38772
I0826 12:53:19.641290  1343 solver.cpp:244]     Train net output #0: loss = 3.38772 (* 1 = 3.38772 loss)
I0826 12:53:19.641296  1343 sgd_solver.cpp:106] Iteration 133300, lr = 2.17078e-07
I0826 12:53:28.045938  1343 solver.cpp:228] Iteration 133400, loss = 3.33586
I0826 12:53:28.046027  1343 solver.cpp:244]     Train net output #0: loss = 3.33586 (* 1 = 3.33586 loss)
I0826 12:53:28.046047  1343 sgd_solver.cpp:106] Iteration 133400, lr = 2.16972e-07
I0826 12:53:36.473354  1343 solver.cpp:228] Iteration 133500, loss = 3.38466
I0826 12:53:36.473419  1343 solver.cpp:244]     Train net output #0: loss = 3.38466 (* 1 = 3.38466 loss)
I0826 12:53:36.473434  1343 sgd_solver.cpp:106] Iteration 133500, lr = 2.16866e-07
I0826 12:53:44.904914  1343 solver.cpp:228] Iteration 133600, loss = 3.26982
I0826 12:53:44.904970  1343 solver.cpp:244]     Train net output #0: loss = 3.26982 (* 1 = 3.26982 loss)
I0826 12:53:44.904978  1343 sgd_solver.cpp:106] Iteration 133600, lr = 2.1676e-07
I0826 12:53:53.303073  1343 solver.cpp:228] Iteration 133700, loss = 3.54566
I0826 12:53:53.303130  1343 solver.cpp:244]     Train net output #0: loss = 3.54566 (* 1 = 3.54566 loss)
I0826 12:53:53.303144  1343 sgd_solver.cpp:106] Iteration 133700, lr = 2.16654e-07
I0826 12:54:01.727720  1343 solver.cpp:228] Iteration 133800, loss = 3.4759
I0826 12:54:01.727792  1343 solver.cpp:244]     Train net output #0: loss = 3.4759 (* 1 = 3.4759 loss)
I0826 12:54:01.727802  1343 sgd_solver.cpp:106] Iteration 133800, lr = 2.16549e-07
I0826 12:54:10.152400  1343 solver.cpp:228] Iteration 133900, loss = 3.3587
I0826 12:54:10.152464  1343 solver.cpp:244]     Train net output #0: loss = 3.3587 (* 1 = 3.3587 loss)
I0826 12:54:10.152474  1343 sgd_solver.cpp:106] Iteration 133900, lr = 2.16443e-07
I0826 12:54:18.561374  1343 solver.cpp:228] Iteration 134000, loss = 3.51456
I0826 12:54:18.561435  1343 solver.cpp:244]     Train net output #0: loss = 3.51456 (* 1 = 3.51456 loss)
I0826 12:54:18.561444  1343 sgd_solver.cpp:106] Iteration 134000, lr = 2.16338e-07
I0826 12:54:26.973788  1343 solver.cpp:228] Iteration 134100, loss = 3.43474
I0826 12:54:26.973842  1343 solver.cpp:244]     Train net output #0: loss = 3.43474 (* 1 = 3.43474 loss)
I0826 12:54:26.973851  1343 sgd_solver.cpp:106] Iteration 134100, lr = 2.16232e-07
I0826 12:54:35.400962  1343 solver.cpp:228] Iteration 134200, loss = 3.44246
I0826 12:54:35.401016  1343 solver.cpp:244]     Train net output #0: loss = 3.44246 (* 1 = 3.44246 loss)
I0826 12:54:35.401023  1343 sgd_solver.cpp:106] Iteration 134200, lr = 2.16127e-07
I0826 12:54:43.825722  1343 solver.cpp:228] Iteration 134300, loss = 3.52409
I0826 12:54:43.825774  1343 solver.cpp:244]     Train net output #0: loss = 3.52409 (* 1 = 3.52409 loss)
I0826 12:54:43.825783  1343 sgd_solver.cpp:106] Iteration 134300, lr = 2.16022e-07
I0826 12:54:52.261204  1343 solver.cpp:228] Iteration 134400, loss = 3.38942
I0826 12:54:52.261251  1343 solver.cpp:244]     Train net output #0: loss = 3.38942 (* 1 = 3.38942 loss)
I0826 12:54:52.261260  1343 sgd_solver.cpp:106] Iteration 134400, lr = 2.15917e-07
I0826 12:55:00.675246  1343 solver.cpp:228] Iteration 134500, loss = 3.43787
I0826 12:55:00.675312  1343 solver.cpp:244]     Train net output #0: loss = 3.43787 (* 1 = 3.43787 loss)
I0826 12:55:00.675321  1343 sgd_solver.cpp:106] Iteration 134500, lr = 2.15812e-07
I0826 12:55:09.092557  1343 solver.cpp:228] Iteration 134600, loss = 3.32963
I0826 12:55:09.092636  1343 solver.cpp:244]     Train net output #0: loss = 3.32963 (* 1 = 3.32963 loss)
I0826 12:55:09.092648  1343 sgd_solver.cpp:106] Iteration 134600, lr = 2.15708e-07
I0826 12:55:17.513070  1343 solver.cpp:228] Iteration 134700, loss = 3.40703
I0826 12:55:17.513149  1343 solver.cpp:244]     Train net output #0: loss = 3.40703 (* 1 = 3.40703 loss)
I0826 12:55:17.513159  1343 sgd_solver.cpp:106] Iteration 134700, lr = 2.15603e-07
I0826 12:55:25.906654  1343 solver.cpp:228] Iteration 134800, loss = 3.51744
I0826 12:55:25.906749  1343 solver.cpp:244]     Train net output #0: loss = 3.51744 (* 1 = 3.51744 loss)
I0826 12:55:25.906762  1343 sgd_solver.cpp:106] Iteration 134800, lr = 2.15499e-07
I0826 12:55:34.324265  1343 solver.cpp:228] Iteration 134900, loss = 3.41453
I0826 12:55:34.324337  1343 solver.cpp:244]     Train net output #0: loss = 3.41453 (* 1 = 3.41453 loss)
I0826 12:55:34.324345  1343 sgd_solver.cpp:106] Iteration 134900, lr = 2.15394e-07
I0826 12:55:42.664976  1343 solver.cpp:337] Iteration 135000, Testing net (#0)
I0826 12:55:52.380259  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:56:19.853036  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302075
I0826 12:56:19.853101  1343 solver.cpp:404]     Test net output #1: loss = 3.42786 (* 1 = 3.42786 loss)
I0826 12:56:19.883240  1343 solver.cpp:228] Iteration 135000, loss = 3.46549
I0826 12:56:19.883297  1343 solver.cpp:244]     Train net output #0: loss = 3.46549 (* 1 = 3.46549 loss)
I0826 12:56:19.883311  1343 sgd_solver.cpp:106] Iteration 135000, lr = 2.1529e-07
I0826 12:56:28.301863  1343 solver.cpp:228] Iteration 135100, loss = 3.24144
I0826 12:56:28.301920  1343 solver.cpp:244]     Train net output #0: loss = 3.24144 (* 1 = 3.24144 loss)
I0826 12:56:28.301930  1343 sgd_solver.cpp:106] Iteration 135100, lr = 2.15186e-07
I0826 12:56:36.712374  1343 solver.cpp:228] Iteration 135200, loss = 3.43787
I0826 12:56:36.712440  1343 solver.cpp:244]     Train net output #0: loss = 3.43787 (* 1 = 3.43787 loss)
I0826 12:56:36.712453  1343 sgd_solver.cpp:106] Iteration 135200, lr = 2.15082e-07
I0826 12:56:45.118875  1343 solver.cpp:228] Iteration 135300, loss = 3.29652
I0826 12:56:45.118927  1343 solver.cpp:244]     Train net output #0: loss = 3.29652 (* 1 = 3.29652 loss)
I0826 12:56:45.118935  1343 sgd_solver.cpp:106] Iteration 135300, lr = 2.14978e-07
I0826 12:56:53.540904  1343 solver.cpp:228] Iteration 135400, loss = 3.52073
I0826 12:56:53.540971  1343 solver.cpp:244]     Train net output #0: loss = 3.52073 (* 1 = 3.52073 loss)
I0826 12:56:53.540980  1343 sgd_solver.cpp:106] Iteration 135400, lr = 2.14874e-07
I0826 12:57:01.944043  1343 solver.cpp:228] Iteration 135500, loss = 3.3306
I0826 12:57:01.944102  1343 solver.cpp:244]     Train net output #0: loss = 3.3306 (* 1 = 3.3306 loss)
I0826 12:57:01.944108  1343 sgd_solver.cpp:106] Iteration 135500, lr = 2.14771e-07
I0826 12:57:10.353382  1343 solver.cpp:228] Iteration 135600, loss = 3.28998
I0826 12:57:10.353449  1343 solver.cpp:244]     Train net output #0: loss = 3.28998 (* 1 = 3.28998 loss)
I0826 12:57:10.353458  1343 sgd_solver.cpp:106] Iteration 135600, lr = 2.14667e-07
I0826 12:57:18.768406  1343 solver.cpp:228] Iteration 135700, loss = 3.41512
I0826 12:57:18.768484  1343 solver.cpp:244]     Train net output #0: loss = 3.41512 (* 1 = 3.41512 loss)
I0826 12:57:18.768497  1343 sgd_solver.cpp:106] Iteration 135700, lr = 2.14564e-07
I0826 12:57:27.169983  1343 solver.cpp:228] Iteration 135800, loss = 3.35984
I0826 12:57:27.170032  1343 solver.cpp:244]     Train net output #0: loss = 3.35984 (* 1 = 3.35984 loss)
I0826 12:57:27.170038  1343 sgd_solver.cpp:106] Iteration 135800, lr = 2.1446e-07
I0826 12:57:35.586328  1343 solver.cpp:228] Iteration 135900, loss = 3.56528
I0826 12:57:35.586403  1343 solver.cpp:244]     Train net output #0: loss = 3.56528 (* 1 = 3.56528 loss)
I0826 12:57:35.586413  1343 sgd_solver.cpp:106] Iteration 135900, lr = 2.14357e-07
I0826 12:57:44.004488  1343 solver.cpp:228] Iteration 136000, loss = 3.41954
I0826 12:57:44.004557  1343 solver.cpp:244]     Train net output #0: loss = 3.41954 (* 1 = 3.41954 loss)
I0826 12:57:44.004567  1343 sgd_solver.cpp:106] Iteration 136000, lr = 2.14254e-07
I0826 12:57:50.224418  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 12:57:52.405879  1343 solver.cpp:228] Iteration 136100, loss = 3.31306
I0826 12:57:52.405933  1343 solver.cpp:244]     Train net output #0: loss = 3.31306 (* 1 = 3.31306 loss)
I0826 12:57:52.405942  1343 sgd_solver.cpp:106] Iteration 136100, lr = 2.14151e-07
I0826 12:58:00.821218  1343 solver.cpp:228] Iteration 136200, loss = 3.58224
I0826 12:58:00.821264  1343 solver.cpp:244]     Train net output #0: loss = 3.58224 (* 1 = 3.58224 loss)
I0826 12:58:00.821269  1343 sgd_solver.cpp:106] Iteration 136200, lr = 2.14048e-07
I0826 12:58:09.235204  1343 solver.cpp:228] Iteration 136300, loss = 3.53107
I0826 12:58:09.235251  1343 solver.cpp:244]     Train net output #0: loss = 3.53107 (* 1 = 3.53107 loss)
I0826 12:58:09.235256  1343 sgd_solver.cpp:106] Iteration 136300, lr = 2.13946e-07
I0826 12:58:17.639580  1343 solver.cpp:228] Iteration 136400, loss = 3.50784
I0826 12:58:17.639641  1343 solver.cpp:244]     Train net output #0: loss = 3.50784 (* 1 = 3.50784 loss)
I0826 12:58:17.639647  1343 sgd_solver.cpp:106] Iteration 136400, lr = 2.13843e-07
I0826 12:58:26.052268  1343 solver.cpp:228] Iteration 136500, loss = 3.40668
I0826 12:58:26.052335  1343 solver.cpp:244]     Train net output #0: loss = 3.40668 (* 1 = 3.40668 loss)
I0826 12:58:26.052345  1343 sgd_solver.cpp:106] Iteration 136500, lr = 2.1374e-07
I0826 12:58:34.468329  1343 solver.cpp:228] Iteration 136600, loss = 3.24774
I0826 12:58:34.468389  1343 solver.cpp:244]     Train net output #0: loss = 3.24774 (* 1 = 3.24774 loss)
I0826 12:58:34.468399  1343 sgd_solver.cpp:106] Iteration 136600, lr = 2.13638e-07
I0826 12:58:42.877988  1343 solver.cpp:228] Iteration 136700, loss = 3.3829
I0826 12:58:42.878046  1343 solver.cpp:244]     Train net output #0: loss = 3.3829 (* 1 = 3.3829 loss)
I0826 12:58:42.878057  1343 sgd_solver.cpp:106] Iteration 136700, lr = 2.13536e-07
I0826 12:58:51.301385  1343 solver.cpp:228] Iteration 136800, loss = 3.5063
I0826 12:58:51.301461  1343 solver.cpp:244]     Train net output #0: loss = 3.5063 (* 1 = 3.5063 loss)
I0826 12:58:51.301475  1343 sgd_solver.cpp:106] Iteration 136800, lr = 2.13434e-07
I0826 12:58:59.692987  1343 solver.cpp:228] Iteration 136900, loss = 3.26446
I0826 12:58:59.693043  1343 solver.cpp:244]     Train net output #0: loss = 3.26446 (* 1 = 3.26446 loss)
I0826 12:58:59.693053  1343 sgd_solver.cpp:106] Iteration 136900, lr = 2.13332e-07
I0826 12:59:08.106936  1343 solver.cpp:228] Iteration 137000, loss = 3.36951
I0826 12:59:08.107012  1343 solver.cpp:244]     Train net output #0: loss = 3.36951 (* 1 = 3.36951 loss)
I0826 12:59:08.107028  1343 sgd_solver.cpp:106] Iteration 137000, lr = 2.1323e-07
I0826 12:59:16.519692  1343 solver.cpp:228] Iteration 137100, loss = 3.43996
I0826 12:59:16.519765  1343 solver.cpp:244]     Train net output #0: loss = 3.43996 (* 1 = 3.43996 loss)
I0826 12:59:16.519785  1343 sgd_solver.cpp:106] Iteration 137100, lr = 2.13128e-07
I0826 12:59:24.934820  1343 solver.cpp:228] Iteration 137200, loss = 3.42286
I0826 12:59:24.934880  1343 solver.cpp:244]     Train net output #0: loss = 3.42286 (* 1 = 3.42286 loss)
I0826 12:59:24.934887  1343 sgd_solver.cpp:106] Iteration 137200, lr = 2.13026e-07
I0826 12:59:33.349611  1343 solver.cpp:228] Iteration 137300, loss = 3.5353
I0826 12:59:33.349680  1343 solver.cpp:244]     Train net output #0: loss = 3.5353 (* 1 = 3.5353 loss)
I0826 12:59:33.349690  1343 sgd_solver.cpp:106] Iteration 137300, lr = 2.12925e-07
I0826 12:59:41.762120  1343 solver.cpp:228] Iteration 137400, loss = 3.46539
I0826 12:59:41.762162  1343 solver.cpp:244]     Train net output #0: loss = 3.46539 (* 1 = 3.46539 loss)
I0826 12:59:41.762168  1343 sgd_solver.cpp:106] Iteration 137400, lr = 2.12823e-07
I0826 12:59:50.155753  1343 solver.cpp:228] Iteration 137500, loss = 3.3181
I0826 12:59:50.155798  1343 solver.cpp:244]     Train net output #0: loss = 3.3181 (* 1 = 3.3181 loss)
I0826 12:59:50.155804  1343 sgd_solver.cpp:106] Iteration 137500, lr = 2.12722e-07
I0826 12:59:58.580754  1343 solver.cpp:228] Iteration 137600, loss = 3.44874
I0826 12:59:58.580801  1343 solver.cpp:244]     Train net output #0: loss = 3.44874 (* 1 = 3.44874 loss)
I0826 12:59:58.580806  1343 sgd_solver.cpp:106] Iteration 137600, lr = 2.12621e-07
I0826 13:00:06.996656  1343 solver.cpp:228] Iteration 137700, loss = 3.55661
I0826 13:00:06.996711  1343 solver.cpp:244]     Train net output #0: loss = 3.55661 (* 1 = 3.55661 loss)
I0826 13:00:06.996719  1343 sgd_solver.cpp:106] Iteration 137700, lr = 2.12519e-07
I0826 13:00:15.402941  1343 solver.cpp:228] Iteration 137800, loss = 3.41919
I0826 13:00:15.403002  1343 solver.cpp:244]     Train net output #0: loss = 3.41919 (* 1 = 3.41919 loss)
I0826 13:00:15.403012  1343 sgd_solver.cpp:106] Iteration 137800, lr = 2.12418e-07
I0826 13:00:23.827230  1343 solver.cpp:228] Iteration 137900, loss = 3.2909
I0826 13:00:23.827288  1343 solver.cpp:244]     Train net output #0: loss = 3.2909 (* 1 = 3.2909 loss)
I0826 13:00:23.827296  1343 sgd_solver.cpp:106] Iteration 137900, lr = 2.12318e-07
I0826 13:00:32.229370  1343 solver.cpp:228] Iteration 138000, loss = 3.61718
I0826 13:00:32.229411  1343 solver.cpp:244]     Train net output #0: loss = 3.61718 (* 1 = 3.61718 loss)
I0826 13:00:32.229418  1343 sgd_solver.cpp:106] Iteration 138000, lr = 2.12217e-07
I0826 13:00:40.647264  1343 solver.cpp:228] Iteration 138100, loss = 3.55779
I0826 13:00:40.647338  1343 solver.cpp:244]     Train net output #0: loss = 3.55779 (* 1 = 3.55779 loss)
I0826 13:00:40.647349  1343 sgd_solver.cpp:106] Iteration 138100, lr = 2.12116e-07
I0826 13:00:49.068881  1343 solver.cpp:228] Iteration 138200, loss = 3.39002
I0826 13:00:49.068948  1343 solver.cpp:244]     Train net output #0: loss = 3.39002 (* 1 = 3.39002 loss)
I0826 13:00:49.068958  1343 sgd_solver.cpp:106] Iteration 138200, lr = 2.12016e-07
I0826 13:00:57.462955  1343 solver.cpp:228] Iteration 138300, loss = 3.44017
I0826 13:00:57.463016  1343 solver.cpp:244]     Train net output #0: loss = 3.44017 (* 1 = 3.44017 loss)
I0826 13:00:57.463023  1343 sgd_solver.cpp:106] Iteration 138300, lr = 2.11915e-07
I0826 13:01:05.875051  1343 solver.cpp:228] Iteration 138400, loss = 3.34933
I0826 13:01:05.875093  1343 solver.cpp:244]     Train net output #0: loss = 3.34933 (* 1 = 3.34933 loss)
I0826 13:01:05.875098  1343 sgd_solver.cpp:106] Iteration 138400, lr = 2.11815e-07
I0826 13:01:14.260468  1343 solver.cpp:228] Iteration 138500, loss = 3.42544
I0826 13:01:14.260531  1343 solver.cpp:244]     Train net output #0: loss = 3.42544 (* 1 = 3.42544 loss)
I0826 13:01:14.260542  1343 sgd_solver.cpp:106] Iteration 138500, lr = 2.11714e-07
I0826 13:01:22.678293  1343 solver.cpp:228] Iteration 138600, loss = 3.41022
I0826 13:01:22.678355  1343 solver.cpp:244]     Train net output #0: loss = 3.41022 (* 1 = 3.41022 loss)
I0826 13:01:22.678366  1343 sgd_solver.cpp:106] Iteration 138600, lr = 2.11614e-07
I0826 13:01:31.110946  1343 solver.cpp:228] Iteration 138700, loss = 3.31244
I0826 13:01:31.111016  1343 solver.cpp:244]     Train net output #0: loss = 3.31244 (* 1 = 3.31244 loss)
I0826 13:01:31.111026  1343 sgd_solver.cpp:106] Iteration 138700, lr = 2.11514e-07
I0826 13:01:39.535827  1343 solver.cpp:228] Iteration 138800, loss = 3.36075
I0826 13:01:39.535878  1343 solver.cpp:244]     Train net output #0: loss = 3.36075 (* 1 = 3.36075 loss)
I0826 13:01:39.535888  1343 sgd_solver.cpp:106] Iteration 138800, lr = 2.11414e-07
I0826 13:01:47.937566  1343 solver.cpp:228] Iteration 138900, loss = 3.42574
I0826 13:01:47.937625  1343 solver.cpp:244]     Train net output #0: loss = 3.42574 (* 1 = 3.42574 loss)
I0826 13:01:47.937638  1343 sgd_solver.cpp:106] Iteration 138900, lr = 2.11315e-07
I0826 13:01:56.359822  1343 solver.cpp:228] Iteration 139000, loss = 3.25348
I0826 13:01:56.359890  1343 solver.cpp:244]     Train net output #0: loss = 3.25348 (* 1 = 3.25348 loss)
I0826 13:01:56.359902  1343 sgd_solver.cpp:106] Iteration 139000, lr = 2.11215e-07
I0826 13:02:04.770103  1343 solver.cpp:228] Iteration 139100, loss = 3.46994
I0826 13:02:04.770170  1343 solver.cpp:244]     Train net output #0: loss = 3.46994 (* 1 = 3.46994 loss)
I0826 13:02:04.770180  1343 sgd_solver.cpp:106] Iteration 139100, lr = 2.11115e-07
I0826 13:02:13.190996  1343 solver.cpp:228] Iteration 139200, loss = 3.47331
I0826 13:02:13.191040  1343 solver.cpp:244]     Train net output #0: loss = 3.47331 (* 1 = 3.47331 loss)
I0826 13:02:13.191045  1343 sgd_solver.cpp:106] Iteration 139200, lr = 2.11016e-07
I0826 13:02:21.599733  1343 solver.cpp:228] Iteration 139300, loss = 3.33017
I0826 13:02:21.599802  1343 solver.cpp:244]     Train net output #0: loss = 3.33017 (* 1 = 3.33017 loss)
I0826 13:02:21.599812  1343 sgd_solver.cpp:106] Iteration 139300, lr = 2.10917e-07
I0826 13:02:30.010336  1343 solver.cpp:228] Iteration 139400, loss = 3.47893
I0826 13:02:30.010409  1343 solver.cpp:244]     Train net output #0: loss = 3.47893 (* 1 = 3.47893 loss)
I0826 13:02:30.010417  1343 sgd_solver.cpp:106] Iteration 139400, lr = 2.10817e-07
I0826 13:02:38.411551  1343 solver.cpp:228] Iteration 139500, loss = 3.57849
I0826 13:02:38.411604  1343 solver.cpp:244]     Train net output #0: loss = 3.57849 (* 1 = 3.57849 loss)
I0826 13:02:38.411612  1343 sgd_solver.cpp:106] Iteration 139500, lr = 2.10718e-07
I0826 13:02:46.822615  1343 solver.cpp:228] Iteration 139600, loss = 3.52103
I0826 13:02:46.822669  1343 solver.cpp:244]     Train net output #0: loss = 3.52103 (* 1 = 3.52103 loss)
I0826 13:02:46.822679  1343 sgd_solver.cpp:106] Iteration 139600, lr = 2.10619e-07
I0826 13:02:55.220222  1343 solver.cpp:228] Iteration 139700, loss = 3.30016
I0826 13:02:55.220280  1343 solver.cpp:244]     Train net output #0: loss = 3.30016 (* 1 = 3.30016 loss)
I0826 13:02:55.220293  1343 sgd_solver.cpp:106] Iteration 139700, lr = 2.1052e-07
I0826 13:03:03.220734  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:03:03.641136  1343 solver.cpp:228] Iteration 139800, loss = 3.45062
I0826 13:03:03.641196  1343 solver.cpp:244]     Train net output #0: loss = 3.45062 (* 1 = 3.45062 loss)
I0826 13:03:03.641206  1343 sgd_solver.cpp:106] Iteration 139800, lr = 2.10421e-07
I0826 13:03:12.071636  1343 solver.cpp:228] Iteration 139900, loss = 3.3585
I0826 13:03:12.071702  1343 solver.cpp:244]     Train net output #0: loss = 3.3585 (* 1 = 3.3585 loss)
I0826 13:03:12.071713  1343 sgd_solver.cpp:106] Iteration 139900, lr = 2.10323e-07
I0826 13:03:20.429563  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_140000.caffemodel
I0826 13:03:20.984657  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_140000.solverstate
I0826 13:03:21.146083  1343 solver.cpp:337] Iteration 140000, Testing net (#0)
I0826 13:03:58.810314  1343 solver.cpp:404]     Test net output #0: accuracy = 0.301997
I0826 13:03:58.810365  1343 solver.cpp:404]     Test net output #1: loss = 3.42685 (* 1 = 3.42685 loss)
I0826 13:03:58.838814  1343 solver.cpp:228] Iteration 140000, loss = 3.4233
I0826 13:03:58.838872  1343 solver.cpp:244]     Train net output #0: loss = 3.4233 (* 1 = 3.4233 loss)
I0826 13:03:58.838884  1343 sgd_solver.cpp:106] Iteration 140000, lr = 2.10224e-07
I0826 13:04:07.257464  1343 solver.cpp:228] Iteration 140100, loss = 3.44067
I0826 13:04:07.257525  1343 solver.cpp:244]     Train net output #0: loss = 3.44067 (* 1 = 3.44067 loss)
I0826 13:04:07.257531  1343 sgd_solver.cpp:106] Iteration 140100, lr = 2.10126e-07
I0826 13:04:15.678776  1343 solver.cpp:228] Iteration 140200, loss = 3.54081
I0826 13:04:15.678833  1343 solver.cpp:244]     Train net output #0: loss = 3.54081 (* 1 = 3.54081 loss)
I0826 13:04:15.678839  1343 sgd_solver.cpp:106] Iteration 140200, lr = 2.10027e-07
I0826 13:04:24.096861  1343 solver.cpp:228] Iteration 140300, loss = 3.41257
I0826 13:04:24.096912  1343 solver.cpp:244]     Train net output #0: loss = 3.41257 (* 1 = 3.41257 loss)
I0826 13:04:24.096920  1343 sgd_solver.cpp:106] Iteration 140300, lr = 2.09929e-07
I0826 13:04:32.504886  1343 solver.cpp:228] Iteration 140400, loss = 3.31336
I0826 13:04:32.504940  1343 solver.cpp:244]     Train net output #0: loss = 3.31336 (* 1 = 3.31336 loss)
I0826 13:04:32.504947  1343 sgd_solver.cpp:106] Iteration 140400, lr = 2.09831e-07
I0826 13:04:40.911667  1343 solver.cpp:228] Iteration 140500, loss = 3.33255
I0826 13:04:40.911710  1343 solver.cpp:244]     Train net output #0: loss = 3.33255 (* 1 = 3.33255 loss)
I0826 13:04:40.911715  1343 sgd_solver.cpp:106] Iteration 140500, lr = 2.09733e-07
I0826 13:04:49.313895  1343 solver.cpp:228] Iteration 140600, loss = 3.41555
I0826 13:04:49.313937  1343 solver.cpp:244]     Train net output #0: loss = 3.41555 (* 1 = 3.41555 loss)
I0826 13:04:49.313942  1343 sgd_solver.cpp:106] Iteration 140600, lr = 2.09635e-07
I0826 13:04:57.726125  1343 solver.cpp:228] Iteration 140700, loss = 3.40504
I0826 13:04:57.726167  1343 solver.cpp:244]     Train net output #0: loss = 3.40504 (* 1 = 3.40504 loss)
I0826 13:04:57.726173  1343 sgd_solver.cpp:106] Iteration 140700, lr = 2.09537e-07
I0826 13:05:06.142637  1343 solver.cpp:228] Iteration 140800, loss = 3.37324
I0826 13:05:06.142691  1343 solver.cpp:244]     Train net output #0: loss = 3.37324 (* 1 = 3.37324 loss)
I0826 13:05:06.142709  1343 sgd_solver.cpp:106] Iteration 140800, lr = 2.09439e-07
I0826 13:05:13.874115  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:05:14.553459  1343 solver.cpp:228] Iteration 140900, loss = 3.49
I0826 13:05:14.553530  1343 solver.cpp:244]     Train net output #0: loss = 3.49 (* 1 = 3.49 loss)
I0826 13:05:14.553544  1343 sgd_solver.cpp:106] Iteration 140900, lr = 2.09342e-07
I0826 13:05:22.975374  1343 solver.cpp:228] Iteration 141000, loss = 3.16378
I0826 13:05:22.975432  1343 solver.cpp:244]     Train net output #0: loss = 3.16378 (* 1 = 3.16378 loss)
I0826 13:05:22.975440  1343 sgd_solver.cpp:106] Iteration 141000, lr = 2.09244e-07
I0826 13:05:31.396891  1343 solver.cpp:228] Iteration 141100, loss = 3.42062
I0826 13:05:31.396945  1343 solver.cpp:244]     Train net output #0: loss = 3.42062 (* 1 = 3.42062 loss)
I0826 13:05:31.396955  1343 sgd_solver.cpp:106] Iteration 141100, lr = 2.09147e-07
I0826 13:05:39.808897  1343 solver.cpp:228] Iteration 141200, loss = 3.43027
I0826 13:05:39.808939  1343 solver.cpp:244]     Train net output #0: loss = 3.43027 (* 1 = 3.43027 loss)
I0826 13:05:39.808944  1343 sgd_solver.cpp:106] Iteration 141200, lr = 2.09049e-07
I0826 13:05:48.214432  1343 solver.cpp:228] Iteration 141300, loss = 3.29762
I0826 13:05:48.214488  1343 solver.cpp:244]     Train net output #0: loss = 3.29762 (* 1 = 3.29762 loss)
I0826 13:05:48.214494  1343 sgd_solver.cpp:106] Iteration 141300, lr = 2.08952e-07
I0826 13:05:56.641857  1343 solver.cpp:228] Iteration 141400, loss = 3.44669
I0826 13:05:56.641898  1343 solver.cpp:244]     Train net output #0: loss = 3.44669 (* 1 = 3.44669 loss)
I0826 13:05:56.641904  1343 sgd_solver.cpp:106] Iteration 141400, lr = 2.08855e-07
I0826 13:06:05.060793  1343 solver.cpp:228] Iteration 141500, loss = 3.39896
I0826 13:06:05.060853  1343 solver.cpp:244]     Train net output #0: loss = 3.39896 (* 1 = 3.39896 loss)
I0826 13:06:05.060864  1343 sgd_solver.cpp:106] Iteration 141500, lr = 2.08758e-07
I0826 13:06:13.474609  1343 solver.cpp:228] Iteration 141600, loss = 3.34329
I0826 13:06:13.474652  1343 solver.cpp:244]     Train net output #0: loss = 3.34329 (* 1 = 3.34329 loss)
I0826 13:06:13.474658  1343 sgd_solver.cpp:106] Iteration 141600, lr = 2.08661e-07
I0826 13:06:21.897717  1343 solver.cpp:228] Iteration 141700, loss = 3.51864
I0826 13:06:21.897780  1343 solver.cpp:244]     Train net output #0: loss = 3.51864 (* 1 = 3.51864 loss)
I0826 13:06:21.897789  1343 sgd_solver.cpp:106] Iteration 141700, lr = 2.08564e-07
I0826 13:06:30.317649  1343 solver.cpp:228] Iteration 141800, loss = 3.5372
I0826 13:06:30.317718  1343 solver.cpp:244]     Train net output #0: loss = 3.5372 (* 1 = 3.5372 loss)
I0826 13:06:30.317725  1343 sgd_solver.cpp:106] Iteration 141800, lr = 2.08468e-07
I0826 13:06:38.739698  1343 solver.cpp:228] Iteration 141900, loss = 3.52469
I0826 13:06:38.739759  1343 solver.cpp:244]     Train net output #0: loss = 3.52469 (* 1 = 3.52469 loss)
I0826 13:06:38.739766  1343 sgd_solver.cpp:106] Iteration 141900, lr = 2.08371e-07
I0826 13:06:47.148932  1343 solver.cpp:228] Iteration 142000, loss = 3.4727
I0826 13:06:47.148978  1343 solver.cpp:244]     Train net output #0: loss = 3.4727 (* 1 = 3.4727 loss)
I0826 13:06:47.148988  1343 sgd_solver.cpp:106] Iteration 142000, lr = 2.08275e-07
I0826 13:06:55.569034  1343 solver.cpp:228] Iteration 142100, loss = 3.31019
I0826 13:06:55.569108  1343 solver.cpp:244]     Train net output #0: loss = 3.31019 (* 1 = 3.31019 loss)
I0826 13:06:55.569116  1343 sgd_solver.cpp:106] Iteration 142100, lr = 2.08178e-07
I0826 13:07:04.009497  1343 solver.cpp:228] Iteration 142200, loss = 3.4403
I0826 13:07:04.009553  1343 solver.cpp:244]     Train net output #0: loss = 3.4403 (* 1 = 3.4403 loss)
I0826 13:07:04.009565  1343 sgd_solver.cpp:106] Iteration 142200, lr = 2.08082e-07
I0826 13:07:12.408824  1343 solver.cpp:228] Iteration 142300, loss = 3.41834
I0826 13:07:12.408865  1343 solver.cpp:244]     Train net output #0: loss = 3.41834 (* 1 = 3.41834 loss)
I0826 13:07:12.408870  1343 sgd_solver.cpp:106] Iteration 142300, lr = 2.07986e-07
I0826 13:07:20.827607  1343 solver.cpp:228] Iteration 142400, loss = 3.24217
I0826 13:07:20.827667  1343 solver.cpp:244]     Train net output #0: loss = 3.24217 (* 1 = 3.24217 loss)
I0826 13:07:20.827677  1343 sgd_solver.cpp:106] Iteration 142400, lr = 2.0789e-07
I0826 13:07:29.265053  1343 solver.cpp:228] Iteration 142500, loss = 3.63263
I0826 13:07:29.265106  1343 solver.cpp:244]     Train net output #0: loss = 3.63263 (* 1 = 3.63263 loss)
I0826 13:07:29.265113  1343 sgd_solver.cpp:106] Iteration 142500, lr = 2.07794e-07
I0826 13:07:37.683197  1343 solver.cpp:228] Iteration 142600, loss = 3.54044
I0826 13:07:37.683257  1343 solver.cpp:244]     Train net output #0: loss = 3.54044 (* 1 = 3.54044 loss)
I0826 13:07:37.683270  1343 sgd_solver.cpp:106] Iteration 142600, lr = 2.07698e-07
I0826 13:07:46.099328  1343 solver.cpp:228] Iteration 142700, loss = 3.36801
I0826 13:07:46.099381  1343 solver.cpp:244]     Train net output #0: loss = 3.36801 (* 1 = 3.36801 loss)
I0826 13:07:46.099391  1343 sgd_solver.cpp:106] Iteration 142700, lr = 2.07602e-07
I0826 13:07:54.503141  1343 solver.cpp:228] Iteration 142800, loss = 3.35621
I0826 13:07:54.503185  1343 solver.cpp:244]     Train net output #0: loss = 3.35621 (* 1 = 3.35621 loss)
I0826 13:07:54.503190  1343 sgd_solver.cpp:106] Iteration 142800, lr = 2.07507e-07
I0826 13:08:02.920689  1343 solver.cpp:228] Iteration 142900, loss = 3.47075
I0826 13:08:02.920753  1343 solver.cpp:244]     Train net output #0: loss = 3.47075 (* 1 = 3.47075 loss)
I0826 13:08:02.920761  1343 sgd_solver.cpp:106] Iteration 142900, lr = 2.07411e-07
I0826 13:08:11.334377  1343 solver.cpp:228] Iteration 143000, loss = 3.43997
I0826 13:08:11.334416  1343 solver.cpp:244]     Train net output #0: loss = 3.43997 (* 1 = 3.43997 loss)
I0826 13:08:11.334421  1343 sgd_solver.cpp:106] Iteration 143000, lr = 2.07316e-07
I0826 13:08:19.741928  1343 solver.cpp:228] Iteration 143100, loss = 3.40613
I0826 13:08:19.741969  1343 solver.cpp:244]     Train net output #0: loss = 3.40613 (* 1 = 3.40613 loss)
I0826 13:08:19.741974  1343 sgd_solver.cpp:106] Iteration 143100, lr = 2.0722e-07
I0826 13:08:28.164293  1343 solver.cpp:228] Iteration 143200, loss = 3.31387
I0826 13:08:28.164360  1343 solver.cpp:244]     Train net output #0: loss = 3.31387 (* 1 = 3.31387 loss)
I0826 13:08:28.164369  1343 sgd_solver.cpp:106] Iteration 143200, lr = 2.07125e-07
I0826 13:08:36.601920  1343 solver.cpp:228] Iteration 143300, loss = 3.48304
I0826 13:08:36.601963  1343 solver.cpp:244]     Train net output #0: loss = 3.48304 (* 1 = 3.48304 loss)
I0826 13:08:36.601969  1343 sgd_solver.cpp:106] Iteration 143300, lr = 2.0703e-07
I0826 13:08:45.005995  1343 solver.cpp:228] Iteration 143400, loss = 3.28765
I0826 13:08:45.006052  1343 solver.cpp:244]     Train net output #0: loss = 3.28765 (* 1 = 3.28765 loss)
I0826 13:08:45.006059  1343 sgd_solver.cpp:106] Iteration 143400, lr = 2.06935e-07
I0826 13:08:53.412904  1343 solver.cpp:228] Iteration 143500, loss = 3.53652
I0826 13:08:53.412967  1343 solver.cpp:244]     Train net output #0: loss = 3.53652 (* 1 = 3.53652 loss)
I0826 13:08:53.412981  1343 sgd_solver.cpp:106] Iteration 143500, lr = 2.0684e-07
I0826 13:09:01.827158  1343 solver.cpp:228] Iteration 143600, loss = 3.26812
I0826 13:09:01.827196  1343 solver.cpp:244]     Train net output #0: loss = 3.26812 (* 1 = 3.26812 loss)
I0826 13:09:01.827203  1343 sgd_solver.cpp:106] Iteration 143600, lr = 2.06745e-07
I0826 13:09:10.242012  1343 solver.cpp:228] Iteration 143700, loss = 3.47584
I0826 13:09:10.242053  1343 solver.cpp:244]     Train net output #0: loss = 3.47584 (* 1 = 3.47584 loss)
I0826 13:09:10.242058  1343 sgd_solver.cpp:106] Iteration 143700, lr = 2.0665e-07
I0826 13:09:18.664430  1343 solver.cpp:228] Iteration 143800, loss = 3.50591
I0826 13:09:18.664499  1343 solver.cpp:244]     Train net output #0: loss = 3.50591 (* 1 = 3.50591 loss)
I0826 13:09:18.664510  1343 sgd_solver.cpp:106] Iteration 143800, lr = 2.06556e-07
I0826 13:09:27.092007  1343 solver.cpp:228] Iteration 143900, loss = 3.53086
I0826 13:09:27.092068  1343 solver.cpp:244]     Train net output #0: loss = 3.53086 (* 1 = 3.53086 loss)
I0826 13:09:27.092077  1343 sgd_solver.cpp:106] Iteration 143900, lr = 2.06461e-07
I0826 13:09:35.505705  1343 solver.cpp:228] Iteration 144000, loss = 3.41655
I0826 13:09:35.505764  1343 solver.cpp:244]     Train net output #0: loss = 3.41655 (* 1 = 3.41655 loss)
I0826 13:09:35.505771  1343 sgd_solver.cpp:106] Iteration 144000, lr = 2.06367e-07
I0826 13:09:43.919739  1343 solver.cpp:228] Iteration 144100, loss = 3.56227
I0826 13:09:43.919781  1343 solver.cpp:244]     Train net output #0: loss = 3.56227 (* 1 = 3.56227 loss)
I0826 13:09:43.919788  1343 sgd_solver.cpp:106] Iteration 144100, lr = 2.06272e-07
I0826 13:09:52.336024  1343 solver.cpp:228] Iteration 144200, loss = 3.51115
I0826 13:09:52.336066  1343 solver.cpp:244]     Train net output #0: loss = 3.51115 (* 1 = 3.51115 loss)
I0826 13:09:52.336071  1343 sgd_solver.cpp:106] Iteration 144200, lr = 2.06178e-07
I0826 13:10:00.765017  1343 solver.cpp:228] Iteration 144300, loss = 3.45985
I0826 13:10:00.765070  1343 solver.cpp:244]     Train net output #0: loss = 3.45985 (* 1 = 3.45985 loss)
I0826 13:10:00.765077  1343 sgd_solver.cpp:106] Iteration 144300, lr = 2.06084e-07
I0826 13:10:09.196188  1343 solver.cpp:228] Iteration 144400, loss = 3.37406
I0826 13:10:09.196265  1343 solver.cpp:244]     Train net output #0: loss = 3.37406 (* 1 = 3.37406 loss)
I0826 13:10:09.196280  1343 sgd_solver.cpp:106] Iteration 144400, lr = 2.0599e-07
I0826 13:10:15.327882  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:10:17.591667  1343 solver.cpp:228] Iteration 144500, loss = 3.49372
I0826 13:10:17.591719  1343 solver.cpp:244]     Train net output #0: loss = 3.49372 (* 1 = 3.49372 loss)
I0826 13:10:17.591727  1343 sgd_solver.cpp:106] Iteration 144500, lr = 2.05896e-07
I0826 13:10:26.009716  1343 solver.cpp:228] Iteration 144600, loss = 3.54259
I0826 13:10:26.009768  1343 solver.cpp:244]     Train net output #0: loss = 3.54259 (* 1 = 3.54259 loss)
I0826 13:10:26.009775  1343 sgd_solver.cpp:106] Iteration 144600, lr = 2.05802e-07
I0826 13:10:34.430137  1343 solver.cpp:228] Iteration 144700, loss = 3.30268
I0826 13:10:34.430197  1343 solver.cpp:244]     Train net output #0: loss = 3.30268 (* 1 = 3.30268 loss)
I0826 13:10:34.430205  1343 sgd_solver.cpp:106] Iteration 144700, lr = 2.05709e-07
I0826 13:10:42.834695  1343 solver.cpp:228] Iteration 144800, loss = 3.55074
I0826 13:10:42.834769  1343 solver.cpp:244]     Train net output #0: loss = 3.55074 (* 1 = 3.55074 loss)
I0826 13:10:42.834781  1343 sgd_solver.cpp:106] Iteration 144800, lr = 2.05615e-07
I0826 13:10:51.261471  1343 solver.cpp:228] Iteration 144900, loss = 3.3533
I0826 13:10:51.261519  1343 solver.cpp:244]     Train net output #0: loss = 3.3533 (* 1 = 3.3533 loss)
I0826 13:10:51.261528  1343 sgd_solver.cpp:106] Iteration 144900, lr = 2.05521e-07
I0826 13:10:59.606214  1343 solver.cpp:337] Iteration 145000, Testing net (#0)
I0826 13:11:34.268227  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:11:37.972640  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302021
I0826 13:11:37.972684  1343 solver.cpp:404]     Test net output #1: loss = 3.4253 (* 1 = 3.4253 loss)
I0826 13:11:38.001077  1343 solver.cpp:228] Iteration 145000, loss = 3.40837
I0826 13:11:38.001119  1343 solver.cpp:244]     Train net output #0: loss = 3.40837 (* 1 = 3.40837 loss)
I0826 13:11:38.001132  1343 sgd_solver.cpp:106] Iteration 145000, lr = 2.05428e-07
I0826 13:11:46.423493  1343 solver.cpp:228] Iteration 145100, loss = 3.26867
I0826 13:11:46.423578  1343 solver.cpp:244]     Train net output #0: loss = 3.26867 (* 1 = 3.26867 loss)
I0826 13:11:46.423589  1343 sgd_solver.cpp:106] Iteration 145100, lr = 2.05335e-07
I0826 13:11:54.843580  1343 solver.cpp:228] Iteration 145200, loss = 3.4955
I0826 13:11:54.843626  1343 solver.cpp:244]     Train net output #0: loss = 3.4955 (* 1 = 3.4955 loss)
I0826 13:11:54.843632  1343 sgd_solver.cpp:106] Iteration 145200, lr = 2.05241e-07
I0826 13:12:03.256355  1343 solver.cpp:228] Iteration 145300, loss = 3.48588
I0826 13:12:03.256409  1343 solver.cpp:244]     Train net output #0: loss = 3.48588 (* 1 = 3.48588 loss)
I0826 13:12:03.256422  1343 sgd_solver.cpp:106] Iteration 145300, lr = 2.05148e-07
I0826 13:12:11.677865  1343 solver.cpp:228] Iteration 145400, loss = 3.51329
I0826 13:12:11.677930  1343 solver.cpp:244]     Train net output #0: loss = 3.51329 (* 1 = 3.51329 loss)
I0826 13:12:11.677942  1343 sgd_solver.cpp:106] Iteration 145400, lr = 2.05055e-07
I0826 13:12:20.102674  1343 solver.cpp:228] Iteration 145500, loss = 3.44756
I0826 13:12:20.102733  1343 solver.cpp:244]     Train net output #0: loss = 3.44756 (* 1 = 3.44756 loss)
I0826 13:12:20.102741  1343 sgd_solver.cpp:106] Iteration 145500, lr = 2.04962e-07
I0826 13:12:28.526202  1343 solver.cpp:228] Iteration 145600, loss = 3.35028
I0826 13:12:28.526265  1343 solver.cpp:244]     Train net output #0: loss = 3.35028 (* 1 = 3.35028 loss)
I0826 13:12:28.526274  1343 sgd_solver.cpp:106] Iteration 145600, lr = 2.04869e-07
I0826 13:12:36.928747  1343 solver.cpp:228] Iteration 145700, loss = 3.24849
I0826 13:12:36.928792  1343 solver.cpp:244]     Train net output #0: loss = 3.24849 (* 1 = 3.24849 loss)
I0826 13:12:36.928798  1343 sgd_solver.cpp:106] Iteration 145700, lr = 2.04777e-07
I0826 13:12:45.347226  1343 solver.cpp:228] Iteration 145800, loss = 3.55371
I0826 13:12:45.347290  1343 solver.cpp:244]     Train net output #0: loss = 3.55371 (* 1 = 3.55371 loss)
I0826 13:12:45.347301  1343 sgd_solver.cpp:106] Iteration 145800, lr = 2.04684e-07
I0826 13:12:53.776952  1343 solver.cpp:228] Iteration 145900, loss = 3.37444
I0826 13:12:53.777009  1343 solver.cpp:244]     Train net output #0: loss = 3.37444 (* 1 = 3.37444 loss)
I0826 13:12:53.777019  1343 sgd_solver.cpp:106] Iteration 145900, lr = 2.04592e-07
I0826 13:13:02.202687  1343 solver.cpp:228] Iteration 146000, loss = 3.49186
I0826 13:13:02.202759  1343 solver.cpp:244]     Train net output #0: loss = 3.49186 (* 1 = 3.49186 loss)
I0826 13:13:02.202774  1343 sgd_solver.cpp:106] Iteration 146000, lr = 2.04499e-07
I0826 13:13:10.597954  1343 solver.cpp:228] Iteration 146100, loss = 3.43458
I0826 13:13:10.598019  1343 solver.cpp:244]     Train net output #0: loss = 3.43458 (* 1 = 3.43458 loss)
I0826 13:13:10.598028  1343 sgd_solver.cpp:106] Iteration 146100, lr = 2.04407e-07
I0826 13:13:19.019433  1343 solver.cpp:228] Iteration 146200, loss = 3.423
I0826 13:13:19.019490  1343 solver.cpp:244]     Train net output #0: loss = 3.423 (* 1 = 3.423 loss)
I0826 13:13:19.019500  1343 sgd_solver.cpp:106] Iteration 146200, lr = 2.04315e-07
I0826 13:13:27.446904  1343 solver.cpp:228] Iteration 146300, loss = 3.62669
I0826 13:13:27.446960  1343 solver.cpp:244]     Train net output #0: loss = 3.62669 (* 1 = 3.62669 loss)
I0826 13:13:27.446974  1343 sgd_solver.cpp:106] Iteration 146300, lr = 2.04222e-07
I0826 13:13:35.868994  1343 solver.cpp:228] Iteration 146400, loss = 3.50856
I0826 13:13:35.869048  1343 solver.cpp:244]     Train net output #0: loss = 3.50856 (* 1 = 3.50856 loss)
I0826 13:13:35.869055  1343 sgd_solver.cpp:106] Iteration 146400, lr = 2.0413e-07
I0826 13:13:44.309384  1343 solver.cpp:228] Iteration 146500, loss = 3.52545
I0826 13:13:44.309429  1343 solver.cpp:244]     Train net output #0: loss = 3.52545 (* 1 = 3.52545 loss)
I0826 13:13:44.309434  1343 sgd_solver.cpp:106] Iteration 146500, lr = 2.04038e-07
I0826 13:13:52.710512  1343 solver.cpp:228] Iteration 146600, loss = 3.44543
I0826 13:13:52.710568  1343 solver.cpp:244]     Train net output #0: loss = 3.44543 (* 1 = 3.44543 loss)
I0826 13:13:52.710579  1343 sgd_solver.cpp:106] Iteration 146600, lr = 2.03946e-07
I0826 13:14:01.133152  1343 solver.cpp:228] Iteration 146700, loss = 3.43725
I0826 13:14:01.133210  1343 solver.cpp:244]     Train net output #0: loss = 3.43725 (* 1 = 3.43725 loss)
I0826 13:14:01.133219  1343 sgd_solver.cpp:106] Iteration 146700, lr = 2.03855e-07
I0826 13:14:09.548426  1343 solver.cpp:228] Iteration 146800, loss = 3.24022
I0826 13:14:09.548494  1343 solver.cpp:244]     Train net output #0: loss = 3.24022 (* 1 = 3.24022 loss)
I0826 13:14:09.548509  1343 sgd_solver.cpp:106] Iteration 146800, lr = 2.03763e-07
I0826 13:14:17.974230  1343 solver.cpp:228] Iteration 146900, loss = 3.42615
I0826 13:14:17.974293  1343 solver.cpp:244]     Train net output #0: loss = 3.42615 (* 1 = 3.42615 loss)
I0826 13:14:17.974304  1343 sgd_solver.cpp:106] Iteration 146900, lr = 2.03672e-07
I0826 13:14:26.397416  1343 solver.cpp:228] Iteration 147000, loss = 3.34787
I0826 13:14:26.397464  1343 solver.cpp:244]     Train net output #0: loss = 3.34787 (* 1 = 3.34787 loss)
I0826 13:14:26.397470  1343 sgd_solver.cpp:106] Iteration 147000, lr = 2.0358e-07
I0826 13:14:34.819797  1343 solver.cpp:228] Iteration 147100, loss = 3.38177
I0826 13:14:34.819854  1343 solver.cpp:244]     Train net output #0: loss = 3.38177 (* 1 = 3.38177 loss)
I0826 13:14:34.819859  1343 sgd_solver.cpp:106] Iteration 147100, lr = 2.03489e-07
I0826 13:14:43.235733  1343 solver.cpp:228] Iteration 147200, loss = 3.42333
I0826 13:14:43.235800  1343 solver.cpp:244]     Train net output #0: loss = 3.42333 (* 1 = 3.42333 loss)
I0826 13:14:43.235811  1343 sgd_solver.cpp:106] Iteration 147200, lr = 2.03397e-07
I0826 13:14:51.642537  1343 solver.cpp:228] Iteration 147300, loss = 3.28532
I0826 13:14:51.642606  1343 solver.cpp:244]     Train net output #0: loss = 3.28532 (* 1 = 3.28532 loss)
I0826 13:14:51.642614  1343 sgd_solver.cpp:106] Iteration 147300, lr = 2.03306e-07
I0826 13:15:00.061945  1343 solver.cpp:228] Iteration 147400, loss = 3.40549
I0826 13:15:00.062026  1343 solver.cpp:244]     Train net output #0: loss = 3.40549 (* 1 = 3.40549 loss)
I0826 13:15:00.062041  1343 sgd_solver.cpp:106] Iteration 147400, lr = 2.03215e-07
I0826 13:15:08.491855  1343 solver.cpp:228] Iteration 147500, loss = 3.33688
I0826 13:15:08.491911  1343 solver.cpp:244]     Train net output #0: loss = 3.33688 (* 1 = 3.33688 loss)
I0826 13:15:08.491919  1343 sgd_solver.cpp:106] Iteration 147500, lr = 2.03124e-07
I0826 13:15:16.918637  1343 solver.cpp:228] Iteration 147600, loss = 3.36048
I0826 13:15:16.918696  1343 solver.cpp:244]     Train net output #0: loss = 3.36048 (* 1 = 3.36048 loss)
I0826 13:15:16.918714  1343 sgd_solver.cpp:106] Iteration 147600, lr = 2.03033e-07
I0826 13:15:25.330270  1343 solver.cpp:228] Iteration 147700, loss = 3.35404
I0826 13:15:25.330335  1343 solver.cpp:244]     Train net output #0: loss = 3.35404 (* 1 = 3.35404 loss)
I0826 13:15:25.330348  1343 sgd_solver.cpp:106] Iteration 147700, lr = 2.02942e-07
I0826 13:15:33.750418  1343 solver.cpp:228] Iteration 147800, loss = 3.43512
I0826 13:15:33.750494  1343 solver.cpp:244]     Train net output #0: loss = 3.43512 (* 1 = 3.43512 loss)
I0826 13:15:33.750505  1343 sgd_solver.cpp:106] Iteration 147800, lr = 2.02852e-07
I0826 13:15:42.189913  1343 solver.cpp:228] Iteration 147900, loss = 3.29393
I0826 13:15:42.189973  1343 solver.cpp:244]     Train net output #0: loss = 3.29393 (* 1 = 3.29393 loss)
I0826 13:15:42.189985  1343 sgd_solver.cpp:106] Iteration 147900, lr = 2.02761e-07
I0826 13:15:50.623989  1343 solver.cpp:228] Iteration 148000, loss = 3.47082
I0826 13:15:50.624045  1343 solver.cpp:244]     Train net output #0: loss = 3.47082 (* 1 = 3.47082 loss)
I0826 13:15:50.624054  1343 sgd_solver.cpp:106] Iteration 148000, lr = 2.02671e-07
I0826 13:15:59.055420  1343 solver.cpp:228] Iteration 148100, loss = 3.5231
I0826 13:15:59.055485  1343 solver.cpp:244]     Train net output #0: loss = 3.5231 (* 1 = 3.5231 loss)
I0826 13:15:59.055496  1343 sgd_solver.cpp:106] Iteration 148100, lr = 2.0258e-07
I0826 13:16:07.469163  1343 solver.cpp:228] Iteration 148200, loss = 3.49732
I0826 13:16:07.469225  1343 solver.cpp:244]     Train net output #0: loss = 3.49732 (* 1 = 3.49732 loss)
I0826 13:16:07.469235  1343 sgd_solver.cpp:106] Iteration 148200, lr = 2.0249e-07
I0826 13:16:15.891116  1343 solver.cpp:228] Iteration 148300, loss = 3.46437
I0826 13:16:15.891165  1343 solver.cpp:244]     Train net output #0: loss = 3.46437 (* 1 = 3.46437 loss)
I0826 13:16:15.891171  1343 sgd_solver.cpp:106] Iteration 148300, lr = 2.02399e-07
I0826 13:16:18.752598  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:16:24.320663  1343 solver.cpp:228] Iteration 148400, loss = 3.44966
I0826 13:16:24.320722  1343 solver.cpp:244]     Train net output #0: loss = 3.44966 (* 1 = 3.44966 loss)
I0826 13:16:24.320736  1343 sgd_solver.cpp:106] Iteration 148400, lr = 2.02309e-07
I0826 13:16:32.753965  1343 solver.cpp:228] Iteration 148500, loss = 3.43633
I0826 13:16:32.754037  1343 solver.cpp:244]     Train net output #0: loss = 3.43633 (* 1 = 3.43633 loss)
I0826 13:16:32.754048  1343 sgd_solver.cpp:106] Iteration 148500, lr = 2.02219e-07
I0826 13:16:41.185550  1343 solver.cpp:228] Iteration 148600, loss = 3.39626
I0826 13:16:41.185602  1343 solver.cpp:244]     Train net output #0: loss = 3.39626 (* 1 = 3.39626 loss)
I0826 13:16:41.185607  1343 sgd_solver.cpp:106] Iteration 148600, lr = 2.02129e-07
I0826 13:16:49.583554  1343 solver.cpp:228] Iteration 148700, loss = 3.66126
I0826 13:16:49.583623  1343 solver.cpp:244]     Train net output #0: loss = 3.66126 (* 1 = 3.66126 loss)
I0826 13:16:49.583638  1343 sgd_solver.cpp:106] Iteration 148700, lr = 2.02039e-07
I0826 13:16:58.009058  1343 solver.cpp:228] Iteration 148800, loss = 3.36525
I0826 13:16:58.009119  1343 solver.cpp:244]     Train net output #0: loss = 3.36525 (* 1 = 3.36525 loss)
I0826 13:16:58.009129  1343 sgd_solver.cpp:106] Iteration 148800, lr = 2.0195e-07
I0826 13:17:06.443732  1343 solver.cpp:228] Iteration 148900, loss = 3.3887
I0826 13:17:06.443809  1343 solver.cpp:244]     Train net output #0: loss = 3.3887 (* 1 = 3.3887 loss)
I0826 13:17:06.443817  1343 sgd_solver.cpp:106] Iteration 148900, lr = 2.0186e-07
I0826 13:17:14.862463  1343 solver.cpp:228] Iteration 149000, loss = 3.40036
I0826 13:17:14.862524  1343 solver.cpp:244]     Train net output #0: loss = 3.40036 (* 1 = 3.40036 loss)
I0826 13:17:14.862534  1343 sgd_solver.cpp:106] Iteration 149000, lr = 2.0177e-07
I0826 13:17:23.279075  1343 solver.cpp:228] Iteration 149100, loss = 3.46038
I0826 13:17:23.279139  1343 solver.cpp:244]     Train net output #0: loss = 3.46038 (* 1 = 3.46038 loss)
I0826 13:17:23.279150  1343 sgd_solver.cpp:106] Iteration 149100, lr = 2.01681e-07
I0826 13:17:31.698556  1343 solver.cpp:228] Iteration 149200, loss = 3.52176
I0826 13:17:31.698614  1343 solver.cpp:244]     Train net output #0: loss = 3.52176 (* 1 = 3.52176 loss)
I0826 13:17:31.698622  1343 sgd_solver.cpp:106] Iteration 149200, lr = 2.01592e-07
I0826 13:17:40.132053  1343 solver.cpp:228] Iteration 149300, loss = 3.33246
I0826 13:17:40.132109  1343 solver.cpp:244]     Train net output #0: loss = 3.33246 (* 1 = 3.33246 loss)
I0826 13:17:40.132117  1343 sgd_solver.cpp:106] Iteration 149300, lr = 2.01502e-07
I0826 13:17:48.554317  1343 solver.cpp:228] Iteration 149400, loss = 3.42851
I0826 13:17:48.554373  1343 solver.cpp:244]     Train net output #0: loss = 3.42851 (* 1 = 3.42851 loss)
I0826 13:17:48.554378  1343 sgd_solver.cpp:106] Iteration 149400, lr = 2.01413e-07
I0826 13:17:56.976819  1343 solver.cpp:228] Iteration 149500, loss = 3.32352
I0826 13:17:56.976879  1343 solver.cpp:244]     Train net output #0: loss = 3.32352 (* 1 = 3.32352 loss)
I0826 13:17:56.976889  1343 sgd_solver.cpp:106] Iteration 149500, lr = 2.01324e-07
I0826 13:18:05.400439  1343 solver.cpp:228] Iteration 149600, loss = 3.45047
I0826 13:18:05.400491  1343 solver.cpp:244]     Train net output #0: loss = 3.45047 (* 1 = 3.45047 loss)
I0826 13:18:05.400499  1343 sgd_solver.cpp:106] Iteration 149600, lr = 2.01235e-07
I0826 13:18:13.817523  1343 solver.cpp:228] Iteration 149700, loss = 3.377
I0826 13:18:13.817591  1343 solver.cpp:244]     Train net output #0: loss = 3.377 (* 1 = 3.377 loss)
I0826 13:18:13.817603  1343 sgd_solver.cpp:106] Iteration 149700, lr = 2.01146e-07
I0826 13:18:22.241010  1343 solver.cpp:228] Iteration 149800, loss = 3.45402
I0826 13:18:22.241077  1343 solver.cpp:244]     Train net output #0: loss = 3.45402 (* 1 = 3.45402 loss)
I0826 13:18:22.241087  1343 sgd_solver.cpp:106] Iteration 149800, lr = 2.01057e-07
I0826 13:18:30.676185  1343 solver.cpp:228] Iteration 149900, loss = 3.45088
I0826 13:18:30.676244  1343 solver.cpp:244]     Train net output #0: loss = 3.45088 (* 1 = 3.45088 loss)
I0826 13:18:30.676250  1343 sgd_solver.cpp:106] Iteration 149900, lr = 2.00968e-07
I0826 13:18:39.027742  1343 solver.cpp:337] Iteration 150000, Testing net (#0)
I0826 13:19:03.855952  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:19:16.717453  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 13:19:16.717527  1343 solver.cpp:404]     Test net output #1: loss = 3.4238 (* 1 = 3.4238 loss)
I0826 13:19:16.748088  1343 solver.cpp:228] Iteration 150000, loss = 3.42675
I0826 13:19:16.748136  1343 solver.cpp:244]     Train net output #0: loss = 3.42675 (* 1 = 3.42675 loss)
I0826 13:19:16.748167  1343 sgd_solver.cpp:106] Iteration 150000, lr = 2.0088e-07
I0826 13:19:25.185555  1343 solver.cpp:228] Iteration 150100, loss = 3.46272
I0826 13:19:25.185628  1343 solver.cpp:244]     Train net output #0: loss = 3.46272 (* 1 = 3.46272 loss)
I0826 13:19:25.185639  1343 sgd_solver.cpp:106] Iteration 150100, lr = 2.00791e-07
I0826 13:19:33.619179  1343 solver.cpp:228] Iteration 150200, loss = 3.3604
I0826 13:19:33.619248  1343 solver.cpp:244]     Train net output #0: loss = 3.3604 (* 1 = 3.3604 loss)
I0826 13:19:33.619257  1343 sgd_solver.cpp:106] Iteration 150200, lr = 2.00703e-07
I0826 13:19:42.054580  1343 solver.cpp:228] Iteration 150300, loss = 3.35243
I0826 13:19:42.054625  1343 solver.cpp:244]     Train net output #0: loss = 3.35243 (* 1 = 3.35243 loss)
I0826 13:19:42.054630  1343 sgd_solver.cpp:106] Iteration 150300, lr = 2.00614e-07
I0826 13:19:50.492831  1343 solver.cpp:228] Iteration 150400, loss = 3.29151
I0826 13:19:50.492892  1343 solver.cpp:244]     Train net output #0: loss = 3.29151 (* 1 = 3.29151 loss)
I0826 13:19:50.492900  1343 sgd_solver.cpp:106] Iteration 150400, lr = 2.00526e-07
I0826 13:19:58.924871  1343 solver.cpp:228] Iteration 150500, loss = 3.50864
I0826 13:19:58.924918  1343 solver.cpp:244]     Train net output #0: loss = 3.50864 (* 1 = 3.50864 loss)
I0826 13:19:58.924924  1343 sgd_solver.cpp:106] Iteration 150500, lr = 2.00438e-07
I0826 13:20:07.336148  1343 solver.cpp:228] Iteration 150600, loss = 3.42969
I0826 13:20:07.336186  1343 solver.cpp:244]     Train net output #0: loss = 3.42969 (* 1 = 3.42969 loss)
I0826 13:20:07.336192  1343 sgd_solver.cpp:106] Iteration 150600, lr = 2.00349e-07
I0826 13:20:15.753782  1343 solver.cpp:228] Iteration 150700, loss = 3.31894
I0826 13:20:15.753823  1343 solver.cpp:244]     Train net output #0: loss = 3.31894 (* 1 = 3.31894 loss)
I0826 13:20:15.753829  1343 sgd_solver.cpp:106] Iteration 150700, lr = 2.00261e-07
I0826 13:20:24.186719  1343 solver.cpp:228] Iteration 150800, loss = 3.3304
I0826 13:20:24.186764  1343 solver.cpp:244]     Train net output #0: loss = 3.3304 (* 1 = 3.3304 loss)
I0826 13:20:24.186770  1343 sgd_solver.cpp:106] Iteration 150800, lr = 2.00174e-07
I0826 13:20:32.627667  1343 solver.cpp:228] Iteration 150900, loss = 3.32509
I0826 13:20:32.627724  1343 solver.cpp:244]     Train net output #0: loss = 3.32509 (* 1 = 3.32509 loss)
I0826 13:20:32.627733  1343 sgd_solver.cpp:106] Iteration 150900, lr = 2.00086e-07
I0826 13:20:41.059254  1343 solver.cpp:228] Iteration 151000, loss = 3.56676
I0826 13:20:41.059312  1343 solver.cpp:244]     Train net output #0: loss = 3.56676 (* 1 = 3.56676 loss)
I0826 13:20:41.059324  1343 sgd_solver.cpp:106] Iteration 151000, lr = 1.99998e-07
I0826 13:20:49.479462  1343 solver.cpp:228] Iteration 151100, loss = 3.37124
I0826 13:20:49.479522  1343 solver.cpp:244]     Train net output #0: loss = 3.37124 (* 1 = 3.37124 loss)
I0826 13:20:49.479532  1343 sgd_solver.cpp:106] Iteration 151100, lr = 1.9991e-07
I0826 13:20:57.919745  1343 solver.cpp:228] Iteration 151200, loss = 3.4933
I0826 13:20:57.919811  1343 solver.cpp:244]     Train net output #0: loss = 3.4933 (* 1 = 3.4933 loss)
I0826 13:20:57.919821  1343 sgd_solver.cpp:106] Iteration 151200, lr = 1.99823e-07
I0826 13:21:06.330849  1343 solver.cpp:228] Iteration 151300, loss = 3.40426
I0826 13:21:06.330911  1343 solver.cpp:244]     Train net output #0: loss = 3.40426 (* 1 = 3.40426 loss)
I0826 13:21:06.330920  1343 sgd_solver.cpp:106] Iteration 151300, lr = 1.99735e-07
I0826 13:21:14.760908  1343 solver.cpp:228] Iteration 151400, loss = 3.38321
I0826 13:21:14.760952  1343 solver.cpp:244]     Train net output #0: loss = 3.38321 (* 1 = 3.38321 loss)
I0826 13:21:14.760958  1343 sgd_solver.cpp:106] Iteration 151400, lr = 1.99648e-07
I0826 13:21:23.188776  1343 solver.cpp:228] Iteration 151500, loss = 3.47854
I0826 13:21:23.188843  1343 solver.cpp:244]     Train net output #0: loss = 3.47854 (* 1 = 3.47854 loss)
I0826 13:21:23.188853  1343 sgd_solver.cpp:106] Iteration 151500, lr = 1.9956e-07
I0826 13:21:31.623792  1343 solver.cpp:228] Iteration 151600, loss = 3.44296
I0826 13:21:31.623863  1343 solver.cpp:244]     Train net output #0: loss = 3.44296 (* 1 = 3.44296 loss)
I0826 13:21:31.623883  1343 sgd_solver.cpp:106] Iteration 151600, lr = 1.99473e-07
I0826 13:21:40.051015  1343 solver.cpp:228] Iteration 151700, loss = 3.43902
I0826 13:21:40.051057  1343 solver.cpp:244]     Train net output #0: loss = 3.43902 (* 1 = 3.43902 loss)
I0826 13:21:40.051064  1343 sgd_solver.cpp:106] Iteration 151700, lr = 1.99386e-07
I0826 13:21:48.467481  1343 solver.cpp:228] Iteration 151800, loss = 3.58323
I0826 13:21:48.467547  1343 solver.cpp:244]     Train net output #0: loss = 3.58323 (* 1 = 3.58323 loss)
I0826 13:21:48.467558  1343 sgd_solver.cpp:106] Iteration 151800, lr = 1.99299e-07
I0826 13:21:56.877526  1343 solver.cpp:228] Iteration 151900, loss = 3.336
I0826 13:21:56.877568  1343 solver.cpp:244]     Train net output #0: loss = 3.336 (* 1 = 3.336 loss)
I0826 13:21:56.877574  1343 sgd_solver.cpp:106] Iteration 151900, lr = 1.99212e-07
I0826 13:22:05.314612  1343 solver.cpp:228] Iteration 152000, loss = 3.36491
I0826 13:22:05.314680  1343 solver.cpp:244]     Train net output #0: loss = 3.36491 (* 1 = 3.36491 loss)
I0826 13:22:05.314688  1343 sgd_solver.cpp:106] Iteration 152000, lr = 1.99125e-07
I0826 13:22:13.733817  1343 solver.cpp:228] Iteration 152100, loss = 3.25406
I0826 13:22:13.733866  1343 solver.cpp:244]     Train net output #0: loss = 3.25406 (* 1 = 3.25406 loss)
I0826 13:22:13.733872  1343 sgd_solver.cpp:106] Iteration 152100, lr = 1.99038e-07
I0826 13:22:22.156762  1343 solver.cpp:228] Iteration 152200, loss = 3.44206
I0826 13:22:22.156810  1343 solver.cpp:244]     Train net output #0: loss = 3.44206 (* 1 = 3.44206 loss)
I0826 13:22:22.156818  1343 sgd_solver.cpp:106] Iteration 152200, lr = 1.98952e-07
I0826 13:22:30.571357  1343 solver.cpp:228] Iteration 152300, loss = 3.31191
I0826 13:22:30.571398  1343 solver.cpp:244]     Train net output #0: loss = 3.31191 (* 1 = 3.31191 loss)
I0826 13:22:30.571404  1343 sgd_solver.cpp:106] Iteration 152300, lr = 1.98865e-07
I0826 13:22:38.989027  1343 solver.cpp:228] Iteration 152400, loss = 3.30966
I0826 13:22:38.989078  1343 solver.cpp:244]     Train net output #0: loss = 3.30966 (* 1 = 3.30966 loss)
I0826 13:22:38.989084  1343 sgd_solver.cpp:106] Iteration 152400, lr = 1.98779e-07
I0826 13:22:47.421695  1343 solver.cpp:228] Iteration 152500, loss = 3.37506
I0826 13:22:47.421737  1343 solver.cpp:244]     Train net output #0: loss = 3.37506 (* 1 = 3.37506 loss)
I0826 13:22:47.421743  1343 sgd_solver.cpp:106] Iteration 152500, lr = 1.98692e-07
I0826 13:22:55.865869  1343 solver.cpp:228] Iteration 152600, loss = 3.30828
I0826 13:22:55.865942  1343 solver.cpp:244]     Train net output #0: loss = 3.30828 (* 1 = 3.30828 loss)
I0826 13:22:55.865958  1343 sgd_solver.cpp:106] Iteration 152600, lr = 1.98606e-07
I0826 13:23:04.283556  1343 solver.cpp:228] Iteration 152700, loss = 3.45607
I0826 13:23:04.283612  1343 solver.cpp:244]     Train net output #0: loss = 3.45607 (* 1 = 3.45607 loss)
I0826 13:23:04.283622  1343 sgd_solver.cpp:106] Iteration 152700, lr = 1.9852e-07
I0826 13:23:12.714058  1343 solver.cpp:228] Iteration 152800, loss = 3.56589
I0826 13:23:12.714121  1343 solver.cpp:244]     Train net output #0: loss = 3.56589 (* 1 = 3.56589 loss)
I0826 13:23:12.714129  1343 sgd_solver.cpp:106] Iteration 152800, lr = 1.98433e-07
I0826 13:23:21.127619  1343 solver.cpp:228] Iteration 152900, loss = 3.40283
I0826 13:23:21.127674  1343 solver.cpp:244]     Train net output #0: loss = 3.40283 (* 1 = 3.40283 loss)
I0826 13:23:21.127681  1343 sgd_solver.cpp:106] Iteration 152900, lr = 1.98347e-07
I0826 13:23:29.548475  1343 solver.cpp:228] Iteration 153000, loss = 3.38689
I0826 13:23:29.548534  1343 solver.cpp:244]     Train net output #0: loss = 3.38689 (* 1 = 3.38689 loss)
I0826 13:23:29.548543  1343 sgd_solver.cpp:106] Iteration 153000, lr = 1.98261e-07
I0826 13:23:37.962805  1343 solver.cpp:228] Iteration 153100, loss = 3.4118
I0826 13:23:37.962842  1343 solver.cpp:244]     Train net output #0: loss = 3.4118 (* 1 = 3.4118 loss)
I0826 13:23:37.962848  1343 sgd_solver.cpp:106] Iteration 153100, lr = 1.98175e-07
I0826 13:23:46.383891  1343 solver.cpp:228] Iteration 153200, loss = 3.55278
I0826 13:23:46.383944  1343 solver.cpp:244]     Train net output #0: loss = 3.55278 (* 1 = 3.55278 loss)
I0826 13:23:46.383950  1343 sgd_solver.cpp:106] Iteration 153200, lr = 1.9809e-07
I0826 13:23:54.801080  1343 solver.cpp:228] Iteration 153300, loss = 3.44833
I0826 13:23:54.801122  1343 solver.cpp:244]     Train net output #0: loss = 3.44833 (* 1 = 3.44833 loss)
I0826 13:23:54.801128  1343 sgd_solver.cpp:106] Iteration 153300, lr = 1.98004e-07
I0826 13:24:03.224298  1343 solver.cpp:228] Iteration 153400, loss = 3.30431
I0826 13:24:03.224354  1343 solver.cpp:244]     Train net output #0: loss = 3.30431 (* 1 = 3.30431 loss)
I0826 13:24:03.224360  1343 sgd_solver.cpp:106] Iteration 153400, lr = 1.97918e-07
I0826 13:24:03.983875  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:24:11.629853  1343 solver.cpp:228] Iteration 153500, loss = 3.39224
I0826 13:24:11.629895  1343 solver.cpp:244]     Train net output #0: loss = 3.39224 (* 1 = 3.39224 loss)
I0826 13:24:11.629901  1343 sgd_solver.cpp:106] Iteration 153500, lr = 1.97833e-07
I0826 13:24:20.070911  1343 solver.cpp:228] Iteration 153600, loss = 3.41097
I0826 13:24:20.070973  1343 solver.cpp:244]     Train net output #0: loss = 3.41097 (* 1 = 3.41097 loss)
I0826 13:24:20.070982  1343 sgd_solver.cpp:106] Iteration 153600, lr = 1.97747e-07
I0826 13:24:28.494158  1343 solver.cpp:228] Iteration 153700, loss = 3.44705
I0826 13:24:28.494223  1343 solver.cpp:244]     Train net output #0: loss = 3.44705 (* 1 = 3.44705 loss)
I0826 13:24:28.494233  1343 sgd_solver.cpp:106] Iteration 153700, lr = 1.97662e-07
I0826 13:24:36.930172  1343 solver.cpp:228] Iteration 153800, loss = 3.44825
I0826 13:24:36.930224  1343 solver.cpp:244]     Train net output #0: loss = 3.44825 (* 1 = 3.44825 loss)
I0826 13:24:36.930233  1343 sgd_solver.cpp:106] Iteration 153800, lr = 1.97576e-07
I0826 13:24:45.348405  1343 solver.cpp:228] Iteration 153900, loss = 3.31086
I0826 13:24:45.348454  1343 solver.cpp:244]     Train net output #0: loss = 3.31086 (* 1 = 3.31086 loss)
I0826 13:24:45.348461  1343 sgd_solver.cpp:106] Iteration 153900, lr = 1.97491e-07
I0826 13:24:53.757731  1343 solver.cpp:228] Iteration 154000, loss = 3.32314
I0826 13:24:53.757784  1343 solver.cpp:244]     Train net output #0: loss = 3.32314 (* 1 = 3.32314 loss)
I0826 13:24:53.757792  1343 sgd_solver.cpp:106] Iteration 154000, lr = 1.97406e-07
I0826 13:25:02.185865  1343 solver.cpp:228] Iteration 154100, loss = 3.52229
I0826 13:25:02.185923  1343 solver.cpp:244]     Train net output #0: loss = 3.52229 (* 1 = 3.52229 loss)
I0826 13:25:02.185931  1343 sgd_solver.cpp:106] Iteration 154100, lr = 1.97321e-07
I0826 13:25:10.610386  1343 solver.cpp:228] Iteration 154200, loss = 3.48253
I0826 13:25:10.610469  1343 solver.cpp:244]     Train net output #0: loss = 3.48253 (* 1 = 3.48253 loss)
I0826 13:25:10.610491  1343 sgd_solver.cpp:106] Iteration 154200, lr = 1.97236e-07
I0826 13:25:19.034353  1343 solver.cpp:228] Iteration 154300, loss = 3.43319
I0826 13:25:19.034415  1343 solver.cpp:244]     Train net output #0: loss = 3.43319 (* 1 = 3.43319 loss)
I0826 13:25:19.034423  1343 sgd_solver.cpp:106] Iteration 154300, lr = 1.97151e-07
I0826 13:25:27.452430  1343 solver.cpp:228] Iteration 154400, loss = 3.49297
I0826 13:25:27.452486  1343 solver.cpp:244]     Train net output #0: loss = 3.49297 (* 1 = 3.49297 loss)
I0826 13:25:27.452494  1343 sgd_solver.cpp:106] Iteration 154400, lr = 1.97066e-07
I0826 13:25:35.875560  1343 solver.cpp:228] Iteration 154500, loss = 3.39879
I0826 13:25:35.875648  1343 solver.cpp:244]     Train net output #0: loss = 3.39879 (* 1 = 3.39879 loss)
I0826 13:25:35.875663  1343 sgd_solver.cpp:106] Iteration 154500, lr = 1.96982e-07
I0826 13:25:44.304105  1343 solver.cpp:228] Iteration 154600, loss = 3.35603
I0826 13:25:44.304147  1343 solver.cpp:244]     Train net output #0: loss = 3.35603 (* 1 = 3.35603 loss)
I0826 13:25:44.304152  1343 sgd_solver.cpp:106] Iteration 154600, lr = 1.96897e-07
I0826 13:25:52.735395  1343 solver.cpp:228] Iteration 154700, loss = 3.63825
I0826 13:25:52.735457  1343 solver.cpp:244]     Train net output #0: loss = 3.63825 (* 1 = 3.63825 loss)
I0826 13:25:52.735466  1343 sgd_solver.cpp:106] Iteration 154700, lr = 1.96813e-07
I0826 13:26:01.161213  1343 solver.cpp:228] Iteration 154800, loss = 3.46591
I0826 13:26:01.161259  1343 solver.cpp:244]     Train net output #0: loss = 3.46591 (* 1 = 3.46591 loss)
I0826 13:26:01.161267  1343 sgd_solver.cpp:106] Iteration 154800, lr = 1.96728e-07
I0826 13:26:09.576635  1343 solver.cpp:228] Iteration 154900, loss = 3.44748
I0826 13:26:09.576701  1343 solver.cpp:244]     Train net output #0: loss = 3.44748 (* 1 = 3.44748 loss)
I0826 13:26:09.576710  1343 sgd_solver.cpp:106] Iteration 154900, lr = 1.96644e-07
I0826 13:26:17.908473  1343 solver.cpp:337] Iteration 155000, Testing net (#0)
I0826 13:26:42.252414  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:26:56.468935  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302038
I0826 13:26:56.468989  1343 solver.cpp:404]     Test net output #1: loss = 3.4225 (* 1 = 3.4225 loss)
I0826 13:26:56.498042  1343 solver.cpp:228] Iteration 155000, loss = 3.35621
I0826 13:26:56.498065  1343 solver.cpp:244]     Train net output #0: loss = 3.35621 (* 1 = 3.35621 loss)
I0826 13:26:56.498076  1343 sgd_solver.cpp:106] Iteration 155000, lr = 1.96559e-07
I0826 13:27:04.930546  1343 solver.cpp:228] Iteration 155100, loss = 3.44235
I0826 13:27:04.930601  1343 solver.cpp:244]     Train net output #0: loss = 3.44235 (* 1 = 3.44235 loss)
I0826 13:27:04.930610  1343 sgd_solver.cpp:106] Iteration 155100, lr = 1.96475e-07
I0826 13:27:13.364092  1343 solver.cpp:228] Iteration 155200, loss = 3.47222
I0826 13:27:13.364145  1343 solver.cpp:244]     Train net output #0: loss = 3.47222 (* 1 = 3.47222 loss)
I0826 13:27:13.364151  1343 sgd_solver.cpp:106] Iteration 155200, lr = 1.96391e-07
I0826 13:27:21.793673  1343 solver.cpp:228] Iteration 155300, loss = 3.39787
I0826 13:27:21.793718  1343 solver.cpp:244]     Train net output #0: loss = 3.39787 (* 1 = 3.39787 loss)
I0826 13:27:21.793725  1343 sgd_solver.cpp:106] Iteration 155300, lr = 1.96307e-07
I0826 13:27:30.194182  1343 solver.cpp:228] Iteration 155400, loss = 3.44722
I0826 13:27:30.194248  1343 solver.cpp:244]     Train net output #0: loss = 3.44722 (* 1 = 3.44722 loss)
I0826 13:27:30.194259  1343 sgd_solver.cpp:106] Iteration 155400, lr = 1.96223e-07
I0826 13:27:38.614472  1343 solver.cpp:228] Iteration 155500, loss = 3.38383
I0826 13:27:38.614523  1343 solver.cpp:244]     Train net output #0: loss = 3.38383 (* 1 = 3.38383 loss)
I0826 13:27:38.614531  1343 sgd_solver.cpp:106] Iteration 155500, lr = 1.96139e-07
I0826 13:27:47.015620  1343 solver.cpp:228] Iteration 155600, loss = 3.49593
I0826 13:27:47.015671  1343 solver.cpp:244]     Train net output #0: loss = 3.49593 (* 1 = 3.49593 loss)
I0826 13:27:47.015679  1343 sgd_solver.cpp:106] Iteration 155600, lr = 1.96056e-07
I0826 13:27:55.433508  1343 solver.cpp:228] Iteration 155700, loss = 3.42434
I0826 13:27:55.433558  1343 solver.cpp:244]     Train net output #0: loss = 3.42434 (* 1 = 3.42434 loss)
I0826 13:27:55.433567  1343 sgd_solver.cpp:106] Iteration 155700, lr = 1.95972e-07
I0826 13:28:03.860859  1343 solver.cpp:228] Iteration 155800, loss = 3.55556
I0826 13:28:03.860903  1343 solver.cpp:244]     Train net output #0: loss = 3.55556 (* 1 = 3.55556 loss)
I0826 13:28:03.860908  1343 sgd_solver.cpp:106] Iteration 155800, lr = 1.95888e-07
I0826 13:28:12.290585  1343 solver.cpp:228] Iteration 155900, loss = 3.29673
I0826 13:28:12.290657  1343 solver.cpp:244]     Train net output #0: loss = 3.29673 (* 1 = 3.29673 loss)
I0826 13:28:12.290668  1343 sgd_solver.cpp:106] Iteration 155900, lr = 1.95805e-07
I0826 13:28:20.723274  1343 solver.cpp:228] Iteration 156000, loss = 3.56589
I0826 13:28:20.723332  1343 solver.cpp:244]     Train net output #0: loss = 3.56589 (* 1 = 3.56589 loss)
I0826 13:28:20.723342  1343 sgd_solver.cpp:106] Iteration 156000, lr = 1.95721e-07
I0826 13:28:29.131964  1343 solver.cpp:228] Iteration 156100, loss = 3.49911
I0826 13:28:29.132020  1343 solver.cpp:244]     Train net output #0: loss = 3.49911 (* 1 = 3.49911 loss)
I0826 13:28:29.132031  1343 sgd_solver.cpp:106] Iteration 156100, lr = 1.95638e-07
I0826 13:28:37.553738  1343 solver.cpp:228] Iteration 156200, loss = 3.37031
I0826 13:28:37.553812  1343 solver.cpp:244]     Train net output #0: loss = 3.37031 (* 1 = 3.37031 loss)
I0826 13:28:37.553822  1343 sgd_solver.cpp:106] Iteration 156200, lr = 1.95555e-07
I0826 13:28:45.976963  1343 solver.cpp:228] Iteration 156300, loss = 3.50032
I0826 13:28:45.977023  1343 solver.cpp:244]     Train net output #0: loss = 3.50032 (* 1 = 3.50032 loss)
I0826 13:28:45.977030  1343 sgd_solver.cpp:106] Iteration 156300, lr = 1.95471e-07
I0826 13:28:54.396409  1343 solver.cpp:228] Iteration 156400, loss = 3.2651
I0826 13:28:54.396467  1343 solver.cpp:244]     Train net output #0: loss = 3.2651 (* 1 = 3.2651 loss)
I0826 13:28:54.396478  1343 sgd_solver.cpp:106] Iteration 156400, lr = 1.95388e-07
I0826 13:29:02.804374  1343 solver.cpp:228] Iteration 156500, loss = 3.457
I0826 13:29:02.804425  1343 solver.cpp:244]     Train net output #0: loss = 3.457 (* 1 = 3.457 loss)
I0826 13:29:02.804432  1343 sgd_solver.cpp:106] Iteration 156500, lr = 1.95305e-07
I0826 13:29:11.239434  1343 solver.cpp:228] Iteration 156600, loss = 3.54039
I0826 13:29:11.239491  1343 solver.cpp:244]     Train net output #0: loss = 3.54039 (* 1 = 3.54039 loss)
I0826 13:29:11.239498  1343 sgd_solver.cpp:106] Iteration 156600, lr = 1.95222e-07
I0826 13:29:19.654799  1343 solver.cpp:228] Iteration 156700, loss = 3.44103
I0826 13:29:19.654863  1343 solver.cpp:244]     Train net output #0: loss = 3.44103 (* 1 = 3.44103 loss)
I0826 13:29:19.654870  1343 sgd_solver.cpp:106] Iteration 156700, lr = 1.95139e-07
I0826 13:29:28.046376  1343 solver.cpp:228] Iteration 156800, loss = 3.51793
I0826 13:29:28.046438  1343 solver.cpp:244]     Train net output #0: loss = 3.51793 (* 1 = 3.51793 loss)
I0826 13:29:28.046447  1343 sgd_solver.cpp:106] Iteration 156800, lr = 1.95057e-07
I0826 13:29:36.468238  1343 solver.cpp:228] Iteration 156900, loss = 3.52419
I0826 13:29:36.468291  1343 solver.cpp:244]     Train net output #0: loss = 3.52419 (* 1 = 3.52419 loss)
I0826 13:29:36.468297  1343 sgd_solver.cpp:106] Iteration 156900, lr = 1.94974e-07
I0826 13:29:44.898383  1343 solver.cpp:228] Iteration 157000, loss = 3.28363
I0826 13:29:44.898425  1343 solver.cpp:244]     Train net output #0: loss = 3.28363 (* 1 = 3.28363 loss)
I0826 13:29:44.898432  1343 sgd_solver.cpp:106] Iteration 157000, lr = 1.94891e-07
I0826 13:29:53.318888  1343 solver.cpp:228] Iteration 157100, loss = 3.53015
I0826 13:29:53.318943  1343 solver.cpp:244]     Train net output #0: loss = 3.53015 (* 1 = 3.53015 loss)
I0826 13:29:53.318953  1343 sgd_solver.cpp:106] Iteration 157100, lr = 1.94809e-07
I0826 13:30:01.758265  1343 solver.cpp:228] Iteration 157200, loss = 3.48452
I0826 13:30:01.758335  1343 solver.cpp:244]     Train net output #0: loss = 3.48452 (* 1 = 3.48452 loss)
I0826 13:30:01.758347  1343 sgd_solver.cpp:106] Iteration 157200, lr = 1.94726e-07
I0826 13:30:10.182366  1343 solver.cpp:228] Iteration 157300, loss = 3.50489
I0826 13:30:10.182432  1343 solver.cpp:244]     Train net output #0: loss = 3.50489 (* 1 = 3.50489 loss)
I0826 13:30:10.182441  1343 sgd_solver.cpp:106] Iteration 157300, lr = 1.94644e-07
I0826 13:30:18.608161  1343 solver.cpp:228] Iteration 157400, loss = 3.36652
I0826 13:30:18.608228  1343 solver.cpp:244]     Train net output #0: loss = 3.36652 (* 1 = 3.36652 loss)
I0826 13:30:18.608235  1343 sgd_solver.cpp:106] Iteration 157400, lr = 1.94562e-07
I0826 13:30:27.035136  1343 solver.cpp:228] Iteration 157500, loss = 3.35518
I0826 13:30:27.035198  1343 solver.cpp:244]     Train net output #0: loss = 3.35518 (* 1 = 3.35518 loss)
I0826 13:30:27.035205  1343 sgd_solver.cpp:106] Iteration 157500, lr = 1.94479e-07
I0826 13:30:33.527487  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:30:35.460713  1343 solver.cpp:228] Iteration 157600, loss = 3.4462
I0826 13:30:35.460763  1343 solver.cpp:244]     Train net output #0: loss = 3.4462 (* 1 = 3.4462 loss)
I0826 13:30:35.460769  1343 sgd_solver.cpp:106] Iteration 157600, lr = 1.94397e-07
I0826 13:30:43.865897  1343 solver.cpp:228] Iteration 157700, loss = 3.42547
I0826 13:30:43.865949  1343 solver.cpp:244]     Train net output #0: loss = 3.42547 (* 1 = 3.42547 loss)
I0826 13:30:43.865957  1343 sgd_solver.cpp:106] Iteration 157700, lr = 1.94315e-07
I0826 13:30:52.294014  1343 solver.cpp:228] Iteration 157800, loss = 3.38265
I0826 13:30:52.294116  1343 solver.cpp:244]     Train net output #0: loss = 3.38265 (* 1 = 3.38265 loss)
I0826 13:30:52.294131  1343 sgd_solver.cpp:106] Iteration 157800, lr = 1.94233e-07
I0826 13:31:00.717722  1343 solver.cpp:228] Iteration 157900, loss = 3.45902
I0826 13:31:00.717782  1343 solver.cpp:244]     Train net output #0: loss = 3.45902 (* 1 = 3.45902 loss)
I0826 13:31:00.717790  1343 sgd_solver.cpp:106] Iteration 157900, lr = 1.94151e-07
I0826 13:31:09.153220  1343 solver.cpp:228] Iteration 158000, loss = 3.46784
I0826 13:31:09.153287  1343 solver.cpp:244]     Train net output #0: loss = 3.46784 (* 1 = 3.46784 loss)
I0826 13:31:09.153296  1343 sgd_solver.cpp:106] Iteration 158000, lr = 1.9407e-07
I0826 13:31:17.568403  1343 solver.cpp:228] Iteration 158100, loss = 3.36483
I0826 13:31:17.568440  1343 solver.cpp:244]     Train net output #0: loss = 3.36483 (* 1 = 3.36483 loss)
I0826 13:31:17.568446  1343 sgd_solver.cpp:106] Iteration 158100, lr = 1.93988e-07
I0826 13:31:25.972534  1343 solver.cpp:228] Iteration 158200, loss = 3.46839
I0826 13:31:25.972594  1343 solver.cpp:244]     Train net output #0: loss = 3.46839 (* 1 = 3.46839 loss)
I0826 13:31:25.972604  1343 sgd_solver.cpp:106] Iteration 158200, lr = 1.93906e-07
I0826 13:31:34.406620  1343 solver.cpp:228] Iteration 158300, loss = 3.32752
I0826 13:31:34.406683  1343 solver.cpp:244]     Train net output #0: loss = 3.32752 (* 1 = 3.32752 loss)
I0826 13:31:34.406697  1343 sgd_solver.cpp:106] Iteration 158300, lr = 1.93825e-07
I0826 13:31:42.828444  1343 solver.cpp:228] Iteration 158400, loss = 3.38984
I0826 13:31:42.828485  1343 solver.cpp:244]     Train net output #0: loss = 3.38984 (* 1 = 3.38984 loss)
I0826 13:31:42.828491  1343 sgd_solver.cpp:106] Iteration 158400, lr = 1.93743e-07
I0826 13:31:51.246948  1343 solver.cpp:228] Iteration 158500, loss = 3.39196
I0826 13:31:51.246994  1343 solver.cpp:244]     Train net output #0: loss = 3.39196 (* 1 = 3.39196 loss)
I0826 13:31:51.247000  1343 sgd_solver.cpp:106] Iteration 158500, lr = 1.93662e-07
I0826 13:31:59.657905  1343 solver.cpp:228] Iteration 158600, loss = 3.45447
I0826 13:31:59.657960  1343 solver.cpp:244]     Train net output #0: loss = 3.45447 (* 1 = 3.45447 loss)
I0826 13:31:59.657968  1343 sgd_solver.cpp:106] Iteration 158600, lr = 1.9358e-07
I0826 13:32:08.084358  1343 solver.cpp:228] Iteration 158700, loss = 3.44561
I0826 13:32:08.084398  1343 solver.cpp:244]     Train net output #0: loss = 3.44561 (* 1 = 3.44561 loss)
I0826 13:32:08.084403  1343 sgd_solver.cpp:106] Iteration 158700, lr = 1.93499e-07
I0826 13:32:16.517868  1343 solver.cpp:228] Iteration 158800, loss = 3.35627
I0826 13:32:16.517922  1343 solver.cpp:244]     Train net output #0: loss = 3.35627 (* 1 = 3.35627 loss)
I0826 13:32:16.517928  1343 sgd_solver.cpp:106] Iteration 158800, lr = 1.93418e-07
I0826 13:32:24.938976  1343 solver.cpp:228] Iteration 158900, loss = 3.27318
I0826 13:32:24.939018  1343 solver.cpp:244]     Train net output #0: loss = 3.27318 (* 1 = 3.27318 loss)
I0826 13:32:24.939023  1343 sgd_solver.cpp:106] Iteration 158900, lr = 1.93337e-07
I0826 13:32:33.355327  1343 solver.cpp:228] Iteration 159000, loss = 3.26894
I0826 13:32:33.355393  1343 solver.cpp:244]     Train net output #0: loss = 3.26894 (* 1 = 3.26894 loss)
I0826 13:32:33.355401  1343 sgd_solver.cpp:106] Iteration 159000, lr = 1.93256e-07
I0826 13:32:41.778864  1343 solver.cpp:228] Iteration 159100, loss = 3.44846
I0826 13:32:41.778923  1343 solver.cpp:244]     Train net output #0: loss = 3.44846 (* 1 = 3.44846 loss)
I0826 13:32:41.778931  1343 sgd_solver.cpp:106] Iteration 159100, lr = 1.93175e-07
I0826 13:32:50.209105  1343 solver.cpp:228] Iteration 159200, loss = 3.3807
I0826 13:32:50.209167  1343 solver.cpp:244]     Train net output #0: loss = 3.3807 (* 1 = 3.3807 loss)
I0826 13:32:50.209173  1343 sgd_solver.cpp:106] Iteration 159200, lr = 1.93094e-07
I0826 13:32:58.637783  1343 solver.cpp:228] Iteration 159300, loss = 3.4523
I0826 13:32:58.637845  1343 solver.cpp:244]     Train net output #0: loss = 3.4523 (* 1 = 3.4523 loss)
I0826 13:32:58.637858  1343 sgd_solver.cpp:106] Iteration 159300, lr = 1.93013e-07
I0826 13:33:07.068503  1343 solver.cpp:228] Iteration 159400, loss = 3.3488
I0826 13:33:07.068558  1343 solver.cpp:244]     Train net output #0: loss = 3.3488 (* 1 = 3.3488 loss)
I0826 13:33:07.068564  1343 sgd_solver.cpp:106] Iteration 159400, lr = 1.92933e-07
I0826 13:33:15.483497  1343 solver.cpp:228] Iteration 159500, loss = 3.37282
I0826 13:33:15.483537  1343 solver.cpp:244]     Train net output #0: loss = 3.37282 (* 1 = 3.37282 loss)
I0826 13:33:15.483542  1343 sgd_solver.cpp:106] Iteration 159500, lr = 1.92852e-07
I0826 13:33:23.893134  1343 solver.cpp:228] Iteration 159600, loss = 3.51605
I0826 13:33:23.893173  1343 solver.cpp:244]     Train net output #0: loss = 3.51605 (* 1 = 3.51605 loss)
I0826 13:33:23.893179  1343 sgd_solver.cpp:106] Iteration 159600, lr = 1.92771e-07
I0826 13:33:32.315927  1343 solver.cpp:228] Iteration 159700, loss = 3.32744
I0826 13:33:32.315989  1343 solver.cpp:244]     Train net output #0: loss = 3.32744 (* 1 = 3.32744 loss)
I0826 13:33:32.315999  1343 sgd_solver.cpp:106] Iteration 159700, lr = 1.92691e-07
I0826 13:33:40.739935  1343 solver.cpp:228] Iteration 159800, loss = 3.38185
I0826 13:33:40.739996  1343 solver.cpp:244]     Train net output #0: loss = 3.38185 (* 1 = 3.38185 loss)
I0826 13:33:40.740006  1343 sgd_solver.cpp:106] Iteration 159800, lr = 1.92611e-07
I0826 13:33:49.148023  1343 solver.cpp:228] Iteration 159900, loss = 3.5421
I0826 13:33:49.148066  1343 solver.cpp:244]     Train net output #0: loss = 3.5421 (* 1 = 3.5421 loss)
I0826 13:33:49.148072  1343 sgd_solver.cpp:106] Iteration 159900, lr = 1.9253e-07
I0826 13:33:57.495052  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_160000.caffemodel
I0826 13:33:58.027715  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_160000.solverstate
I0826 13:33:58.188988  1343 solver.cpp:337] Iteration 160000, Testing net (#0)
I0826 13:34:13.845708  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:34:36.226176  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302031
I0826 13:34:36.226235  1343 solver.cpp:404]     Test net output #1: loss = 3.42158 (* 1 = 3.42158 loss)
I0826 13:34:36.255960  1343 solver.cpp:228] Iteration 160000, loss = 3.4659
I0826 13:34:36.256000  1343 solver.cpp:244]     Train net output #0: loss = 3.4659 (* 1 = 3.4659 loss)
I0826 13:34:36.256011  1343 sgd_solver.cpp:106] Iteration 160000, lr = 1.9245e-07
I0826 13:34:44.665699  1343 solver.cpp:228] Iteration 160100, loss = 3.51946
I0826 13:34:44.665758  1343 solver.cpp:244]     Train net output #0: loss = 3.51946 (* 1 = 3.51946 loss)
I0826 13:34:44.665765  1343 sgd_solver.cpp:106] Iteration 160100, lr = 1.9237e-07
I0826 13:34:53.073266  1343 solver.cpp:228] Iteration 160200, loss = 3.44532
I0826 13:34:53.073318  1343 solver.cpp:244]     Train net output #0: loss = 3.44532 (* 1 = 3.44532 loss)
I0826 13:34:53.073326  1343 sgd_solver.cpp:106] Iteration 160200, lr = 1.9229e-07
I0826 13:35:01.490828  1343 solver.cpp:228] Iteration 160300, loss = 3.38806
I0826 13:35:01.490883  1343 solver.cpp:244]     Train net output #0: loss = 3.38806 (* 1 = 3.38806 loss)
I0826 13:35:01.490890  1343 sgd_solver.cpp:106] Iteration 160300, lr = 1.9221e-07
I0826 13:35:09.888698  1343 solver.cpp:228] Iteration 160400, loss = 3.49283
I0826 13:35:09.888763  1343 solver.cpp:244]     Train net output #0: loss = 3.49283 (* 1 = 3.49283 loss)
I0826 13:35:09.888770  1343 sgd_solver.cpp:106] Iteration 160400, lr = 1.9213e-07
I0826 13:35:18.301939  1343 solver.cpp:228] Iteration 160500, loss = 3.46118
I0826 13:35:18.302007  1343 solver.cpp:244]     Train net output #0: loss = 3.46118 (* 1 = 3.46118 loss)
I0826 13:35:18.302016  1343 sgd_solver.cpp:106] Iteration 160500, lr = 1.9205e-07
I0826 13:35:26.731132  1343 solver.cpp:228] Iteration 160600, loss = 3.36611
I0826 13:35:26.731178  1343 solver.cpp:244]     Train net output #0: loss = 3.36611 (* 1 = 3.36611 loss)
I0826 13:35:26.731184  1343 sgd_solver.cpp:106] Iteration 160600, lr = 1.9197e-07
I0826 13:35:35.137652  1343 solver.cpp:228] Iteration 160700, loss = 3.39015
I0826 13:35:35.137717  1343 solver.cpp:244]     Train net output #0: loss = 3.39015 (* 1 = 3.39015 loss)
I0826 13:35:35.137727  1343 sgd_solver.cpp:106] Iteration 160700, lr = 1.91891e-07
I0826 13:35:43.562628  1343 solver.cpp:228] Iteration 160800, loss = 3.45701
I0826 13:35:43.562700  1343 solver.cpp:244]     Train net output #0: loss = 3.45701 (* 1 = 3.45701 loss)
I0826 13:35:43.562731  1343 sgd_solver.cpp:106] Iteration 160800, lr = 1.91811e-07
I0826 13:35:51.984258  1343 solver.cpp:228] Iteration 160900, loss = 3.39311
I0826 13:35:51.984315  1343 solver.cpp:244]     Train net output #0: loss = 3.39311 (* 1 = 3.39311 loss)
I0826 13:35:51.984326  1343 sgd_solver.cpp:106] Iteration 160900, lr = 1.91732e-07
I0826 13:36:00.401515  1343 solver.cpp:228] Iteration 161000, loss = 3.47132
I0826 13:36:00.401577  1343 solver.cpp:244]     Train net output #0: loss = 3.47132 (* 1 = 3.47132 loss)
I0826 13:36:00.401588  1343 sgd_solver.cpp:106] Iteration 161000, lr = 1.91652e-07
I0826 13:36:08.799090  1343 solver.cpp:228] Iteration 161100, loss = 3.23471
I0826 13:36:08.799157  1343 solver.cpp:244]     Train net output #0: loss = 3.23471 (* 1 = 3.23471 loss)
I0826 13:36:08.799166  1343 sgd_solver.cpp:106] Iteration 161100, lr = 1.91573e-07
I0826 13:36:17.225539  1343 solver.cpp:228] Iteration 161200, loss = 3.59067
I0826 13:36:17.225608  1343 solver.cpp:244]     Train net output #0: loss = 3.59067 (* 1 = 3.59067 loss)
I0826 13:36:17.225620  1343 sgd_solver.cpp:106] Iteration 161200, lr = 1.91493e-07
I0826 13:36:25.645071  1343 solver.cpp:228] Iteration 161300, loss = 3.31876
I0826 13:36:25.645123  1343 solver.cpp:244]     Train net output #0: loss = 3.31876 (* 1 = 3.31876 loss)
I0826 13:36:25.645133  1343 sgd_solver.cpp:106] Iteration 161300, lr = 1.91414e-07
I0826 13:36:34.077672  1343 solver.cpp:228] Iteration 161400, loss = 3.43147
I0826 13:36:34.077754  1343 solver.cpp:244]     Train net output #0: loss = 3.43147 (* 1 = 3.43147 loss)
I0826 13:36:34.077769  1343 sgd_solver.cpp:106] Iteration 161400, lr = 1.91335e-07
I0826 13:36:42.482938  1343 solver.cpp:228] Iteration 161500, loss = 3.37139
I0826 13:36:42.483006  1343 solver.cpp:244]     Train net output #0: loss = 3.37139 (* 1 = 3.37139 loss)
I0826 13:36:42.483016  1343 sgd_solver.cpp:106] Iteration 161500, lr = 1.91256e-07
I0826 13:36:46.782814  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:36:50.903605  1343 solver.cpp:228] Iteration 161600, loss = 3.31185
I0826 13:36:50.903673  1343 solver.cpp:244]     Train net output #0: loss = 3.31185 (* 1 = 3.31185 loss)
I0826 13:36:50.903688  1343 sgd_solver.cpp:106] Iteration 161600, lr = 1.91177e-07
I0826 13:36:59.329737  1343 solver.cpp:228] Iteration 161700, loss = 3.61813
I0826 13:36:59.329804  1343 solver.cpp:244]     Train net output #0: loss = 3.61813 (* 1 = 3.61813 loss)
I0826 13:36:59.329813  1343 sgd_solver.cpp:106] Iteration 161700, lr = 1.91098e-07
I0826 13:37:07.739781  1343 solver.cpp:228] Iteration 161800, loss = 3.57448
I0826 13:37:07.739850  1343 solver.cpp:244]     Train net output #0: loss = 3.57448 (* 1 = 3.57448 loss)
I0826 13:37:07.739861  1343 sgd_solver.cpp:106] Iteration 161800, lr = 1.91019e-07
I0826 13:37:16.149015  1343 solver.cpp:228] Iteration 161900, loss = 3.34495
I0826 13:37:16.149080  1343 solver.cpp:244]     Train net output #0: loss = 3.34495 (* 1 = 3.34495 loss)
I0826 13:37:16.149087  1343 sgd_solver.cpp:106] Iteration 161900, lr = 1.9094e-07
I0826 13:37:24.584017  1343 solver.cpp:228] Iteration 162000, loss = 3.58377
I0826 13:37:24.584084  1343 solver.cpp:244]     Train net output #0: loss = 3.58377 (* 1 = 3.58377 loss)
I0826 13:37:24.584095  1343 sgd_solver.cpp:106] Iteration 162000, lr = 1.90862e-07
I0826 13:37:33.022425  1343 solver.cpp:228] Iteration 162100, loss = 3.27286
I0826 13:37:33.022480  1343 solver.cpp:244]     Train net output #0: loss = 3.27286 (* 1 = 3.27286 loss)
I0826 13:37:33.022487  1343 sgd_solver.cpp:106] Iteration 162100, lr = 1.90783e-07
I0826 13:37:41.433409  1343 solver.cpp:228] Iteration 162200, loss = 3.42758
I0826 13:37:41.433464  1343 solver.cpp:244]     Train net output #0: loss = 3.42758 (* 1 = 3.42758 loss)
I0826 13:37:41.433471  1343 sgd_solver.cpp:106] Iteration 162200, lr = 1.90705e-07
I0826 13:37:49.850950  1343 solver.cpp:228] Iteration 162300, loss = 3.346
I0826 13:37:49.850997  1343 solver.cpp:244]     Train net output #0: loss = 3.346 (* 1 = 3.346 loss)
I0826 13:37:49.851003  1343 sgd_solver.cpp:106] Iteration 162300, lr = 1.90626e-07
I0826 13:37:58.264818  1343 solver.cpp:228] Iteration 162400, loss = 3.49001
I0826 13:37:58.264864  1343 solver.cpp:244]     Train net output #0: loss = 3.49001 (* 1 = 3.49001 loss)
I0826 13:37:58.264870  1343 sgd_solver.cpp:106] Iteration 162400, lr = 1.90548e-07
I0826 13:38:06.672276  1343 solver.cpp:228] Iteration 162500, loss = 3.30465
I0826 13:38:06.672333  1343 solver.cpp:244]     Train net output #0: loss = 3.30465 (* 1 = 3.30465 loss)
I0826 13:38:06.672339  1343 sgd_solver.cpp:106] Iteration 162500, lr = 1.90469e-07
I0826 13:38:15.109725  1343 solver.cpp:228] Iteration 162600, loss = 3.37403
I0826 13:38:15.109798  1343 solver.cpp:244]     Train net output #0: loss = 3.37403 (* 1 = 3.37403 loss)
I0826 13:38:15.109807  1343 sgd_solver.cpp:106] Iteration 162600, lr = 1.90391e-07
I0826 13:38:23.529948  1343 solver.cpp:228] Iteration 162700, loss = 3.50799
I0826 13:38:23.530004  1343 solver.cpp:244]     Train net output #0: loss = 3.50799 (* 1 = 3.50799 loss)
I0826 13:38:23.530012  1343 sgd_solver.cpp:106] Iteration 162700, lr = 1.90313e-07
I0826 13:38:31.962188  1343 solver.cpp:228] Iteration 162800, loss = 3.47318
I0826 13:38:31.962251  1343 solver.cpp:244]     Train net output #0: loss = 3.47318 (* 1 = 3.47318 loss)
I0826 13:38:31.962261  1343 sgd_solver.cpp:106] Iteration 162800, lr = 1.90235e-07
I0826 13:38:40.394577  1343 solver.cpp:228] Iteration 162900, loss = 3.39789
I0826 13:38:40.394645  1343 solver.cpp:244]     Train net output #0: loss = 3.39789 (* 1 = 3.39789 loss)
I0826 13:38:40.394652  1343 sgd_solver.cpp:106] Iteration 162900, lr = 1.90157e-07
I0826 13:38:48.824321  1343 solver.cpp:228] Iteration 163000, loss = 3.49674
I0826 13:38:48.824374  1343 solver.cpp:244]     Train net output #0: loss = 3.49674 (* 1 = 3.49674 loss)
I0826 13:38:48.824384  1343 sgd_solver.cpp:106] Iteration 163000, lr = 1.90079e-07
I0826 13:38:57.239876  1343 solver.cpp:228] Iteration 163100, loss = 3.21657
I0826 13:38:57.239928  1343 solver.cpp:244]     Train net output #0: loss = 3.21657 (* 1 = 3.21657 loss)
I0826 13:38:57.239935  1343 sgd_solver.cpp:106] Iteration 163100, lr = 1.90001e-07
I0826 13:39:05.646816  1343 solver.cpp:228] Iteration 163200, loss = 3.41234
I0826 13:39:05.646872  1343 solver.cpp:244]     Train net output #0: loss = 3.41234 (* 1 = 3.41234 loss)
I0826 13:39:05.646879  1343 sgd_solver.cpp:106] Iteration 163200, lr = 1.89923e-07
I0826 13:39:14.071969  1343 solver.cpp:228] Iteration 163300, loss = 3.50738
I0826 13:39:14.072029  1343 solver.cpp:244]     Train net output #0: loss = 3.50738 (* 1 = 3.50738 loss)
I0826 13:39:14.072041  1343 sgd_solver.cpp:106] Iteration 163300, lr = 1.89846e-07
I0826 13:39:22.495579  1343 solver.cpp:228] Iteration 163400, loss = 3.51162
I0826 13:39:22.495643  1343 solver.cpp:244]     Train net output #0: loss = 3.51162 (* 1 = 3.51162 loss)
I0826 13:39:22.495653  1343 sgd_solver.cpp:106] Iteration 163400, lr = 1.89768e-07
I0826 13:39:30.912148  1343 solver.cpp:228] Iteration 163500, loss = 3.20833
I0826 13:39:30.912195  1343 solver.cpp:244]     Train net output #0: loss = 3.20833 (* 1 = 3.20833 loss)
I0826 13:39:30.912201  1343 sgd_solver.cpp:106] Iteration 163500, lr = 1.8969e-07
I0826 13:39:39.329927  1343 solver.cpp:228] Iteration 163600, loss = 3.45769
I0826 13:39:39.329983  1343 solver.cpp:244]     Train net output #0: loss = 3.45769 (* 1 = 3.45769 loss)
I0826 13:39:39.329993  1343 sgd_solver.cpp:106] Iteration 163600, lr = 1.89613e-07
I0826 13:39:47.747097  1343 solver.cpp:228] Iteration 163700, loss = 3.4727
I0826 13:39:47.747143  1343 solver.cpp:244]     Train net output #0: loss = 3.4727 (* 1 = 3.4727 loss)
I0826 13:39:47.747148  1343 sgd_solver.cpp:106] Iteration 163700, lr = 1.89536e-07
I0826 13:39:56.168054  1343 solver.cpp:228] Iteration 163800, loss = 3.49697
I0826 13:39:56.168098  1343 solver.cpp:244]     Train net output #0: loss = 3.49697 (* 1 = 3.49697 loss)
I0826 13:39:56.168104  1343 sgd_solver.cpp:106] Iteration 163800, lr = 1.89458e-07
I0826 13:40:04.573824  1343 solver.cpp:228] Iteration 163900, loss = 3.37108
I0826 13:40:04.573884  1343 solver.cpp:244]     Train net output #0: loss = 3.37108 (* 1 = 3.37108 loss)
I0826 13:40:04.573889  1343 sgd_solver.cpp:106] Iteration 163900, lr = 1.89381e-07
I0826 13:40:12.996070  1343 solver.cpp:228] Iteration 164000, loss = 3.37951
I0826 13:40:12.996134  1343 solver.cpp:244]     Train net output #0: loss = 3.37951 (* 1 = 3.37951 loss)
I0826 13:40:12.996145  1343 sgd_solver.cpp:106] Iteration 164000, lr = 1.89304e-07
I0826 13:40:21.422977  1343 solver.cpp:228] Iteration 164100, loss = 3.16384
I0826 13:40:21.423025  1343 solver.cpp:244]     Train net output #0: loss = 3.16384 (* 1 = 3.16384 loss)
I0826 13:40:21.423032  1343 sgd_solver.cpp:106] Iteration 164100, lr = 1.89227e-07
I0826 13:40:29.816375  1343 solver.cpp:228] Iteration 164200, loss = 3.40934
I0826 13:40:29.816450  1343 solver.cpp:244]     Train net output #0: loss = 3.40934 (* 1 = 3.40934 loss)
I0826 13:40:29.816460  1343 sgd_solver.cpp:106] Iteration 164200, lr = 1.8915e-07
I0826 13:40:38.245612  1343 solver.cpp:228] Iteration 164300, loss = 3.32532
I0826 13:40:38.245677  1343 solver.cpp:244]     Train net output #0: loss = 3.32532 (* 1 = 3.32532 loss)
I0826 13:40:38.245687  1343 sgd_solver.cpp:106] Iteration 164300, lr = 1.89073e-07
I0826 13:40:46.676419  1343 solver.cpp:228] Iteration 164400, loss = 3.36149
I0826 13:40:46.676481  1343 solver.cpp:244]     Train net output #0: loss = 3.36149 (* 1 = 3.36149 loss)
I0826 13:40:46.676491  1343 sgd_solver.cpp:106] Iteration 164400, lr = 1.88996e-07
I0826 13:40:55.096421  1343 solver.cpp:228] Iteration 164500, loss = 3.15133
I0826 13:40:55.096475  1343 solver.cpp:244]     Train net output #0: loss = 3.15133 (* 1 = 3.15133 loss)
I0826 13:40:55.096484  1343 sgd_solver.cpp:106] Iteration 164500, lr = 1.88919e-07
I0826 13:41:03.519608  1343 solver.cpp:228] Iteration 164600, loss = 3.41559
I0826 13:41:03.519680  1343 solver.cpp:244]     Train net output #0: loss = 3.41559 (* 1 = 3.41559 loss)
I0826 13:41:03.519695  1343 sgd_solver.cpp:106] Iteration 164600, lr = 1.88842e-07
I0826 13:41:11.934378  1343 solver.cpp:228] Iteration 164700, loss = 3.308
I0826 13:41:11.934424  1343 solver.cpp:244]     Train net output #0: loss = 3.308 (* 1 = 3.308 loss)
I0826 13:41:11.934430  1343 sgd_solver.cpp:106] Iteration 164700, lr = 1.88765e-07
I0826 13:41:20.366086  1343 solver.cpp:228] Iteration 164800, loss = 3.24409
I0826 13:41:20.366156  1343 solver.cpp:244]     Train net output #0: loss = 3.24409 (* 1 = 3.24409 loss)
I0826 13:41:20.366169  1343 sgd_solver.cpp:106] Iteration 164800, lr = 1.88689e-07
I0826 13:41:28.794854  1343 solver.cpp:228] Iteration 164900, loss = 3.53143
I0826 13:41:28.794921  1343 solver.cpp:244]     Train net output #0: loss = 3.53143 (* 1 = 3.53143 loss)
I0826 13:41:28.794931  1343 sgd_solver.cpp:106] Iteration 164900, lr = 1.88612e-07
I0826 13:41:37.139781  1343 solver.cpp:337] Iteration 165000, Testing net (#0)
I0826 13:41:40.268525  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:42:13.496309  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302051
I0826 13:42:13.496372  1343 solver.cpp:404]     Test net output #1: loss = 3.42031 (* 1 = 3.42031 loss)
I0826 13:42:13.527011  1343 solver.cpp:228] Iteration 165000, loss = 3.43026
I0826 13:42:13.527065  1343 solver.cpp:244]     Train net output #0: loss = 3.43026 (* 1 = 3.43026 loss)
I0826 13:42:13.527076  1343 sgd_solver.cpp:106] Iteration 165000, lr = 1.88536e-07
I0826 13:42:21.934957  1343 solver.cpp:228] Iteration 165100, loss = 3.43994
I0826 13:42:21.935025  1343 solver.cpp:244]     Train net output #0: loss = 3.43994 (* 1 = 3.43994 loss)
I0826 13:42:21.935034  1343 sgd_solver.cpp:106] Iteration 165100, lr = 1.88459e-07
I0826 13:42:30.348721  1343 solver.cpp:228] Iteration 165200, loss = 3.3089
I0826 13:42:30.348784  1343 solver.cpp:244]     Train net output #0: loss = 3.3089 (* 1 = 3.3089 loss)
I0826 13:42:30.348796  1343 sgd_solver.cpp:106] Iteration 165200, lr = 1.88383e-07
I0826 13:42:38.765357  1343 solver.cpp:228] Iteration 165300, loss = 3.24455
I0826 13:42:38.765426  1343 solver.cpp:244]     Train net output #0: loss = 3.24455 (* 1 = 3.24455 loss)
I0826 13:42:38.765435  1343 sgd_solver.cpp:106] Iteration 165300, lr = 1.88307e-07
I0826 13:42:40.025061  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:42:47.194700  1343 solver.cpp:228] Iteration 165400, loss = 3.35936
I0826 13:42:47.194789  1343 solver.cpp:244]     Train net output #0: loss = 3.35936 (* 1 = 3.35936 loss)
I0826 13:42:47.194798  1343 sgd_solver.cpp:106] Iteration 165400, lr = 1.88231e-07
I0826 13:42:55.622907  1343 solver.cpp:228] Iteration 165500, loss = 3.35044
I0826 13:42:55.622978  1343 solver.cpp:244]     Train net output #0: loss = 3.35044 (* 1 = 3.35044 loss)
I0826 13:42:55.622988  1343 sgd_solver.cpp:106] Iteration 165500, lr = 1.88154e-07
I0826 13:43:04.051367  1343 solver.cpp:228] Iteration 165600, loss = 3.65744
I0826 13:43:04.051429  1343 solver.cpp:244]     Train net output #0: loss = 3.65744 (* 1 = 3.65744 loss)
I0826 13:43:04.051439  1343 sgd_solver.cpp:106] Iteration 165600, lr = 1.88078e-07
I0826 13:43:12.468649  1343 solver.cpp:228] Iteration 165700, loss = 3.46561
I0826 13:43:12.468690  1343 solver.cpp:244]     Train net output #0: loss = 3.46561 (* 1 = 3.46561 loss)
I0826 13:43:12.468696  1343 sgd_solver.cpp:106] Iteration 165700, lr = 1.88002e-07
I0826 13:43:20.896064  1343 solver.cpp:228] Iteration 165800, loss = 3.42835
I0826 13:43:20.896128  1343 solver.cpp:244]     Train net output #0: loss = 3.42835 (* 1 = 3.42835 loss)
I0826 13:43:20.896138  1343 sgd_solver.cpp:106] Iteration 165800, lr = 1.87927e-07
I0826 13:43:29.320631  1343 solver.cpp:228] Iteration 165900, loss = 3.24705
I0826 13:43:29.320689  1343 solver.cpp:244]     Train net output #0: loss = 3.24705 (* 1 = 3.24705 loss)
I0826 13:43:29.320701  1343 sgd_solver.cpp:106] Iteration 165900, lr = 1.87851e-07
I0826 13:43:37.752566  1343 solver.cpp:228] Iteration 166000, loss = 3.50705
I0826 13:43:37.752635  1343 solver.cpp:244]     Train net output #0: loss = 3.50705 (* 1 = 3.50705 loss)
I0826 13:43:37.752645  1343 sgd_solver.cpp:106] Iteration 166000, lr = 1.87775e-07
I0826 13:43:46.154908  1343 solver.cpp:228] Iteration 166100, loss = 3.45762
I0826 13:43:46.154970  1343 solver.cpp:244]     Train net output #0: loss = 3.45762 (* 1 = 3.45762 loss)
I0826 13:43:46.154978  1343 sgd_solver.cpp:106] Iteration 166100, lr = 1.87699e-07
I0826 13:43:54.582806  1343 solver.cpp:228] Iteration 166200, loss = 3.22878
I0826 13:43:54.582864  1343 solver.cpp:244]     Train net output #0: loss = 3.22878 (* 1 = 3.22878 loss)
I0826 13:43:54.582870  1343 sgd_solver.cpp:106] Iteration 166200, lr = 1.87624e-07
I0826 13:44:03.006980  1343 solver.cpp:228] Iteration 166300, loss = 3.41068
I0826 13:44:03.007038  1343 solver.cpp:244]     Train net output #0: loss = 3.41068 (* 1 = 3.41068 loss)
I0826 13:44:03.007050  1343 sgd_solver.cpp:106] Iteration 166300, lr = 1.87548e-07
I0826 13:44:11.435492  1343 solver.cpp:228] Iteration 166400, loss = 3.47499
I0826 13:44:11.435557  1343 solver.cpp:244]     Train net output #0: loss = 3.47499 (* 1 = 3.47499 loss)
I0826 13:44:11.435567  1343 sgd_solver.cpp:106] Iteration 166400, lr = 1.87473e-07
I0826 13:44:19.837677  1343 solver.cpp:228] Iteration 166500, loss = 3.42953
I0826 13:44:19.837745  1343 solver.cpp:244]     Train net output #0: loss = 3.42953 (* 1 = 3.42953 loss)
I0826 13:44:19.837754  1343 sgd_solver.cpp:106] Iteration 166500, lr = 1.87397e-07
I0826 13:44:28.256116  1343 solver.cpp:228] Iteration 166600, loss = 3.2553
I0826 13:44:28.256186  1343 solver.cpp:244]     Train net output #0: loss = 3.2553 (* 1 = 3.2553 loss)
I0826 13:44:28.256197  1343 sgd_solver.cpp:106] Iteration 166600, lr = 1.87322e-07
I0826 13:44:36.675319  1343 solver.cpp:228] Iteration 166700, loss = 3.50258
I0826 13:44:36.675374  1343 solver.cpp:244]     Train net output #0: loss = 3.50258 (* 1 = 3.50258 loss)
I0826 13:44:36.675382  1343 sgd_solver.cpp:106] Iteration 166700, lr = 1.87247e-07
I0826 13:44:45.092407  1343 solver.cpp:228] Iteration 166800, loss = 3.26575
I0826 13:44:45.092483  1343 solver.cpp:244]     Train net output #0: loss = 3.26575 (* 1 = 3.26575 loss)
I0826 13:44:45.092491  1343 sgd_solver.cpp:106] Iteration 166800, lr = 1.87172e-07
I0826 13:44:53.503226  1343 solver.cpp:228] Iteration 166900, loss = 3.38528
I0826 13:44:53.503271  1343 solver.cpp:244]     Train net output #0: loss = 3.38528 (* 1 = 3.38528 loss)
I0826 13:44:53.503278  1343 sgd_solver.cpp:106] Iteration 166900, lr = 1.87096e-07
I0826 13:45:01.923537  1343 solver.cpp:228] Iteration 167000, loss = 3.32082
I0826 13:45:01.923602  1343 solver.cpp:244]     Train net output #0: loss = 3.32082 (* 1 = 3.32082 loss)
I0826 13:45:01.923612  1343 sgd_solver.cpp:106] Iteration 167000, lr = 1.87021e-07
I0826 13:45:10.350425  1343 solver.cpp:228] Iteration 167100, loss = 3.51624
I0826 13:45:10.350489  1343 solver.cpp:244]     Train net output #0: loss = 3.51624 (* 1 = 3.51624 loss)
I0826 13:45:10.350502  1343 sgd_solver.cpp:106] Iteration 167100, lr = 1.86946e-07
I0826 13:45:18.769359  1343 solver.cpp:228] Iteration 167200, loss = 3.43024
I0826 13:45:18.769412  1343 solver.cpp:244]     Train net output #0: loss = 3.43024 (* 1 = 3.43024 loss)
I0826 13:45:18.769418  1343 sgd_solver.cpp:106] Iteration 167200, lr = 1.86872e-07
I0826 13:45:27.187455  1343 solver.cpp:228] Iteration 167300, loss = 3.38623
I0826 13:45:27.187523  1343 solver.cpp:244]     Train net output #0: loss = 3.38623 (* 1 = 3.38623 loss)
I0826 13:45:27.187533  1343 sgd_solver.cpp:106] Iteration 167300, lr = 1.86797e-07
I0826 13:45:35.613749  1343 solver.cpp:228] Iteration 167400, loss = 3.36655
I0826 13:45:35.613818  1343 solver.cpp:244]     Train net output #0: loss = 3.36655 (* 1 = 3.36655 loss)
I0826 13:45:35.613833  1343 sgd_solver.cpp:106] Iteration 167400, lr = 1.86722e-07
I0826 13:45:44.048763  1343 solver.cpp:228] Iteration 167500, loss = 3.38391
I0826 13:45:44.048830  1343 solver.cpp:244]     Train net output #0: loss = 3.38391 (* 1 = 3.38391 loss)
I0826 13:45:44.048840  1343 sgd_solver.cpp:106] Iteration 167500, lr = 1.86647e-07
I0826 13:45:52.468053  1343 solver.cpp:228] Iteration 167600, loss = 3.34605
I0826 13:45:52.468096  1343 solver.cpp:244]     Train net output #0: loss = 3.34605 (* 1 = 3.34605 loss)
I0826 13:45:52.468102  1343 sgd_solver.cpp:106] Iteration 167600, lr = 1.86573e-07
I0826 13:46:00.889379  1343 solver.cpp:228] Iteration 167700, loss = 3.47884
I0826 13:46:00.889436  1343 solver.cpp:244]     Train net output #0: loss = 3.47884 (* 1 = 3.47884 loss)
I0826 13:46:00.889444  1343 sgd_solver.cpp:106] Iteration 167700, lr = 1.86498e-07
I0826 13:46:09.298682  1343 solver.cpp:228] Iteration 167800, loss = 3.29234
I0826 13:46:09.298732  1343 solver.cpp:244]     Train net output #0: loss = 3.29234 (* 1 = 3.29234 loss)
I0826 13:46:09.298738  1343 sgd_solver.cpp:106] Iteration 167800, lr = 1.86424e-07
I0826 13:46:17.725189  1343 solver.cpp:228] Iteration 167900, loss = 3.35415
I0826 13:46:17.725241  1343 solver.cpp:244]     Train net output #0: loss = 3.35415 (* 1 = 3.35415 loss)
I0826 13:46:17.725250  1343 sgd_solver.cpp:106] Iteration 167900, lr = 1.86349e-07
I0826 13:46:26.147269  1343 solver.cpp:228] Iteration 168000, loss = 3.56628
I0826 13:46:26.147310  1343 solver.cpp:244]     Train net output #0: loss = 3.56628 (* 1 = 3.56628 loss)
I0826 13:46:26.147315  1343 sgd_solver.cpp:106] Iteration 168000, lr = 1.86275e-07
I0826 13:46:34.569258  1343 solver.cpp:228] Iteration 168100, loss = 3.49849
I0826 13:46:34.569319  1343 solver.cpp:244]     Train net output #0: loss = 3.49849 (* 1 = 3.49849 loss)
I0826 13:46:34.569332  1343 sgd_solver.cpp:106] Iteration 168100, lr = 1.86201e-07
I0826 13:46:43.016831  1343 solver.cpp:228] Iteration 168200, loss = 3.38791
I0826 13:46:43.016906  1343 solver.cpp:244]     Train net output #0: loss = 3.38791 (* 1 = 3.38791 loss)
I0826 13:46:43.016914  1343 sgd_solver.cpp:106] Iteration 168200, lr = 1.86126e-07
I0826 13:46:51.423300  1343 solver.cpp:228] Iteration 168300, loss = 3.3316
I0826 13:46:51.423351  1343 solver.cpp:244]     Train net output #0: loss = 3.3316 (* 1 = 3.3316 loss)
I0826 13:46:51.423358  1343 sgd_solver.cpp:106] Iteration 168300, lr = 1.86052e-07
I0826 13:46:59.841794  1343 solver.cpp:228] Iteration 168400, loss = 3.35912
I0826 13:46:59.841838  1343 solver.cpp:244]     Train net output #0: loss = 3.35912 (* 1 = 3.35912 loss)
I0826 13:46:59.841845  1343 sgd_solver.cpp:106] Iteration 168400, lr = 1.85978e-07
I0826 13:47:08.258090  1343 solver.cpp:228] Iteration 168500, loss = 3.63096
I0826 13:47:08.258133  1343 solver.cpp:244]     Train net output #0: loss = 3.63096 (* 1 = 3.63096 loss)
I0826 13:47:08.258141  1343 sgd_solver.cpp:106] Iteration 168500, lr = 1.85904e-07
I0826 13:47:16.672338  1343 solver.cpp:228] Iteration 168600, loss = 3.50731
I0826 13:47:16.672389  1343 solver.cpp:244]     Train net output #0: loss = 3.50731 (* 1 = 3.50731 loss)
I0826 13:47:16.672397  1343 sgd_solver.cpp:106] Iteration 168600, lr = 1.8583e-07
I0826 13:47:25.093973  1343 solver.cpp:228] Iteration 168700, loss = 3.5161
I0826 13:47:25.094017  1343 solver.cpp:244]     Train net output #0: loss = 3.5161 (* 1 = 3.5161 loss)
I0826 13:47:25.094022  1343 sgd_solver.cpp:106] Iteration 168700, lr = 1.85756e-07
I0826 13:47:33.519456  1343 solver.cpp:228] Iteration 168800, loss = 3.4624
I0826 13:47:33.519523  1343 solver.cpp:244]     Train net output #0: loss = 3.4624 (* 1 = 3.4624 loss)
I0826 13:47:33.519534  1343 sgd_solver.cpp:106] Iteration 168800, lr = 1.85683e-07
I0826 13:47:41.949385  1343 solver.cpp:228] Iteration 168900, loss = 3.26783
I0826 13:47:41.949442  1343 solver.cpp:244]     Train net output #0: loss = 3.26783 (* 1 = 3.26783 loss)
I0826 13:47:41.949451  1343 sgd_solver.cpp:106] Iteration 168900, lr = 1.85609e-07
I0826 13:47:50.380398  1343 solver.cpp:228] Iteration 169000, loss = 3.55555
I0826 13:47:50.380445  1343 solver.cpp:244]     Train net output #0: loss = 3.55555 (* 1 = 3.55555 loss)
I0826 13:47:50.380450  1343 sgd_solver.cpp:106] Iteration 169000, lr = 1.85535e-07
I0826 13:47:58.802531  1343 solver.cpp:228] Iteration 169100, loss = 3.38564
I0826 13:47:58.802585  1343 solver.cpp:244]     Train net output #0: loss = 3.38564 (* 1 = 3.38564 loss)
I0826 13:47:58.802593  1343 sgd_solver.cpp:106] Iteration 169100, lr = 1.85462e-07
I0826 13:47:59.648505  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:48:07.230976  1343 solver.cpp:228] Iteration 169200, loss = 3.3424
I0826 13:48:07.231047  1343 solver.cpp:244]     Train net output #0: loss = 3.3424 (* 1 = 3.3424 loss)
I0826 13:48:07.231060  1343 sgd_solver.cpp:106] Iteration 169200, lr = 1.85388e-07
I0826 13:48:15.656311  1343 solver.cpp:228] Iteration 169300, loss = 3.36708
I0826 13:48:15.656378  1343 solver.cpp:244]     Train net output #0: loss = 3.36708 (* 1 = 3.36708 loss)
I0826 13:48:15.656388  1343 sgd_solver.cpp:106] Iteration 169300, lr = 1.85315e-07
I0826 13:48:24.087507  1343 solver.cpp:228] Iteration 169400, loss = 3.41093
I0826 13:48:24.087566  1343 solver.cpp:244]     Train net output #0: loss = 3.41093 (* 1 = 3.41093 loss)
I0826 13:48:24.087579  1343 sgd_solver.cpp:106] Iteration 169400, lr = 1.85241e-07
I0826 13:48:32.493461  1343 solver.cpp:228] Iteration 169500, loss = 3.26219
I0826 13:48:32.493518  1343 solver.cpp:244]     Train net output #0: loss = 3.26219 (* 1 = 3.26219 loss)
I0826 13:48:32.493526  1343 sgd_solver.cpp:106] Iteration 169500, lr = 1.85168e-07
I0826 13:48:40.923305  1343 solver.cpp:228] Iteration 169600, loss = 3.55253
I0826 13:48:40.923379  1343 solver.cpp:244]     Train net output #0: loss = 3.55253 (* 1 = 3.55253 loss)
I0826 13:48:40.923389  1343 sgd_solver.cpp:106] Iteration 169600, lr = 1.85095e-07
I0826 13:48:49.354324  1343 solver.cpp:228] Iteration 169700, loss = 3.37711
I0826 13:48:49.354393  1343 solver.cpp:244]     Train net output #0: loss = 3.37711 (* 1 = 3.37711 loss)
I0826 13:48:49.354401  1343 sgd_solver.cpp:106] Iteration 169700, lr = 1.85021e-07
I0826 13:48:57.780484  1343 solver.cpp:228] Iteration 169800, loss = 3.50784
I0826 13:48:57.780542  1343 solver.cpp:244]     Train net output #0: loss = 3.50784 (* 1 = 3.50784 loss)
I0826 13:48:57.780552  1343 sgd_solver.cpp:106] Iteration 169800, lr = 1.84948e-07
I0826 13:49:06.214025  1343 solver.cpp:228] Iteration 169900, loss = 3.48989
I0826 13:49:06.214084  1343 solver.cpp:244]     Train net output #0: loss = 3.48989 (* 1 = 3.48989 loss)
I0826 13:49:06.214093  1343 sgd_solver.cpp:106] Iteration 169900, lr = 1.84875e-07
I0826 13:49:14.552451  1343 solver.cpp:337] Iteration 170000, Testing net (#0)
I0826 13:49:50.303706  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302034
I0826 13:49:50.303774  1343 solver.cpp:404]     Test net output #1: loss = 3.41956 (* 1 = 3.41956 loss)
I0826 13:49:50.332566  1343 solver.cpp:228] Iteration 170000, loss = 3.41352
I0826 13:49:50.332629  1343 solver.cpp:244]     Train net output #0: loss = 3.41352 (* 1 = 3.41352 loss)
I0826 13:49:50.332643  1343 sgd_solver.cpp:106] Iteration 170000, lr = 1.84802e-07
I0826 13:49:58.762130  1343 solver.cpp:228] Iteration 170100, loss = 3.45209
I0826 13:49:58.762214  1343 solver.cpp:244]     Train net output #0: loss = 3.45209 (* 1 = 3.45209 loss)
I0826 13:49:58.762224  1343 sgd_solver.cpp:106] Iteration 170100, lr = 1.84729e-07
I0826 13:50:07.204287  1343 solver.cpp:228] Iteration 170200, loss = 3.41667
I0826 13:50:07.204354  1343 solver.cpp:244]     Train net output #0: loss = 3.41667 (* 1 = 3.41667 loss)
I0826 13:50:07.204362  1343 sgd_solver.cpp:106] Iteration 170200, lr = 1.84656e-07
I0826 13:50:15.647209  1343 solver.cpp:228] Iteration 170300, loss = 3.33431
I0826 13:50:15.647270  1343 solver.cpp:244]     Train net output #0: loss = 3.33431 (* 1 = 3.33431 loss)
I0826 13:50:15.647279  1343 sgd_solver.cpp:106] Iteration 170300, lr = 1.84584e-07
I0826 13:50:24.076061  1343 solver.cpp:228] Iteration 170400, loss = 3.44148
I0826 13:50:24.076108  1343 solver.cpp:244]     Train net output #0: loss = 3.44148 (* 1 = 3.44148 loss)
I0826 13:50:24.076114  1343 sgd_solver.cpp:106] Iteration 170400, lr = 1.84511e-07
I0826 13:50:32.487948  1343 solver.cpp:228] Iteration 170500, loss = 3.26058
I0826 13:50:32.487989  1343 solver.cpp:244]     Train net output #0: loss = 3.26058 (* 1 = 3.26058 loss)
I0826 13:50:32.487995  1343 sgd_solver.cpp:106] Iteration 170500, lr = 1.84438e-07
I0826 13:50:40.934062  1343 solver.cpp:228] Iteration 170600, loss = 3.34075
I0826 13:50:40.934116  1343 solver.cpp:244]     Train net output #0: loss = 3.34075 (* 1 = 3.34075 loss)
I0826 13:50:40.934137  1343 sgd_solver.cpp:106] Iteration 170600, lr = 1.84366e-07
I0826 13:50:49.356508  1343 solver.cpp:228] Iteration 170700, loss = 3.44979
I0826 13:50:49.356551  1343 solver.cpp:244]     Train net output #0: loss = 3.44979 (* 1 = 3.44979 loss)
I0826 13:50:49.356556  1343 sgd_solver.cpp:106] Iteration 170700, lr = 1.84293e-07
I0826 13:50:57.773605  1343 solver.cpp:228] Iteration 170800, loss = 3.57311
I0826 13:50:57.773663  1343 solver.cpp:244]     Train net output #0: loss = 3.57311 (* 1 = 3.57311 loss)
I0826 13:50:57.773671  1343 sgd_solver.cpp:106] Iteration 170800, lr = 1.84221e-07
I0826 13:51:06.200063  1343 solver.cpp:228] Iteration 170900, loss = 3.30239
I0826 13:51:06.200129  1343 solver.cpp:244]     Train net output #0: loss = 3.30239 (* 1 = 3.30239 loss)
I0826 13:51:06.200136  1343 sgd_solver.cpp:106] Iteration 170900, lr = 1.84148e-07
I0826 13:51:14.629025  1343 solver.cpp:228] Iteration 171000, loss = 3.34409
I0826 13:51:14.629076  1343 solver.cpp:244]     Train net output #0: loss = 3.34409 (* 1 = 3.34409 loss)
I0826 13:51:14.629082  1343 sgd_solver.cpp:106] Iteration 171000, lr = 1.84076e-07
I0826 13:51:23.048343  1343 solver.cpp:228] Iteration 171100, loss = 3.33046
I0826 13:51:23.048403  1343 solver.cpp:244]     Train net output #0: loss = 3.33046 (* 1 = 3.33046 loss)
I0826 13:51:23.048413  1343 sgd_solver.cpp:106] Iteration 171100, lr = 1.84004e-07
I0826 13:51:31.484405  1343 solver.cpp:228] Iteration 171200, loss = 3.3519
I0826 13:51:31.484465  1343 solver.cpp:244]     Train net output #0: loss = 3.3519 (* 1 = 3.3519 loss)
I0826 13:51:31.484472  1343 sgd_solver.cpp:106] Iteration 171200, lr = 1.83932e-07
I0826 13:51:39.908926  1343 solver.cpp:228] Iteration 171300, loss = 3.29734
I0826 13:51:39.908977  1343 solver.cpp:244]     Train net output #0: loss = 3.29734 (* 1 = 3.29734 loss)
I0826 13:51:39.908983  1343 sgd_solver.cpp:106] Iteration 171300, lr = 1.8386e-07
I0826 13:51:42.271385  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:51:48.341184  1343 solver.cpp:228] Iteration 171400, loss = 3.45325
I0826 13:51:48.341244  1343 solver.cpp:244]     Train net output #0: loss = 3.45325 (* 1 = 3.45325 loss)
I0826 13:51:48.341253  1343 sgd_solver.cpp:106] Iteration 171400, lr = 1.83788e-07
I0826 13:51:56.764479  1343 solver.cpp:228] Iteration 171500, loss = 3.34586
I0826 13:51:56.764541  1343 solver.cpp:244]     Train net output #0: loss = 3.34586 (* 1 = 3.34586 loss)
I0826 13:51:56.764551  1343 sgd_solver.cpp:106] Iteration 171500, lr = 1.83716e-07
I0826 13:52:05.194396  1343 solver.cpp:228] Iteration 171600, loss = 3.40077
I0826 13:52:05.194438  1343 solver.cpp:244]     Train net output #0: loss = 3.40077 (* 1 = 3.40077 loss)
I0826 13:52:05.194443  1343 sgd_solver.cpp:106] Iteration 171600, lr = 1.83644e-07
I0826 13:52:13.627230  1343 solver.cpp:228] Iteration 171700, loss = 3.16302
I0826 13:52:13.627285  1343 solver.cpp:244]     Train net output #0: loss = 3.16302 (* 1 = 3.16302 loss)
I0826 13:52:13.627292  1343 sgd_solver.cpp:106] Iteration 171700, lr = 1.83572e-07
I0826 13:52:22.064208  1343 solver.cpp:228] Iteration 171800, loss = 3.21501
I0826 13:52:22.064270  1343 solver.cpp:244]     Train net output #0: loss = 3.21501 (* 1 = 3.21501 loss)
I0826 13:52:22.064282  1343 sgd_solver.cpp:106] Iteration 171800, lr = 1.835e-07
I0826 13:52:30.490869  1343 solver.cpp:228] Iteration 171900, loss = 3.31178
I0826 13:52:30.490929  1343 solver.cpp:244]     Train net output #0: loss = 3.31178 (* 1 = 3.31178 loss)
I0826 13:52:30.490939  1343 sgd_solver.cpp:106] Iteration 171900, lr = 1.83428e-07
I0826 13:52:38.913182  1343 solver.cpp:228] Iteration 172000, loss = 3.4669
I0826 13:52:38.913224  1343 solver.cpp:244]     Train net output #0: loss = 3.4669 (* 1 = 3.4669 loss)
I0826 13:52:38.913230  1343 sgd_solver.cpp:106] Iteration 172000, lr = 1.83357e-07
I0826 13:52:47.313964  1343 solver.cpp:228] Iteration 172100, loss = 3.35608
I0826 13:52:47.314016  1343 solver.cpp:244]     Train net output #0: loss = 3.35608 (* 1 = 3.35608 loss)
I0826 13:52:47.314024  1343 sgd_solver.cpp:106] Iteration 172100, lr = 1.83285e-07
I0826 13:52:55.743393  1343 solver.cpp:228] Iteration 172200, loss = 3.53625
I0826 13:52:55.743453  1343 solver.cpp:244]     Train net output #0: loss = 3.53625 (* 1 = 3.53625 loss)
I0826 13:52:55.743461  1343 sgd_solver.cpp:106] Iteration 172200, lr = 1.83214e-07
I0826 13:53:04.171798  1343 solver.cpp:228] Iteration 172300, loss = 3.35338
I0826 13:53:04.171885  1343 solver.cpp:244]     Train net output #0: loss = 3.35338 (* 1 = 3.35338 loss)
I0826 13:53:04.171895  1343 sgd_solver.cpp:106] Iteration 172300, lr = 1.83142e-07
I0826 13:53:12.597126  1343 solver.cpp:228] Iteration 172400, loss = 3.34413
I0826 13:53:12.597201  1343 solver.cpp:244]     Train net output #0: loss = 3.34413 (* 1 = 3.34413 loss)
I0826 13:53:12.597214  1343 sgd_solver.cpp:106] Iteration 172400, lr = 1.83071e-07
I0826 13:53:21.003934  1343 solver.cpp:228] Iteration 172500, loss = 3.41609
I0826 13:53:21.003998  1343 solver.cpp:244]     Train net output #0: loss = 3.41609 (* 1 = 3.41609 loss)
I0826 13:53:21.004005  1343 sgd_solver.cpp:106] Iteration 172500, lr = 1.82999e-07
I0826 13:53:29.424953  1343 solver.cpp:228] Iteration 172600, loss = 3.45791
I0826 13:53:29.425010  1343 solver.cpp:244]     Train net output #0: loss = 3.45791 (* 1 = 3.45791 loss)
I0826 13:53:29.425017  1343 sgd_solver.cpp:106] Iteration 172600, lr = 1.82928e-07
I0826 13:53:37.855304  1343 solver.cpp:228] Iteration 172700, loss = 3.42974
I0826 13:53:37.855345  1343 solver.cpp:244]     Train net output #0: loss = 3.42974 (* 1 = 3.42974 loss)
I0826 13:53:37.855351  1343 sgd_solver.cpp:106] Iteration 172700, lr = 1.82857e-07
I0826 13:53:46.289197  1343 solver.cpp:228] Iteration 172800, loss = 3.3591
I0826 13:53:46.289248  1343 solver.cpp:244]     Train net output #0: loss = 3.3591 (* 1 = 3.3591 loss)
I0826 13:53:46.289254  1343 sgd_solver.cpp:106] Iteration 172800, lr = 1.82786e-07
I0826 13:53:54.719065  1343 solver.cpp:228] Iteration 172900, loss = 3.31412
I0826 13:53:54.719126  1343 solver.cpp:244]     Train net output #0: loss = 3.31412 (* 1 = 3.31412 loss)
I0826 13:53:54.719136  1343 sgd_solver.cpp:106] Iteration 172900, lr = 1.82715e-07
I0826 13:54:03.133209  1343 solver.cpp:228] Iteration 173000, loss = 3.53032
I0826 13:54:03.133249  1343 solver.cpp:244]     Train net output #0: loss = 3.53032 (* 1 = 3.53032 loss)
I0826 13:54:03.133254  1343 sgd_solver.cpp:106] Iteration 173000, lr = 1.82644e-07
I0826 13:54:11.546218  1343 solver.cpp:228] Iteration 173100, loss = 3.27116
I0826 13:54:11.546258  1343 solver.cpp:244]     Train net output #0: loss = 3.27116 (* 1 = 3.27116 loss)
I0826 13:54:11.546264  1343 sgd_solver.cpp:106] Iteration 173100, lr = 1.82573e-07
I0826 13:54:19.977602  1343 solver.cpp:228] Iteration 173200, loss = 3.47527
I0826 13:54:19.977658  1343 solver.cpp:244]     Train net output #0: loss = 3.47527 (* 1 = 3.47527 loss)
I0826 13:54:19.977665  1343 sgd_solver.cpp:106] Iteration 173200, lr = 1.82502e-07
I0826 13:54:28.406577  1343 solver.cpp:228] Iteration 173300, loss = 3.40835
I0826 13:54:28.406636  1343 solver.cpp:244]     Train net output #0: loss = 3.40835 (* 1 = 3.40835 loss)
I0826 13:54:28.406646  1343 sgd_solver.cpp:106] Iteration 173300, lr = 1.82431e-07
I0826 13:54:36.811522  1343 solver.cpp:228] Iteration 173400, loss = 3.42527
I0826 13:54:36.811594  1343 solver.cpp:244]     Train net output #0: loss = 3.42527 (* 1 = 3.42527 loss)
I0826 13:54:36.811607  1343 sgd_solver.cpp:106] Iteration 173400, lr = 1.8236e-07
I0826 13:54:45.242697  1343 solver.cpp:228] Iteration 173500, loss = 3.33195
I0826 13:54:45.242768  1343 solver.cpp:244]     Train net output #0: loss = 3.33195 (* 1 = 3.33195 loss)
I0826 13:54:45.242777  1343 sgd_solver.cpp:106] Iteration 173500, lr = 1.8229e-07
I0826 13:54:53.670790  1343 solver.cpp:228] Iteration 173600, loss = 3.43657
I0826 13:54:53.670861  1343 solver.cpp:244]     Train net output #0: loss = 3.43657 (* 1 = 3.43657 loss)
I0826 13:54:53.670871  1343 sgd_solver.cpp:106] Iteration 173600, lr = 1.82219e-07
I0826 13:55:02.093602  1343 solver.cpp:228] Iteration 173700, loss = 3.59573
I0826 13:55:02.093641  1343 solver.cpp:244]     Train net output #0: loss = 3.59573 (* 1 = 3.59573 loss)
I0826 13:55:02.093647  1343 sgd_solver.cpp:106] Iteration 173700, lr = 1.82148e-07
I0826 13:55:10.515161  1343 solver.cpp:228] Iteration 173800, loss = 3.48934
I0826 13:55:10.515204  1343 solver.cpp:244]     Train net output #0: loss = 3.48934 (* 1 = 3.48934 loss)
I0826 13:55:10.515210  1343 sgd_solver.cpp:106] Iteration 173800, lr = 1.82078e-07
I0826 13:55:18.927160  1343 solver.cpp:228] Iteration 173900, loss = 3.31207
I0826 13:55:18.927203  1343 solver.cpp:244]     Train net output #0: loss = 3.31207 (* 1 = 3.31207 loss)
I0826 13:55:18.927209  1343 sgd_solver.cpp:106] Iteration 173900, lr = 1.82007e-07
I0826 13:55:27.357175  1343 solver.cpp:228] Iteration 174000, loss = 3.32031
I0826 13:55:27.357236  1343 solver.cpp:244]     Train net output #0: loss = 3.32031 (* 1 = 3.32031 loss)
I0826 13:55:27.357247  1343 sgd_solver.cpp:106] Iteration 174000, lr = 1.81937e-07
I0826 13:55:35.779742  1343 solver.cpp:228] Iteration 174100, loss = 3.41903
I0826 13:55:35.779804  1343 solver.cpp:244]     Train net output #0: loss = 3.41903 (* 1 = 3.41903 loss)
I0826 13:55:35.779814  1343 sgd_solver.cpp:106] Iteration 174100, lr = 1.81867e-07
I0826 13:55:44.202064  1343 solver.cpp:228] Iteration 174200, loss = 3.43842
I0826 13:55:44.202107  1343 solver.cpp:244]     Train net output #0: loss = 3.43842 (* 1 = 3.43842 loss)
I0826 13:55:44.202112  1343 sgd_solver.cpp:106] Iteration 174200, lr = 1.81797e-07
I0826 13:55:52.628654  1343 solver.cpp:228] Iteration 174300, loss = 3.36922
I0826 13:55:52.628696  1343 solver.cpp:244]     Train net output #0: loss = 3.36922 (* 1 = 3.36922 loss)
I0826 13:55:52.628701  1343 sgd_solver.cpp:106] Iteration 174300, lr = 1.81726e-07
I0826 13:56:01.055310  1343 solver.cpp:228] Iteration 174400, loss = 3.40054
I0826 13:56:01.055364  1343 solver.cpp:244]     Train net output #0: loss = 3.40054 (* 1 = 3.40054 loss)
I0826 13:56:01.055371  1343 sgd_solver.cpp:106] Iteration 174400, lr = 1.81656e-07
I0826 13:56:09.476189  1343 solver.cpp:228] Iteration 174500, loss = 3.42111
I0826 13:56:09.476243  1343 solver.cpp:244]     Train net output #0: loss = 3.42111 (* 1 = 3.42111 loss)
I0826 13:56:09.476251  1343 sgd_solver.cpp:106] Iteration 174500, lr = 1.81586e-07
I0826 13:56:17.917173  1343 solver.cpp:228] Iteration 174600, loss = 3.29698
I0826 13:56:17.917258  1343 solver.cpp:244]     Train net output #0: loss = 3.29698 (* 1 = 3.29698 loss)
I0826 13:56:17.917273  1343 sgd_solver.cpp:106] Iteration 174600, lr = 1.81516e-07
I0826 13:56:26.354714  1343 solver.cpp:228] Iteration 174700, loss = 3.4735
I0826 13:56:26.354778  1343 solver.cpp:244]     Train net output #0: loss = 3.4735 (* 1 = 3.4735 loss)
I0826 13:56:26.354791  1343 sgd_solver.cpp:106] Iteration 174700, lr = 1.81446e-07
I0826 13:56:34.780812  1343 solver.cpp:228] Iteration 174800, loss = 3.27793
I0826 13:56:34.780855  1343 solver.cpp:244]     Train net output #0: loss = 3.27793 (* 1 = 3.27793 loss)
I0826 13:56:34.780860  1343 sgd_solver.cpp:106] Iteration 174800, lr = 1.81376e-07
I0826 13:56:41.763092  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:56:43.202767  1343 solver.cpp:228] Iteration 174900, loss = 3.46962
I0826 13:56:43.202829  1343 solver.cpp:244]     Train net output #0: loss = 3.46962 (* 1 = 3.46962 loss)
I0826 13:56:43.202838  1343 sgd_solver.cpp:106] Iteration 174900, lr = 1.81307e-07
I0826 13:56:51.535544  1343 solver.cpp:337] Iteration 175000, Testing net (#0)
I0826 13:57:27.086246  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 13:57:27.779340  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302034
I0826 13:57:27.779407  1343 solver.cpp:404]     Test net output #1: loss = 3.41854 (* 1 = 3.41854 loss)
I0826 13:57:27.808630  1343 solver.cpp:228] Iteration 175000, loss = 3.44675
I0826 13:57:27.808678  1343 solver.cpp:244]     Train net output #0: loss = 3.44675 (* 1 = 3.44675 loss)
I0826 13:57:27.808691  1343 sgd_solver.cpp:106] Iteration 175000, lr = 1.81237e-07
I0826 13:57:36.238323  1343 solver.cpp:228] Iteration 175100, loss = 3.44226
I0826 13:57:36.238406  1343 solver.cpp:244]     Train net output #0: loss = 3.44226 (* 1 = 3.44226 loss)
I0826 13:57:36.238417  1343 sgd_solver.cpp:106] Iteration 175100, lr = 1.81167e-07
I0826 13:57:44.659426  1343 solver.cpp:228] Iteration 175200, loss = 3.24722
I0826 13:57:44.659497  1343 solver.cpp:244]     Train net output #0: loss = 3.24722 (* 1 = 3.24722 loss)
I0826 13:57:44.659508  1343 sgd_solver.cpp:106] Iteration 175200, lr = 1.81098e-07
I0826 13:57:53.091328  1343 solver.cpp:228] Iteration 175300, loss = 3.45963
I0826 13:57:53.091382  1343 solver.cpp:244]     Train net output #0: loss = 3.45963 (* 1 = 3.45963 loss)
I0826 13:57:53.091390  1343 sgd_solver.cpp:106] Iteration 175300, lr = 1.81028e-07
I0826 13:58:01.506688  1343 solver.cpp:228] Iteration 175400, loss = 3.52528
I0826 13:58:01.506739  1343 solver.cpp:244]     Train net output #0: loss = 3.52528 (* 1 = 3.52528 loss)
I0826 13:58:01.506747  1343 sgd_solver.cpp:106] Iteration 175400, lr = 1.80959e-07
I0826 13:58:09.918112  1343 solver.cpp:228] Iteration 175500, loss = 3.45985
I0826 13:58:09.918170  1343 solver.cpp:244]     Train net output #0: loss = 3.45985 (* 1 = 3.45985 loss)
I0826 13:58:09.918181  1343 sgd_solver.cpp:106] Iteration 175500, lr = 1.80889e-07
I0826 13:58:18.344514  1343 solver.cpp:228] Iteration 175600, loss = 3.35097
I0826 13:58:18.344584  1343 solver.cpp:244]     Train net output #0: loss = 3.35097 (* 1 = 3.35097 loss)
I0826 13:58:18.344594  1343 sgd_solver.cpp:106] Iteration 175600, lr = 1.8082e-07
I0826 13:58:26.763072  1343 solver.cpp:228] Iteration 175700, loss = 3.39049
I0826 13:58:26.763116  1343 solver.cpp:244]     Train net output #0: loss = 3.39049 (* 1 = 3.39049 loss)
I0826 13:58:26.763123  1343 sgd_solver.cpp:106] Iteration 175700, lr = 1.8075e-07
I0826 13:58:35.196424  1343 solver.cpp:228] Iteration 175800, loss = 3.35842
I0826 13:58:35.196493  1343 solver.cpp:244]     Train net output #0: loss = 3.35842 (* 1 = 3.35842 loss)
I0826 13:58:35.196504  1343 sgd_solver.cpp:106] Iteration 175800, lr = 1.80681e-07
I0826 13:58:43.605403  1343 solver.cpp:228] Iteration 175900, loss = 3.47466
I0826 13:58:43.605455  1343 solver.cpp:244]     Train net output #0: loss = 3.47466 (* 1 = 3.47466 loss)
I0826 13:58:43.605465  1343 sgd_solver.cpp:106] Iteration 175900, lr = 1.80612e-07
I0826 13:58:52.033691  1343 solver.cpp:228] Iteration 176000, loss = 3.42599
I0826 13:58:52.033757  1343 solver.cpp:244]     Train net output #0: loss = 3.42599 (* 1 = 3.42599 loss)
I0826 13:58:52.033766  1343 sgd_solver.cpp:106] Iteration 176000, lr = 1.80543e-07
I0826 13:59:00.467013  1343 solver.cpp:228] Iteration 176100, loss = 3.25157
I0826 13:59:00.467059  1343 solver.cpp:244]     Train net output #0: loss = 3.25157 (* 1 = 3.25157 loss)
I0826 13:59:00.467066  1343 sgd_solver.cpp:106] Iteration 176100, lr = 1.80474e-07
I0826 13:59:08.886603  1343 solver.cpp:228] Iteration 176200, loss = 3.42544
I0826 13:59:08.886679  1343 solver.cpp:244]     Train net output #0: loss = 3.42544 (* 1 = 3.42544 loss)
I0826 13:59:08.886687  1343 sgd_solver.cpp:106] Iteration 176200, lr = 1.80405e-07
I0826 13:59:17.305513  1343 solver.cpp:228] Iteration 176300, loss = 3.35709
I0826 13:59:17.305558  1343 solver.cpp:244]     Train net output #0: loss = 3.35709 (* 1 = 3.35709 loss)
I0826 13:59:17.305564  1343 sgd_solver.cpp:106] Iteration 176300, lr = 1.80336e-07
I0826 13:59:25.728835  1343 solver.cpp:228] Iteration 176400, loss = 3.43033
I0826 13:59:25.728909  1343 solver.cpp:244]     Train net output #0: loss = 3.43033 (* 1 = 3.43033 loss)
I0826 13:59:25.728925  1343 sgd_solver.cpp:106] Iteration 176400, lr = 1.80267e-07
I0826 13:59:34.151834  1343 solver.cpp:228] Iteration 176500, loss = 3.45939
I0826 13:59:34.151881  1343 solver.cpp:244]     Train net output #0: loss = 3.45939 (* 1 = 3.45939 loss)
I0826 13:59:34.151890  1343 sgd_solver.cpp:106] Iteration 176500, lr = 1.80198e-07
I0826 13:59:42.573248  1343 solver.cpp:228] Iteration 176600, loss = 3.30724
I0826 13:59:42.573324  1343 solver.cpp:244]     Train net output #0: loss = 3.30724 (* 1 = 3.30724 loss)
I0826 13:59:42.573339  1343 sgd_solver.cpp:106] Iteration 176600, lr = 1.8013e-07
I0826 13:59:50.979815  1343 solver.cpp:228] Iteration 176700, loss = 3.37391
I0826 13:59:50.979881  1343 solver.cpp:244]     Train net output #0: loss = 3.37391 (* 1 = 3.37391 loss)
I0826 13:59:50.979892  1343 sgd_solver.cpp:106] Iteration 176700, lr = 1.80061e-07
I0826 13:59:59.391640  1343 solver.cpp:228] Iteration 176800, loss = 3.45625
I0826 13:59:59.391708  1343 solver.cpp:244]     Train net output #0: loss = 3.45625 (* 1 = 3.45625 loss)
I0826 13:59:59.391717  1343 sgd_solver.cpp:106] Iteration 176800, lr = 1.79992e-07
I0826 14:00:07.808719  1343 solver.cpp:228] Iteration 176900, loss = 3.33289
I0826 14:00:07.808773  1343 solver.cpp:244]     Train net output #0: loss = 3.33289 (* 1 = 3.33289 loss)
I0826 14:00:07.808779  1343 sgd_solver.cpp:106] Iteration 176900, lr = 1.79924e-07
I0826 14:00:16.223376  1343 solver.cpp:228] Iteration 177000, loss = 3.4621
I0826 14:00:16.223433  1343 solver.cpp:244]     Train net output #0: loss = 3.4621 (* 1 = 3.4621 loss)
I0826 14:00:16.223444  1343 sgd_solver.cpp:106] Iteration 177000, lr = 1.79855e-07
I0826 14:00:24.643316  1343 solver.cpp:228] Iteration 177100, loss = 3.51303
I0826 14:00:24.643388  1343 solver.cpp:244]     Train net output #0: loss = 3.51303 (* 1 = 3.51303 loss)
I0826 14:00:24.643396  1343 sgd_solver.cpp:106] Iteration 177100, lr = 1.79787e-07
I0826 14:00:33.070844  1343 solver.cpp:228] Iteration 177200, loss = 3.47283
I0826 14:00:33.070904  1343 solver.cpp:244]     Train net output #0: loss = 3.47283 (* 1 = 3.47283 loss)
I0826 14:00:33.070917  1343 sgd_solver.cpp:106] Iteration 177200, lr = 1.79718e-07
I0826 14:00:41.497705  1343 solver.cpp:228] Iteration 177300, loss = 3.48322
I0826 14:00:41.497771  1343 solver.cpp:244]     Train net output #0: loss = 3.48322 (* 1 = 3.48322 loss)
I0826 14:00:41.497784  1343 sgd_solver.cpp:106] Iteration 177300, lr = 1.7965e-07
I0826 14:00:49.906384  1343 solver.cpp:228] Iteration 177400, loss = 3.57334
I0826 14:00:49.906429  1343 solver.cpp:244]     Train net output #0: loss = 3.57334 (* 1 = 3.57334 loss)
I0826 14:00:49.906433  1343 sgd_solver.cpp:106] Iteration 177400, lr = 1.79582e-07
I0826 14:00:58.315804  1343 solver.cpp:228] Iteration 177500, loss = 3.44858
I0826 14:00:58.315871  1343 solver.cpp:244]     Train net output #0: loss = 3.44858 (* 1 = 3.44858 loss)
I0826 14:00:58.315881  1343 sgd_solver.cpp:106] Iteration 177500, lr = 1.79514e-07
I0826 14:01:06.743366  1343 solver.cpp:228] Iteration 177600, loss = 3.45379
I0826 14:01:06.743419  1343 solver.cpp:244]     Train net output #0: loss = 3.45379 (* 1 = 3.45379 loss)
I0826 14:01:06.743427  1343 sgd_solver.cpp:106] Iteration 177600, lr = 1.79445e-07
I0826 14:01:15.160624  1343 solver.cpp:228] Iteration 177700, loss = 3.36435
I0826 14:01:15.160682  1343 solver.cpp:244]     Train net output #0: loss = 3.36435 (* 1 = 3.36435 loss)
I0826 14:01:15.160692  1343 sgd_solver.cpp:106] Iteration 177700, lr = 1.79377e-07
I0826 14:01:23.605825  1343 solver.cpp:228] Iteration 177800, loss = 3.36946
I0826 14:01:23.605880  1343 solver.cpp:244]     Train net output #0: loss = 3.36946 (* 1 = 3.36946 loss)
I0826 14:01:23.605887  1343 sgd_solver.cpp:106] Iteration 177800, lr = 1.79309e-07
I0826 14:01:32.041496  1343 solver.cpp:228] Iteration 177900, loss = 3.38377
I0826 14:01:32.041548  1343 solver.cpp:244]     Train net output #0: loss = 3.38377 (* 1 = 3.38377 loss)
I0826 14:01:32.041555  1343 sgd_solver.cpp:106] Iteration 177900, lr = 1.79241e-07
I0826 14:01:40.458122  1343 solver.cpp:228] Iteration 178000, loss = 3.45186
I0826 14:01:40.458183  1343 solver.cpp:244]     Train net output #0: loss = 3.45186 (* 1 = 3.45186 loss)
I0826 14:01:40.458192  1343 sgd_solver.cpp:106] Iteration 178000, lr = 1.79173e-07
I0826 14:01:48.873766  1343 solver.cpp:228] Iteration 178100, loss = 3.57723
I0826 14:01:48.873836  1343 solver.cpp:244]     Train net output #0: loss = 3.57723 (* 1 = 3.57723 loss)
I0826 14:01:48.873847  1343 sgd_solver.cpp:106] Iteration 178100, lr = 1.79106e-07
I0826 14:01:57.300583  1343 solver.cpp:228] Iteration 178200, loss = 3.36547
I0826 14:01:57.300645  1343 solver.cpp:244]     Train net output #0: loss = 3.36547 (* 1 = 3.36547 loss)
I0826 14:01:57.300652  1343 sgd_solver.cpp:106] Iteration 178200, lr = 1.79038e-07
I0826 14:02:05.722954  1343 solver.cpp:228] Iteration 178300, loss = 3.39286
I0826 14:02:05.723021  1343 solver.cpp:244]     Train net output #0: loss = 3.39286 (* 1 = 3.39286 loss)
I0826 14:02:05.723029  1343 sgd_solver.cpp:106] Iteration 178300, lr = 1.7897e-07
I0826 14:02:14.143426  1343 solver.cpp:228] Iteration 178400, loss = 3.48245
I0826 14:02:14.143486  1343 solver.cpp:244]     Train net output #0: loss = 3.48245 (* 1 = 3.48245 loss)
I0826 14:02:14.143493  1343 sgd_solver.cpp:106] Iteration 178400, lr = 1.78902e-07
I0826 14:02:22.563792  1343 solver.cpp:228] Iteration 178500, loss = 3.43886
I0826 14:02:22.563858  1343 solver.cpp:244]     Train net output #0: loss = 3.43886 (* 1 = 3.43886 loss)
I0826 14:02:22.563868  1343 sgd_solver.cpp:106] Iteration 178500, lr = 1.78835e-07
I0826 14:02:24.827611  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:02:30.990948  1343 solver.cpp:228] Iteration 178600, loss = 3.32924
I0826 14:02:30.991020  1343 solver.cpp:244]     Train net output #0: loss = 3.32924 (* 1 = 3.32924 loss)
I0826 14:02:30.991030  1343 sgd_solver.cpp:106] Iteration 178600, lr = 1.78767e-07
I0826 14:02:39.394765  1343 solver.cpp:228] Iteration 178700, loss = 3.33494
I0826 14:02:39.394814  1343 solver.cpp:244]     Train net output #0: loss = 3.33494 (* 1 = 3.33494 loss)
I0826 14:02:39.394820  1343 sgd_solver.cpp:106] Iteration 178700, lr = 1.787e-07
I0826 14:02:47.807155  1343 solver.cpp:228] Iteration 178800, loss = 3.46554
I0826 14:02:47.807216  1343 solver.cpp:244]     Train net output #0: loss = 3.46554 (* 1 = 3.46554 loss)
I0826 14:02:47.807225  1343 sgd_solver.cpp:106] Iteration 178800, lr = 1.78632e-07
I0826 14:02:56.240278  1343 solver.cpp:228] Iteration 178900, loss = 3.39694
I0826 14:02:56.240351  1343 solver.cpp:244]     Train net output #0: loss = 3.39694 (* 1 = 3.39694 loss)
I0826 14:02:56.240360  1343 sgd_solver.cpp:106] Iteration 178900, lr = 1.78565e-07
I0826 14:03:04.672098  1343 solver.cpp:228] Iteration 179000, loss = 3.21402
I0826 14:03:04.672164  1343 solver.cpp:244]     Train net output #0: loss = 3.21402 (* 1 = 3.21402 loss)
I0826 14:03:04.672173  1343 sgd_solver.cpp:106] Iteration 179000, lr = 1.78498e-07
I0826 14:03:13.083667  1343 solver.cpp:228] Iteration 179100, loss = 3.13602
I0826 14:03:13.083742  1343 solver.cpp:244]     Train net output #0: loss = 3.13602 (* 1 = 3.13602 loss)
I0826 14:03:13.083751  1343 sgd_solver.cpp:106] Iteration 179100, lr = 1.7843e-07
I0826 14:03:21.513036  1343 solver.cpp:228] Iteration 179200, loss = 3.45413
I0826 14:03:21.513094  1343 solver.cpp:244]     Train net output #0: loss = 3.45413 (* 1 = 3.45413 loss)
I0826 14:03:21.513100  1343 sgd_solver.cpp:106] Iteration 179200, lr = 1.78363e-07
I0826 14:03:29.938992  1343 solver.cpp:228] Iteration 179300, loss = 3.37904
I0826 14:03:29.939056  1343 solver.cpp:244]     Train net output #0: loss = 3.37904 (* 1 = 3.37904 loss)
I0826 14:03:29.939066  1343 sgd_solver.cpp:106] Iteration 179300, lr = 1.78296e-07
I0826 14:03:38.370282  1343 solver.cpp:228] Iteration 179400, loss = 3.26117
I0826 14:03:38.370342  1343 solver.cpp:244]     Train net output #0: loss = 3.26117 (* 1 = 3.26117 loss)
I0826 14:03:38.370354  1343 sgd_solver.cpp:106] Iteration 179400, lr = 1.78229e-07
I0826 14:03:46.791093  1343 solver.cpp:228] Iteration 179500, loss = 3.50547
I0826 14:03:46.791138  1343 solver.cpp:244]     Train net output #0: loss = 3.50547 (* 1 = 3.50547 loss)
I0826 14:03:46.791144  1343 sgd_solver.cpp:106] Iteration 179500, lr = 1.78162e-07
I0826 14:03:55.217217  1343 solver.cpp:228] Iteration 179600, loss = 3.57421
I0826 14:03:55.217283  1343 solver.cpp:244]     Train net output #0: loss = 3.57421 (* 1 = 3.57421 loss)
I0826 14:03:55.217293  1343 sgd_solver.cpp:106] Iteration 179600, lr = 1.78095e-07
I0826 14:04:03.623735  1343 solver.cpp:228] Iteration 179700, loss = 3.53235
I0826 14:04:03.623801  1343 solver.cpp:244]     Train net output #0: loss = 3.53235 (* 1 = 3.53235 loss)
I0826 14:04:03.623811  1343 sgd_solver.cpp:106] Iteration 179700, lr = 1.78028e-07
I0826 14:04:12.052319  1343 solver.cpp:228] Iteration 179800, loss = 3.5561
I0826 14:04:12.052388  1343 solver.cpp:244]     Train net output #0: loss = 3.5561 (* 1 = 3.5561 loss)
I0826 14:04:12.052397  1343 sgd_solver.cpp:106] Iteration 179800, lr = 1.77961e-07
I0826 14:04:20.483360  1343 solver.cpp:228] Iteration 179900, loss = 3.51583
I0826 14:04:20.483433  1343 solver.cpp:244]     Train net output #0: loss = 3.51583 (* 1 = 3.51583 loss)
I0826 14:04:20.483443  1343 sgd_solver.cpp:106] Iteration 179900, lr = 1.77895e-07
I0826 14:04:28.821394  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_180000.caffemodel
I0826 14:04:29.568975  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_180000.solverstate
I0826 14:04:29.729105  1343 solver.cpp:337] Iteration 180000, Testing net (#0)
I0826 14:04:51.163749  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:05:06.150763  1343 solver.cpp:404]     Test net output #0: accuracy = 0.30199
I0826 14:05:06.150826  1343 solver.cpp:404]     Test net output #1: loss = 3.41759 (* 1 = 3.41759 loss)
I0826 14:05:06.180418  1343 solver.cpp:228] Iteration 180000, loss = 3.188
I0826 14:05:06.180488  1343 solver.cpp:244]     Train net output #0: loss = 3.188 (* 1 = 3.188 loss)
I0826 14:05:06.180501  1343 sgd_solver.cpp:106] Iteration 180000, lr = 1.77828e-07
I0826 14:05:14.611177  1343 solver.cpp:228] Iteration 180100, loss = 3.45233
I0826 14:05:14.611222  1343 solver.cpp:244]     Train net output #0: loss = 3.45233 (* 1 = 3.45233 loss)
I0826 14:05:14.611227  1343 sgd_solver.cpp:106] Iteration 180100, lr = 1.77761e-07
I0826 14:05:23.032413  1343 solver.cpp:228] Iteration 180200, loss = 3.38637
I0826 14:05:23.032481  1343 solver.cpp:244]     Train net output #0: loss = 3.38637 (* 1 = 3.38637 loss)
I0826 14:05:23.032491  1343 sgd_solver.cpp:106] Iteration 180200, lr = 1.77695e-07
I0826 14:05:31.455593  1343 solver.cpp:228] Iteration 180300, loss = 3.269
I0826 14:05:31.455638  1343 solver.cpp:244]     Train net output #0: loss = 3.269 (* 1 = 3.269 loss)
I0826 14:05:31.455644  1343 sgd_solver.cpp:106] Iteration 180300, lr = 1.77628e-07
I0826 14:05:39.893952  1343 solver.cpp:228] Iteration 180400, loss = 3.56869
I0826 14:05:39.894016  1343 solver.cpp:244]     Train net output #0: loss = 3.56869 (* 1 = 3.56869 loss)
I0826 14:05:39.894026  1343 sgd_solver.cpp:106] Iteration 180400, lr = 1.77562e-07
I0826 14:05:48.327379  1343 solver.cpp:228] Iteration 180500, loss = 3.38528
I0826 14:05:48.327445  1343 solver.cpp:244]     Train net output #0: loss = 3.38528 (* 1 = 3.38528 loss)
I0826 14:05:48.327455  1343 sgd_solver.cpp:106] Iteration 180500, lr = 1.77495e-07
I0826 14:05:56.769173  1343 solver.cpp:228] Iteration 180600, loss = 3.26296
I0826 14:05:56.769228  1343 solver.cpp:244]     Train net output #0: loss = 3.26296 (* 1 = 3.26296 loss)
I0826 14:05:56.769243  1343 sgd_solver.cpp:106] Iteration 180600, lr = 1.77429e-07
I0826 14:06:05.194557  1343 solver.cpp:228] Iteration 180700, loss = 3.34016
I0826 14:06:05.194602  1343 solver.cpp:244]     Train net output #0: loss = 3.34016 (* 1 = 3.34016 loss)
I0826 14:06:05.194607  1343 sgd_solver.cpp:106] Iteration 180700, lr = 1.77363e-07
I0826 14:06:13.630292  1343 solver.cpp:228] Iteration 180800, loss = 3.36939
I0826 14:06:13.630348  1343 solver.cpp:244]     Train net output #0: loss = 3.36939 (* 1 = 3.36939 loss)
I0826 14:06:13.630362  1343 sgd_solver.cpp:106] Iteration 180800, lr = 1.77296e-07
I0826 14:06:22.051410  1343 solver.cpp:228] Iteration 180900, loss = 3.42684
I0826 14:06:22.051466  1343 solver.cpp:244]     Train net output #0: loss = 3.42684 (* 1 = 3.42684 loss)
I0826 14:06:22.051473  1343 sgd_solver.cpp:106] Iteration 180900, lr = 1.7723e-07
I0826 14:06:30.470592  1343 solver.cpp:228] Iteration 181000, loss = 3.4877
I0826 14:06:30.470659  1343 solver.cpp:244]     Train net output #0: loss = 3.4877 (* 1 = 3.4877 loss)
I0826 14:06:30.470676  1343 sgd_solver.cpp:106] Iteration 181000, lr = 1.77164e-07
I0826 14:06:38.908308  1343 solver.cpp:228] Iteration 181100, loss = 3.44257
I0826 14:06:38.908387  1343 solver.cpp:244]     Train net output #0: loss = 3.44257 (* 1 = 3.44257 loss)
I0826 14:06:38.908404  1343 sgd_solver.cpp:106] Iteration 181100, lr = 1.77098e-07
I0826 14:06:47.334250  1343 solver.cpp:228] Iteration 181200, loss = 3.57196
I0826 14:06:47.334334  1343 solver.cpp:244]     Train net output #0: loss = 3.57196 (* 1 = 3.57196 loss)
I0826 14:06:47.334354  1343 sgd_solver.cpp:106] Iteration 181200, lr = 1.77032e-07
I0826 14:06:55.766147  1343 solver.cpp:228] Iteration 181300, loss = 3.35602
I0826 14:06:55.766206  1343 solver.cpp:244]     Train net output #0: loss = 3.35602 (* 1 = 3.35602 loss)
I0826 14:06:55.766216  1343 sgd_solver.cpp:106] Iteration 181300, lr = 1.76966e-07
I0826 14:07:04.192167  1343 solver.cpp:228] Iteration 181400, loss = 3.53282
I0826 14:07:04.192231  1343 solver.cpp:244]     Train net output #0: loss = 3.53282 (* 1 = 3.53282 loss)
I0826 14:07:04.192239  1343 sgd_solver.cpp:106] Iteration 181400, lr = 1.769e-07
I0826 14:07:12.613760  1343 solver.cpp:228] Iteration 181500, loss = 3.31525
I0826 14:07:12.613817  1343 solver.cpp:244]     Train net output #0: loss = 3.31525 (* 1 = 3.31525 loss)
I0826 14:07:12.613828  1343 sgd_solver.cpp:106] Iteration 181500, lr = 1.76834e-07
I0826 14:07:21.041389  1343 solver.cpp:228] Iteration 181600, loss = 3.29074
I0826 14:07:21.041455  1343 solver.cpp:244]     Train net output #0: loss = 3.29074 (* 1 = 3.29074 loss)
I0826 14:07:21.041465  1343 sgd_solver.cpp:106] Iteration 181600, lr = 1.76768e-07
I0826 14:07:29.470504  1343 solver.cpp:228] Iteration 181700, loss = 3.51866
I0826 14:07:29.470571  1343 solver.cpp:244]     Train net output #0: loss = 3.51866 (* 1 = 3.51866 loss)
I0826 14:07:29.470579  1343 sgd_solver.cpp:106] Iteration 181700, lr = 1.76703e-07
I0826 14:07:37.898315  1343 solver.cpp:228] Iteration 181800, loss = 3.23711
I0826 14:07:37.898360  1343 solver.cpp:244]     Train net output #0: loss = 3.23711 (* 1 = 3.23711 loss)
I0826 14:07:37.898366  1343 sgd_solver.cpp:106] Iteration 181800, lr = 1.76637e-07
I0826 14:07:46.331032  1343 solver.cpp:228] Iteration 181900, loss = 3.41696
I0826 14:07:46.331101  1343 solver.cpp:244]     Train net output #0: loss = 3.41696 (* 1 = 3.41696 loss)
I0826 14:07:46.331112  1343 sgd_solver.cpp:106] Iteration 181900, lr = 1.76571e-07
I0826 14:07:54.749305  1343 solver.cpp:228] Iteration 182000, loss = 3.48017
I0826 14:07:54.749379  1343 solver.cpp:244]     Train net output #0: loss = 3.48017 (* 1 = 3.48017 loss)
I0826 14:07:54.749390  1343 sgd_solver.cpp:106] Iteration 182000, lr = 1.76506e-07
I0826 14:08:03.163830  1343 solver.cpp:228] Iteration 182100, loss = 3.44468
I0826 14:08:03.163875  1343 solver.cpp:244]     Train net output #0: loss = 3.44468 (* 1 = 3.44468 loss)
I0826 14:08:03.163880  1343 sgd_solver.cpp:106] Iteration 182100, lr = 1.7644e-07
I0826 14:08:10.159106  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:08:11.587579  1343 solver.cpp:228] Iteration 182200, loss = 3.53713
I0826 14:08:11.587633  1343 solver.cpp:244]     Train net output #0: loss = 3.53713 (* 1 = 3.53713 loss)
I0826 14:08:11.587641  1343 sgd_solver.cpp:106] Iteration 182200, lr = 1.76375e-07
I0826 14:08:20.018204  1343 solver.cpp:228] Iteration 182300, loss = 3.50721
I0826 14:08:20.018261  1343 solver.cpp:244]     Train net output #0: loss = 3.50721 (* 1 = 3.50721 loss)
I0826 14:08:20.018267  1343 sgd_solver.cpp:106] Iteration 182300, lr = 1.76309e-07
I0826 14:08:28.447098  1343 solver.cpp:228] Iteration 182400, loss = 3.45142
I0826 14:08:28.447166  1343 solver.cpp:244]     Train net output #0: loss = 3.45142 (* 1 = 3.45142 loss)
I0826 14:08:28.447177  1343 sgd_solver.cpp:106] Iteration 182400, lr = 1.76244e-07
I0826 14:08:36.876871  1343 solver.cpp:228] Iteration 182500, loss = 3.58853
I0826 14:08:36.876929  1343 solver.cpp:244]     Train net output #0: loss = 3.58853 (* 1 = 3.58853 loss)
I0826 14:08:36.876935  1343 sgd_solver.cpp:106] Iteration 182500, lr = 1.76179e-07
I0826 14:08:45.290496  1343 solver.cpp:228] Iteration 182600, loss = 3.48815
I0826 14:08:45.290542  1343 solver.cpp:244]     Train net output #0: loss = 3.48815 (* 1 = 3.48815 loss)
I0826 14:08:45.290547  1343 sgd_solver.cpp:106] Iteration 182600, lr = 1.76114e-07
I0826 14:08:53.719748  1343 solver.cpp:228] Iteration 182700, loss = 3.2715
I0826 14:08:53.719810  1343 solver.cpp:244]     Train net output #0: loss = 3.2715 (* 1 = 3.2715 loss)
I0826 14:08:53.719820  1343 sgd_solver.cpp:106] Iteration 182700, lr = 1.76048e-07
I0826 14:09:02.143957  1343 solver.cpp:228] Iteration 182800, loss = 3.36614
I0826 14:09:02.144028  1343 solver.cpp:244]     Train net output #0: loss = 3.36614 (* 1 = 3.36614 loss)
I0826 14:09:02.144037  1343 sgd_solver.cpp:106] Iteration 182800, lr = 1.75983e-07
I0826 14:09:10.576196  1343 solver.cpp:228] Iteration 182900, loss = 3.21732
I0826 14:09:10.576263  1343 solver.cpp:244]     Train net output #0: loss = 3.21732 (* 1 = 3.21732 loss)
I0826 14:09:10.576272  1343 sgd_solver.cpp:106] Iteration 182900, lr = 1.75918e-07
I0826 14:09:19.006106  1343 solver.cpp:228] Iteration 183000, loss = 3.31971
I0826 14:09:19.006150  1343 solver.cpp:244]     Train net output #0: loss = 3.31971 (* 1 = 3.31971 loss)
I0826 14:09:19.006155  1343 sgd_solver.cpp:106] Iteration 183000, lr = 1.75853e-07
I0826 14:09:27.431429  1343 solver.cpp:228] Iteration 183100, loss = 3.38302
I0826 14:09:27.431496  1343 solver.cpp:244]     Train net output #0: loss = 3.38302 (* 1 = 3.38302 loss)
I0826 14:09:27.431506  1343 sgd_solver.cpp:106] Iteration 183100, lr = 1.75788e-07
I0826 14:09:35.862282  1343 solver.cpp:228] Iteration 183200, loss = 3.40084
I0826 14:09:35.862340  1343 solver.cpp:244]     Train net output #0: loss = 3.40084 (* 1 = 3.40084 loss)
I0826 14:09:35.862352  1343 sgd_solver.cpp:106] Iteration 183200, lr = 1.75723e-07
I0826 14:09:44.287209  1343 solver.cpp:228] Iteration 183300, loss = 3.47352
I0826 14:09:44.287262  1343 solver.cpp:244]     Train net output #0: loss = 3.47352 (* 1 = 3.47352 loss)
I0826 14:09:44.287269  1343 sgd_solver.cpp:106] Iteration 183300, lr = 1.75659e-07
I0826 14:09:52.708328  1343 solver.cpp:228] Iteration 183400, loss = 3.32837
I0826 14:09:52.708396  1343 solver.cpp:244]     Train net output #0: loss = 3.32837 (* 1 = 3.32837 loss)
I0826 14:09:52.708406  1343 sgd_solver.cpp:106] Iteration 183400, lr = 1.75594e-07
I0826 14:10:01.134954  1343 solver.cpp:228] Iteration 183500, loss = 3.5693
I0826 14:10:01.135025  1343 solver.cpp:244]     Train net output #0: loss = 3.5693 (* 1 = 3.5693 loss)
I0826 14:10:01.135035  1343 sgd_solver.cpp:106] Iteration 183500, lr = 1.75529e-07
I0826 14:10:09.552206  1343 solver.cpp:228] Iteration 183600, loss = 3.29182
I0826 14:10:09.552274  1343 solver.cpp:244]     Train net output #0: loss = 3.29182 (* 1 = 3.29182 loss)
I0826 14:10:09.552284  1343 sgd_solver.cpp:106] Iteration 183600, lr = 1.75464e-07
I0826 14:10:17.974447  1343 solver.cpp:228] Iteration 183700, loss = 3.34199
I0826 14:10:17.974503  1343 solver.cpp:244]     Train net output #0: loss = 3.34199 (* 1 = 3.34199 loss)
I0826 14:10:17.974511  1343 sgd_solver.cpp:106] Iteration 183700, lr = 1.754e-07
I0826 14:10:26.398172  1343 solver.cpp:228] Iteration 183800, loss = 3.48332
I0826 14:10:26.398227  1343 solver.cpp:244]     Train net output #0: loss = 3.48332 (* 1 = 3.48332 loss)
I0826 14:10:26.398236  1343 sgd_solver.cpp:106] Iteration 183800, lr = 1.75335e-07
I0826 14:10:34.834573  1343 solver.cpp:228] Iteration 183900, loss = 3.45207
I0826 14:10:34.834638  1343 solver.cpp:244]     Train net output #0: loss = 3.45207 (* 1 = 3.45207 loss)
I0826 14:10:34.834648  1343 sgd_solver.cpp:106] Iteration 183900, lr = 1.75271e-07
I0826 14:10:43.276196  1343 solver.cpp:228] Iteration 184000, loss = 3.47918
I0826 14:10:43.276255  1343 solver.cpp:244]     Train net output #0: loss = 3.47918 (* 1 = 3.47918 loss)
I0826 14:10:43.276264  1343 sgd_solver.cpp:106] Iteration 184000, lr = 1.75206e-07
I0826 14:10:51.709496  1343 solver.cpp:228] Iteration 184100, loss = 3.50914
I0826 14:10:51.709549  1343 solver.cpp:244]     Train net output #0: loss = 3.50914 (* 1 = 3.50914 loss)
I0826 14:10:51.709558  1343 sgd_solver.cpp:106] Iteration 184100, lr = 1.75142e-07
I0826 14:11:00.139355  1343 solver.cpp:228] Iteration 184200, loss = 3.47255
I0826 14:11:00.139425  1343 solver.cpp:244]     Train net output #0: loss = 3.47255 (* 1 = 3.47255 loss)
I0826 14:11:00.139436  1343 sgd_solver.cpp:106] Iteration 184200, lr = 1.75078e-07
I0826 14:11:08.567735  1343 solver.cpp:228] Iteration 184300, loss = 3.52612
I0826 14:11:08.567796  1343 solver.cpp:244]     Train net output #0: loss = 3.52612 (* 1 = 3.52612 loss)
I0826 14:11:08.567806  1343 sgd_solver.cpp:106] Iteration 184300, lr = 1.75013e-07
I0826 14:11:16.987857  1343 solver.cpp:228] Iteration 184400, loss = 3.47406
I0826 14:11:16.987926  1343 solver.cpp:244]     Train net output #0: loss = 3.47406 (* 1 = 3.47406 loss)
I0826 14:11:16.987946  1343 sgd_solver.cpp:106] Iteration 184400, lr = 1.74949e-07
I0826 14:11:25.411504  1343 solver.cpp:228] Iteration 184500, loss = 3.65931
I0826 14:11:25.411558  1343 solver.cpp:244]     Train net output #0: loss = 3.65931 (* 1 = 3.65931 loss)
I0826 14:11:25.411566  1343 sgd_solver.cpp:106] Iteration 184500, lr = 1.74885e-07
I0826 14:11:33.846611  1343 solver.cpp:228] Iteration 184600, loss = 3.42383
I0826 14:11:33.846679  1343 solver.cpp:244]     Train net output #0: loss = 3.42383 (* 1 = 3.42383 loss)
I0826 14:11:33.846690  1343 sgd_solver.cpp:106] Iteration 184600, lr = 1.74821e-07
I0826 14:11:42.274950  1343 solver.cpp:228] Iteration 184700, loss = 3.48333
I0826 14:11:42.275014  1343 solver.cpp:244]     Train net output #0: loss = 3.48333 (* 1 = 3.48333 loss)
I0826 14:11:42.275024  1343 sgd_solver.cpp:106] Iteration 184700, lr = 1.74757e-07
I0826 14:11:50.695374  1343 solver.cpp:228] Iteration 184800, loss = 3.28245
I0826 14:11:50.695417  1343 solver.cpp:244]     Train net output #0: loss = 3.28245 (* 1 = 3.28245 loss)
I0826 14:11:50.695423  1343 sgd_solver.cpp:106] Iteration 184800, lr = 1.74693e-07
I0826 14:11:59.121203  1343 solver.cpp:228] Iteration 184900, loss = 3.52112
I0826 14:11:59.121268  1343 solver.cpp:244]     Train net output #0: loss = 3.52112 (* 1 = 3.52112 loss)
I0826 14:11:59.121279  1343 sgd_solver.cpp:106] Iteration 184900, lr = 1.74629e-07
I0826 14:12:07.472838  1343 solver.cpp:337] Iteration 185000, Testing net (#0)
I0826 14:12:18.487581  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:12:43.347117  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302007
I0826 14:12:43.347182  1343 solver.cpp:404]     Test net output #1: loss = 3.41683 (* 1 = 3.41683 loss)
I0826 14:12:43.377698  1343 solver.cpp:228] Iteration 185000, loss = 3.35519
I0826 14:12:43.377743  1343 solver.cpp:244]     Train net output #0: loss = 3.35519 (* 1 = 3.35519 loss)
I0826 14:12:43.377755  1343 sgd_solver.cpp:106] Iteration 185000, lr = 1.74565e-07
I0826 14:12:51.825899  1343 solver.cpp:228] Iteration 185100, loss = 3.43489
I0826 14:12:51.826004  1343 solver.cpp:244]     Train net output #0: loss = 3.43489 (* 1 = 3.43489 loss)
I0826 14:12:51.826017  1343 sgd_solver.cpp:106] Iteration 185100, lr = 1.74501e-07
I0826 14:13:00.251363  1343 solver.cpp:228] Iteration 185200, loss = 3.44203
I0826 14:13:00.251401  1343 solver.cpp:244]     Train net output #0: loss = 3.44203 (* 1 = 3.44203 loss)
I0826 14:13:00.251407  1343 sgd_solver.cpp:106] Iteration 185200, lr = 1.74437e-07
I0826 14:13:08.664638  1343 solver.cpp:228] Iteration 185300, loss = 3.54659
I0826 14:13:08.664680  1343 solver.cpp:244]     Train net output #0: loss = 3.54659 (* 1 = 3.54659 loss)
I0826 14:13:08.664685  1343 sgd_solver.cpp:106] Iteration 185300, lr = 1.74374e-07
I0826 14:13:17.078752  1343 solver.cpp:228] Iteration 185400, loss = 3.46
I0826 14:13:17.078794  1343 solver.cpp:244]     Train net output #0: loss = 3.46 (* 1 = 3.46 loss)
I0826 14:13:17.078799  1343 sgd_solver.cpp:106] Iteration 185400, lr = 1.7431e-07
I0826 14:13:25.496412  1343 solver.cpp:228] Iteration 185500, loss = 3.41211
I0826 14:13:25.496449  1343 solver.cpp:244]     Train net output #0: loss = 3.41211 (* 1 = 3.41211 loss)
I0826 14:13:25.496454  1343 sgd_solver.cpp:106] Iteration 185500, lr = 1.74246e-07
I0826 14:13:33.917577  1343 solver.cpp:228] Iteration 185600, loss = 3.50279
I0826 14:13:33.917631  1343 solver.cpp:244]     Train net output #0: loss = 3.50279 (* 1 = 3.50279 loss)
I0826 14:13:33.917639  1343 sgd_solver.cpp:106] Iteration 185600, lr = 1.74183e-07
I0826 14:13:42.342530  1343 solver.cpp:228] Iteration 185700, loss = 3.4582
I0826 14:13:42.342574  1343 solver.cpp:244]     Train net output #0: loss = 3.4582 (* 1 = 3.4582 loss)
I0826 14:13:42.342581  1343 sgd_solver.cpp:106] Iteration 185700, lr = 1.74119e-07
I0826 14:13:50.769825  1343 solver.cpp:228] Iteration 185800, loss = 3.49562
I0826 14:13:50.769886  1343 solver.cpp:244]     Train net output #0: loss = 3.49562 (* 1 = 3.49562 loss)
I0826 14:13:50.769893  1343 sgd_solver.cpp:106] Iteration 185800, lr = 1.74056e-07
I0826 14:13:59.197569  1343 solver.cpp:228] Iteration 185900, loss = 3.32286
I0826 14:13:59.197620  1343 solver.cpp:244]     Train net output #0: loss = 3.32286 (* 1 = 3.32286 loss)
I0826 14:13:59.197628  1343 sgd_solver.cpp:106] Iteration 185900, lr = 1.73992e-07
I0826 14:14:07.626348  1343 solver.cpp:228] Iteration 186000, loss = 3.42716
I0826 14:14:07.626415  1343 solver.cpp:244]     Train net output #0: loss = 3.42716 (* 1 = 3.42716 loss)
I0826 14:14:07.626427  1343 sgd_solver.cpp:106] Iteration 186000, lr = 1.73929e-07
I0826 14:14:16.055239  1343 solver.cpp:228] Iteration 186100, loss = 3.43796
I0826 14:14:16.055295  1343 solver.cpp:244]     Train net output #0: loss = 3.43796 (* 1 = 3.43796 loss)
I0826 14:14:16.055305  1343 sgd_solver.cpp:106] Iteration 186100, lr = 1.73866e-07
I0826 14:14:24.473320  1343 solver.cpp:228] Iteration 186200, loss = 3.46652
I0826 14:14:24.473362  1343 solver.cpp:244]     Train net output #0: loss = 3.46652 (* 1 = 3.46652 loss)
I0826 14:14:24.473367  1343 sgd_solver.cpp:106] Iteration 186200, lr = 1.73803e-07
I0826 14:14:32.915010  1343 solver.cpp:228] Iteration 186300, loss = 3.456
I0826 14:14:32.915053  1343 solver.cpp:244]     Train net output #0: loss = 3.456 (* 1 = 3.456 loss)
I0826 14:14:32.915060  1343 sgd_solver.cpp:106] Iteration 186300, lr = 1.73739e-07
I0826 14:14:41.330934  1343 solver.cpp:228] Iteration 186400, loss = 3.47061
I0826 14:14:41.330986  1343 solver.cpp:244]     Train net output #0: loss = 3.47061 (* 1 = 3.47061 loss)
I0826 14:14:41.330993  1343 sgd_solver.cpp:106] Iteration 186400, lr = 1.73676e-07
I0826 14:14:49.763173  1343 solver.cpp:228] Iteration 186500, loss = 3.51883
I0826 14:14:49.763227  1343 solver.cpp:244]     Train net output #0: loss = 3.51883 (* 1 = 3.51883 loss)
I0826 14:14:49.763234  1343 sgd_solver.cpp:106] Iteration 186500, lr = 1.73613e-07
I0826 14:14:58.199739  1343 solver.cpp:228] Iteration 186600, loss = 3.25602
I0826 14:14:58.199808  1343 solver.cpp:244]     Train net output #0: loss = 3.25602 (* 1 = 3.25602 loss)
I0826 14:14:58.199816  1343 sgd_solver.cpp:106] Iteration 186600, lr = 1.7355e-07
I0826 14:15:06.621389  1343 solver.cpp:228] Iteration 186700, loss = 3.52624
I0826 14:15:06.621449  1343 solver.cpp:244]     Train net output #0: loss = 3.52624 (* 1 = 3.52624 loss)
I0826 14:15:06.621457  1343 sgd_solver.cpp:106] Iteration 186700, lr = 1.73487e-07
I0826 14:15:15.062667  1343 solver.cpp:228] Iteration 186800, loss = 3.61403
I0826 14:15:15.062728  1343 solver.cpp:244]     Train net output #0: loss = 3.61403 (* 1 = 3.61403 loss)
I0826 14:15:15.062736  1343 sgd_solver.cpp:106] Iteration 186800, lr = 1.73424e-07
I0826 14:15:23.497383  1343 solver.cpp:228] Iteration 186900, loss = 3.33754
I0826 14:15:23.497442  1343 solver.cpp:244]     Train net output #0: loss = 3.33754 (* 1 = 3.33754 loss)
I0826 14:15:23.497450  1343 sgd_solver.cpp:106] Iteration 186900, lr = 1.73361e-07
I0826 14:15:31.929858  1343 solver.cpp:228] Iteration 187000, loss = 3.25069
I0826 14:15:31.929918  1343 solver.cpp:244]     Train net output #0: loss = 3.25069 (* 1 = 3.25069 loss)
I0826 14:15:31.929924  1343 sgd_solver.cpp:106] Iteration 187000, lr = 1.73298e-07
I0826 14:15:40.373124  1343 solver.cpp:228] Iteration 187100, loss = 3.46639
I0826 14:15:40.373189  1343 solver.cpp:244]     Train net output #0: loss = 3.46639 (* 1 = 3.46639 loss)
I0826 14:15:40.373200  1343 sgd_solver.cpp:106] Iteration 187100, lr = 1.73236e-07
I0826 14:15:48.789508  1343 solver.cpp:228] Iteration 187200, loss = 3.53371
I0826 14:15:48.789572  1343 solver.cpp:244]     Train net output #0: loss = 3.53371 (* 1 = 3.53371 loss)
I0826 14:15:48.789582  1343 sgd_solver.cpp:106] Iteration 187200, lr = 1.73173e-07
I0826 14:15:57.233366  1343 solver.cpp:228] Iteration 187300, loss = 3.28015
I0826 14:15:57.233408  1343 solver.cpp:244]     Train net output #0: loss = 3.28015 (* 1 = 3.28015 loss)
I0826 14:15:57.233414  1343 sgd_solver.cpp:106] Iteration 187300, lr = 1.7311e-07
I0826 14:16:05.652678  1343 solver.cpp:228] Iteration 187400, loss = 3.33116
I0826 14:16:05.652734  1343 solver.cpp:244]     Train net output #0: loss = 3.33116 (* 1 = 3.33116 loss)
I0826 14:16:05.652741  1343 sgd_solver.cpp:106] Iteration 187400, lr = 1.73048e-07
I0826 14:16:14.081418  1343 solver.cpp:228] Iteration 187500, loss = 3.35567
I0826 14:16:14.081480  1343 solver.cpp:244]     Train net output #0: loss = 3.35567 (* 1 = 3.35567 loss)
I0826 14:16:14.081486  1343 sgd_solver.cpp:106] Iteration 187500, lr = 1.72985e-07
I0826 14:16:22.517369  1343 solver.cpp:228] Iteration 187600, loss = 3.24305
I0826 14:16:22.517439  1343 solver.cpp:244]     Train net output #0: loss = 3.24305 (* 1 = 3.24305 loss)
I0826 14:16:22.517449  1343 sgd_solver.cpp:106] Iteration 187600, lr = 1.72923e-07
I0826 14:16:30.929365  1343 solver.cpp:228] Iteration 187700, loss = 3.32969
I0826 14:16:30.929425  1343 solver.cpp:244]     Train net output #0: loss = 3.32969 (* 1 = 3.32969 loss)
I0826 14:16:30.929436  1343 sgd_solver.cpp:106] Iteration 187700, lr = 1.7286e-07
I0826 14:16:39.354936  1343 solver.cpp:228] Iteration 187800, loss = 3.41911
I0826 14:16:39.354977  1343 solver.cpp:244]     Train net output #0: loss = 3.41911 (* 1 = 3.41911 loss)
I0826 14:16:39.354984  1343 sgd_solver.cpp:106] Iteration 187800, lr = 1.72798e-07
I0826 14:16:47.777354  1343 solver.cpp:228] Iteration 187900, loss = 3.38631
I0826 14:16:47.777427  1343 solver.cpp:244]     Train net output #0: loss = 3.38631 (* 1 = 3.38631 loss)
I0826 14:16:47.777436  1343 sgd_solver.cpp:106] Iteration 187900, lr = 1.72736e-07
I0826 14:16:56.211311  1343 solver.cpp:228] Iteration 188000, loss = 3.24389
I0826 14:16:56.211354  1343 solver.cpp:244]     Train net output #0: loss = 3.24389 (* 1 = 3.24389 loss)
I0826 14:16:56.211360  1343 sgd_solver.cpp:106] Iteration 188000, lr = 1.72673e-07
I0826 14:17:04.308611  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:17:04.645022  1343 solver.cpp:228] Iteration 188100, loss = 3.39635
I0826 14:17:04.645087  1343 solver.cpp:244]     Train net output #0: loss = 3.39635 (* 1 = 3.39635 loss)
I0826 14:17:04.645105  1343 sgd_solver.cpp:106] Iteration 188100, lr = 1.72611e-07
I0826 14:17:13.079349  1343 solver.cpp:228] Iteration 188200, loss = 3.47538
I0826 14:17:13.079409  1343 solver.cpp:244]     Train net output #0: loss = 3.47538 (* 1 = 3.47538 loss)
I0826 14:17:13.079419  1343 sgd_solver.cpp:106] Iteration 188200, lr = 1.72549e-07
I0826 14:17:21.510995  1343 solver.cpp:228] Iteration 188300, loss = 3.31245
I0826 14:17:21.511037  1343 solver.cpp:244]     Train net output #0: loss = 3.31245 (* 1 = 3.31245 loss)
I0826 14:17:21.511044  1343 sgd_solver.cpp:106] Iteration 188300, lr = 1.72487e-07
I0826 14:17:29.916610  1343 solver.cpp:228] Iteration 188400, loss = 3.3839
I0826 14:17:29.916683  1343 solver.cpp:244]     Train net output #0: loss = 3.3839 (* 1 = 3.3839 loss)
I0826 14:17:29.916697  1343 sgd_solver.cpp:106] Iteration 188400, lr = 1.72425e-07
I0826 14:17:38.339046  1343 solver.cpp:228] Iteration 188500, loss = 3.56873
I0826 14:17:38.339107  1343 solver.cpp:244]     Train net output #0: loss = 3.56873 (* 1 = 3.56873 loss)
I0826 14:17:38.339118  1343 sgd_solver.cpp:106] Iteration 188500, lr = 1.72363e-07
I0826 14:17:46.775532  1343 solver.cpp:228] Iteration 188600, loss = 3.36751
I0826 14:17:46.775573  1343 solver.cpp:244]     Train net output #0: loss = 3.36751 (* 1 = 3.36751 loss)
I0826 14:17:46.775579  1343 sgd_solver.cpp:106] Iteration 188600, lr = 1.72301e-07
I0826 14:17:55.205184  1343 solver.cpp:228] Iteration 188700, loss = 3.31899
I0826 14:17:55.205238  1343 solver.cpp:244]     Train net output #0: loss = 3.31899 (* 1 = 3.31899 loss)
I0826 14:17:55.205248  1343 sgd_solver.cpp:106] Iteration 188700, lr = 1.72239e-07
I0826 14:18:03.618088  1343 solver.cpp:228] Iteration 188800, loss = 3.4611
I0826 14:18:03.618144  1343 solver.cpp:244]     Train net output #0: loss = 3.4611 (* 1 = 3.4611 loss)
I0826 14:18:03.618149  1343 sgd_solver.cpp:106] Iteration 188800, lr = 1.72177e-07
I0826 14:18:12.057209  1343 solver.cpp:228] Iteration 188900, loss = 3.42763
I0826 14:18:12.057250  1343 solver.cpp:244]     Train net output #0: loss = 3.42763 (* 1 = 3.42763 loss)
I0826 14:18:12.057256  1343 sgd_solver.cpp:106] Iteration 188900, lr = 1.72115e-07
I0826 14:18:20.459076  1343 solver.cpp:228] Iteration 189000, loss = 3.39556
I0826 14:18:20.459138  1343 solver.cpp:244]     Train net output #0: loss = 3.39556 (* 1 = 3.39556 loss)
I0826 14:18:20.459146  1343 sgd_solver.cpp:106] Iteration 189000, lr = 1.72053e-07
I0826 14:18:28.891333  1343 solver.cpp:228] Iteration 189100, loss = 3.448
I0826 14:18:28.891396  1343 solver.cpp:244]     Train net output #0: loss = 3.448 (* 1 = 3.448 loss)
I0826 14:18:28.891408  1343 sgd_solver.cpp:106] Iteration 189100, lr = 1.71992e-07
I0826 14:18:37.307881  1343 solver.cpp:228] Iteration 189200, loss = 3.18805
I0826 14:18:37.307924  1343 solver.cpp:244]     Train net output #0: loss = 3.18805 (* 1 = 3.18805 loss)
I0826 14:18:37.307929  1343 sgd_solver.cpp:106] Iteration 189200, lr = 1.7193e-07
I0826 14:18:45.731305  1343 solver.cpp:228] Iteration 189300, loss = 3.41006
I0826 14:18:45.731344  1343 solver.cpp:244]     Train net output #0: loss = 3.41006 (* 1 = 3.41006 loss)
I0826 14:18:45.731349  1343 sgd_solver.cpp:106] Iteration 189300, lr = 1.71868e-07
I0826 14:18:54.148344  1343 solver.cpp:228] Iteration 189400, loss = 3.29456
I0826 14:18:54.148404  1343 solver.cpp:244]     Train net output #0: loss = 3.29456 (* 1 = 3.29456 loss)
I0826 14:18:54.148412  1343 sgd_solver.cpp:106] Iteration 189400, lr = 1.71807e-07
I0826 14:19:02.567898  1343 solver.cpp:228] Iteration 189500, loss = 3.43479
I0826 14:19:02.567939  1343 solver.cpp:244]     Train net output #0: loss = 3.43479 (* 1 = 3.43479 loss)
I0826 14:19:02.567945  1343 sgd_solver.cpp:106] Iteration 189500, lr = 1.71745e-07
I0826 14:19:10.991907  1343 solver.cpp:228] Iteration 189600, loss = 3.42288
I0826 14:19:10.991950  1343 solver.cpp:244]     Train net output #0: loss = 3.42288 (* 1 = 3.42288 loss)
I0826 14:19:10.991961  1343 sgd_solver.cpp:106] Iteration 189600, lr = 1.71684e-07
I0826 14:19:19.413633  1343 solver.cpp:228] Iteration 189700, loss = 3.53018
I0826 14:19:19.413676  1343 solver.cpp:244]     Train net output #0: loss = 3.53018 (* 1 = 3.53018 loss)
I0826 14:19:19.413682  1343 sgd_solver.cpp:106] Iteration 189700, lr = 1.71622e-07
I0826 14:19:27.849367  1343 solver.cpp:228] Iteration 189800, loss = 3.30101
I0826 14:19:27.849426  1343 solver.cpp:244]     Train net output #0: loss = 3.30101 (* 1 = 3.30101 loss)
I0826 14:19:27.849436  1343 sgd_solver.cpp:106] Iteration 189800, lr = 1.71561e-07
I0826 14:19:36.273044  1343 solver.cpp:228] Iteration 189900, loss = 3.33588
I0826 14:19:36.273103  1343 solver.cpp:244]     Train net output #0: loss = 3.33588 (* 1 = 3.33588 loss)
I0826 14:19:36.273113  1343 sgd_solver.cpp:106] Iteration 189900, lr = 1.715e-07
I0826 14:19:44.614501  1343 solver.cpp:337] Iteration 190000, Testing net (#0)
I0826 14:20:19.546267  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:20:20.031440  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302051
I0826 14:20:20.031532  1343 solver.cpp:404]     Test net output #1: loss = 3.41564 (* 1 = 3.41564 loss)
I0826 14:20:20.060931  1343 solver.cpp:228] Iteration 190000, loss = 3.45169
I0826 14:20:20.060977  1343 solver.cpp:244]     Train net output #0: loss = 3.45169 (* 1 = 3.45169 loss)
I0826 14:20:20.060989  1343 sgd_solver.cpp:106] Iteration 190000, lr = 1.71438e-07
I0826 14:20:28.491937  1343 solver.cpp:228] Iteration 190100, loss = 3.37985
I0826 14:20:28.492019  1343 solver.cpp:244]     Train net output #0: loss = 3.37985 (* 1 = 3.37985 loss)
I0826 14:20:28.492033  1343 sgd_solver.cpp:106] Iteration 190100, lr = 1.71377e-07
I0826 14:20:36.924065  1343 solver.cpp:228] Iteration 190200, loss = 3.61025
I0826 14:20:36.924150  1343 solver.cpp:244]     Train net output #0: loss = 3.61025 (* 1 = 3.61025 loss)
I0826 14:20:36.924162  1343 sgd_solver.cpp:106] Iteration 190200, lr = 1.71316e-07
I0826 14:20:45.343267  1343 solver.cpp:228] Iteration 190300, loss = 3.23394
I0826 14:20:45.343315  1343 solver.cpp:244]     Train net output #0: loss = 3.23394 (* 1 = 3.23394 loss)
I0826 14:20:45.343324  1343 sgd_solver.cpp:106] Iteration 190300, lr = 1.71255e-07
I0826 14:20:53.762585  1343 solver.cpp:228] Iteration 190400, loss = 3.42042
I0826 14:20:53.762650  1343 solver.cpp:244]     Train net output #0: loss = 3.42042 (* 1 = 3.42042 loss)
I0826 14:20:53.762663  1343 sgd_solver.cpp:106] Iteration 190400, lr = 1.71194e-07
I0826 14:21:02.182521  1343 solver.cpp:228] Iteration 190500, loss = 3.48536
I0826 14:21:02.182595  1343 solver.cpp:244]     Train net output #0: loss = 3.48536 (* 1 = 3.48536 loss)
I0826 14:21:02.182605  1343 sgd_solver.cpp:106] Iteration 190500, lr = 1.71133e-07
I0826 14:21:10.606218  1343 solver.cpp:228] Iteration 190600, loss = 3.32375
I0826 14:21:10.606287  1343 solver.cpp:244]     Train net output #0: loss = 3.32375 (* 1 = 3.32375 loss)
I0826 14:21:10.606297  1343 sgd_solver.cpp:106] Iteration 190600, lr = 1.71072e-07
I0826 14:21:19.045145  1343 solver.cpp:228] Iteration 190700, loss = 3.36985
I0826 14:21:19.045210  1343 solver.cpp:244]     Train net output #0: loss = 3.36985 (* 1 = 3.36985 loss)
I0826 14:21:19.045222  1343 sgd_solver.cpp:106] Iteration 190700, lr = 1.71011e-07
I0826 14:21:27.476254  1343 solver.cpp:228] Iteration 190800, loss = 3.39223
I0826 14:21:27.476320  1343 solver.cpp:244]     Train net output #0: loss = 3.39223 (* 1 = 3.39223 loss)
I0826 14:21:27.476331  1343 sgd_solver.cpp:106] Iteration 190800, lr = 1.7095e-07
I0826 14:21:35.898368  1343 solver.cpp:228] Iteration 190900, loss = 3.38405
I0826 14:21:35.898416  1343 solver.cpp:244]     Train net output #0: loss = 3.38405 (* 1 = 3.38405 loss)
I0826 14:21:35.898422  1343 sgd_solver.cpp:106] Iteration 190900, lr = 1.70889e-07
I0826 14:21:44.311796  1343 solver.cpp:228] Iteration 191000, loss = 3.3574
I0826 14:21:44.311861  1343 solver.cpp:244]     Train net output #0: loss = 3.3574 (* 1 = 3.3574 loss)
I0826 14:21:44.311866  1343 sgd_solver.cpp:106] Iteration 191000, lr = 1.70829e-07
I0826 14:21:52.742535  1343 solver.cpp:228] Iteration 191100, loss = 3.39913
I0826 14:21:52.742594  1343 solver.cpp:244]     Train net output #0: loss = 3.39913 (* 1 = 3.39913 loss)
I0826 14:21:52.742605  1343 sgd_solver.cpp:106] Iteration 191100, lr = 1.70768e-07
I0826 14:22:01.171108  1343 solver.cpp:228] Iteration 191200, loss = 3.43121
I0826 14:22:01.171154  1343 solver.cpp:244]     Train net output #0: loss = 3.43121 (* 1 = 3.43121 loss)
I0826 14:22:01.171159  1343 sgd_solver.cpp:106] Iteration 191200, lr = 1.70707e-07
I0826 14:22:09.592927  1343 solver.cpp:228] Iteration 191300, loss = 3.62482
I0826 14:22:09.592978  1343 solver.cpp:244]     Train net output #0: loss = 3.62482 (* 1 = 3.62482 loss)
I0826 14:22:09.592988  1343 sgd_solver.cpp:106] Iteration 191300, lr = 1.70647e-07
I0826 14:22:18.007180  1343 solver.cpp:228] Iteration 191400, loss = 3.34794
I0826 14:22:18.007251  1343 solver.cpp:244]     Train net output #0: loss = 3.34794 (* 1 = 3.34794 loss)
I0826 14:22:18.007261  1343 sgd_solver.cpp:106] Iteration 191400, lr = 1.70586e-07
I0826 14:22:26.431295  1343 solver.cpp:228] Iteration 191500, loss = 3.54074
I0826 14:22:26.431355  1343 solver.cpp:244]     Train net output #0: loss = 3.54074 (* 1 = 3.54074 loss)
I0826 14:22:26.431366  1343 sgd_solver.cpp:106] Iteration 191500, lr = 1.70526e-07
I0826 14:22:34.859834  1343 solver.cpp:228] Iteration 191600, loss = 3.44309
I0826 14:22:34.859901  1343 solver.cpp:244]     Train net output #0: loss = 3.44309 (* 1 = 3.44309 loss)
I0826 14:22:34.859912  1343 sgd_solver.cpp:106] Iteration 191600, lr = 1.70465e-07
I0826 14:22:43.291476  1343 solver.cpp:228] Iteration 191700, loss = 3.37834
I0826 14:22:43.291534  1343 solver.cpp:244]     Train net output #0: loss = 3.37834 (* 1 = 3.37834 loss)
I0826 14:22:43.291545  1343 sgd_solver.cpp:106] Iteration 191700, lr = 1.70405e-07
I0826 14:22:51.728005  1343 solver.cpp:228] Iteration 191800, loss = 3.58724
I0826 14:22:51.728075  1343 solver.cpp:244]     Train net output #0: loss = 3.58724 (* 1 = 3.58724 loss)
I0826 14:22:51.728086  1343 sgd_solver.cpp:106] Iteration 191800, lr = 1.70344e-07
I0826 14:23:00.140709  1343 solver.cpp:228] Iteration 191900, loss = 3.48638
I0826 14:23:00.140768  1343 solver.cpp:244]     Train net output #0: loss = 3.48638 (* 1 = 3.48638 loss)
I0826 14:23:00.140776  1343 sgd_solver.cpp:106] Iteration 191900, lr = 1.70284e-07
I0826 14:23:08.551290  1343 solver.cpp:228] Iteration 192000, loss = 3.38682
I0826 14:23:08.551345  1343 solver.cpp:244]     Train net output #0: loss = 3.38682 (* 1 = 3.38682 loss)
I0826 14:23:08.551352  1343 sgd_solver.cpp:106] Iteration 192000, lr = 1.70224e-07
I0826 14:23:16.973237  1343 solver.cpp:228] Iteration 192100, loss = 3.431
I0826 14:23:16.973279  1343 solver.cpp:244]     Train net output #0: loss = 3.431 (* 1 = 3.431 loss)
I0826 14:23:16.973284  1343 sgd_solver.cpp:106] Iteration 192100, lr = 1.70164e-07
I0826 14:23:25.399281  1343 solver.cpp:228] Iteration 192200, loss = 3.38928
I0826 14:23:25.399350  1343 solver.cpp:244]     Train net output #0: loss = 3.38928 (* 1 = 3.38928 loss)
I0826 14:23:25.399359  1343 sgd_solver.cpp:106] Iteration 192200, lr = 1.70104e-07
I0826 14:23:33.810216  1343 solver.cpp:228] Iteration 192300, loss = 3.45665
I0826 14:23:33.810264  1343 solver.cpp:244]     Train net output #0: loss = 3.45665 (* 1 = 3.45665 loss)
I0826 14:23:33.810273  1343 sgd_solver.cpp:106] Iteration 192300, lr = 1.70043e-07
I0826 14:23:42.239131  1343 solver.cpp:228] Iteration 192400, loss = 3.3052
I0826 14:23:42.239209  1343 solver.cpp:244]     Train net output #0: loss = 3.3052 (* 1 = 3.3052 loss)
I0826 14:23:42.239223  1343 sgd_solver.cpp:106] Iteration 192400, lr = 1.69983e-07
I0826 14:23:50.665406  1343 solver.cpp:228] Iteration 192500, loss = 3.39398
I0826 14:23:50.665470  1343 solver.cpp:244]     Train net output #0: loss = 3.39398 (* 1 = 3.39398 loss)
I0826 14:23:50.665482  1343 sgd_solver.cpp:106] Iteration 192500, lr = 1.69923e-07
I0826 14:23:59.096503  1343 solver.cpp:228] Iteration 192600, loss = 3.39662
I0826 14:23:59.096555  1343 solver.cpp:244]     Train net output #0: loss = 3.39662 (* 1 = 3.39662 loss)
I0826 14:23:59.096561  1343 sgd_solver.cpp:106] Iteration 192600, lr = 1.69863e-07
I0826 14:24:07.524312  1343 solver.cpp:228] Iteration 192700, loss = 3.34469
I0826 14:24:07.524374  1343 solver.cpp:244]     Train net output #0: loss = 3.34469 (* 1 = 3.34469 loss)
I0826 14:24:07.524385  1343 sgd_solver.cpp:106] Iteration 192700, lr = 1.69804e-07
I0826 14:24:15.926545  1343 solver.cpp:228] Iteration 192800, loss = 3.33741
I0826 14:24:15.926615  1343 solver.cpp:244]     Train net output #0: loss = 3.33741 (* 1 = 3.33741 loss)
I0826 14:24:15.926626  1343 sgd_solver.cpp:106] Iteration 192800, lr = 1.69744e-07
I0826 14:24:24.346679  1343 solver.cpp:228] Iteration 192900, loss = 3.56771
I0826 14:24:24.346740  1343 solver.cpp:244]     Train net output #0: loss = 3.56771 (* 1 = 3.56771 loss)
I0826 14:24:24.346748  1343 sgd_solver.cpp:106] Iteration 192900, lr = 1.69684e-07
I0826 14:24:32.773758  1343 solver.cpp:228] Iteration 193000, loss = 3.33771
I0826 14:24:32.773823  1343 solver.cpp:244]     Train net output #0: loss = 3.33771 (* 1 = 3.33771 loss)
I0826 14:24:32.773833  1343 sgd_solver.cpp:106] Iteration 193000, lr = 1.69624e-07
I0826 14:24:41.208714  1343 solver.cpp:228] Iteration 193100, loss = 3.53356
I0826 14:24:41.208761  1343 solver.cpp:244]     Train net output #0: loss = 3.53356 (* 1 = 3.53356 loss)
I0826 14:24:41.208770  1343 sgd_solver.cpp:106] Iteration 193100, lr = 1.69564e-07
I0826 14:24:49.625802  1343 solver.cpp:228] Iteration 193200, loss = 3.25166
I0826 14:24:49.625869  1343 solver.cpp:244]     Train net output #0: loss = 3.25166 (* 1 = 3.25166 loss)
I0826 14:24:49.625881  1343 sgd_solver.cpp:106] Iteration 193200, lr = 1.69505e-07
I0826 14:24:58.048585  1343 solver.cpp:228] Iteration 193300, loss = 3.4318
I0826 14:24:58.048655  1343 solver.cpp:244]     Train net output #0: loss = 3.4318 (* 1 = 3.4318 loss)
I0826 14:24:58.048663  1343 sgd_solver.cpp:106] Iteration 193300, lr = 1.69445e-07
I0826 14:25:06.480466  1343 solver.cpp:228] Iteration 193400, loss = 3.48507
I0826 14:25:06.480535  1343 solver.cpp:244]     Train net output #0: loss = 3.48507 (* 1 = 3.48507 loss)
I0826 14:25:06.480551  1343 sgd_solver.cpp:106] Iteration 193400, lr = 1.69386e-07
I0826 14:25:13.561740  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:25:14.908716  1343 solver.cpp:228] Iteration 193500, loss = 3.38658
I0826 14:25:14.908782  1343 solver.cpp:244]     Train net output #0: loss = 3.38658 (* 1 = 3.38658 loss)
I0826 14:25:14.908797  1343 sgd_solver.cpp:106] Iteration 193500, lr = 1.69326e-07
I0826 14:25:23.344867  1343 solver.cpp:228] Iteration 193600, loss = 3.44234
I0826 14:25:23.344923  1343 solver.cpp:244]     Train net output #0: loss = 3.44234 (* 1 = 3.44234 loss)
I0826 14:25:23.344931  1343 sgd_solver.cpp:106] Iteration 193600, lr = 1.69267e-07
I0826 14:25:31.767890  1343 solver.cpp:228] Iteration 193700, loss = 3.54382
I0826 14:25:31.767933  1343 solver.cpp:244]     Train net output #0: loss = 3.54382 (* 1 = 3.54382 loss)
I0826 14:25:31.767940  1343 sgd_solver.cpp:106] Iteration 193700, lr = 1.69207e-07
I0826 14:25:40.179522  1343 solver.cpp:228] Iteration 193800, loss = 3.29968
I0826 14:25:40.179594  1343 solver.cpp:244]     Train net output #0: loss = 3.29968 (* 1 = 3.29968 loss)
I0826 14:25:40.179603  1343 sgd_solver.cpp:106] Iteration 193800, lr = 1.69148e-07
I0826 14:25:48.618258  1343 solver.cpp:228] Iteration 193900, loss = 3.4898
I0826 14:25:48.618338  1343 solver.cpp:244]     Train net output #0: loss = 3.4898 (* 1 = 3.4898 loss)
I0826 14:25:48.618348  1343 sgd_solver.cpp:106] Iteration 193900, lr = 1.69089e-07
I0826 14:25:57.034396  1343 solver.cpp:228] Iteration 194000, loss = 3.51582
I0826 14:25:57.034441  1343 solver.cpp:244]     Train net output #0: loss = 3.51582 (* 1 = 3.51582 loss)
I0826 14:25:57.034447  1343 sgd_solver.cpp:106] Iteration 194000, lr = 1.69029e-07
I0826 14:26:05.432611  1343 solver.cpp:228] Iteration 194100, loss = 3.44493
I0826 14:26:05.432654  1343 solver.cpp:244]     Train net output #0: loss = 3.44493 (* 1 = 3.44493 loss)
I0826 14:26:05.432660  1343 sgd_solver.cpp:106] Iteration 194100, lr = 1.6897e-07
I0826 14:26:13.847077  1343 solver.cpp:228] Iteration 194200, loss = 3.25794
I0826 14:26:13.847123  1343 solver.cpp:244]     Train net output #0: loss = 3.25794 (* 1 = 3.25794 loss)
I0826 14:26:13.847129  1343 sgd_solver.cpp:106] Iteration 194200, lr = 1.68911e-07
I0826 14:26:22.279026  1343 solver.cpp:228] Iteration 194300, loss = 3.34471
I0826 14:26:22.279098  1343 solver.cpp:244]     Train net output #0: loss = 3.34471 (* 1 = 3.34471 loss)
I0826 14:26:22.279112  1343 sgd_solver.cpp:106] Iteration 194300, lr = 1.68852e-07
I0826 14:26:30.713423  1343 solver.cpp:228] Iteration 194400, loss = 3.37555
I0826 14:26:30.713488  1343 solver.cpp:244]     Train net output #0: loss = 3.37555 (* 1 = 3.37555 loss)
I0826 14:26:30.713500  1343 sgd_solver.cpp:106] Iteration 194400, lr = 1.68793e-07
I0826 14:26:39.131916  1343 solver.cpp:228] Iteration 194500, loss = 3.45716
I0826 14:26:39.131964  1343 solver.cpp:244]     Train net output #0: loss = 3.45716 (* 1 = 3.45716 loss)
I0826 14:26:39.131969  1343 sgd_solver.cpp:106] Iteration 194500, lr = 1.68734e-07
I0826 14:26:47.538486  1343 solver.cpp:228] Iteration 194600, loss = 3.51372
I0826 14:26:47.538560  1343 solver.cpp:244]     Train net output #0: loss = 3.51372 (* 1 = 3.51372 loss)
I0826 14:26:47.538570  1343 sgd_solver.cpp:106] Iteration 194600, lr = 1.68675e-07
I0826 14:26:55.971190  1343 solver.cpp:228] Iteration 194700, loss = 3.43886
I0826 14:26:55.971238  1343 solver.cpp:244]     Train net output #0: loss = 3.43886 (* 1 = 3.43886 loss)
I0826 14:26:55.971245  1343 sgd_solver.cpp:106] Iteration 194700, lr = 1.68616e-07
I0826 14:27:04.398200  1343 solver.cpp:228] Iteration 194800, loss = 3.37009
I0826 14:27:04.398269  1343 solver.cpp:244]     Train net output #0: loss = 3.37009 (* 1 = 3.37009 loss)
I0826 14:27:04.398283  1343 sgd_solver.cpp:106] Iteration 194800, lr = 1.68557e-07
I0826 14:27:12.828737  1343 solver.cpp:228] Iteration 194900, loss = 3.57248
I0826 14:27:12.828814  1343 solver.cpp:244]     Train net output #0: loss = 3.57248 (* 1 = 3.57248 loss)
I0826 14:27:12.828825  1343 sgd_solver.cpp:106] Iteration 194900, lr = 1.68498e-07
I0826 14:27:21.161890  1343 solver.cpp:337] Iteration 195000, Testing net (#0)
I0826 14:27:49.729274  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:27:59.474555  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302027
I0826 14:27:59.474619  1343 solver.cpp:404]     Test net output #1: loss = 3.4149 (* 1 = 3.4149 loss)
I0826 14:27:59.503939  1343 solver.cpp:228] Iteration 195000, loss = 3.49695
I0826 14:27:59.503991  1343 solver.cpp:244]     Train net output #0: loss = 3.49695 (* 1 = 3.49695 loss)
I0826 14:27:59.504006  1343 sgd_solver.cpp:106] Iteration 195000, lr = 1.68439e-07
I0826 14:28:07.926714  1343 solver.cpp:228] Iteration 195100, loss = 3.37944
I0826 14:28:07.926769  1343 solver.cpp:244]     Train net output #0: loss = 3.37944 (* 1 = 3.37944 loss)
I0826 14:28:07.926774  1343 sgd_solver.cpp:106] Iteration 195100, lr = 1.68381e-07
I0826 14:28:16.358499  1343 solver.cpp:228] Iteration 195200, loss = 3.54336
I0826 14:28:16.358559  1343 solver.cpp:244]     Train net output #0: loss = 3.54336 (* 1 = 3.54336 loss)
I0826 14:28:16.358566  1343 sgd_solver.cpp:106] Iteration 195200, lr = 1.68322e-07
I0826 14:28:24.769165  1343 solver.cpp:228] Iteration 195300, loss = 3.55722
I0826 14:28:24.769207  1343 solver.cpp:244]     Train net output #0: loss = 3.55722 (* 1 = 3.55722 loss)
I0826 14:28:24.769212  1343 sgd_solver.cpp:106] Iteration 195300, lr = 1.68263e-07
I0826 14:28:33.202565  1343 solver.cpp:228] Iteration 195400, loss = 3.24524
I0826 14:28:33.202631  1343 solver.cpp:244]     Train net output #0: loss = 3.24524 (* 1 = 3.24524 loss)
I0826 14:28:33.202641  1343 sgd_solver.cpp:106] Iteration 195400, lr = 1.68205e-07
I0826 14:28:41.615813  1343 solver.cpp:228] Iteration 195500, loss = 3.39647
I0826 14:28:41.615872  1343 solver.cpp:244]     Train net output #0: loss = 3.39647 (* 1 = 3.39647 loss)
I0826 14:28:41.615880  1343 sgd_solver.cpp:106] Iteration 195500, lr = 1.68146e-07
I0826 14:28:50.059412  1343 solver.cpp:228] Iteration 195600, loss = 3.57708
I0826 14:28:50.059465  1343 solver.cpp:244]     Train net output #0: loss = 3.57708 (* 1 = 3.57708 loss)
I0826 14:28:50.059473  1343 sgd_solver.cpp:106] Iteration 195600, lr = 1.68088e-07
I0826 14:28:58.489272  1343 solver.cpp:228] Iteration 195700, loss = 3.40733
I0826 14:28:58.489315  1343 solver.cpp:244]     Train net output #0: loss = 3.40733 (* 1 = 3.40733 loss)
I0826 14:28:58.489321  1343 sgd_solver.cpp:106] Iteration 195700, lr = 1.68029e-07
I0826 14:29:06.926334  1343 solver.cpp:228] Iteration 195800, loss = 3.2659
I0826 14:29:06.926386  1343 solver.cpp:244]     Train net output #0: loss = 3.2659 (* 1 = 3.2659 loss)
I0826 14:29:06.926394  1343 sgd_solver.cpp:106] Iteration 195800, lr = 1.67971e-07
I0826 14:29:15.354033  1343 solver.cpp:228] Iteration 195900, loss = 3.47182
I0826 14:29:15.354071  1343 solver.cpp:244]     Train net output #0: loss = 3.47182 (* 1 = 3.47182 loss)
I0826 14:29:15.354079  1343 sgd_solver.cpp:106] Iteration 195900, lr = 1.67912e-07
I0826 14:29:23.765719  1343 solver.cpp:228] Iteration 196000, loss = 3.44534
I0826 14:29:23.765781  1343 solver.cpp:244]     Train net output #0: loss = 3.44534 (* 1 = 3.44534 loss)
I0826 14:29:23.765789  1343 sgd_solver.cpp:106] Iteration 196000, lr = 1.67854e-07
I0826 14:29:32.177485  1343 solver.cpp:228] Iteration 196100, loss = 3.47057
I0826 14:29:32.177531  1343 solver.cpp:244]     Train net output #0: loss = 3.47057 (* 1 = 3.47057 loss)
I0826 14:29:32.177536  1343 sgd_solver.cpp:106] Iteration 196100, lr = 1.67796e-07
I0826 14:29:40.610954  1343 solver.cpp:228] Iteration 196200, loss = 3.27765
I0826 14:29:40.611003  1343 solver.cpp:244]     Train net output #0: loss = 3.27765 (* 1 = 3.27765 loss)
I0826 14:29:40.611011  1343 sgd_solver.cpp:106] Iteration 196200, lr = 1.67738e-07
I0826 14:29:49.047415  1343 solver.cpp:228] Iteration 196300, loss = 3.44161
I0826 14:29:49.047469  1343 solver.cpp:244]     Train net output #0: loss = 3.44161 (* 1 = 3.44161 loss)
I0826 14:29:49.047484  1343 sgd_solver.cpp:106] Iteration 196300, lr = 1.6768e-07
I0826 14:29:57.464548  1343 solver.cpp:228] Iteration 196400, loss = 3.30324
I0826 14:29:57.464589  1343 solver.cpp:244]     Train net output #0: loss = 3.30324 (* 1 = 3.30324 loss)
I0826 14:29:57.464594  1343 sgd_solver.cpp:106] Iteration 196400, lr = 1.67621e-07
I0826 14:30:05.883280  1343 solver.cpp:228] Iteration 196500, loss = 3.1744
I0826 14:30:05.883322  1343 solver.cpp:244]     Train net output #0: loss = 3.1744 (* 1 = 3.1744 loss)
I0826 14:30:05.883328  1343 sgd_solver.cpp:106] Iteration 196500, lr = 1.67563e-07
I0826 14:30:14.302779  1343 solver.cpp:228] Iteration 196600, loss = 3.43346
I0826 14:30:14.302842  1343 solver.cpp:244]     Train net output #0: loss = 3.43346 (* 1 = 3.43346 loss)
I0826 14:30:14.302853  1343 sgd_solver.cpp:106] Iteration 196600, lr = 1.67505e-07
I0826 14:30:22.727327  1343 solver.cpp:228] Iteration 196700, loss = 3.29826
I0826 14:30:22.727385  1343 solver.cpp:244]     Train net output #0: loss = 3.29826 (* 1 = 3.29826 loss)
I0826 14:30:22.727396  1343 sgd_solver.cpp:106] Iteration 196700, lr = 1.67447e-07
I0826 14:30:31.158085  1343 solver.cpp:228] Iteration 196800, loss = 3.44334
I0826 14:30:31.158139  1343 solver.cpp:244]     Train net output #0: loss = 3.44334 (* 1 = 3.44334 loss)
I0826 14:30:31.158146  1343 sgd_solver.cpp:106] Iteration 196800, lr = 1.67389e-07
I0826 14:30:39.575467  1343 solver.cpp:228] Iteration 196900, loss = 3.39913
I0826 14:30:39.575518  1343 solver.cpp:244]     Train net output #0: loss = 3.39913 (* 1 = 3.39913 loss)
I0826 14:30:39.575527  1343 sgd_solver.cpp:106] Iteration 196900, lr = 1.67332e-07
I0826 14:30:48.008586  1343 solver.cpp:228] Iteration 197000, loss = 3.5251
I0826 14:30:48.008627  1343 solver.cpp:244]     Train net output #0: loss = 3.5251 (* 1 = 3.5251 loss)
I0826 14:30:48.008633  1343 sgd_solver.cpp:106] Iteration 197000, lr = 1.67274e-07
I0826 14:30:56.431201  1343 solver.cpp:228] Iteration 197100, loss = 3.65418
I0826 14:30:56.431259  1343 solver.cpp:244]     Train net output #0: loss = 3.65418 (* 1 = 3.65418 loss)
I0826 14:30:56.431269  1343 sgd_solver.cpp:106] Iteration 197100, lr = 1.67216e-07
I0826 14:31:04.867442  1343 solver.cpp:228] Iteration 197200, loss = 3.54616
I0826 14:31:04.867516  1343 solver.cpp:244]     Train net output #0: loss = 3.54616 (* 1 = 3.54616 loss)
I0826 14:31:04.867528  1343 sgd_solver.cpp:106] Iteration 197200, lr = 1.67158e-07
I0826 14:31:13.286257  1343 solver.cpp:228] Iteration 197300, loss = 3.35627
I0826 14:31:13.286305  1343 solver.cpp:244]     Train net output #0: loss = 3.35627 (* 1 = 3.35627 loss)
I0826 14:31:13.286314  1343 sgd_solver.cpp:106] Iteration 197300, lr = 1.671e-07
I0826 14:31:21.705040  1343 solver.cpp:228] Iteration 197400, loss = 3.42867
I0826 14:31:21.705083  1343 solver.cpp:244]     Train net output #0: loss = 3.42867 (* 1 = 3.42867 loss)
I0826 14:31:21.705090  1343 sgd_solver.cpp:106] Iteration 197400, lr = 1.67043e-07
I0826 14:31:30.120030  1343 solver.cpp:228] Iteration 197500, loss = 3.55218
I0826 14:31:30.120090  1343 solver.cpp:244]     Train net output #0: loss = 3.55218 (* 1 = 3.55218 loss)
I0826 14:31:30.120100  1343 sgd_solver.cpp:106] Iteration 197500, lr = 1.66985e-07
I0826 14:31:38.558588  1343 solver.cpp:228] Iteration 197600, loss = 3.41502
I0826 14:31:38.558627  1343 solver.cpp:244]     Train net output #0: loss = 3.41502 (* 1 = 3.41502 loss)
I0826 14:31:38.558634  1343 sgd_solver.cpp:106] Iteration 197600, lr = 1.66928e-07
I0826 14:31:46.985677  1343 solver.cpp:228] Iteration 197700, loss = 3.48292
I0826 14:31:46.985720  1343 solver.cpp:244]     Train net output #0: loss = 3.48292 (* 1 = 3.48292 loss)
I0826 14:31:46.985725  1343 sgd_solver.cpp:106] Iteration 197700, lr = 1.6687e-07
I0826 14:31:55.414856  1343 solver.cpp:228] Iteration 197800, loss = 3.32919
I0826 14:31:55.414903  1343 solver.cpp:244]     Train net output #0: loss = 3.32919 (* 1 = 3.32919 loss)
I0826 14:31:55.414911  1343 sgd_solver.cpp:106] Iteration 197800, lr = 1.66813e-07
I0826 14:31:59.364464  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:32:03.841433  1343 solver.cpp:228] Iteration 197900, loss = 3.42689
I0826 14:32:03.841491  1343 solver.cpp:244]     Train net output #0: loss = 3.42689 (* 1 = 3.42689 loss)
I0826 14:32:03.841501  1343 sgd_solver.cpp:106] Iteration 197900, lr = 1.66755e-07
I0826 14:32:12.284169  1343 solver.cpp:228] Iteration 198000, loss = 3.43566
I0826 14:32:12.284212  1343 solver.cpp:244]     Train net output #0: loss = 3.43566 (* 1 = 3.43566 loss)
I0826 14:32:12.284217  1343 sgd_solver.cpp:106] Iteration 198000, lr = 1.66698e-07
I0826 14:32:20.715831  1343 solver.cpp:228] Iteration 198100, loss = 3.47711
I0826 14:32:20.715924  1343 solver.cpp:244]     Train net output #0: loss = 3.47711 (* 1 = 3.47711 loss)
I0826 14:32:20.715936  1343 sgd_solver.cpp:106] Iteration 198100, lr = 1.66641e-07
I0826 14:32:29.153565  1343 solver.cpp:228] Iteration 198200, loss = 3.43586
I0826 14:32:29.153627  1343 solver.cpp:244]     Train net output #0: loss = 3.43586 (* 1 = 3.43586 loss)
I0826 14:32:29.153635  1343 sgd_solver.cpp:106] Iteration 198200, lr = 1.66583e-07
I0826 14:32:37.572230  1343 solver.cpp:228] Iteration 198300, loss = 3.36387
I0826 14:32:37.572294  1343 solver.cpp:244]     Train net output #0: loss = 3.36387 (* 1 = 3.36387 loss)
I0826 14:32:37.572305  1343 sgd_solver.cpp:106] Iteration 198300, lr = 1.66526e-07
I0826 14:32:45.997303  1343 solver.cpp:228] Iteration 198400, loss = 3.36458
I0826 14:32:45.997364  1343 solver.cpp:244]     Train net output #0: loss = 3.36458 (* 1 = 3.36458 loss)
I0826 14:32:45.997373  1343 sgd_solver.cpp:106] Iteration 198400, lr = 1.66469e-07
I0826 14:32:54.432831  1343 solver.cpp:228] Iteration 198500, loss = 3.37777
I0826 14:32:54.432883  1343 solver.cpp:244]     Train net output #0: loss = 3.37777 (* 1 = 3.37777 loss)
I0826 14:32:54.432890  1343 sgd_solver.cpp:106] Iteration 198500, lr = 1.66412e-07
I0826 14:33:02.854044  1343 solver.cpp:228] Iteration 198600, loss = 3.32063
I0826 14:33:02.854084  1343 solver.cpp:244]     Train net output #0: loss = 3.32063 (* 1 = 3.32063 loss)
I0826 14:33:02.854090  1343 sgd_solver.cpp:106] Iteration 198600, lr = 1.66355e-07
I0826 14:33:11.289364  1343 solver.cpp:228] Iteration 198700, loss = 3.35996
I0826 14:33:11.289428  1343 solver.cpp:244]     Train net output #0: loss = 3.35996 (* 1 = 3.35996 loss)
I0826 14:33:11.289436  1343 sgd_solver.cpp:106] Iteration 198700, lr = 1.66298e-07
I0826 14:33:19.712406  1343 solver.cpp:228] Iteration 198800, loss = 3.16871
I0826 14:33:19.712456  1343 solver.cpp:244]     Train net output #0: loss = 3.16871 (* 1 = 3.16871 loss)
I0826 14:33:19.712476  1343 sgd_solver.cpp:106] Iteration 198800, lr = 1.66241e-07
I0826 14:33:28.130340  1343 solver.cpp:228] Iteration 198900, loss = 3.33781
I0826 14:33:28.130383  1343 solver.cpp:244]     Train net output #0: loss = 3.33781 (* 1 = 3.33781 loss)
I0826 14:33:28.130389  1343 sgd_solver.cpp:106] Iteration 198900, lr = 1.66184e-07
I0826 14:33:36.566690  1343 solver.cpp:228] Iteration 199000, loss = 3.44709
I0826 14:33:36.566754  1343 solver.cpp:244]     Train net output #0: loss = 3.44709 (* 1 = 3.44709 loss)
I0826 14:33:36.566763  1343 sgd_solver.cpp:106] Iteration 199000, lr = 1.66127e-07
I0826 14:33:45.003497  1343 solver.cpp:228] Iteration 199100, loss = 3.38041
I0826 14:33:45.003558  1343 solver.cpp:244]     Train net output #0: loss = 3.38041 (* 1 = 3.38041 loss)
I0826 14:33:45.003569  1343 sgd_solver.cpp:106] Iteration 199100, lr = 1.6607e-07
I0826 14:33:53.442333  1343 solver.cpp:228] Iteration 199200, loss = 3.44468
I0826 14:33:53.442394  1343 solver.cpp:244]     Train net output #0: loss = 3.44468 (* 1 = 3.44468 loss)
I0826 14:33:53.442404  1343 sgd_solver.cpp:106] Iteration 199200, lr = 1.66013e-07
I0826 14:34:01.874950  1343 solver.cpp:228] Iteration 199300, loss = 3.42682
I0826 14:34:01.875010  1343 solver.cpp:244]     Train net output #0: loss = 3.42682 (* 1 = 3.42682 loss)
I0826 14:34:01.875020  1343 sgd_solver.cpp:106] Iteration 199300, lr = 1.65956e-07
I0826 14:34:10.293568  1343 solver.cpp:228] Iteration 199400, loss = 3.49807
I0826 14:34:10.293629  1343 solver.cpp:244]     Train net output #0: loss = 3.49807 (* 1 = 3.49807 loss)
I0826 14:34:10.293637  1343 sgd_solver.cpp:106] Iteration 199400, lr = 1.65899e-07
I0826 14:34:18.719595  1343 solver.cpp:228] Iteration 199500, loss = 3.39627
I0826 14:34:18.719655  1343 solver.cpp:244]     Train net output #0: loss = 3.39627 (* 1 = 3.39627 loss)
I0826 14:34:18.719662  1343 sgd_solver.cpp:106] Iteration 199500, lr = 1.65843e-07
I0826 14:34:27.138089  1343 solver.cpp:228] Iteration 199600, loss = 3.38854
I0826 14:34:27.138150  1343 solver.cpp:244]     Train net output #0: loss = 3.38854 (* 1 = 3.38854 loss)
I0826 14:34:27.138157  1343 sgd_solver.cpp:106] Iteration 199600, lr = 1.65786e-07
I0826 14:34:35.565194  1343 solver.cpp:228] Iteration 199700, loss = 3.39986
I0826 14:34:35.565258  1343 solver.cpp:244]     Train net output #0: loss = 3.39986 (* 1 = 3.39986 loss)
I0826 14:34:35.565270  1343 sgd_solver.cpp:106] Iteration 199700, lr = 1.6573e-07
I0826 14:34:44.009675  1343 solver.cpp:228] Iteration 199800, loss = 3.40936
I0826 14:34:44.009732  1343 solver.cpp:244]     Train net output #0: loss = 3.40936 (* 1 = 3.40936 loss)
I0826 14:34:44.009740  1343 sgd_solver.cpp:106] Iteration 199800, lr = 1.65673e-07
I0826 14:34:52.430909  1343 solver.cpp:228] Iteration 199900, loss = 3.49166
I0826 14:34:52.430963  1343 solver.cpp:244]     Train net output #0: loss = 3.49166 (* 1 = 3.49166 loss)
I0826 14:34:52.430970  1343 sgd_solver.cpp:106] Iteration 199900, lr = 1.65616e-07
I0826 14:35:00.785030  1343 solver.cpp:454] Snapshotting to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_200000.caffemodel
I0826 14:35:01.435626  1343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/coco_all_classes_alex_net/coco_alex_net_inv_lrv_0.000001_iter_200000.solverstate
I0826 14:35:01.596438  1343 solver.cpp:337] Iteration 200000, Testing net (#0)
I0826 14:35:18.710260  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:35:38.215764  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302014
I0826 14:35:38.215833  1343 solver.cpp:404]     Test net output #1: loss = 3.4144 (* 1 = 3.4144 loss)
I0826 14:35:38.245522  1343 solver.cpp:228] Iteration 200000, loss = 3.38224
I0826 14:35:38.245580  1343 solver.cpp:244]     Train net output #0: loss = 3.38224 (* 1 = 3.38224 loss)
I0826 14:35:38.245594  1343 sgd_solver.cpp:106] Iteration 200000, lr = 1.6556e-07
I0826 14:35:46.676545  1343 solver.cpp:228] Iteration 200100, loss = 3.30954
I0826 14:35:46.676637  1343 solver.cpp:244]     Train net output #0: loss = 3.30954 (* 1 = 3.30954 loss)
I0826 14:35:46.676652  1343 sgd_solver.cpp:106] Iteration 200100, lr = 1.65504e-07
I0826 14:35:55.090782  1343 solver.cpp:228] Iteration 200200, loss = 3.30711
I0826 14:35:55.090836  1343 solver.cpp:244]     Train net output #0: loss = 3.30711 (* 1 = 3.30711 loss)
I0826 14:35:55.090845  1343 sgd_solver.cpp:106] Iteration 200200, lr = 1.65447e-07
I0826 14:36:03.517527  1343 solver.cpp:228] Iteration 200300, loss = 3.54128
I0826 14:36:03.517611  1343 solver.cpp:244]     Train net output #0: loss = 3.54128 (* 1 = 3.54128 loss)
I0826 14:36:03.517622  1343 sgd_solver.cpp:106] Iteration 200300, lr = 1.65391e-07
I0826 14:36:11.931273  1343 solver.cpp:228] Iteration 200400, loss = 3.34579
I0826 14:36:11.931334  1343 solver.cpp:244]     Train net output #0: loss = 3.34579 (* 1 = 3.34579 loss)
I0826 14:36:11.931345  1343 sgd_solver.cpp:106] Iteration 200400, lr = 1.65335e-07
I0826 14:36:20.354730  1343 solver.cpp:228] Iteration 200500, loss = 3.52447
I0826 14:36:20.354782  1343 solver.cpp:244]     Train net output #0: loss = 3.52447 (* 1 = 3.52447 loss)
I0826 14:36:20.354791  1343 sgd_solver.cpp:106] Iteration 200500, lr = 1.65278e-07
I0826 14:36:28.776185  1343 solver.cpp:228] Iteration 200600, loss = 3.52453
I0826 14:36:28.776262  1343 solver.cpp:244]     Train net output #0: loss = 3.52453 (* 1 = 3.52453 loss)
I0826 14:36:28.776271  1343 sgd_solver.cpp:106] Iteration 200600, lr = 1.65222e-07
I0826 14:36:37.207844  1343 solver.cpp:228] Iteration 200700, loss = 3.45385
I0826 14:36:37.207911  1343 solver.cpp:244]     Train net output #0: loss = 3.45385 (* 1 = 3.45385 loss)
I0826 14:36:37.207919  1343 sgd_solver.cpp:106] Iteration 200700, lr = 1.65166e-07
I0826 14:36:45.617681  1343 solver.cpp:228] Iteration 200800, loss = 3.38874
I0826 14:36:45.617756  1343 solver.cpp:244]     Train net output #0: loss = 3.38874 (* 1 = 3.38874 loss)
I0826 14:36:45.617766  1343 sgd_solver.cpp:106] Iteration 200800, lr = 1.6511e-07
I0826 14:36:54.037472  1343 solver.cpp:228] Iteration 200900, loss = 3.50722
I0826 14:36:54.037531  1343 solver.cpp:244]     Train net output #0: loss = 3.50722 (* 1 = 3.50722 loss)
I0826 14:36:54.037538  1343 sgd_solver.cpp:106] Iteration 200900, lr = 1.65054e-07
I0826 14:37:02.457227  1343 solver.cpp:228] Iteration 201000, loss = 3.45615
I0826 14:37:02.457296  1343 solver.cpp:244]     Train net output #0: loss = 3.45615 (* 1 = 3.45615 loss)
I0826 14:37:02.457314  1343 sgd_solver.cpp:106] Iteration 201000, lr = 1.64998e-07
I0826 14:37:10.878077  1343 solver.cpp:228] Iteration 201100, loss = 3.37019
I0826 14:37:10.878121  1343 solver.cpp:244]     Train net output #0: loss = 3.37019 (* 1 = 3.37019 loss)
I0826 14:37:10.878128  1343 sgd_solver.cpp:106] Iteration 201100, lr = 1.64942e-07
I0826 14:37:19.304507  1343 solver.cpp:228] Iteration 201200, loss = 3.45223
I0826 14:37:19.304574  1343 solver.cpp:244]     Train net output #0: loss = 3.45223 (* 1 = 3.45223 loss)
I0826 14:37:19.304585  1343 sgd_solver.cpp:106] Iteration 201200, lr = 1.64886e-07
I0826 14:37:27.732893  1343 solver.cpp:228] Iteration 201300, loss = 3.36986
I0826 14:37:27.732967  1343 solver.cpp:244]     Train net output #0: loss = 3.36986 (* 1 = 3.36986 loss)
I0826 14:37:27.732980  1343 sgd_solver.cpp:106] Iteration 201300, lr = 1.6483e-07
I0826 14:37:36.154019  1343 solver.cpp:228] Iteration 201400, loss = 3.42774
I0826 14:37:36.154080  1343 solver.cpp:244]     Train net output #0: loss = 3.42774 (* 1 = 3.42774 loss)
I0826 14:37:36.154088  1343 sgd_solver.cpp:106] Iteration 201400, lr = 1.64774e-07
I0826 14:37:44.585837  1343 solver.cpp:228] Iteration 201500, loss = 3.55522
I0826 14:37:44.585898  1343 solver.cpp:244]     Train net output #0: loss = 3.55522 (* 1 = 3.55522 loss)
I0826 14:37:44.585906  1343 sgd_solver.cpp:106] Iteration 201500, lr = 1.64718e-07
I0826 14:37:52.990486  1343 solver.cpp:228] Iteration 201600, loss = 3.36088
I0826 14:37:52.990547  1343 solver.cpp:244]     Train net output #0: loss = 3.36088 (* 1 = 3.36088 loss)
I0826 14:37:52.990557  1343 sgd_solver.cpp:106] Iteration 201600, lr = 1.64663e-07
I0826 14:38:01.419044  1343 solver.cpp:228] Iteration 201700, loss = 3.45985
I0826 14:38:01.419098  1343 solver.cpp:244]     Train net output #0: loss = 3.45985 (* 1 = 3.45985 loss)
I0826 14:38:01.419106  1343 sgd_solver.cpp:106] Iteration 201700, lr = 1.64607e-07
I0826 14:38:09.845357  1343 solver.cpp:228] Iteration 201800, loss = 3.28244
I0826 14:38:09.845437  1343 solver.cpp:244]     Train net output #0: loss = 3.28244 (* 1 = 3.28244 loss)
I0826 14:38:09.845448  1343 sgd_solver.cpp:106] Iteration 201800, lr = 1.64551e-07
I0826 14:38:18.277554  1343 solver.cpp:228] Iteration 201900, loss = 3.60342
I0826 14:38:18.277621  1343 solver.cpp:244]     Train net output #0: loss = 3.60342 (* 1 = 3.60342 loss)
I0826 14:38:18.277631  1343 sgd_solver.cpp:106] Iteration 201900, lr = 1.64496e-07
I0826 14:38:18.867702  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:38:26.693460  1343 solver.cpp:228] Iteration 202000, loss = 3.54296
I0826 14:38:26.693526  1343 solver.cpp:244]     Train net output #0: loss = 3.54296 (* 1 = 3.54296 loss)
I0826 14:38:26.693534  1343 sgd_solver.cpp:106] Iteration 202000, lr = 1.6444e-07
I0826 14:38:35.103597  1343 solver.cpp:228] Iteration 202100, loss = 3.54201
I0826 14:38:35.103660  1343 solver.cpp:244]     Train net output #0: loss = 3.54201 (* 1 = 3.54201 loss)
I0826 14:38:35.103672  1343 sgd_solver.cpp:106] Iteration 202100, lr = 1.64385e-07
I0826 14:38:43.527657  1343 solver.cpp:228] Iteration 202200, loss = 3.27223
I0826 14:38:43.527714  1343 solver.cpp:244]     Train net output #0: loss = 3.27223 (* 1 = 3.27223 loss)
I0826 14:38:43.527719  1343 sgd_solver.cpp:106] Iteration 202200, lr = 1.64329e-07
I0826 14:38:51.954532  1343 solver.cpp:228] Iteration 202300, loss = 3.59264
I0826 14:38:51.954599  1343 solver.cpp:244]     Train net output #0: loss = 3.59264 (* 1 = 3.59264 loss)
I0826 14:38:51.954610  1343 sgd_solver.cpp:106] Iteration 202300, lr = 1.64274e-07
I0826 14:39:00.363142  1343 solver.cpp:228] Iteration 202400, loss = 3.53146
I0826 14:39:00.363215  1343 solver.cpp:244]     Train net output #0: loss = 3.53146 (* 1 = 3.53146 loss)
I0826 14:39:00.363224  1343 sgd_solver.cpp:106] Iteration 202400, lr = 1.64218e-07
I0826 14:39:08.785646  1343 solver.cpp:228] Iteration 202500, loss = 3.21946
I0826 14:39:08.785717  1343 solver.cpp:244]     Train net output #0: loss = 3.21946 (* 1 = 3.21946 loss)
I0826 14:39:08.785727  1343 sgd_solver.cpp:106] Iteration 202500, lr = 1.64163e-07
I0826 14:39:17.226433  1343 solver.cpp:228] Iteration 202600, loss = 3.44161
I0826 14:39:17.226490  1343 solver.cpp:244]     Train net output #0: loss = 3.44161 (* 1 = 3.44161 loss)
I0826 14:39:17.226498  1343 sgd_solver.cpp:106] Iteration 202600, lr = 1.64108e-07
I0826 14:39:25.655650  1343 solver.cpp:228] Iteration 202700, loss = 3.26484
I0826 14:39:25.655706  1343 solver.cpp:244]     Train net output #0: loss = 3.26484 (* 1 = 3.26484 loss)
I0826 14:39:25.655714  1343 sgd_solver.cpp:106] Iteration 202700, lr = 1.64052e-07
I0826 14:39:34.084597  1343 solver.cpp:228] Iteration 202800, loss = 3.57308
I0826 14:39:34.084656  1343 solver.cpp:244]     Train net output #0: loss = 3.57308 (* 1 = 3.57308 loss)
I0826 14:39:34.084666  1343 sgd_solver.cpp:106] Iteration 202800, lr = 1.63997e-07
I0826 14:39:42.504909  1343 solver.cpp:228] Iteration 202900, loss = 3.61884
I0826 14:39:42.504951  1343 solver.cpp:244]     Train net output #0: loss = 3.61884 (* 1 = 3.61884 loss)
I0826 14:39:42.504958  1343 sgd_solver.cpp:106] Iteration 202900, lr = 1.63942e-07
I0826 14:39:50.911166  1343 solver.cpp:228] Iteration 203000, loss = 3.47754
I0826 14:39:50.911233  1343 solver.cpp:244]     Train net output #0: loss = 3.47754 (* 1 = 3.47754 loss)
I0826 14:39:50.911242  1343 sgd_solver.cpp:106] Iteration 203000, lr = 1.63887e-07
I0826 14:39:59.336431  1343 solver.cpp:228] Iteration 203100, loss = 3.22117
I0826 14:39:59.336503  1343 solver.cpp:244]     Train net output #0: loss = 3.22117 (* 1 = 3.22117 loss)
I0826 14:39:59.336513  1343 sgd_solver.cpp:106] Iteration 203100, lr = 1.63832e-07
I0826 14:40:07.771153  1343 solver.cpp:228] Iteration 203200, loss = 3.33672
I0826 14:40:07.771234  1343 solver.cpp:244]     Train net output #0: loss = 3.33672 (* 1 = 3.33672 loss)
I0826 14:40:07.771250  1343 sgd_solver.cpp:106] Iteration 203200, lr = 1.63777e-07
I0826 14:40:16.203307  1343 solver.cpp:228] Iteration 203300, loss = 3.45475
I0826 14:40:16.203352  1343 solver.cpp:244]     Train net output #0: loss = 3.45475 (* 1 = 3.45475 loss)
I0826 14:40:16.203358  1343 sgd_solver.cpp:106] Iteration 203300, lr = 1.63722e-07
I0826 14:40:24.629987  1343 solver.cpp:228] Iteration 203400, loss = 3.61147
I0826 14:40:24.630046  1343 solver.cpp:244]     Train net output #0: loss = 3.61147 (* 1 = 3.61147 loss)
I0826 14:40:24.630053  1343 sgd_solver.cpp:106] Iteration 203400, lr = 1.63667e-07
I0826 14:40:33.073189  1343 solver.cpp:228] Iteration 203500, loss = 3.41197
I0826 14:40:33.073252  1343 solver.cpp:244]     Train net output #0: loss = 3.41197 (* 1 = 3.41197 loss)
I0826 14:40:33.073262  1343 sgd_solver.cpp:106] Iteration 203500, lr = 1.63612e-07
I0826 14:40:41.503293  1343 solver.cpp:228] Iteration 203600, loss = 3.53415
I0826 14:40:41.503371  1343 solver.cpp:244]     Train net output #0: loss = 3.53415 (* 1 = 3.53415 loss)
I0826 14:40:41.503384  1343 sgd_solver.cpp:106] Iteration 203600, lr = 1.63557e-07
I0826 14:40:49.910549  1343 solver.cpp:228] Iteration 203700, loss = 3.57053
I0826 14:40:49.910598  1343 solver.cpp:244]     Train net output #0: loss = 3.57053 (* 1 = 3.57053 loss)
I0826 14:40:49.910604  1343 sgd_solver.cpp:106] Iteration 203700, lr = 1.63502e-07
I0826 14:40:58.341622  1343 solver.cpp:228] Iteration 203800, loss = 3.52366
I0826 14:40:58.341682  1343 solver.cpp:244]     Train net output #0: loss = 3.52366 (* 1 = 3.52366 loss)
I0826 14:40:58.341692  1343 sgd_solver.cpp:106] Iteration 203800, lr = 1.63447e-07
I0826 14:41:06.787806  1343 solver.cpp:228] Iteration 203900, loss = 3.28254
I0826 14:41:06.787868  1343 solver.cpp:244]     Train net output #0: loss = 3.28254 (* 1 = 3.28254 loss)
I0826 14:41:06.787876  1343 sgd_solver.cpp:106] Iteration 203900, lr = 1.63392e-07
I0826 14:41:15.213322  1343 solver.cpp:228] Iteration 204000, loss = 3.49474
I0826 14:41:15.213361  1343 solver.cpp:244]     Train net output #0: loss = 3.49474 (* 1 = 3.49474 loss)
I0826 14:41:15.213367  1343 sgd_solver.cpp:106] Iteration 204000, lr = 1.63338e-07
I0826 14:41:23.611074  1343 solver.cpp:228] Iteration 204100, loss = 3.32607
I0826 14:41:23.611116  1343 solver.cpp:244]     Train net output #0: loss = 3.32607 (* 1 = 3.32607 loss)
I0826 14:41:23.611122  1343 sgd_solver.cpp:106] Iteration 204100, lr = 1.63283e-07
I0826 14:41:32.028547  1343 solver.cpp:228] Iteration 204200, loss = 3.52312
I0826 14:41:32.028587  1343 solver.cpp:244]     Train net output #0: loss = 3.52312 (* 1 = 3.52312 loss)
I0826 14:41:32.028594  1343 sgd_solver.cpp:106] Iteration 204200, lr = 1.63228e-07
I0826 14:41:40.462976  1343 solver.cpp:228] Iteration 204300, loss = 3.497
I0826 14:41:40.463028  1343 solver.cpp:244]     Train net output #0: loss = 3.497 (* 1 = 3.497 loss)
I0826 14:41:40.463035  1343 sgd_solver.cpp:106] Iteration 204300, lr = 1.63174e-07
I0826 14:41:48.896381  1343 solver.cpp:228] Iteration 204400, loss = 3.55816
I0826 14:41:48.896443  1343 solver.cpp:244]     Train net output #0: loss = 3.55816 (* 1 = 3.55816 loss)
I0826 14:41:48.896450  1343 sgd_solver.cpp:106] Iteration 204400, lr = 1.63119e-07
I0826 14:41:57.329144  1343 solver.cpp:228] Iteration 204500, loss = 3.2321
I0826 14:41:57.329196  1343 solver.cpp:244]     Train net output #0: loss = 3.2321 (* 1 = 3.2321 loss)
I0826 14:41:57.329205  1343 sgd_solver.cpp:106] Iteration 204500, lr = 1.63065e-07
I0826 14:42:05.765969  1343 solver.cpp:228] Iteration 204600, loss = 3.38766
I0826 14:42:05.766034  1343 solver.cpp:244]     Train net output #0: loss = 3.38766 (* 1 = 3.38766 loss)
I0826 14:42:05.766044  1343 sgd_solver.cpp:106] Iteration 204600, lr = 1.6301e-07
I0826 14:42:14.179388  1343 solver.cpp:228] Iteration 204700, loss = 3.58021
I0826 14:42:14.179440  1343 solver.cpp:244]     Train net output #0: loss = 3.58021 (* 1 = 3.58021 loss)
I0826 14:42:14.179448  1343 sgd_solver.cpp:106] Iteration 204700, lr = 1.62956e-07
I0826 14:42:22.610538  1343 solver.cpp:228] Iteration 204800, loss = 3.61236
I0826 14:42:22.610602  1343 solver.cpp:244]     Train net output #0: loss = 3.61236 (* 1 = 3.61236 loss)
I0826 14:42:22.610610  1343 sgd_solver.cpp:106] Iteration 204800, lr = 1.62902e-07
I0826 14:42:31.027518  1343 solver.cpp:228] Iteration 204900, loss = 3.3214
I0826 14:42:31.027583  1343 solver.cpp:244]     Train net output #0: loss = 3.3214 (* 1 = 3.3214 loss)
I0826 14:42:31.027590  1343 sgd_solver.cpp:106] Iteration 204900, lr = 1.62847e-07
I0826 14:42:39.384636  1343 solver.cpp:337] Iteration 205000, Testing net (#0)
I0826 14:42:53.168524  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:43:18.116123  1343 solver.cpp:404]     Test net output #0: accuracy = 0.302021
I0826 14:43:18.116181  1343 solver.cpp:404]     Test net output #1: loss = 3.41358 (* 1 = 3.41358 loss)
I0826 14:43:18.146941  1343 solver.cpp:228] Iteration 205000, loss = 3.47036
I0826 14:43:18.146983  1343 solver.cpp:244]     Train net output #0: loss = 3.47036 (* 1 = 3.47036 loss)
I0826 14:43:18.146996  1343 sgd_solver.cpp:106] Iteration 205000, lr = 1.62793e-07
I0826 14:43:26.549571  1343 solver.cpp:228] Iteration 205100, loss = 3.20212
I0826 14:43:26.549644  1343 solver.cpp:244]     Train net output #0: loss = 3.20212 (* 1 = 3.20212 loss)
I0826 14:43:26.549652  1343 sgd_solver.cpp:106] Iteration 205100, lr = 1.62739e-07
I0826 14:43:34.993667  1343 solver.cpp:228] Iteration 205200, loss = 3.52135
I0826 14:43:34.993736  1343 solver.cpp:244]     Train net output #0: loss = 3.52135 (* 1 = 3.52135 loss)
I0826 14:43:34.993747  1343 sgd_solver.cpp:106] Iteration 205200, lr = 1.62685e-07
I0826 14:43:43.416834  1343 solver.cpp:228] Iteration 205300, loss = 3.29401
I0826 14:43:43.416895  1343 solver.cpp:244]     Train net output #0: loss = 3.29401 (* 1 = 3.29401 loss)
I0826 14:43:43.416903  1343 sgd_solver.cpp:106] Iteration 205300, lr = 1.6263e-07
I0826 14:43:51.847369  1343 solver.cpp:228] Iteration 205400, loss = 3.49578
I0826 14:43:51.847422  1343 solver.cpp:244]     Train net output #0: loss = 3.49578 (* 1 = 3.49578 loss)
I0826 14:43:51.847429  1343 sgd_solver.cpp:106] Iteration 205400, lr = 1.62576e-07
I0826 14:44:00.279845  1343 solver.cpp:228] Iteration 205500, loss = 3.54245
I0826 14:44:00.279909  1343 solver.cpp:244]     Train net output #0: loss = 3.54245 (* 1 = 3.54245 loss)
I0826 14:44:00.279917  1343 sgd_solver.cpp:106] Iteration 205500, lr = 1.62522e-07
I0826 14:44:08.711078  1343 solver.cpp:228] Iteration 205600, loss = 3.55096
I0826 14:44:08.711158  1343 solver.cpp:244]     Train net output #0: loss = 3.55096 (* 1 = 3.55096 loss)
I0826 14:44:08.711168  1343 sgd_solver.cpp:106] Iteration 205600, lr = 1.62468e-07
I0826 14:44:17.134264  1343 solver.cpp:228] Iteration 205700, loss = 3.41468
I0826 14:44:17.134310  1343 solver.cpp:244]     Train net output #0: loss = 3.41468 (* 1 = 3.41468 loss)
I0826 14:44:17.134315  1343 sgd_solver.cpp:106] Iteration 205700, lr = 1.62414e-07
I0826 14:44:25.548251  1343 solver.cpp:228] Iteration 205800, loss = 3.48667
I0826 14:44:25.548331  1343 solver.cpp:244]     Train net output #0: loss = 3.48667 (* 1 = 3.48667 loss)
I0826 14:44:25.548346  1343 sgd_solver.cpp:106] Iteration 205800, lr = 1.6236e-07
I0826 14:44:33.983609  1343 solver.cpp:228] Iteration 205900, loss = 3.27375
I0826 14:44:33.983678  1343 solver.cpp:244]     Train net output #0: loss = 3.27375 (* 1 = 3.27375 loss)
I0826 14:44:33.983686  1343 sgd_solver.cpp:106] Iteration 205900, lr = 1.62306e-07
I0826 14:44:42.407755  1343 solver.cpp:228] Iteration 206000, loss = 3.28097
I0826 14:44:42.407816  1343 solver.cpp:244]     Train net output #0: loss = 3.28097 (* 1 = 3.28097 loss)
I0826 14:44:42.407829  1343 sgd_solver.cpp:106] Iteration 206000, lr = 1.62252e-07
I0826 14:44:50.840637  1343 solver.cpp:228] Iteration 206100, loss = 3.51381
I0826 14:44:50.840698  1343 solver.cpp:244]     Train net output #0: loss = 3.51381 (* 1 = 3.51381 loss)
I0826 14:44:50.840708  1343 sgd_solver.cpp:106] Iteration 206100, lr = 1.62199e-07
I0826 14:44:59.272609  1343 solver.cpp:228] Iteration 206200, loss = 3.37819
I0826 14:44:59.272667  1343 solver.cpp:244]     Train net output #0: loss = 3.37819 (* 1 = 3.37819 loss)
I0826 14:44:59.272675  1343 sgd_solver.cpp:106] Iteration 206200, lr = 1.62145e-07
I0826 14:45:07.704480  1343 solver.cpp:228] Iteration 206300, loss = 3.24093
I0826 14:45:07.704541  1343 solver.cpp:244]     Train net output #0: loss = 3.24093 (* 1 = 3.24093 loss)
I0826 14:45:07.704550  1343 sgd_solver.cpp:106] Iteration 206300, lr = 1.62091e-07
I0826 14:45:16.118302  1343 solver.cpp:228] Iteration 206400, loss = 3.42871
I0826 14:45:16.118357  1343 solver.cpp:244]     Train net output #0: loss = 3.42871 (* 1 = 3.42871 loss)
I0826 14:45:16.118366  1343 sgd_solver.cpp:106] Iteration 206400, lr = 1.62037e-07
I0826 14:45:24.537927  1343 solver.cpp:228] Iteration 206500, loss = 3.31306
I0826 14:45:24.538003  1343 solver.cpp:244]     Train net output #0: loss = 3.31306 (* 1 = 3.31306 loss)
I0826 14:45:24.538012  1343 sgd_solver.cpp:106] Iteration 206500, lr = 1.61984e-07
I0826 14:45:32.975436  1343 solver.cpp:228] Iteration 206600, loss = 3.43682
I0826 14:45:32.975504  1343 solver.cpp:244]     Train net output #0: loss = 3.43682 (* 1 = 3.43682 loss)
I0826 14:45:32.975517  1343 sgd_solver.cpp:106] Iteration 206600, lr = 1.6193e-07
I0826 14:45:41.417263  1343 solver.cpp:228] Iteration 206700, loss = 3.36132
I0826 14:45:41.417322  1343 solver.cpp:244]     Train net output #0: loss = 3.36132 (* 1 = 3.36132 loss)
I0826 14:45:41.417330  1343 sgd_solver.cpp:106] Iteration 206700, lr = 1.61877e-07
I0826 14:45:49.856673  1343 solver.cpp:228] Iteration 206800, loss = 3.36835
I0826 14:45:49.856742  1343 solver.cpp:244]     Train net output #0: loss = 3.36835 (* 1 = 3.36835 loss)
I0826 14:45:49.856753  1343 sgd_solver.cpp:106] Iteration 206800, lr = 1.61823e-07
I0826 14:45:58.285035  1343 solver.cpp:228] Iteration 206900, loss = 3.32672
I0826 14:45:58.285086  1343 solver.cpp:244]     Train net output #0: loss = 3.32672 (* 1 = 3.32672 loss)
I0826 14:45:58.285095  1343 sgd_solver.cpp:106] Iteration 206900, lr = 1.6177e-07
I0826 14:46:01.820592  1343 blocking_queue.cpp:50] Data layer prefetch queue empty
I0826 14:46:06.706068  1343 solver.cpp:228] Iteration 207000, loss = 3.51884
I0826 14:46:06.706116  1343 solver.cpp:244]     Train net output #0: loss = 3.51884 (* 1 = 3.51884 loss)
I0826 14:46:06.706122  1343 sgd_solver.cpp:106] Iteration 207000, lr = 1.61716e-07
I0826 14:46:15.123319  1343 solver.cpp:228] Iteration 207100, loss = 3.57473
I0826 14:46:15.123376  1343 solver.cpp:244]     Train net output #0: loss = 3.57473 (* 1 = 3.57473 loss)
I0826 14:46:15.123385  1343 sgd_solver.cpp:106] Iteration 207100, lr = 1.61663e-07
I0826 14:46:23.548085  1343 solver.cpp:228] Iteration 207200, loss = 3.20551
I0826 14:46:23.548141  1343 solver.cpp:244]     Train net output #0: loss = 3.20551 (* 1 = 3.20551 loss)
I0826 14:46:23.548149  1343 sgd_solver.cpp:106] Iteration 207200, lr = 1.61609e-07
I0826 14:46:31.973045  1343 solver.cpp:228] Iteration 207300, loss = 3.50867
I0826 14:46:31.973098  1343 solver.cpp:244]     Train net output #0: loss = 3.50867 (* 1 = 3.50867 loss)
I0826 14:46:31.973105  1343 sgd_solver.cpp:106] Iteration 207300, lr = 1.61556e-07
I0826 14:46:40.409317  1343 solver.cpp:228] Iteration 207400, loss = 3.47804
I0826 14:46:40.409385  1343 solver.cpp:244]     Train net output #0: loss = 3.47804 (* 1 = 3.47804 loss)
I0826 14:46:40.409395  1343 sgd_solver.cpp:106] Iteration 207400, lr = 1.61503e-07
I0826 14:46:48.827801  1343 solver.cpp:228] Iteration 207500, loss = 3.48546
I0826 14:46:48.827857  1343 solver.cpp:244]     Train net output #0: loss = 3.48546 (* 1 = 3.48546 loss)
I0826 14:46:48.827865  1343 sgd_solver.cpp:106] Iteration 207500, lr = 1.61449e-07
I0826 14:46:57.253229  1343 solver.cpp:228] Iteration 207600, loss = 3.2796
I0826 14:46:57.253305  1343 solver.cpp:244]     Train net output #0: loss = 3.2796 (* 1 = 3.2796 loss)
I0826 14:46:57.253315  1343 sgd_solver.cpp:106] Iteration 207600, lr = 1.61396e-07
I0826 14:47:05.694777  1343 solver.cpp:228] Iteration 207700, loss = 3.32578
I0826 14:47:05.694855  1343 solver.cpp:244]     Train net output #0: loss = 3.32578 (* 1 = 3.32578 loss)
I0826 14:47:05.694867  1343 sgd_solver.cpp:106] Iteration 207700, lr = 1.61343e-07
I0826 14:47:14.119184  1343 solver.cpp:228] Iteration 207800, loss = 3.31223
I0826 14:47:14.119243  1343 solver.cpp:244]     Train net output #0: loss = 3.31223 (* 1 = 3.31223 loss)
I0826 14:47:14.119254  1343 sgd_solver.cpp:106] Iteration 207800, lr = 1.6129e-07
I0826 14:47:22.548291  1343 solver.cpp:228] Iteration 207900, loss = 3.59452
I0826 14:47:22.548362  1343 solver.cpp:244]     Train net output #0: loss = 3.59452 (* 1 = 3.59452 loss)
I0826 14:47:22.548370  1343 sgd_solver.cpp:106] Iteration 207900, lr = 1.61237e-07
I0826 14:47:30.981822  1343 solver.cpp:228] Iteration 208000, loss = 3.42851
I0826 14:47:30.981886  1343 solver.cpp:244]     Train net output #0: loss = 3.42851 (* 1 = 3.42851 loss)
I0826 14:47:30.981896  1343 sgd_solver.cpp:106] Iteration 208000, lr = 1.61184e-07
I0826 14:47:39.410181  1343 solver.cpp:228] Iteration 208100, loss = 3.37997
I0826 14:47:39.410246  1343 solver.cpp:244]     Train net output #0: loss = 3.37997 (* 1 = 3.37997 loss)
I0826 14:47:39.410257  1343 sgd_solver.cpp:106] Iteration 208100, lr = 1.61131e-07
I0826 14:47:47.844336  1343 solver.cpp:228] Iteration 208200, loss = 3.32222
I0826 14:47:47.844406  1343 solver.cpp:244]     Train net output #0: loss = 3.32222 (* 1 = 3.32222 loss)
I0826 14:47:47.844414  1343 sgd_solver.cpp:106] Iteration 208200, lr = 1.61078e-07
I0826 14:47:56.251333  1343 solver.cpp:228] Iteration 208300, loss = 3.29935
I0826 14:47:56.251405  1343 solver.cpp:244]     Train net output #0: loss = 3.29935 (* 1 = 3.29935 loss)
I0826 14:47:56.251412  1343 sgd_solver.cpp:106] Iteration 208300, lr = 1.61025e-07
I0826 14:48:04.685467  1343 solver.cpp:228] Iteration 208400, loss = 3.57659
I0826 14:48:04.685533  1343 solver.cpp:244]     Train net output #0: loss = 3.57659 (* 1 = 3.57659 loss)
I0826 14:48:04.685547  1343 sgd_solver.cpp:106] Iteration 208400, lr = 1.60972e-07
I0826 14:48:13.116650  1343 solver.cpp:228] Iteration 208500, loss = 3.21421
I0826 14:48:13.116716  1343 solver.cpp:244]     Train net output #0: loss = 3.21421 (* 1 = 3.21421 loss)
I0826 14:48:13.116725  1343 sgd_solver.cpp:106] Iteration 208500, lr = 1.60919e-07
I0826 14:48:21.545794  1343 solver.cpp:228] Iteration 208600, loss = 3.44711
I0826 14:48:21.545866  1343 solver.cpp:244]     Train net output #0: loss = 3.44711 (* 1 = 3.44711 loss)
I0826 14:48:21.545876  1343 sgd_solver.cpp:106] Iteration 208600, lr = 1.60866e-07
I0826 14:48:29.978462  1343 solver.cpp:228] Iteration 208700, loss = 3.279
I0826 14:48:29.978518  1343 solver.cpp:244]     Train net output #0: loss = 3.279 (* 1 = 3.279 loss)
I0826 14:48:29.978526  1343 sgd_solver.cpp:106] Iteration 208700, lr = 1.60814e-07
I0826 14:48:38.402176  1343 solver.cpp:228] Iteration 208800, loss = 3.47637
I0826 14:48:38.402245  1343 solver.cpp:244]     Train net output #0: loss = 3.47637 (* 1 = 3.47637 loss)
I0826 14:48:38.402254  1343 sgd_solver.cpp:106] Iteration 208800, lr = 1.60761e-07
I0826 14:48:46.827385  1343 solver.cpp:228] Iteration 208900, loss = 3.30073
I0826 14:48:46.827469  1343 solver.cpp:244]     Train net output #0: loss = 3.30073 (* 1 = 3.30073 loss)
I0826 14:48:46.827482  1343 sgd_solver.cpp:106] Iteration 208900, lr = 1.60708e-07
I0826 14:48:55.248977  1343 solver.cpp:228] Iteration 209000, loss = 3.29012
I0826 14:48:55.249035  1343 solver.cpp:244]     Train net output #0: loss = 3.29012 (* 1 = 3.29012 loss)
I0826 14:48:55.249043  1343 sgd_solver.cpp:106] Iteration 209000, lr = 1.60656e-07
I0826 14:49:03.672618  1343 solver.cpp:228] Iteration 209100, loss = 3.4452
I0826 14:49:03.672685  1343 solver.cpp:244]     Train net output #0: loss = 3.4452 (* 1 = 3.4452 loss)
I0826 14:49:03.672696  1343 sgd_solver.cpp:106] Iteration 209100, lr = 1.60603e-07
I0826 14:49:12.107518  1343 solver.cpp:228] Iteration 209200, loss = 3.51908
I0826 14:49:12.107563  1343 solver.cpp:244]     Train net output #0: loss = 3.51908 (* 1 = 3.51908 loss)
I0826 14:49:12.107568  1343 sgd_solver.cpp:106] Iteration 209200, lr = 1.6055e-07
I0826 14:49:20.539999  1343 solver.cpp:228] Iteration 209300, loss = 3.43133
I0826 14:49:20.540042  1343 solver.cpp:244]     Train net output #0: loss = 3.43133 (* 1 = 3.43133 loss)
I0826 14:49:20.540048  1343 sgd_solver.cpp:106] Iteration 209300, lr = 1.60498e-07
I0826 14:49:28.945157  1343 solver.cpp:228] Iteration 209400, loss = 3.45416
I0826 14:49:28.945214  1343 solver.cpp:244]     Train net output #0: loss = 3.45416 (* 1 = 3.45416 loss)
I0826 14:49:28.945222  1343 sgd_solver.cpp:106] Iteration 209400, lr = 1.60445e-07
I0826 14:49:37.376498  1343 solver.cpp:228] Iteration 209500, loss = 3.22598
I0826 14:49:37.376574  1343 solver.cpp:244]     Train net output #0: loss = 3.22598 (* 1 = 3.22598 loss)
I0826 14:49:37.376590  1343 sgd_solver.cpp:106] Iteration 209500, lr = 1.60393e-07
                                                                                                                                                                                                                                                                         