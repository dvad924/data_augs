WARNING: Logging before InitGoogleLogging() is written to STDERR
I0805 19:02:47.340590 10603 solver.cpp:48] Initializing solver from parameters: 
test_iter: 172
test_interval: 500
base_lr: 1e-05
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
snapshot: 5000
snapshot_prefix: "models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001"
solver_mode: GPU
net: "nets/person_background_only_alex_net/trainval.prototxt"
I0805 19:02:47.340669 10603 solver.cpp:91] Creating training net from net file: nets/person_background_only_alex_net/trainval.prototxt
I0805 19:02:47.341174 10603 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0805 19:02:47.341203 10603 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0805 19:02:47.341336 10603 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_only_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_only_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0805 19:02:47.341413 10603 layer_factory.hpp:77] Creating layer mnist
I0805 19:02:47.342463 10603 net.cpp:91] Creating Layer mnist
I0805 19:02:47.342474 10603 net.cpp:399] mnist -> data
I0805 19:02:47.342484 10603 net.cpp:399] mnist -> label
I0805 19:02:47.343822 10610 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_only_train_lmdb
I0805 19:02:47.344068 10603 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_only_color_mean.binaryproto
I0805 19:02:55.609310 10603 data_layer.cpp:41] output data size: 64,3,128,128
I0805 19:02:55.630662 10603 net.cpp:141] Setting up mnist
I0805 19:02:55.630708 10603 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0805 19:02:55.630715 10603 net.cpp:148] Top shape: 64 (64)
I0805 19:02:55.630718 10603 net.cpp:156] Memory required for data: 12583168
I0805 19:02:55.630761 10603 layer_factory.hpp:77] Creating layer conv1
I0805 19:02:55.630836 10603 net.cpp:91] Creating Layer conv1
I0805 19:02:55.630851 10603 net.cpp:425] conv1 <- data
I0805 19:02:55.630867 10603 net.cpp:399] conv1 -> conv1
I0805 19:02:56.124269 10603 net.cpp:141] Setting up conv1
I0805 19:02:56.124320 10603 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0805 19:02:56.124330 10603 net.cpp:156] Memory required for data: 34701568
I0805 19:02:56.124368 10603 layer_factory.hpp:77] Creating layer relu1
I0805 19:02:56.124397 10603 net.cpp:91] Creating Layer relu1
I0805 19:02:56.124406 10603 net.cpp:425] relu1 <- conv1
I0805 19:02:56.124416 10603 net.cpp:386] relu1 -> conv1 (in-place)
I0805 19:02:56.124788 10603 net.cpp:141] Setting up relu1
I0805 19:02:56.124832 10603 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0805 19:02:56.124840 10603 net.cpp:156] Memory required for data: 56819968
I0805 19:02:56.124847 10603 layer_factory.hpp:77] Creating layer norm1
I0805 19:02:56.124872 10603 net.cpp:91] Creating Layer norm1
I0805 19:02:56.124881 10603 net.cpp:425] norm1 <- conv1
I0805 19:02:56.124889 10603 net.cpp:399] norm1 -> norm1
I0805 19:02:56.127465 10603 net.cpp:141] Setting up norm1
I0805 19:02:56.127492 10603 net.cpp:148] Top shape: 64 96 30 30 (5529600)
I0805 19:02:56.127499 10603 net.cpp:156] Memory required for data: 78938368
I0805 19:02:56.127507 10603 layer_factory.hpp:77] Creating layer pool1
I0805 19:02:56.127526 10603 net.cpp:91] Creating Layer pool1
I0805 19:02:56.127532 10603 net.cpp:425] pool1 <- norm1
I0805 19:02:56.127542 10603 net.cpp:399] pool1 -> pool1
I0805 19:02:56.127609 10603 net.cpp:141] Setting up pool1
I0805 19:02:56.127625 10603 net.cpp:148] Top shape: 64 96 15 15 (1382400)
I0805 19:02:56.127631 10603 net.cpp:156] Memory required for data: 84467968
I0805 19:02:56.127637 10603 layer_factory.hpp:77] Creating layer conv2
I0805 19:02:56.127673 10603 net.cpp:91] Creating Layer conv2
I0805 19:02:56.127683 10603 net.cpp:425] conv2 <- pool1
I0805 19:02:56.127694 10603 net.cpp:399] conv2 -> conv2
I0805 19:02:56.148953 10603 net.cpp:141] Setting up conv2
I0805 19:02:56.148980 10603 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0805 19:02:56.148988 10603 net.cpp:156] Memory required for data: 99213568
I0805 19:02:56.149004 10603 layer_factory.hpp:77] Creating layer relu2
I0805 19:02:56.149015 10603 net.cpp:91] Creating Layer relu2
I0805 19:02:56.149021 10603 net.cpp:425] relu2 <- conv2
I0805 19:02:56.149030 10603 net.cpp:386] relu2 -> conv2 (in-place)
I0805 19:02:56.149489 10603 net.cpp:141] Setting up relu2
I0805 19:02:56.149510 10603 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0805 19:02:56.149518 10603 net.cpp:156] Memory required for data: 113959168
I0805 19:02:56.149523 10603 layer_factory.hpp:77] Creating layer norm2
I0805 19:02:56.149544 10603 net.cpp:91] Creating Layer norm2
I0805 19:02:56.149551 10603 net.cpp:425] norm2 <- conv2
I0805 19:02:56.149560 10603 net.cpp:399] norm2 -> norm2
I0805 19:02:56.149883 10603 net.cpp:141] Setting up norm2
I0805 19:02:56.149900 10603 net.cpp:148] Top shape: 64 256 15 15 (3686400)
I0805 19:02:56.149905 10603 net.cpp:156] Memory required for data: 128704768
I0805 19:02:56.149911 10603 layer_factory.hpp:77] Creating layer pool2
I0805 19:02:56.149924 10603 net.cpp:91] Creating Layer pool2
I0805 19:02:56.149930 10603 net.cpp:425] pool2 <- norm2
I0805 19:02:56.149937 10603 net.cpp:399] pool2 -> pool2
I0805 19:02:56.149992 10603 net.cpp:141] Setting up pool2
I0805 19:02:56.150010 10603 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0805 19:02:56.150015 10603 net.cpp:156] Memory required for data: 131916032
I0805 19:02:56.150020 10603 layer_factory.hpp:77] Creating layer conv3
I0805 19:02:56.150046 10603 net.cpp:91] Creating Layer conv3
I0805 19:02:56.150058 10603 net.cpp:425] conv3 <- pool2
I0805 19:02:56.150066 10603 net.cpp:399] conv3 -> conv3
I0805 19:02:56.196022 10603 net.cpp:141] Setting up conv3
I0805 19:02:56.196045 10603 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0805 19:02:56.196051 10603 net.cpp:156] Memory required for data: 136732928
I0805 19:02:56.196064 10603 layer_factory.hpp:77] Creating layer relu3
I0805 19:02:56.196074 10603 net.cpp:91] Creating Layer relu3
I0805 19:02:56.196079 10603 net.cpp:425] relu3 <- conv3
I0805 19:02:56.196085 10603 net.cpp:386] relu3 -> conv3 (in-place)
I0805 19:02:56.196471 10603 net.cpp:141] Setting up relu3
I0805 19:02:56.196490 10603 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0805 19:02:56.196494 10603 net.cpp:156] Memory required for data: 141549824
I0805 19:02:56.196499 10603 layer_factory.hpp:77] Creating layer conv4
I0805 19:02:56.196511 10603 net.cpp:91] Creating Layer conv4
I0805 19:02:56.196517 10603 net.cpp:425] conv4 <- conv3
I0805 19:02:56.196526 10603 net.cpp:399] conv4 -> conv4
I0805 19:02:56.226702 10603 net.cpp:141] Setting up conv4
I0805 19:02:56.226722 10603 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0805 19:02:56.226727 10603 net.cpp:156] Memory required for data: 146366720
I0805 19:02:56.226734 10603 layer_factory.hpp:77] Creating layer relu4
I0805 19:02:56.226742 10603 net.cpp:91] Creating Layer relu4
I0805 19:02:56.226747 10603 net.cpp:425] relu4 <- conv4
I0805 19:02:56.226754 10603 net.cpp:386] relu4 -> conv4 (in-place)
I0805 19:02:56.227092 10603 net.cpp:141] Setting up relu4
I0805 19:02:56.227107 10603 net.cpp:148] Top shape: 64 384 7 7 (1204224)
I0805 19:02:56.227111 10603 net.cpp:156] Memory required for data: 151183616
I0805 19:02:56.227115 10603 layer_factory.hpp:77] Creating layer conv5
I0805 19:02:56.227128 10603 net.cpp:91] Creating Layer conv5
I0805 19:02:56.227133 10603 net.cpp:425] conv5 <- conv4
I0805 19:02:56.227140 10603 net.cpp:399] conv5 -> conv5
I0805 19:02:56.246368 10603 net.cpp:141] Setting up conv5
I0805 19:02:56.246387 10603 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0805 19:02:56.246392 10603 net.cpp:156] Memory required for data: 154394880
I0805 19:02:56.246402 10603 layer_factory.hpp:77] Creating layer relu5
I0805 19:02:56.246423 10603 net.cpp:91] Creating Layer relu5
I0805 19:02:56.246428 10603 net.cpp:425] relu5 <- conv5
I0805 19:02:56.246433 10603 net.cpp:386] relu5 -> conv5 (in-place)
I0805 19:02:56.246747 10603 net.cpp:141] Setting up relu5
I0805 19:02:56.246762 10603 net.cpp:148] Top shape: 64 256 7 7 (802816)
I0805 19:02:56.246765 10603 net.cpp:156] Memory required for data: 157606144
I0805 19:02:56.246769 10603 layer_factory.hpp:77] Creating layer pool5
I0805 19:02:56.246776 10603 net.cpp:91] Creating Layer pool5
I0805 19:02:56.246780 10603 net.cpp:425] pool5 <- conv5
I0805 19:02:56.246788 10603 net.cpp:399] pool5 -> pool5
I0805 19:02:56.246835 10603 net.cpp:141] Setting up pool5
I0805 19:02:56.246842 10603 net.cpp:148] Top shape: 64 256 3 3 (147456)
I0805 19:02:56.246846 10603 net.cpp:156] Memory required for data: 158195968
I0805 19:02:56.246850 10603 layer_factory.hpp:77] Creating layer fc6
I0805 19:02:56.246861 10603 net.cpp:91] Creating Layer fc6
I0805 19:02:56.246865 10603 net.cpp:425] fc6 <- pool5
I0805 19:02:56.246871 10603 net.cpp:399] fc6 -> fc6
I0805 19:02:56.503689 10603 net.cpp:141] Setting up fc6
I0805 19:02:56.503721 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.503726 10603 net.cpp:156] Memory required for data: 159244544
I0805 19:02:56.503734 10603 layer_factory.hpp:77] Creating layer relu6
I0805 19:02:56.503744 10603 net.cpp:91] Creating Layer relu6
I0805 19:02:56.503748 10603 net.cpp:425] relu6 <- fc6
I0805 19:02:56.503754 10603 net.cpp:386] relu6 -> fc6 (in-place)
I0805 19:02:56.504000 10603 net.cpp:141] Setting up relu6
I0805 19:02:56.504009 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.504024 10603 net.cpp:156] Memory required for data: 160293120
I0805 19:02:56.504026 10603 layer_factory.hpp:77] Creating layer drop6
I0805 19:02:56.504042 10603 net.cpp:91] Creating Layer drop6
I0805 19:02:56.504045 10603 net.cpp:425] drop6 <- fc6
I0805 19:02:56.504050 10603 net.cpp:386] drop6 -> fc6 (in-place)
I0805 19:02:56.504073 10603 net.cpp:141] Setting up drop6
I0805 19:02:56.504079 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.504081 10603 net.cpp:156] Memory required for data: 161341696
I0805 19:02:56.504096 10603 layer_factory.hpp:77] Creating layer fc7
I0805 19:02:56.504102 10603 net.cpp:91] Creating Layer fc7
I0805 19:02:56.504106 10603 net.cpp:425] fc7 <- fc6
I0805 19:02:56.504112 10603 net.cpp:399] fc7 -> fc7
I0805 19:02:56.954829 10603 net.cpp:141] Setting up fc7
I0805 19:02:56.954856 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.954860 10603 net.cpp:156] Memory required for data: 162390272
I0805 19:02:56.954869 10603 layer_factory.hpp:77] Creating layer relu7
I0805 19:02:56.954876 10603 net.cpp:91] Creating Layer relu7
I0805 19:02:56.954880 10603 net.cpp:425] relu7 <- fc7
I0805 19:02:56.954885 10603 net.cpp:386] relu7 -> fc7 (in-place)
I0805 19:02:56.955266 10603 net.cpp:141] Setting up relu7
I0805 19:02:56.955278 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.955292 10603 net.cpp:156] Memory required for data: 163438848
I0805 19:02:56.955296 10603 layer_factory.hpp:77] Creating layer drop7
I0805 19:02:56.955302 10603 net.cpp:91] Creating Layer drop7
I0805 19:02:56.955307 10603 net.cpp:425] drop7 <- fc7
I0805 19:02:56.955312 10603 net.cpp:386] drop7 -> fc7 (in-place)
I0805 19:02:56.955348 10603 net.cpp:141] Setting up drop7
I0805 19:02:56.955353 10603 net.cpp:148] Top shape: 64 4096 (262144)
I0805 19:02:56.955355 10603 net.cpp:156] Memory required for data: 164487424
I0805 19:02:56.955358 10603 layer_factory.hpp:77] Creating layer fc8
I0805 19:02:56.955394 10603 net.cpp:91] Creating Layer fc8
I0805 19:02:56.955396 10603 net.cpp:425] fc8 <- fc7
I0805 19:02:56.955401 10603 net.cpp:399] fc8 -> fc8
I0805 19:02:56.956215 10603 net.cpp:141] Setting up fc8
I0805 19:02:56.956228 10603 net.cpp:148] Top shape: 64 2 (128)
I0805 19:02:56.956241 10603 net.cpp:156] Memory required for data: 164487936
I0805 19:02:56.956248 10603 layer_factory.hpp:77] Creating layer loss
I0805 19:02:56.956256 10603 net.cpp:91] Creating Layer loss
I0805 19:02:56.956260 10603 net.cpp:425] loss <- fc8
I0805 19:02:56.956264 10603 net.cpp:425] loss <- label
I0805 19:02:56.956269 10603 net.cpp:399] loss -> loss
I0805 19:02:56.956287 10603 layer_factory.hpp:77] Creating layer loss
I0805 19:02:56.956562 10603 net.cpp:141] Setting up loss
I0805 19:02:56.956571 10603 net.cpp:148] Top shape: (1)
I0805 19:02:56.956585 10603 net.cpp:151]     with loss weight 1
I0805 19:02:56.956598 10603 net.cpp:156] Memory required for data: 164487940
I0805 19:02:56.956603 10603 net.cpp:217] loss needs backward computation.
I0805 19:02:56.956606 10603 net.cpp:217] fc8 needs backward computation.
I0805 19:02:56.956609 10603 net.cpp:217] drop7 needs backward computation.
I0805 19:02:56.956611 10603 net.cpp:217] relu7 needs backward computation.
I0805 19:02:56.956614 10603 net.cpp:217] fc7 needs backward computation.
I0805 19:02:56.956616 10603 net.cpp:217] drop6 needs backward computation.
I0805 19:02:56.956619 10603 net.cpp:217] relu6 needs backward computation.
I0805 19:02:56.956621 10603 net.cpp:217] fc6 needs backward computation.
I0805 19:02:56.956625 10603 net.cpp:217] pool5 needs backward computation.
I0805 19:02:56.956629 10603 net.cpp:217] relu5 needs backward computation.
I0805 19:02:56.956631 10603 net.cpp:217] conv5 needs backward computation.
I0805 19:02:56.956634 10603 net.cpp:217] relu4 needs backward computation.
I0805 19:02:56.956637 10603 net.cpp:217] conv4 needs backward computation.
I0805 19:02:56.956640 10603 net.cpp:217] relu3 needs backward computation.
I0805 19:02:56.956642 10603 net.cpp:217] conv3 needs backward computation.
I0805 19:02:56.956646 10603 net.cpp:217] pool2 needs backward computation.
I0805 19:02:56.956650 10603 net.cpp:217] norm2 needs backward computation.
I0805 19:02:56.956652 10603 net.cpp:217] relu2 needs backward computation.
I0805 19:02:56.956655 10603 net.cpp:217] conv2 needs backward computation.
I0805 19:02:56.956658 10603 net.cpp:217] pool1 needs backward computation.
I0805 19:02:56.956660 10603 net.cpp:217] norm1 needs backward computation.
I0805 19:02:56.956663 10603 net.cpp:217] relu1 needs backward computation.
I0805 19:02:56.956666 10603 net.cpp:217] conv1 needs backward computation.
I0805 19:02:56.956670 10603 net.cpp:219] mnist does not need backward computation.
I0805 19:02:56.956672 10603 net.cpp:261] This network produces output loss
I0805 19:02:56.956684 10603 net.cpp:274] Network initialization done.
I0805 19:02:56.957429 10603 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_background_only_alex_net/trainval.prototxt
I0805 19:02:56.957479 10603 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0805 19:02:56.957628 10603 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_background_only_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_only_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0805 19:02:56.957720 10603 layer_factory.hpp:77] Creating layer mnist
I0805 19:02:56.957816 10603 net.cpp:91] Creating Layer mnist
I0805 19:02:56.957823 10603 net.cpp:399] mnist -> data
I0805 19:02:56.957830 10603 net.cpp:399] mnist -> label
I0805 19:02:56.957837 10603 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_only_color_mean.binaryproto
I0805 19:02:56.959233 10612 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_only_test_lmdb
I0805 19:02:56.959578 10603 data_layer.cpp:41] output data size: 100,3,128,128
I0805 19:02:57.001528 10603 net.cpp:141] Setting up mnist
I0805 19:02:57.001554 10603 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0805 19:02:57.001559 10603 net.cpp:148] Top shape: 100 (100)
I0805 19:02:57.001561 10603 net.cpp:156] Memory required for data: 19661200
I0805 19:02:57.001566 10603 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0805 19:02:57.001576 10603 net.cpp:91] Creating Layer label_mnist_1_split
I0805 19:02:57.001579 10603 net.cpp:425] label_mnist_1_split <- label
I0805 19:02:57.001585 10603 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0805 19:02:57.001593 10603 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0805 19:02:57.001669 10603 net.cpp:141] Setting up label_mnist_1_split
I0805 19:02:57.001675 10603 net.cpp:148] Top shape: 100 (100)
I0805 19:02:57.001678 10603 net.cpp:148] Top shape: 100 (100)
I0805 19:02:57.001682 10603 net.cpp:156] Memory required for data: 19662000
I0805 19:02:57.001684 10603 layer_factory.hpp:77] Creating layer conv1
I0805 19:02:57.001695 10603 net.cpp:91] Creating Layer conv1
I0805 19:02:57.001698 10603 net.cpp:425] conv1 <- data
I0805 19:02:57.001703 10603 net.cpp:399] conv1 -> conv1
I0805 19:02:57.006948 10603 net.cpp:141] Setting up conv1
I0805 19:02:57.006965 10603 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0805 19:02:57.006969 10603 net.cpp:156] Memory required for data: 54222000
I0805 19:02:57.006978 10603 layer_factory.hpp:77] Creating layer relu1
I0805 19:02:57.006984 10603 net.cpp:91] Creating Layer relu1
I0805 19:02:57.006989 10603 net.cpp:425] relu1 <- conv1
I0805 19:02:57.006992 10603 net.cpp:386] relu1 -> conv1 (in-place)
I0805 19:02:57.007261 10603 net.cpp:141] Setting up relu1
I0805 19:02:57.007272 10603 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0805 19:02:57.007287 10603 net.cpp:156] Memory required for data: 88782000
I0805 19:02:57.007290 10603 layer_factory.hpp:77] Creating layer norm1
I0805 19:02:57.007297 10603 net.cpp:91] Creating Layer norm1
I0805 19:02:57.007300 10603 net.cpp:425] norm1 <- conv1
I0805 19:02:57.007305 10603 net.cpp:399] norm1 -> norm1
I0805 19:02:57.007503 10603 net.cpp:141] Setting up norm1
I0805 19:02:57.007522 10603 net.cpp:148] Top shape: 100 96 30 30 (8640000)
I0805 19:02:57.007525 10603 net.cpp:156] Memory required for data: 123342000
I0805 19:02:57.007529 10603 layer_factory.hpp:77] Creating layer pool1
I0805 19:02:57.007545 10603 net.cpp:91] Creating Layer pool1
I0805 19:02:57.007549 10603 net.cpp:425] pool1 <- norm1
I0805 19:02:57.007553 10603 net.cpp:399] pool1 -> pool1
I0805 19:02:57.007587 10603 net.cpp:141] Setting up pool1
I0805 19:02:57.007593 10603 net.cpp:148] Top shape: 100 96 15 15 (2160000)
I0805 19:02:57.007596 10603 net.cpp:156] Memory required for data: 131982000
I0805 19:02:57.007598 10603 layer_factory.hpp:77] Creating layer conv2
I0805 19:02:57.007617 10603 net.cpp:91] Creating Layer conv2
I0805 19:02:57.007621 10603 net.cpp:425] conv2 <- pool1
I0805 19:02:57.007625 10603 net.cpp:399] conv2 -> conv2
I0805 19:02:57.017305 10603 net.cpp:141] Setting up conv2
I0805 19:02:57.017319 10603 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0805 19:02:57.017323 10603 net.cpp:156] Memory required for data: 155022000
I0805 19:02:57.017330 10603 layer_factory.hpp:77] Creating layer relu2
I0805 19:02:57.017336 10603 net.cpp:91] Creating Layer relu2
I0805 19:02:57.017339 10603 net.cpp:425] relu2 <- conv2
I0805 19:02:57.017344 10603 net.cpp:386] relu2 -> conv2 (in-place)
I0805 19:02:57.017621 10603 net.cpp:141] Setting up relu2
I0805 19:02:57.017632 10603 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0805 19:02:57.017647 10603 net.cpp:156] Memory required for data: 178062000
I0805 19:02:57.017649 10603 layer_factory.hpp:77] Creating layer norm2
I0805 19:02:57.017657 10603 net.cpp:91] Creating Layer norm2
I0805 19:02:57.017659 10603 net.cpp:425] norm2 <- conv2
I0805 19:02:57.017664 10603 net.cpp:399] norm2 -> norm2
I0805 19:02:57.017854 10603 net.cpp:141] Setting up norm2
I0805 19:02:57.017864 10603 net.cpp:148] Top shape: 100 256 15 15 (5760000)
I0805 19:02:57.017879 10603 net.cpp:156] Memory required for data: 201102000
I0805 19:02:57.017881 10603 layer_factory.hpp:77] Creating layer pool2
I0805 19:02:57.017886 10603 net.cpp:91] Creating Layer pool2
I0805 19:02:57.017889 10603 net.cpp:425] pool2 <- norm2
I0805 19:02:57.017894 10603 net.cpp:399] pool2 -> pool2
I0805 19:02:57.017926 10603 net.cpp:141] Setting up pool2
I0805 19:02:57.017931 10603 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0805 19:02:57.017935 10603 net.cpp:156] Memory required for data: 206119600
I0805 19:02:57.017937 10603 layer_factory.hpp:77] Creating layer conv3
I0805 19:02:57.017945 10603 net.cpp:91] Creating Layer conv3
I0805 19:02:57.017948 10603 net.cpp:425] conv3 <- pool2
I0805 19:02:57.017953 10603 net.cpp:399] conv3 -> conv3
I0805 19:02:57.042268 10603 net.cpp:141] Setting up conv3
I0805 19:02:57.042282 10603 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0805 19:02:57.042286 10603 net.cpp:156] Memory required for data: 213646000
I0805 19:02:57.042294 10603 layer_factory.hpp:77] Creating layer relu3
I0805 19:02:57.042300 10603 net.cpp:91] Creating Layer relu3
I0805 19:02:57.042304 10603 net.cpp:425] relu3 <- conv3
I0805 19:02:57.042307 10603 net.cpp:386] relu3 -> conv3 (in-place)
I0805 19:02:57.042482 10603 net.cpp:141] Setting up relu3
I0805 19:02:57.042491 10603 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0805 19:02:57.042505 10603 net.cpp:156] Memory required for data: 221172400
I0805 19:02:57.042508 10603 layer_factory.hpp:77] Creating layer conv4
I0805 19:02:57.042516 10603 net.cpp:91] Creating Layer conv4
I0805 19:02:57.042520 10603 net.cpp:425] conv4 <- conv3
I0805 19:02:57.042526 10603 net.cpp:399] conv4 -> conv4
I0805 19:02:57.061660 10603 net.cpp:141] Setting up conv4
I0805 19:02:57.061673 10603 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0805 19:02:57.061676 10603 net.cpp:156] Memory required for data: 228698800
I0805 19:02:57.061682 10603 layer_factory.hpp:77] Creating layer relu4
I0805 19:02:57.061688 10603 net.cpp:91] Creating Layer relu4
I0805 19:02:57.061691 10603 net.cpp:425] relu4 <- conv4
I0805 19:02:57.061697 10603 net.cpp:386] relu4 -> conv4 (in-place)
I0805 19:02:57.061985 10603 net.cpp:141] Setting up relu4
I0805 19:02:57.061996 10603 net.cpp:148] Top shape: 100 384 7 7 (1881600)
I0805 19:02:57.062011 10603 net.cpp:156] Memory required for data: 236225200
I0805 19:02:57.062014 10603 layer_factory.hpp:77] Creating layer conv5
I0805 19:02:57.062022 10603 net.cpp:91] Creating Layer conv5
I0805 19:02:57.062026 10603 net.cpp:425] conv5 <- conv4
I0805 19:02:57.062032 10603 net.cpp:399] conv5 -> conv5
I0805 19:02:57.075042 10603 net.cpp:141] Setting up conv5
I0805 19:02:57.075057 10603 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0805 19:02:57.075059 10603 net.cpp:156] Memory required for data: 241242800
I0805 19:02:57.075068 10603 layer_factory.hpp:77] Creating layer relu5
I0805 19:02:57.075074 10603 net.cpp:91] Creating Layer relu5
I0805 19:02:57.075078 10603 net.cpp:425] relu5 <- conv5
I0805 19:02:57.075081 10603 net.cpp:386] relu5 -> conv5 (in-place)
I0805 19:02:57.075356 10603 net.cpp:141] Setting up relu5
I0805 19:02:57.075366 10603 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I0805 19:02:57.075381 10603 net.cpp:156] Memory required for data: 246260400
I0805 19:02:57.075384 10603 layer_factory.hpp:77] Creating layer pool5
I0805 19:02:57.075392 10603 net.cpp:91] Creating Layer pool5
I0805 19:02:57.075395 10603 net.cpp:425] pool5 <- conv5
I0805 19:02:57.075400 10603 net.cpp:399] pool5 -> pool5
I0805 19:02:57.075443 10603 net.cpp:141] Setting up pool5
I0805 19:02:57.075448 10603 net.cpp:148] Top shape: 100 256 3 3 (230400)
I0805 19:02:57.075451 10603 net.cpp:156] Memory required for data: 247182000
I0805 19:02:57.075453 10603 layer_factory.hpp:77] Creating layer fc6
I0805 19:02:57.075460 10603 net.cpp:91] Creating Layer fc6
I0805 19:02:57.075464 10603 net.cpp:425] fc6 <- pool5
I0805 19:02:57.075469 10603 net.cpp:399] fc6 -> fc6
I0805 19:02:57.331724 10603 net.cpp:141] Setting up fc6
I0805 19:02:57.331753 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.331755 10603 net.cpp:156] Memory required for data: 248820400
I0805 19:02:57.331763 10603 layer_factory.hpp:77] Creating layer relu6
I0805 19:02:57.331770 10603 net.cpp:91] Creating Layer relu6
I0805 19:02:57.331773 10603 net.cpp:425] relu6 <- fc6
I0805 19:02:57.331779 10603 net.cpp:386] relu6 -> fc6 (in-place)
I0805 19:02:57.332002 10603 net.cpp:141] Setting up relu6
I0805 19:02:57.332011 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.332026 10603 net.cpp:156] Memory required for data: 250458800
I0805 19:02:57.332029 10603 layer_factory.hpp:77] Creating layer drop6
I0805 19:02:57.332036 10603 net.cpp:91] Creating Layer drop6
I0805 19:02:57.332038 10603 net.cpp:425] drop6 <- fc6
I0805 19:02:57.332046 10603 net.cpp:386] drop6 -> fc6 (in-place)
I0805 19:02:57.332072 10603 net.cpp:141] Setting up drop6
I0805 19:02:57.332077 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.332079 10603 net.cpp:156] Memory required for data: 252097200
I0805 19:02:57.332082 10603 layer_factory.hpp:77] Creating layer fc7
I0805 19:02:57.332088 10603 net.cpp:91] Creating Layer fc7
I0805 19:02:57.332092 10603 net.cpp:425] fc7 <- fc6
I0805 19:02:57.332096 10603 net.cpp:399] fc7 -> fc7
I0805 19:02:57.784643 10603 net.cpp:141] Setting up fc7
I0805 19:02:57.784679 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.784683 10603 net.cpp:156] Memory required for data: 253735600
I0805 19:02:57.784692 10603 layer_factory.hpp:77] Creating layer relu7
I0805 19:02:57.784703 10603 net.cpp:91] Creating Layer relu7
I0805 19:02:57.784709 10603 net.cpp:425] relu7 <- fc7
I0805 19:02:57.784715 10603 net.cpp:386] relu7 -> fc7 (in-place)
I0805 19:02:57.785229 10603 net.cpp:141] Setting up relu7
I0805 19:02:57.785254 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.785256 10603 net.cpp:156] Memory required for data: 255374000
I0805 19:02:57.785260 10603 layer_factory.hpp:77] Creating layer drop7
I0805 19:02:57.785269 10603 net.cpp:91] Creating Layer drop7
I0805 19:02:57.785272 10603 net.cpp:425] drop7 <- fc7
I0805 19:02:57.785277 10603 net.cpp:386] drop7 -> fc7 (in-place)
I0805 19:02:57.785307 10603 net.cpp:141] Setting up drop7
I0805 19:02:57.785312 10603 net.cpp:148] Top shape: 100 4096 (409600)
I0805 19:02:57.785315 10603 net.cpp:156] Memory required for data: 257012400
I0805 19:02:57.785317 10603 layer_factory.hpp:77] Creating layer fc8
I0805 19:02:57.785328 10603 net.cpp:91] Creating Layer fc8
I0805 19:02:57.785342 10603 net.cpp:425] fc8 <- fc7
I0805 19:02:57.785347 10603 net.cpp:399] fc8 -> fc8
I0805 19:02:57.785742 10603 net.cpp:141] Setting up fc8
I0805 19:02:57.785750 10603 net.cpp:148] Top shape: 100 2 (200)
I0805 19:02:57.785764 10603 net.cpp:156] Memory required for data: 257013200
I0805 19:02:57.785770 10603 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0805 19:02:57.785778 10603 net.cpp:91] Creating Layer fc8_fc8_0_split
I0805 19:02:57.785781 10603 net.cpp:425] fc8_fc8_0_split <- fc8
I0805 19:02:57.785785 10603 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0805 19:02:57.785791 10603 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0805 19:02:57.785825 10603 net.cpp:141] Setting up fc8_fc8_0_split
I0805 19:02:57.785830 10603 net.cpp:148] Top shape: 100 2 (200)
I0805 19:02:57.785833 10603 net.cpp:148] Top shape: 100 2 (200)
I0805 19:02:57.785835 10603 net.cpp:156] Memory required for data: 257014800
I0805 19:02:57.785838 10603 layer_factory.hpp:77] Creating layer accuracy
I0805 19:02:57.785845 10603 net.cpp:91] Creating Layer accuracy
I0805 19:02:57.785847 10603 net.cpp:425] accuracy <- fc8_fc8_0_split_0
I0805 19:02:57.785851 10603 net.cpp:425] accuracy <- label_mnist_1_split_0
I0805 19:02:57.785856 10603 net.cpp:399] accuracy -> accuracy
I0805 19:02:57.785863 10603 net.cpp:141] Setting up accuracy
I0805 19:02:57.785866 10603 net.cpp:148] Top shape: (1)
I0805 19:02:57.785869 10603 net.cpp:156] Memory required for data: 257014804
I0805 19:02:57.785871 10603 layer_factory.hpp:77] Creating layer loss
I0805 19:02:57.785876 10603 net.cpp:91] Creating Layer loss
I0805 19:02:57.785879 10603 net.cpp:425] loss <- fc8_fc8_0_split_1
I0805 19:02:57.785882 10603 net.cpp:425] loss <- label_mnist_1_split_1
I0805 19:02:57.785887 10603 net.cpp:399] loss -> loss
I0805 19:02:57.785893 10603 layer_factory.hpp:77] Creating layer loss
I0805 19:02:57.786146 10603 net.cpp:141] Setting up loss
I0805 19:02:57.786155 10603 net.cpp:148] Top shape: (1)
I0805 19:02:57.786170 10603 net.cpp:151]     with loss weight 1
I0805 19:02:57.786180 10603 net.cpp:156] Memory required for data: 257014808
I0805 19:02:57.786183 10603 net.cpp:217] loss needs backward computation.
I0805 19:02:57.786187 10603 net.cpp:219] accuracy does not need backward computation.
I0805 19:02:57.786191 10603 net.cpp:217] fc8_fc8_0_split needs backward computation.
I0805 19:02:57.786195 10603 net.cpp:217] fc8 needs backward computation.
I0805 19:02:57.786196 10603 net.cpp:217] drop7 needs backward computation.
I0805 19:02:57.786200 10603 net.cpp:217] relu7 needs backward computation.
I0805 19:02:57.786201 10603 net.cpp:217] fc7 needs backward computation.
I0805 19:02:57.786203 10603 net.cpp:217] drop6 needs backward computation.
I0805 19:02:57.786206 10603 net.cpp:217] relu6 needs backward computation.
I0805 19:02:57.786209 10603 net.cpp:217] fc6 needs backward computation.
I0805 19:02:57.786212 10603 net.cpp:217] pool5 needs backward computation.
I0805 19:02:57.786216 10603 net.cpp:217] relu5 needs backward computation.
I0805 19:02:57.786218 10603 net.cpp:217] conv5 needs backward computation.
I0805 19:02:57.786222 10603 net.cpp:217] relu4 needs backward computation.
I0805 19:02:57.786224 10603 net.cpp:217] conv4 needs backward computation.
I0805 19:02:57.786227 10603 net.cpp:217] relu3 needs backward computation.
I0805 19:02:57.786231 10603 net.cpp:217] conv3 needs backward computation.
I0805 19:02:57.786234 10603 net.cpp:217] pool2 needs backward computation.
I0805 19:02:57.786238 10603 net.cpp:217] norm2 needs backward computation.
I0805 19:02:57.786240 10603 net.cpp:217] relu2 needs backward computation.
I0805 19:02:57.786243 10603 net.cpp:217] conv2 needs backward computation.
I0805 19:02:57.786247 10603 net.cpp:217] pool1 needs backward computation.
I0805 19:02:57.786249 10603 net.cpp:217] norm1 needs backward computation.
I0805 19:02:57.786253 10603 net.cpp:217] relu1 needs backward computation.
I0805 19:02:57.786255 10603 net.cpp:217] conv1 needs backward computation.
I0805 19:02:57.786259 10603 net.cpp:219] label_mnist_1_split does not need backward computation.
I0805 19:02:57.786262 10603 net.cpp:219] mnist does not need backward computation.
I0805 19:02:57.786265 10603 net.cpp:261] This network produces output accuracy
I0805 19:02:57.786268 10603 net.cpp:261] This network produces output loss
I0805 19:02:57.786283 10603 net.cpp:274] Network initialization done.
I0805 19:02:57.786373 10603 solver.cpp:60] Solver scaffolding done.
I0805 19:02:57.788277 10603 solver.cpp:337] Iteration 0, Testing net (#0)
I0805 19:02:57.940290 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:03:01.251969 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:03:01.251996 10603 solver.cpp:404]     Test net output #1: loss = 0.702031 (* 1 = 0.702031 loss)
I0805 19:03:01.272507 10603 solver.cpp:228] Iteration 0, loss = 0.695283
I0805 19:03:01.272554 10603 solver.cpp:244]     Train net output #0: loss = 0.695283 (* 1 = 0.695283 loss)
I0805 19:03:01.274168 10603 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0805 19:03:04.310045 10603 solver.cpp:228] Iteration 100, loss = 0.689625
I0805 19:03:04.310065 10603 solver.cpp:244]     Train net output #0: loss = 0.689625 (* 1 = 0.689625 loss)
I0805 19:03:04.310070 10603 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-06
I0805 19:03:07.356775 10603 solver.cpp:228] Iteration 200, loss = 0.687615
I0805 19:03:07.357683 10603 solver.cpp:244]     Train net output #0: loss = 0.687615 (* 1 = 0.687615 loss)
I0805 19:03:07.357692 10603 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-06
I0805 19:03:10.403832 10603 solver.cpp:228] Iteration 300, loss = 0.69827
I0805 19:03:10.403874 10603 solver.cpp:244]     Train net output #0: loss = 0.69827 (* 1 = 0.69827 loss)
I0805 19:03:10.403882 10603 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-06
I0805 19:03:13.449548 10603 solver.cpp:228] Iteration 400, loss = 0.692893
I0805 19:03:13.449587 10603 solver.cpp:244]     Train net output #0: loss = 0.692893 (* 1 = 0.692893 loss)
I0805 19:03:13.449594 10603 sgd_solver.cpp:106] Iteration 400, lr = 9.85258e-06
I0805 19:03:16.467438 10603 solver.cpp:337] Iteration 500, Testing net (#0)
I0805 19:03:19.943927 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:03:19.943954 10603 solver.cpp:404]     Test net output #1: loss = 0.694065 (* 1 = 0.694065 loss)
I0805 19:03:19.956578 10603 solver.cpp:228] Iteration 500, loss = 0.68969
I0805 19:03:19.956650 10603 solver.cpp:244]     Train net output #0: loss = 0.68969 (* 1 = 0.68969 loss)
I0805 19:03:19.956668 10603 sgd_solver.cpp:106] Iteration 500, lr = 9.81651e-06
I0805 19:03:22.998971 10603 solver.cpp:228] Iteration 600, loss = 0.690128
I0805 19:03:22.999016 10603 solver.cpp:244]     Train net output #0: loss = 0.690128 (* 1 = 0.690128 loss)
I0805 19:03:22.999022 10603 sgd_solver.cpp:106] Iteration 600, lr = 9.78075e-06
I0805 19:03:26.039896 10603 solver.cpp:228] Iteration 700, loss = 0.696809
I0805 19:03:26.039943 10603 solver.cpp:244]     Train net output #0: loss = 0.696809 (* 1 = 0.696809 loss)
I0805 19:03:26.039949 10603 sgd_solver.cpp:106] Iteration 700, lr = 9.74529e-06
I0805 19:03:29.087175 10603 solver.cpp:228] Iteration 800, loss = 0.692672
I0805 19:03:29.087216 10603 solver.cpp:244]     Train net output #0: loss = 0.692672 (* 1 = 0.692672 loss)
I0805 19:03:29.087222 10603 sgd_solver.cpp:106] Iteration 800, lr = 9.71013e-06
I0805 19:03:32.132103 10603 solver.cpp:228] Iteration 900, loss = 0.692624
I0805 19:03:32.132146 10603 solver.cpp:244]     Train net output #0: loss = 0.692624 (* 1 = 0.692624 loss)
I0805 19:03:32.132153 10603 sgd_solver.cpp:106] Iteration 900, lr = 9.67526e-06
I0805 19:03:35.167660 10603 solver.cpp:337] Iteration 1000, Testing net (#0)
I0805 19:03:38.644126 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0805 19:03:38.644157 10603 solver.cpp:404]     Test net output #1: loss = 0.693106 (* 1 = 0.693106 loss)
I0805 19:03:38.654168 10603 solver.cpp:228] Iteration 1000, loss = 0.69692
I0805 19:03:38.654187 10603 solver.cpp:244]     Train net output #0: loss = 0.69692 (* 1 = 0.69692 loss)
I0805 19:03:38.654206 10603 sgd_solver.cpp:106] Iteration 1000, lr = 9.64069e-06
I0805 19:03:41.741358 10603 solver.cpp:228] Iteration 1100, loss = 0.69532
I0805 19:03:41.741396 10603 solver.cpp:244]     Train net output #0: loss = 0.69532 (* 1 = 0.69532 loss)
I0805 19:03:41.741402 10603 sgd_solver.cpp:106] Iteration 1100, lr = 9.6064e-06
I0805 19:03:44.832937 10603 solver.cpp:228] Iteration 1200, loss = 0.698019
I0805 19:03:44.832993 10603 solver.cpp:244]     Train net output #0: loss = 0.698019 (* 1 = 0.698019 loss)
I0805 19:03:44.833001 10603 sgd_solver.cpp:106] Iteration 1200, lr = 9.5724e-06
I0805 19:03:47.914890 10603 solver.cpp:228] Iteration 1300, loss = 0.69352
I0805 19:03:47.914927 10603 solver.cpp:244]     Train net output #0: loss = 0.69352 (* 1 = 0.69352 loss)
I0805 19:03:47.914932 10603 sgd_solver.cpp:106] Iteration 1300, lr = 9.53867e-06
I0805 19:03:50.999841 10603 solver.cpp:228] Iteration 1400, loss = 0.68851
I0805 19:03:50.999883 10603 solver.cpp:244]     Train net output #0: loss = 0.68851 (* 1 = 0.68851 loss)
I0805 19:03:50.999891 10603 sgd_solver.cpp:106] Iteration 1400, lr = 9.50522e-06
I0805 19:03:54.053133 10603 solver.cpp:337] Iteration 1500, Testing net (#0)
I0805 19:03:57.692867 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:03:57.692922 10603 solver.cpp:404]     Test net output #1: loss = 0.693745 (* 1 = 0.693745 loss)
I0805 19:03:57.705322 10603 solver.cpp:228] Iteration 1500, loss = 0.692819
I0805 19:03:57.705353 10603 solver.cpp:244]     Train net output #0: loss = 0.692819 (* 1 = 0.692819 loss)
I0805 19:03:57.705365 10603 sgd_solver.cpp:106] Iteration 1500, lr = 9.47204e-06
I0805 19:04:00.777787 10603 solver.cpp:228] Iteration 1600, loss = 0.702822
I0805 19:04:00.777823 10603 solver.cpp:244]     Train net output #0: loss = 0.702822 (* 1 = 0.702822 loss)
I0805 19:04:00.777829 10603 sgd_solver.cpp:106] Iteration 1600, lr = 9.43913e-06
I0805 19:04:03.865402 10603 solver.cpp:228] Iteration 1700, loss = 0.693053
I0805 19:04:03.865461 10603 solver.cpp:244]     Train net output #0: loss = 0.693053 (* 1 = 0.693053 loss)
I0805 19:04:03.865468 10603 sgd_solver.cpp:106] Iteration 1700, lr = 9.40649e-06
I0805 19:04:06.957650 10603 solver.cpp:228] Iteration 1800, loss = 0.69815
I0805 19:04:06.957687 10603 solver.cpp:244]     Train net output #0: loss = 0.69815 (* 1 = 0.69815 loss)
I0805 19:04:06.957695 10603 sgd_solver.cpp:106] Iteration 1800, lr = 9.37411e-06
I0805 19:04:10.058496 10603 solver.cpp:228] Iteration 1900, loss = 0.69371
I0805 19:04:10.058542 10603 solver.cpp:244]     Train net output #0: loss = 0.69371 (* 1 = 0.69371 loss)
I0805 19:04:10.058549 10603 sgd_solver.cpp:106] Iteration 1900, lr = 9.34199e-06
I0805 19:04:13.133450 10603 solver.cpp:337] Iteration 2000, Testing net (#0)
I0805 19:04:16.780086 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:04:16.780143 10603 solver.cpp:404]     Test net output #1: loss = 0.695078 (* 1 = 0.695078 loss)
I0805 19:04:16.790587 10603 solver.cpp:228] Iteration 2000, loss = 0.6992
I0805 19:04:16.790621 10603 solver.cpp:244]     Train net output #0: loss = 0.6992 (* 1 = 0.6992 loss)
I0805 19:04:16.790642 10603 sgd_solver.cpp:106] Iteration 2000, lr = 9.31012e-06
I0805 19:04:19.315402 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:04:20.028905 10603 solver.cpp:228] Iteration 2100, loss = 0.69352
I0805 19:04:20.028936 10603 solver.cpp:244]     Train net output #0: loss = 0.69352 (* 1 = 0.69352 loss)
I0805 19:04:20.028942 10603 sgd_solver.cpp:106] Iteration 2100, lr = 9.27851e-06
I0805 19:04:23.272115 10603 solver.cpp:228] Iteration 2200, loss = 0.697137
I0805 19:04:23.272136 10603 solver.cpp:244]     Train net output #0: loss = 0.697137 (* 1 = 0.697137 loss)
I0805 19:04:23.272142 10603 sgd_solver.cpp:106] Iteration 2200, lr = 9.24715e-06
I0805 19:04:26.511673 10603 solver.cpp:228] Iteration 2300, loss = 0.684952
I0805 19:04:26.511716 10603 solver.cpp:244]     Train net output #0: loss = 0.684952 (* 1 = 0.684952 loss)
I0805 19:04:26.511723 10603 sgd_solver.cpp:106] Iteration 2300, lr = 9.21603e-06
I0805 19:04:29.751405 10603 solver.cpp:228] Iteration 2400, loss = 0.701201
I0805 19:04:29.751453 10603 solver.cpp:244]     Train net output #0: loss = 0.701201 (* 1 = 0.701201 loss)
I0805 19:04:29.751461 10603 sgd_solver.cpp:106] Iteration 2400, lr = 9.18515e-06
I0805 19:04:32.957674 10603 solver.cpp:337] Iteration 2500, Testing net (#0)
I0805 19:04:36.479018 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:04:36.479064 10603 solver.cpp:404]     Test net output #1: loss = 0.693448 (* 1 = 0.693448 loss)
I0805 19:04:36.492226 10603 solver.cpp:228] Iteration 2500, loss = 0.683905
I0805 19:04:36.492260 10603 solver.cpp:244]     Train net output #0: loss = 0.683905 (* 1 = 0.683905 loss)
I0805 19:04:36.492272 10603 sgd_solver.cpp:106] Iteration 2500, lr = 9.15452e-06
I0805 19:04:39.743088 10603 solver.cpp:228] Iteration 2600, loss = 0.700946
I0805 19:04:39.743127 10603 solver.cpp:244]     Train net output #0: loss = 0.700946 (* 1 = 0.700946 loss)
I0805 19:04:39.743134 10603 sgd_solver.cpp:106] Iteration 2600, lr = 9.12412e-06
I0805 19:04:42.998500 10603 solver.cpp:228] Iteration 2700, loss = 0.698506
I0805 19:04:42.998543 10603 solver.cpp:244]     Train net output #0: loss = 0.698506 (* 1 = 0.698506 loss)
I0805 19:04:42.998550 10603 sgd_solver.cpp:106] Iteration 2700, lr = 9.09396e-06
I0805 19:04:46.248241 10603 solver.cpp:228] Iteration 2800, loss = 0.699592
I0805 19:04:46.248281 10603 solver.cpp:244]     Train net output #0: loss = 0.699592 (* 1 = 0.699592 loss)
I0805 19:04:46.248288 10603 sgd_solver.cpp:106] Iteration 2800, lr = 9.06403e-06
I0805 19:04:49.501214 10603 solver.cpp:228] Iteration 2900, loss = 0.696098
I0805 19:04:49.501252 10603 solver.cpp:244]     Train net output #0: loss = 0.696098 (* 1 = 0.696098 loss)
I0805 19:04:49.501258 10603 sgd_solver.cpp:106] Iteration 2900, lr = 9.03433e-06
I0805 19:04:52.724045 10603 solver.cpp:337] Iteration 3000, Testing net (#0)
I0805 19:04:56.378770 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208953
I0805 19:04:56.378814 10603 solver.cpp:404]     Test net output #1: loss = 0.693935 (* 1 = 0.693935 loss)
I0805 19:04:56.392105 10603 solver.cpp:228] Iteration 3000, loss = 0.687035
I0805 19:04:56.392143 10603 solver.cpp:244]     Train net output #0: loss = 0.687035 (* 1 = 0.687035 loss)
I0805 19:04:56.392154 10603 sgd_solver.cpp:106] Iteration 3000, lr = 9.00485e-06
I0805 19:04:59.609813 10603 solver.cpp:228] Iteration 3100, loss = 0.696158
I0805 19:04:59.609853 10603 solver.cpp:244]     Train net output #0: loss = 0.696158 (* 1 = 0.696158 loss)
I0805 19:04:59.609858 10603 sgd_solver.cpp:106] Iteration 3100, lr = 8.9756e-06
I0805 19:05:02.847854 10603 solver.cpp:228] Iteration 3200, loss = 0.701484
I0805 19:05:02.847873 10603 solver.cpp:244]     Train net output #0: loss = 0.701484 (* 1 = 0.701484 loss)
I0805 19:05:02.847878 10603 sgd_solver.cpp:106] Iteration 3200, lr = 8.94657e-06
I0805 19:05:06.084046 10603 solver.cpp:228] Iteration 3300, loss = 0.690051
I0805 19:05:06.084106 10603 solver.cpp:244]     Train net output #0: loss = 0.690051 (* 1 = 0.690051 loss)
I0805 19:05:06.084116 10603 sgd_solver.cpp:106] Iteration 3300, lr = 8.91776e-06
I0805 19:05:09.330713 10603 solver.cpp:228] Iteration 3400, loss = 0.689928
I0805 19:05:09.330766 10603 solver.cpp:244]     Train net output #0: loss = 0.689928 (* 1 = 0.689928 loss)
I0805 19:05:09.330775 10603 sgd_solver.cpp:106] Iteration 3400, lr = 8.88916e-06
I0805 19:05:12.562299 10603 solver.cpp:337] Iteration 3500, Testing net (#0)
I0805 19:05:16.227465 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0805 19:05:16.227512 10603 solver.cpp:404]     Test net output #1: loss = 0.692819 (* 1 = 0.692819 loss)
I0805 19:05:16.237917 10603 solver.cpp:228] Iteration 3500, loss = 0.685897
I0805 19:05:16.237946 10603 solver.cpp:244]     Train net output #0: loss = 0.685897 (* 1 = 0.685897 loss)
I0805 19:05:16.237957 10603 sgd_solver.cpp:106] Iteration 3500, lr = 8.86077e-06
I0805 19:05:19.485833 10603 solver.cpp:228] Iteration 3600, loss = 0.696949
I0805 19:05:19.485877 10603 solver.cpp:244]     Train net output #0: loss = 0.696949 (* 1 = 0.696949 loss)
I0805 19:05:19.485883 10603 sgd_solver.cpp:106] Iteration 3600, lr = 8.8326e-06
I0805 19:05:22.747860 10603 solver.cpp:228] Iteration 3700, loss = 0.704997
I0805 19:05:22.747902 10603 solver.cpp:244]     Train net output #0: loss = 0.704997 (* 1 = 0.704997 loss)
I0805 19:05:22.747908 10603 sgd_solver.cpp:106] Iteration 3700, lr = 8.80463e-06
I0805 19:05:26.016366 10603 solver.cpp:228] Iteration 3800, loss = 0.700263
I0805 19:05:26.016412 10603 solver.cpp:244]     Train net output #0: loss = 0.700263 (* 1 = 0.700263 loss)
I0805 19:05:26.016419 10603 sgd_solver.cpp:106] Iteration 3800, lr = 8.77687e-06
I0805 19:05:29.304878 10603 solver.cpp:228] Iteration 3900, loss = 0.693575
I0805 19:05:29.304927 10603 solver.cpp:244]     Train net output #0: loss = 0.693575 (* 1 = 0.693575 loss)
I0805 19:05:29.304934 10603 sgd_solver.cpp:106] Iteration 3900, lr = 8.74932e-06
I0805 19:05:32.557358 10603 solver.cpp:337] Iteration 4000, Testing net (#0)
I0805 19:05:36.252166 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:05:36.252214 10603 solver.cpp:404]     Test net output #1: loss = 0.693804 (* 1 = 0.693804 loss)
I0805 19:05:36.265138 10603 solver.cpp:228] Iteration 4000, loss = 0.692989
I0805 19:05:36.265189 10603 solver.cpp:244]     Train net output #0: loss = 0.692989 (* 1 = 0.692989 loss)
I0805 19:05:36.265213 10603 sgd_solver.cpp:106] Iteration 4000, lr = 8.72196e-06
I0805 19:05:39.488524 10603 solver.cpp:228] Iteration 4100, loss = 0.695831
I0805 19:05:39.488562 10603 solver.cpp:244]     Train net output #0: loss = 0.695831 (* 1 = 0.695831 loss)
I0805 19:05:39.488569 10603 sgd_solver.cpp:106] Iteration 4100, lr = 8.6948e-06
I0805 19:05:42.726443 10603 solver.cpp:228] Iteration 4200, loss = 0.687331
I0805 19:05:42.726485 10603 solver.cpp:244]     Train net output #0: loss = 0.687331 (* 1 = 0.687331 loss)
I0805 19:05:42.726492 10603 sgd_solver.cpp:106] Iteration 4200, lr = 8.66784e-06
I0805 19:05:45.969069 10603 solver.cpp:228] Iteration 4300, loss = 0.70134
I0805 19:05:45.969108 10603 solver.cpp:244]     Train net output #0: loss = 0.70134 (* 1 = 0.70134 loss)
I0805 19:05:45.969115 10603 sgd_solver.cpp:106] Iteration 4300, lr = 8.64107e-06
I0805 19:05:49.236549 10603 solver.cpp:228] Iteration 4400, loss = 0.703181
I0805 19:05:49.236603 10603 solver.cpp:244]     Train net output #0: loss = 0.703181 (* 1 = 0.703181 loss)
I0805 19:05:49.236611 10603 sgd_solver.cpp:106] Iteration 4400, lr = 8.6145e-06
I0805 19:05:52.502697 10603 solver.cpp:337] Iteration 4500, Testing net (#0)
I0805 19:05:52.901208 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:05:56.173496 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0805 19:05:56.173528 10603 solver.cpp:404]     Test net output #1: loss = 0.692637 (* 1 = 0.692637 loss)
I0805 19:05:56.186401 10603 solver.cpp:228] Iteration 4500, loss = 0.699197
I0805 19:05:56.186434 10603 solver.cpp:244]     Train net output #0: loss = 0.699197 (* 1 = 0.699197 loss)
I0805 19:05:56.186445 10603 sgd_solver.cpp:106] Iteration 4500, lr = 8.58812e-06
I0805 19:05:59.439136 10603 solver.cpp:228] Iteration 4600, loss = 0.695323
I0805 19:05:59.439177 10603 solver.cpp:244]     Train net output #0: loss = 0.695323 (* 1 = 0.695323 loss)
I0805 19:05:59.439183 10603 sgd_solver.cpp:106] Iteration 4600, lr = 8.56192e-06
I0805 19:06:02.685374 10603 solver.cpp:228] Iteration 4700, loss = 0.687291
I0805 19:06:02.685421 10603 solver.cpp:244]     Train net output #0: loss = 0.687291 (* 1 = 0.687291 loss)
I0805 19:06:02.685427 10603 sgd_solver.cpp:106] Iteration 4700, lr = 8.53591e-06
I0805 19:06:05.937471 10603 solver.cpp:228] Iteration 4800, loss = 0.69402
I0805 19:06:05.937510 10603 solver.cpp:244]     Train net output #0: loss = 0.69402 (* 1 = 0.69402 loss)
I0805 19:06:05.937516 10603 sgd_solver.cpp:106] Iteration 4800, lr = 8.51008e-06
I0805 19:06:09.188901 10603 solver.cpp:228] Iteration 4900, loss = 0.700722
I0805 19:06:09.188952 10603 solver.cpp:244]     Train net output #0: loss = 0.700722 (* 1 = 0.700722 loss)
I0805 19:06:09.188958 10603 sgd_solver.cpp:106] Iteration 4900, lr = 8.48444e-06
I0805 19:06:12.424825 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_5000.caffemodel
I0805 19:06:12.859652 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_5000.solverstate
I0805 19:06:12.992501 10603 solver.cpp:337] Iteration 5000, Testing net (#0)
I0805 19:06:16.464870 10603 solver.cpp:404]     Test net output #0: accuracy = 0.209012
I0805 19:06:16.464926 10603 solver.cpp:404]     Test net output #1: loss = 0.693298 (* 1 = 0.693298 loss)
I0805 19:06:16.478582 10603 solver.cpp:228] Iteration 5000, loss = 0.698948
I0805 19:06:16.478653 10603 solver.cpp:244]     Train net output #0: loss = 0.698948 (* 1 = 0.698948 loss)
I0805 19:06:16.478673 10603 sgd_solver.cpp:106] Iteration 5000, lr = 8.45897e-06
I0805 19:06:19.713668 10603 solver.cpp:228] Iteration 5100, loss = 0.688047
I0805 19:06:19.713711 10603 solver.cpp:244]     Train net output #0: loss = 0.688047 (* 1 = 0.688047 loss)
I0805 19:06:19.713716 10603 sgd_solver.cpp:106] Iteration 5100, lr = 8.43368e-06
I0805 19:06:22.975013 10603 solver.cpp:228] Iteration 5200, loss = 0.695016
I0805 19:06:22.975050 10603 solver.cpp:244]     Train net output #0: loss = 0.695016 (* 1 = 0.695016 loss)
I0805 19:06:22.975056 10603 sgd_solver.cpp:106] Iteration 5200, lr = 8.40857e-06
I0805 19:06:26.281347 10603 solver.cpp:228] Iteration 5300, loss = 0.693932
I0805 19:06:26.281394 10603 solver.cpp:244]     Train net output #0: loss = 0.693932 (* 1 = 0.693932 loss)
I0805 19:06:26.281401 10603 sgd_solver.cpp:106] Iteration 5300, lr = 8.38363e-06
I0805 19:06:29.589421 10603 solver.cpp:228] Iteration 5400, loss = 0.70238
I0805 19:06:29.589479 10603 solver.cpp:244]     Train net output #0: loss = 0.70238 (* 1 = 0.70238 loss)
I0805 19:06:29.589489 10603 sgd_solver.cpp:106] Iteration 5400, lr = 8.35886e-06
I0805 19:06:32.866137 10603 solver.cpp:337] Iteration 5500, Testing net (#0)
I0805 19:06:36.458302 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:06:36.458335 10603 solver.cpp:404]     Test net output #1: loss = 0.693893 (* 1 = 0.693893 loss)
I0805 19:06:36.468516 10603 solver.cpp:228] Iteration 5500, loss = 0.687589
I0805 19:06:36.468534 10603 solver.cpp:244]     Train net output #0: loss = 0.687589 (* 1 = 0.687589 loss)
I0805 19:06:36.468541 10603 sgd_solver.cpp:106] Iteration 5500, lr = 8.33427e-06
I0805 19:06:39.719091 10603 solver.cpp:228] Iteration 5600, loss = 0.686769
I0805 19:06:39.719139 10603 solver.cpp:244]     Train net output #0: loss = 0.686769 (* 1 = 0.686769 loss)
I0805 19:06:39.719146 10603 sgd_solver.cpp:106] Iteration 5600, lr = 8.30984e-06
I0805 19:06:42.970680 10603 solver.cpp:228] Iteration 5700, loss = 0.697786
I0805 19:06:42.970722 10603 solver.cpp:244]     Train net output #0: loss = 0.697786 (* 1 = 0.697786 loss)
I0805 19:06:42.970731 10603 sgd_solver.cpp:106] Iteration 5700, lr = 8.28557e-06
I0805 19:06:46.217610 10603 solver.cpp:228] Iteration 5800, loss = 0.695748
I0805 19:06:46.217664 10603 solver.cpp:244]     Train net output #0: loss = 0.695748 (* 1 = 0.695748 loss)
I0805 19:06:46.217669 10603 sgd_solver.cpp:106] Iteration 5800, lr = 8.26148e-06
I0805 19:06:49.493625 10603 solver.cpp:228] Iteration 5900, loss = 0.695188
I0805 19:06:49.493669 10603 solver.cpp:244]     Train net output #0: loss = 0.695188 (* 1 = 0.695188 loss)
I0805 19:06:49.493677 10603 sgd_solver.cpp:106] Iteration 5900, lr = 8.23754e-06
I0805 19:06:52.757652 10603 solver.cpp:337] Iteration 6000, Testing net (#0)
I0805 19:06:56.355561 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791628
I0805 19:06:56.355644 10603 solver.cpp:404]     Test net output #1: loss = 0.693097 (* 1 = 0.693097 loss)
I0805 19:06:56.366876 10603 solver.cpp:228] Iteration 6000, loss = 0.70723
I0805 19:06:56.366946 10603 solver.cpp:244]     Train net output #0: loss = 0.70723 (* 1 = 0.70723 loss)
I0805 19:06:56.366966 10603 sgd_solver.cpp:106] Iteration 6000, lr = 8.21377e-06
I0805 19:06:59.660428 10603 solver.cpp:228] Iteration 6100, loss = 0.696023
I0805 19:06:59.660475 10603 solver.cpp:244]     Train net output #0: loss = 0.696023 (* 1 = 0.696023 loss)
I0805 19:06:59.660482 10603 sgd_solver.cpp:106] Iteration 6100, lr = 8.19015e-06
I0805 19:07:02.948442 10603 solver.cpp:228] Iteration 6200, loss = 0.681129
I0805 19:07:02.948480 10603 solver.cpp:244]     Train net output #0: loss = 0.681129 (* 1 = 0.681129 loss)
I0805 19:07:02.948487 10603 sgd_solver.cpp:106] Iteration 6200, lr = 8.1667e-06
I0805 19:07:06.229225 10603 solver.cpp:228] Iteration 6300, loss = 0.698296
I0805 19:07:06.229275 10603 solver.cpp:244]     Train net output #0: loss = 0.698296 (* 1 = 0.698296 loss)
I0805 19:07:06.229281 10603 sgd_solver.cpp:106] Iteration 6300, lr = 8.1434e-06
I0805 19:07:09.515928 10603 solver.cpp:228] Iteration 6400, loss = 0.697343
I0805 19:07:09.515969 10603 solver.cpp:244]     Train net output #0: loss = 0.697343 (* 1 = 0.697343 loss)
I0805 19:07:09.515980 10603 sgd_solver.cpp:106] Iteration 6400, lr = 8.12025e-06
I0805 19:07:12.779350 10603 solver.cpp:337] Iteration 6500, Testing net (#0)
I0805 19:07:16.558948 10603 solver.cpp:404]     Test net output #0: accuracy = 0.790872
I0805 19:07:16.558992 10603 solver.cpp:404]     Test net output #1: loss = 0.692627 (* 1 = 0.692627 loss)
I0805 19:07:16.569960 10603 solver.cpp:228] Iteration 6500, loss = 0.709852
I0805 19:07:16.570032 10603 solver.cpp:244]     Train net output #0: loss = 0.709852 (* 1 = 0.709852 loss)
I0805 19:07:16.570051 10603 sgd_solver.cpp:106] Iteration 6500, lr = 8.09726e-06
I0805 19:07:19.791720 10603 solver.cpp:228] Iteration 6600, loss = 0.693219
I0805 19:07:19.791784 10603 solver.cpp:244]     Train net output #0: loss = 0.693219 (* 1 = 0.693219 loss)
I0805 19:07:19.791792 10603 sgd_solver.cpp:106] Iteration 6600, lr = 8.07442e-06
I0805 19:07:23.033144 10603 solver.cpp:228] Iteration 6700, loss = 0.690076
I0805 19:07:23.033190 10603 solver.cpp:244]     Train net output #0: loss = 0.690076 (* 1 = 0.690076 loss)
I0805 19:07:23.033200 10603 sgd_solver.cpp:106] Iteration 6700, lr = 8.05173e-06
I0805 19:07:26.294687 10603 solver.cpp:228] Iteration 6800, loss = 0.693342
I0805 19:07:26.294733 10603 solver.cpp:244]     Train net output #0: loss = 0.693342 (* 1 = 0.693342 loss)
I0805 19:07:26.294739 10603 sgd_solver.cpp:106] Iteration 6800, lr = 8.02918e-06
I0805 19:07:29.564333 10603 solver.cpp:228] Iteration 6900, loss = 0.690524
I0805 19:07:29.564375 10603 solver.cpp:244]     Train net output #0: loss = 0.690524 (* 1 = 0.690524 loss)
I0805 19:07:29.564381 10603 sgd_solver.cpp:106] Iteration 6900, lr = 8.00679e-06
I0805 19:07:32.807001 10603 solver.cpp:337] Iteration 7000, Testing net (#0)
I0805 19:07:36.402320 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:07:36.583478 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:07:36.583526 10603 solver.cpp:404]     Test net output #1: loss = 0.693344 (* 1 = 0.693344 loss)
I0805 19:07:36.593683 10603 solver.cpp:228] Iteration 7000, loss = 0.701325
I0805 19:07:36.593719 10603 solver.cpp:244]     Train net output #0: loss = 0.701325 (* 1 = 0.701325 loss)
I0805 19:07:36.593726 10603 sgd_solver.cpp:106] Iteration 7000, lr = 7.98454e-06
I0805 19:07:39.818049 10603 solver.cpp:228] Iteration 7100, loss = 0.695653
I0805 19:07:39.818095 10603 solver.cpp:244]     Train net output #0: loss = 0.695653 (* 1 = 0.695653 loss)
I0805 19:07:39.818101 10603 sgd_solver.cpp:106] Iteration 7100, lr = 7.96243e-06
I0805 19:07:43.076854 10603 solver.cpp:228] Iteration 7200, loss = 0.693334
I0805 19:07:43.076900 10603 solver.cpp:244]     Train net output #0: loss = 0.693334 (* 1 = 0.693334 loss)
I0805 19:07:43.076907 10603 sgd_solver.cpp:106] Iteration 7200, lr = 7.94046e-06
I0805 19:07:46.338210 10603 solver.cpp:228] Iteration 7300, loss = 0.697462
I0805 19:07:46.338258 10603 solver.cpp:244]     Train net output #0: loss = 0.697462 (* 1 = 0.697462 loss)
I0805 19:07:46.338264 10603 sgd_solver.cpp:106] Iteration 7300, lr = 7.91864e-06
I0805 19:07:49.611377 10603 solver.cpp:228] Iteration 7400, loss = 0.70207
I0805 19:07:49.611420 10603 solver.cpp:244]     Train net output #0: loss = 0.70207 (* 1 = 0.70207 loss)
I0805 19:07:49.611426 10603 sgd_solver.cpp:106] Iteration 7400, lr = 7.89695e-06
I0805 19:07:52.850735 10603 solver.cpp:337] Iteration 7500, Testing net (#0)
I0805 19:07:56.596177 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208139
I0805 19:07:56.596243 10603 solver.cpp:404]     Test net output #1: loss = 0.694483 (* 1 = 0.694483 loss)
I0805 19:07:56.606650 10603 solver.cpp:228] Iteration 7500, loss = 0.685223
I0805 19:07:56.606681 10603 solver.cpp:244]     Train net output #0: loss = 0.685223 (* 1 = 0.685223 loss)
I0805 19:07:56.606695 10603 sgd_solver.cpp:106] Iteration 7500, lr = 7.87541e-06
I0805 19:07:59.860935 10603 solver.cpp:228] Iteration 7600, loss = 0.693591
I0805 19:07:59.860987 10603 solver.cpp:244]     Train net output #0: loss = 0.693591 (* 1 = 0.693591 loss)
I0805 19:07:59.860998 10603 sgd_solver.cpp:106] Iteration 7600, lr = 7.854e-06
I0805 19:08:03.116236 10603 solver.cpp:228] Iteration 7700, loss = 0.69375
I0805 19:08:03.116279 10603 solver.cpp:244]     Train net output #0: loss = 0.69375 (* 1 = 0.69375 loss)
I0805 19:08:03.116286 10603 sgd_solver.cpp:106] Iteration 7700, lr = 7.83272e-06
I0805 19:08:06.383141 10603 solver.cpp:228] Iteration 7800, loss = 0.685731
I0805 19:08:06.383183 10603 solver.cpp:244]     Train net output #0: loss = 0.685731 (* 1 = 0.685731 loss)
I0805 19:08:06.383188 10603 sgd_solver.cpp:106] Iteration 7800, lr = 7.81158e-06
I0805 19:08:09.641273 10603 solver.cpp:228] Iteration 7900, loss = 0.699046
I0805 19:08:09.641322 10603 solver.cpp:244]     Train net output #0: loss = 0.699046 (* 1 = 0.699046 loss)
I0805 19:08:09.641330 10603 sgd_solver.cpp:106] Iteration 7900, lr = 7.79057e-06
I0805 19:08:12.869511 10603 solver.cpp:337] Iteration 8000, Testing net (#0)
I0805 19:08:16.418735 10603 solver.cpp:404]     Test net output #0: accuracy = 0.792384
I0805 19:08:16.418777 10603 solver.cpp:404]     Test net output #1: loss = 0.69289 (* 1 = 0.69289 loss)
I0805 19:08:16.429061 10603 solver.cpp:228] Iteration 8000, loss = 0.69039
I0805 19:08:16.429091 10603 solver.cpp:244]     Train net output #0: loss = 0.69039 (* 1 = 0.69039 loss)
I0805 19:08:16.429119 10603 sgd_solver.cpp:106] Iteration 8000, lr = 7.7697e-06
I0805 19:08:19.674121 10603 solver.cpp:228] Iteration 8100, loss = 0.694948
I0805 19:08:19.674161 10603 solver.cpp:244]     Train net output #0: loss = 0.694948 (* 1 = 0.694948 loss)
I0805 19:08:19.674167 10603 sgd_solver.cpp:106] Iteration 8100, lr = 7.74895e-06
I0805 19:08:22.928951 10603 solver.cpp:228] Iteration 8200, loss = 0.695937
I0805 19:08:22.928998 10603 solver.cpp:244]     Train net output #0: loss = 0.695937 (* 1 = 0.695937 loss)
I0805 19:08:22.929005 10603 sgd_solver.cpp:106] Iteration 8200, lr = 7.72833e-06
I0805 19:08:26.201300 10603 solver.cpp:228] Iteration 8300, loss = 0.684338
I0805 19:08:26.201319 10603 solver.cpp:244]     Train net output #0: loss = 0.684338 (* 1 = 0.684338 loss)
I0805 19:08:26.201324 10603 sgd_solver.cpp:106] Iteration 8300, lr = 7.70784e-06
I0805 19:08:29.481925 10603 solver.cpp:228] Iteration 8400, loss = 0.694471
I0805 19:08:29.481967 10603 solver.cpp:244]     Train net output #0: loss = 0.694471 (* 1 = 0.694471 loss)
I0805 19:08:29.481973 10603 sgd_solver.cpp:106] Iteration 8400, lr = 7.68748e-06
I0805 19:08:32.749733 10603 solver.cpp:337] Iteration 8500, Testing net (#0)
I0805 19:08:36.370079 10603 solver.cpp:404]     Test net output #0: accuracy = 0.79157
I0805 19:08:36.370118 10603 solver.cpp:404]     Test net output #1: loss = 0.693103 (* 1 = 0.693103 loss)
I0805 19:08:36.383332 10603 solver.cpp:228] Iteration 8500, loss = 0.692251
I0805 19:08:36.383368 10603 solver.cpp:244]     Train net output #0: loss = 0.692251 (* 1 = 0.692251 loss)
I0805 19:08:36.383379 10603 sgd_solver.cpp:106] Iteration 8500, lr = 7.66724e-06
I0805 19:08:39.613204 10603 solver.cpp:228] Iteration 8600, loss = 0.696857
I0805 19:08:39.613245 10603 solver.cpp:244]     Train net output #0: loss = 0.696857 (* 1 = 0.696857 loss)
I0805 19:08:39.613252 10603 sgd_solver.cpp:106] Iteration 8600, lr = 7.64712e-06
I0805 19:08:42.868618 10603 solver.cpp:228] Iteration 8700, loss = 0.699833
I0805 19:08:42.868667 10603 solver.cpp:244]     Train net output #0: loss = 0.699833 (* 1 = 0.699833 loss)
I0805 19:08:42.868674 10603 sgd_solver.cpp:106] Iteration 8700, lr = 7.62713e-06
I0805 19:08:46.141353 10603 solver.cpp:228] Iteration 8800, loss = 0.700442
I0805 19:08:46.141392 10603 solver.cpp:244]     Train net output #0: loss = 0.700442 (* 1 = 0.700442 loss)
I0805 19:08:46.141398 10603 sgd_solver.cpp:106] Iteration 8800, lr = 7.60726e-06
I0805 19:08:49.432570 10603 solver.cpp:228] Iteration 8900, loss = 0.690522
I0805 19:08:49.432620 10603 solver.cpp:244]     Train net output #0: loss = 0.690522 (* 1 = 0.690522 loss)
I0805 19:08:49.432628 10603 sgd_solver.cpp:106] Iteration 8900, lr = 7.58751e-06
I0805 19:08:52.686099 10603 solver.cpp:337] Iteration 9000, Testing net (#0)
I0805 19:08:56.268455 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:08:56.268515 10603 solver.cpp:404]     Test net output #1: loss = 0.693738 (* 1 = 0.693738 loss)
I0805 19:08:56.278965 10603 solver.cpp:228] Iteration 9000, loss = 0.701274
I0805 19:08:56.279014 10603 solver.cpp:244]     Train net output #0: loss = 0.701274 (* 1 = 0.701274 loss)
I0805 19:08:56.279026 10603 sgd_solver.cpp:106] Iteration 9000, lr = 7.56788e-06
I0805 19:08:59.532721 10603 solver.cpp:228] Iteration 9100, loss = 0.697118
I0805 19:08:59.532810 10603 solver.cpp:244]     Train net output #0: loss = 0.697118 (* 1 = 0.697118 loss)
I0805 19:08:59.532819 10603 sgd_solver.cpp:106] Iteration 9100, lr = 7.54836e-06
I0805 19:09:02.778801 10603 solver.cpp:228] Iteration 9200, loss = 0.697418
I0805 19:09:02.778853 10603 solver.cpp:244]     Train net output #0: loss = 0.697418 (* 1 = 0.697418 loss)
I0805 19:09:02.778864 10603 sgd_solver.cpp:106] Iteration 9200, lr = 7.52897e-06
I0805 19:09:06.021380 10603 solver.cpp:228] Iteration 9300, loss = 0.699894
I0805 19:09:06.021422 10603 solver.cpp:244]     Train net output #0: loss = 0.699894 (* 1 = 0.699894 loss)
I0805 19:09:06.021428 10603 sgd_solver.cpp:106] Iteration 9300, lr = 7.50969e-06
I0805 19:09:09.271186 10603 solver.cpp:228] Iteration 9400, loss = 0.6922
I0805 19:09:09.271234 10603 solver.cpp:244]     Train net output #0: loss = 0.6922 (* 1 = 0.6922 loss)
I0805 19:09:09.271240 10603 sgd_solver.cpp:106] Iteration 9400, lr = 7.49052e-06
I0805 19:09:12.481179 10603 solver.cpp:337] Iteration 9500, Testing net (#0)
I0805 19:09:16.022024 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:09:16.022059 10603 solver.cpp:404]     Test net output #1: loss = 0.694347 (* 1 = 0.694347 loss)
I0805 19:09:16.035917 10603 solver.cpp:228] Iteration 9500, loss = 0.697132
I0805 19:09:16.035989 10603 solver.cpp:244]     Train net output #0: loss = 0.697132 (* 1 = 0.697132 loss)
I0805 19:09:16.036010 10603 sgd_solver.cpp:106] Iteration 9500, lr = 7.47147e-06
I0805 19:09:19.279980 10603 solver.cpp:228] Iteration 9600, loss = 0.699091
I0805 19:09:19.280036 10603 solver.cpp:244]     Train net output #0: loss = 0.699091 (* 1 = 0.699091 loss)
I0805 19:09:19.280042 10603 sgd_solver.cpp:106] Iteration 9600, lr = 7.45253e-06
I0805 19:09:22.539237 10603 solver.cpp:228] Iteration 9700, loss = 0.694595
I0805 19:09:22.539280 10603 solver.cpp:244]     Train net output #0: loss = 0.694595 (* 1 = 0.694595 loss)
I0805 19:09:22.539288 10603 sgd_solver.cpp:106] Iteration 9700, lr = 7.4337e-06
I0805 19:09:25.786983 10603 solver.cpp:228] Iteration 9800, loss = 0.701741
I0805 19:09:25.787026 10603 solver.cpp:244]     Train net output #0: loss = 0.701741 (* 1 = 0.701741 loss)
I0805 19:09:25.787032 10603 sgd_solver.cpp:106] Iteration 9800, lr = 7.41499e-06
I0805 19:09:29.035157 10603 solver.cpp:228] Iteration 9900, loss = 0.685519
I0805 19:09:29.035202 10603 solver.cpp:244]     Train net output #0: loss = 0.685519 (* 1 = 0.685519 loss)
I0805 19:09:29.035214 10603 sgd_solver.cpp:106] Iteration 9900, lr = 7.39638e-06
I0805 19:09:32.274885 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_10000.caffemodel
I0805 19:09:32.670328 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_10000.solverstate
I0805 19:09:32.806941 10603 solver.cpp:337] Iteration 10000, Testing net (#0)
I0805 19:09:35.833343 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:09:36.511761 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 19:09:36.511791 10603 solver.cpp:404]     Test net output #1: loss = 0.693499 (* 1 = 0.693499 loss)
I0805 19:09:36.524979 10603 solver.cpp:228] Iteration 10000, loss = 0.696895
I0805 19:09:36.525012 10603 solver.cpp:244]     Train net output #0: loss = 0.696895 (* 1 = 0.696895 loss)
I0805 19:09:36.525022 10603 sgd_solver.cpp:106] Iteration 10000, lr = 7.37788e-06
I0805 19:09:39.722087 10603 solver.cpp:228] Iteration 10100, loss = 0.683343
I0805 19:09:39.722131 10603 solver.cpp:244]     Train net output #0: loss = 0.683343 (* 1 = 0.683343 loss)
I0805 19:09:39.722137 10603 sgd_solver.cpp:106] Iteration 10100, lr = 7.35949e-06
I0805 19:09:42.949543 10603 solver.cpp:228] Iteration 10200, loss = 0.697131
I0805 19:09:42.949585 10603 solver.cpp:244]     Train net output #0: loss = 0.697131 (* 1 = 0.697131 loss)
I0805 19:09:42.949592 10603 sgd_solver.cpp:106] Iteration 10200, lr = 7.3412e-06
I0805 19:09:46.212872 10603 solver.cpp:228] Iteration 10300, loss = 0.700162
I0805 19:09:46.212920 10603 solver.cpp:244]     Train net output #0: loss = 0.700162 (* 1 = 0.700162 loss)
I0805 19:09:46.212927 10603 sgd_solver.cpp:106] Iteration 10300, lr = 7.32302e-06
I0805 19:09:49.471634 10603 solver.cpp:228] Iteration 10400, loss = 0.695135
I0805 19:09:49.471675 10603 solver.cpp:244]     Train net output #0: loss = 0.695135 (* 1 = 0.695135 loss)
I0805 19:09:49.471683 10603 sgd_solver.cpp:106] Iteration 10400, lr = 7.30495e-06
I0805 19:09:52.694586 10603 solver.cpp:337] Iteration 10500, Testing net (#0)
I0805 19:09:56.256616 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208779
I0805 19:09:56.256669 10603 solver.cpp:404]     Test net output #1: loss = 0.693679 (* 1 = 0.693679 loss)
I0805 19:09:56.269659 10603 solver.cpp:228] Iteration 10500, loss = 0.692139
I0805 19:09:56.269690 10603 solver.cpp:244]     Train net output #0: loss = 0.692139 (* 1 = 0.692139 loss)
I0805 19:09:56.269713 10603 sgd_solver.cpp:106] Iteration 10500, lr = 7.28698e-06
I0805 19:09:59.513638 10603 solver.cpp:228] Iteration 10600, loss = 0.698866
I0805 19:09:59.513682 10603 solver.cpp:244]     Train net output #0: loss = 0.698866 (* 1 = 0.698866 loss)
I0805 19:09:59.513689 10603 sgd_solver.cpp:106] Iteration 10600, lr = 7.26911e-06
I0805 19:10:02.755692 10603 solver.cpp:228] Iteration 10700, loss = 0.69729
I0805 19:10:02.755736 10603 solver.cpp:244]     Train net output #0: loss = 0.69729 (* 1 = 0.69729 loss)
I0805 19:10:02.755743 10603 sgd_solver.cpp:106] Iteration 10700, lr = 7.25135e-06
I0805 19:10:06.015980 10603 solver.cpp:228] Iteration 10800, loss = 0.683598
I0805 19:10:06.016024 10603 solver.cpp:244]     Train net output #0: loss = 0.683598 (* 1 = 0.683598 loss)
I0805 19:10:06.016031 10603 sgd_solver.cpp:106] Iteration 10800, lr = 7.23368e-06
I0805 19:10:09.283094 10603 solver.cpp:228] Iteration 10900, loss = 0.696941
I0805 19:10:09.283138 10603 solver.cpp:244]     Train net output #0: loss = 0.696941 (* 1 = 0.696941 loss)
I0805 19:10:09.283150 10603 sgd_solver.cpp:106] Iteration 10900, lr = 7.21612e-06
I0805 19:10:12.519469 10603 solver.cpp:337] Iteration 11000, Testing net (#0)
I0805 19:10:16.183058 10603 solver.cpp:404]     Test net output #0: accuracy = 0.792209
I0805 19:10:16.183109 10603 solver.cpp:404]     Test net output #1: loss = 0.693104 (* 1 = 0.693104 loss)
I0805 19:10:16.194043 10603 solver.cpp:228] Iteration 11000, loss = 0.697362
I0805 19:10:16.194105 10603 solver.cpp:244]     Train net output #0: loss = 0.697362 (* 1 = 0.697362 loss)
I0805 19:10:16.194128 10603 sgd_solver.cpp:106] Iteration 11000, lr = 7.19865e-06
I0805 19:10:19.406513 10603 solver.cpp:228] Iteration 11100, loss = 0.693661
I0805 19:10:19.406558 10603 solver.cpp:244]     Train net output #0: loss = 0.693661 (* 1 = 0.693661 loss)
I0805 19:10:19.406564 10603 sgd_solver.cpp:106] Iteration 11100, lr = 7.18129e-06
I0805 19:10:22.645896 10603 solver.cpp:228] Iteration 11200, loss = 0.687143
I0805 19:10:22.645944 10603 solver.cpp:244]     Train net output #0: loss = 0.687143 (* 1 = 0.687143 loss)
I0805 19:10:22.645954 10603 sgd_solver.cpp:106] Iteration 11200, lr = 7.16402e-06
I0805 19:10:25.944803 10603 solver.cpp:228] Iteration 11300, loss = 0.693278
I0805 19:10:25.944854 10603 solver.cpp:244]     Train net output #0: loss = 0.693278 (* 1 = 0.693278 loss)
I0805 19:10:25.944861 10603 sgd_solver.cpp:106] Iteration 11300, lr = 7.14684e-06
I0805 19:10:29.241149 10603 solver.cpp:228] Iteration 11400, loss = 0.686018
I0805 19:10:29.241191 10603 solver.cpp:244]     Train net output #0: loss = 0.686018 (* 1 = 0.686018 loss)
I0805 19:10:29.241197 10603 sgd_solver.cpp:106] Iteration 11400, lr = 7.12977e-06
I0805 19:10:32.494349 10603 solver.cpp:337] Iteration 11500, Testing net (#0)
I0805 19:10:36.144994 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:10:36.145056 10603 solver.cpp:404]     Test net output #1: loss = 0.693591 (* 1 = 0.693591 loss)
I0805 19:10:36.155956 10603 solver.cpp:228] Iteration 11500, loss = 0.696743
I0805 19:10:36.156026 10603 solver.cpp:244]     Train net output #0: loss = 0.696743 (* 1 = 0.696743 loss)
I0805 19:10:36.156049 10603 sgd_solver.cpp:106] Iteration 11500, lr = 7.11278e-06
I0805 19:10:39.345980 10603 solver.cpp:228] Iteration 11600, loss = 0.688928
I0805 19:10:39.346030 10603 solver.cpp:244]     Train net output #0: loss = 0.688928 (* 1 = 0.688928 loss)
I0805 19:10:39.346041 10603 sgd_solver.cpp:106] Iteration 11600, lr = 7.09589e-06
I0805 19:10:42.569799 10603 solver.cpp:228] Iteration 11700, loss = 0.69297
I0805 19:10:42.569859 10603 solver.cpp:244]     Train net output #0: loss = 0.69297 (* 1 = 0.69297 loss)
I0805 19:10:42.569869 10603 sgd_solver.cpp:106] Iteration 11700, lr = 7.0791e-06
I0805 19:10:45.842391 10603 solver.cpp:228] Iteration 11800, loss = 0.693782
I0805 19:10:45.842432 10603 solver.cpp:244]     Train net output #0: loss = 0.693782 (* 1 = 0.693782 loss)
I0805 19:10:45.842438 10603 sgd_solver.cpp:106] Iteration 11800, lr = 7.0624e-06
I0805 19:10:49.105033 10603 solver.cpp:228] Iteration 11900, loss = 0.699974
I0805 19:10:49.105094 10603 solver.cpp:244]     Train net output #0: loss = 0.699974 (* 1 = 0.699974 loss)
I0805 19:10:49.105105 10603 sgd_solver.cpp:106] Iteration 11900, lr = 7.04579e-06
I0805 19:10:52.336732 10603 solver.cpp:337] Iteration 12000, Testing net (#0)
I0805 19:10:55.918056 10603 solver.cpp:404]     Test net output #0: accuracy = 0.792209
I0805 19:10:55.918126 10603 solver.cpp:404]     Test net output #1: loss = 0.692764 (* 1 = 0.692764 loss)
I0805 19:10:55.931043 10603 solver.cpp:228] Iteration 12000, loss = 0.689322
I0805 19:10:55.931104 10603 solver.cpp:244]     Train net output #0: loss = 0.689322 (* 1 = 0.689322 loss)
I0805 19:10:55.931118 10603 sgd_solver.cpp:106] Iteration 12000, lr = 7.02927e-06
I0805 19:10:59.145781 10603 solver.cpp:228] Iteration 12100, loss = 0.70336
I0805 19:10:59.145834 10603 solver.cpp:244]     Train net output #0: loss = 0.70336 (* 1 = 0.70336 loss)
I0805 19:10:59.145841 10603 sgd_solver.cpp:106] Iteration 12100, lr = 7.01284e-06
I0805 19:11:02.387199 10603 solver.cpp:228] Iteration 12200, loss = 0.699946
I0805 19:11:02.387246 10603 solver.cpp:244]     Train net output #0: loss = 0.699946 (* 1 = 0.699946 loss)
I0805 19:11:02.387253 10603 sgd_solver.cpp:106] Iteration 12200, lr = 6.9965e-06
I0805 19:11:05.637742 10603 solver.cpp:228] Iteration 12300, loss = 0.703813
I0805 19:11:05.637783 10603 solver.cpp:244]     Train net output #0: loss = 0.703813 (* 1 = 0.703813 loss)
I0805 19:11:05.637789 10603 sgd_solver.cpp:106] Iteration 12300, lr = 6.98024e-06
I0805 19:11:08.888423 10603 solver.cpp:228] Iteration 12400, loss = 0.686425
I0805 19:11:08.888468 10603 solver.cpp:244]     Train net output #0: loss = 0.686425 (* 1 = 0.686425 loss)
I0805 19:11:08.888474 10603 sgd_solver.cpp:106] Iteration 12400, lr = 6.96408e-06
I0805 19:11:12.100225 10603 solver.cpp:337] Iteration 12500, Testing net (#0)
I0805 19:11:15.640018 10603 solver.cpp:404]     Test net output #0: accuracy = 0.53093
I0805 19:11:15.640053 10603 solver.cpp:404]     Test net output #1: loss = 0.693145 (* 1 = 0.693145 loss)
I0805 19:11:15.650949 10603 solver.cpp:228] Iteration 12500, loss = 0.703236
I0805 19:11:15.651022 10603 solver.cpp:244]     Train net output #0: loss = 0.703236 (* 1 = 0.703236 loss)
I0805 19:11:15.651041 10603 sgd_solver.cpp:106] Iteration 12500, lr = 6.948e-06
I0805 19:11:18.874768 10603 solver.cpp:228] Iteration 12600, loss = 0.692872
I0805 19:11:18.874819 10603 solver.cpp:244]     Train net output #0: loss = 0.692872 (* 1 = 0.692872 loss)
I0805 19:11:18.874825 10603 sgd_solver.cpp:106] Iteration 12600, lr = 6.93201e-06
I0805 19:11:22.111368 10603 solver.cpp:228] Iteration 12700, loss = 0.697527
I0805 19:11:22.111398 10603 solver.cpp:244]     Train net output #0: loss = 0.697527 (* 1 = 0.697527 loss)
I0805 19:11:22.111403 10603 sgd_solver.cpp:106] Iteration 12700, lr = 6.91611e-06
I0805 19:11:25.357929 10603 solver.cpp:228] Iteration 12800, loss = 0.701678
I0805 19:11:25.357981 10603 solver.cpp:244]     Train net output #0: loss = 0.701678 (* 1 = 0.701678 loss)
I0805 19:11:25.357998 10603 sgd_solver.cpp:106] Iteration 12800, lr = 6.90029e-06
I0805 19:11:28.607667 10603 solver.cpp:228] Iteration 12900, loss = 0.685479
I0805 19:11:28.607714 10603 solver.cpp:244]     Train net output #0: loss = 0.685479 (* 1 = 0.685479 loss)
I0805 19:11:28.607722 10603 sgd_solver.cpp:106] Iteration 12900, lr = 6.88455e-06
I0805 19:11:31.832144 10603 solver.cpp:337] Iteration 13000, Testing net (#0)
I0805 19:11:34.812705 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:11:35.355473 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:11:35.355502 10603 solver.cpp:404]     Test net output #1: loss = 0.69436 (* 1 = 0.69436 loss)
I0805 19:11:35.368983 10603 solver.cpp:228] Iteration 13000, loss = 0.697322
I0805 19:11:35.369055 10603 solver.cpp:244]     Train net output #0: loss = 0.697322 (* 1 = 0.697322 loss)
I0805 19:11:35.369073 10603 sgd_solver.cpp:106] Iteration 13000, lr = 6.8689e-06
I0805 19:11:38.606950 10603 solver.cpp:228] Iteration 13100, loss = 0.703195
I0805 19:11:38.606992 10603 solver.cpp:244]     Train net output #0: loss = 0.703195 (* 1 = 0.703195 loss)
I0805 19:11:38.606998 10603 sgd_solver.cpp:106] Iteration 13100, lr = 6.85333e-06
I0805 19:11:41.851915 10603 solver.cpp:228] Iteration 13200, loss = 0.695229
I0805 19:11:41.851959 10603 solver.cpp:244]     Train net output #0: loss = 0.695229 (* 1 = 0.695229 loss)
I0805 19:11:41.851966 10603 sgd_solver.cpp:106] Iteration 13200, lr = 6.83784e-06
I0805 19:11:45.095834 10603 solver.cpp:228] Iteration 13300, loss = 0.693189
I0805 19:11:45.095878 10603 solver.cpp:244]     Train net output #0: loss = 0.693189 (* 1 = 0.693189 loss)
I0805 19:11:45.095885 10603 sgd_solver.cpp:106] Iteration 13300, lr = 6.82243e-06
I0805 19:11:48.333535 10603 solver.cpp:228] Iteration 13400, loss = 0.699299
I0805 19:11:48.333554 10603 solver.cpp:244]     Train net output #0: loss = 0.699299 (* 1 = 0.699299 loss)
I0805 19:11:48.333561 10603 sgd_solver.cpp:106] Iteration 13400, lr = 6.80711e-06
I0805 19:11:51.550364 10603 solver.cpp:337] Iteration 13500, Testing net (#0)
I0805 19:11:55.221209 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791163
I0805 19:11:55.221259 10603 solver.cpp:404]     Test net output #1: loss = 0.693057 (* 1 = 0.693057 loss)
I0805 19:11:55.231492 10603 solver.cpp:228] Iteration 13500, loss = 0.701243
I0805 19:11:55.231523 10603 solver.cpp:244]     Train net output #0: loss = 0.701243 (* 1 = 0.701243 loss)
I0805 19:11:55.231540 10603 sgd_solver.cpp:106] Iteration 13500, lr = 6.79186e-06
I0805 19:11:58.473146 10603 solver.cpp:228] Iteration 13600, loss = 0.685343
I0805 19:11:58.473192 10603 solver.cpp:244]     Train net output #0: loss = 0.685343 (* 1 = 0.685343 loss)
I0805 19:11:58.473199 10603 sgd_solver.cpp:106] Iteration 13600, lr = 6.7767e-06
I0805 19:12:01.730607 10603 solver.cpp:228] Iteration 13700, loss = 0.686132
I0805 19:12:01.730648 10603 solver.cpp:244]     Train net output #0: loss = 0.686132 (* 1 = 0.686132 loss)
I0805 19:12:01.730655 10603 sgd_solver.cpp:106] Iteration 13700, lr = 6.76161e-06
I0805 19:12:04.984128 10603 solver.cpp:228] Iteration 13800, loss = 0.689824
I0805 19:12:04.984174 10603 solver.cpp:244]     Train net output #0: loss = 0.689824 (* 1 = 0.689824 loss)
I0805 19:12:04.984181 10603 sgd_solver.cpp:106] Iteration 13800, lr = 6.7466e-06
I0805 19:12:08.245414 10603 solver.cpp:228] Iteration 13900, loss = 0.696439
I0805 19:12:08.245452 10603 solver.cpp:244]     Train net output #0: loss = 0.696439 (* 1 = 0.696439 loss)
I0805 19:12:08.245458 10603 sgd_solver.cpp:106] Iteration 13900, lr = 6.73167e-06
I0805 19:12:11.473809 10603 solver.cpp:337] Iteration 14000, Testing net (#0)
I0805 19:12:15.005472 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791802
I0805 19:12:15.005512 10603 solver.cpp:404]     Test net output #1: loss = 0.692627 (* 1 = 0.692627 loss)
I0805 19:12:15.018610 10603 solver.cpp:228] Iteration 14000, loss = 0.701022
I0805 19:12:15.018640 10603 solver.cpp:244]     Train net output #0: loss = 0.701022 (* 1 = 0.701022 loss)
I0805 19:12:15.018657 10603 sgd_solver.cpp:106] Iteration 14000, lr = 6.71681e-06
I0805 19:12:18.233079 10603 solver.cpp:228] Iteration 14100, loss = 0.694874
I0805 19:12:18.233125 10603 solver.cpp:244]     Train net output #0: loss = 0.694874 (* 1 = 0.694874 loss)
I0805 19:12:18.233131 10603 sgd_solver.cpp:106] Iteration 14100, lr = 6.70204e-06
I0805 19:12:21.474632 10603 solver.cpp:228] Iteration 14200, loss = 0.681698
I0805 19:12:21.474673 10603 solver.cpp:244]     Train net output #0: loss = 0.681698 (* 1 = 0.681698 loss)
I0805 19:12:21.474679 10603 sgd_solver.cpp:106] Iteration 14200, lr = 6.68733e-06
I0805 19:12:24.720878 10603 solver.cpp:228] Iteration 14300, loss = 0.701201
I0805 19:12:24.720929 10603 solver.cpp:244]     Train net output #0: loss = 0.701201 (* 1 = 0.701201 loss)
I0805 19:12:24.720935 10603 sgd_solver.cpp:106] Iteration 14300, lr = 6.6727e-06
I0805 19:12:27.961386 10603 solver.cpp:228] Iteration 14400, loss = 0.692931
I0805 19:12:27.961405 10603 solver.cpp:244]     Train net output #0: loss = 0.692931 (* 1 = 0.692931 loss)
I0805 19:12:27.961411 10603 sgd_solver.cpp:106] Iteration 14400, lr = 6.65815e-06
I0805 19:12:31.172020 10603 solver.cpp:337] Iteration 14500, Testing net (#0)
I0805 19:12:34.686553 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207907
I0805 19:12:34.686607 10603 solver.cpp:404]     Test net output #1: loss = 0.693498 (* 1 = 0.693498 loss)
I0805 19:12:34.696790 10603 solver.cpp:228] Iteration 14500, loss = 0.69774
I0805 19:12:34.696825 10603 solver.cpp:244]     Train net output #0: loss = 0.69774 (* 1 = 0.69774 loss)
I0805 19:12:34.696832 10603 sgd_solver.cpp:106] Iteration 14500, lr = 6.64367e-06
I0805 19:12:37.929049 10603 solver.cpp:228] Iteration 14600, loss = 0.69732
I0805 19:12:37.929095 10603 solver.cpp:244]     Train net output #0: loss = 0.69732 (* 1 = 0.69732 loss)
I0805 19:12:37.929102 10603 sgd_solver.cpp:106] Iteration 14600, lr = 6.62927e-06
I0805 19:12:41.175199 10603 solver.cpp:228] Iteration 14700, loss = 0.691736
I0805 19:12:41.175243 10603 solver.cpp:244]     Train net output #0: loss = 0.691736 (* 1 = 0.691736 loss)
I0805 19:12:41.175252 10603 sgd_solver.cpp:106] Iteration 14700, lr = 6.61493e-06
I0805 19:12:44.419410 10603 solver.cpp:228] Iteration 14800, loss = 0.699259
I0805 19:12:44.419458 10603 solver.cpp:244]     Train net output #0: loss = 0.699259 (* 1 = 0.699259 loss)
I0805 19:12:44.419466 10603 sgd_solver.cpp:106] Iteration 14800, lr = 6.60067e-06
I0805 19:12:47.666743 10603 solver.cpp:228] Iteration 14900, loss = 0.703413
I0805 19:12:47.666785 10603 solver.cpp:244]     Train net output #0: loss = 0.703413 (* 1 = 0.703413 loss)
I0805 19:12:47.666791 10603 sgd_solver.cpp:106] Iteration 14900, lr = 6.58648e-06
I0805 19:12:50.881692 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_15000.caffemodel
I0805 19:12:51.263134 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_15000.solverstate
I0805 19:12:51.398680 10603 solver.cpp:337] Iteration 15000, Testing net (#0)
I0805 19:12:54.843266 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207965
I0805 19:12:54.843307 10603 solver.cpp:404]     Test net output #1: loss = 0.694142 (* 1 = 0.694142 loss)
I0805 19:12:54.856129 10603 solver.cpp:228] Iteration 15000, loss = 0.703055
I0805 19:12:54.856175 10603 solver.cpp:244]     Train net output #0: loss = 0.703055 (* 1 = 0.703055 loss)
I0805 19:12:54.856184 10603 sgd_solver.cpp:106] Iteration 15000, lr = 6.57236e-06
I0805 19:12:58.055974 10603 solver.cpp:228] Iteration 15100, loss = 0.691005
I0805 19:12:58.056030 10603 solver.cpp:244]     Train net output #0: loss = 0.691005 (* 1 = 0.691005 loss)
I0805 19:12:58.056036 10603 sgd_solver.cpp:106] Iteration 15100, lr = 6.55831e-06
I0805 19:13:01.291504 10603 solver.cpp:228] Iteration 15200, loss = 0.689324
I0805 19:13:01.291548 10603 solver.cpp:244]     Train net output #0: loss = 0.689324 (* 1 = 0.689324 loss)
I0805 19:13:01.291553 10603 sgd_solver.cpp:106] Iteration 15200, lr = 6.54433e-06
I0805 19:13:04.570227 10603 solver.cpp:228] Iteration 15300, loss = 0.687328
I0805 19:13:04.570274 10603 solver.cpp:244]     Train net output #0: loss = 0.687328 (* 1 = 0.687328 loss)
I0805 19:13:04.570281 10603 sgd_solver.cpp:106] Iteration 15300, lr = 6.53043e-06
I0805 19:13:07.860911 10603 solver.cpp:228] Iteration 15400, loss = 0.700829
I0805 19:13:07.860951 10603 solver.cpp:244]     Train net output #0: loss = 0.700829 (* 1 = 0.700829 loss)
I0805 19:13:07.860957 10603 sgd_solver.cpp:106] Iteration 15400, lr = 6.51658e-06
I0805 19:13:11.111871 10603 solver.cpp:337] Iteration 15500, Testing net (#0)
I0805 19:13:14.659653 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:13:14.659703 10603 solver.cpp:404]     Test net output #1: loss = 0.693264 (* 1 = 0.693264 loss)
I0805 19:13:14.672755 10603 solver.cpp:228] Iteration 15500, loss = 0.693847
I0805 19:13:14.672785 10603 solver.cpp:244]     Train net output #0: loss = 0.693847 (* 1 = 0.693847 loss)
I0805 19:13:14.672793 10603 sgd_solver.cpp:106] Iteration 15500, lr = 6.50281e-06
I0805 19:13:17.895943 10603 solver.cpp:228] Iteration 15600, loss = 0.694247
I0805 19:13:17.895988 10603 solver.cpp:244]     Train net output #0: loss = 0.694247 (* 1 = 0.694247 loss)
I0805 19:13:17.895997 10603 sgd_solver.cpp:106] Iteration 15600, lr = 6.48911e-06
I0805 19:13:21.116288 10603 solver.cpp:228] Iteration 15700, loss = 0.699376
I0805 19:13:21.116331 10603 solver.cpp:244]     Train net output #0: loss = 0.699376 (* 1 = 0.699376 loss)
I0805 19:13:21.116338 10603 sgd_solver.cpp:106] Iteration 15700, lr = 6.47547e-06
I0805 19:13:24.353076 10603 solver.cpp:228] Iteration 15800, loss = 0.691582
I0805 19:13:24.353119 10603 solver.cpp:244]     Train net output #0: loss = 0.691582 (* 1 = 0.691582 loss)
I0805 19:13:24.353127 10603 sgd_solver.cpp:106] Iteration 15800, lr = 6.4619e-06
I0805 19:13:25.815593 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:13:27.601516 10603 solver.cpp:228] Iteration 15900, loss = 0.68916
I0805 19:13:27.601557 10603 solver.cpp:244]     Train net output #0: loss = 0.68916 (* 1 = 0.68916 loss)
I0805 19:13:27.601562 10603 sgd_solver.cpp:106] Iteration 15900, lr = 6.4484e-06
I0805 19:13:30.822001 10603 solver.cpp:337] Iteration 16000, Testing net (#0)
I0805 19:13:34.316951 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:13:34.317004 10603 solver.cpp:404]     Test net output #1: loss = 0.693421 (* 1 = 0.693421 loss)
I0805 19:13:34.327150 10603 solver.cpp:228] Iteration 16000, loss = 0.679675
I0805 19:13:34.327179 10603 solver.cpp:244]     Train net output #0: loss = 0.679675 (* 1 = 0.679675 loss)
I0805 19:13:34.327186 10603 sgd_solver.cpp:106] Iteration 16000, lr = 6.43496e-06
I0805 19:13:37.556519 10603 solver.cpp:228] Iteration 16100, loss = 0.698015
I0805 19:13:37.556573 10603 solver.cpp:244]     Train net output #0: loss = 0.698015 (* 1 = 0.698015 loss)
I0805 19:13:37.556581 10603 sgd_solver.cpp:106] Iteration 16100, lr = 6.42158e-06
I0805 19:13:40.787814 10603 solver.cpp:228] Iteration 16200, loss = 0.690179
I0805 19:13:40.787871 10603 solver.cpp:244]     Train net output #0: loss = 0.690179 (* 1 = 0.690179 loss)
I0805 19:13:40.787879 10603 sgd_solver.cpp:106] Iteration 16200, lr = 6.40827e-06
I0805 19:13:44.025394 10603 solver.cpp:228] Iteration 16300, loss = 0.703632
I0805 19:13:44.025451 10603 solver.cpp:244]     Train net output #0: loss = 0.703632 (* 1 = 0.703632 loss)
I0805 19:13:44.025459 10603 sgd_solver.cpp:106] Iteration 16300, lr = 6.39503e-06
I0805 19:13:47.280609 10603 solver.cpp:228] Iteration 16400, loss = 0.698464
I0805 19:13:47.280652 10603 solver.cpp:244]     Train net output #0: loss = 0.698464 (* 1 = 0.698464 loss)
I0805 19:13:47.280659 10603 sgd_solver.cpp:106] Iteration 16400, lr = 6.38185e-06
I0805 19:13:50.543310 10603 solver.cpp:337] Iteration 16500, Testing net (#0)
I0805 19:13:54.212946 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:13:54.212996 10603 solver.cpp:404]     Test net output #1: loss = 0.693173 (* 1 = 0.693173 loss)
I0805 19:13:54.223913 10603 solver.cpp:228] Iteration 16500, loss = 0.706016
I0805 19:13:54.223975 10603 solver.cpp:244]     Train net output #0: loss = 0.706016 (* 1 = 0.706016 loss)
I0805 19:13:54.223994 10603 sgd_solver.cpp:106] Iteration 16500, lr = 6.36873e-06
I0805 19:13:57.430990 10603 solver.cpp:228] Iteration 16600, loss = 0.695377
I0805 19:13:57.431047 10603 solver.cpp:244]     Train net output #0: loss = 0.695377 (* 1 = 0.695377 loss)
I0805 19:13:57.431056 10603 sgd_solver.cpp:106] Iteration 16600, lr = 6.35567e-06
I0805 19:14:00.664054 10603 solver.cpp:228] Iteration 16700, loss = 0.698543
I0805 19:14:00.664094 10603 solver.cpp:244]     Train net output #0: loss = 0.698543 (* 1 = 0.698543 loss)
I0805 19:14:00.664100 10603 sgd_solver.cpp:106] Iteration 16700, lr = 6.34268e-06
I0805 19:14:03.921969 10603 solver.cpp:228] Iteration 16800, loss = 0.69549
I0805 19:14:03.922013 10603 solver.cpp:244]     Train net output #0: loss = 0.69549 (* 1 = 0.69549 loss)
I0805 19:14:03.922019 10603 sgd_solver.cpp:106] Iteration 16800, lr = 6.32975e-06
I0805 19:14:07.168957 10603 solver.cpp:228] Iteration 16900, loss = 0.702757
I0805 19:14:07.168999 10603 solver.cpp:244]     Train net output #0: loss = 0.702757 (* 1 = 0.702757 loss)
I0805 19:14:07.169005 10603 sgd_solver.cpp:106] Iteration 16900, lr = 6.31688e-06
I0805 19:14:10.381836 10603 solver.cpp:337] Iteration 17000, Testing net (#0)
I0805 19:14:13.915169 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208139
I0805 19:14:13.915233 10603 solver.cpp:404]     Test net output #1: loss = 0.6939 (* 1 = 0.6939 loss)
I0805 19:14:13.926066 10603 solver.cpp:228] Iteration 17000, loss = 0.695377
I0805 19:14:13.926110 10603 solver.cpp:244]     Train net output #0: loss = 0.695377 (* 1 = 0.695377 loss)
I0805 19:14:13.926126 10603 sgd_solver.cpp:106] Iteration 17000, lr = 6.30407e-06
I0805 19:14:17.148322 10603 solver.cpp:228] Iteration 17100, loss = 0.690639
I0805 19:14:17.148385 10603 solver.cpp:244]     Train net output #0: loss = 0.690639 (* 1 = 0.690639 loss)
I0805 19:14:17.148391 10603 sgd_solver.cpp:106] Iteration 17100, lr = 6.29132e-06
I0805 19:14:20.378558 10603 solver.cpp:228] Iteration 17200, loss = 0.688086
I0805 19:14:20.378599 10603 solver.cpp:244]     Train net output #0: loss = 0.688086 (* 1 = 0.688086 loss)
I0805 19:14:20.378605 10603 sgd_solver.cpp:106] Iteration 17200, lr = 6.27864e-06
I0805 19:14:23.606019 10603 solver.cpp:228] Iteration 17300, loss = 0.699719
I0805 19:14:23.606065 10603 solver.cpp:244]     Train net output #0: loss = 0.699719 (* 1 = 0.699719 loss)
I0805 19:14:23.606072 10603 sgd_solver.cpp:106] Iteration 17300, lr = 6.26601e-06
I0805 19:14:26.844626 10603 solver.cpp:228] Iteration 17400, loss = 0.686561
I0805 19:14:26.844668 10603 solver.cpp:244]     Train net output #0: loss = 0.686561 (* 1 = 0.686561 loss)
I0805 19:14:26.844674 10603 sgd_solver.cpp:106] Iteration 17400, lr = 6.25344e-06
I0805 19:14:30.058758 10603 solver.cpp:337] Iteration 17500, Testing net (#0)
I0805 19:14:33.608518 10603 solver.cpp:404]     Test net output #0: accuracy = 0.419012
I0805 19:14:33.608556 10603 solver.cpp:404]     Test net output #1: loss = 0.69315 (* 1 = 0.69315 loss)
I0805 19:14:33.621335 10603 solver.cpp:228] Iteration 17500, loss = 0.705727
I0805 19:14:33.621352 10603 solver.cpp:244]     Train net output #0: loss = 0.705727 (* 1 = 0.705727 loss)
I0805 19:14:33.621361 10603 sgd_solver.cpp:106] Iteration 17500, lr = 6.24093e-06
I0805 19:14:36.842865 10603 solver.cpp:228] Iteration 17600, loss = 0.703353
I0805 19:14:36.842917 10603 solver.cpp:244]     Train net output #0: loss = 0.703353 (* 1 = 0.703353 loss)
I0805 19:14:36.842923 10603 sgd_solver.cpp:106] Iteration 17600, lr = 6.22847e-06
I0805 19:14:40.062870 10603 solver.cpp:228] Iteration 17700, loss = 0.69406
I0805 19:14:40.062913 10603 solver.cpp:244]     Train net output #0: loss = 0.69406 (* 1 = 0.69406 loss)
I0805 19:14:40.062919 10603 sgd_solver.cpp:106] Iteration 17700, lr = 6.21608e-06
I0805 19:14:43.294289 10603 solver.cpp:228] Iteration 17800, loss = 0.698639
I0805 19:14:43.294347 10603 solver.cpp:244]     Train net output #0: loss = 0.698639 (* 1 = 0.698639 loss)
I0805 19:14:43.294354 10603 sgd_solver.cpp:106] Iteration 17800, lr = 6.20374e-06
I0805 19:14:46.548183 10603 solver.cpp:228] Iteration 17900, loss = 0.693563
I0805 19:14:46.548220 10603 solver.cpp:244]     Train net output #0: loss = 0.693563 (* 1 = 0.693563 loss)
I0805 19:14:46.548228 10603 sgd_solver.cpp:106] Iteration 17900, lr = 6.19146e-06
I0805 19:14:49.765183 10603 solver.cpp:337] Iteration 18000, Testing net (#0)
I0805 19:14:53.309697 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:14:53.309751 10603 solver.cpp:404]     Test net output #1: loss = 0.693574 (* 1 = 0.693574 loss)
I0805 19:14:53.319998 10603 solver.cpp:228] Iteration 18000, loss = 0.694516
I0805 19:14:53.320029 10603 solver.cpp:244]     Train net output #0: loss = 0.694516 (* 1 = 0.694516 loss)
I0805 19:14:53.320036 10603 sgd_solver.cpp:106] Iteration 18000, lr = 6.17924e-06
I0805 19:14:56.563541 10603 solver.cpp:228] Iteration 18100, loss = 0.690716
I0805 19:14:56.563582 10603 solver.cpp:244]     Train net output #0: loss = 0.690716 (* 1 = 0.690716 loss)
I0805 19:14:56.563588 10603 sgd_solver.cpp:106] Iteration 18100, lr = 6.16707e-06
I0805 19:14:59.808465 10603 solver.cpp:228] Iteration 18200, loss = 0.688185
I0805 19:14:59.808506 10603 solver.cpp:244]     Train net output #0: loss = 0.688185 (* 1 = 0.688185 loss)
I0805 19:14:59.808511 10603 sgd_solver.cpp:106] Iteration 18200, lr = 6.15496e-06
I0805 19:15:03.053220 10603 solver.cpp:228] Iteration 18300, loss = 0.696379
I0805 19:15:03.053268 10603 solver.cpp:244]     Train net output #0: loss = 0.696379 (* 1 = 0.696379 loss)
I0805 19:15:03.053274 10603 sgd_solver.cpp:106] Iteration 18300, lr = 6.1429e-06
I0805 19:15:06.298913 10603 solver.cpp:228] Iteration 18400, loss = 0.69541
I0805 19:15:06.298956 10603 solver.cpp:244]     Train net output #0: loss = 0.69541 (* 1 = 0.69541 loss)
I0805 19:15:06.298964 10603 sgd_solver.cpp:106] Iteration 18400, lr = 6.1309e-06
I0805 19:15:09.520944 10603 solver.cpp:337] Iteration 18500, Testing net (#0)
I0805 19:15:13.060716 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:15:13.060770 10603 solver.cpp:404]     Test net output #1: loss = 0.693814 (* 1 = 0.693814 loss)
I0805 19:15:13.071709 10603 solver.cpp:228] Iteration 18500, loss = 0.704599
I0805 19:15:13.071771 10603 solver.cpp:244]     Train net output #0: loss = 0.704599 (* 1 = 0.704599 loss)
I0805 19:15:13.071796 10603 sgd_solver.cpp:106] Iteration 18500, lr = 6.11895e-06
I0805 19:15:16.291419 10603 solver.cpp:228] Iteration 18600, loss = 0.689582
I0805 19:15:16.291463 10603 solver.cpp:244]     Train net output #0: loss = 0.689582 (* 1 = 0.689582 loss)
I0805 19:15:16.291471 10603 sgd_solver.cpp:106] Iteration 18600, lr = 6.10706e-06
I0805 19:15:19.506260 10603 solver.cpp:228] Iteration 18700, loss = 0.690462
I0805 19:15:19.506302 10603 solver.cpp:244]     Train net output #0: loss = 0.690462 (* 1 = 0.690462 loss)
I0805 19:15:19.506309 10603 sgd_solver.cpp:106] Iteration 18700, lr = 6.09522e-06
I0805 19:15:22.739636 10603 solver.cpp:228] Iteration 18800, loss = 0.689673
I0805 19:15:22.739682 10603 solver.cpp:244]     Train net output #0: loss = 0.689673 (* 1 = 0.689673 loss)
I0805 19:15:22.739689 10603 sgd_solver.cpp:106] Iteration 18800, lr = 6.08343e-06
I0805 19:15:25.999439 10603 solver.cpp:228] Iteration 18900, loss = 0.702595
I0805 19:15:25.999476 10603 solver.cpp:244]     Train net output #0: loss = 0.702595 (* 1 = 0.702595 loss)
I0805 19:15:25.999482 10603 sgd_solver.cpp:106] Iteration 18900, lr = 6.0717e-06
I0805 19:15:29.229344 10603 solver.cpp:337] Iteration 19000, Testing net (#0)
I0805 19:15:30.027984 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:15:33.062839 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:15:33.062870 10603 solver.cpp:404]     Test net output #1: loss = 0.693606 (* 1 = 0.693606 loss)
I0805 19:15:33.075956 10603 solver.cpp:228] Iteration 19000, loss = 0.684931
I0805 19:15:33.076020 10603 solver.cpp:244]     Train net output #0: loss = 0.684931 (* 1 = 0.684931 loss)
I0805 19:15:33.076037 10603 sgd_solver.cpp:106] Iteration 19000, lr = 6.06002e-06
I0805 19:15:36.270014 10603 solver.cpp:228] Iteration 19100, loss = 0.685607
I0805 19:15:36.270061 10603 solver.cpp:244]     Train net output #0: loss = 0.685607 (* 1 = 0.685607 loss)
I0805 19:15:36.270067 10603 sgd_solver.cpp:106] Iteration 19100, lr = 6.04839e-06
I0805 19:15:39.473909 10603 solver.cpp:228] Iteration 19200, loss = 0.681731
I0805 19:15:39.473956 10603 solver.cpp:244]     Train net output #0: loss = 0.681731 (* 1 = 0.681731 loss)
I0805 19:15:39.473968 10603 sgd_solver.cpp:106] Iteration 19200, lr = 6.03682e-06
I0805 19:15:42.730496 10603 solver.cpp:228] Iteration 19300, loss = 0.689274
I0805 19:15:42.730559 10603 solver.cpp:244]     Train net output #0: loss = 0.689274 (* 1 = 0.689274 loss)
I0805 19:15:42.730566 10603 sgd_solver.cpp:106] Iteration 19300, lr = 6.02529e-06
I0805 19:15:45.979230 10603 solver.cpp:228] Iteration 19400, loss = 0.696555
I0805 19:15:45.979281 10603 solver.cpp:244]     Train net output #0: loss = 0.696555 (* 1 = 0.696555 loss)
I0805 19:15:45.979290 10603 sgd_solver.cpp:106] Iteration 19400, lr = 6.01382e-06
I0805 19:15:49.198860 10603 solver.cpp:337] Iteration 19500, Testing net (#0)
I0805 19:15:52.854928 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791395
I0805 19:15:52.854984 10603 solver.cpp:404]     Test net output #1: loss = 0.692744 (* 1 = 0.692744 loss)
I0805 19:15:52.868530 10603 solver.cpp:228] Iteration 19500, loss = 0.700929
I0805 19:15:52.868593 10603 solver.cpp:244]     Train net output #0: loss = 0.700929 (* 1 = 0.700929 loss)
I0805 19:15:52.868612 10603 sgd_solver.cpp:106] Iteration 19500, lr = 6.0024e-06
I0805 19:15:56.096551 10603 solver.cpp:228] Iteration 19600, loss = 0.697814
I0805 19:15:56.096598 10603 solver.cpp:244]     Train net output #0: loss = 0.697814 (* 1 = 0.697814 loss)
I0805 19:15:56.096604 10603 sgd_solver.cpp:106] Iteration 19600, lr = 5.99102e-06
I0805 19:15:59.333278 10603 solver.cpp:228] Iteration 19700, loss = 0.696616
I0805 19:15:59.333334 10603 solver.cpp:244]     Train net output #0: loss = 0.696616 (* 1 = 0.696616 loss)
I0805 19:15:59.333351 10603 sgd_solver.cpp:106] Iteration 19700, lr = 5.9797e-06
I0805 19:16:02.569257 10603 solver.cpp:228] Iteration 19800, loss = 0.693704
I0805 19:16:02.569303 10603 solver.cpp:244]     Train net output #0: loss = 0.693704 (* 1 = 0.693704 loss)
I0805 19:16:02.569309 10603 sgd_solver.cpp:106] Iteration 19800, lr = 5.96843e-06
I0805 19:16:05.812602 10603 solver.cpp:228] Iteration 19900, loss = 0.708888
I0805 19:16:05.812649 10603 solver.cpp:244]     Train net output #0: loss = 0.708888 (* 1 = 0.708888 loss)
I0805 19:16:05.812692 10603 sgd_solver.cpp:106] Iteration 19900, lr = 5.95721e-06
I0805 19:16:09.024981 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_20000.caffemodel
I0805 19:16:09.393687 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_20000.solverstate
I0805 19:16:09.526042 10603 solver.cpp:337] Iteration 20000, Testing net (#0)
I0805 19:16:12.966274 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:16:12.966325 10603 solver.cpp:404]     Test net output #1: loss = 0.69341 (* 1 = 0.69341 loss)
I0805 19:16:12.979259 10603 solver.cpp:228] Iteration 20000, loss = 0.682826
I0805 19:16:12.979287 10603 solver.cpp:244]     Train net output #0: loss = 0.682826 (* 1 = 0.682826 loss)
I0805 19:16:12.979296 10603 sgd_solver.cpp:106] Iteration 20000, lr = 5.94604e-06
I0805 19:16:16.163187 10603 solver.cpp:228] Iteration 20100, loss = 0.696328
I0805 19:16:16.163265 10603 solver.cpp:244]     Train net output #0: loss = 0.696328 (* 1 = 0.696328 loss)
I0805 19:16:16.163274 10603 sgd_solver.cpp:106] Iteration 20100, lr = 5.93491e-06
I0805 19:16:19.379348 10603 solver.cpp:228] Iteration 20200, loss = 0.693635
I0805 19:16:19.379400 10603 solver.cpp:244]     Train net output #0: loss = 0.693635 (* 1 = 0.693635 loss)
I0805 19:16:19.379410 10603 sgd_solver.cpp:106] Iteration 20200, lr = 5.92384e-06
I0805 19:16:22.610941 10603 solver.cpp:228] Iteration 20300, loss = 0.679717
I0805 19:16:22.610991 10603 solver.cpp:244]     Train net output #0: loss = 0.679717 (* 1 = 0.679717 loss)
I0805 19:16:22.610998 10603 sgd_solver.cpp:106] Iteration 20300, lr = 5.91281e-06
I0805 19:16:25.864197 10603 solver.cpp:228] Iteration 20400, loss = 0.69143
I0805 19:16:25.864251 10603 solver.cpp:244]     Train net output #0: loss = 0.69143 (* 1 = 0.69143 loss)
I0805 19:16:25.864259 10603 sgd_solver.cpp:106] Iteration 20400, lr = 5.90183e-06
I0805 19:16:29.082306 10603 solver.cpp:337] Iteration 20500, Testing net (#0)
I0805 19:16:32.629962 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207849
I0805 19:16:32.630033 10603 solver.cpp:404]     Test net output #1: loss = 0.694307 (* 1 = 0.694307 loss)
I0805 19:16:32.643204 10603 solver.cpp:228] Iteration 20500, loss = 0.687957
I0805 19:16:32.643239 10603 solver.cpp:244]     Train net output #0: loss = 0.687957 (* 1 = 0.687957 loss)
I0805 19:16:32.643247 10603 sgd_solver.cpp:106] Iteration 20500, lr = 5.89089e-06
I0805 19:16:35.869771 10603 solver.cpp:228] Iteration 20600, loss = 0.687811
I0805 19:16:35.869817 10603 solver.cpp:244]     Train net output #0: loss = 0.687811 (* 1 = 0.687811 loss)
I0805 19:16:35.869823 10603 sgd_solver.cpp:106] Iteration 20600, lr = 5.88001e-06
I0805 19:16:39.115057 10603 solver.cpp:228] Iteration 20700, loss = 0.69488
I0805 19:16:39.115082 10603 solver.cpp:244]     Train net output #0: loss = 0.69488 (* 1 = 0.69488 loss)
I0805 19:16:39.115087 10603 sgd_solver.cpp:106] Iteration 20700, lr = 5.86917e-06
I0805 19:16:42.365746 10603 solver.cpp:228] Iteration 20800, loss = 0.703455
I0805 19:16:42.365792 10603 solver.cpp:244]     Train net output #0: loss = 0.703455 (* 1 = 0.703455 loss)
I0805 19:16:42.365797 10603 sgd_solver.cpp:106] Iteration 20800, lr = 5.85838e-06
I0805 19:16:45.605929 10603 solver.cpp:228] Iteration 20900, loss = 0.705464
I0805 19:16:45.605970 10603 solver.cpp:244]     Train net output #0: loss = 0.705464 (* 1 = 0.705464 loss)
I0805 19:16:45.605976 10603 sgd_solver.cpp:106] Iteration 20900, lr = 5.84763e-06
I0805 19:16:48.819126 10603 solver.cpp:337] Iteration 21000, Testing net (#0)
I0805 19:16:51.142210 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:16:52.631356 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791163
I0805 19:16:52.631407 10603 solver.cpp:404]     Test net output #1: loss = 0.693032 (* 1 = 0.693032 loss)
I0805 19:16:52.644594 10603 solver.cpp:228] Iteration 21000, loss = 0.691601
I0805 19:16:52.644618 10603 solver.cpp:244]     Train net output #0: loss = 0.691601 (* 1 = 0.691601 loss)
I0805 19:16:52.644631 10603 sgd_solver.cpp:106] Iteration 21000, lr = 5.83693e-06
I0805 19:16:55.830335 10603 solver.cpp:228] Iteration 21100, loss = 0.678863
I0805 19:16:55.830374 10603 solver.cpp:244]     Train net output #0: loss = 0.678863 (* 1 = 0.678863 loss)
I0805 19:16:55.830380 10603 sgd_solver.cpp:106] Iteration 21100, lr = 5.82628e-06
I0805 19:16:59.055063 10603 solver.cpp:228] Iteration 21200, loss = 0.687557
I0805 19:16:59.055109 10603 solver.cpp:244]     Train net output #0: loss = 0.687557 (* 1 = 0.687557 loss)
I0805 19:16:59.055116 10603 sgd_solver.cpp:106] Iteration 21200, lr = 5.81567e-06
I0805 19:17:02.311295 10603 solver.cpp:228] Iteration 21300, loss = 0.698685
I0805 19:17:02.311348 10603 solver.cpp:244]     Train net output #0: loss = 0.698685 (* 1 = 0.698685 loss)
I0805 19:17:02.311357 10603 sgd_solver.cpp:106] Iteration 21300, lr = 5.8051e-06
I0805 19:17:05.577986 10603 solver.cpp:228] Iteration 21400, loss = 0.696962
I0805 19:17:05.578027 10603 solver.cpp:244]     Train net output #0: loss = 0.696962 (* 1 = 0.696962 loss)
I0805 19:17:05.578033 10603 sgd_solver.cpp:106] Iteration 21400, lr = 5.79458e-06
I0805 19:17:08.809856 10603 solver.cpp:337] Iteration 21500, Testing net (#0)
I0805 19:17:12.532271 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208895
I0805 19:17:12.532311 10603 solver.cpp:404]     Test net output #1: loss = 0.693348 (* 1 = 0.693348 loss)
I0805 19:17:12.545140 10603 solver.cpp:228] Iteration 21500, loss = 0.693189
I0805 19:17:12.545171 10603 solver.cpp:244]     Train net output #0: loss = 0.693189 (* 1 = 0.693189 loss)
I0805 19:17:12.545199 10603 sgd_solver.cpp:106] Iteration 21500, lr = 5.78411e-06
I0805 19:17:15.725724 10603 solver.cpp:228] Iteration 21600, loss = 0.693971
I0805 19:17:15.725762 10603 solver.cpp:244]     Train net output #0: loss = 0.693971 (* 1 = 0.693971 loss)
I0805 19:17:15.725769 10603 sgd_solver.cpp:106] Iteration 21600, lr = 5.77368e-06
I0805 19:17:18.950448 10603 solver.cpp:228] Iteration 21700, loss = 0.701463
I0805 19:17:18.950500 10603 solver.cpp:244]     Train net output #0: loss = 0.701463 (* 1 = 0.701463 loss)
I0805 19:17:18.950506 10603 sgd_solver.cpp:106] Iteration 21700, lr = 5.76329e-06
I0805 19:17:22.203181 10603 solver.cpp:228] Iteration 21800, loss = 0.685346
I0805 19:17:22.203222 10603 solver.cpp:244]     Train net output #0: loss = 0.685346 (* 1 = 0.685346 loss)
I0805 19:17:22.203228 10603 sgd_solver.cpp:106] Iteration 21800, lr = 5.75295e-06
I0805 19:17:25.438820 10603 solver.cpp:228] Iteration 21900, loss = 0.692722
I0805 19:17:25.438864 10603 solver.cpp:244]     Train net output #0: loss = 0.692722 (* 1 = 0.692722 loss)
I0805 19:17:25.438871 10603 sgd_solver.cpp:106] Iteration 21900, lr = 5.74265e-06
I0805 19:17:28.652683 10603 solver.cpp:337] Iteration 22000, Testing net (#0)
I0805 19:17:32.368609 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207849
I0805 19:17:32.368677 10603 solver.cpp:404]     Test net output #1: loss = 0.693655 (* 1 = 0.693655 loss)
I0805 19:17:32.382045 10603 solver.cpp:228] Iteration 22000, loss = 0.693581
I0805 19:17:32.382084 10603 solver.cpp:244]     Train net output #0: loss = 0.693581 (* 1 = 0.693581 loss)
I0805 19:17:32.382097 10603 sgd_solver.cpp:106] Iteration 22000, lr = 5.73239e-06
I0805 19:17:35.574864 10603 solver.cpp:228] Iteration 22100, loss = 0.69343
I0805 19:17:35.574903 10603 solver.cpp:244]     Train net output #0: loss = 0.69343 (* 1 = 0.69343 loss)
I0805 19:17:35.574910 10603 sgd_solver.cpp:106] Iteration 22100, lr = 5.72217e-06
I0805 19:17:38.787116 10603 solver.cpp:228] Iteration 22200, loss = 0.699009
I0805 19:17:38.787163 10603 solver.cpp:244]     Train net output #0: loss = 0.699009 (* 1 = 0.699009 loss)
I0805 19:17:38.787169 10603 sgd_solver.cpp:106] Iteration 22200, lr = 5.712e-06
I0805 19:17:42.035964 10603 solver.cpp:228] Iteration 22300, loss = 0.681025
I0805 19:17:42.036005 10603 solver.cpp:244]     Train net output #0: loss = 0.681025 (* 1 = 0.681025 loss)
I0805 19:17:42.036011 10603 sgd_solver.cpp:106] Iteration 22300, lr = 5.70187e-06
I0805 19:17:45.284852 10603 solver.cpp:228] Iteration 22400, loss = 0.699473
I0805 19:17:45.284965 10603 solver.cpp:244]     Train net output #0: loss = 0.699473 (* 1 = 0.699473 loss)
I0805 19:17:45.284971 10603 sgd_solver.cpp:106] Iteration 22400, lr = 5.69178e-06
I0805 19:17:48.498821 10603 solver.cpp:337] Iteration 22500, Testing net (#0)
I0805 19:17:52.145485 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:17:52.145535 10603 solver.cpp:404]     Test net output #1: loss = 0.694352 (* 1 = 0.694352 loss)
I0805 19:17:52.155835 10603 solver.cpp:228] Iteration 22500, loss = 0.705111
I0805 19:17:52.155869 10603 solver.cpp:244]     Train net output #0: loss = 0.705111 (* 1 = 0.705111 loss)
I0805 19:17:52.155880 10603 sgd_solver.cpp:106] Iteration 22500, lr = 5.68173e-06
I0805 19:17:55.343780 10603 solver.cpp:228] Iteration 22600, loss = 0.693883
I0805 19:17:55.343818 10603 solver.cpp:244]     Train net output #0: loss = 0.693883 (* 1 = 0.693883 loss)
I0805 19:17:55.343824 10603 sgd_solver.cpp:106] Iteration 22600, lr = 5.67173e-06
I0805 19:17:58.592115 10603 solver.cpp:228] Iteration 22700, loss = 0.695977
I0805 19:17:58.592160 10603 solver.cpp:244]     Train net output #0: loss = 0.695977 (* 1 = 0.695977 loss)
I0805 19:17:58.592166 10603 sgd_solver.cpp:106] Iteration 22700, lr = 5.66176e-06
I0805 19:18:01.843063 10603 solver.cpp:228] Iteration 22800, loss = 0.705452
I0805 19:18:01.843108 10603 solver.cpp:244]     Train net output #0: loss = 0.705452 (* 1 = 0.705452 loss)
I0805 19:18:01.843116 10603 sgd_solver.cpp:106] Iteration 22800, lr = 5.65184e-06
I0805 19:18:05.092559 10603 solver.cpp:228] Iteration 22900, loss = 0.690972
I0805 19:18:05.092599 10603 solver.cpp:244]     Train net output #0: loss = 0.690972 (* 1 = 0.690972 loss)
I0805 19:18:05.092607 10603 sgd_solver.cpp:106] Iteration 22900, lr = 5.64195e-06
I0805 19:18:08.313243 10603 solver.cpp:337] Iteration 23000, Testing net (#0)
I0805 19:18:12.026109 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:18:12.026180 10603 solver.cpp:404]     Test net output #1: loss = 0.693445 (* 1 = 0.693445 loss)
I0805 19:18:12.040149 10603 solver.cpp:228] Iteration 23000, loss = 0.691809
I0805 19:18:12.040213 10603 solver.cpp:244]     Train net output #0: loss = 0.691809 (* 1 = 0.691809 loss)
I0805 19:18:12.040235 10603 sgd_solver.cpp:106] Iteration 23000, lr = 5.63211e-06
I0805 19:18:15.215116 10603 solver.cpp:228] Iteration 23100, loss = 0.688359
I0805 19:18:15.215154 10603 solver.cpp:244]     Train net output #0: loss = 0.688359 (* 1 = 0.688359 loss)
I0805 19:18:15.215160 10603 sgd_solver.cpp:106] Iteration 23100, lr = 5.62231e-06
I0805 19:18:18.406117 10603 solver.cpp:228] Iteration 23200, loss = 0.691627
I0805 19:18:18.406188 10603 solver.cpp:244]     Train net output #0: loss = 0.691627 (* 1 = 0.691627 loss)
I0805 19:18:18.406195 10603 sgd_solver.cpp:106] Iteration 23200, lr = 5.61254e-06
I0805 19:18:21.642801 10603 solver.cpp:228] Iteration 23300, loss = 0.701971
I0805 19:18:21.642841 10603 solver.cpp:244]     Train net output #0: loss = 0.701971 (* 1 = 0.701971 loss)
I0805 19:18:21.642848 10603 sgd_solver.cpp:106] Iteration 23300, lr = 5.60282e-06
I0805 19:18:24.885289 10603 solver.cpp:228] Iteration 23400, loss = 0.697193
I0805 19:18:24.885335 10603 solver.cpp:244]     Train net output #0: loss = 0.697193 (* 1 = 0.697193 loss)
I0805 19:18:24.885341 10603 sgd_solver.cpp:106] Iteration 23400, lr = 5.59313e-06
I0805 19:18:26.827833 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:18:28.095360 10603 solver.cpp:337] Iteration 23500, Testing net (#0)
I0805 19:18:31.621423 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:18:31.621503 10603 solver.cpp:404]     Test net output #1: loss = 0.693813 (* 1 = 0.693813 loss)
I0805 19:18:31.634670 10603 solver.cpp:228] Iteration 23500, loss = 0.700559
I0805 19:18:31.634704 10603 solver.cpp:244]     Train net output #0: loss = 0.700559 (* 1 = 0.700559 loss)
I0805 19:18:31.634721 10603 sgd_solver.cpp:106] Iteration 23500, lr = 5.58349e-06
I0805 19:18:34.868734 10603 solver.cpp:228] Iteration 23600, loss = 0.689416
I0805 19:18:34.868775 10603 solver.cpp:244]     Train net output #0: loss = 0.689416 (* 1 = 0.689416 loss)
I0805 19:18:34.868782 10603 sgd_solver.cpp:106] Iteration 23600, lr = 5.57388e-06
I0805 19:18:38.130309 10603 solver.cpp:228] Iteration 23700, loss = 0.701443
I0805 19:18:38.130354 10603 solver.cpp:244]     Train net output #0: loss = 0.701443 (* 1 = 0.701443 loss)
I0805 19:18:38.130360 10603 sgd_solver.cpp:106] Iteration 23700, lr = 5.56431e-06
I0805 19:18:41.394656 10603 solver.cpp:228] Iteration 23800, loss = 0.692374
I0805 19:18:41.394701 10603 solver.cpp:244]     Train net output #0: loss = 0.692374 (* 1 = 0.692374 loss)
I0805 19:18:41.394708 10603 sgd_solver.cpp:106] Iteration 23800, lr = 5.55478e-06
I0805 19:18:44.652597 10603 solver.cpp:228] Iteration 23900, loss = 0.691151
I0805 19:18:44.652642 10603 solver.cpp:244]     Train net output #0: loss = 0.691151 (* 1 = 0.691151 loss)
I0805 19:18:44.652648 10603 sgd_solver.cpp:106] Iteration 23900, lr = 5.54529e-06
I0805 19:18:47.880807 10603 solver.cpp:337] Iteration 24000, Testing net (#0)
I0805 19:18:51.476424 10603 solver.cpp:404]     Test net output #0: accuracy = 0.789942
I0805 19:18:51.476480 10603 solver.cpp:404]     Test net output #1: loss = 0.693125 (* 1 = 0.693125 loss)
I0805 19:18:51.486863 10603 solver.cpp:228] Iteration 24000, loss = 0.682413
I0805 19:18:51.486893 10603 solver.cpp:244]     Train net output #0: loss = 0.682413 (* 1 = 0.682413 loss)
I0805 19:18:51.486912 10603 sgd_solver.cpp:106] Iteration 24000, lr = 5.53583e-06
I0805 19:18:54.686729 10603 solver.cpp:228] Iteration 24100, loss = 0.686855
I0805 19:18:54.686774 10603 solver.cpp:244]     Train net output #0: loss = 0.686855 (* 1 = 0.686855 loss)
I0805 19:18:54.686780 10603 sgd_solver.cpp:106] Iteration 24100, lr = 5.52642e-06
I0805 19:18:57.910609 10603 solver.cpp:228] Iteration 24200, loss = 0.691512
I0805 19:18:57.910650 10603 solver.cpp:244]     Train net output #0: loss = 0.691512 (* 1 = 0.691512 loss)
I0805 19:18:57.910657 10603 sgd_solver.cpp:106] Iteration 24200, lr = 5.51704e-06
I0805 19:19:01.156350 10603 solver.cpp:228] Iteration 24300, loss = 0.699605
I0805 19:19:01.156399 10603 solver.cpp:244]     Train net output #0: loss = 0.699605 (* 1 = 0.699605 loss)
I0805 19:19:01.156406 10603 sgd_solver.cpp:106] Iteration 24300, lr = 5.50769e-06
I0805 19:19:04.394915 10603 solver.cpp:228] Iteration 24400, loss = 0.689269
I0805 19:19:04.394958 10603 solver.cpp:244]     Train net output #0: loss = 0.689269 (* 1 = 0.689269 loss)
I0805 19:19:04.394963 10603 sgd_solver.cpp:106] Iteration 24400, lr = 5.49839e-06
I0805 19:19:07.603373 10603 solver.cpp:337] Iteration 24500, Testing net (#0)
I0805 19:19:11.153175 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:19:11.153241 10603 solver.cpp:404]     Test net output #1: loss = 0.693636 (* 1 = 0.693636 loss)
I0805 19:19:11.166661 10603 solver.cpp:228] Iteration 24500, loss = 0.699088
I0805 19:19:11.166695 10603 solver.cpp:244]     Train net output #0: loss = 0.699088 (* 1 = 0.699088 loss)
I0805 19:19:11.166707 10603 sgd_solver.cpp:106] Iteration 24500, lr = 5.48912e-06
I0805 19:19:14.351073 10603 solver.cpp:228] Iteration 24600, loss = 0.697387
I0805 19:19:14.351122 10603 solver.cpp:244]     Train net output #0: loss = 0.697387 (* 1 = 0.697387 loss)
I0805 19:19:14.351128 10603 sgd_solver.cpp:106] Iteration 24600, lr = 5.47988e-06
I0805 19:19:17.573778 10603 solver.cpp:228] Iteration 24700, loss = 0.699292
I0805 19:19:17.573828 10603 solver.cpp:244]     Train net output #0: loss = 0.699292 (* 1 = 0.699292 loss)
I0805 19:19:17.573834 10603 sgd_solver.cpp:106] Iteration 24700, lr = 5.47069e-06
I0805 19:19:20.817428 10603 solver.cpp:228] Iteration 24800, loss = 0.698393
I0805 19:19:20.817500 10603 solver.cpp:244]     Train net output #0: loss = 0.698393 (* 1 = 0.698393 loss)
I0805 19:19:20.817513 10603 sgd_solver.cpp:106] Iteration 24800, lr = 5.46153e-06
I0805 19:19:24.062264 10603 solver.cpp:228] Iteration 24900, loss = 0.697421
I0805 19:19:24.062314 10603 solver.cpp:244]     Train net output #0: loss = 0.697421 (* 1 = 0.697421 loss)
I0805 19:19:24.062320 10603 sgd_solver.cpp:106] Iteration 24900, lr = 5.4524e-06
I0805 19:19:27.274842 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_25000.caffemodel
I0805 19:19:27.641788 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_25000.solverstate
I0805 19:19:27.774374 10603 solver.cpp:337] Iteration 25000, Testing net (#0)
I0805 19:19:31.247668 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791686
I0805 19:19:31.247714 10603 solver.cpp:404]     Test net output #1: loss = 0.69284 (* 1 = 0.69284 loss)
I0805 19:19:31.260370 10603 solver.cpp:228] Iteration 25000, loss = 0.681488
I0805 19:19:31.260404 10603 solver.cpp:244]     Train net output #0: loss = 0.681488 (* 1 = 0.681488 loss)
I0805 19:19:31.260412 10603 sgd_solver.cpp:106] Iteration 25000, lr = 5.44331e-06
I0805 19:19:34.455544 10603 solver.cpp:228] Iteration 25100, loss = 0.684649
I0805 19:19:34.455588 10603 solver.cpp:244]     Train net output #0: loss = 0.684649 (* 1 = 0.684649 loss)
I0805 19:19:34.455595 10603 sgd_solver.cpp:106] Iteration 25100, lr = 5.43426e-06
I0805 19:19:37.716255 10603 solver.cpp:228] Iteration 25200, loss = 0.699023
I0805 19:19:37.716294 10603 solver.cpp:244]     Train net output #0: loss = 0.699023 (* 1 = 0.699023 loss)
I0805 19:19:37.716300 10603 sgd_solver.cpp:106] Iteration 25200, lr = 5.42524e-06
I0805 19:19:40.980875 10603 solver.cpp:228] Iteration 25300, loss = 0.685962
I0805 19:19:40.980924 10603 solver.cpp:244]     Train net output #0: loss = 0.685962 (* 1 = 0.685962 loss)
I0805 19:19:40.980931 10603 sgd_solver.cpp:106] Iteration 25300, lr = 5.41625e-06
I0805 19:19:44.229396 10603 solver.cpp:228] Iteration 25400, loss = 0.69689
I0805 19:19:44.229437 10603 solver.cpp:244]     Train net output #0: loss = 0.69689 (* 1 = 0.69689 loss)
I0805 19:19:44.229444 10603 sgd_solver.cpp:106] Iteration 25400, lr = 5.4073e-06
I0805 19:19:47.450578 10603 solver.cpp:337] Iteration 25500, Testing net (#0)
I0805 19:19:51.056426 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:19:51.056485 10603 solver.cpp:404]     Test net output #1: loss = 0.693391 (* 1 = 0.693391 loss)
I0805 19:19:51.070056 10603 solver.cpp:228] Iteration 25500, loss = 0.678934
I0805 19:19:51.070127 10603 solver.cpp:244]     Train net output #0: loss = 0.678934 (* 1 = 0.678934 loss)
I0805 19:19:51.070145 10603 sgd_solver.cpp:106] Iteration 25500, lr = 5.39839e-06
I0805 19:19:54.261369 10603 solver.cpp:228] Iteration 25600, loss = 0.692236
I0805 19:19:54.261428 10603 solver.cpp:244]     Train net output #0: loss = 0.692236 (* 1 = 0.692236 loss)
I0805 19:19:54.261435 10603 sgd_solver.cpp:106] Iteration 25600, lr = 5.3895e-06
I0805 19:19:57.467247 10603 solver.cpp:228] Iteration 25700, loss = 0.700482
I0805 19:19:57.467293 10603 solver.cpp:244]     Train net output #0: loss = 0.700482 (* 1 = 0.700482 loss)
I0805 19:19:57.467298 10603 sgd_solver.cpp:106] Iteration 25700, lr = 5.38066e-06
I0805 19:20:00.682200 10603 solver.cpp:228] Iteration 25800, loss = 0.684477
I0805 19:20:00.682243 10603 solver.cpp:244]     Train net output #0: loss = 0.684477 (* 1 = 0.684477 loss)
I0805 19:20:00.682250 10603 sgd_solver.cpp:106] Iteration 25800, lr = 5.37184e-06
I0805 19:20:03.922508 10603 solver.cpp:228] Iteration 25900, loss = 0.700573
I0805 19:20:03.922552 10603 solver.cpp:244]     Train net output #0: loss = 0.700573 (* 1 = 0.700573 loss)
I0805 19:20:03.922559 10603 sgd_solver.cpp:106] Iteration 25900, lr = 5.36306e-06
I0805 19:20:07.138087 10603 solver.cpp:337] Iteration 26000, Testing net (#0)
I0805 19:20:08.041546 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:20:10.799787 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:20:10.799854 10603 solver.cpp:404]     Test net output #1: loss = 0.693988 (* 1 = 0.693988 loss)
I0805 19:20:10.813089 10603 solver.cpp:228] Iteration 26000, loss = 0.707838
I0805 19:20:10.813115 10603 solver.cpp:244]     Train net output #0: loss = 0.707838 (* 1 = 0.707838 loss)
I0805 19:20:10.813127 10603 sgd_solver.cpp:106] Iteration 26000, lr = 5.35432e-06
I0805 19:20:14.027384 10603 solver.cpp:228] Iteration 26100, loss = 0.694914
I0805 19:20:14.027441 10603 solver.cpp:244]     Train net output #0: loss = 0.694914 (* 1 = 0.694914 loss)
I0805 19:20:14.027448 10603 sgd_solver.cpp:106] Iteration 26100, lr = 5.3456e-06
I0805 19:20:17.270261 10603 solver.cpp:228] Iteration 26200, loss = 0.693
I0805 19:20:17.270298 10603 solver.cpp:244]     Train net output #0: loss = 0.693 (* 1 = 0.693 loss)
I0805 19:20:17.270305 10603 sgd_solver.cpp:106] Iteration 26200, lr = 5.33692e-06
I0805 19:20:20.533128 10603 solver.cpp:228] Iteration 26300, loss = 0.693686
I0805 19:20:20.533174 10603 solver.cpp:244]     Train net output #0: loss = 0.693686 (* 1 = 0.693686 loss)
I0805 19:20:20.533181 10603 sgd_solver.cpp:106] Iteration 26300, lr = 5.32828e-06
I0805 19:20:23.807359 10603 solver.cpp:228] Iteration 26400, loss = 0.687938
I0805 19:20:23.807402 10603 solver.cpp:244]     Train net output #0: loss = 0.687938 (* 1 = 0.687938 loss)
I0805 19:20:23.807410 10603 sgd_solver.cpp:106] Iteration 26400, lr = 5.31966e-06
I0805 19:20:27.056879 10603 solver.cpp:337] Iteration 26500, Testing net (#0)
I0805 19:20:30.660264 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:20:30.660323 10603 solver.cpp:404]     Test net output #1: loss = 0.693376 (* 1 = 0.693376 loss)
I0805 19:20:30.673339 10603 solver.cpp:228] Iteration 26500, loss = 0.696151
I0805 19:20:30.673370 10603 solver.cpp:244]     Train net output #0: loss = 0.696151 (* 1 = 0.696151 loss)
I0805 19:20:30.673382 10603 sgd_solver.cpp:106] Iteration 26500, lr = 5.31108e-06
I0805 19:20:33.894906 10603 solver.cpp:228] Iteration 26600, loss = 0.701999
I0805 19:20:33.894948 10603 solver.cpp:244]     Train net output #0: loss = 0.701999 (* 1 = 0.701999 loss)
I0805 19:20:33.894953 10603 sgd_solver.cpp:106] Iteration 26600, lr = 5.30253e-06
I0805 19:20:37.116158 10603 solver.cpp:228] Iteration 26700, loss = 0.699332
I0805 19:20:37.116201 10603 solver.cpp:244]     Train net output #0: loss = 0.699332 (* 1 = 0.699332 loss)
I0805 19:20:37.116209 10603 sgd_solver.cpp:106] Iteration 26700, lr = 5.29401e-06
I0805 19:20:40.331045 10603 solver.cpp:228] Iteration 26800, loss = 0.693421
I0805 19:20:40.331086 10603 solver.cpp:244]     Train net output #0: loss = 0.693421 (* 1 = 0.693421 loss)
I0805 19:20:40.331092 10603 sgd_solver.cpp:106] Iteration 26800, lr = 5.28552e-06
I0805 19:20:43.571918 10603 solver.cpp:228] Iteration 26900, loss = 0.683453
I0805 19:20:43.571966 10603 solver.cpp:244]     Train net output #0: loss = 0.683453 (* 1 = 0.683453 loss)
I0805 19:20:43.571974 10603 sgd_solver.cpp:106] Iteration 26900, lr = 5.27707e-06
I0805 19:20:46.790110 10603 solver.cpp:337] Iteration 27000, Testing net (#0)
I0805 19:20:50.328328 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791337
I0805 19:20:50.328393 10603 solver.cpp:404]     Test net output #1: loss = 0.692798 (* 1 = 0.692798 loss)
I0805 19:20:50.342361 10603 solver.cpp:228] Iteration 27000, loss = 0.701047
I0805 19:20:50.342419 10603 solver.cpp:244]     Train net output #0: loss = 0.701047 (* 1 = 0.701047 loss)
I0805 19:20:50.342443 10603 sgd_solver.cpp:106] Iteration 27000, lr = 5.26865e-06
I0805 19:20:53.566529 10603 solver.cpp:228] Iteration 27100, loss = 0.695306
I0805 19:20:53.566572 10603 solver.cpp:244]     Train net output #0: loss = 0.695306 (* 1 = 0.695306 loss)
I0805 19:20:53.566578 10603 sgd_solver.cpp:106] Iteration 27100, lr = 5.26025e-06
I0805 19:20:56.785840 10603 solver.cpp:228] Iteration 27200, loss = 0.691495
I0805 19:20:56.785910 10603 solver.cpp:244]     Train net output #0: loss = 0.691495 (* 1 = 0.691495 loss)
I0805 19:20:56.785917 10603 sgd_solver.cpp:106] Iteration 27200, lr = 5.25189e-06
I0805 19:21:00.029894 10603 solver.cpp:228] Iteration 27300, loss = 0.697311
I0805 19:21:00.029933 10603 solver.cpp:244]     Train net output #0: loss = 0.697311 (* 1 = 0.697311 loss)
I0805 19:21:00.029940 10603 sgd_solver.cpp:106] Iteration 27300, lr = 5.24356e-06
I0805 19:21:03.286953 10603 solver.cpp:228] Iteration 27400, loss = 0.70769
I0805 19:21:03.286999 10603 solver.cpp:244]     Train net output #0: loss = 0.70769 (* 1 = 0.70769 loss)
I0805 19:21:03.287006 10603 sgd_solver.cpp:106] Iteration 27400, lr = 5.23527e-06
I0805 19:21:06.513448 10603 solver.cpp:337] Iteration 27500, Testing net (#0)
I0805 19:21:10.121979 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208547
I0805 19:21:10.122031 10603 solver.cpp:404]     Test net output #1: loss = 0.693298 (* 1 = 0.693298 loss)
I0805 19:21:10.132383 10603 solver.cpp:228] Iteration 27500, loss = 0.696727
I0805 19:21:10.132416 10603 solver.cpp:244]     Train net output #0: loss = 0.696727 (* 1 = 0.696727 loss)
I0805 19:21:10.132426 10603 sgd_solver.cpp:106] Iteration 27500, lr = 5.227e-06
I0805 19:21:13.336472 10603 solver.cpp:228] Iteration 27600, loss = 0.709925
I0805 19:21:13.336522 10603 solver.cpp:244]     Train net output #0: loss = 0.709925 (* 1 = 0.709925 loss)
I0805 19:21:13.336529 10603 sgd_solver.cpp:106] Iteration 27600, lr = 5.21876e-06
I0805 19:21:16.546739 10603 solver.cpp:228] Iteration 27700, loss = 0.677656
I0805 19:21:16.546758 10603 solver.cpp:244]     Train net output #0: loss = 0.677656 (* 1 = 0.677656 loss)
I0805 19:21:16.546766 10603 sgd_solver.cpp:106] Iteration 27700, lr = 5.21055e-06
I0805 19:21:19.794615 10603 solver.cpp:228] Iteration 27800, loss = 0.706131
I0805 19:21:19.794661 10603 solver.cpp:244]     Train net output #0: loss = 0.706131 (* 1 = 0.706131 loss)
I0805 19:21:19.794667 10603 sgd_solver.cpp:106] Iteration 27800, lr = 5.20237e-06
I0805 19:21:23.069767 10603 solver.cpp:228] Iteration 27900, loss = 0.691229
I0805 19:21:23.069825 10603 solver.cpp:244]     Train net output #0: loss = 0.691229 (* 1 = 0.691229 loss)
I0805 19:21:23.069833 10603 sgd_solver.cpp:106] Iteration 27900, lr = 5.19423e-06
I0805 19:21:26.293485 10603 solver.cpp:337] Iteration 28000, Testing net (#0)
I0805 19:21:29.785006 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208895
I0805 19:21:29.785048 10603 solver.cpp:404]     Test net output #1: loss = 0.694045 (* 1 = 0.694045 loss)
I0805 19:21:29.795260 10603 solver.cpp:228] Iteration 28000, loss = 0.683754
I0805 19:21:29.795289 10603 solver.cpp:244]     Train net output #0: loss = 0.683754 (* 1 = 0.683754 loss)
I0805 19:21:29.795300 10603 sgd_solver.cpp:106] Iteration 28000, lr = 5.18611e-06
I0805 19:21:33.007107 10603 solver.cpp:228] Iteration 28100, loss = 0.696332
I0805 19:21:33.007153 10603 solver.cpp:244]     Train net output #0: loss = 0.696332 (* 1 = 0.696332 loss)
I0805 19:21:33.007158 10603 sgd_solver.cpp:106] Iteration 28100, lr = 5.17802e-06
I0805 19:21:36.231051 10603 solver.cpp:228] Iteration 28200, loss = 0.689809
I0805 19:21:36.231101 10603 solver.cpp:244]     Train net output #0: loss = 0.689809 (* 1 = 0.689809 loss)
I0805 19:21:36.231107 10603 sgd_solver.cpp:106] Iteration 28200, lr = 5.16996e-06
I0805 19:21:39.471741 10603 solver.cpp:228] Iteration 28300, loss = 0.684959
I0805 19:21:39.471782 10603 solver.cpp:244]     Train net output #0: loss = 0.684959 (* 1 = 0.684959 loss)
I0805 19:21:39.471788 10603 sgd_solver.cpp:106] Iteration 28300, lr = 5.16193e-06
I0805 19:21:42.718771 10603 solver.cpp:228] Iteration 28400, loss = 0.69537
I0805 19:21:42.718819 10603 solver.cpp:244]     Train net output #0: loss = 0.69537 (* 1 = 0.69537 loss)
I0805 19:21:42.718827 10603 sgd_solver.cpp:106] Iteration 28400, lr = 5.15393e-06
I0805 19:21:45.930408 10603 solver.cpp:337] Iteration 28500, Testing net (#0)
I0805 19:21:49.534139 10603 solver.cpp:404]     Test net output #0: accuracy = 0.253547
I0805 19:21:49.534176 10603 solver.cpp:404]     Test net output #1: loss = 0.693164 (* 1 = 0.693164 loss)
I0805 19:21:49.547407 10603 solver.cpp:228] Iteration 28500, loss = 0.692949
I0805 19:21:49.547473 10603 solver.cpp:244]     Train net output #0: loss = 0.692949 (* 1 = 0.692949 loss)
I0805 19:21:49.547494 10603 sgd_solver.cpp:106] Iteration 28500, lr = 5.14596e-06
I0805 19:21:52.745365 10603 solver.cpp:228] Iteration 28600, loss = 0.700695
I0805 19:21:52.745412 10603 solver.cpp:244]     Train net output #0: loss = 0.700695 (* 1 = 0.700695 loss)
I0805 19:21:52.745419 10603 sgd_solver.cpp:106] Iteration 28600, lr = 5.13801e-06
I0805 19:21:55.978359 10603 solver.cpp:228] Iteration 28700, loss = 0.684741
I0805 19:21:55.978401 10603 solver.cpp:244]     Train net output #0: loss = 0.684741 (* 1 = 0.684741 loss)
I0805 19:21:55.978410 10603 sgd_solver.cpp:106] Iteration 28700, lr = 5.1301e-06
I0805 19:21:59.242110 10603 solver.cpp:228] Iteration 28800, loss = 0.690981
I0805 19:21:59.242174 10603 solver.cpp:244]     Train net output #0: loss = 0.690981 (* 1 = 0.690981 loss)
I0805 19:21:59.242182 10603 sgd_solver.cpp:106] Iteration 28800, lr = 5.12221e-06
I0805 19:22:02.511358 10603 solver.cpp:228] Iteration 28900, loss = 0.692818
I0805 19:22:02.511427 10603 solver.cpp:244]     Train net output #0: loss = 0.692818 (* 1 = 0.692818 loss)
I0805 19:22:02.511440 10603 sgd_solver.cpp:106] Iteration 28900, lr = 5.11435e-06
I0805 19:22:05.740331 10603 solver.cpp:337] Iteration 29000, Testing net (#0)
I0805 19:22:09.483465 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:22:09.483500 10603 solver.cpp:404]     Test net output #1: loss = 0.693349 (* 1 = 0.693349 loss)
I0805 19:22:09.494400 10603 solver.cpp:228] Iteration 29000, loss = 0.693966
I0805 19:22:09.494465 10603 solver.cpp:244]     Train net output #0: loss = 0.693966 (* 1 = 0.693966 loss)
I0805 19:22:09.494482 10603 sgd_solver.cpp:106] Iteration 29000, lr = 5.10652e-06
I0805 19:22:12.686096 10603 solver.cpp:228] Iteration 29100, loss = 0.689212
I0805 19:22:12.686154 10603 solver.cpp:244]     Train net output #0: loss = 0.689212 (* 1 = 0.689212 loss)
I0805 19:22:12.686162 10603 sgd_solver.cpp:106] Iteration 29100, lr = 5.09872e-06
I0805 19:22:15.887557 10603 solver.cpp:228] Iteration 29200, loss = 0.691638
I0805 19:22:15.887593 10603 solver.cpp:244]     Train net output #0: loss = 0.691638 (* 1 = 0.691638 loss)
I0805 19:22:15.887599 10603 sgd_solver.cpp:106] Iteration 29200, lr = 5.09095e-06
I0805 19:22:19.105509 10603 solver.cpp:228] Iteration 29300, loss = 0.687433
I0805 19:22:19.105553 10603 solver.cpp:244]     Train net output #0: loss = 0.687433 (* 1 = 0.687433 loss)
I0805 19:22:19.105561 10603 sgd_solver.cpp:106] Iteration 29300, lr = 5.0832e-06
I0805 19:22:22.345607 10603 solver.cpp:228] Iteration 29400, loss = 0.693799
I0805 19:22:22.345648 10603 solver.cpp:244]     Train net output #0: loss = 0.693799 (* 1 = 0.693799 loss)
I0805 19:22:22.345655 10603 sgd_solver.cpp:106] Iteration 29400, lr = 5.07548e-06
I0805 19:22:22.995780 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:22:25.553079 10603 solver.cpp:337] Iteration 29500, Testing net (#0)
I0805 19:22:29.066212 10603 solver.cpp:404]     Test net output #0: accuracy = 0.794419
I0805 19:22:29.066254 10603 solver.cpp:404]     Test net output #1: loss = 0.693115 (* 1 = 0.693115 loss)
I0805 19:22:29.079068 10603 solver.cpp:228] Iteration 29500, loss = 0.698148
I0805 19:22:29.079100 10603 solver.cpp:244]     Train net output #0: loss = 0.698148 (* 1 = 0.698148 loss)
I0805 19:22:29.079121 10603 sgd_solver.cpp:106] Iteration 29500, lr = 5.06779e-06
I0805 19:22:32.292354 10603 solver.cpp:228] Iteration 29600, loss = 0.700997
I0805 19:22:32.292399 10603 solver.cpp:244]     Train net output #0: loss = 0.700997 (* 1 = 0.700997 loss)
I0805 19:22:32.292405 10603 sgd_solver.cpp:106] Iteration 29600, lr = 5.06012e-06
I0805 19:22:35.531980 10603 solver.cpp:228] Iteration 29700, loss = 0.69175
I0805 19:22:35.532017 10603 solver.cpp:244]     Train net output #0: loss = 0.69175 (* 1 = 0.69175 loss)
I0805 19:22:35.532023 10603 sgd_solver.cpp:106] Iteration 29700, lr = 5.05249e-06
I0805 19:22:38.789815 10603 solver.cpp:228] Iteration 29800, loss = 0.692955
I0805 19:22:38.789858 10603 solver.cpp:244]     Train net output #0: loss = 0.692955 (* 1 = 0.692955 loss)
I0805 19:22:38.789865 10603 sgd_solver.cpp:106] Iteration 29800, lr = 5.04488e-06
I0805 19:22:42.045032 10603 solver.cpp:228] Iteration 29900, loss = 0.687735
I0805 19:22:42.045075 10603 solver.cpp:244]     Train net output #0: loss = 0.687735 (* 1 = 0.687735 loss)
I0805 19:22:42.045084 10603 sgd_solver.cpp:106] Iteration 29900, lr = 5.03729e-06
I0805 19:22:45.262060 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_30000.caffemodel
I0805 19:22:45.629580 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_30000.solverstate
I0805 19:22:45.761694 10603 solver.cpp:337] Iteration 30000, Testing net (#0)
I0805 19:22:49.311518 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207849
I0805 19:22:49.311569 10603 solver.cpp:404]     Test net output #1: loss = 0.693799 (* 1 = 0.693799 loss)
I0805 19:22:49.322212 10603 solver.cpp:228] Iteration 30000, loss = 0.694621
I0805 19:22:49.322276 10603 solver.cpp:244]     Train net output #0: loss = 0.694621 (* 1 = 0.694621 loss)
I0805 19:22:49.322294 10603 sgd_solver.cpp:106] Iteration 30000, lr = 5.02973e-06
I0805 19:22:52.513449 10603 solver.cpp:228] Iteration 30100, loss = 0.698353
I0805 19:22:52.513495 10603 solver.cpp:244]     Train net output #0: loss = 0.698353 (* 1 = 0.698353 loss)
I0805 19:22:52.513504 10603 sgd_solver.cpp:106] Iteration 30100, lr = 5.0222e-06
I0805 19:22:55.745857 10603 solver.cpp:228] Iteration 30200, loss = 0.699735
I0805 19:22:55.745894 10603 solver.cpp:244]     Train net output #0: loss = 0.699735 (* 1 = 0.699735 loss)
I0805 19:22:55.745900 10603 sgd_solver.cpp:106] Iteration 30200, lr = 5.0147e-06
I0805 19:22:58.997092 10603 solver.cpp:228] Iteration 30300, loss = 0.696883
I0805 19:22:58.997149 10603 solver.cpp:244]     Train net output #0: loss = 0.696883 (* 1 = 0.696883 loss)
I0805 19:22:58.997155 10603 sgd_solver.cpp:106] Iteration 30300, lr = 5.00722e-06
I0805 19:23:02.259055 10603 solver.cpp:228] Iteration 30400, loss = 0.692332
I0805 19:23:02.259094 10603 solver.cpp:244]     Train net output #0: loss = 0.692332 (* 1 = 0.692332 loss)
I0805 19:23:02.259100 10603 sgd_solver.cpp:106] Iteration 30400, lr = 4.99976e-06
I0805 19:23:05.488275 10603 solver.cpp:337] Iteration 30500, Testing net (#0)
I0805 19:23:09.056094 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207616
I0805 19:23:09.056136 10603 solver.cpp:404]     Test net output #1: loss = 0.693271 (* 1 = 0.693271 loss)
I0805 19:23:09.070081 10603 solver.cpp:228] Iteration 30500, loss = 0.699207
I0805 19:23:09.070149 10603 solver.cpp:244]     Train net output #0: loss = 0.699207 (* 1 = 0.699207 loss)
I0805 19:23:09.070176 10603 sgd_solver.cpp:106] Iteration 30500, lr = 4.99234e-06
I0805 19:23:12.268613 10603 solver.cpp:228] Iteration 30600, loss = 0.69473
I0805 19:23:12.268659 10603 solver.cpp:244]     Train net output #0: loss = 0.69473 (* 1 = 0.69473 loss)
I0805 19:23:12.268666 10603 sgd_solver.cpp:106] Iteration 30600, lr = 4.98494e-06
I0805 19:23:15.484181 10603 solver.cpp:228] Iteration 30700, loss = 0.69884
I0805 19:23:15.484220 10603 solver.cpp:244]     Train net output #0: loss = 0.69884 (* 1 = 0.69884 loss)
I0805 19:23:15.484225 10603 sgd_solver.cpp:106] Iteration 30700, lr = 4.97756e-06
I0805 19:23:18.714668 10603 solver.cpp:228] Iteration 30800, loss = 0.703584
I0805 19:23:18.714712 10603 solver.cpp:244]     Train net output #0: loss = 0.703584 (* 1 = 0.703584 loss)
I0805 19:23:18.714720 10603 sgd_solver.cpp:106] Iteration 30800, lr = 4.97021e-06
I0805 19:23:21.988878 10603 solver.cpp:228] Iteration 30900, loss = 0.698562
I0805 19:23:21.988929 10603 solver.cpp:244]     Train net output #0: loss = 0.698562 (* 1 = 0.698562 loss)
I0805 19:23:21.988935 10603 sgd_solver.cpp:106] Iteration 30900, lr = 4.96288e-06
I0805 19:23:25.230247 10603 solver.cpp:337] Iteration 31000, Testing net (#0)
I0805 19:23:28.818156 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207907
I0805 19:23:28.818207 10603 solver.cpp:404]     Test net output #1: loss = 0.69334 (* 1 = 0.69334 loss)
I0805 19:23:28.831276 10603 solver.cpp:228] Iteration 31000, loss = 0.692467
I0805 19:23:28.831307 10603 solver.cpp:244]     Train net output #0: loss = 0.692467 (* 1 = 0.692467 loss)
I0805 19:23:28.831317 10603 sgd_solver.cpp:106] Iteration 31000, lr = 4.95558e-06
I0805 19:23:32.057881 10603 solver.cpp:228] Iteration 31100, loss = 0.685608
I0805 19:23:32.057927 10603 solver.cpp:244]     Train net output #0: loss = 0.685608 (* 1 = 0.685608 loss)
I0805 19:23:32.057936 10603 sgd_solver.cpp:106] Iteration 31100, lr = 4.94831e-06
I0805 19:23:35.334652 10603 solver.cpp:228] Iteration 31200, loss = 0.701853
I0805 19:23:35.334692 10603 solver.cpp:244]     Train net output #0: loss = 0.701853 (* 1 = 0.701853 loss)
I0805 19:23:35.334698 10603 sgd_solver.cpp:106] Iteration 31200, lr = 4.94106e-06
I0805 19:23:38.609226 10603 solver.cpp:228] Iteration 31300, loss = 0.697043
I0805 19:23:38.609274 10603 solver.cpp:244]     Train net output #0: loss = 0.697043 (* 1 = 0.697043 loss)
I0805 19:23:38.609280 10603 sgd_solver.cpp:106] Iteration 31300, lr = 4.93383e-06
I0805 19:23:41.866171 10603 solver.cpp:228] Iteration 31400, loss = 0.701387
I0805 19:23:41.866233 10603 solver.cpp:244]     Train net output #0: loss = 0.701387 (* 1 = 0.701387 loss)
I0805 19:23:41.866240 10603 sgd_solver.cpp:106] Iteration 31400, lr = 4.92663e-06
I0805 19:23:45.096479 10603 solver.cpp:337] Iteration 31500, Testing net (#0)
I0805 19:23:48.337499 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:23:48.697423 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 19:23:48.697453 10603 solver.cpp:404]     Test net output #1: loss = 0.693207 (* 1 = 0.693207 loss)
I0805 19:23:48.708528 10603 solver.cpp:228] Iteration 31500, loss = 0.684777
I0805 19:23:48.708588 10603 solver.cpp:244]     Train net output #0: loss = 0.684777 (* 1 = 0.684777 loss)
I0805 19:23:48.708609 10603 sgd_solver.cpp:106] Iteration 31500, lr = 4.91946e-06
I0805 19:23:51.909456 10603 solver.cpp:228] Iteration 31600, loss = 0.693825
I0805 19:23:51.909497 10603 solver.cpp:244]     Train net output #0: loss = 0.693825 (* 1 = 0.693825 loss)
I0805 19:23:51.909502 10603 sgd_solver.cpp:106] Iteration 31600, lr = 4.9123e-06
I0805 19:23:55.141484 10603 solver.cpp:228] Iteration 31700, loss = 0.694647
I0805 19:23:55.141533 10603 solver.cpp:244]     Train net output #0: loss = 0.694647 (* 1 = 0.694647 loss)
I0805 19:23:55.141540 10603 sgd_solver.cpp:106] Iteration 31700, lr = 4.90518e-06
I0805 19:23:58.403141 10603 solver.cpp:228] Iteration 31800, loss = 0.707837
I0805 19:23:58.403183 10603 solver.cpp:244]     Train net output #0: loss = 0.707837 (* 1 = 0.707837 loss)
I0805 19:23:58.403189 10603 sgd_solver.cpp:106] Iteration 31800, lr = 4.89807e-06
I0805 19:24:01.658507 10603 solver.cpp:228] Iteration 31900, loss = 0.692682
I0805 19:24:01.658558 10603 solver.cpp:244]     Train net output #0: loss = 0.692682 (* 1 = 0.692682 loss)
I0805 19:24:01.658565 10603 sgd_solver.cpp:106] Iteration 31900, lr = 4.89099e-06
I0805 19:24:04.868419 10603 solver.cpp:337] Iteration 32000, Testing net (#0)
I0805 19:24:08.513519 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:24:08.513573 10603 solver.cpp:404]     Test net output #1: loss = 0.693325 (* 1 = 0.693325 loss)
I0805 19:24:08.527024 10603 solver.cpp:228] Iteration 32000, loss = 0.698094
I0805 19:24:08.527099 10603 solver.cpp:244]     Train net output #0: loss = 0.698094 (* 1 = 0.698094 loss)
I0805 19:24:08.527122 10603 sgd_solver.cpp:106] Iteration 32000, lr = 4.88394e-06
I0805 19:24:11.721132 10603 solver.cpp:228] Iteration 32100, loss = 0.694929
I0805 19:24:11.721171 10603 solver.cpp:244]     Train net output #0: loss = 0.694929 (* 1 = 0.694929 loss)
I0805 19:24:11.721179 10603 sgd_solver.cpp:106] Iteration 32100, lr = 4.8769e-06
I0805 19:24:14.960783 10603 solver.cpp:228] Iteration 32200, loss = 0.699668
I0805 19:24:14.960835 10603 solver.cpp:244]     Train net output #0: loss = 0.699668 (* 1 = 0.699668 loss)
I0805 19:24:14.960842 10603 sgd_solver.cpp:106] Iteration 32200, lr = 4.86989e-06
I0805 19:24:18.214164 10603 solver.cpp:228] Iteration 32300, loss = 0.709129
I0805 19:24:18.214221 10603 solver.cpp:244]     Train net output #0: loss = 0.709129 (* 1 = 0.709129 loss)
I0805 19:24:18.214228 10603 sgd_solver.cpp:106] Iteration 32300, lr = 4.86291e-06
I0805 19:24:21.466389 10603 solver.cpp:228] Iteration 32400, loss = 0.699225
I0805 19:24:21.466430 10603 solver.cpp:244]     Train net output #0: loss = 0.699225 (* 1 = 0.699225 loss)
I0805 19:24:21.466437 10603 sgd_solver.cpp:106] Iteration 32400, lr = 4.85595e-06
I0805 19:24:24.680176 10603 solver.cpp:337] Iteration 32500, Testing net (#0)
I0805 19:24:28.234921 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791803
I0805 19:24:28.234964 10603 solver.cpp:404]     Test net output #1: loss = 0.692798 (* 1 = 0.692798 loss)
I0805 19:24:28.245719 10603 solver.cpp:228] Iteration 32500, loss = 0.69511
I0805 19:24:28.245790 10603 solver.cpp:244]     Train net output #0: loss = 0.69511 (* 1 = 0.69511 loss)
I0805 19:24:28.245811 10603 sgd_solver.cpp:106] Iteration 32500, lr = 4.84901e-06
I0805 19:24:31.487037 10603 solver.cpp:228] Iteration 32600, loss = 0.706001
I0805 19:24:31.487084 10603 solver.cpp:244]     Train net output #0: loss = 0.706001 (* 1 = 0.706001 loss)
I0805 19:24:31.487090 10603 sgd_solver.cpp:106] Iteration 32600, lr = 4.84209e-06
I0805 19:24:34.722656 10603 solver.cpp:228] Iteration 32700, loss = 0.701976
I0805 19:24:34.722697 10603 solver.cpp:244]     Train net output #0: loss = 0.701976 (* 1 = 0.701976 loss)
I0805 19:24:34.722702 10603 sgd_solver.cpp:106] Iteration 32700, lr = 4.8352e-06
I0805 19:24:37.956274 10603 solver.cpp:228] Iteration 32800, loss = 0.690502
I0805 19:24:37.956318 10603 solver.cpp:244]     Train net output #0: loss = 0.690502 (* 1 = 0.690502 loss)
I0805 19:24:37.956326 10603 sgd_solver.cpp:106] Iteration 32800, lr = 4.82833e-06
I0805 19:24:41.209831 10603 solver.cpp:228] Iteration 32900, loss = 0.697195
I0805 19:24:41.209872 10603 solver.cpp:244]     Train net output #0: loss = 0.697195 (* 1 = 0.697195 loss)
I0805 19:24:41.209879 10603 sgd_solver.cpp:106] Iteration 32900, lr = 4.82148e-06
I0805 19:24:44.436957 10603 solver.cpp:337] Iteration 33000, Testing net (#0)
I0805 19:24:47.989558 10603 solver.cpp:404]     Test net output #0: accuracy = 0.79157
I0805 19:24:47.989609 10603 solver.cpp:404]     Test net output #1: loss = 0.693098 (* 1 = 0.693098 loss)
I0805 19:24:47.999907 10603 solver.cpp:228] Iteration 33000, loss = 0.695766
I0805 19:24:47.999938 10603 solver.cpp:244]     Train net output #0: loss = 0.695766 (* 1 = 0.695766 loss)
I0805 19:24:47.999954 10603 sgd_solver.cpp:106] Iteration 33000, lr = 4.81466e-06
I0805 19:24:51.202349 10603 solver.cpp:228] Iteration 33100, loss = 0.695418
I0805 19:24:51.202394 10603 solver.cpp:244]     Train net output #0: loss = 0.695418 (* 1 = 0.695418 loss)
I0805 19:24:51.202399 10603 sgd_solver.cpp:106] Iteration 33100, lr = 4.80786e-06
I0805 19:24:54.436450 10603 solver.cpp:228] Iteration 33200, loss = 0.685912
I0805 19:24:54.436504 10603 solver.cpp:244]     Train net output #0: loss = 0.685912 (* 1 = 0.685912 loss)
I0805 19:24:54.436513 10603 sgd_solver.cpp:106] Iteration 33200, lr = 4.80108e-06
I0805 19:24:57.685345 10603 solver.cpp:228] Iteration 33300, loss = 0.69177
I0805 19:24:57.685402 10603 solver.cpp:244]     Train net output #0: loss = 0.69177 (* 1 = 0.69177 loss)
I0805 19:24:57.685412 10603 sgd_solver.cpp:106] Iteration 33300, lr = 4.79432e-06
I0805 19:25:00.927872 10603 solver.cpp:228] Iteration 33400, loss = 0.69372
I0805 19:25:00.927912 10603 solver.cpp:244]     Train net output #0: loss = 0.69372 (* 1 = 0.69372 loss)
I0805 19:25:00.927918 10603 sgd_solver.cpp:106] Iteration 33400, lr = 4.78759e-06
I0805 19:25:04.144208 10603 solver.cpp:337] Iteration 33500, Testing net (#0)
I0805 19:25:07.892123 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 19:25:07.892168 10603 solver.cpp:404]     Test net output #1: loss = 0.694057 (* 1 = 0.694057 loss)
I0805 19:25:07.902907 10603 solver.cpp:228] Iteration 33500, loss = 0.68855
I0805 19:25:07.902976 10603 solver.cpp:244]     Train net output #0: loss = 0.68855 (* 1 = 0.68855 loss)
I0805 19:25:07.902993 10603 sgd_solver.cpp:106] Iteration 33500, lr = 4.78087e-06
I0805 19:25:11.113766 10603 solver.cpp:228] Iteration 33600, loss = 0.698581
I0805 19:25:11.113823 10603 solver.cpp:244]     Train net output #0: loss = 0.698581 (* 1 = 0.698581 loss)
I0805 19:25:11.113829 10603 sgd_solver.cpp:106] Iteration 33600, lr = 4.77418e-06
I0805 19:25:14.348947 10603 solver.cpp:228] Iteration 33700, loss = 0.693221
I0805 19:25:14.348990 10603 solver.cpp:244]     Train net output #0: loss = 0.693221 (* 1 = 0.693221 loss)
I0805 19:25:14.348997 10603 sgd_solver.cpp:106] Iteration 33700, lr = 4.76751e-06
I0805 19:25:17.624336 10603 solver.cpp:228] Iteration 33800, loss = 0.696495
I0805 19:25:17.624380 10603 solver.cpp:244]     Train net output #0: loss = 0.696495 (* 1 = 0.696495 loss)
I0805 19:25:17.624387 10603 sgd_solver.cpp:106] Iteration 33800, lr = 4.76086e-06
I0805 19:25:20.894909 10603 solver.cpp:228] Iteration 33900, loss = 0.693662
I0805 19:25:20.894965 10603 solver.cpp:244]     Train net output #0: loss = 0.693662 (* 1 = 0.693662 loss)
I0805 19:25:20.894973 10603 sgd_solver.cpp:106] Iteration 33900, lr = 4.75424e-06
I0805 19:25:24.132540 10603 solver.cpp:337] Iteration 34000, Testing net (#0)
I0805 19:25:27.681745 10603 solver.cpp:404]     Test net output #0: accuracy = 0.633546
I0805 19:25:27.681785 10603 solver.cpp:404]     Test net output #1: loss = 0.693138 (* 1 = 0.693138 loss)
I0805 19:25:27.695423 10603 solver.cpp:228] Iteration 34000, loss = 0.692323
I0805 19:25:27.695492 10603 solver.cpp:244]     Train net output #0: loss = 0.692323 (* 1 = 0.692323 loss)
I0805 19:25:27.695510 10603 sgd_solver.cpp:106] Iteration 34000, lr = 4.74763e-06
I0805 19:25:30.923377 10603 solver.cpp:228] Iteration 34100, loss = 0.69376
I0805 19:25:30.923418 10603 solver.cpp:244]     Train net output #0: loss = 0.69376 (* 1 = 0.69376 loss)
I0805 19:25:30.923424 10603 sgd_solver.cpp:106] Iteration 34100, lr = 4.74105e-06
I0805 19:25:34.164899 10603 solver.cpp:228] Iteration 34200, loss = 0.689739
I0805 19:25:34.164938 10603 solver.cpp:244]     Train net output #0: loss = 0.689739 (* 1 = 0.689739 loss)
I0805 19:25:34.164945 10603 sgd_solver.cpp:106] Iteration 34200, lr = 4.73449e-06
I0805 19:25:37.416431 10603 solver.cpp:228] Iteration 34300, loss = 0.681428
I0805 19:25:37.416482 10603 solver.cpp:244]     Train net output #0: loss = 0.681428 (* 1 = 0.681428 loss)
I0805 19:25:37.416489 10603 sgd_solver.cpp:106] Iteration 34300, lr = 4.72795e-06
I0805 19:25:40.658113 10603 solver.cpp:228] Iteration 34400, loss = 0.69692
I0805 19:25:40.658154 10603 solver.cpp:244]     Train net output #0: loss = 0.69692 (* 1 = 0.69692 loss)
I0805 19:25:40.658160 10603 sgd_solver.cpp:106] Iteration 34400, lr = 4.72143e-06
I0805 19:25:43.873746 10603 solver.cpp:337] Iteration 34500, Testing net (#0)
I0805 19:25:46.491714 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:25:47.394824 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791802
I0805 19:25:47.394855 10603 solver.cpp:404]     Test net output #1: loss = 0.693019 (* 1 = 0.693019 loss)
I0805 19:25:47.408092 10603 solver.cpp:228] Iteration 34500, loss = 0.696672
I0805 19:25:47.408143 10603 solver.cpp:244]     Train net output #0: loss = 0.696672 (* 1 = 0.696672 loss)
I0805 19:25:47.408152 10603 sgd_solver.cpp:106] Iteration 34500, lr = 4.71493e-06
I0805 19:25:50.633997 10603 solver.cpp:228] Iteration 34600, loss = 0.701866
I0805 19:25:50.634052 10603 solver.cpp:244]     Train net output #0: loss = 0.701866 (* 1 = 0.701866 loss)
I0805 19:25:50.634058 10603 sgd_solver.cpp:106] Iteration 34600, lr = 4.70845e-06
I0805 19:25:53.861933 10603 solver.cpp:228] Iteration 34700, loss = 0.695876
I0805 19:25:53.861984 10603 solver.cpp:244]     Train net output #0: loss = 0.695876 (* 1 = 0.695876 loss)
I0805 19:25:53.861995 10603 sgd_solver.cpp:106] Iteration 34700, lr = 4.70199e-06
I0805 19:25:57.097057 10603 solver.cpp:228] Iteration 34800, loss = 0.701948
I0805 19:25:57.097097 10603 solver.cpp:244]     Train net output #0: loss = 0.701948 (* 1 = 0.701948 loss)
I0805 19:25:57.097105 10603 sgd_solver.cpp:106] Iteration 34800, lr = 4.69556e-06
I0805 19:26:00.343181 10603 solver.cpp:228] Iteration 34900, loss = 0.704464
I0805 19:26:00.343225 10603 solver.cpp:244]     Train net output #0: loss = 0.704464 (* 1 = 0.704464 loss)
I0805 19:26:00.343230 10603 sgd_solver.cpp:106] Iteration 34900, lr = 4.68914e-06
I0805 19:26:03.564858 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_35000.caffemodel
I0805 19:26:03.940886 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_35000.solverstate
I0805 19:26:04.075863 10603 solver.cpp:337] Iteration 35000, Testing net (#0)
I0805 19:26:07.566457 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20907
I0805 19:26:07.566498 10603 solver.cpp:404]     Test net output #1: loss = 0.693756 (* 1 = 0.693756 loss)
I0805 19:26:07.576644 10603 solver.cpp:228] Iteration 35000, loss = 0.701462
I0805 19:26:07.576674 10603 solver.cpp:244]     Train net output #0: loss = 0.701462 (* 1 = 0.701462 loss)
I0805 19:26:07.576681 10603 sgd_solver.cpp:106] Iteration 35000, lr = 4.68274e-06
I0805 19:26:10.785703 10603 solver.cpp:228] Iteration 35100, loss = 0.694883
I0805 19:26:10.785747 10603 solver.cpp:244]     Train net output #0: loss = 0.694883 (* 1 = 0.694883 loss)
I0805 19:26:10.785753 10603 sgd_solver.cpp:106] Iteration 35100, lr = 4.67637e-06
I0805 19:26:14.044045 10603 solver.cpp:228] Iteration 35200, loss = 0.686911
I0805 19:26:14.044090 10603 solver.cpp:244]     Train net output #0: loss = 0.686911 (* 1 = 0.686911 loss)
I0805 19:26:14.044096 10603 sgd_solver.cpp:106] Iteration 35200, lr = 4.67001e-06
I0805 19:26:17.306607 10603 solver.cpp:228] Iteration 35300, loss = 0.694244
I0805 19:26:17.306651 10603 solver.cpp:244]     Train net output #0: loss = 0.694244 (* 1 = 0.694244 loss)
I0805 19:26:17.306658 10603 sgd_solver.cpp:106] Iteration 35300, lr = 4.66368e-06
I0805 19:26:20.573393 10603 solver.cpp:228] Iteration 35400, loss = 0.693512
I0805 19:26:20.573433 10603 solver.cpp:244]     Train net output #0: loss = 0.693512 (* 1 = 0.693512 loss)
I0805 19:26:20.573439 10603 sgd_solver.cpp:106] Iteration 35400, lr = 4.65736e-06
I0805 19:26:23.798125 10603 solver.cpp:337] Iteration 35500, Testing net (#0)
I0805 19:26:27.335803 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:26:27.335844 10603 solver.cpp:404]     Test net output #1: loss = 0.694192 (* 1 = 0.694192 loss)
I0805 19:26:27.348740 10603 solver.cpp:228] Iteration 35500, loss = 0.695988
I0805 19:26:27.348772 10603 solver.cpp:244]     Train net output #0: loss = 0.695988 (* 1 = 0.695988 loss)
I0805 19:26:27.348779 10603 sgd_solver.cpp:106] Iteration 35500, lr = 4.65107e-06
I0805 19:26:30.569623 10603 solver.cpp:228] Iteration 35600, loss = 0.697559
I0805 19:26:30.569670 10603 solver.cpp:244]     Train net output #0: loss = 0.697559 (* 1 = 0.697559 loss)
I0805 19:26:30.569677 10603 sgd_solver.cpp:106] Iteration 35600, lr = 4.64479e-06
I0805 19:26:33.790479 10603 solver.cpp:228] Iteration 35700, loss = 0.687862
I0805 19:26:33.790519 10603 solver.cpp:244]     Train net output #0: loss = 0.687862 (* 1 = 0.687862 loss)
I0805 19:26:33.790525 10603 sgd_solver.cpp:106] Iteration 35700, lr = 4.63854e-06
I0805 19:26:37.019721 10603 solver.cpp:228] Iteration 35800, loss = 0.69346
I0805 19:26:37.019763 10603 solver.cpp:244]     Train net output #0: loss = 0.69346 (* 1 = 0.69346 loss)
I0805 19:26:37.019770 10603 sgd_solver.cpp:106] Iteration 35800, lr = 4.6323e-06
I0805 19:26:40.249891 10603 solver.cpp:228] Iteration 35900, loss = 0.681311
I0805 19:26:40.249929 10603 solver.cpp:244]     Train net output #0: loss = 0.681311 (* 1 = 0.681311 loss)
I0805 19:26:40.249934 10603 sgd_solver.cpp:106] Iteration 35900, lr = 4.62609e-06
I0805 19:26:43.468654 10603 solver.cpp:337] Iteration 36000, Testing net (#0)
I0805 19:26:47.026495 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:26:47.026540 10603 solver.cpp:404]     Test net output #1: loss = 0.693626 (* 1 = 0.693626 loss)
I0805 19:26:47.037317 10603 solver.cpp:228] Iteration 36000, loss = 0.692874
I0805 19:26:47.037380 10603 solver.cpp:244]     Train net output #0: loss = 0.692874 (* 1 = 0.692874 loss)
I0805 19:26:47.037397 10603 sgd_solver.cpp:106] Iteration 36000, lr = 4.61989e-06
I0805 19:26:50.279526 10603 solver.cpp:228] Iteration 36100, loss = 0.694735
I0805 19:26:50.279572 10603 solver.cpp:244]     Train net output #0: loss = 0.694735 (* 1 = 0.694735 loss)
I0805 19:26:50.279582 10603 sgd_solver.cpp:106] Iteration 36100, lr = 4.61371e-06
I0805 19:26:53.526898 10603 solver.cpp:228] Iteration 36200, loss = 0.691227
I0805 19:26:53.526943 10603 solver.cpp:244]     Train net output #0: loss = 0.691227 (* 1 = 0.691227 loss)
I0805 19:26:53.526950 10603 sgd_solver.cpp:106] Iteration 36200, lr = 4.60755e-06
I0805 19:26:56.790642 10603 solver.cpp:228] Iteration 36300, loss = 0.688568
I0805 19:26:56.790691 10603 solver.cpp:244]     Train net output #0: loss = 0.688568 (* 1 = 0.688568 loss)
I0805 19:26:56.790699 10603 sgd_solver.cpp:106] Iteration 36300, lr = 4.60141e-06
I0805 19:27:00.066189 10603 solver.cpp:228] Iteration 36400, loss = 0.691368
I0805 19:27:00.066229 10603 solver.cpp:244]     Train net output #0: loss = 0.691368 (* 1 = 0.691368 loss)
I0805 19:27:00.066236 10603 sgd_solver.cpp:106] Iteration 36400, lr = 4.59529e-06
I0805 19:27:03.304419 10603 solver.cpp:337] Iteration 36500, Testing net (#0)
I0805 19:27:06.908042 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:27:06.908107 10603 solver.cpp:404]     Test net output #1: loss = 0.69369 (* 1 = 0.69369 loss)
I0805 19:27:06.921895 10603 solver.cpp:228] Iteration 36500, loss = 0.691176
I0805 19:27:06.921967 10603 solver.cpp:244]     Train net output #0: loss = 0.691176 (* 1 = 0.691176 loss)
I0805 19:27:06.921983 10603 sgd_solver.cpp:106] Iteration 36500, lr = 4.58919e-06
I0805 19:27:10.149926 10603 solver.cpp:228] Iteration 36600, loss = 0.695947
I0805 19:27:10.149976 10603 solver.cpp:244]     Train net output #0: loss = 0.695947 (* 1 = 0.695947 loss)
I0805 19:27:10.149984 10603 sgd_solver.cpp:106] Iteration 36600, lr = 4.58311e-06
I0805 19:27:13.381294 10603 solver.cpp:228] Iteration 36700, loss = 0.691195
I0805 19:27:13.381340 10603 solver.cpp:244]     Train net output #0: loss = 0.691195 (* 1 = 0.691195 loss)
I0805 19:27:13.381345 10603 sgd_solver.cpp:106] Iteration 36700, lr = 4.57705e-06
I0805 19:27:16.634749 10603 solver.cpp:228] Iteration 36800, loss = 0.689903
I0805 19:27:16.634799 10603 solver.cpp:244]     Train net output #0: loss = 0.689903 (* 1 = 0.689903 loss)
I0805 19:27:16.634805 10603 sgd_solver.cpp:106] Iteration 36800, lr = 4.571e-06
I0805 19:27:19.888093 10603 solver.cpp:228] Iteration 36900, loss = 0.695889
I0805 19:27:19.888134 10603 solver.cpp:244]     Train net output #0: loss = 0.695889 (* 1 = 0.695889 loss)
I0805 19:27:19.888140 10603 sgd_solver.cpp:106] Iteration 36900, lr = 4.56497e-06
I0805 19:27:23.111800 10603 solver.cpp:337] Iteration 37000, Testing net (#0)
I0805 19:27:26.736526 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:27:26.736578 10603 solver.cpp:404]     Test net output #1: loss = 0.693189 (* 1 = 0.693189 loss)
I0805 19:27:26.747406 10603 solver.cpp:228] Iteration 37000, loss = 0.69066
I0805 19:27:26.747480 10603 solver.cpp:244]     Train net output #0: loss = 0.69066 (* 1 = 0.69066 loss)
I0805 19:27:26.747498 10603 sgd_solver.cpp:106] Iteration 37000, lr = 4.55897e-06
I0805 19:27:29.954560 10603 solver.cpp:228] Iteration 37100, loss = 0.695044
I0805 19:27:29.954608 10603 solver.cpp:244]     Train net output #0: loss = 0.695044 (* 1 = 0.695044 loss)
I0805 19:27:29.954615 10603 sgd_solver.cpp:106] Iteration 37100, lr = 4.55298e-06
I0805 19:27:33.152676 10603 solver.cpp:228] Iteration 37200, loss = 0.691417
I0805 19:27:33.152715 10603 solver.cpp:244]     Train net output #0: loss = 0.691417 (* 1 = 0.691417 loss)
I0805 19:27:33.152721 10603 sgd_solver.cpp:106] Iteration 37200, lr = 4.54701e-06
I0805 19:27:36.399734 10603 solver.cpp:228] Iteration 37300, loss = 0.687752
I0805 19:27:36.399791 10603 solver.cpp:244]     Train net output #0: loss = 0.687752 (* 1 = 0.687752 loss)
I0805 19:27:36.399801 10603 sgd_solver.cpp:106] Iteration 37300, lr = 4.54105e-06
I0805 19:27:39.641917 10603 solver.cpp:228] Iteration 37400, loss = 0.692905
I0805 19:27:39.641985 10603 solver.cpp:244]     Train net output #0: loss = 0.692905 (* 1 = 0.692905 loss)
I0805 19:27:39.642002 10603 sgd_solver.cpp:106] Iteration 37400, lr = 4.53512e-06
I0805 19:27:42.859798 10603 solver.cpp:337] Iteration 37500, Testing net (#0)
I0805 19:27:45.579689 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:27:46.519605 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 19:27:46.519661 10603 solver.cpp:404]     Test net output #1: loss = 0.693941 (* 1 = 0.693941 loss)
I0805 19:27:46.530599 10603 solver.cpp:228] Iteration 37500, loss = 0.702072
I0805 19:27:46.530670 10603 solver.cpp:244]     Train net output #0: loss = 0.702072 (* 1 = 0.702072 loss)
I0805 19:27:46.530694 10603 sgd_solver.cpp:106] Iteration 37500, lr = 4.5292e-06
I0805 19:27:49.769124 10603 solver.cpp:228] Iteration 37600, loss = 0.687585
I0805 19:27:49.769165 10603 solver.cpp:244]     Train net output #0: loss = 0.687585 (* 1 = 0.687585 loss)
I0805 19:27:49.769171 10603 sgd_solver.cpp:106] Iteration 37600, lr = 4.5233e-06
I0805 19:27:53.018633 10603 solver.cpp:228] Iteration 37700, loss = 0.700133
I0805 19:27:53.018676 10603 solver.cpp:244]     Train net output #0: loss = 0.700133 (* 1 = 0.700133 loss)
I0805 19:27:53.018683 10603 sgd_solver.cpp:106] Iteration 37700, lr = 4.51742e-06
I0805 19:27:56.284090 10603 solver.cpp:228] Iteration 37800, loss = 0.687573
I0805 19:27:56.284138 10603 solver.cpp:244]     Train net output #0: loss = 0.687573 (* 1 = 0.687573 loss)
I0805 19:27:56.284144 10603 sgd_solver.cpp:106] Iteration 37800, lr = 4.51156e-06
I0805 19:27:59.540484 10603 solver.cpp:228] Iteration 37900, loss = 0.688768
I0805 19:27:59.540527 10603 solver.cpp:244]     Train net output #0: loss = 0.688768 (* 1 = 0.688768 loss)
I0805 19:27:59.540534 10603 sgd_solver.cpp:106] Iteration 37900, lr = 4.50571e-06
I0805 19:28:02.760813 10603 solver.cpp:337] Iteration 38000, Testing net (#0)
I0805 19:28:06.380352 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0805 19:28:06.380401 10603 solver.cpp:404]     Test net output #1: loss = 0.693105 (* 1 = 0.693105 loss)
I0805 19:28:06.393131 10603 solver.cpp:228] Iteration 38000, loss = 0.690602
I0805 19:28:06.393162 10603 solver.cpp:244]     Train net output #0: loss = 0.690602 (* 1 = 0.690602 loss)
I0805 19:28:06.393170 10603 sgd_solver.cpp:106] Iteration 38000, lr = 4.49989e-06
I0805 19:28:09.599558 10603 solver.cpp:228] Iteration 38100, loss = 0.686758
I0805 19:28:09.599607 10603 solver.cpp:244]     Train net output #0: loss = 0.686758 (* 1 = 0.686758 loss)
I0805 19:28:09.599613 10603 sgd_solver.cpp:106] Iteration 38100, lr = 4.49408e-06
I0805 19:28:12.844285 10603 solver.cpp:228] Iteration 38200, loss = 0.699993
I0805 19:28:12.844326 10603 solver.cpp:244]     Train net output #0: loss = 0.699993 (* 1 = 0.699993 loss)
I0805 19:28:12.844332 10603 sgd_solver.cpp:106] Iteration 38200, lr = 4.48828e-06
I0805 19:28:16.092329 10603 solver.cpp:228] Iteration 38300, loss = 0.689261
I0805 19:28:16.092387 10603 solver.cpp:244]     Train net output #0: loss = 0.689261 (* 1 = 0.689261 loss)
I0805 19:28:16.092394 10603 sgd_solver.cpp:106] Iteration 38300, lr = 4.48251e-06
I0805 19:28:19.341630 10603 solver.cpp:228] Iteration 38400, loss = 0.699999
I0805 19:28:19.341672 10603 solver.cpp:244]     Train net output #0: loss = 0.699999 (* 1 = 0.699999 loss)
I0805 19:28:19.341678 10603 sgd_solver.cpp:106] Iteration 38400, lr = 4.47675e-06
I0805 19:28:22.558531 10603 solver.cpp:337] Iteration 38500, Testing net (#0)
I0805 19:28:26.419720 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:28:26.419777 10603 solver.cpp:404]     Test net output #1: loss = 0.693185 (* 1 = 0.693185 loss)
I0805 19:28:26.432982 10603 solver.cpp:228] Iteration 38500, loss = 0.690224
I0805 19:28:26.433012 10603 solver.cpp:244]     Train net output #0: loss = 0.690224 (* 1 = 0.690224 loss)
I0805 19:28:26.433032 10603 sgd_solver.cpp:106] Iteration 38500, lr = 4.47101e-06
I0805 19:28:29.633903 10603 solver.cpp:228] Iteration 38600, loss = 0.700094
I0805 19:28:29.633966 10603 solver.cpp:244]     Train net output #0: loss = 0.700094 (* 1 = 0.700094 loss)
I0805 19:28:29.633975 10603 sgd_solver.cpp:106] Iteration 38600, lr = 4.46529e-06
I0805 19:28:32.875332 10603 solver.cpp:228] Iteration 38700, loss = 0.704519
I0805 19:28:32.875391 10603 solver.cpp:244]     Train net output #0: loss = 0.704519 (* 1 = 0.704519 loss)
I0805 19:28:32.875397 10603 sgd_solver.cpp:106] Iteration 38700, lr = 4.45958e-06
I0805 19:28:36.147270 10603 solver.cpp:228] Iteration 38800, loss = 0.698495
I0805 19:28:36.147323 10603 solver.cpp:244]     Train net output #0: loss = 0.698495 (* 1 = 0.698495 loss)
I0805 19:28:36.147330 10603 sgd_solver.cpp:106] Iteration 38800, lr = 4.45389e-06
I0805 19:28:39.418086 10603 solver.cpp:228] Iteration 38900, loss = 0.699623
I0805 19:28:39.418126 10603 solver.cpp:244]     Train net output #0: loss = 0.699623 (* 1 = 0.699623 loss)
I0805 19:28:39.418133 10603 sgd_solver.cpp:106] Iteration 38900, lr = 4.44822e-06
I0805 19:28:42.659150 10603 solver.cpp:337] Iteration 39000, Testing net (#0)
I0805 19:28:46.234581 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:28:46.234647 10603 solver.cpp:404]     Test net output #1: loss = 0.693633 (* 1 = 0.693633 loss)
I0805 19:28:46.247267 10603 solver.cpp:228] Iteration 39000, loss = 0.703574
I0805 19:28:46.247298 10603 solver.cpp:244]     Train net output #0: loss = 0.703574 (* 1 = 0.703574 loss)
I0805 19:28:46.247308 10603 sgd_solver.cpp:106] Iteration 39000, lr = 4.44256e-06
I0805 19:28:49.436693 10603 solver.cpp:228] Iteration 39100, loss = 0.708302
I0805 19:28:49.436760 10603 solver.cpp:244]     Train net output #0: loss = 0.708302 (* 1 = 0.708302 loss)
I0805 19:28:49.436767 10603 sgd_solver.cpp:106] Iteration 39100, lr = 4.43692e-06
I0805 19:28:52.660315 10603 solver.cpp:228] Iteration 39200, loss = 0.695103
I0805 19:28:52.660359 10603 solver.cpp:244]     Train net output #0: loss = 0.695103 (* 1 = 0.695103 loss)
I0805 19:28:52.660365 10603 sgd_solver.cpp:106] Iteration 39200, lr = 4.4313e-06
I0805 19:28:55.921121 10603 solver.cpp:228] Iteration 39300, loss = 0.690272
I0805 19:28:55.921156 10603 solver.cpp:244]     Train net output #0: loss = 0.690272 (* 1 = 0.690272 loss)
I0805 19:28:55.921162 10603 sgd_solver.cpp:106] Iteration 39300, lr = 4.42569e-06
I0805 19:28:59.168203 10603 solver.cpp:228] Iteration 39400, loss = 0.698028
I0805 19:28:59.168246 10603 solver.cpp:244]     Train net output #0: loss = 0.698028 (* 1 = 0.698028 loss)
I0805 19:28:59.168252 10603 sgd_solver.cpp:106] Iteration 39400, lr = 4.42011e-06
I0805 19:29:02.371487 10603 solver.cpp:337] Iteration 39500, Testing net (#0)
I0805 19:29:05.909850 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:29:05.909915 10603 solver.cpp:404]     Test net output #1: loss = 0.693261 (* 1 = 0.693261 loss)
I0805 19:29:05.920130 10603 solver.cpp:228] Iteration 39500, loss = 0.708276
I0805 19:29:05.920161 10603 solver.cpp:244]     Train net output #0: loss = 0.708276 (* 1 = 0.708276 loss)
I0805 19:29:05.920172 10603 sgd_solver.cpp:106] Iteration 39500, lr = 4.41453e-06
I0805 19:29:09.149575 10603 solver.cpp:228] Iteration 39600, loss = 0.698674
I0805 19:29:09.149619 10603 solver.cpp:244]     Train net output #0: loss = 0.698674 (* 1 = 0.698674 loss)
I0805 19:29:09.149626 10603 sgd_solver.cpp:106] Iteration 39600, lr = 4.40898e-06
I0805 19:29:12.397238 10603 solver.cpp:228] Iteration 39700, loss = 0.694331
I0805 19:29:12.397281 10603 solver.cpp:244]     Train net output #0: loss = 0.694331 (* 1 = 0.694331 loss)
I0805 19:29:12.397289 10603 sgd_solver.cpp:106] Iteration 39700, lr = 4.40344e-06
I0805 19:29:15.654779 10603 solver.cpp:228] Iteration 39800, loss = 0.697922
I0805 19:29:15.654816 10603 solver.cpp:244]     Train net output #0: loss = 0.697922 (* 1 = 0.697922 loss)
I0805 19:29:15.654822 10603 sgd_solver.cpp:106] Iteration 39800, lr = 4.39791e-06
I0805 19:29:18.912557 10603 solver.cpp:228] Iteration 39900, loss = 0.690056
I0805 19:29:18.912602 10603 solver.cpp:244]     Train net output #0: loss = 0.690056 (* 1 = 0.690056 loss)
I0805 19:29:18.912608 10603 sgd_solver.cpp:106] Iteration 39900, lr = 4.39241e-06
I0805 19:29:22.136696 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_40000.caffemodel
I0805 19:29:22.504765 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_40000.solverstate
I0805 19:29:22.637235 10603 solver.cpp:337] Iteration 40000, Testing net (#0)
I0805 19:29:23.794914 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:29:26.161622 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791686
I0805 19:29:26.161660 10603 solver.cpp:404]     Test net output #1: loss = 0.692825 (* 1 = 0.692825 loss)
I0805 19:29:26.175453 10603 solver.cpp:228] Iteration 40000, loss = 0.695381
I0805 19:29:26.175531 10603 solver.cpp:244]     Train net output #0: loss = 0.695381 (* 1 = 0.695381 loss)
I0805 19:29:26.175554 10603 sgd_solver.cpp:106] Iteration 40000, lr = 4.38691e-06
I0805 19:29:29.387923 10603 solver.cpp:228] Iteration 40100, loss = 0.695085
I0805 19:29:29.387964 10603 solver.cpp:244]     Train net output #0: loss = 0.695085 (* 1 = 0.695085 loss)
I0805 19:29:29.387970 10603 sgd_solver.cpp:106] Iteration 40100, lr = 4.38144e-06
I0805 19:29:32.636016 10603 solver.cpp:228] Iteration 40200, loss = 0.691234
I0805 19:29:32.636065 10603 solver.cpp:244]     Train net output #0: loss = 0.691234 (* 1 = 0.691234 loss)
I0805 19:29:32.636071 10603 sgd_solver.cpp:106] Iteration 40200, lr = 4.37598e-06
I0805 19:29:35.896984 10603 solver.cpp:228] Iteration 40300, loss = 0.700812
I0805 19:29:35.897024 10603 solver.cpp:244]     Train net output #0: loss = 0.700812 (* 1 = 0.700812 loss)
I0805 19:29:35.897030 10603 sgd_solver.cpp:106] Iteration 40300, lr = 4.37053e-06
I0805 19:29:39.155392 10603 solver.cpp:228] Iteration 40400, loss = 0.690436
I0805 19:29:39.155438 10603 solver.cpp:244]     Train net output #0: loss = 0.690436 (* 1 = 0.690436 loss)
I0805 19:29:39.155446 10603 sgd_solver.cpp:106] Iteration 40400, lr = 4.36511e-06
I0805 19:29:42.383133 10603 solver.cpp:337] Iteration 40500, Testing net (#0)
I0805 19:29:45.910709 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:29:45.910742 10603 solver.cpp:404]     Test net output #1: loss = 0.69333 (* 1 = 0.69333 loss)
I0805 19:29:45.920841 10603 solver.cpp:228] Iteration 40500, loss = 0.693106
I0805 19:29:45.920860 10603 solver.cpp:244]     Train net output #0: loss = 0.693106 (* 1 = 0.693106 loss)
I0805 19:29:45.920867 10603 sgd_solver.cpp:106] Iteration 40500, lr = 4.35969e-06
I0805 19:29:49.142468 10603 solver.cpp:228] Iteration 40600, loss = 0.698332
I0805 19:29:49.142514 10603 solver.cpp:244]     Train net output #0: loss = 0.698332 (* 1 = 0.698332 loss)
I0805 19:29:49.142521 10603 sgd_solver.cpp:106] Iteration 40600, lr = 4.3543e-06
I0805 19:29:52.373491 10603 solver.cpp:228] Iteration 40700, loss = 0.70002
I0805 19:29:52.373534 10603 solver.cpp:244]     Train net output #0: loss = 0.70002 (* 1 = 0.70002 loss)
I0805 19:29:52.373544 10603 sgd_solver.cpp:106] Iteration 40700, lr = 4.34892e-06
I0805 19:29:55.618355 10603 solver.cpp:228] Iteration 40800, loss = 0.700674
I0805 19:29:55.618388 10603 solver.cpp:244]     Train net output #0: loss = 0.700674 (* 1 = 0.700674 loss)
I0805 19:29:55.618396 10603 sgd_solver.cpp:106] Iteration 40800, lr = 4.34355e-06
I0805 19:29:58.870558 10603 solver.cpp:228] Iteration 40900, loss = 0.694049
I0805 19:29:58.870597 10603 solver.cpp:244]     Train net output #0: loss = 0.694049 (* 1 = 0.694049 loss)
I0805 19:29:58.870604 10603 sgd_solver.cpp:106] Iteration 40900, lr = 4.3382e-06
I0805 19:30:02.110805 10603 solver.cpp:337] Iteration 41000, Testing net (#0)
I0805 19:30:05.682075 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 19:30:05.682117 10603 solver.cpp:404]     Test net output #1: loss = 0.694072 (* 1 = 0.694072 loss)
I0805 19:30:05.695401 10603 solver.cpp:228] Iteration 41000, loss = 0.69773
I0805 19:30:05.695438 10603 solver.cpp:244]     Train net output #0: loss = 0.69773 (* 1 = 0.69773 loss)
I0805 19:30:05.695451 10603 sgd_solver.cpp:106] Iteration 41000, lr = 4.33286e-06
I0805 19:30:08.909778 10603 solver.cpp:228] Iteration 41100, loss = 0.68606
I0805 19:30:08.909838 10603 solver.cpp:244]     Train net output #0: loss = 0.68606 (* 1 = 0.68606 loss)
I0805 19:30:08.909845 10603 sgd_solver.cpp:106] Iteration 41100, lr = 4.32754e-06
I0805 19:30:12.147248 10603 solver.cpp:228] Iteration 41200, loss = 0.685323
I0805 19:30:12.147301 10603 solver.cpp:244]     Train net output #0: loss = 0.685323 (* 1 = 0.685323 loss)
I0805 19:30:12.147308 10603 sgd_solver.cpp:106] Iteration 41200, lr = 4.32224e-06
I0805 19:30:15.404671 10603 solver.cpp:228] Iteration 41300, loss = 0.696334
I0805 19:30:15.404726 10603 solver.cpp:244]     Train net output #0: loss = 0.696334 (* 1 = 0.696334 loss)
I0805 19:30:15.404736 10603 sgd_solver.cpp:106] Iteration 41300, lr = 4.31695e-06
I0805 19:30:18.668565 10603 solver.cpp:228] Iteration 41400, loss = 0.706731
I0805 19:30:18.668606 10603 solver.cpp:244]     Train net output #0: loss = 0.706731 (* 1 = 0.706731 loss)
I0805 19:30:18.668614 10603 sgd_solver.cpp:106] Iteration 41400, lr = 4.31168e-06
I0805 19:30:21.908953 10603 solver.cpp:337] Iteration 41500, Testing net (#0)
I0805 19:30:25.417876 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208779
I0805 19:30:25.417928 10603 solver.cpp:404]     Test net output #1: loss = 0.693191 (* 1 = 0.693191 loss)
I0805 19:30:25.431524 10603 solver.cpp:228] Iteration 41500, loss = 0.694008
I0805 19:30:25.431588 10603 solver.cpp:244]     Train net output #0: loss = 0.694008 (* 1 = 0.694008 loss)
I0805 19:30:25.431605 10603 sgd_solver.cpp:106] Iteration 41500, lr = 4.30642e-06
I0805 19:30:28.657349 10603 solver.cpp:228] Iteration 41600, loss = 0.690167
I0805 19:30:28.657395 10603 solver.cpp:244]     Train net output #0: loss = 0.690167 (* 1 = 0.690167 loss)
I0805 19:30:28.657403 10603 sgd_solver.cpp:106] Iteration 41600, lr = 4.30117e-06
I0805 19:30:31.881913 10603 solver.cpp:228] Iteration 41700, loss = 0.683689
I0805 19:30:31.881971 10603 solver.cpp:244]     Train net output #0: loss = 0.683689 (* 1 = 0.683689 loss)
I0805 19:30:31.881983 10603 sgd_solver.cpp:106] Iteration 41700, lr = 4.29594e-06
I0805 19:30:35.123399 10603 solver.cpp:228] Iteration 41800, loss = 0.696847
I0805 19:30:35.123464 10603 solver.cpp:244]     Train net output #0: loss = 0.696847 (* 1 = 0.696847 loss)
I0805 19:30:35.123476 10603 sgd_solver.cpp:106] Iteration 41800, lr = 4.29073e-06
I0805 19:30:38.359941 10603 solver.cpp:228] Iteration 41900, loss = 0.701353
I0805 19:30:38.359982 10603 solver.cpp:244]     Train net output #0: loss = 0.701353 (* 1 = 0.701353 loss)
I0805 19:30:38.359988 10603 sgd_solver.cpp:106] Iteration 41900, lr = 4.28553e-06
I0805 19:30:41.570333 10603 solver.cpp:337] Iteration 42000, Testing net (#0)
I0805 19:30:45.153242 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:30:45.153298 10603 solver.cpp:404]     Test net output #1: loss = 0.693318 (* 1 = 0.693318 loss)
I0805 19:30:45.166738 10603 solver.cpp:228] Iteration 42000, loss = 0.693099
I0805 19:30:45.166802 10603 solver.cpp:244]     Train net output #0: loss = 0.693099 (* 1 = 0.693099 loss)
I0805 19:30:45.166821 10603 sgd_solver.cpp:106] Iteration 42000, lr = 4.28034e-06
I0805 19:30:48.387261 10603 solver.cpp:228] Iteration 42100, loss = 0.68823
I0805 19:30:48.387317 10603 solver.cpp:244]     Train net output #0: loss = 0.68823 (* 1 = 0.68823 loss)
I0805 19:30:48.387325 10603 sgd_solver.cpp:106] Iteration 42100, lr = 4.27517e-06
I0805 19:30:51.606873 10603 solver.cpp:228] Iteration 42200, loss = 0.698443
I0805 19:30:51.606914 10603 solver.cpp:244]     Train net output #0: loss = 0.698443 (* 1 = 0.698443 loss)
I0805 19:30:51.606920 10603 sgd_solver.cpp:106] Iteration 42200, lr = 4.27002e-06
I0805 19:30:54.838798 10603 solver.cpp:228] Iteration 42300, loss = 0.703291
I0805 19:30:54.838845 10603 solver.cpp:244]     Train net output #0: loss = 0.703291 (* 1 = 0.703291 loss)
I0805 19:30:54.838852 10603 sgd_solver.cpp:106] Iteration 42300, lr = 4.26488e-06
I0805 19:30:58.081781 10603 solver.cpp:228] Iteration 42400, loss = 0.712416
I0805 19:30:58.081822 10603 solver.cpp:244]     Train net output #0: loss = 0.712416 (* 1 = 0.712416 loss)
I0805 19:30:58.081830 10603 sgd_solver.cpp:106] Iteration 42400, lr = 4.25975e-06
I0805 19:31:01.297413 10603 solver.cpp:337] Iteration 42500, Testing net (#0)
I0805 19:31:02.413522 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:31:04.936288 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208895
I0805 19:31:04.936339 10603 solver.cpp:404]     Test net output #1: loss = 0.693376 (* 1 = 0.693376 loss)
I0805 19:31:04.946425 10603 solver.cpp:228] Iteration 42500, loss = 0.696432
I0805 19:31:04.946458 10603 solver.cpp:244]     Train net output #0: loss = 0.696432 (* 1 = 0.696432 loss)
I0805 19:31:04.946470 10603 sgd_solver.cpp:106] Iteration 42500, lr = 4.25464e-06
I0805 19:31:08.165316 10603 solver.cpp:228] Iteration 42600, loss = 0.69997
I0805 19:31:08.165375 10603 solver.cpp:244]     Train net output #0: loss = 0.69997 (* 1 = 0.69997 loss)
I0805 19:31:08.165381 10603 sgd_solver.cpp:106] Iteration 42600, lr = 4.24954e-06
I0805 19:31:11.420233 10603 solver.cpp:228] Iteration 42700, loss = 0.699471
I0805 19:31:11.420281 10603 solver.cpp:244]     Train net output #0: loss = 0.699471 (* 1 = 0.699471 loss)
I0805 19:31:11.420287 10603 sgd_solver.cpp:106] Iteration 42700, lr = 4.24445e-06
I0805 19:31:14.676204 10603 solver.cpp:228] Iteration 42800, loss = 0.700074
I0805 19:31:14.676249 10603 solver.cpp:244]     Train net output #0: loss = 0.700074 (* 1 = 0.700074 loss)
I0805 19:31:14.676255 10603 sgd_solver.cpp:106] Iteration 42800, lr = 4.23938e-06
I0805 19:31:17.927759 10603 solver.cpp:228] Iteration 42900, loss = 0.697599
I0805 19:31:17.927801 10603 solver.cpp:244]     Train net output #0: loss = 0.697599 (* 1 = 0.697599 loss)
I0805 19:31:17.927809 10603 sgd_solver.cpp:106] Iteration 42900, lr = 4.23433e-06
I0805 19:31:21.149576 10603 solver.cpp:337] Iteration 43000, Testing net (#0)
I0805 19:31:24.678213 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:31:24.678287 10603 solver.cpp:404]     Test net output #1: loss = 0.69378 (* 1 = 0.69378 loss)
I0805 19:31:24.691841 10603 solver.cpp:228] Iteration 43000, loss = 0.697455
I0805 19:31:24.691896 10603 solver.cpp:244]     Train net output #0: loss = 0.697455 (* 1 = 0.697455 loss)
I0805 19:31:24.691911 10603 sgd_solver.cpp:106] Iteration 43000, lr = 4.22929e-06
I0805 19:31:27.906991 10603 solver.cpp:228] Iteration 43100, loss = 0.687344
I0805 19:31:27.907043 10603 solver.cpp:244]     Train net output #0: loss = 0.687344 (* 1 = 0.687344 loss)
I0805 19:31:27.907049 10603 sgd_solver.cpp:106] Iteration 43100, lr = 4.22426e-06
I0805 19:31:31.128643 10603 solver.cpp:228] Iteration 43200, loss = 0.681593
I0805 19:31:31.128684 10603 solver.cpp:244]     Train net output #0: loss = 0.681593 (* 1 = 0.681593 loss)
I0805 19:31:31.128690 10603 sgd_solver.cpp:106] Iteration 43200, lr = 4.21924e-06
I0805 19:31:34.381701 10603 solver.cpp:228] Iteration 43300, loss = 0.69747
I0805 19:31:34.381749 10603 solver.cpp:244]     Train net output #0: loss = 0.69747 (* 1 = 0.69747 loss)
I0805 19:31:34.381757 10603 sgd_solver.cpp:106] Iteration 43300, lr = 4.21424e-06
I0805 19:31:37.638715 10603 solver.cpp:228] Iteration 43400, loss = 0.689781
I0805 19:31:37.638756 10603 solver.cpp:244]     Train net output #0: loss = 0.689781 (* 1 = 0.689781 loss)
I0805 19:31:37.638761 10603 sgd_solver.cpp:106] Iteration 43400, lr = 4.20926e-06
I0805 19:31:40.849792 10603 solver.cpp:337] Iteration 43500, Testing net (#0)
I0805 19:31:44.390622 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 19:31:44.390682 10603 solver.cpp:404]     Test net output #1: loss = 0.693265 (* 1 = 0.693265 loss)
I0805 19:31:44.404389 10603 solver.cpp:228] Iteration 43500, loss = 0.69198
I0805 19:31:44.404454 10603 solver.cpp:244]     Train net output #0: loss = 0.69198 (* 1 = 0.69198 loss)
I0805 19:31:44.404472 10603 sgd_solver.cpp:106] Iteration 43500, lr = 4.20429e-06
I0805 19:31:47.643939 10603 solver.cpp:228] Iteration 43600, loss = 0.688211
I0805 19:31:47.643985 10603 solver.cpp:244]     Train net output #0: loss = 0.688211 (* 1 = 0.688211 loss)
I0805 19:31:47.643991 10603 sgd_solver.cpp:106] Iteration 43600, lr = 4.19933e-06
I0805 19:31:50.879350 10603 solver.cpp:228] Iteration 43700, loss = 0.688232
I0805 19:31:50.879390 10603 solver.cpp:244]     Train net output #0: loss = 0.688232 (* 1 = 0.688232 loss)
I0805 19:31:50.879397 10603 sgd_solver.cpp:106] Iteration 43700, lr = 4.19438e-06
I0805 19:31:54.133069 10603 solver.cpp:228] Iteration 43800, loss = 0.694172
I0805 19:31:54.133116 10603 solver.cpp:244]     Train net output #0: loss = 0.694172 (* 1 = 0.694172 loss)
I0805 19:31:54.133122 10603 sgd_solver.cpp:106] Iteration 43800, lr = 4.18945e-06
I0805 19:31:57.397138 10603 solver.cpp:228] Iteration 43900, loss = 0.685666
I0805 19:31:57.397181 10603 solver.cpp:244]     Train net output #0: loss = 0.685666 (* 1 = 0.685666 loss)
I0805 19:31:57.397187 10603 sgd_solver.cpp:106] Iteration 43900, lr = 4.18453e-06
I0805 19:32:00.622222 10603 solver.cpp:337] Iteration 44000, Testing net (#0)
I0805 19:32:04.147339 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:32:04.147389 10603 solver.cpp:404]     Test net output #1: loss = 0.693492 (* 1 = 0.693492 loss)
I0805 19:32:04.157521 10603 solver.cpp:228] Iteration 44000, loss = 0.697157
I0805 19:32:04.157564 10603 solver.cpp:244]     Train net output #0: loss = 0.697157 (* 1 = 0.697157 loss)
I0805 19:32:04.157572 10603 sgd_solver.cpp:106] Iteration 44000, lr = 4.17963e-06
I0805 19:32:07.374524 10603 solver.cpp:228] Iteration 44100, loss = 0.695756
I0805 19:32:07.374577 10603 solver.cpp:244]     Train net output #0: loss = 0.695756 (* 1 = 0.695756 loss)
I0805 19:32:07.374583 10603 sgd_solver.cpp:106] Iteration 44100, lr = 4.17474e-06
I0805 19:32:10.609818 10603 solver.cpp:228] Iteration 44200, loss = 0.697185
I0805 19:32:10.609859 10603 solver.cpp:244]     Train net output #0: loss = 0.697185 (* 1 = 0.697185 loss)
I0805 19:32:10.609865 10603 sgd_solver.cpp:106] Iteration 44200, lr = 4.16986e-06
I0805 19:32:13.855170 10603 solver.cpp:228] Iteration 44300, loss = 0.689857
I0805 19:32:13.855217 10603 solver.cpp:244]     Train net output #0: loss = 0.689857 (* 1 = 0.689857 loss)
I0805 19:32:13.855224 10603 sgd_solver.cpp:106] Iteration 44300, lr = 4.16499e-06
I0805 19:32:17.096006 10603 solver.cpp:228] Iteration 44400, loss = 0.689664
I0805 19:32:17.096048 10603 solver.cpp:244]     Train net output #0: loss = 0.689664 (* 1 = 0.689664 loss)
I0805 19:32:17.096055 10603 sgd_solver.cpp:106] Iteration 44400, lr = 4.16014e-06
I0805 19:32:20.311729 10603 solver.cpp:337] Iteration 44500, Testing net (#0)
I0805 19:32:23.919133 10603 solver.cpp:404]     Test net output #0: accuracy = 0.292675
I0805 19:32:23.919208 10603 solver.cpp:404]     Test net output #1: loss = 0.693162 (* 1 = 0.693162 loss)
I0805 19:32:23.931785 10603 solver.cpp:228] Iteration 44500, loss = 0.691773
I0805 19:32:23.931814 10603 solver.cpp:244]     Train net output #0: loss = 0.691773 (* 1 = 0.691773 loss)
I0805 19:32:23.931833 10603 sgd_solver.cpp:106] Iteration 44500, lr = 4.1553e-06
I0805 19:32:27.116487 10603 solver.cpp:228] Iteration 44600, loss = 0.687552
I0805 19:32:27.116531 10603 solver.cpp:244]     Train net output #0: loss = 0.687552 (* 1 = 0.687552 loss)
I0805 19:32:27.116538 10603 sgd_solver.cpp:106] Iteration 44600, lr = 4.15048e-06
I0805 19:32:30.347102 10603 solver.cpp:228] Iteration 44700, loss = 0.704588
I0805 19:32:30.347143 10603 solver.cpp:244]     Train net output #0: loss = 0.704588 (* 1 = 0.704588 loss)
I0805 19:32:30.347149 10603 sgd_solver.cpp:106] Iteration 44700, lr = 4.14567e-06
I0805 19:32:33.591850 10603 solver.cpp:228] Iteration 44800, loss = 0.690674
I0805 19:32:33.591895 10603 solver.cpp:244]     Train net output #0: loss = 0.690674 (* 1 = 0.690674 loss)
I0805 19:32:33.591902 10603 sgd_solver.cpp:106] Iteration 44800, lr = 4.14087e-06
I0805 19:32:35.283859 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:32:36.841598 10603 solver.cpp:228] Iteration 44900, loss = 0.696894
I0805 19:32:36.841642 10603 solver.cpp:244]     Train net output #0: loss = 0.696894 (* 1 = 0.696894 loss)
I0805 19:32:36.841648 10603 sgd_solver.cpp:106] Iteration 44900, lr = 4.13608e-06
I0805 19:32:40.054252 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_45000.caffemodel
I0805 19:32:40.433320 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_45000.solverstate
I0805 19:32:40.566486 10603 solver.cpp:337] Iteration 45000, Testing net (#0)
I0805 19:32:44.034991 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 19:32:44.035068 10603 solver.cpp:404]     Test net output #1: loss = 0.693536 (* 1 = 0.693536 loss)
I0805 19:32:44.045639 10603 solver.cpp:228] Iteration 45000, loss = 0.692132
I0805 19:32:44.045691 10603 solver.cpp:244]     Train net output #0: loss = 0.692132 (* 1 = 0.692132 loss)
I0805 19:32:44.045711 10603 sgd_solver.cpp:106] Iteration 45000, lr = 4.13131e-06
I0805 19:32:47.257401 10603 solver.cpp:228] Iteration 45100, loss = 0.693213
I0805 19:32:47.257447 10603 solver.cpp:244]     Train net output #0: loss = 0.693213 (* 1 = 0.693213 loss)
I0805 19:32:47.257454 10603 sgd_solver.cpp:106] Iteration 45100, lr = 4.12655e-06
I0805 19:32:50.510524 10603 solver.cpp:228] Iteration 45200, loss = 0.694106
I0805 19:32:50.510567 10603 solver.cpp:244]     Train net output #0: loss = 0.694106 (* 1 = 0.694106 loss)
I0805 19:32:50.510574 10603 sgd_solver.cpp:106] Iteration 45200, lr = 4.1218e-06
I0805 19:32:53.769116 10603 solver.cpp:228] Iteration 45300, loss = 0.686332
I0805 19:32:53.769165 10603 solver.cpp:244]     Train net output #0: loss = 0.686332 (* 1 = 0.686332 loss)
I0805 19:32:53.769171 10603 sgd_solver.cpp:106] Iteration 45300, lr = 4.11706e-06
I0805 19:32:57.025439 10603 solver.cpp:228] Iteration 45400, loss = 0.695142
I0805 19:32:57.025485 10603 solver.cpp:244]     Train net output #0: loss = 0.695142 (* 1 = 0.695142 loss)
I0805 19:32:57.025492 10603 sgd_solver.cpp:106] Iteration 45400, lr = 4.11234e-06
I0805 19:33:00.241061 10603 solver.cpp:337] Iteration 45500, Testing net (#0)
I0805 19:33:03.746302 10603 solver.cpp:404]     Test net output #0: accuracy = 0.792383
I0805 19:33:03.746387 10603 solver.cpp:404]     Test net output #1: loss = 0.693106 (* 1 = 0.693106 loss)
I0805 19:33:03.761013 10603 solver.cpp:228] Iteration 45500, loss = 0.702851
I0805 19:33:03.761049 10603 solver.cpp:244]     Train net output #0: loss = 0.702851 (* 1 = 0.702851 loss)
I0805 19:33:03.761059 10603 sgd_solver.cpp:106] Iteration 45500, lr = 4.10763e-06
I0805 19:33:06.977263 10603 solver.cpp:228] Iteration 45600, loss = 0.69998
I0805 19:33:06.977324 10603 solver.cpp:244]     Train net output #0: loss = 0.69998 (* 1 = 0.69998 loss)
I0805 19:33:06.977336 10603 sgd_solver.cpp:106] Iteration 45600, lr = 4.10293e-06
I0805 19:33:10.216063 10603 solver.cpp:228] Iteration 45700, loss = 0.706058
I0805 19:33:10.216111 10603 solver.cpp:244]     Train net output #0: loss = 0.706058 (* 1 = 0.706058 loss)
I0805 19:33:10.216120 10603 sgd_solver.cpp:106] Iteration 45700, lr = 4.09825e-06
I0805 19:33:13.457731 10603 solver.cpp:228] Iteration 45800, loss = 0.690787
I0805 19:33:13.457784 10603 solver.cpp:244]     Train net output #0: loss = 0.690787 (* 1 = 0.690787 loss)
I0805 19:33:13.457795 10603 sgd_solver.cpp:106] Iteration 45800, lr = 4.09358e-06
I0805 19:33:16.709166 10603 solver.cpp:228] Iteration 45900, loss = 0.704475
I0805 19:33:16.709210 10603 solver.cpp:244]     Train net output #0: loss = 0.704475 (* 1 = 0.704475 loss)
I0805 19:33:16.709216 10603 sgd_solver.cpp:106] Iteration 45900, lr = 4.08892e-06
I0805 19:33:19.919069 10603 solver.cpp:337] Iteration 46000, Testing net (#0)
I0805 19:33:23.445271 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 19:33:23.445310 10603 solver.cpp:404]     Test net output #1: loss = 0.693306 (* 1 = 0.693306 loss)
I0805 19:33:23.458827 10603 solver.cpp:228] Iteration 46000, loss = 0.678076
I0805 19:33:23.458891 10603 solver.cpp:244]     Train net output #0: loss = 0.678076 (* 1 = 0.678076 loss)
I0805 19:33:23.458909 10603 sgd_solver.cpp:106] Iteration 46000, lr = 4.08427e-06
I0805 19:33:26.689671 10603 solver.cpp:228] Iteration 46100, loss = 0.68723
I0805 19:33:26.689738 10603 solver.cpp:244]     Train net output #0: loss = 0.68723 (* 1 = 0.68723 loss)
I0805 19:33:26.689745 10603 sgd_solver.cpp:106] Iteration 46100, lr = 4.07964e-06
I0805 19:33:29.929630 10603 solver.cpp:228] Iteration 46200, loss = 0.694054
I0805 19:33:29.929673 10603 solver.cpp:244]     Train net output #0: loss = 0.694054 (* 1 = 0.694054 loss)
I0805 19:33:29.929680 10603 sgd_solver.cpp:106] Iteration 46200, lr = 4.07501e-06
I0805 19:33:33.179523 10603 solver.cpp:228] Iteration 46300, loss = 0.677761
I0805 19:33:33.179568 10603 solver.cpp:244]     Train net output #0: loss = 0.677761 (* 1 = 0.677761 loss)
I0805 19:33:33.179574 10603 sgd_solver.cpp:106] Iteration 46300, lr = 4.0704e-06
I0805 19:33:36.443570 10603 solver.cpp:228] Iteration 46400, loss = 0.683979
I0805 19:33:36.443616 10603 solver.cpp:244]     Train net output #0: loss = 0.683979 (* 1 = 0.683979 loss)
I0805 19:33:36.443624 10603 sgd_solver.cpp:106] Iteration 46400, lr = 4.0658e-06
I0805 19:33:39.670408 10603 solver.cpp:337] Iteration 46500, Testing net (#0)
I0805 19:33:43.328285 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208139
I0805 19:33:43.328322 10603 solver.cpp:404]     Test net output #1: loss = 0.693941 (* 1 = 0.693941 loss)
I0805 19:33:43.340898 10603 solver.cpp:228] Iteration 46500, loss = 0.686259
I0805 19:33:43.340916 10603 solver.cpp:244]     Train net output #0: loss = 0.686259 (* 1 = 0.686259 loss)
I0805 19:33:43.340925 10603 sgd_solver.cpp:106] Iteration 46500, lr = 4.06122e-06
I0805 19:33:46.535997 10603 solver.cpp:228] Iteration 46600, loss = 0.692745
I0805 19:33:46.536044 10603 solver.cpp:244]     Train net output #0: loss = 0.692745 (* 1 = 0.692745 loss)
I0805 19:33:46.536051 10603 sgd_solver.cpp:106] Iteration 46600, lr = 4.05664e-06
I0805 19:33:49.753763 10603 solver.cpp:228] Iteration 46700, loss = 0.699237
I0805 19:33:49.753805 10603 solver.cpp:244]     Train net output #0: loss = 0.699237 (* 1 = 0.699237 loss)
I0805 19:33:49.753813 10603 sgd_solver.cpp:106] Iteration 46700, lr = 4.05208e-06
I0805 19:33:52.994809 10603 solver.cpp:228] Iteration 46800, loss = 0.69212
I0805 19:33:52.994853 10603 solver.cpp:244]     Train net output #0: loss = 0.69212 (* 1 = 0.69212 loss)
I0805 19:33:52.994863 10603 sgd_solver.cpp:106] Iteration 46800, lr = 4.04753e-06
I0805 19:33:56.240094 10603 solver.cpp:228] Iteration 46900, loss = 0.689837
I0805 19:33:56.240131 10603 solver.cpp:244]     Train net output #0: loss = 0.689837 (* 1 = 0.689837 loss)
I0805 19:33:56.240137 10603 sgd_solver.cpp:106] Iteration 46900, lr = 4.04299e-06
I0805 19:33:59.454021 10603 solver.cpp:337] Iteration 47000, Testing net (#0)
I0805 19:34:02.952307 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:34:02.952359 10603 solver.cpp:404]     Test net output #1: loss = 0.69346 (* 1 = 0.69346 loss)
I0805 19:34:02.965606 10603 solver.cpp:228] Iteration 47000, loss = 0.690709
I0805 19:34:02.965629 10603 solver.cpp:244]     Train net output #0: loss = 0.690709 (* 1 = 0.690709 loss)
I0805 19:34:02.965636 10603 sgd_solver.cpp:106] Iteration 47000, lr = 4.03847e-06
I0805 19:34:06.199955 10603 solver.cpp:228] Iteration 47100, loss = 0.685494
I0805 19:34:06.200011 10603 solver.cpp:244]     Train net output #0: loss = 0.685494 (* 1 = 0.685494 loss)
I0805 19:34:06.200017 10603 sgd_solver.cpp:106] Iteration 47100, lr = 4.03395e-06
I0805 19:34:09.414065 10603 solver.cpp:228] Iteration 47200, loss = 0.688614
I0805 19:34:09.414108 10603 solver.cpp:244]     Train net output #0: loss = 0.688614 (* 1 = 0.688614 loss)
I0805 19:34:09.414114 10603 sgd_solver.cpp:106] Iteration 47200, lr = 4.02945e-06
I0805 19:34:12.639302 10603 solver.cpp:228] Iteration 47300, loss = 0.689382
I0805 19:34:12.639353 10603 solver.cpp:244]     Train net output #0: loss = 0.689382 (* 1 = 0.689382 loss)
I0805 19:34:12.639361 10603 sgd_solver.cpp:106] Iteration 47300, lr = 4.02496e-06
I0805 19:34:15.895006 10603 solver.cpp:228] Iteration 47400, loss = 0.704233
I0805 19:34:15.895045 10603 solver.cpp:244]     Train net output #0: loss = 0.704233 (* 1 = 0.704233 loss)
I0805 19:34:15.895052 10603 sgd_solver.cpp:106] Iteration 47400, lr = 4.02048e-06
I0805 19:34:19.103978 10603 solver.cpp:337] Iteration 47500, Testing net (#0)
I0805 19:34:22.310755 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:34:22.671001 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207442
I0805 19:34:22.671033 10603 solver.cpp:404]     Test net output #1: loss = 0.693242 (* 1 = 0.693242 loss)
I0805 19:34:22.683923 10603 solver.cpp:228] Iteration 47500, loss = 0.704487
I0805 19:34:22.683955 10603 solver.cpp:244]     Train net output #0: loss = 0.704487 (* 1 = 0.704487 loss)
I0805 19:34:22.683964 10603 sgd_solver.cpp:106] Iteration 47500, lr = 4.01601e-06
I0805 19:34:25.886391 10603 solver.cpp:228] Iteration 47600, loss = 0.696627
I0805 19:34:25.886436 10603 solver.cpp:244]     Train net output #0: loss = 0.696627 (* 1 = 0.696627 loss)
I0805 19:34:25.886443 10603 sgd_solver.cpp:106] Iteration 47600, lr = 4.01155e-06
I0805 19:34:29.134063 10603 solver.cpp:228] Iteration 47700, loss = 0.69089
I0805 19:34:29.134104 10603 solver.cpp:244]     Train net output #0: loss = 0.69089 (* 1 = 0.69089 loss)
I0805 19:34:29.134109 10603 sgd_solver.cpp:106] Iteration 47700, lr = 4.00711e-06
I0805 19:34:32.391798 10603 solver.cpp:228] Iteration 47800, loss = 0.686534
I0805 19:34:32.391840 10603 solver.cpp:244]     Train net output #0: loss = 0.686534 (* 1 = 0.686534 loss)
I0805 19:34:32.391847 10603 sgd_solver.cpp:106] Iteration 47800, lr = 4.00267e-06
I0805 19:34:35.650683 10603 solver.cpp:228] Iteration 47900, loss = 0.697247
I0805 19:34:35.650730 10603 solver.cpp:244]     Train net output #0: loss = 0.697247 (* 1 = 0.697247 loss)
I0805 19:34:35.650739 10603 sgd_solver.cpp:106] Iteration 47900, lr = 3.99825e-06
I0805 19:34:38.877437 10603 solver.cpp:337] Iteration 48000, Testing net (#0)
I0805 19:34:42.386281 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:34:42.386332 10603 solver.cpp:404]     Test net output #1: loss = 0.693588 (* 1 = 0.693588 loss)
I0805 19:34:42.399186 10603 solver.cpp:228] Iteration 48000, loss = 0.700038
I0805 19:34:42.399226 10603 solver.cpp:244]     Train net output #0: loss = 0.700038 (* 1 = 0.700038 loss)
I0805 19:34:42.399235 10603 sgd_solver.cpp:106] Iteration 48000, lr = 3.99384e-06
I0805 19:34:45.598790 10603 solver.cpp:228] Iteration 48100, loss = 0.688722
I0805 19:34:45.598850 10603 solver.cpp:244]     Train net output #0: loss = 0.688722 (* 1 = 0.688722 loss)
I0805 19:34:45.598856 10603 sgd_solver.cpp:106] Iteration 48100, lr = 3.98944e-06
I0805 19:34:48.834674 10603 solver.cpp:228] Iteration 48200, loss = 0.690442
I0805 19:34:48.834715 10603 solver.cpp:244]     Train net output #0: loss = 0.690442 (* 1 = 0.690442 loss)
I0805 19:34:48.834722 10603 sgd_solver.cpp:106] Iteration 48200, lr = 3.98505e-06
I0805 19:34:52.077839 10603 solver.cpp:228] Iteration 48300, loss = 0.686878
I0805 19:34:52.077890 10603 solver.cpp:244]     Train net output #0: loss = 0.686878 (* 1 = 0.686878 loss)
I0805 19:34:52.077896 10603 sgd_solver.cpp:106] Iteration 48300, lr = 3.98068e-06
I0805 19:34:55.322026 10603 solver.cpp:228] Iteration 48400, loss = 0.696576
I0805 19:34:55.322062 10603 solver.cpp:244]     Train net output #0: loss = 0.696576 (* 1 = 0.696576 loss)
I0805 19:34:55.322068 10603 sgd_solver.cpp:106] Iteration 48400, lr = 3.97631e-06
I0805 19:34:58.532107 10603 solver.cpp:337] Iteration 48500, Testing net (#0)
I0805 19:35:02.120199 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:35:02.120242 10603 solver.cpp:404]     Test net output #1: loss = 0.693948 (* 1 = 0.693948 loss)
I0805 19:35:02.133812 10603 solver.cpp:228] Iteration 48500, loss = 0.701455
I0805 19:35:02.133883 10603 solver.cpp:244]     Train net output #0: loss = 0.701455 (* 1 = 0.701455 loss)
I0805 19:35:02.133900 10603 sgd_solver.cpp:106] Iteration 48500, lr = 3.97196e-06
I0805 19:35:05.375350 10603 solver.cpp:228] Iteration 48600, loss = 0.687212
I0805 19:35:05.375392 10603 solver.cpp:244]     Train net output #0: loss = 0.687212 (* 1 = 0.687212 loss)
I0805 19:35:05.375399 10603 sgd_solver.cpp:106] Iteration 48600, lr = 3.96761e-06
I0805 19:35:08.639528 10603 solver.cpp:228] Iteration 48700, loss = 0.684629
I0805 19:35:08.639574 10603 solver.cpp:244]     Train net output #0: loss = 0.684629 (* 1 = 0.684629 loss)
I0805 19:35:08.639580 10603 sgd_solver.cpp:106] Iteration 48700, lr = 3.96328e-06
I0805 19:35:11.899235 10603 solver.cpp:228] Iteration 48800, loss = 0.693139
I0805 19:35:11.899281 10603 solver.cpp:244]     Train net output #0: loss = 0.693139 (* 1 = 0.693139 loss)
I0805 19:35:11.899287 10603 sgd_solver.cpp:106] Iteration 48800, lr = 3.95896e-06
I0805 19:35:15.164750 10603 solver.cpp:228] Iteration 48900, loss = 0.682563
I0805 19:35:15.164819 10603 solver.cpp:244]     Train net output #0: loss = 0.682563 (* 1 = 0.682563 loss)
I0805 19:35:15.164829 10603 sgd_solver.cpp:106] Iteration 48900, lr = 3.95465e-06
I0805 19:35:18.395624 10603 solver.cpp:337] Iteration 49000, Testing net (#0)
I0805 19:35:21.945340 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:35:21.945379 10603 solver.cpp:404]     Test net output #1: loss = 0.693381 (* 1 = 0.693381 loss)
I0805 19:35:21.955490 10603 solver.cpp:228] Iteration 49000, loss = 0.694417
I0805 19:35:21.955518 10603 solver.cpp:244]     Train net output #0: loss = 0.694417 (* 1 = 0.694417 loss)
I0805 19:35:21.955525 10603 sgd_solver.cpp:106] Iteration 49000, lr = 3.95035e-06
I0805 19:35:25.166465 10603 solver.cpp:228] Iteration 49100, loss = 0.687061
I0805 19:35:25.166510 10603 solver.cpp:244]     Train net output #0: loss = 0.687061 (* 1 = 0.687061 loss)
I0805 19:35:25.166517 10603 sgd_solver.cpp:106] Iteration 49100, lr = 3.94606e-06
I0805 19:35:28.382024 10603 solver.cpp:228] Iteration 49200, loss = 0.704094
I0805 19:35:28.382062 10603 solver.cpp:244]     Train net output #0: loss = 0.704094 (* 1 = 0.704094 loss)
I0805 19:35:28.382068 10603 sgd_solver.cpp:106] Iteration 49200, lr = 3.94178e-06
I0805 19:35:31.619662 10603 solver.cpp:228] Iteration 49300, loss = 0.687065
I0805 19:35:31.619706 10603 solver.cpp:244]     Train net output #0: loss = 0.687065 (* 1 = 0.687065 loss)
I0805 19:35:31.619712 10603 sgd_solver.cpp:106] Iteration 49300, lr = 3.93752e-06
I0805 19:35:34.859491 10603 solver.cpp:228] Iteration 49400, loss = 0.694963
I0805 19:35:34.859535 10603 solver.cpp:244]     Train net output #0: loss = 0.694963 (* 1 = 0.694963 loss)
I0805 19:35:34.859542 10603 sgd_solver.cpp:106] Iteration 49400, lr = 3.93326e-06
I0805 19:35:38.068797 10603 solver.cpp:337] Iteration 49500, Testing net (#0)
I0805 19:35:41.594486 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:35:41.594527 10603 solver.cpp:404]     Test net output #1: loss = 0.693633 (* 1 = 0.693633 loss)
I0805 19:35:41.604655 10603 solver.cpp:228] Iteration 49500, loss = 0.71023
I0805 19:35:41.604684 10603 solver.cpp:244]     Train net output #0: loss = 0.71023 (* 1 = 0.71023 loss)
I0805 19:35:41.604692 10603 sgd_solver.cpp:106] Iteration 49500, lr = 3.92902e-06
I0805 19:35:44.826478 10603 solver.cpp:228] Iteration 49600, loss = 0.69702
I0805 19:35:44.826522 10603 solver.cpp:244]     Train net output #0: loss = 0.69702 (* 1 = 0.69702 loss)
I0805 19:35:44.826529 10603 sgd_solver.cpp:106] Iteration 49600, lr = 3.92478e-06
I0805 19:35:48.069108 10603 solver.cpp:228] Iteration 49700, loss = 0.687928
I0805 19:35:48.069151 10603 solver.cpp:244]     Train net output #0: loss = 0.687928 (* 1 = 0.687928 loss)
I0805 19:35:48.069157 10603 sgd_solver.cpp:106] Iteration 49700, lr = 3.92056e-06
I0805 19:35:51.324009 10603 solver.cpp:228] Iteration 49800, loss = 0.699536
I0805 19:35:51.324056 10603 solver.cpp:244]     Train net output #0: loss = 0.699536 (* 1 = 0.699536 loss)
I0805 19:35:51.324064 10603 sgd_solver.cpp:106] Iteration 49800, lr = 3.91634e-06
I0805 19:35:54.567900 10603 solver.cpp:228] Iteration 49900, loss = 0.692371
I0805 19:35:54.567945 10603 solver.cpp:244]     Train net output #0: loss = 0.692371 (* 1 = 0.692371 loss)
I0805 19:35:54.567951 10603 sgd_solver.cpp:106] Iteration 49900, lr = 3.91214e-06
I0805 19:35:57.784714 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_50000.caffemodel
I0805 19:35:58.172775 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_50000.solverstate
I0805 19:35:58.305502 10603 solver.cpp:337] Iteration 50000, Testing net (#0)
I0805 19:36:01.836988 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:36:01.837049 10603 solver.cpp:404]     Test net output #1: loss = 0.693292 (* 1 = 0.693292 loss)
I0805 19:36:01.847441 10603 solver.cpp:228] Iteration 50000, loss = 0.695158
I0805 19:36:01.847477 10603 solver.cpp:244]     Train net output #0: loss = 0.695158 (* 1 = 0.695158 loss)
I0805 19:36:01.847489 10603 sgd_solver.cpp:106] Iteration 50000, lr = 3.90795e-06
I0805 19:36:05.035754 10603 solver.cpp:228] Iteration 50100, loss = 0.691821
I0805 19:36:05.035805 10603 solver.cpp:244]     Train net output #0: loss = 0.691821 (* 1 = 0.691821 loss)
I0805 19:36:05.035812 10603 sgd_solver.cpp:106] Iteration 50100, lr = 3.90377e-06
I0805 19:36:08.278817 10603 solver.cpp:228] Iteration 50200, loss = 0.692421
I0805 19:36:08.278858 10603 solver.cpp:244]     Train net output #0: loss = 0.692421 (* 1 = 0.692421 loss)
I0805 19:36:08.278867 10603 sgd_solver.cpp:106] Iteration 50200, lr = 3.8996e-06
I0805 19:36:11.529810 10603 solver.cpp:228] Iteration 50300, loss = 0.698314
I0805 19:36:11.529872 10603 solver.cpp:244]     Train net output #0: loss = 0.698314 (* 1 = 0.698314 loss)
I0805 19:36:11.529882 10603 sgd_solver.cpp:106] Iteration 50300, lr = 3.89544e-06
I0805 19:36:14.780895 10603 solver.cpp:228] Iteration 50400, loss = 0.689601
I0805 19:36:14.780936 10603 solver.cpp:244]     Train net output #0: loss = 0.689601 (* 1 = 0.689601 loss)
I0805 19:36:14.780943 10603 sgd_solver.cpp:106] Iteration 50400, lr = 3.89128e-06
I0805 19:36:18.008247 10603 solver.cpp:337] Iteration 50500, Testing net (#0)
I0805 19:36:21.538851 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207849
I0805 19:36:21.538905 10603 solver.cpp:404]     Test net output #1: loss = 0.693868 (* 1 = 0.693868 loss)
I0805 19:36:21.549074 10603 solver.cpp:228] Iteration 50500, loss = 0.691712
I0805 19:36:21.549134 10603 solver.cpp:244]     Train net output #0: loss = 0.691712 (* 1 = 0.691712 loss)
I0805 19:36:21.549144 10603 sgd_solver.cpp:106] Iteration 50500, lr = 3.88714e-06
I0805 19:36:22.484297 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:36:24.766265 10603 solver.cpp:228] Iteration 50600, loss = 0.70299
I0805 19:36:24.766319 10603 solver.cpp:244]     Train net output #0: loss = 0.70299 (* 1 = 0.70299 loss)
I0805 19:36:24.766325 10603 sgd_solver.cpp:106] Iteration 50600, lr = 3.88301e-06
I0805 19:36:28.003314 10603 solver.cpp:228] Iteration 50700, loss = 0.685042
I0805 19:36:28.003353 10603 solver.cpp:244]     Train net output #0: loss = 0.685042 (* 1 = 0.685042 loss)
I0805 19:36:28.003360 10603 sgd_solver.cpp:106] Iteration 50700, lr = 3.87889e-06
I0805 19:36:31.248657 10603 solver.cpp:228] Iteration 50800, loss = 0.706904
I0805 19:36:31.248703 10603 solver.cpp:244]     Train net output #0: loss = 0.706904 (* 1 = 0.706904 loss)
I0805 19:36:31.248708 10603 sgd_solver.cpp:106] Iteration 50800, lr = 3.87478e-06
I0805 19:36:34.494029 10603 solver.cpp:228] Iteration 50900, loss = 0.695857
I0805 19:36:34.494068 10603 solver.cpp:244]     Train net output #0: loss = 0.695857 (* 1 = 0.695857 loss)
I0805 19:36:34.494076 10603 sgd_solver.cpp:106] Iteration 50900, lr = 3.87068e-06
I0805 19:36:37.705788 10603 solver.cpp:337] Iteration 51000, Testing net (#0)
I0805 19:36:41.235757 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:36:41.235811 10603 solver.cpp:404]     Test net output #1: loss = 0.693392 (* 1 = 0.693392 loss)
I0805 19:36:41.249511 10603 solver.cpp:228] Iteration 51000, loss = 0.700474
I0805 19:36:41.249573 10603 solver.cpp:244]     Train net output #0: loss = 0.700474 (* 1 = 0.700474 loss)
I0805 19:36:41.249588 10603 sgd_solver.cpp:106] Iteration 51000, lr = 3.8666e-06
I0805 19:36:44.485769 10603 solver.cpp:228] Iteration 51100, loss = 0.693628
I0805 19:36:44.485815 10603 solver.cpp:244]     Train net output #0: loss = 0.693628 (* 1 = 0.693628 loss)
I0805 19:36:44.485821 10603 sgd_solver.cpp:106] Iteration 51100, lr = 3.86252e-06
I0805 19:36:47.721572 10603 solver.cpp:228] Iteration 51200, loss = 0.710784
I0805 19:36:47.721609 10603 solver.cpp:244]     Train net output #0: loss = 0.710784 (* 1 = 0.710784 loss)
I0805 19:36:47.721616 10603 sgd_solver.cpp:106] Iteration 51200, lr = 3.85845e-06
I0805 19:36:50.977818 10603 solver.cpp:228] Iteration 51300, loss = 0.706633
I0805 19:36:50.977872 10603 solver.cpp:244]     Train net output #0: loss = 0.706633 (* 1 = 0.706633 loss)
I0805 19:36:50.977880 10603 sgd_solver.cpp:106] Iteration 51300, lr = 3.85439e-06
I0805 19:36:54.240228 10603 solver.cpp:228] Iteration 51400, loss = 0.700171
I0805 19:36:54.240278 10603 solver.cpp:244]     Train net output #0: loss = 0.700171 (* 1 = 0.700171 loss)
I0805 19:36:54.240285 10603 sgd_solver.cpp:106] Iteration 51400, lr = 3.85034e-06
I0805 19:36:57.465993 10603 solver.cpp:337] Iteration 51500, Testing net (#0)
I0805 19:37:00.985826 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:37:00.985878 10603 solver.cpp:404]     Test net output #1: loss = 0.693646 (* 1 = 0.693646 loss)
I0805 19:37:00.999004 10603 solver.cpp:228] Iteration 51500, loss = 0.703025
I0805 19:37:00.999033 10603 solver.cpp:244]     Train net output #0: loss = 0.703025 (* 1 = 0.703025 loss)
I0805 19:37:00.999052 10603 sgd_solver.cpp:106] Iteration 51500, lr = 3.8463e-06
I0805 19:37:04.214558 10603 solver.cpp:228] Iteration 51600, loss = 0.689133
I0805 19:37:04.214606 10603 solver.cpp:244]     Train net output #0: loss = 0.689133 (* 1 = 0.689133 loss)
I0805 19:37:04.214612 10603 sgd_solver.cpp:106] Iteration 51600, lr = 3.84227e-06
I0805 19:37:07.456301 10603 solver.cpp:228] Iteration 51700, loss = 0.695819
I0805 19:37:07.456342 10603 solver.cpp:244]     Train net output #0: loss = 0.695819 (* 1 = 0.695819 loss)
I0805 19:37:07.456347 10603 sgd_solver.cpp:106] Iteration 51700, lr = 3.83825e-06
I0805 19:37:10.701678 10603 solver.cpp:228] Iteration 51800, loss = 0.696133
I0805 19:37:10.701725 10603 solver.cpp:244]     Train net output #0: loss = 0.696133 (* 1 = 0.696133 loss)
I0805 19:37:10.701731 10603 sgd_solver.cpp:106] Iteration 51800, lr = 3.83424e-06
I0805 19:37:13.947355 10603 solver.cpp:228] Iteration 51900, loss = 0.699617
I0805 19:37:13.947398 10603 solver.cpp:244]     Train net output #0: loss = 0.699617 (* 1 = 0.699617 loss)
I0805 19:37:13.947405 10603 sgd_solver.cpp:106] Iteration 51900, lr = 3.83024e-06
I0805 19:37:17.157588 10603 solver.cpp:337] Iteration 52000, Testing net (#0)
I0805 19:37:20.674021 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:37:20.674072 10603 solver.cpp:404]     Test net output #1: loss = 0.69361 (* 1 = 0.69361 loss)
I0805 19:37:20.687255 10603 solver.cpp:228] Iteration 52000, loss = 0.685096
I0805 19:37:20.687286 10603 solver.cpp:244]     Train net output #0: loss = 0.685096 (* 1 = 0.685096 loss)
I0805 19:37:20.687294 10603 sgd_solver.cpp:106] Iteration 52000, lr = 3.82625e-06
I0805 19:37:23.909857 10603 solver.cpp:228] Iteration 52100, loss = 0.693544
I0805 19:37:23.909901 10603 solver.cpp:244]     Train net output #0: loss = 0.693544 (* 1 = 0.693544 loss)
I0805 19:37:23.909907 10603 sgd_solver.cpp:106] Iteration 52100, lr = 3.82227e-06
I0805 19:37:27.144088 10603 solver.cpp:228] Iteration 52200, loss = 0.689923
I0805 19:37:27.144105 10603 solver.cpp:244]     Train net output #0: loss = 0.689923 (* 1 = 0.689923 loss)
I0805 19:37:27.144112 10603 sgd_solver.cpp:106] Iteration 52200, lr = 3.8183e-06
I0805 19:37:30.384876 10603 solver.cpp:228] Iteration 52300, loss = 0.691098
I0805 19:37:30.384924 10603 solver.cpp:244]     Train net output #0: loss = 0.691098 (* 1 = 0.691098 loss)
I0805 19:37:30.384930 10603 sgd_solver.cpp:106] Iteration 52300, lr = 3.81433e-06
I0805 19:37:33.624022 10603 solver.cpp:228] Iteration 52400, loss = 0.68675
I0805 19:37:33.624063 10603 solver.cpp:244]     Train net output #0: loss = 0.68675 (* 1 = 0.68675 loss)
I0805 19:37:33.624068 10603 sgd_solver.cpp:106] Iteration 52400, lr = 3.81038e-06
I0805 19:37:36.845824 10603 solver.cpp:337] Iteration 52500, Testing net (#0)
I0805 19:37:40.412822 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:37:40.412863 10603 solver.cpp:404]     Test net output #1: loss = 0.693513 (* 1 = 0.693513 loss)
I0805 19:37:40.425721 10603 solver.cpp:228] Iteration 52500, loss = 0.699963
I0805 19:37:40.425752 10603 solver.cpp:244]     Train net output #0: loss = 0.699963 (* 1 = 0.699963 loss)
I0805 19:37:40.425762 10603 sgd_solver.cpp:106] Iteration 52500, lr = 3.80644e-06
I0805 19:37:43.648564 10603 solver.cpp:228] Iteration 52600, loss = 0.683194
I0805 19:37:43.648612 10603 solver.cpp:244]     Train net output #0: loss = 0.683194 (* 1 = 0.683194 loss)
I0805 19:37:43.648618 10603 sgd_solver.cpp:106] Iteration 52600, lr = 3.80251e-06
I0805 19:37:46.882091 10603 solver.cpp:228] Iteration 52700, loss = 0.687804
I0805 19:37:46.882130 10603 solver.cpp:244]     Train net output #0: loss = 0.687804 (* 1 = 0.687804 loss)
I0805 19:37:46.882136 10603 sgd_solver.cpp:106] Iteration 52700, lr = 3.79858e-06
I0805 19:37:50.144276 10603 solver.cpp:228] Iteration 52800, loss = 0.696269
I0805 19:37:50.144318 10603 solver.cpp:244]     Train net output #0: loss = 0.696269 (* 1 = 0.696269 loss)
I0805 19:37:50.144325 10603 sgd_solver.cpp:106] Iteration 52800, lr = 3.79467e-06
I0805 19:37:53.399045 10603 solver.cpp:228] Iteration 52900, loss = 0.687448
I0805 19:37:53.399087 10603 solver.cpp:244]     Train net output #0: loss = 0.687448 (* 1 = 0.687448 loss)
I0805 19:37:53.399094 10603 sgd_solver.cpp:106] Iteration 52900, lr = 3.79076e-06
I0805 19:37:56.624558 10603 solver.cpp:337] Iteration 53000, Testing net (#0)
I0805 19:38:00.137383 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791221
I0805 19:38:00.137424 10603 solver.cpp:404]     Test net output #1: loss = 0.693021 (* 1 = 0.693021 loss)
I0805 19:38:00.150909 10603 solver.cpp:228] Iteration 53000, loss = 0.698458
I0805 19:38:00.150980 10603 solver.cpp:244]     Train net output #0: loss = 0.698458 (* 1 = 0.698458 loss)
I0805 19:38:00.150998 10603 sgd_solver.cpp:106] Iteration 53000, lr = 3.78687e-06
I0805 19:38:03.365609 10603 solver.cpp:228] Iteration 53100, loss = 0.688614
I0805 19:38:03.365656 10603 solver.cpp:244]     Train net output #0: loss = 0.688614 (* 1 = 0.688614 loss)
I0805 19:38:03.365664 10603 sgd_solver.cpp:106] Iteration 53100, lr = 3.78298e-06
I0805 19:38:06.601876 10603 solver.cpp:228] Iteration 53200, loss = 0.691724
I0805 19:38:06.601914 10603 solver.cpp:244]     Train net output #0: loss = 0.691724 (* 1 = 0.691724 loss)
I0805 19:38:06.601922 10603 sgd_solver.cpp:106] Iteration 53200, lr = 3.77911e-06
I0805 19:38:09.108325 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:38:09.852835 10603 solver.cpp:228] Iteration 53300, loss = 0.70104
I0805 19:38:09.852866 10603 solver.cpp:244]     Train net output #0: loss = 0.70104 (* 1 = 0.70104 loss)
I0805 19:38:09.852872 10603 sgd_solver.cpp:106] Iteration 53300, lr = 3.77524e-06
I0805 19:38:13.095378 10603 solver.cpp:228] Iteration 53400, loss = 0.69497
I0805 19:38:13.095420 10603 solver.cpp:244]     Train net output #0: loss = 0.69497 (* 1 = 0.69497 loss)
I0805 19:38:13.095427 10603 sgd_solver.cpp:106] Iteration 53400, lr = 3.77138e-06
I0805 19:38:16.311156 10603 solver.cpp:337] Iteration 53500, Testing net (#0)
I0805 19:38:19.843922 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20814
I0805 19:38:19.843971 10603 solver.cpp:404]     Test net output #1: loss = 0.693255 (* 1 = 0.693255 loss)
I0805 19:38:19.857054 10603 solver.cpp:228] Iteration 53500, loss = 0.69517
I0805 19:38:19.857084 10603 solver.cpp:244]     Train net output #0: loss = 0.69517 (* 1 = 0.69517 loss)
I0805 19:38:19.857103 10603 sgd_solver.cpp:106] Iteration 53500, lr = 3.76753e-06
I0805 19:38:23.103544 10603 solver.cpp:228] Iteration 53600, loss = 0.688416
I0805 19:38:23.103590 10603 solver.cpp:244]     Train net output #0: loss = 0.688416 (* 1 = 0.688416 loss)
I0805 19:38:23.103596 10603 sgd_solver.cpp:106] Iteration 53600, lr = 3.76369e-06
I0805 19:38:26.335186 10603 solver.cpp:228] Iteration 53700, loss = 0.694326
I0805 19:38:26.335237 10603 solver.cpp:244]     Train net output #0: loss = 0.694326 (* 1 = 0.694326 loss)
I0805 19:38:26.335247 10603 sgd_solver.cpp:106] Iteration 53700, lr = 3.75986e-06
I0805 19:38:29.604158 10603 solver.cpp:228] Iteration 53800, loss = 0.696126
I0805 19:38:29.604205 10603 solver.cpp:244]     Train net output #0: loss = 0.696126 (* 1 = 0.696126 loss)
I0805 19:38:29.604212 10603 sgd_solver.cpp:106] Iteration 53800, lr = 3.75604e-06
I0805 19:38:32.866716 10603 solver.cpp:228] Iteration 53900, loss = 0.694373
I0805 19:38:32.866756 10603 solver.cpp:244]     Train net output #0: loss = 0.694373 (* 1 = 0.694373 loss)
I0805 19:38:32.866762 10603 sgd_solver.cpp:106] Iteration 53900, lr = 3.75223e-06
I0805 19:38:36.097587 10603 solver.cpp:337] Iteration 54000, Testing net (#0)
I0805 19:38:39.630513 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207907
I0805 19:38:39.630599 10603 solver.cpp:404]     Test net output #1: loss = 0.693965 (* 1 = 0.693965 loss)
I0805 19:38:39.641000 10603 solver.cpp:228] Iteration 54000, loss = 0.693063
I0805 19:38:39.641046 10603 solver.cpp:244]     Train net output #0: loss = 0.693063 (* 1 = 0.693063 loss)
I0805 19:38:39.641055 10603 sgd_solver.cpp:106] Iteration 54000, lr = 3.74842e-06
I0805 19:38:42.864497 10603 solver.cpp:228] Iteration 54100, loss = 0.68872
I0805 19:38:42.864548 10603 solver.cpp:244]     Train net output #0: loss = 0.68872 (* 1 = 0.68872 loss)
I0805 19:38:42.864557 10603 sgd_solver.cpp:106] Iteration 54100, lr = 3.74463e-06
I0805 19:38:46.077241 10603 solver.cpp:228] Iteration 54200, loss = 0.697621
I0805 19:38:46.077278 10603 solver.cpp:244]     Train net output #0: loss = 0.697621 (* 1 = 0.697621 loss)
I0805 19:38:46.077285 10603 sgd_solver.cpp:106] Iteration 54200, lr = 3.74084e-06
I0805 19:38:49.316474 10603 solver.cpp:228] Iteration 54300, loss = 0.698185
I0805 19:38:49.316530 10603 solver.cpp:244]     Train net output #0: loss = 0.698185 (* 1 = 0.698185 loss)
I0805 19:38:49.316540 10603 sgd_solver.cpp:106] Iteration 54300, lr = 3.73707e-06
I0805 19:38:52.563443 10603 solver.cpp:228] Iteration 54400, loss = 0.698232
I0805 19:38:52.563485 10603 solver.cpp:244]     Train net output #0: loss = 0.698232 (* 1 = 0.698232 loss)
I0805 19:38:52.563493 10603 sgd_solver.cpp:106] Iteration 54400, lr = 3.7333e-06
I0805 19:38:55.774281 10603 solver.cpp:337] Iteration 54500, Testing net (#0)
I0805 19:38:59.311367 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791802
I0805 19:38:59.311413 10603 solver.cpp:404]     Test net output #1: loss = 0.693066 (* 1 = 0.693066 loss)
I0805 19:38:59.324893 10603 solver.cpp:228] Iteration 54500, loss = 0.694522
I0805 19:38:59.324970 10603 solver.cpp:244]     Train net output #0: loss = 0.694522 (* 1 = 0.694522 loss)
I0805 19:38:59.324987 10603 sgd_solver.cpp:106] Iteration 54500, lr = 3.72954e-06
I0805 19:39:02.547686 10603 solver.cpp:228] Iteration 54600, loss = 0.694299
I0805 19:39:02.547746 10603 solver.cpp:244]     Train net output #0: loss = 0.694299 (* 1 = 0.694299 loss)
I0805 19:39:02.547757 10603 sgd_solver.cpp:106] Iteration 54600, lr = 3.72579e-06
I0805 19:39:05.797760 10603 solver.cpp:228] Iteration 54700, loss = 0.685803
I0805 19:39:05.797791 10603 solver.cpp:244]     Train net output #0: loss = 0.685803 (* 1 = 0.685803 loss)
I0805 19:39:05.797797 10603 sgd_solver.cpp:106] Iteration 54700, lr = 3.72205e-06
I0805 19:39:09.044908 10603 solver.cpp:228] Iteration 54800, loss = 0.701298
I0805 19:39:09.044953 10603 solver.cpp:244]     Train net output #0: loss = 0.701298 (* 1 = 0.701298 loss)
I0805 19:39:09.044960 10603 sgd_solver.cpp:106] Iteration 54800, lr = 3.71832e-06
I0805 19:39:12.294461 10603 solver.cpp:228] Iteration 54900, loss = 0.687198
I0805 19:39:12.294502 10603 solver.cpp:244]     Train net output #0: loss = 0.687198 (* 1 = 0.687198 loss)
I0805 19:39:12.294512 10603 sgd_solver.cpp:106] Iteration 54900, lr = 3.71459e-06
I0805 19:39:15.513295 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_55000.caffemodel
I0805 19:39:15.882086 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_55000.solverstate
I0805 19:39:16.015446 10603 solver.cpp:337] Iteration 55000, Testing net (#0)
I0805 19:39:19.456816 10603 solver.cpp:404]     Test net output #0: accuracy = 0.794942
I0805 19:39:19.456885 10603 solver.cpp:404]     Test net output #1: loss = 0.693118 (* 1 = 0.693118 loss)
I0805 19:39:19.469826 10603 solver.cpp:228] Iteration 55000, loss = 0.699456
I0805 19:39:19.469873 10603 solver.cpp:244]     Train net output #0: loss = 0.699456 (* 1 = 0.699456 loss)
I0805 19:39:19.469882 10603 sgd_solver.cpp:106] Iteration 55000, lr = 3.71088e-06
I0805 19:39:22.667268 10603 solver.cpp:228] Iteration 55100, loss = 0.690543
I0805 19:39:22.667330 10603 solver.cpp:244]     Train net output #0: loss = 0.690543 (* 1 = 0.690543 loss)
I0805 19:39:22.667338 10603 sgd_solver.cpp:106] Iteration 55100, lr = 3.70717e-06
I0805 19:39:25.912856 10603 solver.cpp:228] Iteration 55200, loss = 0.691125
I0805 19:39:25.912930 10603 solver.cpp:244]     Train net output #0: loss = 0.691125 (* 1 = 0.691125 loss)
I0805 19:39:25.912938 10603 sgd_solver.cpp:106] Iteration 55200, lr = 3.70347e-06
I0805 19:39:29.175174 10603 solver.cpp:228] Iteration 55300, loss = 0.697892
I0805 19:39:29.175221 10603 solver.cpp:244]     Train net output #0: loss = 0.697892 (* 1 = 0.697892 loss)
I0805 19:39:29.175228 10603 sgd_solver.cpp:106] Iteration 55300, lr = 3.69978e-06
I0805 19:39:32.421644 10603 solver.cpp:228] Iteration 55400, loss = 0.693438
I0805 19:39:32.421680 10603 solver.cpp:244]     Train net output #0: loss = 0.693438 (* 1 = 0.693438 loss)
I0805 19:39:32.421686 10603 sgd_solver.cpp:106] Iteration 55400, lr = 3.6961e-06
I0805 19:39:35.647017 10603 solver.cpp:337] Iteration 55500, Testing net (#0)
I0805 19:39:39.293906 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:39:39.293946 10603 solver.cpp:404]     Test net output #1: loss = 0.69346 (* 1 = 0.69346 loss)
I0805 19:39:39.306972 10603 solver.cpp:228] Iteration 55500, loss = 0.698319
I0805 19:39:39.307042 10603 solver.cpp:244]     Train net output #0: loss = 0.698319 (* 1 = 0.698319 loss)
I0805 19:39:39.307060 10603 sgd_solver.cpp:106] Iteration 55500, lr = 3.69243e-06
I0805 19:39:42.494801 10603 solver.cpp:228] Iteration 55600, loss = 0.689984
I0805 19:39:42.494846 10603 solver.cpp:244]     Train net output #0: loss = 0.689984 (* 1 = 0.689984 loss)
I0805 19:39:42.494853 10603 sgd_solver.cpp:106] Iteration 55600, lr = 3.68877e-06
I0805 19:39:45.698894 10603 solver.cpp:228] Iteration 55700, loss = 0.688289
I0805 19:39:45.698933 10603 solver.cpp:244]     Train net output #0: loss = 0.688289 (* 1 = 0.688289 loss)
I0805 19:39:45.698940 10603 sgd_solver.cpp:106] Iteration 55700, lr = 3.68511e-06
I0805 19:39:47.582792 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:39:48.948819 10603 solver.cpp:228] Iteration 55800, loss = 0.693053
I0805 19:39:48.948861 10603 solver.cpp:244]     Train net output #0: loss = 0.693053 (* 1 = 0.693053 loss)
I0805 19:39:48.948868 10603 sgd_solver.cpp:106] Iteration 55800, lr = 3.68146e-06
I0805 19:39:52.196236 10603 solver.cpp:228] Iteration 55900, loss = 0.689943
I0805 19:39:52.196281 10603 solver.cpp:244]     Train net output #0: loss = 0.689943 (* 1 = 0.689943 loss)
I0805 19:39:52.196288 10603 sgd_solver.cpp:106] Iteration 55900, lr = 3.67783e-06
I0805 19:39:55.410117 10603 solver.cpp:337] Iteration 56000, Testing net (#0)
I0805 19:39:58.960852 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207791
I0805 19:39:58.960906 10603 solver.cpp:404]     Test net output #1: loss = 0.693665 (* 1 = 0.693665 loss)
I0805 19:39:58.970990 10603 solver.cpp:228] Iteration 56000, loss = 0.687541
I0805 19:39:58.971019 10603 solver.cpp:244]     Train net output #0: loss = 0.687541 (* 1 = 0.687541 loss)
I0805 19:39:58.971034 10603 sgd_solver.cpp:106] Iteration 56000, lr = 3.6742e-06
I0805 19:40:02.217236 10603 solver.cpp:228] Iteration 56100, loss = 0.696649
I0805 19:40:02.217280 10603 solver.cpp:244]     Train net output #0: loss = 0.696649 (* 1 = 0.696649 loss)
I0805 19:40:02.217286 10603 sgd_solver.cpp:106] Iteration 56100, lr = 3.67057e-06
I0805 19:40:05.467650 10603 solver.cpp:228] Iteration 56200, loss = 0.702391
I0805 19:40:05.467689 10603 solver.cpp:244]     Train net output #0: loss = 0.702391 (* 1 = 0.702391 loss)
I0805 19:40:05.467695 10603 sgd_solver.cpp:106] Iteration 56200, lr = 3.66696e-06
I0805 19:40:08.732270 10603 solver.cpp:228] Iteration 56300, loss = 0.702303
I0805 19:40:08.732316 10603 solver.cpp:244]     Train net output #0: loss = 0.702303 (* 1 = 0.702303 loss)
I0805 19:40:08.732321 10603 sgd_solver.cpp:106] Iteration 56300, lr = 3.66336e-06
I0805 19:40:11.995221 10603 solver.cpp:228] Iteration 56400, loss = 0.679628
I0805 19:40:11.995261 10603 solver.cpp:244]     Train net output #0: loss = 0.679628 (* 1 = 0.679628 loss)
I0805 19:40:11.995267 10603 sgd_solver.cpp:106] Iteration 56400, lr = 3.65976e-06
I0805 19:40:15.226085 10603 solver.cpp:337] Iteration 56500, Testing net (#0)
I0805 19:40:18.756350 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:40:18.756391 10603 solver.cpp:404]     Test net output #1: loss = 0.69334 (* 1 = 0.69334 loss)
I0805 19:40:18.769578 10603 solver.cpp:228] Iteration 56500, loss = 0.697512
I0805 19:40:18.769601 10603 solver.cpp:244]     Train net output #0: loss = 0.697512 (* 1 = 0.697512 loss)
I0805 19:40:18.769609 10603 sgd_solver.cpp:106] Iteration 56500, lr = 3.65617e-06
I0805 19:40:22.005761 10603 solver.cpp:228] Iteration 56600, loss = 0.698202
I0805 19:40:22.005808 10603 solver.cpp:244]     Train net output #0: loss = 0.698202 (* 1 = 0.698202 loss)
I0805 19:40:22.005815 10603 sgd_solver.cpp:106] Iteration 56600, lr = 3.65259e-06
I0805 19:40:25.242743 10603 solver.cpp:228] Iteration 56700, loss = 0.70076
I0805 19:40:25.242780 10603 solver.cpp:244]     Train net output #0: loss = 0.70076 (* 1 = 0.70076 loss)
I0805 19:40:25.242786 10603 sgd_solver.cpp:106] Iteration 56700, lr = 3.64902e-06
I0805 19:40:28.487042 10603 solver.cpp:228] Iteration 56800, loss = 0.688737
I0805 19:40:28.487088 10603 solver.cpp:244]     Train net output #0: loss = 0.688737 (* 1 = 0.688737 loss)
I0805 19:40:28.487095 10603 sgd_solver.cpp:106] Iteration 56800, lr = 3.64545e-06
I0805 19:40:31.731066 10603 solver.cpp:228] Iteration 56900, loss = 0.687554
I0805 19:40:31.731107 10603 solver.cpp:244]     Train net output #0: loss = 0.687554 (* 1 = 0.687554 loss)
I0805 19:40:31.731113 10603 sgd_solver.cpp:106] Iteration 56900, lr = 3.6419e-06
I0805 19:40:34.944064 10603 solver.cpp:337] Iteration 57000, Testing net (#0)
I0805 19:40:38.588129 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:40:38.588189 10603 solver.cpp:404]     Test net output #1: loss = 0.69357 (* 1 = 0.69357 loss)
I0805 19:40:38.598585 10603 solver.cpp:228] Iteration 57000, loss = 0.67962
I0805 19:40:38.598618 10603 solver.cpp:244]     Train net output #0: loss = 0.67962 (* 1 = 0.67962 loss)
I0805 19:40:38.598628 10603 sgd_solver.cpp:106] Iteration 57000, lr = 3.63835e-06
I0805 19:40:41.804468 10603 solver.cpp:228] Iteration 57100, loss = 0.69893
I0805 19:40:41.804515 10603 solver.cpp:244]     Train net output #0: loss = 0.69893 (* 1 = 0.69893 loss)
I0805 19:40:41.804522 10603 sgd_solver.cpp:106] Iteration 57100, lr = 3.63481e-06
I0805 19:40:45.004717 10603 solver.cpp:228] Iteration 57200, loss = 0.701155
I0805 19:40:45.004765 10603 solver.cpp:244]     Train net output #0: loss = 0.701155 (* 1 = 0.701155 loss)
I0805 19:40:45.004771 10603 sgd_solver.cpp:106] Iteration 57200, lr = 3.63128e-06
I0805 19:40:48.241034 10603 solver.cpp:228] Iteration 57300, loss = 0.686554
I0805 19:40:48.241083 10603 solver.cpp:244]     Train net output #0: loss = 0.686554 (* 1 = 0.686554 loss)
I0805 19:40:48.241089 10603 sgd_solver.cpp:106] Iteration 57300, lr = 3.62775e-06
I0805 19:40:51.489682 10603 solver.cpp:228] Iteration 57400, loss = 0.694108
I0805 19:40:51.489727 10603 solver.cpp:244]     Train net output #0: loss = 0.694108 (* 1 = 0.694108 loss)
I0805 19:40:51.489732 10603 sgd_solver.cpp:106] Iteration 57400, lr = 3.62424e-06
I0805 19:40:54.700951 10603 solver.cpp:337] Iteration 57500, Testing net (#0)
I0805 19:40:58.328460 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:40:58.328532 10603 solver.cpp:404]     Test net output #1: loss = 0.693232 (* 1 = 0.693232 loss)
I0805 19:40:58.338937 10603 solver.cpp:228] Iteration 57500, loss = 0.696701
I0805 19:40:58.338985 10603 solver.cpp:244]     Train net output #0: loss = 0.696701 (* 1 = 0.696701 loss)
I0805 19:40:58.339002 10603 sgd_solver.cpp:106] Iteration 57500, lr = 3.62073e-06
I0805 19:41:01.571833 10603 solver.cpp:228] Iteration 57600, loss = 0.691206
I0805 19:41:01.571883 10603 solver.cpp:244]     Train net output #0: loss = 0.691206 (* 1 = 0.691206 loss)
I0805 19:41:01.571894 10603 sgd_solver.cpp:106] Iteration 57600, lr = 3.61723e-06
I0805 19:41:04.823024 10603 solver.cpp:228] Iteration 57700, loss = 0.695147
I0805 19:41:04.823083 10603 solver.cpp:244]     Train net output #0: loss = 0.695147 (* 1 = 0.695147 loss)
I0805 19:41:04.823091 10603 sgd_solver.cpp:106] Iteration 57700, lr = 3.61374e-06
I0805 19:41:08.075386 10603 solver.cpp:228] Iteration 57800, loss = 0.694348
I0805 19:41:08.075428 10603 solver.cpp:244]     Train net output #0: loss = 0.694348 (* 1 = 0.694348 loss)
I0805 19:41:08.075434 10603 sgd_solver.cpp:106] Iteration 57800, lr = 3.61025e-06
I0805 19:41:11.324548 10603 solver.cpp:228] Iteration 57900, loss = 0.696228
I0805 19:41:11.324594 10603 solver.cpp:244]     Train net output #0: loss = 0.696228 (* 1 = 0.696228 loss)
I0805 19:41:11.324599 10603 sgd_solver.cpp:106] Iteration 57900, lr = 3.60678e-06
I0805 19:41:14.542608 10603 solver.cpp:337] Iteration 58000, Testing net (#0)
I0805 19:41:18.167610 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 19:41:18.167649 10603 solver.cpp:404]     Test net output #1: loss = 0.693479 (* 1 = 0.693479 loss)
I0805 19:41:18.181429 10603 solver.cpp:228] Iteration 58000, loss = 0.685728
I0805 19:41:18.181496 10603 solver.cpp:244]     Train net output #0: loss = 0.685728 (* 1 = 0.685728 loss)
I0805 19:41:18.181517 10603 sgd_solver.cpp:106] Iteration 58000, lr = 3.60331e-06
I0805 19:41:21.380630 10603 solver.cpp:228] Iteration 58100, loss = 0.692336
I0805 19:41:21.380689 10603 solver.cpp:244]     Train net output #0: loss = 0.692336 (* 1 = 0.692336 loss)
I0805 19:41:21.380697 10603 sgd_solver.cpp:106] Iteration 58100, lr = 3.59985e-06
I0805 19:41:24.598212 10603 solver.cpp:228] Iteration 58200, loss = 0.69512
I0805 19:41:24.598271 10603 solver.cpp:244]     Train net output #0: loss = 0.69512 (* 1 = 0.69512 loss)
I0805 19:41:24.598278 10603 sgd_solver.cpp:106] Iteration 58200, lr = 3.5964e-06
I0805 19:41:27.846087 10603 solver.cpp:228] Iteration 58300, loss = 0.703468
I0805 19:41:27.846129 10603 solver.cpp:244]     Train net output #0: loss = 0.703468 (* 1 = 0.703468 loss)
I0805 19:41:27.846137 10603 sgd_solver.cpp:106] Iteration 58300, lr = 3.59295e-06
I0805 19:41:31.094303 10603 solver.cpp:228] Iteration 58400, loss = 0.69381
I0805 19:41:31.094365 10603 solver.cpp:244]     Train net output #0: loss = 0.69381 (* 1 = 0.69381 loss)
I0805 19:41:31.094372 10603 sgd_solver.cpp:106] Iteration 58400, lr = 3.58951e-06
I0805 19:41:34.306337 10603 solver.cpp:337] Iteration 58500, Testing net (#0)
I0805 19:41:36.132659 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:41:37.824453 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791628
I0805 19:41:37.824524 10603 solver.cpp:404]     Test net output #1: loss = 0.693087 (* 1 = 0.693087 loss)
I0805 19:41:37.837348 10603 solver.cpp:228] Iteration 58500, loss = 0.690796
I0805 19:41:37.837389 10603 solver.cpp:244]     Train net output #0: loss = 0.690796 (* 1 = 0.690796 loss)
I0805 19:41:37.837401 10603 sgd_solver.cpp:106] Iteration 58500, lr = 3.58608e-06
I0805 19:41:41.074683 10603 solver.cpp:228] Iteration 58600, loss = 0.687449
I0805 19:41:41.074733 10603 solver.cpp:244]     Train net output #0: loss = 0.687449 (* 1 = 0.687449 loss)
I0805 19:41:41.074739 10603 sgd_solver.cpp:106] Iteration 58600, lr = 3.58266e-06
I0805 19:41:44.343145 10603 solver.cpp:228] Iteration 58700, loss = 0.699043
I0805 19:41:44.343209 10603 solver.cpp:244]     Train net output #0: loss = 0.699043 (* 1 = 0.699043 loss)
I0805 19:41:44.343216 10603 sgd_solver.cpp:106] Iteration 58700, lr = 3.57925e-06
I0805 19:41:47.604125 10603 solver.cpp:228] Iteration 58800, loss = 0.702943
I0805 19:41:47.604179 10603 solver.cpp:244]     Train net output #0: loss = 0.702943 (* 1 = 0.702943 loss)
I0805 19:41:47.604187 10603 sgd_solver.cpp:106] Iteration 58800, lr = 3.57584e-06
I0805 19:41:50.866019 10603 solver.cpp:228] Iteration 58900, loss = 0.689404
I0805 19:41:50.866078 10603 solver.cpp:244]     Train net output #0: loss = 0.689404 (* 1 = 0.689404 loss)
I0805 19:41:50.866086 10603 sgd_solver.cpp:106] Iteration 58900, lr = 3.57244e-06
I0805 19:41:54.097399 10603 solver.cpp:337] Iteration 59000, Testing net (#0)
I0805 19:41:57.647413 10603 solver.cpp:404]     Test net output #0: accuracy = 0.255523
I0805 19:41:57.647449 10603 solver.cpp:404]     Test net output #1: loss = 0.693168 (* 1 = 0.693168 loss)
I0805 19:41:57.658176 10603 solver.cpp:228] Iteration 59000, loss = 0.689823
I0805 19:41:57.658238 10603 solver.cpp:244]     Train net output #0: loss = 0.689823 (* 1 = 0.689823 loss)
I0805 19:41:57.658255 10603 sgd_solver.cpp:106] Iteration 59000, lr = 3.56905e-06
I0805 19:42:00.880043 10603 solver.cpp:228] Iteration 59100, loss = 0.685377
I0805 19:42:00.880090 10603 solver.cpp:244]     Train net output #0: loss = 0.685377 (* 1 = 0.685377 loss)
I0805 19:42:00.880096 10603 sgd_solver.cpp:106] Iteration 59100, lr = 3.56566e-06
I0805 19:42:04.097784 10603 solver.cpp:228] Iteration 59200, loss = 0.696639
I0805 19:42:04.097806 10603 solver.cpp:244]     Train net output #0: loss = 0.696639 (* 1 = 0.696639 loss)
I0805 19:42:04.097812 10603 sgd_solver.cpp:106] Iteration 59200, lr = 3.56228e-06
I0805 19:42:07.323704 10603 solver.cpp:228] Iteration 59300, loss = 0.696687
I0805 19:42:07.323747 10603 solver.cpp:244]     Train net output #0: loss = 0.696687 (* 1 = 0.696687 loss)
I0805 19:42:07.323755 10603 sgd_solver.cpp:106] Iteration 59300, lr = 3.55891e-06
I0805 19:42:10.574612 10603 solver.cpp:228] Iteration 59400, loss = 0.689147
I0805 19:42:10.574652 10603 solver.cpp:244]     Train net output #0: loss = 0.689147 (* 1 = 0.689147 loss)
I0805 19:42:10.574658 10603 sgd_solver.cpp:106] Iteration 59400, lr = 3.55555e-06
I0805 19:42:13.793089 10603 solver.cpp:337] Iteration 59500, Testing net (#0)
I0805 19:42:17.336026 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:42:17.336082 10603 solver.cpp:404]     Test net output #1: loss = 0.69357 (* 1 = 0.69357 loss)
I0805 19:42:17.349748 10603 solver.cpp:228] Iteration 59500, loss = 0.688141
I0805 19:42:17.349817 10603 solver.cpp:244]     Train net output #0: loss = 0.688141 (* 1 = 0.688141 loss)
I0805 19:42:17.349836 10603 sgd_solver.cpp:106] Iteration 59500, lr = 3.5522e-06
I0805 19:42:20.589239 10603 solver.cpp:228] Iteration 59600, loss = 0.698357
I0805 19:42:20.589283 10603 solver.cpp:244]     Train net output #0: loss = 0.698357 (* 1 = 0.698357 loss)
I0805 19:42:20.589289 10603 sgd_solver.cpp:106] Iteration 59600, lr = 3.54885e-06
I0805 19:42:23.831122 10603 solver.cpp:228] Iteration 59700, loss = 0.691774
I0805 19:42:23.831166 10603 solver.cpp:244]     Train net output #0: loss = 0.691774 (* 1 = 0.691774 loss)
I0805 19:42:23.831172 10603 sgd_solver.cpp:106] Iteration 59700, lr = 3.54551e-06
I0805 19:42:27.078346 10603 solver.cpp:228] Iteration 59800, loss = 0.693649
I0805 19:42:27.078392 10603 solver.cpp:244]     Train net output #0: loss = 0.693649 (* 1 = 0.693649 loss)
I0805 19:42:27.078398 10603 sgd_solver.cpp:106] Iteration 59800, lr = 3.54218e-06
I0805 19:42:30.327637 10603 solver.cpp:228] Iteration 59900, loss = 0.699582
I0805 19:42:30.327693 10603 solver.cpp:244]     Train net output #0: loss = 0.699582 (* 1 = 0.699582 loss)
I0805 19:42:30.327699 10603 sgd_solver.cpp:106] Iteration 59900, lr = 3.53885e-06
I0805 19:42:33.546299 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_60000.caffemodel
I0805 19:42:33.925376 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_60000.solverstate
I0805 19:42:34.060876 10603 solver.cpp:337] Iteration 60000, Testing net (#0)
I0805 19:42:37.609275 10603 solver.cpp:404]     Test net output #0: accuracy = 0.767035
I0805 19:42:37.609366 10603 solver.cpp:404]     Test net output #1: loss = 0.693125 (* 1 = 0.693125 loss)
I0805 19:42:37.619603 10603 solver.cpp:228] Iteration 60000, loss = 0.69341
I0805 19:42:37.619643 10603 solver.cpp:244]     Train net output #0: loss = 0.69341 (* 1 = 0.69341 loss)
I0805 19:42:37.619665 10603 sgd_solver.cpp:106] Iteration 60000, lr = 3.53553e-06
I0805 19:42:40.811897 10603 solver.cpp:228] Iteration 60100, loss = 0.689554
I0805 19:42:40.811947 10603 solver.cpp:244]     Train net output #0: loss = 0.689554 (* 1 = 0.689554 loss)
I0805 19:42:40.811954 10603 sgd_solver.cpp:106] Iteration 60100, lr = 3.53222e-06
I0805 19:42:44.030028 10603 solver.cpp:228] Iteration 60200, loss = 0.690263
I0805 19:42:44.030069 10603 solver.cpp:244]     Train net output #0: loss = 0.690263 (* 1 = 0.690263 loss)
I0805 19:42:44.030077 10603 sgd_solver.cpp:106] Iteration 60200, lr = 3.52892e-06
I0805 19:42:47.294239 10603 solver.cpp:228] Iteration 60300, loss = 0.694781
I0805 19:42:47.294298 10603 solver.cpp:244]     Train net output #0: loss = 0.694781 (* 1 = 0.694781 loss)
I0805 19:42:47.294306 10603 sgd_solver.cpp:106] Iteration 60300, lr = 3.52562e-06
I0805 19:42:50.567242 10603 solver.cpp:228] Iteration 60400, loss = 0.69136
I0805 19:42:50.567283 10603 solver.cpp:244]     Train net output #0: loss = 0.69136 (* 1 = 0.69136 loss)
I0805 19:42:50.567288 10603 sgd_solver.cpp:106] Iteration 60400, lr = 3.52233e-06
I0805 19:42:53.816890 10603 solver.cpp:337] Iteration 60500, Testing net (#0)
I0805 19:42:57.370805 10603 solver.cpp:404]     Test net output #0: accuracy = 0.790872
I0805 19:42:57.370856 10603 solver.cpp:404]     Test net output #1: loss = 0.693003 (* 1 = 0.693003 loss)
I0805 19:42:57.381206 10603 solver.cpp:228] Iteration 60500, loss = 0.695313
I0805 19:42:57.381252 10603 solver.cpp:244]     Train net output #0: loss = 0.695313 (* 1 = 0.695313 loss)
I0805 19:42:57.381263 10603 sgd_solver.cpp:106] Iteration 60500, lr = 3.51905e-06
I0805 19:43:00.594544 10603 solver.cpp:228] Iteration 60600, loss = 0.68571
I0805 19:43:00.594588 10603 solver.cpp:244]     Train net output #0: loss = 0.68571 (* 1 = 0.68571 loss)
I0805 19:43:00.594594 10603 sgd_solver.cpp:106] Iteration 60600, lr = 3.51578e-06
I0805 19:43:03.818480 10603 solver.cpp:228] Iteration 60700, loss = 0.707511
I0805 19:43:03.818524 10603 solver.cpp:244]     Train net output #0: loss = 0.707511 (* 1 = 0.707511 loss)
I0805 19:43:03.818531 10603 sgd_solver.cpp:106] Iteration 60700, lr = 3.51251e-06
I0805 19:43:07.060811 10603 solver.cpp:228] Iteration 60800, loss = 0.70585
I0805 19:43:07.060855 10603 solver.cpp:244]     Train net output #0: loss = 0.70585 (* 1 = 0.70585 loss)
I0805 19:43:07.060861 10603 sgd_solver.cpp:106] Iteration 60800, lr = 3.50925e-06
I0805 19:43:10.308168 10603 solver.cpp:228] Iteration 60900, loss = 0.694663
I0805 19:43:10.308215 10603 solver.cpp:244]     Train net output #0: loss = 0.694663 (* 1 = 0.694663 loss)
I0805 19:43:10.308223 10603 sgd_solver.cpp:106] Iteration 60900, lr = 3.50599e-06
I0805 19:43:13.518038 10603 solver.cpp:337] Iteration 61000, Testing net (#0)
I0805 19:43:17.033424 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:43:17.033485 10603 solver.cpp:404]     Test net output #1: loss = 0.693625 (* 1 = 0.693625 loss)
I0805 19:43:17.043656 10603 solver.cpp:228] Iteration 61000, loss = 0.69359
I0805 19:43:17.043674 10603 solver.cpp:244]     Train net output #0: loss = 0.69359 (* 1 = 0.69359 loss)
I0805 19:43:17.043684 10603 sgd_solver.cpp:106] Iteration 61000, lr = 3.50275e-06
I0805 19:43:20.273648 10603 solver.cpp:228] Iteration 61100, loss = 0.68875
I0805 19:43:20.273696 10603 solver.cpp:244]     Train net output #0: loss = 0.68875 (* 1 = 0.68875 loss)
I0805 19:43:20.273702 10603 sgd_solver.cpp:106] Iteration 61100, lr = 3.49951e-06
I0805 19:43:23.512935 10603 solver.cpp:228] Iteration 61200, loss = 0.697925
I0805 19:43:23.512980 10603 solver.cpp:244]     Train net output #0: loss = 0.697925 (* 1 = 0.697925 loss)
I0805 19:43:23.512989 10603 sgd_solver.cpp:106] Iteration 61200, lr = 3.49627e-06
I0805 19:43:26.814667 10603 solver.cpp:228] Iteration 61300, loss = 0.692049
I0805 19:43:26.814709 10603 solver.cpp:244]     Train net output #0: loss = 0.692049 (* 1 = 0.692049 loss)
I0805 19:43:26.814715 10603 sgd_solver.cpp:106] Iteration 61300, lr = 3.49305e-06
I0805 19:43:27.833202 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:43:30.102411 10603 solver.cpp:228] Iteration 61400, loss = 0.688914
I0805 19:43:30.102458 10603 solver.cpp:244]     Train net output #0: loss = 0.688914 (* 1 = 0.688914 loss)
I0805 19:43:30.102464 10603 sgd_solver.cpp:106] Iteration 61400, lr = 3.48983e-06
I0805 19:43:33.352258 10603 solver.cpp:337] Iteration 61500, Testing net (#0)
I0805 19:43:37.072379 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207849
I0805 19:43:37.072428 10603 solver.cpp:404]     Test net output #1: loss = 0.694045 (* 1 = 0.694045 loss)
I0805 19:43:37.085561 10603 solver.cpp:228] Iteration 61500, loss = 0.695478
I0805 19:43:37.085621 10603 solver.cpp:244]     Train net output #0: loss = 0.695478 (* 1 = 0.695478 loss)
I0805 19:43:37.085650 10603 sgd_solver.cpp:106] Iteration 61500, lr = 3.48662e-06
I0805 19:43:40.275033 10603 solver.cpp:228] Iteration 61600, loss = 0.698997
I0805 19:43:40.275089 10603 solver.cpp:244]     Train net output #0: loss = 0.698997 (* 1 = 0.698997 loss)
I0805 19:43:40.275097 10603 sgd_solver.cpp:106] Iteration 61600, lr = 3.48341e-06
I0805 19:43:43.498554 10603 solver.cpp:228] Iteration 61700, loss = 0.707212
I0805 19:43:43.498597 10603 solver.cpp:244]     Train net output #0: loss = 0.707212 (* 1 = 0.707212 loss)
I0805 19:43:43.498603 10603 sgd_solver.cpp:106] Iteration 61700, lr = 3.48021e-06
I0805 19:43:46.739403 10603 solver.cpp:228] Iteration 61800, loss = 0.691429
I0805 19:43:46.739446 10603 solver.cpp:244]     Train net output #0: loss = 0.691429 (* 1 = 0.691429 loss)
I0805 19:43:46.739452 10603 sgd_solver.cpp:106] Iteration 61800, lr = 3.47702e-06
I0805 19:43:49.982956 10603 solver.cpp:228] Iteration 61900, loss = 0.691902
I0805 19:43:49.983006 10603 solver.cpp:244]     Train net output #0: loss = 0.691902 (* 1 = 0.691902 loss)
I0805 19:43:49.983011 10603 sgd_solver.cpp:106] Iteration 61900, lr = 3.47384e-06
I0805 19:43:53.192198 10603 solver.cpp:337] Iteration 62000, Testing net (#0)
I0805 19:43:56.776849 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:43:56.776885 10603 solver.cpp:404]     Test net output #1: loss = 0.693367 (* 1 = 0.693367 loss)
I0805 19:43:56.788036 10603 solver.cpp:228] Iteration 62000, loss = 0.707137
I0805 19:43:56.788108 10603 solver.cpp:244]     Train net output #0: loss = 0.707137 (* 1 = 0.707137 loss)
I0805 19:43:56.788132 10603 sgd_solver.cpp:106] Iteration 62000, lr = 3.47066e-06
I0805 19:44:00.038338 10603 solver.cpp:228] Iteration 62100, loss = 0.701204
I0805 19:44:00.038379 10603 solver.cpp:244]     Train net output #0: loss = 0.701204 (* 1 = 0.701204 loss)
I0805 19:44:00.038385 10603 sgd_solver.cpp:106] Iteration 62100, lr = 3.46749e-06
I0805 19:44:03.298995 10603 solver.cpp:228] Iteration 62200, loss = 0.685749
I0805 19:44:03.299043 10603 solver.cpp:244]     Train net output #0: loss = 0.685749 (* 1 = 0.685749 loss)
I0805 19:44:03.299051 10603 sgd_solver.cpp:106] Iteration 62200, lr = 3.46433e-06
I0805 19:44:06.544119 10603 solver.cpp:228] Iteration 62300, loss = 0.699614
I0805 19:44:06.544168 10603 solver.cpp:244]     Train net output #0: loss = 0.699614 (* 1 = 0.699614 loss)
I0805 19:44:06.544176 10603 sgd_solver.cpp:106] Iteration 62300, lr = 3.46117e-06
I0805 19:44:09.789181 10603 solver.cpp:228] Iteration 62400, loss = 0.687087
I0805 19:44:09.789222 10603 solver.cpp:244]     Train net output #0: loss = 0.687087 (* 1 = 0.687087 loss)
I0805 19:44:09.789228 10603 sgd_solver.cpp:106] Iteration 62400, lr = 3.45802e-06
I0805 19:44:13.002753 10603 solver.cpp:337] Iteration 62500, Testing net (#0)
I0805 19:44:16.723044 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 19:44:16.723086 10603 solver.cpp:404]     Test net output #1: loss = 0.693447 (* 1 = 0.693447 loss)
I0805 19:44:16.733211 10603 solver.cpp:228] Iteration 62500, loss = 0.696136
I0805 19:44:16.733243 10603 solver.cpp:244]     Train net output #0: loss = 0.696136 (* 1 = 0.696136 loss)
I0805 19:44:16.733253 10603 sgd_solver.cpp:106] Iteration 62500, lr = 3.45487e-06
I0805 19:44:19.927774 10603 solver.cpp:228] Iteration 62600, loss = 0.687904
I0805 19:44:19.927819 10603 solver.cpp:244]     Train net output #0: loss = 0.687904 (* 1 = 0.687904 loss)
I0805 19:44:19.927826 10603 sgd_solver.cpp:106] Iteration 62600, lr = 3.45173e-06
I0805 19:44:23.167577 10603 solver.cpp:228] Iteration 62700, loss = 0.692122
I0805 19:44:23.167618 10603 solver.cpp:244]     Train net output #0: loss = 0.692122 (* 1 = 0.692122 loss)
I0805 19:44:23.167624 10603 sgd_solver.cpp:106] Iteration 62700, lr = 3.4486e-06
I0805 19:44:26.418262 10603 solver.cpp:228] Iteration 62800, loss = 0.696438
I0805 19:44:26.418308 10603 solver.cpp:244]     Train net output #0: loss = 0.696438 (* 1 = 0.696438 loss)
I0805 19:44:26.418314 10603 sgd_solver.cpp:106] Iteration 62800, lr = 3.44548e-06
I0805 19:44:29.667634 10603 solver.cpp:228] Iteration 62900, loss = 0.706084
I0805 19:44:29.667685 10603 solver.cpp:244]     Train net output #0: loss = 0.706084 (* 1 = 0.706084 loss)
I0805 19:44:29.667696 10603 sgd_solver.cpp:106] Iteration 62900, lr = 3.44236e-06
I0805 19:44:32.893102 10603 solver.cpp:337] Iteration 63000, Testing net (#0)
I0805 19:44:36.504973 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207965
I0805 19:44:36.505031 10603 solver.cpp:404]     Test net output #1: loss = 0.693428 (* 1 = 0.693428 loss)
I0805 19:44:36.515193 10603 solver.cpp:228] Iteration 63000, loss = 0.702579
I0805 19:44:36.515221 10603 solver.cpp:244]     Train net output #0: loss = 0.702579 (* 1 = 0.702579 loss)
I0805 19:44:36.515230 10603 sgd_solver.cpp:106] Iteration 63000, lr = 3.43925e-06
I0805 19:44:39.694439 10603 solver.cpp:228] Iteration 63100, loss = 0.682685
I0805 19:44:39.694507 10603 solver.cpp:244]     Train net output #0: loss = 0.682685 (* 1 = 0.682685 loss)
I0805 19:44:39.694519 10603 sgd_solver.cpp:106] Iteration 63100, lr = 3.43615e-06
I0805 19:44:42.928871 10603 solver.cpp:228] Iteration 63200, loss = 0.701946
I0805 19:44:42.928912 10603 solver.cpp:244]     Train net output #0: loss = 0.701946 (* 1 = 0.701946 loss)
I0805 19:44:42.928918 10603 sgd_solver.cpp:106] Iteration 63200, lr = 3.43305e-06
I0805 19:44:46.172246 10603 solver.cpp:228] Iteration 63300, loss = 0.699204
I0805 19:44:46.172291 10603 solver.cpp:244]     Train net output #0: loss = 0.699204 (* 1 = 0.699204 loss)
I0805 19:44:46.172297 10603 sgd_solver.cpp:106] Iteration 63300, lr = 3.42996e-06
I0805 19:44:49.419900 10603 solver.cpp:228] Iteration 63400, loss = 0.6956
I0805 19:44:49.419939 10603 solver.cpp:244]     Train net output #0: loss = 0.6956 (* 1 = 0.6956 loss)
I0805 19:44:49.419945 10603 sgd_solver.cpp:106] Iteration 63400, lr = 3.42687e-06
I0805 19:44:52.630269 10603 solver.cpp:337] Iteration 63500, Testing net (#0)
I0805 19:44:56.229651 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:44:56.229693 10603 solver.cpp:404]     Test net output #1: loss = 0.693821 (* 1 = 0.693821 loss)
I0805 19:44:56.243321 10603 solver.cpp:228] Iteration 63500, loss = 0.69728
I0805 19:44:56.243392 10603 solver.cpp:244]     Train net output #0: loss = 0.69728 (* 1 = 0.69728 loss)
I0805 19:44:56.243409 10603 sgd_solver.cpp:106] Iteration 63500, lr = 3.42379e-06
I0805 19:44:59.478449 10603 solver.cpp:228] Iteration 63600, loss = 0.692418
I0805 19:44:59.478495 10603 solver.cpp:244]     Train net output #0: loss = 0.692418 (* 1 = 0.692418 loss)
I0805 19:44:59.478502 10603 sgd_solver.cpp:106] Iteration 63600, lr = 3.42072e-06
I0805 19:45:02.736250 10603 solver.cpp:228] Iteration 63700, loss = 0.701557
I0805 19:45:02.736290 10603 solver.cpp:244]     Train net output #0: loss = 0.701557 (* 1 = 0.701557 loss)
I0805 19:45:02.736296 10603 sgd_solver.cpp:106] Iteration 63700, lr = 3.41766e-06
I0805 19:45:05.998831 10603 solver.cpp:228] Iteration 63800, loss = 0.691289
I0805 19:45:05.998875 10603 solver.cpp:244]     Train net output #0: loss = 0.691289 (* 1 = 0.691289 loss)
I0805 19:45:05.998883 10603 sgd_solver.cpp:106] Iteration 63800, lr = 3.4146e-06
I0805 19:45:09.262557 10603 solver.cpp:228] Iteration 63900, loss = 0.693788
I0805 19:45:09.262596 10603 solver.cpp:244]     Train net output #0: loss = 0.693788 (* 1 = 0.693788 loss)
I0805 19:45:09.262603 10603 sgd_solver.cpp:106] Iteration 63900, lr = 3.41154e-06
I0805 19:45:12.486775 10603 solver.cpp:337] Iteration 64000, Testing net (#0)
I0805 19:45:15.662039 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:45:16.005517 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208139
I0805 19:45:16.005549 10603 solver.cpp:404]     Test net output #1: loss = 0.69348 (* 1 = 0.69348 loss)
I0805 19:45:16.016320 10603 solver.cpp:228] Iteration 64000, loss = 0.69624
I0805 19:45:16.016387 10603 solver.cpp:244]     Train net output #0: loss = 0.69624 (* 1 = 0.69624 loss)
I0805 19:45:16.016405 10603 sgd_solver.cpp:106] Iteration 64000, lr = 3.4085e-06
I0805 19:45:19.232223 10603 solver.cpp:228] Iteration 64100, loss = 0.702616
I0805 19:45:19.232269 10603 solver.cpp:244]     Train net output #0: loss = 0.702616 (* 1 = 0.702616 loss)
I0805 19:45:19.232275 10603 sgd_solver.cpp:106] Iteration 64100, lr = 3.40546e-06
I0805 19:45:22.472293 10603 solver.cpp:228] Iteration 64200, loss = 0.693176
I0805 19:45:22.472337 10603 solver.cpp:244]     Train net output #0: loss = 0.693176 (* 1 = 0.693176 loss)
I0805 19:45:22.472344 10603 sgd_solver.cpp:106] Iteration 64200, lr = 3.40242e-06
I0805 19:45:25.718755 10603 solver.cpp:228] Iteration 64300, loss = 0.697469
I0805 19:45:25.718799 10603 solver.cpp:244]     Train net output #0: loss = 0.697469 (* 1 = 0.697469 loss)
I0805 19:45:25.718806 10603 sgd_solver.cpp:106] Iteration 64300, lr = 3.3994e-06
I0805 19:45:28.955945 10603 solver.cpp:228] Iteration 64400, loss = 0.695657
I0805 19:45:28.955987 10603 solver.cpp:244]     Train net output #0: loss = 0.695657 (* 1 = 0.695657 loss)
I0805 19:45:28.955994 10603 sgd_solver.cpp:106] Iteration 64400, lr = 3.39637e-06
I0805 19:45:32.171661 10603 solver.cpp:337] Iteration 64500, Testing net (#0)
I0805 19:45:35.692381 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:45:35.692422 10603 solver.cpp:404]     Test net output #1: loss = 0.693597 (* 1 = 0.693597 loss)
I0805 19:45:35.702893 10603 solver.cpp:228] Iteration 64500, loss = 0.706544
I0805 19:45:35.702950 10603 solver.cpp:244]     Train net output #0: loss = 0.706544 (* 1 = 0.706544 loss)
I0805 19:45:35.702965 10603 sgd_solver.cpp:106] Iteration 64500, lr = 3.39336e-06
I0805 19:45:38.919787 10603 solver.cpp:228] Iteration 64600, loss = 0.69665
I0805 19:45:38.919833 10603 solver.cpp:244]     Train net output #0: loss = 0.69665 (* 1 = 0.69665 loss)
I0805 19:45:38.919839 10603 sgd_solver.cpp:106] Iteration 64600, lr = 3.39035e-06
I0805 19:45:42.142612 10603 solver.cpp:228] Iteration 64700, loss = 0.704982
I0805 19:45:42.142653 10603 solver.cpp:244]     Train net output #0: loss = 0.704982 (* 1 = 0.704982 loss)
I0805 19:45:42.142659 10603 sgd_solver.cpp:106] Iteration 64700, lr = 3.38735e-06
I0805 19:45:45.388881 10603 solver.cpp:228] Iteration 64800, loss = 0.68782
I0805 19:45:45.388923 10603 solver.cpp:244]     Train net output #0: loss = 0.68782 (* 1 = 0.68782 loss)
I0805 19:45:45.388931 10603 sgd_solver.cpp:106] Iteration 64800, lr = 3.38435e-06
I0805 19:45:48.633008 10603 solver.cpp:228] Iteration 64900, loss = 0.69083
I0805 19:45:48.633047 10603 solver.cpp:244]     Train net output #0: loss = 0.69083 (* 1 = 0.69083 loss)
I0805 19:45:48.633054 10603 sgd_solver.cpp:106] Iteration 64900, lr = 3.38136e-06
I0805 19:45:51.867856 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_65000.caffemodel
I0805 19:45:52.245789 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_65000.solverstate
I0805 19:45:52.381809 10603 solver.cpp:337] Iteration 65000, Testing net (#0)
I0805 19:45:55.908553 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:45:55.908607 10603 solver.cpp:404]     Test net output #1: loss = 0.693448 (* 1 = 0.693448 loss)
I0805 19:45:55.918903 10603 solver.cpp:228] Iteration 65000, loss = 0.694216
I0805 19:45:55.918931 10603 solver.cpp:244]     Train net output #0: loss = 0.694216 (* 1 = 0.694216 loss)
I0805 19:45:55.918938 10603 sgd_solver.cpp:106] Iteration 65000, lr = 3.37838e-06
I0805 19:45:59.112664 10603 solver.cpp:228] Iteration 65100, loss = 0.700486
I0805 19:45:59.112706 10603 solver.cpp:244]     Train net output #0: loss = 0.700486 (* 1 = 0.700486 loss)
I0805 19:45:59.112712 10603 sgd_solver.cpp:106] Iteration 65100, lr = 3.3754e-06
I0805 19:46:02.364995 10603 solver.cpp:228] Iteration 65200, loss = 0.696728
I0805 19:46:02.365038 10603 solver.cpp:244]     Train net output #0: loss = 0.696728 (* 1 = 0.696728 loss)
I0805 19:46:02.365046 10603 sgd_solver.cpp:106] Iteration 65200, lr = 3.37243e-06
I0805 19:46:05.617385 10603 solver.cpp:228] Iteration 65300, loss = 0.693301
I0805 19:46:05.617427 10603 solver.cpp:244]     Train net output #0: loss = 0.693301 (* 1 = 0.693301 loss)
I0805 19:46:05.617434 10603 sgd_solver.cpp:106] Iteration 65300, lr = 3.36946e-06
I0805 19:46:08.870924 10603 solver.cpp:228] Iteration 65400, loss = 0.689979
I0805 19:46:08.870966 10603 solver.cpp:244]     Train net output #0: loss = 0.689979 (* 1 = 0.689979 loss)
I0805 19:46:08.870972 10603 sgd_solver.cpp:106] Iteration 65400, lr = 3.3665e-06
I0805 19:46:12.097153 10603 solver.cpp:337] Iteration 65500, Testing net (#0)
I0805 19:46:15.618664 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:46:15.618721 10603 solver.cpp:404]     Test net output #1: loss = 0.69357 (* 1 = 0.69357 loss)
I0805 19:46:15.629495 10603 solver.cpp:228] Iteration 65500, loss = 0.712374
I0805 19:46:15.629559 10603 solver.cpp:244]     Train net output #0: loss = 0.712374 (* 1 = 0.712374 loss)
I0805 19:46:15.629578 10603 sgd_solver.cpp:106] Iteration 65500, lr = 3.36355e-06
I0805 19:46:18.852515 10603 solver.cpp:228] Iteration 65600, loss = 0.681025
I0805 19:46:18.852571 10603 solver.cpp:244]     Train net output #0: loss = 0.681025 (* 1 = 0.681025 loss)
I0805 19:46:18.852577 10603 sgd_solver.cpp:106] Iteration 65600, lr = 3.3606e-06
I0805 19:46:22.095491 10603 solver.cpp:228] Iteration 65700, loss = 0.6907
I0805 19:46:22.095530 10603 solver.cpp:244]     Train net output #0: loss = 0.6907 (* 1 = 0.6907 loss)
I0805 19:46:22.095536 10603 sgd_solver.cpp:106] Iteration 65700, lr = 3.35766e-06
I0805 19:46:25.335561 10603 solver.cpp:228] Iteration 65800, loss = 0.691731
I0805 19:46:25.335605 10603 solver.cpp:244]     Train net output #0: loss = 0.691731 (* 1 = 0.691731 loss)
I0805 19:46:25.335611 10603 sgd_solver.cpp:106] Iteration 65800, lr = 3.35473e-06
I0805 19:46:28.582408 10603 solver.cpp:228] Iteration 65900, loss = 0.702303
I0805 19:46:28.582453 10603 solver.cpp:244]     Train net output #0: loss = 0.702303 (* 1 = 0.702303 loss)
I0805 19:46:28.582459 10603 sgd_solver.cpp:106] Iteration 65900, lr = 3.3518e-06
I0805 19:46:31.790717 10603 solver.cpp:337] Iteration 66000, Testing net (#0)
I0805 19:46:35.447527 10603 solver.cpp:404]     Test net output #0: accuracy = 0.725233
I0805 19:46:35.447577 10603 solver.cpp:404]     Test net output #1: loss = 0.693129 (* 1 = 0.693129 loss)
I0805 19:46:35.460888 10603 solver.cpp:228] Iteration 66000, loss = 0.691628
I0805 19:46:35.460959 10603 solver.cpp:244]     Train net output #0: loss = 0.691628 (* 1 = 0.691628 loss)
I0805 19:46:35.460978 10603 sgd_solver.cpp:106] Iteration 66000, lr = 3.34887e-06
I0805 19:46:38.675348 10603 solver.cpp:228] Iteration 66100, loss = 0.709728
I0805 19:46:38.675391 10603 solver.cpp:244]     Train net output #0: loss = 0.709728 (* 1 = 0.709728 loss)
I0805 19:46:38.675397 10603 sgd_solver.cpp:106] Iteration 66100, lr = 3.34596e-06
I0805 19:46:41.930974 10603 solver.cpp:228] Iteration 66200, loss = 0.702481
I0805 19:46:41.931031 10603 solver.cpp:244]     Train net output #0: loss = 0.702481 (* 1 = 0.702481 loss)
I0805 19:46:41.931040 10603 sgd_solver.cpp:106] Iteration 66200, lr = 3.34304e-06
I0805 19:46:45.193933 10603 solver.cpp:228] Iteration 66300, loss = 0.703156
I0805 19:46:45.193974 10603 solver.cpp:244]     Train net output #0: loss = 0.703156 (* 1 = 0.703156 loss)
I0805 19:46:45.193979 10603 sgd_solver.cpp:106] Iteration 66300, lr = 3.34014e-06
I0805 19:46:48.454247 10603 solver.cpp:228] Iteration 66400, loss = 0.700582
I0805 19:46:48.454291 10603 solver.cpp:244]     Train net output #0: loss = 0.700582 (* 1 = 0.700582 loss)
I0805 19:46:48.454298 10603 sgd_solver.cpp:106] Iteration 66400, lr = 3.33724e-06
I0805 19:46:51.687628 10603 solver.cpp:337] Iteration 66500, Testing net (#0)
I0805 19:46:54.688496 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:46:55.269863 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:46:55.269906 10603 solver.cpp:404]     Test net output #1: loss = 0.693598 (* 1 = 0.693598 loss)
I0805 19:46:55.282932 10603 solver.cpp:228] Iteration 66500, loss = 0.696166
I0805 19:46:55.282960 10603 solver.cpp:244]     Train net output #0: loss = 0.696166 (* 1 = 0.696166 loss)
I0805 19:46:55.282968 10603 sgd_solver.cpp:106] Iteration 66500, lr = 3.33434e-06
I0805 19:46:58.495558 10603 solver.cpp:228] Iteration 66600, loss = 0.693858
I0805 19:46:58.495601 10603 solver.cpp:244]     Train net output #0: loss = 0.693858 (* 1 = 0.693858 loss)
I0805 19:46:58.495609 10603 sgd_solver.cpp:106] Iteration 66600, lr = 3.33146e-06
I0805 19:47:01.721590 10603 solver.cpp:228] Iteration 66700, loss = 0.693096
I0805 19:47:01.721638 10603 solver.cpp:244]     Train net output #0: loss = 0.693096 (* 1 = 0.693096 loss)
I0805 19:47:01.721645 10603 sgd_solver.cpp:106] Iteration 66700, lr = 3.32857e-06
I0805 19:47:04.964293 10603 solver.cpp:228] Iteration 66800, loss = 0.691273
I0805 19:47:04.964335 10603 solver.cpp:244]     Train net output #0: loss = 0.691273 (* 1 = 0.691273 loss)
I0805 19:47:04.964341 10603 sgd_solver.cpp:106] Iteration 66800, lr = 3.3257e-06
I0805 19:47:08.212394 10603 solver.cpp:228] Iteration 66900, loss = 0.703485
I0805 19:47:08.212436 10603 solver.cpp:244]     Train net output #0: loss = 0.703485 (* 1 = 0.703485 loss)
I0805 19:47:08.212442 10603 sgd_solver.cpp:106] Iteration 66900, lr = 3.32283e-06
I0805 19:47:11.433892 10603 solver.cpp:337] Iteration 67000, Testing net (#0)
I0805 19:47:14.980200 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:47:14.980252 10603 solver.cpp:404]     Test net output #1: loss = 0.694092 (* 1 = 0.694092 loss)
I0805 19:47:14.993372 10603 solver.cpp:228] Iteration 67000, loss = 0.697404
I0805 19:47:14.993402 10603 solver.cpp:244]     Train net output #0: loss = 0.697404 (* 1 = 0.697404 loss)
I0805 19:47:14.993410 10603 sgd_solver.cpp:106] Iteration 67000, lr = 3.31996e-06
I0805 19:47:18.217667 10603 solver.cpp:228] Iteration 67100, loss = 0.688822
I0805 19:47:18.217713 10603 solver.cpp:244]     Train net output #0: loss = 0.688822 (* 1 = 0.688822 loss)
I0805 19:47:18.217720 10603 sgd_solver.cpp:106] Iteration 67100, lr = 3.3171e-06
I0805 19:47:21.467084 10603 solver.cpp:228] Iteration 67200, loss = 0.694299
I0805 19:47:21.467144 10603 solver.cpp:244]     Train net output #0: loss = 0.694299 (* 1 = 0.694299 loss)
I0805 19:47:21.467154 10603 sgd_solver.cpp:106] Iteration 67200, lr = 3.31425e-06
I0805 19:47:24.715549 10603 solver.cpp:228] Iteration 67300, loss = 0.696933
I0805 19:47:24.715613 10603 solver.cpp:244]     Train net output #0: loss = 0.696933 (* 1 = 0.696933 loss)
I0805 19:47:24.715620 10603 sgd_solver.cpp:106] Iteration 67300, lr = 3.3114e-06
I0805 19:47:27.962772 10603 solver.cpp:228] Iteration 67400, loss = 0.694445
I0805 19:47:27.962822 10603 solver.cpp:244]     Train net output #0: loss = 0.694445 (* 1 = 0.694445 loss)
I0805 19:47:27.962836 10603 sgd_solver.cpp:106] Iteration 67400, lr = 3.30856e-06
I0805 19:47:31.178696 10603 solver.cpp:337] Iteration 67500, Testing net (#0)
I0805 19:47:34.707434 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:47:34.707490 10603 solver.cpp:404]     Test net output #1: loss = 0.693316 (* 1 = 0.693316 loss)
I0805 19:47:34.721272 10603 solver.cpp:228] Iteration 67500, loss = 0.704015
I0805 19:47:34.721334 10603 solver.cpp:244]     Train net output #0: loss = 0.704015 (* 1 = 0.704015 loss)
I0805 19:47:34.721352 10603 sgd_solver.cpp:106] Iteration 67500, lr = 3.30572e-06
I0805 19:47:37.947624 10603 solver.cpp:228] Iteration 67600, loss = 0.685516
I0805 19:47:37.947665 10603 solver.cpp:244]     Train net output #0: loss = 0.685516 (* 1 = 0.685516 loss)
I0805 19:47:37.947671 10603 sgd_solver.cpp:106] Iteration 67600, lr = 3.30289e-06
I0805 19:47:41.179419 10603 solver.cpp:228] Iteration 67700, loss = 0.696877
I0805 19:47:41.179463 10603 solver.cpp:244]     Train net output #0: loss = 0.696877 (* 1 = 0.696877 loss)
I0805 19:47:41.179469 10603 sgd_solver.cpp:106] Iteration 67700, lr = 3.30007e-06
I0805 19:47:44.431747 10603 solver.cpp:228] Iteration 67800, loss = 0.696903
I0805 19:47:44.431795 10603 solver.cpp:244]     Train net output #0: loss = 0.696903 (* 1 = 0.696903 loss)
I0805 19:47:44.431802 10603 sgd_solver.cpp:106] Iteration 67800, lr = 3.29725e-06
I0805 19:47:47.687672 10603 solver.cpp:228] Iteration 67900, loss = 0.690492
I0805 19:47:47.687710 10603 solver.cpp:244]     Train net output #0: loss = 0.690492 (* 1 = 0.690492 loss)
I0805 19:47:47.687716 10603 sgd_solver.cpp:106] Iteration 67900, lr = 3.29443e-06
I0805 19:47:50.905666 10603 solver.cpp:337] Iteration 68000, Testing net (#0)
I0805 19:47:54.426879 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208779
I0805 19:47:54.426921 10603 solver.cpp:404]     Test net output #1: loss = 0.693198 (* 1 = 0.693198 loss)
I0805 19:47:54.437664 10603 solver.cpp:228] Iteration 68000, loss = 0.695438
I0805 19:47:54.437736 10603 solver.cpp:244]     Train net output #0: loss = 0.695438 (* 1 = 0.695438 loss)
I0805 19:47:54.437752 10603 sgd_solver.cpp:106] Iteration 68000, lr = 3.29163e-06
I0805 19:47:57.655633 10603 solver.cpp:228] Iteration 68100, loss = 0.68985
I0805 19:47:57.655683 10603 solver.cpp:244]     Train net output #0: loss = 0.68985 (* 1 = 0.68985 loss)
I0805 19:47:57.655689 10603 sgd_solver.cpp:106] Iteration 68100, lr = 3.28882e-06
I0805 19:48:00.869916 10603 solver.cpp:228] Iteration 68200, loss = 0.691929
I0805 19:48:00.869956 10603 solver.cpp:244]     Train net output #0: loss = 0.691929 (* 1 = 0.691929 loss)
I0805 19:48:00.869962 10603 sgd_solver.cpp:106] Iteration 68200, lr = 3.28603e-06
I0805 19:48:04.114258 10603 solver.cpp:228] Iteration 68300, loss = 0.693967
I0805 19:48:04.114302 10603 solver.cpp:244]     Train net output #0: loss = 0.693967 (* 1 = 0.693967 loss)
I0805 19:48:04.114308 10603 sgd_solver.cpp:106] Iteration 68300, lr = 3.28323e-06
I0805 19:48:07.356921 10603 solver.cpp:228] Iteration 68400, loss = 0.688525
I0805 19:48:07.356961 10603 solver.cpp:244]     Train net output #0: loss = 0.688525 (* 1 = 0.688525 loss)
I0805 19:48:07.356966 10603 sgd_solver.cpp:106] Iteration 68400, lr = 3.28045e-06
I0805 19:48:10.569972 10603 solver.cpp:337] Iteration 68500, Testing net (#0)
I0805 19:48:14.124363 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:48:14.124428 10603 solver.cpp:404]     Test net output #1: loss = 0.693483 (* 1 = 0.693483 loss)
I0805 19:48:14.138164 10603 solver.cpp:228] Iteration 68500, loss = 0.698096
I0805 19:48:14.138228 10603 solver.cpp:244]     Train net output #0: loss = 0.698096 (* 1 = 0.698096 loss)
I0805 19:48:14.138247 10603 sgd_solver.cpp:106] Iteration 68500, lr = 3.27767e-06
I0805 19:48:17.380409 10603 solver.cpp:228] Iteration 68600, loss = 0.696464
I0805 19:48:17.380456 10603 solver.cpp:244]     Train net output #0: loss = 0.696464 (* 1 = 0.696464 loss)
I0805 19:48:17.380462 10603 sgd_solver.cpp:106] Iteration 68600, lr = 3.27489e-06
I0805 19:48:20.643314 10603 solver.cpp:228] Iteration 68700, loss = 0.704483
I0805 19:48:20.643359 10603 solver.cpp:244]     Train net output #0: loss = 0.704483 (* 1 = 0.704483 loss)
I0805 19:48:20.643365 10603 sgd_solver.cpp:106] Iteration 68700, lr = 3.27212e-06
I0805 19:48:23.904652 10603 solver.cpp:228] Iteration 68800, loss = 0.69469
I0805 19:48:23.904696 10603 solver.cpp:244]     Train net output #0: loss = 0.69469 (* 1 = 0.69469 loss)
I0805 19:48:23.904703 10603 sgd_solver.cpp:106] Iteration 68800, lr = 3.26936e-06
I0805 19:48:27.167810 10603 solver.cpp:228] Iteration 68900, loss = 0.687043
I0805 19:48:27.167850 10603 solver.cpp:244]     Train net output #0: loss = 0.687043 (* 1 = 0.687043 loss)
I0805 19:48:27.167855 10603 sgd_solver.cpp:106] Iteration 68900, lr = 3.2666e-06
I0805 19:48:30.395337 10603 solver.cpp:337] Iteration 69000, Testing net (#0)
I0805 19:48:33.854962 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:48:33.999155 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207733
I0805 19:48:33.999187 10603 solver.cpp:404]     Test net output #1: loss = 0.693746 (* 1 = 0.693746 loss)
I0805 19:48:34.010135 10603 solver.cpp:228] Iteration 69000, loss = 0.693383
I0805 19:48:34.010210 10603 solver.cpp:244]     Train net output #0: loss = 0.693383 (* 1 = 0.693383 loss)
I0805 19:48:34.010227 10603 sgd_solver.cpp:106] Iteration 69000, lr = 3.26385e-06
I0805 19:48:37.206461 10603 solver.cpp:228] Iteration 69100, loss = 0.682969
I0805 19:48:37.206523 10603 solver.cpp:244]     Train net output #0: loss = 0.682969 (* 1 = 0.682969 loss)
I0805 19:48:37.206529 10603 sgd_solver.cpp:106] Iteration 69100, lr = 3.2611e-06
I0805 19:48:40.437006 10603 solver.cpp:228] Iteration 69200, loss = 0.689823
I0805 19:48:40.437069 10603 solver.cpp:244]     Train net output #0: loss = 0.689823 (* 1 = 0.689823 loss)
I0805 19:48:40.437075 10603 sgd_solver.cpp:106] Iteration 69200, lr = 3.25836e-06
I0805 19:48:43.681582 10603 solver.cpp:228] Iteration 69300, loss = 0.693905
I0805 19:48:43.681656 10603 solver.cpp:244]     Train net output #0: loss = 0.693905 (* 1 = 0.693905 loss)
I0805 19:48:43.681663 10603 sgd_solver.cpp:106] Iteration 69300, lr = 3.25562e-06
I0805 19:48:46.920259 10603 solver.cpp:228] Iteration 69400, loss = 0.701693
I0805 19:48:46.920298 10603 solver.cpp:244]     Train net output #0: loss = 0.701693 (* 1 = 0.701693 loss)
I0805 19:48:46.920305 10603 sgd_solver.cpp:106] Iteration 69400, lr = 3.25289e-06
I0805 19:48:50.130897 10603 solver.cpp:337] Iteration 69500, Testing net (#0)
I0805 19:48:53.734647 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 19:48:53.734714 10603 solver.cpp:404]     Test net output #1: loss = 0.693292 (* 1 = 0.693292 loss)
I0805 19:48:53.745036 10603 solver.cpp:228] Iteration 69500, loss = 0.692899
I0805 19:48:53.745064 10603 solver.cpp:244]     Train net output #0: loss = 0.692899 (* 1 = 0.692899 loss)
I0805 19:48:53.745081 10603 sgd_solver.cpp:106] Iteration 69500, lr = 3.25016e-06
I0805 19:48:56.963820 10603 solver.cpp:228] Iteration 69600, loss = 0.692227
I0805 19:48:56.963863 10603 solver.cpp:244]     Train net output #0: loss = 0.692227 (* 1 = 0.692227 loss)
I0805 19:48:56.963870 10603 sgd_solver.cpp:106] Iteration 69600, lr = 3.24744e-06
I0805 19:49:00.196950 10603 solver.cpp:228] Iteration 69700, loss = 0.702123
I0805 19:49:00.196995 10603 solver.cpp:244]     Train net output #0: loss = 0.702123 (* 1 = 0.702123 loss)
I0805 19:49:00.197002 10603 sgd_solver.cpp:106] Iteration 69700, lr = 3.24473e-06
I0805 19:49:03.449534 10603 solver.cpp:228] Iteration 69800, loss = 0.689794
I0805 19:49:03.449579 10603 solver.cpp:244]     Train net output #0: loss = 0.689794 (* 1 = 0.689794 loss)
I0805 19:49:03.449585 10603 sgd_solver.cpp:106] Iteration 69800, lr = 3.24202e-06
I0805 19:49:06.698169 10603 solver.cpp:228] Iteration 69900, loss = 0.697394
I0805 19:49:06.698210 10603 solver.cpp:244]     Train net output #0: loss = 0.697394 (* 1 = 0.697394 loss)
I0805 19:49:06.698216 10603 sgd_solver.cpp:106] Iteration 69900, lr = 3.23931e-06
I0805 19:49:09.905002 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_70000.caffemodel
I0805 19:49:10.275104 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_70000.solverstate
I0805 19:49:10.407568 10603 solver.cpp:337] Iteration 70000, Testing net (#0)
I0805 19:49:13.839262 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207558
I0805 19:49:13.839313 10603 solver.cpp:404]     Test net output #1: loss = 0.693532 (* 1 = 0.693532 loss)
I0805 19:49:13.852248 10603 solver.cpp:228] Iteration 70000, loss = 0.705701
I0805 19:49:13.852283 10603 solver.cpp:244]     Train net output #0: loss = 0.705701 (* 1 = 0.705701 loss)
I0805 19:49:13.852290 10603 sgd_solver.cpp:106] Iteration 70000, lr = 3.23661e-06
I0805 19:49:17.061107 10603 solver.cpp:228] Iteration 70100, loss = 0.693472
I0805 19:49:17.061154 10603 solver.cpp:244]     Train net output #0: loss = 0.693472 (* 1 = 0.693472 loss)
I0805 19:49:17.061161 10603 sgd_solver.cpp:106] Iteration 70100, lr = 3.23392e-06
I0805 19:49:20.317601 10603 solver.cpp:228] Iteration 70200, loss = 0.692827
I0805 19:49:20.317641 10603 solver.cpp:244]     Train net output #0: loss = 0.692827 (* 1 = 0.692827 loss)
I0805 19:49:20.317647 10603 sgd_solver.cpp:106] Iteration 70200, lr = 3.23123e-06
I0805 19:49:23.571501 10603 solver.cpp:228] Iteration 70300, loss = 0.697192
I0805 19:49:23.571544 10603 solver.cpp:244]     Train net output #0: loss = 0.697192 (* 1 = 0.697192 loss)
I0805 19:49:23.571550 10603 sgd_solver.cpp:106] Iteration 70300, lr = 3.22854e-06
I0805 19:49:26.823539 10603 solver.cpp:228] Iteration 70400, loss = 0.702124
I0805 19:49:26.823581 10603 solver.cpp:244]     Train net output #0: loss = 0.702124 (* 1 = 0.702124 loss)
I0805 19:49:26.823587 10603 sgd_solver.cpp:106] Iteration 70400, lr = 3.22586e-06
I0805 19:49:30.044641 10603 solver.cpp:337] Iteration 70500, Testing net (#0)
I0805 19:49:33.708923 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:49:33.708986 10603 solver.cpp:404]     Test net output #1: loss = 0.693213 (* 1 = 0.693213 loss)
I0805 19:49:33.719084 10603 solver.cpp:228] Iteration 70500, loss = 0.689889
I0805 19:49:33.719130 10603 solver.cpp:244]     Train net output #0: loss = 0.689889 (* 1 = 0.689889 loss)
I0805 19:49:33.719138 10603 sgd_solver.cpp:106] Iteration 70500, lr = 3.22319e-06
I0805 19:49:36.912875 10603 solver.cpp:228] Iteration 70600, loss = 0.692614
I0805 19:49:36.912919 10603 solver.cpp:244]     Train net output #0: loss = 0.692614 (* 1 = 0.692614 loss)
I0805 19:49:36.912925 10603 sgd_solver.cpp:106] Iteration 70600, lr = 3.22052e-06
I0805 19:49:40.149869 10603 solver.cpp:228] Iteration 70700, loss = 0.692651
I0805 19:49:40.149914 10603 solver.cpp:244]     Train net output #0: loss = 0.692651 (* 1 = 0.692651 loss)
I0805 19:49:40.149920 10603 sgd_solver.cpp:106] Iteration 70700, lr = 3.21786e-06
I0805 19:49:43.394310 10603 solver.cpp:228] Iteration 70800, loss = 0.693361
I0805 19:49:43.394353 10603 solver.cpp:244]     Train net output #0: loss = 0.693361 (* 1 = 0.693361 loss)
I0805 19:49:43.394359 10603 sgd_solver.cpp:106] Iteration 70800, lr = 3.2152e-06
I0805 19:49:46.642308 10603 solver.cpp:228] Iteration 70900, loss = 0.694247
I0805 19:49:46.642359 10603 solver.cpp:244]     Train net output #0: loss = 0.694247 (* 1 = 0.694247 loss)
I0805 19:49:46.642366 10603 sgd_solver.cpp:106] Iteration 70900, lr = 3.21255e-06
I0805 19:49:49.855221 10603 solver.cpp:337] Iteration 71000, Testing net (#0)
I0805 19:49:53.447325 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208895
I0805 19:49:53.447371 10603 solver.cpp:404]     Test net output #1: loss = 0.693631 (* 1 = 0.693631 loss)
I0805 19:49:53.457487 10603 solver.cpp:228] Iteration 71000, loss = 0.692733
I0805 19:49:53.457525 10603 solver.cpp:244]     Train net output #0: loss = 0.692733 (* 1 = 0.692733 loss)
I0805 19:49:53.457535 10603 sgd_solver.cpp:106] Iteration 71000, lr = 3.2099e-06
I0805 19:49:56.672379 10603 solver.cpp:228] Iteration 71100, loss = 0.691725
I0805 19:49:56.672426 10603 solver.cpp:244]     Train net output #0: loss = 0.691725 (* 1 = 0.691725 loss)
I0805 19:49:56.672432 10603 sgd_solver.cpp:106] Iteration 71100, lr = 3.20726e-06
I0805 19:49:59.896641 10603 solver.cpp:228] Iteration 71200, loss = 0.686503
I0805 19:49:59.896680 10603 solver.cpp:244]     Train net output #0: loss = 0.686503 (* 1 = 0.686503 loss)
I0805 19:49:59.896687 10603 sgd_solver.cpp:106] Iteration 71200, lr = 3.20462e-06
I0805 19:50:03.155736 10603 solver.cpp:228] Iteration 71300, loss = 0.693425
I0805 19:50:03.155784 10603 solver.cpp:244]     Train net output #0: loss = 0.693425 (* 1 = 0.693425 loss)
I0805 19:50:03.155791 10603 sgd_solver.cpp:106] Iteration 71300, lr = 3.20199e-06
I0805 19:50:06.416390 10603 solver.cpp:228] Iteration 71400, loss = 0.701939
I0805 19:50:06.416441 10603 solver.cpp:244]     Train net output #0: loss = 0.701939 (* 1 = 0.701939 loss)
I0805 19:50:06.416451 10603 sgd_solver.cpp:106] Iteration 71400, lr = 3.19936e-06
I0805 19:50:08.078191 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:50:09.646880 10603 solver.cpp:337] Iteration 71500, Testing net (#0)
I0805 19:50:13.342860 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20814
I0805 19:50:13.342921 10603 solver.cpp:404]     Test net output #1: loss = 0.693252 (* 1 = 0.693252 loss)
I0805 19:50:13.356243 10603 solver.cpp:228] Iteration 71500, loss = 0.697591
I0805 19:50:13.356298 10603 solver.cpp:244]     Train net output #0: loss = 0.697591 (* 1 = 0.697591 loss)
I0805 19:50:13.356312 10603 sgd_solver.cpp:106] Iteration 71500, lr = 3.19674e-06
I0805 19:50:16.555789 10603 solver.cpp:228] Iteration 71600, loss = 0.68655
I0805 19:50:16.555841 10603 solver.cpp:244]     Train net output #0: loss = 0.68655 (* 1 = 0.68655 loss)
I0805 19:50:16.555850 10603 sgd_solver.cpp:106] Iteration 71600, lr = 3.19412e-06
I0805 19:50:19.799552 10603 solver.cpp:228] Iteration 71700, loss = 0.691232
I0805 19:50:19.799597 10603 solver.cpp:244]     Train net output #0: loss = 0.691232 (* 1 = 0.691232 loss)
I0805 19:50:19.799603 10603 sgd_solver.cpp:106] Iteration 71700, lr = 3.1915e-06
I0805 19:50:23.038054 10603 solver.cpp:228] Iteration 71800, loss = 0.697438
I0805 19:50:23.038103 10603 solver.cpp:244]     Train net output #0: loss = 0.697438 (* 1 = 0.697438 loss)
I0805 19:50:23.038110 10603 sgd_solver.cpp:106] Iteration 71800, lr = 3.1889e-06
I0805 19:50:26.283560 10603 solver.cpp:228] Iteration 71900, loss = 0.698206
I0805 19:50:26.283598 10603 solver.cpp:244]     Train net output #0: loss = 0.698206 (* 1 = 0.698206 loss)
I0805 19:50:26.283604 10603 sgd_solver.cpp:106] Iteration 71900, lr = 3.18629e-06
I0805 19:50:29.496234 10603 solver.cpp:337] Iteration 72000, Testing net (#0)
I0805 19:50:33.019492 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 19:50:33.019532 10603 solver.cpp:404]     Test net output #1: loss = 0.693362 (* 1 = 0.693362 loss)
I0805 19:50:33.029623 10603 solver.cpp:228] Iteration 72000, loss = 0.693836
I0805 19:50:33.029667 10603 solver.cpp:244]     Train net output #0: loss = 0.693836 (* 1 = 0.693836 loss)
I0805 19:50:33.029675 10603 sgd_solver.cpp:106] Iteration 72000, lr = 3.1837e-06
I0805 19:50:36.248781 10603 solver.cpp:228] Iteration 72100, loss = 0.689553
I0805 19:50:36.248831 10603 solver.cpp:244]     Train net output #0: loss = 0.689553 (* 1 = 0.689553 loss)
I0805 19:50:36.248837 10603 sgd_solver.cpp:106] Iteration 72100, lr = 3.1811e-06
I0805 19:50:39.476977 10603 solver.cpp:228] Iteration 72200, loss = 0.69068
I0805 19:50:39.477015 10603 solver.cpp:244]     Train net output #0: loss = 0.69068 (* 1 = 0.69068 loss)
I0805 19:50:39.477021 10603 sgd_solver.cpp:106] Iteration 72200, lr = 3.17852e-06
I0805 19:50:42.716485 10603 solver.cpp:228] Iteration 72300, loss = 0.700246
I0805 19:50:42.716527 10603 solver.cpp:244]     Train net output #0: loss = 0.700246 (* 1 = 0.700246 loss)
I0805 19:50:42.716533 10603 sgd_solver.cpp:106] Iteration 72300, lr = 3.17593e-06
I0805 19:50:45.960270 10603 solver.cpp:228] Iteration 72400, loss = 0.695785
I0805 19:50:45.960307 10603 solver.cpp:244]     Train net output #0: loss = 0.695785 (* 1 = 0.695785 loss)
I0805 19:50:45.960314 10603 sgd_solver.cpp:106] Iteration 72400, lr = 3.17335e-06
I0805 19:50:49.171264 10603 solver.cpp:337] Iteration 72500, Testing net (#0)
I0805 19:50:52.707231 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:50:52.707286 10603 solver.cpp:404]     Test net output #1: loss = 0.693785 (* 1 = 0.693785 loss)
I0805 19:50:52.717522 10603 solver.cpp:228] Iteration 72500, loss = 0.694118
I0805 19:50:52.717555 10603 solver.cpp:244]     Train net output #0: loss = 0.694118 (* 1 = 0.694118 loss)
I0805 19:50:52.717563 10603 sgd_solver.cpp:106] Iteration 72500, lr = 3.17078e-06
I0805 19:50:55.947257 10603 solver.cpp:228] Iteration 72600, loss = 0.71598
I0805 19:50:55.947296 10603 solver.cpp:244]     Train net output #0: loss = 0.71598 (* 1 = 0.71598 loss)
I0805 19:50:55.947304 10603 sgd_solver.cpp:106] Iteration 72600, lr = 3.16821e-06
I0805 19:50:59.180850 10603 solver.cpp:228] Iteration 72700, loss = 0.683664
I0805 19:50:59.180891 10603 solver.cpp:244]     Train net output #0: loss = 0.683664 (* 1 = 0.683664 loss)
I0805 19:50:59.180897 10603 sgd_solver.cpp:106] Iteration 72700, lr = 3.16565e-06
I0805 19:51:02.438493 10603 solver.cpp:228] Iteration 72800, loss = 0.700336
I0805 19:51:02.438539 10603 solver.cpp:244]     Train net output #0: loss = 0.700336 (* 1 = 0.700336 loss)
I0805 19:51:02.438544 10603 sgd_solver.cpp:106] Iteration 72800, lr = 3.16309e-06
I0805 19:51:05.682790 10603 solver.cpp:228] Iteration 72900, loss = 0.695681
I0805 19:51:05.682826 10603 solver.cpp:244]     Train net output #0: loss = 0.695681 (* 1 = 0.695681 loss)
I0805 19:51:05.682832 10603 sgd_solver.cpp:106] Iteration 72900, lr = 3.16054e-06
I0805 19:51:08.902058 10603 solver.cpp:337] Iteration 73000, Testing net (#0)
I0805 19:51:12.500639 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:51:12.500697 10603 solver.cpp:404]     Test net output #1: loss = 0.693432 (* 1 = 0.693432 loss)
I0805 19:51:12.514323 10603 solver.cpp:228] Iteration 73000, loss = 0.690637
I0805 19:51:12.514389 10603 solver.cpp:244]     Train net output #0: loss = 0.690637 (* 1 = 0.690637 loss)
I0805 19:51:12.514405 10603 sgd_solver.cpp:106] Iteration 73000, lr = 3.15799e-06
I0805 19:51:15.728355 10603 solver.cpp:228] Iteration 73100, loss = 0.685608
I0805 19:51:15.728395 10603 solver.cpp:244]     Train net output #0: loss = 0.685608 (* 1 = 0.685608 loss)
I0805 19:51:15.728402 10603 sgd_solver.cpp:106] Iteration 73100, lr = 3.15544e-06
I0805 19:51:18.948514 10603 solver.cpp:228] Iteration 73200, loss = 0.699702
I0805 19:51:18.948565 10603 solver.cpp:244]     Train net output #0: loss = 0.699702 (* 1 = 0.699702 loss)
I0805 19:51:18.948570 10603 sgd_solver.cpp:106] Iteration 73200, lr = 3.1529e-06
I0805 19:51:22.187779 10603 solver.cpp:228] Iteration 73300, loss = 0.694385
I0805 19:51:22.187822 10603 solver.cpp:244]     Train net output #0: loss = 0.694385 (* 1 = 0.694385 loss)
I0805 19:51:22.187829 10603 sgd_solver.cpp:106] Iteration 73300, lr = 3.15037e-06
nets/person_background_only_alex_net/solver.prototxt
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: I0805 19:51:25.432195 10603 solver.cpp:228] Iteration 73400, loss = 0.688532
I0805 19:51:25.432241 10603 solver.cpp:244]     Train net output #0: loss = 0.688532 (* 1 = 0.688532 loss)
I0805 19:51:25.432247 10603 sgd_solver.cpp:106] Iteration 73400, lr = 3.14784e-06
I0805 19:51:28.645905 10603 solver.cpp:337] Iteration 73500, Testing net (#0)
I0805 19:51:32.177762 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0805 19:51:32.177803 10603 solver.cpp:404]     Test net output #1: loss = 0.692969 (* 1 = 0.692969 loss)
I0805 19:51:32.191318 10603 solver.cpp:228] Iteration 73500, loss = 0.695815
I0805 19:51:32.191385 10603 solver.cpp:244]     Train net output #0: loss = 0.695815 (* 1 = 0.695815 loss)
I0805 19:51:32.191402 10603 sgd_solver.cpp:106] Iteration 73500, lr = 3.14531e-06
I0805 19:51:35.418998 10603 solver.cpp:228] Iteration 73600, loss = 0.699339
I0805 19:51:35.419051 10603 solver.cpp:244]     Train net output #0: loss = 0.699339 (* 1 = 0.699339 loss)
I0805 19:51:35.419059 10603 sgd_solver.cpp:106] Iteration 73600, lr = 3.14279e-06
I0805 19:51:38.660641 10603 solver.cpp:228] Iteration 73700, loss = 0.69766
I0805 19:51:38.660684 10603 solver.cpp:244]     Train net output #0: loss = 0.69766 (* 1 = 0.69766 loss)
I0805 19:51:38.660691 10603 sgd_solver.cpp:106] Iteration 73700, lr = 3.14028e-06
I0805 19:51:41.920514 10603 solver.cpp:228] Iteration 73800, loss = 0.690542
I0805 19:51:41.920562 10603 solver.cpp:244]     Train net output #0: loss = 0.690542 (* 1 = 0.690542 loss)
I0805 19:51:41.920570 10603 sgd_solver.cpp:106] Iteration 73800, lr = 3.13776e-06
I0805 19:51:45.180738 10603 solver.cpp:228] Iteration 73900, loss = 0.689292
I0805 19:51:45.180775 10603 solver.cpp:244]     Train net output #0: loss = 0.689292 (* 1 = 0.689292 loss)
I0805 19:51:45.180781 10603 sgd_solver.cpp:106] Iteration 73900, lr = 3.13526e-06
I0805 19:51:48.408892 10603 solver.cpp:337] Iteration 74000, Testing net (#0)
I0805 19:51:49.246410 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:51:51.923919 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 19:51:51.923979 10603 solver.cpp:404]     Test net output #1: loss = 0.693539 (* 1 = 0.693539 loss)
I0805 19:51:51.937849 10603 solver.cpp:228] Iteration 74000, loss = 0.694811
I0805 19:51:51.937916 10603 solver.cpp:244]     Train net output #0: loss = 0.694811 (* 1 = 0.694811 loss)
I0805 19:51:51.937935 10603 sgd_solver.cpp:106] Iteration 74000, lr = 3.13276e-06
I0805 19:51:55.154474 10603 solver.cpp:228] Iteration 74100, loss = 0.689563
I0805 19:51:55.154525 10603 solver.cpp:244]     Train net output #0: loss = 0.689563 (* 1 = 0.689563 loss)
I0805 19:51:55.154541 10603 sgd_solver.cpp:106] Iteration 74100, lr = 3.13026e-06
I0805 19:51:58.371970 10603 solver.cpp:228] Iteration 74200, loss = 0.69024
I0805 19:51:58.372009 10603 solver.cpp:244]     Train net output #0: loss = 0.69024 (* 1 = 0.69024 loss)
I0805 19:51:58.372015 10603 sgd_solver.cpp:106] Iteration 74200, lr = 3.12777e-06
I0805 19:52:01.614017 10603 solver.cpp:228] Iteration 74300, loss = 0.69661
I0805 19:52:01.614058 10603 solver.cpp:244]     Train net output #0: loss = 0.69661 (* 1 = 0.69661 loss)
I0805 19:52:01.614065 10603 sgd_solver.cpp:106] Iteration 74300, lr = 3.12528e-06
I0805 19:52:04.856547 10603 solver.cpp:228] Iteration 74400, loss = 0.69525
I0805 19:52:04.856590 10603 solver.cpp:244]     Train net output #0: loss = 0.69525 (* 1 = 0.69525 loss)
I0805 19:52:04.856597 10603 sgd_solver.cpp:106] Iteration 74400, lr = 3.1228e-06
I0805 19:52:08.068065 10603 solver.cpp:337] Iteration 74500, Testing net (#0)
I0805 19:52:11.676383 10603 solver.cpp:404]     Test net output #0: accuracy = 0.209128
I0805 19:52:11.676425 10603 solver.cpp:404]     Test net output #1: loss = 0.693878 (* 1 = 0.693878 loss)
I0805 19:52:11.690098 10603 solver.cpp:228] Iteration 74500, loss = 0.688814
I0805 19:52:11.690158 10603 solver.cpp:244]     Train net output #0: loss = 0.688814 (* 1 = 0.688814 loss)
I0805 19:52:11.690176 10603 sgd_solver.cpp:106] Iteration 74500, lr = 3.12032e-06
I0805 19:52:14.923002 10603 solver.cpp:228] Iteration 74600, loss = 0.690595
I0805 19:52:14.923054 10603 solver.cpp:244]     Train net output #0: loss = 0.690595 (* 1 = 0.690595 loss)
I0805 19:52:14.923060 10603 sgd_solver.cpp:106] Iteration 74600, lr = 3.11784e-06
I0805 19:52:18.164093 10603 solver.cpp:228] Iteration 74700, loss = 0.701938
I0805 19:52:18.164135 10603 solver.cpp:244]     Train net output #0: loss = 0.701938 (* 1 = 0.701938 loss)
I0805 19:52:18.164142 10603 sgd_solver.cpp:106] Iteration 74700, lr = 3.11537e-06
I0805 19:52:21.406373 10603 solver.cpp:228] Iteration 74800, loss = 0.700892
I0805 19:52:21.406417 10603 solver.cpp:244]     Train net output #0: loss = 0.700892 (* 1 = 0.700892 loss)
I0805 19:52:21.406424 10603 sgd_solver.cpp:106] Iteration 74800, lr = 3.11291e-06
I0805 19:52:24.648927 10603 solver.cpp:228] Iteration 74900, loss = 0.693113
I0805 19:52:24.648968 10603 solver.cpp:244]     Train net output #0: loss = 0.693113 (* 1 = 0.693113 loss)
I0805 19:52:24.648974 10603 sgd_solver.cpp:106] Iteration 74900, lr = 3.11045e-06
I0805 19:52:27.858265 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_75000.caffemodel
I0805 19:52:28.247831 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_75000.solverstate
I0805 19:52:28.390450 10603 solver.cpp:337] Iteration 75000, Testing net (#0)
I0805 19:52:31.903846 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 19:52:31.903889 10603 solver.cpp:404]     Test net output #1: loss = 0.693292 (* 1 = 0.693292 loss)
I0805 19:52:31.916751 10603 solver.cpp:228] Iteration 75000, loss = 0.696874
I0805 19:52:31.916806 10603 solver.cpp:244]     Train net output #0: loss = 0.696874 (* 1 = 0.696874 loss)
I0805 19:52:31.916815 10603 sgd_solver.cpp:106] Iteration 75000, lr = 3.10799e-06
I0805 19:52:35.118891 10603 solver.cpp:228] Iteration 75100, loss = 0.695485
I0805 19:52:35.118930 10603 solver.cpp:244]     Train net output #0: loss = 0.695485 (* 1 = 0.695485 loss)
I0805 19:52:35.118937 10603 sgd_solver.cpp:106] Iteration 75100, lr = 3.10554e-06
I0805 19:52:38.371280 10603 solver.cpp:228] Iteration 75200, loss = 0.695788
I0805 19:52:38.371320 10603 solver.cpp:244]     Train net output #0: loss = 0.695788 (* 1 = 0.695788 loss)
I0805 19:52:38.371326 10603 sgd_solver.cpp:106] Iteration 75200, lr = 3.10309e-06
I0805 19:52:41.622668 10603 solver.cpp:228] Iteration 75300, loss = 0.68201
I0805 19:52:41.622714 10603 solver.cpp:244]     Train net output #0: loss = 0.68201 (* 1 = 0.68201 loss)
I0805 19:52:41.622720 10603 sgd_solver.cpp:106] Iteration 75300, lr = 3.10065e-06
I0805 19:52:44.872764 10603 solver.cpp:228] Iteration 75400, loss = 0.682069
I0805 19:52:44.872810 10603 solver.cpp:244]     Train net output #0: loss = 0.682069 (* 1 = 0.682069 loss)
I0805 19:52:44.872818 10603 sgd_solver.cpp:106] Iteration 75400, lr = 3.09821e-06
I0805 19:52:48.100107 10603 solver.cpp:337] Iteration 75500, Testing net (#0)
I0805 19:52:51.639670 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:52:51.639734 10603 solver.cpp:404]     Test net output #1: loss = 0.693534 (* 1 = 0.693534 loss)
I0805 19:52:51.653532 10603 solver.cpp:228] Iteration 75500, loss = 0.693314
I0805 19:52:51.653595 10603 solver.cpp:244]     Train net output #0: loss = 0.693314 (* 1 = 0.693314 loss)
I0805 19:52:51.653612 10603 sgd_solver.cpp:106] Iteration 75500, lr = 3.09578e-06
I0805 19:52:54.883023 10603 solver.cpp:228] Iteration 75600, loss = 0.689042
I0805 19:52:54.883077 10603 solver.cpp:244]     Train net output #0: loss = 0.689042 (* 1 = 0.689042 loss)
I0805 19:52:54.883083 10603 sgd_solver.cpp:106] Iteration 75600, lr = 3.09335e-06
I0805 19:52:58.115569 10603 solver.cpp:228] Iteration 75700, loss = 0.686931
I0805 19:52:58.115620 10603 solver.cpp:244]     Train net output #0: loss = 0.686931 (* 1 = 0.686931 loss)
I0805 19:52:58.115628 10603 sgd_solver.cpp:106] Iteration 75700, lr = 3.09093e-06
I0805 19:53:01.356676 10603 solver.cpp:228] Iteration 75800, loss = 0.689284
I0805 19:53:01.356737 10603 solver.cpp:244]     Train net output #0: loss = 0.689284 (* 1 = 0.689284 loss)
I0805 19:53:01.356771 10603 sgd_solver.cpp:106] Iteration 75800, lr = 3.08851e-06
I0805 19:53:04.601687 10603 solver.cpp:228] Iteration 75900, loss = 0.707831
I0805 19:53:04.601740 10603 solver.cpp:244]     Train net output #0: loss = 0.707831 (* 1 = 0.707831 loss)
I0805 19:53:04.601750 10603 sgd_solver.cpp:106] Iteration 75900, lr = 3.08609e-06
I0805 19:53:07.807751 10603 solver.cpp:337] Iteration 76000, Testing net (#0)
I0805 19:53:11.634531 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:53:11.634574 10603 solver.cpp:404]     Test net output #1: loss = 0.693466 (* 1 = 0.693466 loss)
I0805 19:53:11.647466 10603 solver.cpp:228] Iteration 76000, loss = 0.691988
I0805 19:53:11.647548 10603 solver.cpp:244]     Train net output #0: loss = 0.691988 (* 1 = 0.691988 loss)
I0805 19:53:11.647565 10603 sgd_solver.cpp:106] Iteration 76000, lr = 3.08368e-06
I0805 19:53:14.844781 10603 solver.cpp:228] Iteration 76100, loss = 0.699478
I0805 19:53:14.844858 10603 solver.cpp:244]     Train net output #0: loss = 0.699478 (* 1 = 0.699478 loss)
I0805 19:53:14.844866 10603 sgd_solver.cpp:106] Iteration 76100, lr = 3.08127e-06
I0805 19:53:18.078728 10603 solver.cpp:228] Iteration 76200, loss = 0.702361
I0805 19:53:18.078768 10603 solver.cpp:244]     Train net output #0: loss = 0.702361 (* 1 = 0.702361 loss)
I0805 19:53:18.078773 10603 sgd_solver.cpp:106] Iteration 76200, lr = 3.07887e-06
I0805 19:53:20.855088 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:53:21.342872 10603 solver.cpp:228] Iteration 76300, loss = 0.685154
I0805 19:53:21.342902 10603 solver.cpp:244]     Train net output #0: loss = 0.685154 (* 1 = 0.685154 loss)
I0805 19:53:21.342908 10603 sgd_solver.cpp:106] Iteration 76300, lr = 3.07647e-06
I0805 19:53:24.604327 10603 solver.cpp:228] Iteration 76400, loss = 0.685494
I0805 19:53:24.604367 10603 solver.cpp:244]     Train net output #0: loss = 0.685494 (* 1 = 0.685494 loss)
I0805 19:53:24.604373 10603 sgd_solver.cpp:106] Iteration 76400, lr = 3.07408e-06
I0805 19:53:27.835862 10603 solver.cpp:337] Iteration 76500, Testing net (#0)
I0805 19:53:31.448549 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 19:53:31.448595 10603 solver.cpp:404]     Test net output #1: loss = 0.693721 (* 1 = 0.693721 loss)
I0805 19:53:31.462081 10603 solver.cpp:228] Iteration 76500, loss = 0.695301
I0805 19:53:31.462146 10603 solver.cpp:244]     Train net output #0: loss = 0.695301 (* 1 = 0.695301 loss)
I0805 19:53:31.462162 10603 sgd_solver.cpp:106] Iteration 76500, lr = 3.07169e-06
I0805 19:53:34.678730 10603 solver.cpp:228] Iteration 76600, loss = 0.679289
I0805 19:53:34.678777 10603 solver.cpp:244]     Train net output #0: loss = 0.679289 (* 1 = 0.679289 loss)
I0805 19:53:34.678783 10603 sgd_solver.cpp:106] Iteration 76600, lr = 3.0693e-06
I0805 19:53:37.921831 10603 solver.cpp:228] Iteration 76700, loss = 0.696526
I0805 19:53:37.921875 10603 solver.cpp:244]     Train net output #0: loss = 0.696526 (* 1 = 0.696526 loss)
I0805 19:53:37.921880 10603 sgd_solver.cpp:106] Iteration 76700, lr = 3.06692e-06
I0805 19:53:41.170550 10603 solver.cpp:228] Iteration 76800, loss = 0.692238
I0805 19:53:41.170598 10603 solver.cpp:244]     Train net output #0: loss = 0.692238 (* 1 = 0.692238 loss)
I0805 19:53:41.170604 10603 sgd_solver.cpp:106] Iteration 76800, lr = 3.06454e-06
I0805 19:53:44.411825 10603 solver.cpp:228] Iteration 76900, loss = 0.686657
I0805 19:53:44.411864 10603 solver.cpp:244]     Train net output #0: loss = 0.686657 (* 1 = 0.686657 loss)
I0805 19:53:44.411870 10603 sgd_solver.cpp:106] Iteration 76900, lr = 3.06217e-06
I0805 19:53:47.627286 10603 solver.cpp:337] Iteration 77000, Testing net (#0)
I0805 19:53:51.177858 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208081
I0805 19:53:51.177913 10603 solver.cpp:404]     Test net output #1: loss = 0.693416 (* 1 = 0.693416 loss)
I0805 19:53:51.191222 10603 solver.cpp:228] Iteration 77000, loss = 0.695281
I0805 19:53:51.191257 10603 solver.cpp:244]     Train net output #0: loss = 0.695281 (* 1 = 0.695281 loss)
I0805 19:53:51.191267 10603 sgd_solver.cpp:106] Iteration 77000, lr = 3.0598e-06
I0805 19:53:54.413426 10603 solver.cpp:228] Iteration 77100, loss = 0.697298
I0805 19:53:54.413473 10603 solver.cpp:244]     Train net output #0: loss = 0.697298 (* 1 = 0.697298 loss)
I0805 19:53:54.413480 10603 sgd_solver.cpp:106] Iteration 77100, lr = 3.05744e-06
I0805 19:53:57.629091 10603 solver.cpp:228] Iteration 77200, loss = 0.698182
I0805 19:53:57.629130 10603 solver.cpp:244]     Train net output #0: loss = 0.698182 (* 1 = 0.698182 loss)
I0805 19:53:57.629137 10603 sgd_solver.cpp:106] Iteration 77200, lr = 3.05508e-06
I0805 19:54:00.876377 10603 solver.cpp:228] Iteration 77300, loss = 0.688436
I0805 19:54:00.876421 10603 solver.cpp:244]     Train net output #0: loss = 0.688436 (* 1 = 0.688436 loss)
I0805 19:54:00.876427 10603 sgd_solver.cpp:106] Iteration 77300, lr = 3.05273e-06
I0805 19:54:04.128676 10603 solver.cpp:228] Iteration 77400, loss = 0.696224
I0805 19:54:04.128718 10603 solver.cpp:244]     Train net output #0: loss = 0.696224 (* 1 = 0.696224 loss)
I0805 19:54:04.128725 10603 sgd_solver.cpp:106] Iteration 77400, lr = 3.05038e-06
I0805 19:54:07.344691 10603 solver.cpp:337] Iteration 77500, Testing net (#0)
I0805 19:54:10.849318 10603 solver.cpp:404]     Test net output #0: accuracy = 0.209011
I0805 19:54:10.849357 10603 solver.cpp:404]     Test net output #1: loss = 0.693471 (* 1 = 0.693471 loss)
I0805 19:54:10.860270 10603 solver.cpp:228] Iteration 77500, loss = 0.697793
I0805 19:54:10.860339 10603 solver.cpp:244]     Train net output #0: loss = 0.697793 (* 1 = 0.697793 loss)
I0805 19:54:10.860357 10603 sgd_solver.cpp:106] Iteration 77500, lr = 3.04803e-06
I0805 19:54:14.083530 10603 solver.cpp:228] Iteration 77600, loss = 0.690529
I0805 19:54:14.083575 10603 solver.cpp:244]     Train net output #0: loss = 0.690529 (* 1 = 0.690529 loss)
I0805 19:54:14.083581 10603 sgd_solver.cpp:106] Iteration 77600, lr = 3.04569e-06
I0805 19:54:17.335261 10603 solver.cpp:228] Iteration 77700, loss = 0.693801
I0805 19:54:17.335302 10603 solver.cpp:244]     Train net output #0: loss = 0.693801 (* 1 = 0.693801 loss)
I0805 19:54:17.335309 10603 sgd_solver.cpp:106] Iteration 77700, lr = 3.04335e-06
I0805 19:54:20.589167 10603 solver.cpp:228] Iteration 77800, loss = 0.694757
I0805 19:54:20.589208 10603 solver.cpp:244]     Train net output #0: loss = 0.694757 (* 1 = 0.694757 loss)
I0805 19:54:20.589215 10603 sgd_solver.cpp:106] Iteration 77800, lr = 3.04101e-06
I0805 19:54:23.842859 10603 solver.cpp:228] Iteration 77900, loss = 0.692635
I0805 19:54:23.842905 10603 solver.cpp:244]     Train net output #0: loss = 0.692635 (* 1 = 0.692635 loss)
I0805 19:54:23.842911 10603 sgd_solver.cpp:106] Iteration 77900, lr = 3.03868e-06
I0805 19:54:27.068923 10603 solver.cpp:337] Iteration 78000, Testing net (#0)
I0805 19:54:30.619741 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208488
I0805 19:54:30.619783 10603 solver.cpp:404]     Test net output #1: loss = 0.693216 (* 1 = 0.693216 loss)
I0805 19:54:30.630635 10603 solver.cpp:228] Iteration 78000, loss = 0.705873
I0805 19:54:30.630707 10603 solver.cpp:244]     Train net output #0: loss = 0.705873 (* 1 = 0.705873 loss)
I0805 19:54:30.630723 10603 sgd_solver.cpp:106] Iteration 78000, lr = 3.03636e-06
I0805 19:54:33.874635 10603 solver.cpp:228] Iteration 78100, loss = 0.684587
I0805 19:54:33.874680 10603 solver.cpp:244]     Train net output #0: loss = 0.684587 (* 1 = 0.684587 loss)
I0805 19:54:33.874686 10603 sgd_solver.cpp:106] Iteration 78100, lr = 3.03404e-06
I0805 19:54:37.125432 10603 solver.cpp:228] Iteration 78200, loss = 0.688609
I0805 19:54:37.125478 10603 solver.cpp:244]     Train net output #0: loss = 0.688609 (* 1 = 0.688609 loss)
I0805 19:54:37.125484 10603 sgd_solver.cpp:106] Iteration 78200, lr = 3.03172e-06
I0805 19:54:40.369720 10603 solver.cpp:228] Iteration 78300, loss = 0.688473
I0805 19:54:40.369766 10603 solver.cpp:244]     Train net output #0: loss = 0.688473 (* 1 = 0.688473 loss)
I0805 19:54:40.369772 10603 sgd_solver.cpp:106] Iteration 78300, lr = 3.0294e-06
I0805 19:54:43.612869 10603 solver.cpp:228] Iteration 78400, loss = 0.699621
I0805 19:54:43.612910 10603 solver.cpp:244]     Train net output #0: loss = 0.699621 (* 1 = 0.699621 loss)
I0805 19:54:43.612915 10603 sgd_solver.cpp:106] Iteration 78400, lr = 3.0271e-06
I0805 19:54:46.823889 10603 solver.cpp:337] Iteration 78500, Testing net (#0)
I0805 19:54:50.517876 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 19:54:50.517925 10603 solver.cpp:404]     Test net output #1: loss = 0.693428 (* 1 = 0.693428 loss)
I0805 19:54:50.528532 10603 solver.cpp:228] Iteration 78500, loss = 0.698805
I0805 19:54:50.528604 10603 solver.cpp:244]     Train net output #0: loss = 0.698805 (* 1 = 0.698805 loss)
I0805 19:54:50.528621 10603 sgd_solver.cpp:106] Iteration 78500, lr = 3.02479e-06
I0805 19:54:53.734912 10603 solver.cpp:228] Iteration 78600, loss = 0.68849
I0805 19:54:53.734956 10603 solver.cpp:244]     Train net output #0: loss = 0.68849 (* 1 = 0.68849 loss)
I0805 19:54:53.734961 10603 sgd_solver.cpp:106] Iteration 78600, lr = 3.02249e-06
I0805 19:54:56.966652 10603 solver.cpp:228] Iteration 78700, loss = 0.695987
I0805 19:54:56.966692 10603 solver.cpp:244]     Train net output #0: loss = 0.695987 (* 1 = 0.695987 loss)
I0805 19:54:56.966698 10603 sgd_solver.cpp:106] Iteration 78700, lr = 3.02019e-06
I0805 19:55:00.227110 10603 solver.cpp:228] Iteration 78800, loss = 0.68944
I0805 19:55:00.227164 10603 solver.cpp:244]     Train net output #0: loss = 0.68944 (* 1 = 0.68944 loss)
I0805 19:55:00.227169 10603 sgd_solver.cpp:106] Iteration 78800, lr = 3.0179e-06
I0805 19:55:00.292923 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:55:03.493041 10603 solver.cpp:228] Iteration 78900, loss = 0.693992
I0805 19:55:03.493085 10603 solver.cpp:244]     Train net output #0: loss = 0.693992 (* 1 = 0.693992 loss)
I0805 19:55:03.493093 10603 sgd_solver.cpp:106] Iteration 78900, lr = 3.01561e-06
I0805 19:55:06.724644 10603 solver.cpp:337] Iteration 79000, Testing net (#0)
I0805 19:55:10.247745 10603 solver.cpp:404]     Test net output #0: accuracy = 0.463256
I0805 19:55:10.247786 10603 solver.cpp:404]     Test net output #1: loss = 0.69315 (* 1 = 0.69315 loss)
I0805 19:55:10.257880 10603 solver.cpp:228] Iteration 79000, loss = 0.690921
I0805 19:55:10.257899 10603 solver.cpp:244]     Train net output #0: loss = 0.690921 (* 1 = 0.690921 loss)
I0805 19:55:10.257905 10603 sgd_solver.cpp:106] Iteration 79000, lr = 3.01333e-06
I0805 19:55:13.484328 10603 solver.cpp:228] Iteration 79100, loss = 0.697456
I0805 19:55:13.484376 10603 solver.cpp:244]     Train net output #0: loss = 0.697456 (* 1 = 0.697456 loss)
I0805 19:55:13.484382 10603 sgd_solver.cpp:106] Iteration 79100, lr = 3.01105e-06
I0805 19:55:16.725319 10603 solver.cpp:228] Iteration 79200, loss = 0.699348
I0805 19:55:16.725368 10603 solver.cpp:244]     Train net output #0: loss = 0.699348 (* 1 = 0.699348 loss)
I0805 19:55:16.725378 10603 sgd_solver.cpp:106] Iteration 79200, lr = 3.00877e-06
I0805 19:55:19.967553 10603 solver.cpp:228] Iteration 79300, loss = 0.68856
I0805 19:55:19.967598 10603 solver.cpp:244]     Train net output #0: loss = 0.68856 (* 1 = 0.68856 loss)
I0805 19:55:19.967605 10603 sgd_solver.cpp:106] Iteration 79300, lr = 3.0065e-06
I0805 19:55:23.208098 10603 solver.cpp:228] Iteration 79400, loss = 0.684935
I0805 19:55:23.208143 10603 solver.cpp:244]     Train net output #0: loss = 0.684935 (* 1 = 0.684935 loss)
I0805 19:55:23.208153 10603 sgd_solver.cpp:106] Iteration 79400, lr = 3.00423e-06
I0805 19:55:26.416120 10603 solver.cpp:337] Iteration 79500, Testing net (#0)
I0805 19:55:29.949692 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 19:55:29.949746 10603 solver.cpp:404]     Test net output #1: loss = 0.693324 (* 1 = 0.693324 loss)
I0805 19:55:29.960511 10603 solver.cpp:228] Iteration 79500, loss = 0.702597
I0805 19:55:29.960582 10603 solver.cpp:244]     Train net output #0: loss = 0.702597 (* 1 = 0.702597 loss)
I0805 19:55:29.960602 10603 sgd_solver.cpp:106] Iteration 79500, lr = 3.00196e-06
I0805 19:55:33.205765 10603 solver.cpp:228] Iteration 79600, loss = 0.693112
I0805 19:55:33.205821 10603 solver.cpp:244]     Train net output #0: loss = 0.693112 (* 1 = 0.693112 loss)
I0805 19:55:33.205826 10603 sgd_solver.cpp:106] Iteration 79600, lr = 2.9997e-06
I0805 19:55:36.450937 10603 solver.cpp:228] Iteration 79700, loss = 0.689105
I0805 19:55:36.450984 10603 solver.cpp:244]     Train net output #0: loss = 0.689105 (* 1 = 0.689105 loss)
I0805 19:55:36.450990 10603 sgd_solver.cpp:106] Iteration 79700, lr = 2.99744e-06
I0805 19:55:39.704787 10603 solver.cpp:228] Iteration 79800, loss = 0.694955
I0805 19:55:39.704835 10603 solver.cpp:244]     Train net output #0: loss = 0.694955 (* 1 = 0.694955 loss)
I0805 19:55:39.704843 10603 sgd_solver.cpp:106] Iteration 79800, lr = 2.99519e-06
I0805 19:55:42.946310 10603 solver.cpp:228] Iteration 79900, loss = 0.686697
I0805 19:55:42.946359 10603 solver.cpp:244]     Train net output #0: loss = 0.686697 (* 1 = 0.686697 loss)
I0805 19:55:42.946367 10603 sgd_solver.cpp:106] Iteration 79900, lr = 2.99294e-06
I0805 19:55:46.164283 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_80000.caffemodel
I0805 19:55:46.541142 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_80000.solverstate
I0805 19:55:46.676240 10603 solver.cpp:337] Iteration 80000, Testing net (#0)
I0805 19:55:50.166204 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:55:50.166244 10603 solver.cpp:404]     Test net output #1: loss = 0.693651 (* 1 = 0.693651 loss)
I0805 19:55:50.179585 10603 solver.cpp:228] Iteration 80000, loss = 0.692606
I0805 19:55:50.179662 10603 solver.cpp:244]     Train net output #0: loss = 0.692606 (* 1 = 0.692606 loss)
I0805 19:55:50.179679 10603 sgd_solver.cpp:106] Iteration 80000, lr = 2.9907e-06
I0805 19:55:53.371275 10603 solver.cpp:228] Iteration 80100, loss = 0.68933
I0805 19:55:53.371318 10603 solver.cpp:244]     Train net output #0: loss = 0.68933 (* 1 = 0.68933 loss)
I0805 19:55:53.371325 10603 sgd_solver.cpp:106] Iteration 80100, lr = 2.98846e-06
I0805 19:55:56.604641 10603 solver.cpp:228] Iteration 80200, loss = 0.693722
I0805 19:55:56.604686 10603 solver.cpp:244]     Train net output #0: loss = 0.693722 (* 1 = 0.693722 loss)
I0805 19:55:56.604692 10603 sgd_solver.cpp:106] Iteration 80200, lr = 2.98622e-06
I0805 19:55:59.857934 10603 solver.cpp:228] Iteration 80300, loss = 0.693272
I0805 19:55:59.857991 10603 solver.cpp:244]     Train net output #0: loss = 0.693272 (* 1 = 0.693272 loss)
I0805 19:55:59.857998 10603 sgd_solver.cpp:106] Iteration 80300, lr = 2.98399e-06
I0805 19:56:03.110865 10603 solver.cpp:228] Iteration 80400, loss = 0.688613
I0805 19:56:03.110905 10603 solver.cpp:244]     Train net output #0: loss = 0.688613 (* 1 = 0.688613 loss)
I0805 19:56:03.110911 10603 sgd_solver.cpp:106] Iteration 80400, lr = 2.98176e-06
I0805 19:56:06.336079 10603 solver.cpp:337] Iteration 80500, Testing net (#0)
I0805 19:56:09.859024 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 19:56:09.859077 10603 solver.cpp:404]     Test net output #1: loss = 0.693293 (* 1 = 0.693293 loss)
I0805 19:56:09.869812 10603 solver.cpp:228] Iteration 80500, loss = 0.690906
I0805 19:56:09.869891 10603 solver.cpp:244]     Train net output #0: loss = 0.690906 (* 1 = 0.690906 loss)
I0805 19:56:09.869907 10603 sgd_solver.cpp:106] Iteration 80500, lr = 2.97953e-06
I0805 19:56:13.083940 10603 solver.cpp:228] Iteration 80600, loss = 0.698667
I0805 19:56:13.083988 10603 solver.cpp:244]     Train net output #0: loss = 0.698667 (* 1 = 0.698667 loss)
I0805 19:56:13.083995 10603 sgd_solver.cpp:106] Iteration 80600, lr = 2.97731e-06
I0805 19:56:16.308806 10603 solver.cpp:228] Iteration 80700, loss = 0.684347
I0805 19:56:16.308851 10603 solver.cpp:244]     Train net output #0: loss = 0.684347 (* 1 = 0.684347 loss)
I0805 19:56:16.308856 10603 sgd_solver.cpp:106] Iteration 80700, lr = 2.97509e-06
I0805 19:56:19.574092 10603 solver.cpp:228] Iteration 80800, loss = 0.694506
I0805 19:56:19.574136 10603 solver.cpp:244]     Train net output #0: loss = 0.694506 (* 1 = 0.694506 loss)
I0805 19:56:19.574143 10603 sgd_solver.cpp:106] Iteration 80800, lr = 2.97288e-06
I0805 19:56:22.840240 10603 solver.cpp:228] Iteration 80900, loss = 0.700369
I0805 19:56:22.840281 10603 solver.cpp:244]     Train net output #0: loss = 0.700369 (* 1 = 0.700369 loss)
I0805 19:56:22.840286 10603 sgd_solver.cpp:106] Iteration 80900, lr = 2.97067e-06
I0805 19:56:26.076941 10603 solver.cpp:337] Iteration 81000, Testing net (#0)
I0805 19:56:29.592649 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 19:56:29.592694 10603 solver.cpp:404]     Test net output #1: loss = 0.693187 (* 1 = 0.693187 loss)
I0805 19:56:29.605653 10603 solver.cpp:228] Iteration 81000, loss = 0.692314
I0805 19:56:29.605682 10603 solver.cpp:244]     Train net output #0: loss = 0.692314 (* 1 = 0.692314 loss)
I0805 19:56:29.605690 10603 sgd_solver.cpp:106] Iteration 81000, lr = 2.96846e-06
I0805 19:56:32.850615 10603 solver.cpp:228] Iteration 81100, loss = 0.693041
I0805 19:56:32.850662 10603 solver.cpp:244]     Train net output #0: loss = 0.693041 (* 1 = 0.693041 loss)
I0805 19:56:32.850672 10603 sgd_solver.cpp:106] Iteration 81100, lr = 2.96626e-06
I0805 19:56:36.109407 10603 solver.cpp:228] Iteration 81200, loss = 0.691519
I0805 19:56:36.109447 10603 solver.cpp:244]     Train net output #0: loss = 0.691519 (* 1 = 0.691519 loss)
I0805 19:56:36.109453 10603 sgd_solver.cpp:106] Iteration 81200, lr = 2.96406e-06
I0805 19:56:39.370858 10603 solver.cpp:228] Iteration 81300, loss = 0.696373
I0805 19:56:39.370905 10603 solver.cpp:244]     Train net output #0: loss = 0.696373 (* 1 = 0.696373 loss)
I0805 19:56:39.370913 10603 sgd_solver.cpp:106] Iteration 81300, lr = 2.96187e-06
I0805 19:56:42.626374 10603 solver.cpp:228] Iteration 81400, loss = 0.689472
I0805 19:56:42.626417 10603 solver.cpp:244]     Train net output #0: loss = 0.689472 (* 1 = 0.689472 loss)
I0805 19:56:42.626423 10603 sgd_solver.cpp:106] Iteration 81400, lr = 2.95968e-06
I0805 19:56:45.859007 10603 solver.cpp:337] Iteration 81500, Testing net (#0)
I0805 19:56:46.504897 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:56:49.374347 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:56:49.374384 10603 solver.cpp:404]     Test net output #1: loss = 0.693581 (* 1 = 0.693581 loss)
I0805 19:56:49.384558 10603 solver.cpp:228] Iteration 81500, loss = 0.691034
I0805 19:56:49.384588 10603 solver.cpp:244]     Train net output #0: loss = 0.691034 (* 1 = 0.691034 loss)
I0805 19:56:49.384595 10603 sgd_solver.cpp:106] Iteration 81500, lr = 2.95749e-06
I0805 19:56:52.612172 10603 solver.cpp:228] Iteration 81600, loss = 0.690419
I0805 19:56:52.612217 10603 solver.cpp:244]     Train net output #0: loss = 0.690419 (* 1 = 0.690419 loss)
I0805 19:56:52.612223 10603 sgd_solver.cpp:106] Iteration 81600, lr = 2.9553e-06
I0805 19:56:55.857283 10603 solver.cpp:228] Iteration 81700, loss = 0.696995
I0805 19:56:55.857342 10603 solver.cpp:244]     Train net output #0: loss = 0.696995 (* 1 = 0.696995 loss)
I0805 19:56:55.857348 10603 sgd_solver.cpp:106] Iteration 81700, lr = 2.95312e-06
I0805 19:56:59.092716 10603 solver.cpp:228] Iteration 81800, loss = 0.677858
I0805 19:56:59.092759 10603 solver.cpp:244]     Train net output #0: loss = 0.677858 (* 1 = 0.677858 loss)
I0805 19:56:59.092767 10603 sgd_solver.cpp:106] Iteration 81800, lr = 2.95095e-06
I0805 19:57:02.332890 10603 solver.cpp:228] Iteration 81900, loss = 0.690358
I0805 19:57:02.332942 10603 solver.cpp:244]     Train net output #0: loss = 0.690358 (* 1 = 0.690358 loss)
I0805 19:57:02.332949 10603 sgd_solver.cpp:106] Iteration 81900, lr = 2.94878e-06
I0805 19:57:05.544803 10603 solver.cpp:337] Iteration 82000, Testing net (#0)
I0805 19:57:09.402848 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208779
I0805 19:57:09.402889 10603 solver.cpp:404]     Test net output #1: loss = 0.693862 (* 1 = 0.693862 loss)
I0805 19:57:09.415704 10603 solver.cpp:228] Iteration 82000, loss = 0.685011
I0805 19:57:09.415722 10603 solver.cpp:244]     Train net output #0: loss = 0.685011 (* 1 = 0.685011 loss)
I0805 19:57:09.415729 10603 sgd_solver.cpp:106] Iteration 82000, lr = 2.94661e-06
I0805 19:57:12.593924 10603 solver.cpp:228] Iteration 82100, loss = 0.699096
I0805 19:57:12.593969 10603 solver.cpp:244]     Train net output #0: loss = 0.699096 (* 1 = 0.699096 loss)
I0805 19:57:12.593982 10603 sgd_solver.cpp:106] Iteration 82100, lr = 2.94444e-06
I0805 19:57:15.828991 10603 solver.cpp:228] Iteration 82200, loss = 0.696172
I0805 19:57:15.829027 10603 solver.cpp:244]     Train net output #0: loss = 0.696172 (* 1 = 0.696172 loss)
I0805 19:57:15.829033 10603 sgd_solver.cpp:106] Iteration 82200, lr = 2.94228e-06
I0805 19:57:19.076102 10603 solver.cpp:228] Iteration 82300, loss = 0.689131
I0805 19:57:19.076146 10603 solver.cpp:244]     Train net output #0: loss = 0.689131 (* 1 = 0.689131 loss)
I0805 19:57:19.076153 10603 sgd_solver.cpp:106] Iteration 82300, lr = 2.94012e-06
I0805 19:57:22.312551 10603 solver.cpp:228] Iteration 82400, loss = 0.689281
I0805 19:57:22.312597 10603 solver.cpp:244]     Train net output #0: loss = 0.689281 (* 1 = 0.689281 loss)
I0805 19:57:22.312602 10603 sgd_solver.cpp:106] Iteration 82400, lr = 2.93797e-06
I0805 19:57:25.533259 10603 solver.cpp:337] Iteration 82500, Testing net (#0)
I0805 19:57:29.070351 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 19:57:29.070433 10603 solver.cpp:404]     Test net output #1: loss = 0.693514 (* 1 = 0.693514 loss)
I0805 19:57:29.081324 10603 solver.cpp:228] Iteration 82500, loss = 0.695926
I0805 19:57:29.081387 10603 solver.cpp:244]     Train net output #0: loss = 0.695926 (* 1 = 0.695926 loss)
I0805 19:57:29.081403 10603 sgd_solver.cpp:106] Iteration 82500, lr = 2.93582e-06
I0805 19:57:32.320919 10603 solver.cpp:228] Iteration 82600, loss = 0.694902
I0805 19:57:32.320965 10603 solver.cpp:244]     Train net output #0: loss = 0.694902 (* 1 = 0.694902 loss)
I0805 19:57:32.320969 10603 sgd_solver.cpp:106] Iteration 82600, lr = 2.93367e-06
I0805 19:57:35.569835 10603 solver.cpp:228] Iteration 82700, loss = 0.686612
I0805 19:57:35.569880 10603 solver.cpp:244]     Train net output #0: loss = 0.686612 (* 1 = 0.686612 loss)
I0805 19:57:35.569887 10603 sgd_solver.cpp:106] Iteration 82700, lr = 2.93153e-06
I0805 19:57:38.819344 10603 solver.cpp:228] Iteration 82800, loss = 0.688507
I0805 19:57:38.819386 10603 solver.cpp:244]     Train net output #0: loss = 0.688507 (* 1 = 0.688507 loss)
I0805 19:57:38.819392 10603 sgd_solver.cpp:106] Iteration 82800, lr = 2.92939e-06
I0805 19:57:42.067715 10603 solver.cpp:228] Iteration 82900, loss = 0.688064
I0805 19:57:42.067759 10603 solver.cpp:244]     Train net output #0: loss = 0.688064 (* 1 = 0.688064 loss)
I0805 19:57:42.067767 10603 sgd_solver.cpp:106] Iteration 82900, lr = 2.92726e-06
I0805 19:57:45.281955 10603 solver.cpp:337] Iteration 83000, Testing net (#0)
I0805 19:57:48.819514 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0805 19:57:48.819557 10603 solver.cpp:404]     Test net output #1: loss = 0.693557 (* 1 = 0.693557 loss)
I0805 19:57:48.829725 10603 solver.cpp:228] Iteration 83000, loss = 0.697802
I0805 19:57:48.829742 10603 solver.cpp:244]     Train net output #0: loss = 0.697802 (* 1 = 0.697802 loss)
I0805 19:57:48.829751 10603 sgd_solver.cpp:106] Iteration 83000, lr = 2.92513e-06
I0805 19:57:52.071283 10603 solver.cpp:228] Iteration 83100, loss = 0.696232
I0805 19:57:52.071333 10603 solver.cpp:244]     Train net output #0: loss = 0.696232 (* 1 = 0.696232 loss)
I0805 19:57:52.071339 10603 sgd_solver.cpp:106] Iteration 83100, lr = 2.923e-06
I0805 19:57:55.315520 10603 solver.cpp:228] Iteration 83200, loss = 0.699574
I0805 19:57:55.315557 10603 solver.cpp:244]     Train net output #0: loss = 0.699574 (* 1 = 0.699574 loss)
I0805 19:57:55.315564 10603 sgd_solver.cpp:106] Iteration 83200, lr = 2.92087e-06
I0805 19:57:58.557849 10603 solver.cpp:228] Iteration 83300, loss = 0.698763
I0805 19:57:58.557894 10603 solver.cpp:244]     Train net output #0: loss = 0.698763 (* 1 = 0.698763 loss)
I0805 19:57:58.557900 10603 sgd_solver.cpp:106] Iteration 83300, lr = 2.91875e-06
I0805 19:58:01.797276 10603 solver.cpp:228] Iteration 83400, loss = 0.689313
I0805 19:58:01.797319 10603 solver.cpp:244]     Train net output #0: loss = 0.689313 (* 1 = 0.689313 loss)
I0805 19:58:01.797328 10603 sgd_solver.cpp:106] Iteration 83400, lr = 2.91663e-06
I0805 19:58:05.008756 10603 solver.cpp:337] Iteration 83500, Testing net (#0)
I0805 19:58:08.546584 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 19:58:08.546624 10603 solver.cpp:404]     Test net output #1: loss = 0.693335 (* 1 = 0.693335 loss)
I0805 19:58:08.559554 10603 solver.cpp:228] Iteration 83500, loss = 0.686832
I0805 19:58:08.559602 10603 solver.cpp:244]     Train net output #0: loss = 0.686832 (* 1 = 0.686832 loss)
I0805 19:58:08.559609 10603 sgd_solver.cpp:106] Iteration 83500, lr = 2.91452e-06
I0805 19:58:11.791007 10603 solver.cpp:228] Iteration 83600, loss = 0.698702
I0805 19:58:11.791050 10603 solver.cpp:244]     Train net output #0: loss = 0.698702 (* 1 = 0.698702 loss)
I0805 19:58:11.791056 10603 sgd_solver.cpp:106] Iteration 83600, lr = 2.91241e-06
I0805 19:58:15.046267 10603 solver.cpp:228] Iteration 83700, loss = 0.694408
I0805 19:58:15.046324 10603 solver.cpp:244]     Train net output #0: loss = 0.694408 (* 1 = 0.694408 loss)
I0805 19:58:15.046329 10603 sgd_solver.cpp:106] Iteration 83700, lr = 2.9103e-06
I0805 19:58:18.300503 10603 solver.cpp:228] Iteration 83800, loss = 0.689018
I0805 19:58:18.300560 10603 solver.cpp:244]     Train net output #0: loss = 0.689018 (* 1 = 0.689018 loss)
I0805 19:58:18.300570 10603 sgd_solver.cpp:106] Iteration 83800, lr = 2.9082e-06
I0805 19:58:18.563797 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:58:21.563292 10603 solver.cpp:228] Iteration 83900, loss = 0.691722
I0805 19:58:21.563333 10603 solver.cpp:244]     Train net output #0: loss = 0.691722 (* 1 = 0.691722 loss)
I0805 19:58:21.563338 10603 sgd_solver.cpp:106] Iteration 83900, lr = 2.9061e-06
I0805 19:58:24.797121 10603 solver.cpp:337] Iteration 84000, Testing net (#0)
I0805 19:58:28.419953 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:58:28.420001 10603 solver.cpp:404]     Test net output #1: loss = 0.693766 (* 1 = 0.693766 loss)
I0805 19:58:28.430176 10603 solver.cpp:228] Iteration 84000, loss = 0.687898
I0805 19:58:28.430212 10603 solver.cpp:244]     Train net output #0: loss = 0.687898 (* 1 = 0.687898 loss)
I0805 19:58:28.430230 10603 sgd_solver.cpp:106] Iteration 84000, lr = 2.90401e-06
I0805 19:58:31.625171 10603 solver.cpp:228] Iteration 84100, loss = 0.690197
I0805 19:58:31.625217 10603 solver.cpp:244]     Train net output #0: loss = 0.690197 (* 1 = 0.690197 loss)
I0805 19:58:31.625223 10603 sgd_solver.cpp:106] Iteration 84100, lr = 2.90191e-06
I0805 19:58:34.843420 10603 solver.cpp:228] Iteration 84200, loss = 0.68861
I0805 19:58:34.843469 10603 solver.cpp:244]     Train net output #0: loss = 0.68861 (* 1 = 0.68861 loss)
I0805 19:58:34.843479 10603 sgd_solver.cpp:106] Iteration 84200, lr = 2.89982e-06
I0805 19:58:38.084333 10603 solver.cpp:228] Iteration 84300, loss = 0.6941
I0805 19:58:38.084381 10603 solver.cpp:244]     Train net output #0: loss = 0.6941 (* 1 = 0.6941 loss)
I0805 19:58:38.084388 10603 sgd_solver.cpp:106] Iteration 84300, lr = 2.89774e-06
I0805 19:58:41.327801 10603 solver.cpp:228] Iteration 84400, loss = 0.688425
I0805 19:58:41.327858 10603 solver.cpp:244]     Train net output #0: loss = 0.688425 (* 1 = 0.688425 loss)
I0805 19:58:41.327865 10603 sgd_solver.cpp:106] Iteration 84400, lr = 2.89566e-06
I0805 19:58:44.539628 10603 solver.cpp:337] Iteration 84500, Testing net (#0)
I0805 19:58:48.075886 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 19:58:48.075928 10603 solver.cpp:404]     Test net output #1: loss = 0.693286 (* 1 = 0.693286 loss)
I0805 19:58:48.089498 10603 solver.cpp:228] Iteration 84500, loss = 0.694496
I0805 19:58:48.089560 10603 solver.cpp:244]     Train net output #0: loss = 0.694496 (* 1 = 0.694496 loss)
I0805 19:58:48.089575 10603 sgd_solver.cpp:106] Iteration 84500, lr = 2.89358e-06
I0805 19:58:51.316541 10603 solver.cpp:228] Iteration 84600, loss = 0.690436
I0805 19:58:51.316587 10603 solver.cpp:244]     Train net output #0: loss = 0.690436 (* 1 = 0.690436 loss)
I0805 19:58:51.316593 10603 sgd_solver.cpp:106] Iteration 84600, lr = 2.8915e-06
I0805 19:58:54.557750 10603 solver.cpp:228] Iteration 84700, loss = 0.688772
I0805 19:58:54.557791 10603 solver.cpp:244]     Train net output #0: loss = 0.688772 (* 1 = 0.688772 loss)
I0805 19:58:54.557796 10603 sgd_solver.cpp:106] Iteration 84700, lr = 2.88943e-06
I0805 19:58:57.800931 10603 solver.cpp:228] Iteration 84800, loss = 0.705832
I0805 19:58:57.800979 10603 solver.cpp:244]     Train net output #0: loss = 0.705832 (* 1 = 0.705832 loss)
I0805 19:58:57.800986 10603 sgd_solver.cpp:106] Iteration 84800, lr = 2.88736e-06
I0805 19:59:01.043221 10603 solver.cpp:228] Iteration 84900, loss = 0.699822
I0805 19:59:01.043262 10603 solver.cpp:244]     Train net output #0: loss = 0.699822 (* 1 = 0.699822 loss)
I0805 19:59:01.043267 10603 sgd_solver.cpp:106] Iteration 84900, lr = 2.8853e-06
I0805 19:59:04.250152 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_85000.caffemodel
I0805 19:59:04.616977 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_85000.solverstate
I0805 19:59:04.749557 10603 solver.cpp:337] Iteration 85000, Testing net (#0)
I0805 19:59:08.486939 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208721
I0805 19:59:08.486980 10603 solver.cpp:404]     Test net output #1: loss = 0.693361 (* 1 = 0.693361 loss)
I0805 19:59:08.497175 10603 solver.cpp:228] Iteration 85000, loss = 0.691141
I0805 19:59:08.497202 10603 solver.cpp:244]     Train net output #0: loss = 0.691141 (* 1 = 0.691141 loss)
I0805 19:59:08.497210 10603 sgd_solver.cpp:106] Iteration 85000, lr = 2.88324e-06
I0805 19:59:11.684695 10603 solver.cpp:228] Iteration 85100, loss = 0.701489
I0805 19:59:11.684736 10603 solver.cpp:244]     Train net output #0: loss = 0.701489 (* 1 = 0.701489 loss)
I0805 19:59:11.684742 10603 sgd_solver.cpp:106] Iteration 85100, lr = 2.88118e-06
I0805 19:59:14.927084 10603 solver.cpp:228] Iteration 85200, loss = 0.70123
I0805 19:59:14.927125 10603 solver.cpp:244]     Train net output #0: loss = 0.70123 (* 1 = 0.70123 loss)
I0805 19:59:14.927131 10603 sgd_solver.cpp:106] Iteration 85200, lr = 2.87913e-06
I0805 19:59:18.185051 10603 solver.cpp:228] Iteration 85300, loss = 0.689329
I0805 19:59:18.185098 10603 solver.cpp:244]     Train net output #0: loss = 0.689329 (* 1 = 0.689329 loss)
I0805 19:59:18.185104 10603 sgd_solver.cpp:106] Iteration 85300, lr = 2.87708e-06
I0805 19:59:21.436669 10603 solver.cpp:228] Iteration 85400, loss = 0.698466
I0805 19:59:21.436708 10603 solver.cpp:244]     Train net output #0: loss = 0.698466 (* 1 = 0.698466 loss)
I0805 19:59:21.436714 10603 sgd_solver.cpp:106] Iteration 85400, lr = 2.87503e-06
I0805 19:59:24.655730 10603 solver.cpp:337] Iteration 85500, Testing net (#0)
I0805 19:59:28.174093 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 19:59:28.174134 10603 solver.cpp:404]     Test net output #1: loss = 0.693702 (* 1 = 0.693702 loss)
I0805 19:59:28.184908 10603 solver.cpp:228] Iteration 85500, loss = 0.690923
I0805 19:59:28.184979 10603 solver.cpp:244]     Train net output #0: loss = 0.690923 (* 1 = 0.690923 loss)
I0805 19:59:28.184996 10603 sgd_solver.cpp:106] Iteration 85500, lr = 2.87298e-06
I0805 19:59:31.403717 10603 solver.cpp:228] Iteration 85600, loss = 0.698827
I0805 19:59:31.403759 10603 solver.cpp:244]     Train net output #0: loss = 0.698827 (* 1 = 0.698827 loss)
I0805 19:59:31.403765 10603 sgd_solver.cpp:106] Iteration 85600, lr = 2.87094e-06
I0805 19:59:34.636152 10603 solver.cpp:228] Iteration 85700, loss = 0.708077
I0805 19:59:34.636193 10603 solver.cpp:244]     Train net output #0: loss = 0.708077 (* 1 = 0.708077 loss)
I0805 19:59:34.636198 10603 sgd_solver.cpp:106] Iteration 85700, lr = 2.86891e-06
I0805 19:59:37.883337 10603 solver.cpp:228] Iteration 85800, loss = 0.700938
I0805 19:59:37.883380 10603 solver.cpp:244]     Train net output #0: loss = 0.700938 (* 1 = 0.700938 loss)
I0805 19:59:37.883386 10603 sgd_solver.cpp:106] Iteration 85800, lr = 2.86687e-06
I0805 19:59:41.126500 10603 solver.cpp:228] Iteration 85900, loss = 0.700185
I0805 19:59:41.126540 10603 solver.cpp:244]     Train net output #0: loss = 0.700185 (* 1 = 0.700185 loss)
I0805 19:59:41.126546 10603 sgd_solver.cpp:106] Iteration 85900, lr = 2.86484e-06
I0805 19:59:44.333433 10603 solver.cpp:337] Iteration 86000, Testing net (#0)
I0805 19:59:47.743821 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 19:59:47.844184 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 19:59:47.844213 10603 solver.cpp:404]     Test net output #1: loss = 0.69357 (* 1 = 0.69357 loss)
I0805 19:59:47.857779 10603 solver.cpp:228] Iteration 86000, loss = 0.686376
I0805 19:59:47.857846 10603 solver.cpp:244]     Train net output #0: loss = 0.686376 (* 1 = 0.686376 loss)
I0805 19:59:47.857867 10603 sgd_solver.cpp:106] Iteration 86000, lr = 2.86281e-06
I0805 19:59:51.101425 10603 solver.cpp:228] Iteration 86100, loss = 0.693763
I0805 19:59:51.101467 10603 solver.cpp:244]     Train net output #0: loss = 0.693763 (* 1 = 0.693763 loss)
I0805 19:59:51.101474 10603 sgd_solver.cpp:106] Iteration 86100, lr = 2.86079e-06
I0805 19:59:54.361690 10603 solver.cpp:228] Iteration 86200, loss = 0.695525
I0805 19:59:54.361732 10603 solver.cpp:244]     Train net output #0: loss = 0.695525 (* 1 = 0.695525 loss)
I0805 19:59:54.361738 10603 sgd_solver.cpp:106] Iteration 86200, lr = 2.85877e-06
I0805 19:59:57.623848 10603 solver.cpp:228] Iteration 86300, loss = 0.690282
I0805 19:59:57.623893 10603 solver.cpp:244]     Train net output #0: loss = 0.690282 (* 1 = 0.690282 loss)
I0805 19:59:57.623898 10603 sgd_solver.cpp:106] Iteration 86300, lr = 2.85675e-06
I0805 20:00:00.880355 10603 solver.cpp:228] Iteration 86400, loss = 0.69233
I0805 20:00:00.880396 10603 solver.cpp:244]     Train net output #0: loss = 0.69233 (* 1 = 0.69233 loss)
I0805 20:00:00.880403 10603 sgd_solver.cpp:106] Iteration 86400, lr = 2.85474e-06
I0805 20:00:04.106935 10603 solver.cpp:337] Iteration 86500, Testing net (#0)
I0805 20:00:07.803820 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 20:00:07.803859 10603 solver.cpp:404]     Test net output #1: loss = 0.693232 (* 1 = 0.693232 loss)
I0805 20:00:07.816846 10603 solver.cpp:228] Iteration 86500, loss = 0.694763
I0805 20:00:07.816864 10603 solver.cpp:244]     Train net output #0: loss = 0.694763 (* 1 = 0.694763 loss)
I0805 20:00:07.816872 10603 sgd_solver.cpp:106] Iteration 86500, lr = 2.85273e-06
I0805 20:00:11.020766 10603 solver.cpp:228] Iteration 86600, loss = 0.693316
I0805 20:00:11.020819 10603 solver.cpp:244]     Train net output #0: loss = 0.693316 (* 1 = 0.693316 loss)
I0805 20:00:11.020826 10603 sgd_solver.cpp:106] Iteration 86600, lr = 2.85072e-06
I0805 20:00:14.253057 10603 solver.cpp:228] Iteration 86700, loss = 0.690507
I0805 20:00:14.253098 10603 solver.cpp:244]     Train net output #0: loss = 0.690507 (* 1 = 0.690507 loss)
I0805 20:00:14.253104 10603 sgd_solver.cpp:106] Iteration 86700, lr = 2.84872e-06
I0805 20:00:17.500125 10603 solver.cpp:228] Iteration 86800, loss = 0.689947
I0805 20:00:17.500170 10603 solver.cpp:244]     Train net output #0: loss = 0.689947 (* 1 = 0.689947 loss)
I0805 20:00:17.500177 10603 sgd_solver.cpp:106] Iteration 86800, lr = 2.84672e-06
I0805 20:00:20.742295 10603 solver.cpp:228] Iteration 86900, loss = 0.690532
I0805 20:00:20.742332 10603 solver.cpp:244]     Train net output #0: loss = 0.690532 (* 1 = 0.690532 loss)
I0805 20:00:20.742338 10603 sgd_solver.cpp:106] Iteration 86900, lr = 2.84472e-06
I0805 20:00:23.947031 10603 solver.cpp:337] Iteration 87000, Testing net (#0)
I0805 20:00:27.475577 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207558
I0805 20:00:27.475617 10603 solver.cpp:404]     Test net output #1: loss = 0.693562 (* 1 = 0.693562 loss)
I0805 20:00:27.488773 10603 solver.cpp:228] Iteration 87000, loss = 0.701216
I0805 20:00:27.488807 10603 solver.cpp:244]     Train net output #0: loss = 0.701216 (* 1 = 0.701216 loss)
I0805 20:00:27.488821 10603 sgd_solver.cpp:106] Iteration 87000, lr = 2.84272e-06
I0805 20:00:30.709141 10603 solver.cpp:228] Iteration 87100, loss = 0.687723
I0805 20:00:30.709190 10603 solver.cpp:244]     Train net output #0: loss = 0.687723 (* 1 = 0.687723 loss)
I0805 20:00:30.709197 10603 sgd_solver.cpp:106] Iteration 87100, lr = 2.84073e-06
I0805 20:00:33.947455 10603 solver.cpp:228] Iteration 87200, loss = 0.695182
I0805 20:00:33.947495 10603 solver.cpp:244]     Train net output #0: loss = 0.695182 (* 1 = 0.695182 loss)
I0805 20:00:33.947501 10603 sgd_solver.cpp:106] Iteration 87200, lr = 2.83875e-06
I0805 20:00:37.196063 10603 solver.cpp:228] Iteration 87300, loss = 0.69961
I0805 20:00:37.196107 10603 solver.cpp:244]     Train net output #0: loss = 0.69961 (* 1 = 0.69961 loss)
I0805 20:00:37.196113 10603 sgd_solver.cpp:106] Iteration 87300, lr = 2.83676e-06
I0805 20:00:40.436378 10603 solver.cpp:228] Iteration 87400, loss = 0.70061
I0805 20:00:40.436419 10603 solver.cpp:244]     Train net output #0: loss = 0.70061 (* 1 = 0.70061 loss)
I0805 20:00:40.436425 10603 sgd_solver.cpp:106] Iteration 87400, lr = 2.83478e-06
I0805 20:00:43.645812 10603 solver.cpp:337] Iteration 87500, Testing net (#0)
I0805 20:00:47.173003 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20843
I0805 20:00:47.173056 10603 solver.cpp:404]     Test net output #1: loss = 0.693933 (* 1 = 0.693933 loss)
I0805 20:00:47.186622 10603 solver.cpp:228] Iteration 87500, loss = 0.693129
I0805 20:00:47.186697 10603 solver.cpp:244]     Train net output #0: loss = 0.693129 (* 1 = 0.693129 loss)
I0805 20:00:47.186714 10603 sgd_solver.cpp:106] Iteration 87500, lr = 2.8328e-06
I0805 20:00:50.416002 10603 solver.cpp:228] Iteration 87600, loss = 0.692025
I0805 20:00:50.416046 10603 solver.cpp:244]     Train net output #0: loss = 0.692025 (* 1 = 0.692025 loss)
I0805 20:00:50.416052 10603 sgd_solver.cpp:106] Iteration 87600, lr = 2.83083e-06
I0805 20:00:53.662706 10603 solver.cpp:228] Iteration 87700, loss = 0.687704
I0805 20:00:53.662750 10603 solver.cpp:244]     Train net output #0: loss = 0.687704 (* 1 = 0.687704 loss)
I0805 20:00:53.662756 10603 sgd_solver.cpp:106] Iteration 87700, lr = 2.82886e-06
I0805 20:00:56.921013 10603 solver.cpp:228] Iteration 87800, loss = 0.697627
I0805 20:00:56.921061 10603 solver.cpp:244]     Train net output #0: loss = 0.697627 (* 1 = 0.697627 loss)
I0805 20:00:56.921068 10603 sgd_solver.cpp:106] Iteration 87800, lr = 2.82689e-06
I0805 20:01:00.175808 10603 solver.cpp:228] Iteration 87900, loss = 0.703597
I0805 20:01:00.175848 10603 solver.cpp:244]     Train net output #0: loss = 0.703597 (* 1 = 0.703597 loss)
I0805 20:01:00.175854 10603 sgd_solver.cpp:106] Iteration 87900, lr = 2.82492e-06
I0805 20:01:03.392530 10603 solver.cpp:337] Iteration 88000, Testing net (#0)
I0805 20:01:07.097308 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 20:01:07.097350 10603 solver.cpp:404]     Test net output #1: loss = 0.693404 (* 1 = 0.693404 loss)
I0805 20:01:07.110419 10603 solver.cpp:228] Iteration 88000, loss = 0.685304
I0805 20:01:07.110447 10603 solver.cpp:244]     Train net output #0: loss = 0.685304 (* 1 = 0.685304 loss)
I0805 20:01:07.110455 10603 sgd_solver.cpp:106] Iteration 88000, lr = 2.82296e-06
I0805 20:01:10.317550 10603 solver.cpp:228] Iteration 88100, loss = 0.699359
I0805 20:01:10.317602 10603 solver.cpp:244]     Train net output #0: loss = 0.699359 (* 1 = 0.699359 loss)
I0805 20:01:10.317610 10603 sgd_solver.cpp:106] Iteration 88100, lr = 2.821e-06
I0805 20:01:13.566205 10603 solver.cpp:228] Iteration 88200, loss = 0.685629
I0805 20:01:13.566263 10603 solver.cpp:244]     Train net output #0: loss = 0.685629 (* 1 = 0.685629 loss)
I0805 20:01:13.566270 10603 sgd_solver.cpp:106] Iteration 88200, lr = 2.81905e-06
I0805 20:01:16.807453 10603 solver.cpp:228] Iteration 88300, loss = 0.690872
I0805 20:01:16.807503 10603 solver.cpp:244]     Train net output #0: loss = 0.690872 (* 1 = 0.690872 loss)
I0805 20:01:16.807509 10603 sgd_solver.cpp:106] Iteration 88300, lr = 2.81709e-06
I0805 20:01:20.049664 10603 solver.cpp:228] Iteration 88400, loss = 0.698673
I0805 20:01:20.049706 10603 solver.cpp:244]     Train net output #0: loss = 0.698673 (* 1 = 0.698673 loss)
I0805 20:01:20.049715 10603 sgd_solver.cpp:106] Iteration 88400, lr = 2.81514e-06
I0805 20:01:23.264691 10603 solver.cpp:337] Iteration 88500, Testing net (#0)
I0805 20:01:26.218554 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 20:01:26.780865 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 20:01:26.780920 10603 solver.cpp:404]     Test net output #1: loss = 0.693366 (* 1 = 0.693366 loss)
I0805 20:01:26.794417 10603 solver.cpp:228] Iteration 88500, loss = 0.694246
I0805 20:01:26.794486 10603 solver.cpp:244]     Train net output #0: loss = 0.694246 (* 1 = 0.694246 loss)
I0805 20:01:26.794502 10603 sgd_solver.cpp:106] Iteration 88500, lr = 2.8132e-06
I0805 20:01:30.027161 10603 solver.cpp:228] Iteration 88600, loss = 0.700056
I0805 20:01:30.027206 10603 solver.cpp:244]     Train net output #0: loss = 0.700056 (* 1 = 0.700056 loss)
I0805 20:01:30.027212 10603 sgd_solver.cpp:106] Iteration 88600, lr = 2.81125e-06
I0805 20:01:33.279078 10603 solver.cpp:228] Iteration 88700, loss = 0.696655
I0805 20:01:33.279132 10603 solver.cpp:244]     Train net output #0: loss = 0.696655 (* 1 = 0.696655 loss)
I0805 20:01:33.279139 10603 sgd_solver.cpp:106] Iteration 88700, lr = 2.80931e-06
I0805 20:01:36.541878 10603 solver.cpp:228] Iteration 88800, loss = 0.700473
I0805 20:01:36.541934 10603 solver.cpp:244]     Train net output #0: loss = 0.700473 (* 1 = 0.700473 loss)
I0805 20:01:36.541940 10603 sgd_solver.cpp:106] Iteration 88800, lr = 2.80738e-06
I0805 20:01:39.802975 10603 solver.cpp:228] Iteration 88900, loss = 0.691811
I0805 20:01:39.803015 10603 solver.cpp:244]     Train net output #0: loss = 0.691811 (* 1 = 0.691811 loss)
I0805 20:01:39.803021 10603 sgd_solver.cpp:106] Iteration 88900, lr = 2.80544e-06
I0805 20:01:43.034934 10603 solver.cpp:337] Iteration 89000, Testing net (#0)
I0805 20:01:46.559756 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208837
I0805 20:01:46.559808 10603 solver.cpp:404]     Test net output #1: loss = 0.69355 (* 1 = 0.69355 loss)
I0805 20:01:46.573487 10603 solver.cpp:228] Iteration 89000, loss = 0.69833
I0805 20:01:46.573556 10603 solver.cpp:244]     Train net output #0: loss = 0.69833 (* 1 = 0.69833 loss)
I0805 20:01:46.573573 10603 sgd_solver.cpp:106] Iteration 89000, lr = 2.80351e-06
I0805 20:01:49.789136 10603 solver.cpp:228] Iteration 89100, loss = 0.690898
I0805 20:01:49.789180 10603 solver.cpp:244]     Train net output #0: loss = 0.690898 (* 1 = 0.690898 loss)
I0805 20:01:49.789186 10603 sgd_solver.cpp:106] Iteration 89100, lr = 2.80159e-06
I0805 20:01:53.003204 10603 solver.cpp:228] Iteration 89200, loss = 0.696038
I0805 20:01:53.003244 10603 solver.cpp:244]     Train net output #0: loss = 0.696038 (* 1 = 0.696038 loss)
I0805 20:01:53.003250 10603 sgd_solver.cpp:106] Iteration 89200, lr = 2.79966e-06
I0805 20:01:56.243885 10603 solver.cpp:228] Iteration 89300, loss = 0.690708
I0805 20:01:56.243923 10603 solver.cpp:244]     Train net output #0: loss = 0.690708 (* 1 = 0.690708 loss)
I0805 20:01:56.243929 10603 sgd_solver.cpp:106] Iteration 89300, lr = 2.79774e-06
I0805 20:01:59.487496 10603 solver.cpp:228] Iteration 89400, loss = 0.685874
I0805 20:01:59.487535 10603 solver.cpp:244]     Train net output #0: loss = 0.685874 (* 1 = 0.685874 loss)
I0805 20:01:59.487541 10603 sgd_solver.cpp:106] Iteration 89400, lr = 2.79582e-06
I0805 20:02:02.698690 10603 solver.cpp:337] Iteration 89500, Testing net (#0)
I0805 20:02:06.355739 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 20:02:06.355792 10603 solver.cpp:404]     Test net output #1: loss = 0.69374 (* 1 = 0.69374 loss)
I0805 20:02:06.368331 10603 solver.cpp:228] Iteration 89500, loss = 0.678482
I0805 20:02:06.368360 10603 solver.cpp:244]     Train net output #0: loss = 0.678482 (* 1 = 0.678482 loss)
I0805 20:02:06.368369 10603 sgd_solver.cpp:106] Iteration 89500, lr = 2.79391e-06
I0805 20:02:09.564931 10603 solver.cpp:228] Iteration 89600, loss = 0.701357
I0805 20:02:09.564978 10603 solver.cpp:244]     Train net output #0: loss = 0.701357 (* 1 = 0.701357 loss)
I0805 20:02:09.564985 10603 sgd_solver.cpp:106] Iteration 89600, lr = 2.79199e-06
I0805 20:02:12.800824 10603 solver.cpp:228] Iteration 89700, loss = 0.700398
I0805 20:02:12.800876 10603 solver.cpp:244]     Train net output #0: loss = 0.700398 (* 1 = 0.700398 loss)
I0805 20:02:12.800882 10603 sgd_solver.cpp:106] Iteration 89700, lr = 2.79009e-06
I0805 20:02:16.046180 10603 solver.cpp:228] Iteration 89800, loss = 0.698134
I0805 20:02:16.046222 10603 solver.cpp:244]     Train net output #0: loss = 0.698134 (* 1 = 0.698134 loss)
I0805 20:02:16.046228 10603 sgd_solver.cpp:106] Iteration 89800, lr = 2.78818e-06
I0805 20:02:19.289727 10603 solver.cpp:228] Iteration 89900, loss = 0.69863
I0805 20:02:19.289770 10603 solver.cpp:244]     Train net output #0: loss = 0.69863 (* 1 = 0.69863 loss)
I0805 20:02:19.289777 10603 sgd_solver.cpp:106] Iteration 89900, lr = 2.78628e-06
I0805 20:02:22.499816 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_90000.caffemodel
I0805 20:02:22.877611 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_90000.solverstate
I0805 20:02:23.012692 10603 solver.cpp:337] Iteration 90000, Testing net (#0)
I0805 20:02:26.471546 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208256
I0805 20:02:26.471586 10603 solver.cpp:404]     Test net output #1: loss = 0.693504 (* 1 = 0.693504 loss)
I0805 20:02:26.484241 10603 solver.cpp:228] Iteration 90000, loss = 0.686164
I0805 20:02:26.484269 10603 solver.cpp:244]     Train net output #0: loss = 0.686164 (* 1 = 0.686164 loss)
I0805 20:02:26.484277 10603 sgd_solver.cpp:106] Iteration 90000, lr = 2.78438e-06
I0805 20:02:29.688189 10603 solver.cpp:228] Iteration 90100, loss = 0.687507
I0805 20:02:29.688231 10603 solver.cpp:244]     Train net output #0: loss = 0.687507 (* 1 = 0.687507 loss)
I0805 20:02:29.688237 10603 sgd_solver.cpp:106] Iteration 90100, lr = 2.78248e-06
I0805 20:02:32.929141 10603 solver.cpp:228] Iteration 90200, loss = 0.689436
I0805 20:02:32.929180 10603 solver.cpp:244]     Train net output #0: loss = 0.689436 (* 1 = 0.689436 loss)
I0805 20:02:32.929186 10603 sgd_solver.cpp:106] Iteration 90200, lr = 2.78059e-06
I0805 20:02:36.175163 10603 solver.cpp:228] Iteration 90300, loss = 0.693847
I0805 20:02:36.175209 10603 solver.cpp:244]     Train net output #0: loss = 0.693847 (* 1 = 0.693847 loss)
I0805 20:02:36.175215 10603 sgd_solver.cpp:106] Iteration 90300, lr = 2.77869e-06
I0805 20:02:39.431002 10603 solver.cpp:228] Iteration 90400, loss = 0.699268
I0805 20:02:39.431046 10603 solver.cpp:244]     Train net output #0: loss = 0.699268 (* 1 = 0.699268 loss)
I0805 20:02:39.431052 10603 sgd_solver.cpp:106] Iteration 90400, lr = 2.77681e-06
I0805 20:02:42.674036 10603 solver.cpp:337] Iteration 90500, Testing net (#0)
I0805 20:02:46.220917 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207733
I0805 20:02:46.220958 10603 solver.cpp:404]     Test net output #1: loss = 0.693707 (* 1 = 0.693707 loss)
I0805 20:02:46.231067 10603 solver.cpp:228] Iteration 90500, loss = 0.694179
I0805 20:02:46.231097 10603 solver.cpp:244]     Train net output #0: loss = 0.694179 (* 1 = 0.694179 loss)
I0805 20:02:46.231106 10603 sgd_solver.cpp:106] Iteration 90500, lr = 2.77492e-06
I0805 20:02:49.446795 10603 solver.cpp:228] Iteration 90600, loss = 0.694999
I0805 20:02:49.446852 10603 solver.cpp:244]     Train net output #0: loss = 0.694999 (* 1 = 0.694999 loss)
I0805 20:02:49.446858 10603 sgd_solver.cpp:106] Iteration 90600, lr = 2.77304e-06
I0805 20:02:52.672602 10603 solver.cpp:228] Iteration 90700, loss = 0.695182
I0805 20:02:52.672644 10603 solver.cpp:244]     Train net output #0: loss = 0.695182 (* 1 = 0.695182 loss)
I0805 20:02:52.672651 10603 sgd_solver.cpp:106] Iteration 90700, lr = 2.77116e-06
I0805 20:02:55.915706 10603 solver.cpp:228] Iteration 90800, loss = 0.68464
I0805 20:02:55.915752 10603 solver.cpp:244]     Train net output #0: loss = 0.68464 (* 1 = 0.68464 loss)
I0805 20:02:55.915758 10603 sgd_solver.cpp:106] Iteration 90800, lr = 2.76929e-06
I0805 20:02:59.155859 10603 solver.cpp:228] Iteration 90900, loss = 0.69016
I0805 20:02:59.155900 10603 solver.cpp:244]     Train net output #0: loss = 0.69016 (* 1 = 0.69016 loss)
I0805 20:02:59.155906 10603 sgd_solver.cpp:106] Iteration 90900, lr = 2.76741e-06
I0805 20:03:02.370342 10603 solver.cpp:337] Iteration 91000, Testing net (#0)
I0805 20:03:06.050642 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 20:03:06.050711 10603 solver.cpp:404]     Test net output #1: loss = 0.693344 (* 1 = 0.693344 loss)
I0805 20:03:06.063941 10603 solver.cpp:228] Iteration 91000, loss = 0.682426
I0805 20:03:06.063977 10603 solver.cpp:244]     Train net output #0: loss = 0.682426 (* 1 = 0.682426 loss)
I0805 20:03:06.063987 10603 sgd_solver.cpp:106] Iteration 91000, lr = 2.76554e-06
I0805 20:03:07.168576 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 20:03:09.304661 10603 solver.cpp:228] Iteration 91100, loss = 0.690174
I0805 20:03:09.304707 10603 solver.cpp:244]     Train net output #0: loss = 0.690174 (* 1 = 0.690174 loss)
I0805 20:03:09.304713 10603 sgd_solver.cpp:106] Iteration 91100, lr = 2.76367e-06
I0805 20:03:12.555752 10603 solver.cpp:228] Iteration 91200, loss = 0.700331
I0805 20:03:12.555790 10603 solver.cpp:244]     Train net output #0: loss = 0.700331 (* 1 = 0.700331 loss)
I0805 20:03:12.555796 10603 sgd_solver.cpp:106] Iteration 91200, lr = 2.76181e-06
I0805 20:03:15.819628 10603 solver.cpp:228] Iteration 91300, loss = 0.696865
I0805 20:03:15.819677 10603 solver.cpp:244]     Train net output #0: loss = 0.696865 (* 1 = 0.696865 loss)
I0805 20:03:15.819684 10603 sgd_solver.cpp:106] Iteration 91300, lr = 2.75995e-06
I0805 20:03:19.081045 10603 solver.cpp:228] Iteration 91400, loss = 0.697373
I0805 20:03:19.081089 10603 solver.cpp:244]     Train net output #0: loss = 0.697373 (* 1 = 0.697373 loss)
I0805 20:03:19.081094 10603 sgd_solver.cpp:106] Iteration 91400, lr = 2.75809e-06
I0805 20:03:22.309741 10603 solver.cpp:337] Iteration 91500, Testing net (#0)
I0805 20:03:26.091979 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 20:03:26.092033 10603 solver.cpp:404]     Test net output #1: loss = 0.693568 (* 1 = 0.693568 loss)
I0805 20:03:26.105645 10603 solver.cpp:228] Iteration 91500, loss = 0.691371
I0805 20:03:26.105715 10603 solver.cpp:244]     Train net output #0: loss = 0.691371 (* 1 = 0.691371 loss)
I0805 20:03:26.105742 10603 sgd_solver.cpp:106] Iteration 91500, lr = 2.75624e-06
I0805 20:03:29.292785 10603 solver.cpp:228] Iteration 91600, loss = 0.683945
I0805 20:03:29.292834 10603 solver.cpp:244]     Train net output #0: loss = 0.683945 (* 1 = 0.683945 loss)
I0805 20:03:29.292840 10603 sgd_solver.cpp:106] Iteration 91600, lr = 2.75438e-06
I0805 20:03:32.520679 10603 solver.cpp:228] Iteration 91700, loss = 0.690229
I0805 20:03:32.520722 10603 solver.cpp:244]     Train net output #0: loss = 0.690229 (* 1 = 0.690229 loss)
I0805 20:03:32.520743 10603 sgd_solver.cpp:106] Iteration 91700, lr = 2.75253e-06
I0805 20:03:35.757140 10603 solver.cpp:228] Iteration 91800, loss = 0.707241
I0805 20:03:35.757184 10603 solver.cpp:244]     Train net output #0: loss = 0.707241 (* 1 = 0.707241 loss)
I0805 20:03:35.757191 10603 sgd_solver.cpp:106] Iteration 91800, lr = 2.75069e-06
I0805 20:03:38.999397 10603 solver.cpp:228] Iteration 91900, loss = 0.692971
I0805 20:03:38.999441 10603 solver.cpp:244]     Train net output #0: loss = 0.692971 (* 1 = 0.692971 loss)
I0805 20:03:38.999449 10603 sgd_solver.cpp:106] Iteration 91900, lr = 2.74884e-06
I0805 20:03:42.207109 10603 solver.cpp:337] Iteration 92000, Testing net (#0)
I0805 20:03:45.770789 10603 solver.cpp:404]     Test net output #0: accuracy = 0.791802
I0805 20:03:45.770848 10603 solver.cpp:404]     Test net output #1: loss = 0.693079 (* 1 = 0.693079 loss)
I0805 20:03:45.783843 10603 solver.cpp:228] Iteration 92000, loss = 0.700078
I0805 20:03:45.783879 10603 solver.cpp:244]     Train net output #0: loss = 0.700078 (* 1 = 0.700078 loss)
I0805 20:03:45.783891 10603 sgd_solver.cpp:106] Iteration 92000, lr = 2.747e-06
I0805 20:03:48.999442 10603 solver.cpp:228] Iteration 92100, loss = 0.693934
I0805 20:03:48.999482 10603 solver.cpp:244]     Train net output #0: loss = 0.693934 (* 1 = 0.693934 loss)
I0805 20:03:48.999488 10603 sgd_solver.cpp:106] Iteration 92100, lr = 2.74516e-06
I0805 20:03:52.239039 10603 solver.cpp:228] Iteration 92200, loss = 0.699189
I0805 20:03:52.239086 10603 solver.cpp:244]     Train net output #0: loss = 0.699189 (* 1 = 0.699189 loss)
I0805 20:03:52.239092 10603 sgd_solver.cpp:106] Iteration 92200, lr = 2.74333e-06
I0805 20:03:55.482210 10603 solver.cpp:228] Iteration 92300, loss = 0.694211
I0805 20:03:55.482249 10603 solver.cpp:244]     Train net output #0: loss = 0.694211 (* 1 = 0.694211 loss)
I0805 20:03:55.482255 10603 sgd_solver.cpp:106] Iteration 92300, lr = 2.7415e-06
I0805 20:03:58.734920 10603 solver.cpp:228] Iteration 92400, loss = 0.696007
I0805 20:03:58.734964 10603 solver.cpp:244]     Train net output #0: loss = 0.696007 (* 1 = 0.696007 loss)
I0805 20:03:58.734972 10603 sgd_solver.cpp:106] Iteration 92400, lr = 2.73967e-06
I0805 20:04:01.949739 10603 solver.cpp:337] Iteration 92500, Testing net (#0)
I0805 20:04:05.578665 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208953
I0805 20:04:05.578717 10603 solver.cpp:404]     Test net output #1: loss = 0.693247 (* 1 = 0.693247 loss)
I0805 20:04:05.589030 10603 solver.cpp:228] Iteration 92500, loss = 0.693806
I0805 20:04:05.589071 10603 solver.cpp:244]     Train net output #0: loss = 0.693806 (* 1 = 0.693806 loss)
I0805 20:04:05.589082 10603 sgd_solver.cpp:106] Iteration 92500, lr = 2.73784e-06
I0805 20:04:08.806774 10603 solver.cpp:228] Iteration 92600, loss = 0.700609
I0805 20:04:08.806819 10603 solver.cpp:244]     Train net output #0: loss = 0.700609 (* 1 = 0.700609 loss)
I0805 20:04:08.806825 10603 sgd_solver.cpp:106] Iteration 92600, lr = 2.73602e-06
I0805 20:04:12.036558 10603 solver.cpp:228] Iteration 92700, loss = 0.684828
I0805 20:04:12.036600 10603 solver.cpp:244]     Train net output #0: loss = 0.684828 (* 1 = 0.684828 loss)
I0805 20:04:12.036607 10603 sgd_solver.cpp:106] Iteration 92700, lr = 2.7342e-06
I0805 20:04:15.286129 10603 solver.cpp:228] Iteration 92800, loss = 0.695854
I0805 20:04:15.286176 10603 solver.cpp:244]     Train net output #0: loss = 0.695854 (* 1 = 0.695854 loss)
I0805 20:04:15.286182 10603 sgd_solver.cpp:106] Iteration 92800, lr = 2.73238e-06
I0805 20:04:18.536176 10603 solver.cpp:228] Iteration 92900, loss = 0.703386
I0805 20:04:18.536229 10603 solver.cpp:244]     Train net output #0: loss = 0.703386 (* 1 = 0.703386 loss)
I0805 20:04:18.536237 10603 sgd_solver.cpp:106] Iteration 92900, lr = 2.73056e-06
I0805 20:04:21.751539 10603 solver.cpp:337] Iteration 93000, Testing net (#0)
I0805 20:04:25.384603 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208023
I0805 20:04:25.384651 10603 solver.cpp:404]     Test net output #1: loss = 0.693597 (* 1 = 0.693597 loss)
I0805 20:04:25.395066 10603 solver.cpp:228] Iteration 93000, loss = 0.693692
I0805 20:04:25.395095 10603 solver.cpp:244]     Train net output #0: loss = 0.693692 (* 1 = 0.693692 loss)
I0805 20:04:25.395107 10603 sgd_solver.cpp:106] Iteration 93000, lr = 2.72875e-06
I0805 20:04:28.610774 10603 solver.cpp:228] Iteration 93100, loss = 0.698514
I0805 20:04:28.610823 10603 solver.cpp:244]     Train net output #0: loss = 0.698514 (* 1 = 0.698514 loss)
I0805 20:04:28.610829 10603 sgd_solver.cpp:106] Iteration 93100, lr = 2.72694e-06
I0805 20:04:31.855583 10603 solver.cpp:228] Iteration 93200, loss = 0.700108
I0805 20:04:31.855628 10603 solver.cpp:244]     Train net output #0: loss = 0.700108 (* 1 = 0.700108 loss)
I0805 20:04:31.855633 10603 sgd_solver.cpp:106] Iteration 93200, lr = 2.72513e-06
I0805 20:04:35.102628 10603 solver.cpp:228] Iteration 93300, loss = 0.697779
I0805 20:04:35.102669 10603 solver.cpp:244]     Train net output #0: loss = 0.697779 (* 1 = 0.697779 loss)
I0805 20:04:35.102674 10603 sgd_solver.cpp:106] Iteration 93300, lr = 2.72333e-06
I0805 20:04:38.346936 10603 solver.cpp:228] Iteration 93400, loss = 0.695686
I0805 20:04:38.346981 10603 solver.cpp:244]     Train net output #0: loss = 0.695686 (* 1 = 0.695686 loss)
I0805 20:04:38.346987 10603 sgd_solver.cpp:106] Iteration 93400, lr = 2.72153e-06
I0805 20:04:41.328660 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 20:04:41.555367 10603 solver.cpp:337] Iteration 93500, Testing net (#0)
I0805 20:04:45.258389 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20814
I0805 20:04:45.258433 10603 solver.cpp:404]     Test net output #1: loss = 0.693353 (* 1 = 0.693353 loss)
I0805 20:04:45.271252 10603 solver.cpp:228] Iteration 93500, loss = 0.703438
I0805 20:04:45.271282 10603 solver.cpp:244]     Train net output #0: loss = 0.703438 (* 1 = 0.703438 loss)
I0805 20:04:45.271296 10603 sgd_solver.cpp:106] Iteration 93500, lr = 2.71973e-06
I0805 20:04:48.477392 10603 solver.cpp:228] Iteration 93600, loss = 0.695007
I0805 20:04:48.477433 10603 solver.cpp:244]     Train net output #0: loss = 0.695007 (* 1 = 0.695007 loss)
I0805 20:04:48.477440 10603 sgd_solver.cpp:106] Iteration 93600, lr = 2.71793e-06
I0805 20:04:51.726871 10603 solver.cpp:228] Iteration 93700, loss = 0.69396
I0805 20:04:51.726915 10603 solver.cpp:244]     Train net output #0: loss = 0.69396 (* 1 = 0.69396 loss)
I0805 20:04:51.726922 10603 sgd_solver.cpp:106] Iteration 93700, lr = 2.71614e-06
I0805 20:04:54.987836 10603 solver.cpp:228] Iteration 93800, loss = 0.689517
I0805 20:04:54.987877 10603 solver.cpp:244]     Train net output #0: loss = 0.689517 (* 1 = 0.689517 loss)
I0805 20:04:54.987884 10603 sgd_solver.cpp:106] Iteration 93800, lr = 2.71435e-06
I0805 20:04:58.256434 10603 solver.cpp:228] Iteration 93900, loss = 0.695371
I0805 20:04:58.256480 10603 solver.cpp:244]     Train net output #0: loss = 0.695371 (* 1 = 0.695371 loss)
I0805 20:04:58.256486 10603 sgd_solver.cpp:106] Iteration 93900, lr = 2.71256e-06
I0805 20:05:01.483131 10603 solver.cpp:337] Iteration 94000, Testing net (#0)
I0805 20:05:05.123951 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 20:05:05.123997 10603 solver.cpp:404]     Test net output #1: loss = 0.693185 (* 1 = 0.693185 loss)
I0805 20:05:05.134356 10603 solver.cpp:228] Iteration 94000, loss = 0.69828
I0805 20:05:05.134387 10603 solver.cpp:244]     Train net output #0: loss = 0.69828 (* 1 = 0.69828 loss)
I0805 20:05:05.134398 10603 sgd_solver.cpp:106] Iteration 94000, lr = 2.71078e-06
I0805 20:05:08.345813 10603 solver.cpp:228] Iteration 94100, loss = 0.698167
I0805 20:05:08.345852 10603 solver.cpp:244]     Train net output #0: loss = 0.698167 (* 1 = 0.698167 loss)
I0805 20:05:08.345857 10603 sgd_solver.cpp:106] Iteration 94100, lr = 2.709e-06
I0805 20:05:11.609578 10603 solver.cpp:228] Iteration 94200, loss = 0.705844
I0805 20:05:11.609625 10603 solver.cpp:244]     Train net output #0: loss = 0.705844 (* 1 = 0.705844 loss)
I0805 20:05:11.609632 10603 sgd_solver.cpp:106] Iteration 94200, lr = 2.70722e-06
I0805 20:05:14.872614 10603 solver.cpp:228] Iteration 94300, loss = 0.68601
I0805 20:05:14.872654 10603 solver.cpp:244]     Train net output #0: loss = 0.68601 (* 1 = 0.68601 loss)
I0805 20:05:14.872660 10603 sgd_solver.cpp:106] Iteration 94300, lr = 2.70544e-06
I0805 20:05:18.137627 10603 solver.cpp:228] Iteration 94400, loss = 0.687375
I0805 20:05:18.137670 10603 solver.cpp:244]     Train net output #0: loss = 0.687375 (* 1 = 0.687375 loss)
I0805 20:05:18.137676 10603 sgd_solver.cpp:106] Iteration 94400, lr = 2.70367e-06
I0805 20:05:21.370234 10603 solver.cpp:337] Iteration 94500, Testing net (#0)
I0805 20:05:24.945237 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 20:05:24.945294 10603 solver.cpp:404]     Test net output #1: loss = 0.693492 (* 1 = 0.693492 loss)
I0805 20:05:24.958475 10603 solver.cpp:228] Iteration 94500, loss = 0.695461
I0805 20:05:24.958513 10603 solver.cpp:244]     Train net output #0: loss = 0.695461 (* 1 = 0.695461 loss)
I0805 20:05:24.958531 10603 sgd_solver.cpp:106] Iteration 94500, lr = 2.70189e-06
I0805 20:05:28.149879 10603 solver.cpp:228] Iteration 94600, loss = 0.693783
I0805 20:05:28.149931 10603 solver.cpp:244]     Train net output #0: loss = 0.693783 (* 1 = 0.693783 loss)
I0805 20:05:28.149938 10603 sgd_solver.cpp:106] Iteration 94600, lr = 2.70013e-06
I0805 20:05:31.354894 10603 solver.cpp:228] Iteration 94700, loss = 0.693011
I0805 20:05:31.354933 10603 solver.cpp:244]     Train net output #0: loss = 0.693011 (* 1 = 0.693011 loss)
I0805 20:05:31.354939 10603 sgd_solver.cpp:106] Iteration 94700, lr = 2.69836e-06
I0805 20:05:34.597771 10603 solver.cpp:228] Iteration 94800, loss = 0.695211
I0805 20:05:34.597811 10603 solver.cpp:244]     Train net output #0: loss = 0.695211 (* 1 = 0.695211 loss)
I0805 20:05:34.597817 10603 sgd_solver.cpp:106] Iteration 94800, lr = 2.6966e-06
I0805 20:05:37.844283 10603 solver.cpp:228] Iteration 94900, loss = 0.683097
I0805 20:05:37.844327 10603 solver.cpp:244]     Train net output #0: loss = 0.683097 (* 1 = 0.683097 loss)
I0805 20:05:37.844334 10603 sgd_solver.cpp:106] Iteration 94900, lr = 2.69484e-06
I0805 20:05:41.057060 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_95000.caffemodel
I0805 20:05:41.431231 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_95000.solverstate
I0805 20:05:41.563891 10603 solver.cpp:337] Iteration 95000, Testing net (#0)
I0805 20:05:45.268863 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 20:05:45.268910 10603 solver.cpp:404]     Test net output #1: loss = 0.693834 (* 1 = 0.693834 loss)
I0805 20:05:45.279693 10603 solver.cpp:228] Iteration 95000, loss = 0.705948
I0805 20:05:45.279765 10603 solver.cpp:244]     Train net output #0: loss = 0.705948 (* 1 = 0.705948 loss)
I0805 20:05:45.279783 10603 sgd_solver.cpp:106] Iteration 95000, lr = 2.69308e-06
I0805 20:05:48.476294 10603 solver.cpp:228] Iteration 95100, loss = 0.695611
I0805 20:05:48.476336 10603 solver.cpp:244]     Train net output #0: loss = 0.695611 (* 1 = 0.695611 loss)
I0805 20:05:48.476342 10603 sgd_solver.cpp:106] Iteration 95100, lr = 2.69132e-06
I0805 20:05:51.706743 10603 solver.cpp:228] Iteration 95200, loss = 0.692257
I0805 20:05:51.706780 10603 solver.cpp:244]     Train net output #0: loss = 0.692257 (* 1 = 0.692257 loss)
I0805 20:05:51.706790 10603 sgd_solver.cpp:106] Iteration 95200, lr = 2.68957e-06
I0805 20:05:54.955597 10603 solver.cpp:228] Iteration 95300, loss = 0.683455
I0805 20:05:54.955643 10603 solver.cpp:244]     Train net output #0: loss = 0.683455 (* 1 = 0.683455 loss)
I0805 20:05:54.955651 10603 sgd_solver.cpp:106] Iteration 95300, lr = 2.68782e-06
I0805 20:05:58.209564 10603 solver.cpp:228] Iteration 95400, loss = 0.697701
I0805 20:05:58.209610 10603 solver.cpp:244]     Train net output #0: loss = 0.697701 (* 1 = 0.697701 loss)
I0805 20:05:58.209616 10603 sgd_solver.cpp:106] Iteration 95400, lr = 2.68608e-06
I0805 20:06:01.425822 10603 solver.cpp:337] Iteration 95500, Testing net (#0)
I0805 20:06:04.059649 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 20:06:04.944015 10603 solver.cpp:404]     Test net output #0: accuracy = 0.20814
I0805 20:06:04.944046 10603 solver.cpp:404]     Test net output #1: loss = 0.693245 (* 1 = 0.693245 loss)
I0805 20:06:04.957007 10603 solver.cpp:228] Iteration 95500, loss = 0.694523
I0805 20:06:04.957052 10603 solver.cpp:244]     Train net output #0: loss = 0.694523 (* 1 = 0.694523 loss)
I0805 20:06:04.957062 10603 sgd_solver.cpp:106] Iteration 95500, lr = 2.68433e-06
I0805 20:06:08.173928 10603 solver.cpp:228] Iteration 95600, loss = 0.69295
I0805 20:06:08.173974 10603 solver.cpp:244]     Train net output #0: loss = 0.69295 (* 1 = 0.69295 loss)
I0805 20:06:08.173979 10603 sgd_solver.cpp:106] Iteration 95600, lr = 2.68259e-06
I0805 20:06:11.415158 10603 solver.cpp:228] Iteration 95700, loss = 0.694065
I0805 20:06:11.415199 10603 solver.cpp:244]     Train net output #0: loss = 0.694065 (* 1 = 0.694065 loss)
I0805 20:06:11.415205 10603 sgd_solver.cpp:106] Iteration 95700, lr = 2.68085e-06
I0805 20:06:14.654991 10603 solver.cpp:228] Iteration 95800, loss = 0.690624
I0805 20:06:14.655035 10603 solver.cpp:244]     Train net output #0: loss = 0.690624 (* 1 = 0.690624 loss)
I0805 20:06:14.655040 10603 sgd_solver.cpp:106] Iteration 95800, lr = 2.67911e-06
I0805 20:06:17.891366 10603 solver.cpp:228] Iteration 95900, loss = 0.698636
I0805 20:06:17.891410 10603 solver.cpp:244]     Train net output #0: loss = 0.698636 (* 1 = 0.698636 loss)
I0805 20:06:17.891417 10603 sgd_solver.cpp:106] Iteration 95900, lr = 2.67738e-06
I0805 20:06:21.097934 10603 solver.cpp:337] Iteration 96000, Testing net (#0)
I0805 20:06:24.870487 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207965
I0805 20:06:24.870586 10603 solver.cpp:404]     Test net output #1: loss = 0.69345 (* 1 = 0.69345 loss)
I0805 20:06:24.881191 10603 solver.cpp:228] Iteration 96000, loss = 0.684989
I0805 20:06:24.881243 10603 solver.cpp:244]     Train net output #0: loss = 0.684989 (* 1 = 0.684989 loss)
I0805 20:06:24.881263 10603 sgd_solver.cpp:106] Iteration 96000, lr = 2.67565e-06
I0805 20:06:28.108361 10603 solver.cpp:228] Iteration 96100, loss = 0.690441
I0805 20:06:28.108407 10603 solver.cpp:244]     Train net output #0: loss = 0.690441 (* 1 = 0.690441 loss)
I0805 20:06:28.108414 10603 sgd_solver.cpp:106] Iteration 96100, lr = 2.67392e-06
I0805 20:06:31.370398 10603 solver.cpp:228] Iteration 96200, loss = 0.705537
I0805 20:06:31.370437 10603 solver.cpp:244]     Train net output #0: loss = 0.705537 (* 1 = 0.705537 loss)
I0805 20:06:31.370443 10603 sgd_solver.cpp:106] Iteration 96200, lr = 2.67219e-06
I0805 20:06:34.631624 10603 solver.cpp:228] Iteration 96300, loss = 0.69666
I0805 20:06:34.631671 10603 solver.cpp:244]     Train net output #0: loss = 0.69666 (* 1 = 0.69666 loss)
I0805 20:06:34.631677 10603 sgd_solver.cpp:106] Iteration 96300, lr = 2.67047e-06
I0805 20:06:37.884654 10603 solver.cpp:228] Iteration 96400, loss = 0.692999
I0805 20:06:37.884694 10603 solver.cpp:244]     Train net output #0: loss = 0.692999 (* 1 = 0.692999 loss)
I0805 20:06:37.884701 10603 sgd_solver.cpp:106] Iteration 96400, lr = 2.66875e-06
I0805 20:06:41.113996 10603 solver.cpp:337] Iteration 96500, Testing net (#0)
I0805 20:06:44.771209 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208663
I0805 20:06:44.771275 10603 solver.cpp:404]     Test net output #1: loss = 0.693379 (* 1 = 0.693379 loss)
I0805 20:06:44.784103 10603 solver.cpp:228] Iteration 96500, loss = 0.692005
I0805 20:06:44.784142 10603 solver.cpp:244]     Train net output #0: loss = 0.692005 (* 1 = 0.692005 loss)
I0805 20:06:44.784149 10603 sgd_solver.cpp:106] Iteration 96500, lr = 2.66703e-06
I0805 20:06:48.004693 10603 solver.cpp:228] Iteration 96600, loss = 0.704255
I0805 20:06:48.004736 10603 solver.cpp:244]     Train net output #0: loss = 0.704255 (* 1 = 0.704255 loss)
I0805 20:06:48.004742 10603 sgd_solver.cpp:106] Iteration 96600, lr = 2.66532e-06
I0805 20:06:51.244889 10603 solver.cpp:228] Iteration 96700, loss = 0.698739
I0805 20:06:51.244936 10603 solver.cpp:244]     Train net output #0: loss = 0.698739 (* 1 = 0.698739 loss)
I0805 20:06:51.244943 10603 sgd_solver.cpp:106] Iteration 96700, lr = 2.6636e-06
I0805 20:06:54.489364 10603 solver.cpp:228] Iteration 96800, loss = 0.687318
I0805 20:06:54.489408 10603 solver.cpp:244]     Train net output #0: loss = 0.687318 (* 1 = 0.687318 loss)
I0805 20:06:54.489413 10603 sgd_solver.cpp:106] Iteration 96800, lr = 2.66189e-06
I0805 20:06:57.729707 10603 solver.cpp:228] Iteration 96900, loss = 0.695823
I0805 20:06:57.729765 10603 solver.cpp:244]     Train net output #0: loss = 0.695823 (* 1 = 0.695823 loss)
I0805 20:06:57.729773 10603 sgd_solver.cpp:106] Iteration 96900, lr = 2.66018e-06
I0805 20:07:00.938400 10603 solver.cpp:337] Iteration 97000, Testing net (#0)
I0805 20:07:04.526751 10603 solver.cpp:404]     Test net output #0: accuracy = 0.207907
I0805 20:07:04.526793 10603 solver.cpp:404]     Test net output #1: loss = 0.693712 (* 1 = 0.693712 loss)
I0805 20:07:04.537400 10603 solver.cpp:228] Iteration 97000, loss = 0.708398
I0805 20:07:04.537478 10603 solver.cpp:244]     Train net output #0: loss = 0.708398 (* 1 = 0.708398 loss)
I0805 20:07:04.537495 10603 sgd_solver.cpp:106] Iteration 97000, lr = 2.65848e-06
I0805 20:07:07.738868 10603 solver.cpp:228] Iteration 97100, loss = 0.689818
I0805 20:07:07.738950 10603 solver.cpp:244]     Train net output #0: loss = 0.689818 (* 1 = 0.689818 loss)
I0805 20:07:07.738962 10603 sgd_solver.cpp:106] Iteration 97100, lr = 2.65678e-06
I0805 20:07:10.969753 10603 solver.cpp:228] Iteration 97200, loss = 0.688643
I0805 20:07:10.969802 10603 solver.cpp:244]     Train net output #0: loss = 0.688643 (* 1 = 0.688643 loss)
I0805 20:07:10.969810 10603 sgd_solver.cpp:106] Iteration 97200, lr = 2.65507e-06
I0805 20:07:14.216308 10603 solver.cpp:228] Iteration 97300, loss = 0.699917
I0805 20:07:14.216363 10603 solver.cpp:244]     Train net output #0: loss = 0.699917 (* 1 = 0.699917 loss)
I0805 20:07:14.216372 10603 sgd_solver.cpp:106] Iteration 97300, lr = 2.65338e-06
I0805 20:07:17.462085 10603 solver.cpp:228] Iteration 97400, loss = 0.690215
I0805 20:07:17.462121 10603 solver.cpp:244]     Train net output #0: loss = 0.690215 (* 1 = 0.690215 loss)
I0805 20:07:17.462126 10603 sgd_solver.cpp:106] Iteration 97400, lr = 2.65168e-06
I0805 20:07:20.678228 10603 solver.cpp:337] Iteration 97500, Testing net (#0)
I0805 20:07:24.277560 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208779
I0805 20:07:24.277611 10603 solver.cpp:404]     Test net output #1: loss = 0.693398 (* 1 = 0.693398 loss)
I0805 20:07:24.290796 10603 solver.cpp:228] Iteration 97500, loss = 0.693124
I0805 20:07:24.290832 10603 solver.cpp:244]     Train net output #0: loss = 0.693124 (* 1 = 0.693124 loss)
I0805 20:07:24.290851 10603 sgd_solver.cpp:106] Iteration 97500, lr = 2.64999e-06
I0805 20:07:27.503736 10603 solver.cpp:228] Iteration 97600, loss = 0.691863
I0805 20:07:27.503778 10603 solver.cpp:244]     Train net output #0: loss = 0.691863 (* 1 = 0.691863 loss)
I0805 20:07:27.503785 10603 sgd_solver.cpp:106] Iteration 97600, lr = 2.6483e-06
I0805 20:07:30.748330 10603 solver.cpp:228] Iteration 97700, loss = 0.691036
I0805 20:07:30.748369 10603 solver.cpp:244]     Train net output #0: loss = 0.691036 (* 1 = 0.691036 loss)
I0805 20:07:30.748375 10603 sgd_solver.cpp:106] Iteration 97700, lr = 2.64661e-06
I0805 20:07:34.000423 10603 solver.cpp:228] Iteration 97800, loss = 0.688052
I0805 20:07:34.000468 10603 solver.cpp:244]     Train net output #0: loss = 0.688052 (* 1 = 0.688052 loss)
I0805 20:07:34.000473 10603 sgd_solver.cpp:106] Iteration 97800, lr = 2.64493e-06
I0805 20:07:37.249480 10603 solver.cpp:228] Iteration 97900, loss = 0.698375
I0805 20:07:37.249514 10603 solver.cpp:244]     Train net output #0: loss = 0.698375 (* 1 = 0.698375 loss)
I0805 20:07:37.249521 10603 sgd_solver.cpp:106] Iteration 97900, lr = 2.64324e-06
I0805 20:07:40.471899 10603 solver.cpp:337] Iteration 98000, Testing net (#0)
I0805 20:07:42.038542 10603 blocking_queue.cpp:50] Data layer prefetch queue empty
I0805 20:07:44.003473 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208198
I0805 20:07:44.003532 10603 solver.cpp:404]     Test net output #1: loss = 0.69354 (* 1 = 0.69354 loss)
I0805 20:07:44.017171 10603 solver.cpp:228] Iteration 98000, loss = 0.699196
I0805 20:07:44.017236 10603 solver.cpp:244]     Train net output #0: loss = 0.699196 (* 1 = 0.699196 loss)
I0805 20:07:44.017256 10603 sgd_solver.cpp:106] Iteration 98000, lr = 2.64156e-06
I0805 20:07:47.257143 10603 solver.cpp:228] Iteration 98100, loss = 0.70289
I0805 20:07:47.257203 10603 solver.cpp:244]     Train net output #0: loss = 0.70289 (* 1 = 0.70289 loss)
I0805 20:07:47.257210 10603 sgd_solver.cpp:106] Iteration 98100, lr = 2.63989e-06
I0805 20:07:50.496466 10603 solver.cpp:228] Iteration 98200, loss = 0.701006
I0805 20:07:50.496505 10603 solver.cpp:244]     Train net output #0: loss = 0.701006 (* 1 = 0.701006 loss)
I0805 20:07:50.496510 10603 sgd_solver.cpp:106] Iteration 98200, lr = 2.63821e-06
I0805 20:07:53.734699 10603 solver.cpp:228] Iteration 98300, loss = 0.699607
I0805 20:07:53.734747 10603 solver.cpp:244]     Train net output #0: loss = 0.699607 (* 1 = 0.699607 loss)
I0805 20:07:53.734753 10603 sgd_solver.cpp:106] Iteration 98300, lr = 2.63654e-06
I0805 20:07:56.975066 10603 solver.cpp:228] Iteration 98400, loss = 0.694139
I0805 20:07:56.975108 10603 solver.cpp:244]     Train net output #0: loss = 0.694139 (* 1 = 0.694139 loss)
I0805 20:07:56.975114 10603 sgd_solver.cpp:106] Iteration 98400, lr = 2.63487e-06
I0805 20:08:00.188443 10603 solver.cpp:337] Iteration 98500, Testing net (#0)
I0805 20:08:03.786320 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208605
I0805 20:08:03.786360 10603 solver.cpp:404]     Test net output #1: loss = 0.693518 (* 1 = 0.693518 loss)
I0805 20:08:03.796619 10603 solver.cpp:228] Iteration 98500, loss = 0.70193
I0805 20:08:03.796648 10603 solver.cpp:244]     Train net output #0: loss = 0.70193 (* 1 = 0.70193 loss)
I0805 20:08:03.796658 10603 sgd_solver.cpp:106] Iteration 98500, lr = 2.6332e-06
I0805 20:08:07.015346 10603 solver.cpp:228] Iteration 98600, loss = 0.691632
I0805 20:08:07.015388 10603 solver.cpp:244]     Train net output #0: loss = 0.691632 (* 1 = 0.691632 loss)
I0805 20:08:07.015394 10603 sgd_solver.cpp:106] Iteration 98600, lr = 2.63153e-06
I0805 20:08:10.259361 10603 solver.cpp:228] Iteration 98700, loss = 0.700127
I0805 20:08:10.259399 10603 solver.cpp:244]     Train net output #0: loss = 0.700127 (* 1 = 0.700127 loss)
I0805 20:08:10.259405 10603 sgd_solver.cpp:106] Iteration 98700, lr = 2.62987e-06
I0805 20:08:13.523351 10603 solver.cpp:228] Iteration 98800, loss = 0.680941
I0805 20:08:13.523404 10603 solver.cpp:244]     Train net output #0: loss = 0.680941 (* 1 = 0.680941 loss)
I0805 20:08:13.523412 10603 sgd_solver.cpp:106] Iteration 98800, lr = 2.62821e-06
I0805 20:08:16.783080 10603 solver.cpp:228] Iteration 98900, loss = 0.696287
I0805 20:08:16.783125 10603 solver.cpp:244]     Train net output #0: loss = 0.696287 (* 1 = 0.696287 loss)
I0805 20:08:16.783131 10603 sgd_solver.cpp:106] Iteration 98900, lr = 2.62655e-06
I0805 20:08:20.008033 10603 solver.cpp:337] Iteration 99000, Testing net (#0)
I0805 20:08:23.648396 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0805 20:08:23.648437 10603 solver.cpp:404]     Test net output #1: loss = 0.693439 (* 1 = 0.693439 loss)
I0805 20:08:23.658663 10603 solver.cpp:228] Iteration 99000, loss = 0.70658
I0805 20:08:23.658692 10603 solver.cpp:244]     Train net output #0: loss = 0.70658 (* 1 = 0.70658 loss)
I0805 20:08:23.658699 10603 sgd_solver.cpp:106] Iteration 99000, lr = 2.6249e-06
I0805 20:08:26.858428 10603 solver.cpp:228] Iteration 99100, loss = 0.690754
I0805 20:08:26.858471 10603 solver.cpp:244]     Train net output #0: loss = 0.690754 (* 1 = 0.690754 loss)
I0805 20:08:26.858477 10603 sgd_solver.cpp:106] Iteration 99100, lr = 2.62324e-06
I0805 20:08:30.075559 10603 solver.cpp:228] Iteration 99200, loss = 0.69966
I0805 20:08:30.075601 10603 solver.cpp:244]     Train net output #0: loss = 0.69966 (* 1 = 0.69966 loss)
I0805 20:08:30.075608 10603 sgd_solver.cpp:106] Iteration 99200, lr = 2.62159e-06
I0805 20:08:33.319264 10603 solver.cpp:228] Iteration 99300, loss = 0.698679
I0805 20:08:33.319308 10603 solver.cpp:244]     Train net output #0: loss = 0.698679 (* 1 = 0.698679 loss)
I0805 20:08:33.319314 10603 sgd_solver.cpp:106] Iteration 99300, lr = 2.61995e-06
I0805 20:08:36.556453 10603 solver.cpp:228] Iteration 99400, loss = 0.694187
I0805 20:08:36.556495 10603 solver.cpp:244]     Train net output #0: loss = 0.694187 (* 1 = 0.694187 loss)
I0805 20:08:36.556501 10603 sgd_solver.cpp:106] Iteration 99400, lr = 2.6183e-06
I0805 20:08:39.762661 10603 solver.cpp:337] Iteration 99500, Testing net (#0)
I0805 20:08:43.361974 10603 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0805 20:08:43.362015 10603 solver.cpp:404]     Test net output #1: loss = 0.693186 (* 1 = 0.693186 loss)
I0805 20:08:43.375003 10603 solver.cpp:228] Iteration 99500, loss = 0.700464
I0805 20:08:43.375035 10603 solver.cpp:244]     Train net output #0: loss = 0.700464 (* 1 = 0.700464 loss)
I0805 20:08:43.375042 10603 sgd_solver.cpp:106] Iteration 99500, lr = 2.61666e-06
I0805 20:08:46.569914 10603 solver.cpp:228] Iteration 99600, loss = 0.683646
I0805 20:08:46.569960 10603 solver.cpp:244]     Train net output #0: loss = 0.683646 (* 1 = 0.683646 loss)
I0805 20:08:46.569967 10603 sgd_solver.cpp:106] Iteration 99600, lr = 2.61501e-06
I0805 20:08:49.802003 10603 solver.cpp:228] Iteration 99700, loss = 0.692326
I0805 20:08:49.802048 10603 solver.cpp:244]     Train net output #0: loss = 0.692326 (* 1 = 0.692326 loss)
I0805 20:08:49.802054 10603 sgd_solver.cpp:106] Iteration 99700, lr = 2.61338e-06
I0805 20:08:53.049268 10603 solver.cpp:228] Iteration 99800, loss = 0.693193
I0805 20:08:53.049312 10603 solver.cpp:244]     Train net output #0: loss = 0.693193 (* 1 = 0.693193 loss)
I0805 20:08:53.049319 10603 sgd_solver.cpp:106] Iteration 99800, lr = 2.61174e-06
I0805 20:08:56.293274 10603 solver.cpp:228] Iteration 99900, loss = 0.68986
I0805 20:08:56.293318 10603 solver.cpp:244]     Train net output #0: loss = 0.68986 (* 1 = 0.68986 loss)
I0805 20:08:56.293323 10603 sgd_solver.cpp:106] Iteration 99900, lr = 2.61011e-06
I0805 20:08:59.505841 10603 solver.cpp:454] Snapshotting to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_100000.caffemodel
I0805 20:08:59.881765 10603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_background_only_alex_net/person_background_only_alex_net_lr_0.00001_iter_100000.solverstate
I0805 20:09:00.016516 10603 solver.cpp:337] Iteration 100000, Testing net (#0)
I0805 20:09:03.535531 10603 solver.cpp:404]     Test net output #0: accuracy = 0.209128
I0805 20:09:03.535583 10603 solver.cpp:404]     Test net output #1: loss = 0.693438 (* 1 = 0.693438 loss)
I0805 20:09:03.548529 10603 solver.cpp:228] Iteration 100000, loss = 0.687228
I0805 20:09:03.548564 10603 solver.cpp:244]     Train net output #0: loss = 0.687228 (* 1 = 0.687228 loss)
I0805 20:09:03.548573 10603 sgd_solver.cpp:106] Iteration 100000, lr = 2.60847e-06
0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
iter: 0.0s
