WARNING: Logging before InitGoogleLogging() is written to STDERR
I0815 13:08:06.413388 19187 solver.cpp:48] Initializing solver from parameters: 
test_iter: 172
test_interval: 100
base_lr: 0.01
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.5
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 1000
snapshot: 10000
snapshot_prefix: "models/person_background_only_alex_net_mirror/person_background_only_alex_net_lr_0.01"
solver_mode: GPU
net: "nets/person_background_only_alex_net_mirror/trainval.prototxt"
I0815 13:08:06.413512 19187 solver.cpp:91] Creating training net from net file: nets/person_background_only_alex_net_mirror/trainval.prototxt
I0815 13:08:06.413816 19187 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0815 13:08:06.413836 19187 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0815 13:08:06.413975 19187 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mirror: true
    mean_file: "data/person_only_lmdb/person_background_only_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_only_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0815 13:08:06.414049 19187 layer_factory.hpp:77] Creating layer mnist
I0815 13:08:06.414579 19187 net.cpp:100] Creating Layer mnist
I0815 13:08:06.414592 19187 net.cpp:408] mnist -> data
I0815 13:08:06.414607 19187 net.cpp:408] mnist -> label
I0815 13:08:06.414621 19187 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_only_color_mean.binaryproto
I0815 13:08:06.416105 19196 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_only_train_lmdb
I0815 13:08:06.435570 19187 data_layer.cpp:41] output data size: 128,3,128,128
I0815 13:08:06.492693 19187 net.cpp:150] Setting up mnist
I0815 13:08:06.492733 19187 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0815 13:08:06.492739 19187 net.cpp:157] Top shape: 128 (128)
I0815 13:08:06.492743 19187 net.cpp:165] Memory required for data: 25166336
I0815 13:08:06.492749 19187 layer_factory.hpp:77] Creating layer conv1
I0815 13:08:06.492774 19187 net.cpp:100] Creating Layer conv1
I0815 13:08:06.492779 19187 net.cpp:434] conv1 <- data
I0815 13:08:06.492789 19187 net.cpp:408] conv1 -> conv1
I0815 13:08:06.817029 19187 net.cpp:150] Setting up conv1
I0815 13:08:06.817061 19187 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0815 13:08:06.817065 19187 net.cpp:165] Memory required for data: 69403136
I0815 13:08:06.817083 19187 layer_factory.hpp:77] Creating layer relu1
I0815 13:08:06.817101 19187 net.cpp:100] Creating Layer relu1
I0815 13:08:06.817106 19187 net.cpp:434] relu1 <- conv1
I0815 13:08:06.817111 19187 net.cpp:395] relu1 -> conv1 (in-place)
I0815 13:08:06.817304 19187 net.cpp:150] Setting up relu1
I0815 13:08:06.817317 19187 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0815 13:08:06.817320 19187 net.cpp:165] Memory required for data: 113639936
I0815 13:08:06.817323 19187 layer_factory.hpp:77] Creating layer norm1
I0815 13:08:06.817334 19187 net.cpp:100] Creating Layer norm1
I0815 13:08:06.817338 19187 net.cpp:434] norm1 <- conv1
I0815 13:08:06.817343 19187 net.cpp:408] norm1 -> norm1
I0815 13:08:06.817842 19187 net.cpp:150] Setting up norm1
I0815 13:08:06.817858 19187 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0815 13:08:06.817862 19187 net.cpp:165] Memory required for data: 157876736
I0815 13:08:06.817867 19187 layer_factory.hpp:77] Creating layer pool1
I0815 13:08:06.817878 19187 net.cpp:100] Creating Layer pool1
I0815 13:08:06.817881 19187 net.cpp:434] pool1 <- norm1
I0815 13:08:06.817888 19187 net.cpp:408] pool1 -> pool1
I0815 13:08:06.817930 19187 net.cpp:150] Setting up pool1
I0815 13:08:06.817939 19187 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0815 13:08:06.817942 19187 net.cpp:165] Memory required for data: 168935936
I0815 13:08:06.817945 19187 layer_factory.hpp:77] Creating layer conv2
I0815 13:08:06.817960 19187 net.cpp:100] Creating Layer conv2
I0815 13:08:06.817965 19187 net.cpp:434] conv2 <- pool1
I0815 13:08:06.817972 19187 net.cpp:408] conv2 -> conv2
I0815 13:08:06.824370 19187 net.cpp:150] Setting up conv2
I0815 13:08:06.824388 19187 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0815 13:08:06.824390 19187 net.cpp:165] Memory required for data: 198427136
I0815 13:08:06.824400 19187 layer_factory.hpp:77] Creating layer relu2
I0815 13:08:06.824409 19187 net.cpp:100] Creating Layer relu2
I0815 13:08:06.824412 19187 net.cpp:434] relu2 <- conv2
I0815 13:08:06.824419 19187 net.cpp:395] relu2 -> conv2 (in-place)
I0815 13:08:06.824890 19187 net.cpp:150] Setting up relu2
I0815 13:08:06.824910 19187 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0815 13:08:06.824914 19187 net.cpp:165] Memory required for data: 227918336
I0815 13:08:06.824918 19187 layer_factory.hpp:77] Creating layer norm2
I0815 13:08:06.824924 19187 net.cpp:100] Creating Layer norm2
I0815 13:08:06.824929 19187 net.cpp:434] norm2 <- conv2
I0815 13:08:06.824935 19187 net.cpp:408] norm2 -> norm2
I0815 13:08:06.825157 19187 net.cpp:150] Setting up norm2
I0815 13:08:06.825170 19187 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0815 13:08:06.825173 19187 net.cpp:165] Memory required for data: 257409536
I0815 13:08:06.825176 19187 layer_factory.hpp:77] Creating layer pool2
I0815 13:08:06.825186 19187 net.cpp:100] Creating Layer pool2
I0815 13:08:06.825189 19187 net.cpp:434] pool2 <- norm2
I0815 13:08:06.825197 19187 net.cpp:408] pool2 -> pool2
I0815 13:08:06.825240 19187 net.cpp:150] Setting up pool2
I0815 13:08:06.825248 19187 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0815 13:08:06.825251 19187 net.cpp:165] Memory required for data: 263832064
I0815 13:08:06.825254 19187 layer_factory.hpp:77] Creating layer conv3
I0815 13:08:06.825265 19187 net.cpp:100] Creating Layer conv3
I0815 13:08:06.825268 19187 net.cpp:434] conv3 <- pool2
I0815 13:08:06.825275 19187 net.cpp:408] conv3 -> conv3
I0815 13:08:06.838675 19187 net.cpp:150] Setting up conv3
I0815 13:08:06.838691 19187 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0815 13:08:06.838696 19187 net.cpp:165] Memory required for data: 273465856
I0815 13:08:06.838707 19187 layer_factory.hpp:77] Creating layer relu3
I0815 13:08:06.838714 19187 net.cpp:100] Creating Layer relu3
I0815 13:08:06.838717 19187 net.cpp:434] relu3 <- conv3
I0815 13:08:06.838722 19187 net.cpp:395] relu3 -> conv3 (in-place)
I0815 13:08:06.838920 19187 net.cpp:150] Setting up relu3
I0815 13:08:06.838932 19187 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0815 13:08:06.838935 19187 net.cpp:165] Memory required for data: 283099648
I0815 13:08:06.838939 19187 layer_factory.hpp:77] Creating layer conv4
I0815 13:08:06.838953 19187 net.cpp:100] Creating Layer conv4
I0815 13:08:06.838958 19187 net.cpp:434] conv4 <- conv3
I0815 13:08:06.838964 19187 net.cpp:408] conv4 -> conv4
I0815 13:08:06.850250 19187 net.cpp:150] Setting up conv4
I0815 13:08:06.850266 19187 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0815 13:08:06.850270 19187 net.cpp:165] Memory required for data: 292733440
I0815 13:08:06.850277 19187 layer_factory.hpp:77] Creating layer relu4
I0815 13:08:06.850286 19187 net.cpp:100] Creating Layer relu4
I0815 13:08:06.850289 19187 net.cpp:434] relu4 <- conv4
I0815 13:08:06.850294 19187 net.cpp:395] relu4 -> conv4 (in-place)
I0815 13:08:06.850498 19187 net.cpp:150] Setting up relu4
I0815 13:08:06.850510 19187 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0815 13:08:06.850513 19187 net.cpp:165] Memory required for data: 302367232
I0815 13:08:06.850517 19187 layer_factory.hpp:77] Creating layer conv5
I0815 13:08:06.850529 19187 net.cpp:100] Creating Layer conv5
I0815 13:08:06.850533 19187 net.cpp:434] conv5 <- conv4
I0815 13:08:06.850539 19187 net.cpp:408] conv5 -> conv5
I0815 13:08:06.859046 19187 net.cpp:150] Setting up conv5
I0815 13:08:06.859063 19187 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0815 13:08:06.859066 19187 net.cpp:165] Memory required for data: 308789760
I0815 13:08:06.859076 19187 layer_factory.hpp:77] Creating layer relu5
I0815 13:08:06.859086 19187 net.cpp:100] Creating Layer relu5
I0815 13:08:06.859091 19187 net.cpp:434] relu5 <- conv5
I0815 13:08:06.859096 19187 net.cpp:395] relu5 -> conv5 (in-place)
I0815 13:08:06.859299 19187 net.cpp:150] Setting up relu5
I0815 13:08:06.859311 19187 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0815 13:08:06.859314 19187 net.cpp:165] Memory required for data: 315212288
I0815 13:08:06.859318 19187 layer_factory.hpp:77] Creating layer pool5
I0815 13:08:06.859324 19187 net.cpp:100] Creating Layer pool5
I0815 13:08:06.859328 19187 net.cpp:434] pool5 <- conv5
I0815 13:08:06.859338 19187 net.cpp:408] pool5 -> pool5
I0815 13:08:06.859390 19187 net.cpp:150] Setting up pool5
I0815 13:08:06.859398 19187 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0815 13:08:06.859401 19187 net.cpp:165] Memory required for data: 316391936
I0815 13:08:06.859405 19187 layer_factory.hpp:77] Creating layer fc6
I0815 13:08:06.859418 19187 net.cpp:100] Creating Layer fc6
I0815 13:08:06.859423 19187 net.cpp:434] fc6 <- pool5
I0815 13:08:06.859429 19187 net.cpp:408] fc6 -> fc6
I0815 13:08:06.991262 19187 net.cpp:150] Setting up fc6
I0815 13:08:06.991299 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:06.991302 19187 net.cpp:165] Memory required for data: 318489088
I0815 13:08:06.991317 19187 layer_factory.hpp:77] Creating layer relu6
I0815 13:08:06.991328 19187 net.cpp:100] Creating Layer relu6
I0815 13:08:06.991333 19187 net.cpp:434] relu6 <- fc6
I0815 13:08:06.991340 19187 net.cpp:395] relu6 -> fc6 (in-place)
I0815 13:08:06.991952 19187 net.cpp:150] Setting up relu6
I0815 13:08:06.991968 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:06.991971 19187 net.cpp:165] Memory required for data: 320586240
I0815 13:08:06.991974 19187 layer_factory.hpp:77] Creating layer drop6
I0815 13:08:06.991983 19187 net.cpp:100] Creating Layer drop6
I0815 13:08:06.991986 19187 net.cpp:434] drop6 <- fc6
I0815 13:08:06.991994 19187 net.cpp:395] drop6 -> fc6 (in-place)
I0815 13:08:06.992022 19187 net.cpp:150] Setting up drop6
I0815 13:08:06.992027 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:06.992030 19187 net.cpp:165] Memory required for data: 322683392
I0815 13:08:06.992033 19187 layer_factory.hpp:77] Creating layer fc7
I0815 13:08:06.992045 19187 net.cpp:100] Creating Layer fc7
I0815 13:08:06.992051 19187 net.cpp:434] fc7 <- fc6
I0815 13:08:06.992058 19187 net.cpp:408] fc7 -> fc7
I0815 13:08:07.225486 19187 net.cpp:150] Setting up fc7
I0815 13:08:07.225528 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:07.225536 19187 net.cpp:165] Memory required for data: 324780544
I0815 13:08:07.225559 19187 layer_factory.hpp:77] Creating layer relu7
I0815 13:08:07.225576 19187 net.cpp:100] Creating Layer relu7
I0815 13:08:07.225584 19187 net.cpp:434] relu7 <- fc7
I0815 13:08:07.225600 19187 net.cpp:395] relu7 -> fc7 (in-place)
I0815 13:08:07.226119 19187 net.cpp:150] Setting up relu7
I0815 13:08:07.226131 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:07.226135 19187 net.cpp:165] Memory required for data: 326877696
I0815 13:08:07.226137 19187 layer_factory.hpp:77] Creating layer drop7
I0815 13:08:07.226150 19187 net.cpp:100] Creating Layer drop7
I0815 13:08:07.226153 19187 net.cpp:434] drop7 <- fc7
I0815 13:08:07.226158 19187 net.cpp:395] drop7 -> fc7 (in-place)
I0815 13:08:07.226186 19187 net.cpp:150] Setting up drop7
I0815 13:08:07.226196 19187 net.cpp:157] Top shape: 128 4096 (524288)
I0815 13:08:07.226198 19187 net.cpp:165] Memory required for data: 328974848
I0815 13:08:07.226202 19187 layer_factory.hpp:77] Creating layer fc8
I0815 13:08:07.226217 19187 net.cpp:100] Creating Layer fc8
I0815 13:08:07.226220 19187 net.cpp:434] fc8 <- fc7
I0815 13:08:07.226227 19187 net.cpp:408] fc8 -> fc8
I0815 13:08:07.227928 19187 net.cpp:150] Setting up fc8
I0815 13:08:07.227944 19187 net.cpp:157] Top shape: 128 2 (256)
I0815 13:08:07.227947 19187 net.cpp:165] Memory required for data: 328975872
I0815 13:08:07.227954 19187 layer_factory.hpp:77] Creating layer loss
I0815 13:08:07.227963 19187 net.cpp:100] Creating Layer loss
I0815 13:08:07.227967 19187 net.cpp:434] loss <- fc8
I0815 13:08:07.227970 19187 net.cpp:434] loss <- label
I0815 13:08:07.227975 19187 net.cpp:408] loss -> loss
I0815 13:08:07.227985 19187 layer_factory.hpp:77] Creating layer loss
I0815 13:08:07.228281 19187 net.cpp:150] Setting up loss
I0815 13:08:07.228292 19187 net.cpp:157] Top shape: (1)
I0815 13:08:07.228296 19187 net.cpp:160]     with loss weight 1
I0815 13:08:07.228305 19187 net.cpp:165] Memory required for data: 328975876
I0815 13:08:07.228310 19187 net.cpp:226] loss needs backward computation.
I0815 13:08:07.228314 19187 net.cpp:226] fc8 needs backward computation.
I0815 13:08:07.228318 19187 net.cpp:226] drop7 needs backward computation.
I0815 13:08:07.228322 19187 net.cpp:226] relu7 needs backward computation.
I0815 13:08:07.228324 19187 net.cpp:226] fc7 needs backward computation.
I0815 13:08:07.228327 19187 net.cpp:226] drop6 needs backward computation.
I0815 13:08:07.228330 19187 net.cpp:226] relu6 needs backward computation.
I0815 13:08:07.228333 19187 net.cpp:226] fc6 needs backward computation.
I0815 13:08:07.228337 19187 net.cpp:226] pool5 needs backward computation.
I0815 13:08:07.228340 19187 net.cpp:226] relu5 needs backward computation.
I0815 13:08:07.228343 19187 net.cpp:226] conv5 needs backward computation.
I0815 13:08:07.228346 19187 net.cpp:226] relu4 needs backward computation.
I0815 13:08:07.228349 19187 net.cpp:226] conv4 needs backward computation.
I0815 13:08:07.228353 19187 net.cpp:226] relu3 needs backward computation.
I0815 13:08:07.228356 19187 net.cpp:226] conv3 needs backward computation.
I0815 13:08:07.228359 19187 net.cpp:226] pool2 needs backward computation.
I0815 13:08:07.228363 19187 net.cpp:226] norm2 needs backward computation.
I0815 13:08:07.228366 19187 net.cpp:226] relu2 needs backward computation.
I0815 13:08:07.228369 19187 net.cpp:226] conv2 needs backward computation.
I0815 13:08:07.228373 19187 net.cpp:226] pool1 needs backward computation.
I0815 13:08:07.228379 19187 net.cpp:226] norm1 needs backward computation.
I0815 13:08:07.228381 19187 net.cpp:226] relu1 needs backward computation.
I0815 13:08:07.228394 19187 net.cpp:226] conv1 needs backward computation.
I0815 13:08:07.228399 19187 net.cpp:228] mnist does not need backward computation.
I0815 13:08:07.228401 19187 net.cpp:270] This network produces output loss
I0815 13:08:07.228420 19187 net.cpp:283] Network initialization done.
I0815 13:08:07.229002 19187 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_background_only_alex_net_mirror/trainval.prototxt
I0815 13:08:07.229046 19187 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0815 13:08:07.229218 19187 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_file: "data/person_only_lmdb/person_background_only_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_background_only_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0815 13:08:07.229326 19187 layer_factory.hpp:77] Creating layer mnist
I0815 13:08:07.229923 19187 net.cpp:100] Creating Layer mnist
I0815 13:08:07.229933 19187 net.cpp:408] mnist -> data
I0815 13:08:07.229943 19187 net.cpp:408] mnist -> label
I0815 13:08:07.229954 19187 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_background_only_color_mean.binaryproto
I0815 13:08:07.231487 19199 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_background_only_test_lmdb
I0815 13:08:07.231806 19187 data_layer.cpp:41] output data size: 100,3,128,128
I0815 13:08:07.293860 19187 net.cpp:150] Setting up mnist
I0815 13:08:07.293905 19187 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0815 13:08:07.293913 19187 net.cpp:157] Top shape: 100 (100)
I0815 13:08:07.293917 19187 net.cpp:165] Memory required for data: 19661200
I0815 13:08:07.293926 19187 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0815 13:08:07.293948 19187 net.cpp:100] Creating Layer label_mnist_1_split
I0815 13:08:07.293956 19187 net.cpp:434] label_mnist_1_split <- label
I0815 13:08:07.293969 19187 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I0815 13:08:07.293987 19187 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I0815 13:08:07.294109 19187 net.cpp:150] Setting up label_mnist_1_split
I0815 13:08:07.294123 19187 net.cpp:157] Top shape: 100 (100)
I0815 13:08:07.294129 19187 net.cpp:157] Top shape: 100 (100)
I0815 13:08:07.294133 19187 net.cpp:165] Memory required for data: 19662000
I0815 13:08:07.294138 19187 layer_factory.hpp:77] Creating layer conv1
I0815 13:08:07.294160 19187 net.cpp:100] Creating Layer conv1
I0815 13:08:07.294169 19187 net.cpp:434] conv1 <- data
I0815 13:08:07.294181 19187 net.cpp:408] conv1 -> conv1
I0815 13:08:07.301533 19187 net.cpp:150] Setting up conv1
I0815 13:08:07.301568 19187 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0815 13:08:07.301576 19187 net.cpp:165] Memory required for data: 54222000
I0815 13:08:07.301599 19187 layer_factory.hpp:77] Creating layer relu1
I0815 13:08:07.301614 19187 net.cpp:100] Creating Layer relu1
I0815 13:08:07.301620 19187 net.cpp:434] relu1 <- conv1
I0815 13:08:07.301637 19187 net.cpp:395] relu1 -> conv1 (in-place)
I0815 13:08:07.302012 19187 net.cpp:150] Setting up relu1
I0815 13:08:07.302031 19187 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0815 13:08:07.302037 19187 net.cpp:165] Memory required for data: 88782000
I0815 13:08:07.302043 19187 layer_factory.hpp:77] Creating layer norm1
I0815 13:08:07.302062 19187 net.cpp:100] Creating Layer norm1
I0815 13:08:07.302067 19187 net.cpp:434] norm1 <- conv1
I0815 13:08:07.302079 19187 net.cpp:408] norm1 -> norm1
I0815 13:08:07.303053 19187 net.cpp:150] Setting up norm1
I0815 13:08:07.303087 19187 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0815 13:08:07.303095 19187 net.cpp:165] Memory required for data: 123342000
I0815 13:08:07.303102 19187 layer_factory.hpp:77] Creating layer pool1
I0815 13:08:07.303115 19187 net.cpp:100] Creating Layer pool1
I0815 13:08:07.303122 19187 net.cpp:434] pool1 <- norm1
I0815 13:08:07.303134 19187 net.cpp:408] pool1 -> pool1
I0815 13:08:07.303216 19187 net.cpp:150] Setting up pool1
I0815 13:08:07.303231 19187 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0815 13:08:07.303236 19187 net.cpp:165] Memory required for data: 131982000
I0815 13:08:07.303242 19187 layer_factory.hpp:77] Creating layer conv2
I0815 13:08:07.303262 19187 net.cpp:100] Creating Layer conv2
I0815 13:08:07.303272 19187 net.cpp:434] conv2 <- pool1
I0815 13:08:07.303285 19187 net.cpp:408] conv2 -> conv2
I0815 13:08:07.315055 19187 net.cpp:150] Setting up conv2
I0815 13:08:07.315086 19187 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0815 13:08:07.315093 19187 net.cpp:165] Memory required for data: 155022000
I0815 13:08:07.315110 19187 layer_factory.hpp:77] Creating layer relu2
I0815 13:08:07.315124 19187 net.cpp:100] Creating Layer relu2
I0815 13:08:07.315130 19187 net.cpp:434] relu2 <- conv2
I0815 13:08:07.315143 19187 net.cpp:395] relu2 -> conv2 (in-place)
I0815 13:08:07.316007 19187 net.cpp:150] Setting up relu2
I0815 13:08:07.316038 19187 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0815 13:08:07.316045 19187 net.cpp:165] Memory required for data: 178062000
I0815 13:08:07.316051 19187 layer_factory.hpp:77] Creating layer norm2
I0815 13:08:07.316069 19187 net.cpp:100] Creating Layer norm2
I0815 13:08:07.316076 19187 net.cpp:434] norm2 <- conv2
I0815 13:08:07.316087 19187 net.cpp:408] norm2 -> norm2
I0815 13:08:07.316591 19187 net.cpp:150] Setting up norm2
I0815 13:08:07.316613 19187 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0815 13:08:07.316618 19187 net.cpp:165] Memory required for data: 201102000
I0815 13:08:07.316624 19187 layer_factory.hpp:77] Creating layer pool2
I0815 13:08:07.316638 19187 net.cpp:100] Creating Layer pool2
I0815 13:08:07.316644 19187 net.cpp:434] pool2 <- norm2
I0815 13:08:07.316654 19187 net.cpp:408] pool2 -> pool2
I0815 13:08:07.316731 19187 net.cpp:150] Setting up pool2
I0815 13:08:07.316745 19187 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0815 13:08:07.316751 19187 net.cpp:165] Memory required for data: 206119600
I0815 13:08:07.316756 19187 layer_factory.hpp:77] Creating layer conv3
I0815 13:08:07.316776 19187 net.cpp:100] Creating Layer conv3
I0815 13:08:07.316784 19187 net.cpp:434] conv3 <- pool2
I0815 13:08:07.316797 19187 net.cpp:408] conv3 -> conv3
I0815 13:08:07.340085 19187 net.cpp:150] Setting up conv3
I0815 13:08:07.340122 19187 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0815 13:08:07.340128 19187 net.cpp:165] Memory required for data: 213646000
I0815 13:08:07.340150 19187 layer_factory.hpp:77] Creating layer relu3
I0815 13:08:07.340173 19187 net.cpp:100] Creating Layer relu3
I0815 13:08:07.340181 19187 net.cpp:434] relu3 <- conv3
I0815 13:08:07.340191 19187 net.cpp:395] relu3 -> conv3 (in-place)
I0815 13:08:07.340548 19187 net.cpp:150] Setting up relu3
I0815 13:08:07.340566 19187 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0815 13:08:07.340571 19187 net.cpp:165] Memory required for data: 221172400
I0815 13:08:07.340576 19187 layer_factory.hpp:77] Creating layer conv4
I0815 13:08:07.340596 19187 net.cpp:100] Creating Layer conv4
I0815 13:08:07.340602 19187 net.cpp:434] conv4 <- conv3
I0815 13:08:07.340612 19187 net.cpp:408] conv4 -> conv4
I0815 13:08:07.363409 19187 net.cpp:150] Setting up conv4
I0815 13:08:07.363447 19187 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0815 13:08:07.363453 19187 net.cpp:165] Memory required for data: 228698800
I0815 13:08:07.363468 19187 layer_factory.hpp:77] Creating layer relu4
I0815 13:08:07.363487 19187 net.cpp:100] Creating Layer relu4
I0815 13:08:07.363493 19187 net.cpp:434] relu4 <- conv4
I0815 13:08:07.363507 19187 net.cpp:395] relu4 -> conv4 (in-place)
I0815 13:08:07.364282 19187 net.cpp:150] Setting up relu4
I0815 13:08:07.364305 19187 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0815 13:08:07.364310 19187 net.cpp:165] Memory required for data: 236225200
I0815 13:08:07.364315 19187 layer_factory.hpp:77] Creating layer conv5
I0815 13:08:07.364336 19187 net.cpp:100] Creating Layer conv5
I0815 13:08:07.364341 19187 net.cpp:434] conv5 <- conv4
I0815 13:08:07.364354 19187 net.cpp:408] conv5 -> conv5
I0815 13:08:07.376694 19187 net.cpp:150] Setting up conv5
I0815 13:08:07.376729 19187 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0815 13:08:07.376734 19187 net.cpp:165] Memory required for data: 241242800
I0815 13:08:07.376754 19187 layer_factory.hpp:77] Creating layer relu5
I0815 13:08:07.376770 19187 net.cpp:100] Creating Layer relu5
I0815 13:08:07.376775 19187 net.cpp:434] relu5 <- conv5
I0815 13:08:07.376785 19187 net.cpp:395] relu5 -> conv5 (in-place)
I0815 13:08:07.377084 19187 net.cpp:150] Setting up relu5
I0815 13:08:07.377100 19187 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0815 13:08:07.377104 19187 net.cpp:165] Memory required for data: 246260400
I0815 13:08:07.377109 19187 layer_factory.hpp:77] Creating layer pool5
I0815 13:08:07.377126 19187 net.cpp:100] Creating Layer pool5
I0815 13:08:07.377131 19187 net.cpp:434] pool5 <- conv5
I0815 13:08:07.377140 19187 net.cpp:408] pool5 -> pool5
I0815 13:08:07.377220 19187 net.cpp:150] Setting up pool5
I0815 13:08:07.377233 19187 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0815 13:08:07.377235 19187 net.cpp:165] Memory required for data: 247182000
I0815 13:08:07.377240 19187 layer_factory.hpp:77] Creating layer fc6
I0815 13:08:07.377254 19187 net.cpp:100] Creating Layer fc6
I0815 13:08:07.377260 19187 net.cpp:434] fc6 <- pool5
I0815 13:08:07.377269 19187 net.cpp:408] fc6 -> fc6
I0815 13:08:07.518404 19187 net.cpp:150] Setting up fc6
I0815 13:08:07.518445 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.518447 19187 net.cpp:165] Memory required for data: 248820400
I0815 13:08:07.518460 19187 layer_factory.hpp:77] Creating layer relu6
I0815 13:08:07.518474 19187 net.cpp:100] Creating Layer relu6
I0815 13:08:07.518479 19187 net.cpp:434] relu6 <- fc6
I0815 13:08:07.518489 19187 net.cpp:395] relu6 -> fc6 (in-place)
I0815 13:08:07.518779 19187 net.cpp:150] Setting up relu6
I0815 13:08:07.518790 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.518792 19187 net.cpp:165] Memory required for data: 250458800
I0815 13:08:07.518795 19187 layer_factory.hpp:77] Creating layer drop6
I0815 13:08:07.518803 19187 net.cpp:100] Creating Layer drop6
I0815 13:08:07.518806 19187 net.cpp:434] drop6 <- fc6
I0815 13:08:07.518812 19187 net.cpp:395] drop6 -> fc6 (in-place)
I0815 13:08:07.518852 19187 net.cpp:150] Setting up drop6
I0815 13:08:07.518862 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.518864 19187 net.cpp:165] Memory required for data: 252097200
I0815 13:08:07.518867 19187 layer_factory.hpp:77] Creating layer fc7
I0815 13:08:07.518877 19187 net.cpp:100] Creating Layer fc7
I0815 13:08:07.518879 19187 net.cpp:434] fc7 <- fc6
I0815 13:08:07.518887 19187 net.cpp:408] fc7 -> fc7
I0815 13:08:07.750483 19187 net.cpp:150] Setting up fc7
I0815 13:08:07.750524 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.750527 19187 net.cpp:165] Memory required for data: 253735600
I0815 13:08:07.750540 19187 layer_factory.hpp:77] Creating layer relu7
I0815 13:08:07.750552 19187 net.cpp:100] Creating Layer relu7
I0815 13:08:07.750556 19187 net.cpp:434] relu7 <- fc7
I0815 13:08:07.750566 19187 net.cpp:395] relu7 -> fc7 (in-place)
I0815 13:08:07.751322 19187 net.cpp:150] Setting up relu7
I0815 13:08:07.751338 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.751340 19187 net.cpp:165] Memory required for data: 255374000
I0815 13:08:07.751343 19187 layer_factory.hpp:77] Creating layer drop7
I0815 13:08:07.751354 19187 net.cpp:100] Creating Layer drop7
I0815 13:08:07.751358 19187 net.cpp:434] drop7 <- fc7
I0815 13:08:07.751363 19187 net.cpp:395] drop7 -> fc7 (in-place)
I0815 13:08:07.751405 19187 net.cpp:150] Setting up drop7
I0815 13:08:07.751412 19187 net.cpp:157] Top shape: 100 4096 (409600)
I0815 13:08:07.751415 19187 net.cpp:165] Memory required for data: 257012400
I0815 13:08:07.751418 19187 layer_factory.hpp:77] Creating layer fc8
I0815 13:08:07.751427 19187 net.cpp:100] Creating Layer fc8
I0815 13:08:07.751430 19187 net.cpp:434] fc8 <- fc7
I0815 13:08:07.751441 19187 net.cpp:408] fc8 -> fc8
I0815 13:08:07.751672 19187 net.cpp:150] Setting up fc8
I0815 13:08:07.751682 19187 net.cpp:157] Top shape: 100 2 (200)
I0815 13:08:07.751684 19187 net.cpp:165] Memory required for data: 257013200
I0815 13:08:07.751690 19187 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0815 13:08:07.751698 19187 net.cpp:100] Creating Layer fc8_fc8_0_split
I0815 13:08:07.751699 19187 net.cpp:434] fc8_fc8_0_split <- fc8
I0815 13:08:07.751706 19187 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0815 13:08:07.751713 19187 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0815 13:08:07.751757 19187 net.cpp:150] Setting up fc8_fc8_0_split
I0815 13:08:07.751765 19187 net.cpp:157] Top shape: 100 2 (200)
I0815 13:08:07.751768 19187 net.cpp:157] Top shape: 100 2 (200)
I0815 13:08:07.751771 19187 net.cpp:165] Memory required for data: 257014800
I0815 13:08:07.751773 19187 layer_factory.hpp:77] Creating layer accuracy
I0815 13:08:07.751785 19187 net.cpp:100] Creating Layer accuracy
I0815 13:08:07.751787 19187 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0815 13:08:07.751791 19187 net.cpp:434] accuracy <- label_mnist_1_split_0
I0815 13:08:07.751798 19187 net.cpp:408] accuracy -> accuracy
I0815 13:08:07.751806 19187 net.cpp:150] Setting up accuracy
I0815 13:08:07.751811 19187 net.cpp:157] Top shape: (1)
I0815 13:08:07.751813 19187 net.cpp:165] Memory required for data: 257014804
I0815 13:08:07.751816 19187 layer_factory.hpp:77] Creating layer loss
I0815 13:08:07.751821 19187 net.cpp:100] Creating Layer loss
I0815 13:08:07.751824 19187 net.cpp:434] loss <- fc8_fc8_0_split_1
I0815 13:08:07.751828 19187 net.cpp:434] loss <- label_mnist_1_split_1
I0815 13:08:07.751834 19187 net.cpp:408] loss -> loss
I0815 13:08:07.751842 19187 layer_factory.hpp:77] Creating layer loss
I0815 13:08:07.752166 19187 net.cpp:150] Setting up loss
I0815 13:08:07.752179 19187 net.cpp:157] Top shape: (1)
I0815 13:08:07.752182 19187 net.cpp:160]     with loss weight 1
I0815 13:08:07.752192 19187 net.cpp:165] Memory required for data: 257014808
I0815 13:08:07.752197 19187 net.cpp:226] loss needs backward computation.
I0815 13:08:07.752202 19187 net.cpp:228] accuracy does not need backward computation.
I0815 13:08:07.752205 19187 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0815 13:08:07.752208 19187 net.cpp:226] fc8 needs backward computation.
I0815 13:08:07.752213 19187 net.cpp:226] drop7 needs backward computation.
I0815 13:08:07.752214 19187 net.cpp:226] relu7 needs backward computation.
I0815 13:08:07.752218 19187 net.cpp:226] fc7 needs backward computation.
I0815 13:08:07.752220 19187 net.cpp:226] drop6 needs backward computation.
I0815 13:08:07.752223 19187 net.cpp:226] relu6 needs backward computation.
I0815 13:08:07.752228 19187 net.cpp:226] fc6 needs backward computation.
I0815 13:08:07.752230 19187 net.cpp:226] pool5 needs backward computation.
I0815 13:08:07.752233 19187 net.cpp:226] relu5 needs backward computation.
I0815 13:08:07.752238 19187 net.cpp:226] conv5 needs backward computation.
I0815 13:08:07.752240 19187 net.cpp:226] relu4 needs backward computation.
I0815 13:08:07.752243 19187 net.cpp:226] conv4 needs backward computation.
I0815 13:08:07.752248 19187 net.cpp:226] relu3 needs backward computation.
I0815 13:08:07.752250 19187 net.cpp:226] conv3 needs backward computation.
I0815 13:08:07.752254 19187 net.cpp:226] pool2 needs backward computation.
I0815 13:08:07.752257 19187 net.cpp:226] norm2 needs backward computation.
I0815 13:08:07.752260 19187 net.cpp:226] relu2 needs backward computation.
I0815 13:08:07.752264 19187 net.cpp:226] conv2 needs backward computation.
I0815 13:08:07.752267 19187 net.cpp:226] pool1 needs backward computation.
I0815 13:08:07.752270 19187 net.cpp:226] norm1 needs backward computation.
I0815 13:08:07.752274 19187 net.cpp:226] relu1 needs backward computation.
I0815 13:08:07.752277 19187 net.cpp:226] conv1 needs backward computation.
I0815 13:08:07.752281 19187 net.cpp:228] label_mnist_1_split does not need backward computation.
I0815 13:08:07.752285 19187 net.cpp:228] mnist does not need backward computation.
I0815 13:08:07.752288 19187 net.cpp:270] This network produces output accuracy
I0815 13:08:07.752292 19187 net.cpp:270] This network produces output loss
I0815 13:08:07.752313 19187 net.cpp:283] Network initialization done.
I0815 13:08:07.752405 19187 solver.cpp:60] Solver scaffolding done.
I0815 13:08:07.755825 19187 solver.cpp:337] Iteration 0, Testing net (#0)
I0815 13:08:07.867228 19187 blocking_queue.cpp:50] Data layer prefetch queue empty
I0815 13:08:10.178141 19187 solver.cpp:404]     Test net output #0: accuracy = 0.208372
I0815 13:08:10.178176 19187 solver.cpp:404]     Test net output #1: loss = 0.703671 (* 1 = 0.703671 loss)
I0815 13:08:10.212327 19187 solver.cpp:228] Iteration 0, loss = 0.69541
I0815 13:08:10.212384 19187 solver.cpp:244]     Train net output #0: loss = 0.69541 (* 1 = 0.69541 loss)
I0815 13:08:10.212405 19187 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0815 13:08:14.657655 19187 solver.cpp:337] Iteration 100, Testing net (#0)
I0815 13:08:17.035440 19187 solver.cpp:404]     Test net output #0: accuracy = 0.208314
I0815 13:08:17.035473 19187 solver.cpp:404]     Test net output #1: loss = 0.749151 (* 1 = 0.749151 loss)
I0815 13:08:17.051882 19187 solver.cpp:228] Iteration 100, loss = 0.681756
I0815 13:08:17.051955 19187 solver.cpp:244]     Train net output #0: loss = 0.681756 (* 1 = 0.681756 loss)
I0815 13:08:17.051972 19187 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0815 13:08:21.516455 19187 solver.cpp:337] Iteration 200, Testing net (#0)
I0815 13:08:24.162021 19187 solver.cpp:404]     Test net output #0: accuracy = 0.791744
I0815 13:08:24.162076 19187 solver.cpp:404]     Test net output #1: loss = 0.650614 (* 1 = 0.650614 loss)
I0815 13:08:24.177817 19187 solver.cpp:228] Iteration 200, loss = 0.682193
I0815 13:08:24.177865 19187 solver.cpp:244]     Train net output #0: loss = 0.682193 (* 1 = 0.682193 loss)
I0815 13:08:24.177891 19187 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0815 13:08:28.647892 19187 solver.cpp:337] Iteration 300, Testing net (#0)
I0815 13:08:31.098515 19187 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0815 13:08:31.098565 19187 solver.cpp:404]     Test net output #1: loss = 0.749716 (* 1 = 0.749716 loss)
I0815 13:08:31.114467 19187 solver.cpp:228] Iteration 300, loss = 0.684966
I0815 13:08:31.114513 19187 solver.cpp:244]     Train net output #0: loss = 0.684966 (* 1 = 0.684966 loss)
I0815 13:08:31.114547 19187 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0815 13:08:35.585124 19187 solver.cpp:337] Iteration 400, Testing net (#0)
I0815 13:08:38.035392 19187 solver.cpp:404]     Test net output #0: accuracy = 0.791511
I0815 13:08:38.035437 19187 solver.cpp:404]     Test net output #1: loss = 0.650059 (* 1 = 0.650059 loss)
I0815 13:08:38.051743 19187 solver.cpp:228] Iteration 400, loss = 0.68741
I0815 13:08:38.051779 19187 solver.cpp:244]     Train net output #0: loss = 0.68741 (* 1 = 0.68741 loss)
I0815 13:08:38.051790 19187 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0815 13:08:42.540212 19187 solver.cpp:337] Iteration 500, Testing net (#0)
I0815 13:08:45.041880 19187 solver.cpp:404]     Test net output #0: accuracy = 0.208546
I0815 13:08:45.041949 19187 solver.cpp:404]     Test net output #1: loss = 0.740555 (* 1 = 0.740555 loss)
I0815 13:08:45.057598 19187 solver.cpp:228] Iteration 500, loss = 0.68824
I0815 13:08:45.057646 19187 solver.cpp:244]     Train net output #0: loss = 0.68824 (* 1 = 0.68824 loss)
I0815 13:08:45.057662 19187 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0815 13:08:49.539270 19187 solver.cpp:337] Iteration 600, Testing net (#0)
I0815 13:08:52.121290 19187 solver.cpp:404]     Test net output #0: accuracy = 0.634128
I0815 13:08:52.121330 19187 solver.cpp:404]     Test net output #1: loss = 0.563289 (* 1 = 0.563289 loss)
I0815 13:08:52.136880 19187 solver.cpp:228] Iteration 600, loss = 0.580704
I0815 13:08:52.136912 19187 solver.cpp:244]     Train net output #0: loss = 0.580704 (* 1 = 0.580704 loss)
I0815 13:08:52.136927 19187 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0815 13:08:56.614367 19187 solver.cpp:337] Iteration 700, Testing net (#0)
I0815 13:08:58.984827 19187 solver.cpp:404]     Test net output #0: accuracy = 0.805
I0815 13:08:58.984858 19187 solver.cpp:404]     Test net output #1: loss = 0.402116 (* 1 = 0.402116 loss)
I0815 13:08:59.001315 19187 solver.cpp:228] Iteration 700, loss = 0.316564
I0815 13:08:59.001361 19187 solver.cpp:244]     Train net output #0: loss = 0.316564 (* 1 = 0.316564 loss)
I0815 13:08:59.001399 19187 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0815 13:09:03.502323 19187 solver.cpp:337] Iteration 800, Testing net (#0)
I0815 13:09:05.834431 19187 solver.cpp:404]     Test net output #0: accuracy = 0.837674
I0815 13:09:05.834487 19187 solver.cpp:404]     Test net output #1: loss = 0.367496 (* 1 = 0.367496 loss)
I0815 13:09:05.849359 19187 solver.cpp:228] Iteration 800, loss = 0.471229
I0815 13:09:05.849409 19187 solver.cpp:244]     Train net output #0: loss = 0.471229 (* 1 = 0.471229 loss)
I0815 13:09:05.849427 19187 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0815 13:09:10.353281 19187 solver.cpp:337] Iteration 900, Testing net (#0)
I0815 13:09:12.584275 19187 solver.cpp:404]     Test net output #0: accuracy = 0.890523
I0815 13:09:12.584349 19187 solver.cpp:404]     Test net output #1: loss = 0.243714 (* 1 = 0.243714 loss)
I0815 13:09:12.599074 19187 solver.cpp:228] Iteration 900, loss = 0.355359
I0815 13:09:12.599133 19187 solver.cpp:244]     Train net output #0: loss = 0.355359 (* 1 = 0.355359 loss)
I0815 13:09:12.599263 19187 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0815 13:09:17.093852 19187 solver.cpp:337] Iteration 1000, Testing net (#0)
I0815 13:09:19.714689 19187 solver.cpp:404]     Test net output #0: accuracy = 0.915116
I0815 13:09:19.714736 19187 solver.cpp:404]     Test net output #1: loss = 0.201409 (* 1 = 0.201409 loss)
I0815 13:09:19.731263 19187 solver.cpp:228] Iteration 1000, loss = 0.34849
I0815 13:09:19.731303 19187 solver.cpp:244]     Train net output #0: loss = 0.34849 (* 1 = 0.34849 loss)
I0815 13:09:19.731317 19187 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0815 13:09:24.233379 19187 solver.cpp:337] Iteration 1100, Testing net (#0)
I0815 13:09:26.928777 19187 blocking_queue.cpp:50] Data layer prefetch queue empty
I0815 13:09:26.973664 19187 solver.cpp:404]     Test net output #0: accuracy = 0.907907
I0815 13:09:26.973690 19187 solver.cpp:404]     Test net output #1: loss = 0.217078 (* 1 = 0.217078 loss)
I0815 13:09:26.990913 19187 solver.cpp:228] Iteration 1100, loss = 0.300876
I0815 13:09:26.990988 19187 solver.cpp:244]     Train net output #0: loss = 0.300876 (* 1 = 0.300876 loss)
I0815 13:09:26.991006 19187 sgd_solver.cpp:106] Iteration 1100, lr = 0.005
I0815 13:09:31.495522 19187 solver.cpp:337] Iteration 1200, Testing net (#0)
