WARNING: Logging before InitGoogleLogging() is written to STDERR
I0830 12:56:09.810514 11353 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 10000
snapshot_prefix: "models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1"
solver_mode: GPU
net: "nets/person_vs_background_vs_random_caffe_net/trainval.prototxt"
I0830 12:56:09.810626 11353 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0830 12:56:09.810925 11353 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0830 12:56:09.810945 11353 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0830 12:56:09.811085 11353 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0830 12:56:09.811164 11353 layer_factory.hpp:77] Creating layer data
I0830 12:56:09.811681 11353 net.cpp:100] Creating Layer data
I0830 12:56:09.811694 11353 net.cpp:408] data -> data
I0830 12:56:09.811708 11353 net.cpp:408] data -> label
I0830 12:56:09.811719 11353 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0830 12:56:09.813311 11366 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0830 12:56:09.847193 11353 data_layer.cpp:41] output data size: 128,3,128,128
I0830 12:56:09.918349 11353 net.cpp:150] Setting up data
I0830 12:56:09.918392 11353 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0830 12:56:09.918398 11353 net.cpp:157] Top shape: 128 (128)
I0830 12:56:09.918402 11353 net.cpp:165] Memory required for data: 25166336
I0830 12:56:09.918409 11353 layer_factory.hpp:77] Creating layer conv1
I0830 12:56:09.918438 11353 net.cpp:100] Creating Layer conv1
I0830 12:56:09.918444 11353 net.cpp:434] conv1 <- data
I0830 12:56:09.918454 11353 net.cpp:408] conv1 -> conv1
I0830 12:56:10.229236 11353 net.cpp:150] Setting up conv1
I0830 12:56:10.229276 11353 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0830 12:56:10.229280 11353 net.cpp:165] Memory required for data: 69403136
I0830 12:56:10.229297 11353 layer_factory.hpp:77] Creating layer relu1
I0830 12:56:10.229315 11353 net.cpp:100] Creating Layer relu1
I0830 12:56:10.229320 11353 net.cpp:434] relu1 <- conv1
I0830 12:56:10.229326 11353 net.cpp:395] relu1 -> conv1 (in-place)
I0830 12:56:10.229531 11353 net.cpp:150] Setting up relu1
I0830 12:56:10.229550 11353 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0830 12:56:10.229554 11353 net.cpp:165] Memory required for data: 113639936
I0830 12:56:10.229558 11353 layer_factory.hpp:77] Creating layer pool1
I0830 12:56:10.229565 11353 net.cpp:100] Creating Layer pool1
I0830 12:56:10.229568 11353 net.cpp:434] pool1 <- conv1
I0830 12:56:10.229575 11353 net.cpp:408] pool1 -> pool1
I0830 12:56:10.229625 11353 net.cpp:150] Setting up pool1
I0830 12:56:10.229635 11353 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0830 12:56:10.229637 11353 net.cpp:165] Memory required for data: 124699136
I0830 12:56:10.229640 11353 layer_factory.hpp:77] Creating layer norm1
I0830 12:56:10.229651 11353 net.cpp:100] Creating Layer norm1
I0830 12:56:10.229655 11353 net.cpp:434] norm1 <- pool1
I0830 12:56:10.229661 11353 net.cpp:408] norm1 -> norm1
I0830 12:56:10.230175 11353 net.cpp:150] Setting up norm1
I0830 12:56:10.230188 11353 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0830 12:56:10.230191 11353 net.cpp:165] Memory required for data: 135758336
I0830 12:56:10.230195 11353 layer_factory.hpp:77] Creating layer conv2
I0830 12:56:10.230211 11353 net.cpp:100] Creating Layer conv2
I0830 12:56:10.230214 11353 net.cpp:434] conv2 <- norm1
I0830 12:56:10.230222 11353 net.cpp:408] conv2 -> conv2
I0830 12:56:10.236603 11353 net.cpp:150] Setting up conv2
I0830 12:56:10.236621 11353 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0830 12:56:10.236624 11353 net.cpp:165] Memory required for data: 165249536
I0830 12:56:10.236634 11353 layer_factory.hpp:77] Creating layer relu2
I0830 12:56:10.236639 11353 net.cpp:100] Creating Layer relu2
I0830 12:56:10.236642 11353 net.cpp:434] relu2 <- conv2
I0830 12:56:10.236649 11353 net.cpp:395] relu2 -> conv2 (in-place)
I0830 12:56:10.237130 11353 net.cpp:150] Setting up relu2
I0830 12:56:10.237145 11353 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0830 12:56:10.237149 11353 net.cpp:165] Memory required for data: 194740736
I0830 12:56:10.237151 11353 layer_factory.hpp:77] Creating layer pool2
I0830 12:56:10.237160 11353 net.cpp:100] Creating Layer pool2
I0830 12:56:10.237164 11353 net.cpp:434] pool2 <- conv2
I0830 12:56:10.237169 11353 net.cpp:408] pool2 -> pool2
I0830 12:56:10.237221 11353 net.cpp:150] Setting up pool2
I0830 12:56:10.237231 11353 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0830 12:56:10.237233 11353 net.cpp:165] Memory required for data: 201163264
I0830 12:56:10.237236 11353 layer_factory.hpp:77] Creating layer norm2
I0830 12:56:10.237244 11353 net.cpp:100] Creating Layer norm2
I0830 12:56:10.237248 11353 net.cpp:434] norm2 <- pool2
I0830 12:56:10.237253 11353 net.cpp:408] norm2 -> norm2
I0830 12:56:10.237465 11353 net.cpp:150] Setting up norm2
I0830 12:56:10.237476 11353 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0830 12:56:10.237478 11353 net.cpp:165] Memory required for data: 207585792
I0830 12:56:10.237481 11353 layer_factory.hpp:77] Creating layer conv3
I0830 12:56:10.237493 11353 net.cpp:100] Creating Layer conv3
I0830 12:56:10.237495 11353 net.cpp:434] conv3 <- norm2
I0830 12:56:10.237504 11353 net.cpp:408] conv3 -> conv3
I0830 12:56:10.250871 11353 net.cpp:150] Setting up conv3
I0830 12:56:10.250890 11353 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0830 12:56:10.250893 11353 net.cpp:165] Memory required for data: 217219584
I0830 12:56:10.250903 11353 layer_factory.hpp:77] Creating layer relu3
I0830 12:56:10.250910 11353 net.cpp:100] Creating Layer relu3
I0830 12:56:10.250913 11353 net.cpp:434] relu3 <- conv3
I0830 12:56:10.250918 11353 net.cpp:395] relu3 -> conv3 (in-place)
I0830 12:56:10.251117 11353 net.cpp:150] Setting up relu3
I0830 12:56:10.251129 11353 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0830 12:56:10.251132 11353 net.cpp:165] Memory required for data: 226853376
I0830 12:56:10.251135 11353 layer_factory.hpp:77] Creating layer conv4
I0830 12:56:10.251147 11353 net.cpp:100] Creating Layer conv4
I0830 12:56:10.251150 11353 net.cpp:434] conv4 <- conv3
I0830 12:56:10.251158 11353 net.cpp:408] conv4 -> conv4
I0830 12:56:10.262411 11353 net.cpp:150] Setting up conv4
I0830 12:56:10.262428 11353 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0830 12:56:10.262431 11353 net.cpp:165] Memory required for data: 236487168
I0830 12:56:10.262439 11353 layer_factory.hpp:77] Creating layer relu4
I0830 12:56:10.262445 11353 net.cpp:100] Creating Layer relu4
I0830 12:56:10.262449 11353 net.cpp:434] relu4 <- conv4
I0830 12:56:10.262455 11353 net.cpp:395] relu4 -> conv4 (in-place)
I0830 12:56:10.262658 11353 net.cpp:150] Setting up relu4
I0830 12:56:10.262671 11353 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0830 12:56:10.262673 11353 net.cpp:165] Memory required for data: 246120960
I0830 12:56:10.262677 11353 layer_factory.hpp:77] Creating layer conv5
I0830 12:56:10.262691 11353 net.cpp:100] Creating Layer conv5
I0830 12:56:10.262693 11353 net.cpp:434] conv5 <- conv4
I0830 12:56:10.262701 11353 net.cpp:408] conv5 -> conv5
I0830 12:56:10.271208 11353 net.cpp:150] Setting up conv5
I0830 12:56:10.271225 11353 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0830 12:56:10.271229 11353 net.cpp:165] Memory required for data: 252543488
I0830 12:56:10.271239 11353 layer_factory.hpp:77] Creating layer relu5
I0830 12:56:10.271245 11353 net.cpp:100] Creating Layer relu5
I0830 12:56:10.271248 11353 net.cpp:434] relu5 <- conv5
I0830 12:56:10.271255 11353 net.cpp:395] relu5 -> conv5 (in-place)
I0830 12:56:10.271457 11353 net.cpp:150] Setting up relu5
I0830 12:56:10.271469 11353 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0830 12:56:10.271472 11353 net.cpp:165] Memory required for data: 258966016
I0830 12:56:10.271476 11353 layer_factory.hpp:77] Creating layer pool5
I0830 12:56:10.271486 11353 net.cpp:100] Creating Layer pool5
I0830 12:56:10.271489 11353 net.cpp:434] pool5 <- conv5
I0830 12:56:10.271494 11353 net.cpp:408] pool5 -> pool5
I0830 12:56:10.271545 11353 net.cpp:150] Setting up pool5
I0830 12:56:10.271554 11353 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0830 12:56:10.271556 11353 net.cpp:165] Memory required for data: 260145664
I0830 12:56:10.271560 11353 layer_factory.hpp:77] Creating layer fc6n
I0830 12:56:10.271572 11353 net.cpp:100] Creating Layer fc6n
I0830 12:56:10.271575 11353 net.cpp:434] fc6n <- pool5
I0830 12:56:10.271584 11353 net.cpp:408] fc6n -> fc6
I0830 12:56:10.402845 11353 net.cpp:150] Setting up fc6n
I0830 12:56:10.402885 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.402889 11353 net.cpp:165] Memory required for data: 262242816
I0830 12:56:10.402901 11353 layer_factory.hpp:77] Creating layer relu6
I0830 12:56:10.402915 11353 net.cpp:100] Creating Layer relu6
I0830 12:56:10.402918 11353 net.cpp:434] relu6 <- fc6
I0830 12:56:10.402928 11353 net.cpp:395] relu6 -> fc6 (in-place)
I0830 12:56:10.403517 11353 net.cpp:150] Setting up relu6
I0830 12:56:10.403532 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.403534 11353 net.cpp:165] Memory required for data: 264339968
I0830 12:56:10.403538 11353 layer_factory.hpp:77] Creating layer drop6
I0830 12:56:10.403548 11353 net.cpp:100] Creating Layer drop6
I0830 12:56:10.403551 11353 net.cpp:434] drop6 <- fc6
I0830 12:56:10.403556 11353 net.cpp:395] drop6 -> fc6 (in-place)
I0830 12:56:10.403584 11353 net.cpp:150] Setting up drop6
I0830 12:56:10.403590 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.403594 11353 net.cpp:165] Memory required for data: 266437120
I0830 12:56:10.403596 11353 layer_factory.hpp:77] Creating layer fc7n
I0830 12:56:10.403605 11353 net.cpp:100] Creating Layer fc7n
I0830 12:56:10.403609 11353 net.cpp:434] fc7n <- fc6
I0830 12:56:10.403615 11353 net.cpp:408] fc7n -> fc7
I0830 12:56:10.634145 11353 net.cpp:150] Setting up fc7n
I0830 12:56:10.634196 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.634199 11353 net.cpp:165] Memory required for data: 268534272
I0830 12:56:10.634212 11353 layer_factory.hpp:77] Creating layer relu7
I0830 12:56:10.634224 11353 net.cpp:100] Creating Layer relu7
I0830 12:56:10.634228 11353 net.cpp:434] relu7 <- fc7
I0830 12:56:10.634237 11353 net.cpp:395] relu7 -> fc7 (in-place)
I0830 12:56:10.634521 11353 net.cpp:150] Setting up relu7
I0830 12:56:10.634532 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.634536 11353 net.cpp:165] Memory required for data: 270631424
I0830 12:56:10.634538 11353 layer_factory.hpp:77] Creating layer drop7
I0830 12:56:10.634546 11353 net.cpp:100] Creating Layer drop7
I0830 12:56:10.634549 11353 net.cpp:434] drop7 <- fc7
I0830 12:56:10.634558 11353 net.cpp:395] drop7 -> fc7 (in-place)
I0830 12:56:10.634583 11353 net.cpp:150] Setting up drop7
I0830 12:56:10.634589 11353 net.cpp:157] Top shape: 128 4096 (524288)
I0830 12:56:10.634593 11353 net.cpp:165] Memory required for data: 272728576
I0830 12:56:10.634595 11353 layer_factory.hpp:77] Creating layer fc8n
I0830 12:56:10.634605 11353 net.cpp:100] Creating Layer fc8n
I0830 12:56:10.634608 11353 net.cpp:434] fc8n <- fc7
I0830 12:56:10.634613 11353 net.cpp:408] fc8n -> fc8
I0830 12:56:10.636258 11353 net.cpp:150] Setting up fc8n
I0830 12:56:10.636271 11353 net.cpp:157] Top shape: 128 3 (384)
I0830 12:56:10.636274 11353 net.cpp:165] Memory required for data: 272730112
I0830 12:56:10.636281 11353 layer_factory.hpp:77] Creating layer loss
I0830 12:56:10.636287 11353 net.cpp:100] Creating Layer loss
I0830 12:56:10.636291 11353 net.cpp:434] loss <- fc8
I0830 12:56:10.636296 11353 net.cpp:434] loss <- label
I0830 12:56:10.636303 11353 net.cpp:408] loss -> loss
I0830 12:56:10.636312 11353 layer_factory.hpp:77] Creating layer loss
I0830 12:56:10.636611 11353 net.cpp:150] Setting up loss
I0830 12:56:10.636622 11353 net.cpp:157] Top shape: (1)
I0830 12:56:10.636626 11353 net.cpp:160]     with loss weight 1
I0830 12:56:10.636647 11353 net.cpp:165] Memory required for data: 272730116
I0830 12:56:10.636651 11353 net.cpp:226] loss needs backward computation.
I0830 12:56:10.636657 11353 net.cpp:226] fc8n needs backward computation.
I0830 12:56:10.636660 11353 net.cpp:226] drop7 needs backward computation.
I0830 12:56:10.636663 11353 net.cpp:226] relu7 needs backward computation.
I0830 12:56:10.636665 11353 net.cpp:226] fc7n needs backward computation.
I0830 12:56:10.636668 11353 net.cpp:226] drop6 needs backward computation.
I0830 12:56:10.636672 11353 net.cpp:226] relu6 needs backward computation.
I0830 12:56:10.636674 11353 net.cpp:226] fc6n needs backward computation.
I0830 12:56:10.636677 11353 net.cpp:226] pool5 needs backward computation.
I0830 12:56:10.636680 11353 net.cpp:226] relu5 needs backward computation.
I0830 12:56:10.636683 11353 net.cpp:226] conv5 needs backward computation.
I0830 12:56:10.636687 11353 net.cpp:226] relu4 needs backward computation.
I0830 12:56:10.636689 11353 net.cpp:226] conv4 needs backward computation.
I0830 12:56:10.636692 11353 net.cpp:226] relu3 needs backward computation.
I0830 12:56:10.636695 11353 net.cpp:226] conv3 needs backward computation.
I0830 12:56:10.636698 11353 net.cpp:226] norm2 needs backward computation.
I0830 12:56:10.636700 11353 net.cpp:226] pool2 needs backward computation.
I0830 12:56:10.636703 11353 net.cpp:226] relu2 needs backward computation.
I0830 12:56:10.636706 11353 net.cpp:226] conv2 needs backward computation.
I0830 12:56:10.636709 11353 net.cpp:226] norm1 needs backward computation.
I0830 12:56:10.636713 11353 net.cpp:226] pool1 needs backward computation.
I0830 12:56:10.636715 11353 net.cpp:226] relu1 needs backward computation.
I0830 12:56:10.636718 11353 net.cpp:226] conv1 needs backward computation.
I0830 12:56:10.636723 11353 net.cpp:228] data does not need backward computation.
I0830 12:56:10.636724 11353 net.cpp:270] This network produces output loss
I0830 12:56:10.636741 11353 net.cpp:283] Network initialization done.
I0830 12:56:10.637118 11353 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0830 12:56:10.637159 11353 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0830 12:56:10.637337 11353 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0830 12:56:10.637450 11353 layer_factory.hpp:77] Creating layer data
I0830 12:56:10.637599 11353 net.cpp:100] Creating Layer data
I0830 12:56:10.637611 11353 net.cpp:408] data -> data
I0830 12:56:10.637620 11353 net.cpp:408] data -> label
I0830 12:56:10.637629 11353 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0830 12:56:10.639135 11370 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0830 12:56:10.639525 11353 data_layer.cpp:41] output data size: 100,3,128,128
I0830 12:56:10.695804 11353 net.cpp:150] Setting up data
I0830 12:56:10.695844 11353 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0830 12:56:10.695852 11353 net.cpp:157] Top shape: 100 (100)
I0830 12:56:10.695855 11353 net.cpp:165] Memory required for data: 19661200
I0830 12:56:10.695863 11353 layer_factory.hpp:77] Creating layer label_data_1_split
I0830 12:56:10.695883 11353 net.cpp:100] Creating Layer label_data_1_split
I0830 12:56:10.695889 11353 net.cpp:434] label_data_1_split <- label
I0830 12:56:10.695900 11353 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0830 12:56:10.695916 11353 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0830 12:56:10.696152 11353 net.cpp:150] Setting up label_data_1_split
I0830 12:56:10.696184 11353 net.cpp:157] Top shape: 100 (100)
I0830 12:56:10.696192 11353 net.cpp:157] Top shape: 100 (100)
I0830 12:56:10.696197 11353 net.cpp:165] Memory required for data: 19662000
I0830 12:56:10.696202 11353 layer_factory.hpp:77] Creating layer conv1
I0830 12:56:10.696225 11353 net.cpp:100] Creating Layer conv1
I0830 12:56:10.696233 11353 net.cpp:434] conv1 <- data
I0830 12:56:10.696244 11353 net.cpp:408] conv1 -> conv1
I0830 12:56:10.700935 11353 net.cpp:150] Setting up conv1
I0830 12:56:10.700966 11353 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0830 12:56:10.700973 11353 net.cpp:165] Memory required for data: 54222000
I0830 12:56:10.700992 11353 layer_factory.hpp:77] Creating layer relu1
I0830 12:56:10.701006 11353 net.cpp:100] Creating Layer relu1
I0830 12:56:10.701014 11353 net.cpp:434] relu1 <- conv1
I0830 12:56:10.701025 11353 net.cpp:395] relu1 -> conv1 (in-place)
I0830 12:56:10.701371 11353 net.cpp:150] Setting up relu1
I0830 12:56:10.701390 11353 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0830 12:56:10.701395 11353 net.cpp:165] Memory required for data: 88782000
I0830 12:56:10.701400 11353 layer_factory.hpp:77] Creating layer pool1
I0830 12:56:10.701417 11353 net.cpp:100] Creating Layer pool1
I0830 12:56:10.701426 11353 net.cpp:434] pool1 <- conv1
I0830 12:56:10.701436 11353 net.cpp:408] pool1 -> pool1
I0830 12:56:10.701524 11353 net.cpp:150] Setting up pool1
I0830 12:56:10.701555 11353 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0830 12:56:10.701563 11353 net.cpp:165] Memory required for data: 97422000
I0830 12:56:10.701570 11353 layer_factory.hpp:77] Creating layer norm1
I0830 12:56:10.701581 11353 net.cpp:100] Creating Layer norm1
I0830 12:56:10.701587 11353 net.cpp:434] norm1 <- pool1
I0830 12:56:10.701596 11353 net.cpp:408] norm1 -> norm1
I0830 12:56:10.702522 11353 net.cpp:150] Setting up norm1
I0830 12:56:10.702548 11353 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0830 12:56:10.702553 11353 net.cpp:165] Memory required for data: 106062000
I0830 12:56:10.702558 11353 layer_factory.hpp:77] Creating layer conv2
I0830 12:56:10.702576 11353 net.cpp:100] Creating Layer conv2
I0830 12:56:10.702582 11353 net.cpp:434] conv2 <- norm1
I0830 12:56:10.702594 11353 net.cpp:408] conv2 -> conv2
I0830 12:56:10.714642 11353 net.cpp:150] Setting up conv2
I0830 12:56:10.714673 11353 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0830 12:56:10.714681 11353 net.cpp:165] Memory required for data: 129102000
I0830 12:56:10.714699 11353 layer_factory.hpp:77] Creating layer relu2
I0830 12:56:10.714714 11353 net.cpp:100] Creating Layer relu2
I0830 12:56:10.714720 11353 net.cpp:434] relu2 <- conv2
I0830 12:56:10.714730 11353 net.cpp:395] relu2 -> conv2 (in-place)
I0830 12:56:10.715641 11353 net.cpp:150] Setting up relu2
I0830 12:56:10.715667 11353 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0830 12:56:10.715672 11353 net.cpp:165] Memory required for data: 152142000
I0830 12:56:10.715678 11353 layer_factory.hpp:77] Creating layer pool2
I0830 12:56:10.715694 11353 net.cpp:100] Creating Layer pool2
I0830 12:56:10.715700 11353 net.cpp:434] pool2 <- conv2
I0830 12:56:10.715714 11353 net.cpp:408] pool2 -> pool2
I0830 12:56:10.715821 11353 net.cpp:150] Setting up pool2
I0830 12:56:10.715837 11353 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0830 12:56:10.715845 11353 net.cpp:165] Memory required for data: 157159600
I0830 12:56:10.715850 11353 layer_factory.hpp:77] Creating layer norm2
I0830 12:56:10.715865 11353 net.cpp:100] Creating Layer norm2
I0830 12:56:10.715873 11353 net.cpp:434] norm2 <- pool2
I0830 12:56:10.715883 11353 net.cpp:408] norm2 -> norm2
I0830 12:56:10.716310 11353 net.cpp:150] Setting up norm2
I0830 12:56:10.716328 11353 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0830 12:56:10.716334 11353 net.cpp:165] Memory required for data: 162177200
I0830 12:56:10.716339 11353 layer_factory.hpp:77] Creating layer conv3
I0830 12:56:10.716361 11353 net.cpp:100] Creating Layer conv3
I0830 12:56:10.716367 11353 net.cpp:434] conv3 <- norm2
I0830 12:56:10.716378 11353 net.cpp:408] conv3 -> conv3
I0830 12:56:10.740393 11353 net.cpp:150] Setting up conv3
I0830 12:56:10.740437 11353 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0830 12:56:10.740442 11353 net.cpp:165] Memory required for data: 169703600
I0830 12:56:10.740463 11353 layer_factory.hpp:77] Creating layer relu3
I0830 12:56:10.740478 11353 net.cpp:100] Creating Layer relu3
I0830 12:56:10.740484 11353 net.cpp:434] relu3 <- conv3
I0830 12:56:10.740499 11353 net.cpp:395] relu3 -> conv3 (in-place)
I0830 12:56:10.740854 11353 net.cpp:150] Setting up relu3
I0830 12:56:10.740871 11353 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0830 12:56:10.740876 11353 net.cpp:165] Memory required for data: 177230000
I0830 12:56:10.740881 11353 layer_factory.hpp:77] Creating layer conv4
I0830 12:56:10.740900 11353 net.cpp:100] Creating Layer conv4
I0830 12:56:10.740906 11353 net.cpp:434] conv4 <- conv3
I0830 12:56:10.740918 11353 net.cpp:408] conv4 -> conv4
I0830 12:56:10.759793 11353 net.cpp:150] Setting up conv4
I0830 12:56:10.759831 11353 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0830 12:56:10.759837 11353 net.cpp:165] Memory required for data: 184756400
I0830 12:56:10.759851 11353 layer_factory.hpp:77] Creating layer relu4
I0830 12:56:10.759866 11353 net.cpp:100] Creating Layer relu4
I0830 12:56:10.759872 11353 net.cpp:434] relu4 <- conv4
I0830 12:56:10.759883 11353 net.cpp:395] relu4 -> conv4 (in-place)
I0830 12:56:10.760691 11353 net.cpp:150] Setting up relu4
I0830 12:56:10.760713 11353 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0830 12:56:10.760718 11353 net.cpp:165] Memory required for data: 192282800
I0830 12:56:10.760723 11353 layer_factory.hpp:77] Creating layer conv5
I0830 12:56:10.760746 11353 net.cpp:100] Creating Layer conv5
I0830 12:56:10.760751 11353 net.cpp:434] conv5 <- conv4
I0830 12:56:10.760761 11353 net.cpp:408] conv5 -> conv5
I0830 12:56:10.775315 11353 net.cpp:150] Setting up conv5
I0830 12:56:10.775348 11353 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0830 12:56:10.775354 11353 net.cpp:165] Memory required for data: 197300400
I0830 12:56:10.775373 11353 layer_factory.hpp:77] Creating layer relu5
I0830 12:56:10.775387 11353 net.cpp:100] Creating Layer relu5
I0830 12:56:10.775391 11353 net.cpp:434] relu5 <- conv5
I0830 12:56:10.775401 11353 net.cpp:395] relu5 -> conv5 (in-place)
I0830 12:56:10.775717 11353 net.cpp:150] Setting up relu5
I0830 12:56:10.775733 11353 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0830 12:56:10.775738 11353 net.cpp:165] Memory required for data: 202318000
I0830 12:56:10.775741 11353 layer_factory.hpp:77] Creating layer pool5
I0830 12:56:10.775760 11353 net.cpp:100] Creating Layer pool5
I0830 12:56:10.775765 11353 net.cpp:434] pool5 <- conv5
I0830 12:56:10.775774 11353 net.cpp:408] pool5 -> pool5
I0830 12:56:10.775853 11353 net.cpp:150] Setting up pool5
I0830 12:56:10.775867 11353 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0830 12:56:10.775871 11353 net.cpp:165] Memory required for data: 203239600
I0830 12:56:10.775876 11353 layer_factory.hpp:77] Creating layer fc6n
I0830 12:56:10.775887 11353 net.cpp:100] Creating Layer fc6n
I0830 12:56:10.775893 11353 net.cpp:434] fc6n <- pool5
I0830 12:56:10.775903 11353 net.cpp:408] fc6n -> fc6
I0830 12:56:10.918645 11353 net.cpp:150] Setting up fc6n
I0830 12:56:10.918689 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:10.918691 11353 net.cpp:165] Memory required for data: 204878000
I0830 12:56:10.918704 11353 layer_factory.hpp:77] Creating layer relu6
I0830 12:56:10.918717 11353 net.cpp:100] Creating Layer relu6
I0830 12:56:10.918722 11353 net.cpp:434] relu6 <- fc6
I0830 12:56:10.918730 11353 net.cpp:395] relu6 -> fc6 (in-place)
I0830 12:56:10.919010 11353 net.cpp:150] Setting up relu6
I0830 12:56:10.919023 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:10.919025 11353 net.cpp:165] Memory required for data: 206516400
I0830 12:56:10.919028 11353 layer_factory.hpp:77] Creating layer drop6
I0830 12:56:10.919037 11353 net.cpp:100] Creating Layer drop6
I0830 12:56:10.919040 11353 net.cpp:434] drop6 <- fc6
I0830 12:56:10.919045 11353 net.cpp:395] drop6 -> fc6 (in-place)
I0830 12:56:10.919082 11353 net.cpp:150] Setting up drop6
I0830 12:56:10.919091 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:10.919095 11353 net.cpp:165] Memory required for data: 208154800
I0830 12:56:10.919097 11353 layer_factory.hpp:77] Creating layer fc7n
I0830 12:56:10.919113 11353 net.cpp:100] Creating Layer fc7n
I0830 12:56:10.919117 11353 net.cpp:434] fc7n <- fc6
I0830 12:56:10.919122 11353 net.cpp:408] fc7n -> fc7
I0830 12:56:11.149547 11353 net.cpp:150] Setting up fc7n
I0830 12:56:11.149596 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:11.149600 11353 net.cpp:165] Memory required for data: 209793200
I0830 12:56:11.149611 11353 layer_factory.hpp:77] Creating layer relu7
I0830 12:56:11.149626 11353 net.cpp:100] Creating Layer relu7
I0830 12:56:11.149629 11353 net.cpp:434] relu7 <- fc7
I0830 12:56:11.149636 11353 net.cpp:395] relu7 -> fc7 (in-place)
I0830 12:56:11.150396 11353 net.cpp:150] Setting up relu7
I0830 12:56:11.150411 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:11.150414 11353 net.cpp:165] Memory required for data: 211431600
I0830 12:56:11.150418 11353 layer_factory.hpp:77] Creating layer drop7
I0830 12:56:11.150426 11353 net.cpp:100] Creating Layer drop7
I0830 12:56:11.150429 11353 net.cpp:434] drop7 <- fc7
I0830 12:56:11.150439 11353 net.cpp:395] drop7 -> fc7 (in-place)
I0830 12:56:11.150476 11353 net.cpp:150] Setting up drop7
I0830 12:56:11.150485 11353 net.cpp:157] Top shape: 100 4096 (409600)
I0830 12:56:11.150486 11353 net.cpp:165] Memory required for data: 213070000
I0830 12:56:11.150490 11353 layer_factory.hpp:77] Creating layer fc8n
I0830 12:56:11.150501 11353 net.cpp:100] Creating Layer fc8n
I0830 12:56:11.150504 11353 net.cpp:434] fc8n <- fc7
I0830 12:56:11.150511 11353 net.cpp:408] fc8n -> fc8
I0830 12:56:11.150805 11353 net.cpp:150] Setting up fc8n
I0830 12:56:11.150815 11353 net.cpp:157] Top shape: 100 3 (300)
I0830 12:56:11.150816 11353 net.cpp:165] Memory required for data: 213071200
I0830 12:56:11.150823 11353 layer_factory.hpp:77] Creating layer fc8_fc8n_0_split
I0830 12:56:11.150833 11353 net.cpp:100] Creating Layer fc8_fc8n_0_split
I0830 12:56:11.150835 11353 net.cpp:434] fc8_fc8n_0_split <- fc8
I0830 12:56:11.150842 11353 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_0
I0830 12:56:11.150849 11353 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_1
I0830 12:56:11.150892 11353 net.cpp:150] Setting up fc8_fc8n_0_split
I0830 12:56:11.150900 11353 net.cpp:157] Top shape: 100 3 (300)
I0830 12:56:11.150903 11353 net.cpp:157] Top shape: 100 3 (300)
I0830 12:56:11.150905 11353 net.cpp:165] Memory required for data: 213073600
I0830 12:56:11.150908 11353 layer_factory.hpp:77] Creating layer accuracy
I0830 12:56:11.150915 11353 net.cpp:100] Creating Layer accuracy
I0830 12:56:11.150918 11353 net.cpp:434] accuracy <- fc8_fc8n_0_split_0
I0830 12:56:11.150923 11353 net.cpp:434] accuracy <- label_data_1_split_0
I0830 12:56:11.150928 11353 net.cpp:408] accuracy -> accuracy
I0830 12:56:11.150938 11353 net.cpp:150] Setting up accuracy
I0830 12:56:11.150941 11353 net.cpp:157] Top shape: (1)
I0830 12:56:11.150944 11353 net.cpp:165] Memory required for data: 213073604
I0830 12:56:11.150946 11353 layer_factory.hpp:77] Creating layer loss
I0830 12:56:11.150952 11353 net.cpp:100] Creating Layer loss
I0830 12:56:11.150955 11353 net.cpp:434] loss <- fc8_fc8n_0_split_1
I0830 12:56:11.150959 11353 net.cpp:434] loss <- label_data_1_split_1
I0830 12:56:11.150964 11353 net.cpp:408] loss -> loss
I0830 12:56:11.150971 11353 layer_factory.hpp:77] Creating layer loss
I0830 12:56:11.151278 11353 net.cpp:150] Setting up loss
I0830 12:56:11.151289 11353 net.cpp:157] Top shape: (1)
I0830 12:56:11.151291 11353 net.cpp:160]     with loss weight 1
I0830 12:56:11.151304 11353 net.cpp:165] Memory required for data: 213073608
I0830 12:56:11.151309 11353 net.cpp:226] loss needs backward computation.
I0830 12:56:11.151312 11353 net.cpp:228] accuracy does not need backward computation.
I0830 12:56:11.151316 11353 net.cpp:226] fc8_fc8n_0_split needs backward computation.
I0830 12:56:11.151319 11353 net.cpp:226] fc8n needs backward computation.
I0830 12:56:11.151322 11353 net.cpp:226] drop7 needs backward computation.
I0830 12:56:11.151324 11353 net.cpp:226] relu7 needs backward computation.
I0830 12:56:11.151327 11353 net.cpp:226] fc7n needs backward computation.
I0830 12:56:11.151329 11353 net.cpp:226] drop6 needs backward computation.
I0830 12:56:11.151332 11353 net.cpp:226] relu6 needs backward computation.
I0830 12:56:11.151335 11353 net.cpp:226] fc6n needs backward computation.
I0830 12:56:11.151338 11353 net.cpp:226] pool5 needs backward computation.
I0830 12:56:11.151341 11353 net.cpp:226] relu5 needs backward computation.
I0830 12:56:11.151345 11353 net.cpp:226] conv5 needs backward computation.
I0830 12:56:11.151347 11353 net.cpp:226] relu4 needs backward computation.
I0830 12:56:11.151350 11353 net.cpp:226] conv4 needs backward computation.
I0830 12:56:11.151352 11353 net.cpp:226] relu3 needs backward computation.
I0830 12:56:11.151355 11353 net.cpp:226] conv3 needs backward computation.
I0830 12:56:11.151358 11353 net.cpp:226] norm2 needs backward computation.
I0830 12:56:11.151361 11353 net.cpp:226] pool2 needs backward computation.
I0830 12:56:11.151365 11353 net.cpp:226] relu2 needs backward computation.
I0830 12:56:11.151367 11353 net.cpp:226] conv2 needs backward computation.
I0830 12:56:11.151371 11353 net.cpp:226] norm1 needs backward computation.
I0830 12:56:11.151372 11353 net.cpp:226] pool1 needs backward computation.
I0830 12:56:11.151376 11353 net.cpp:226] relu1 needs backward computation.
I0830 12:56:11.151378 11353 net.cpp:226] conv1 needs backward computation.
I0830 12:56:11.151381 11353 net.cpp:228] label_data_1_split does not need backward computation.
I0830 12:56:11.151386 11353 net.cpp:228] data does not need backward computation.
I0830 12:56:11.151387 11353 net.cpp:270] This network produces output accuracy
I0830 12:56:11.151391 11353 net.cpp:270] This network produces output loss
I0830 12:56:11.151412 11353 net.cpp:283] Network initialization done.
I0830 12:56:11.151517 11353 solver.cpp:60] Solver scaffolding done.
I0830 12:56:11.154932 11353 solver.cpp:337] Iteration 0, Testing net (#0)
I0830 12:56:11.270967 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 12:56:14.510882 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0830 12:56:14.510928 11353 solver.cpp:404]     Test net output #1: loss = 1.0821 (* 1 = 1.0821 loss)
I0830 12:56:14.543064 11353 solver.cpp:228] Iteration 0, loss = 1.10275
I0830 12:56:14.543115 11353 solver.cpp:244]     Train net output #0: loss = 1.10275 (* 1 = 1.10275 loss)
I0830 12:56:14.543135 11353 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0830 12:56:18.786164 11353 solver.cpp:228] Iteration 100, loss = 1.1009
I0830 12:56:18.786243 11353 solver.cpp:244]     Train net output #0: loss = 1.1009 (* 1 = 1.1009 loss)
I0830 12:56:18.786250 11353 sgd_solver.cpp:106] Iteration 100, lr = 0.0996266
I0830 12:56:23.039433 11353 solver.cpp:228] Iteration 200, loss = 1.11649
I0830 12:56:23.039454 11353 solver.cpp:244]     Train net output #0: loss = 1.11649 (* 1 = 1.11649 loss)
I0830 12:56:23.039459 11353 sgd_solver.cpp:106] Iteration 200, lr = 0.0992565
I0830 12:56:27.294589 11353 solver.cpp:228] Iteration 300, loss = 1.12998
I0830 12:56:27.294607 11353 solver.cpp:244]     Train net output #0: loss = 1.12998 (* 1 = 1.12998 loss)
I0830 12:56:27.294611 11353 sgd_solver.cpp:106] Iteration 300, lr = 0.0988896
I0830 12:56:31.552566 11353 solver.cpp:228] Iteration 400, loss = 1.10477
I0830 12:56:31.552585 11353 solver.cpp:244]     Train net output #0: loss = 1.10477 (* 1 = 1.10477 loss)
I0830 12:56:31.552590 11353 sgd_solver.cpp:106] Iteration 400, lr = 0.0985258
I0830 12:56:35.780957 11353 solver.cpp:337] Iteration 500, Testing net (#0)
I0830 12:56:38.921378 11353 solver.cpp:404]     Test net output #0: accuracy = 0.579292
I0830 12:56:38.921407 11353 solver.cpp:404]     Test net output #1: loss = 1.08949 (* 1 = 1.08949 loss)
I0830 12:56:38.935817 11353 solver.cpp:228] Iteration 500, loss = 1.09589
I0830 12:56:38.935833 11353 solver.cpp:244]     Train net output #0: loss = 1.09589 (* 1 = 1.09589 loss)
I0830 12:56:38.935838 11353 sgd_solver.cpp:106] Iteration 500, lr = 0.0981651
I0830 12:56:43.208034 11353 solver.cpp:228] Iteration 600, loss = 1.09898
I0830 12:56:43.208075 11353 solver.cpp:244]     Train net output #0: loss = 1.09898 (* 1 = 1.09898 loss)
I0830 12:56:43.208081 11353 sgd_solver.cpp:106] Iteration 600, lr = 0.0978075
I0830 12:56:47.477164 11353 solver.cpp:228] Iteration 700, loss = 1.09173
I0830 12:56:47.477223 11353 solver.cpp:244]     Train net output #0: loss = 1.09173 (* 1 = 1.09173 loss)
I0830 12:56:47.477228 11353 sgd_solver.cpp:106] Iteration 700, lr = 0.0974529
I0830 12:56:51.747494 11353 solver.cpp:228] Iteration 800, loss = 1.10085
I0830 12:56:51.747552 11353 solver.cpp:244]     Train net output #0: loss = 1.10085 (* 1 = 1.10085 loss)
I0830 12:56:51.747558 11353 sgd_solver.cpp:106] Iteration 800, lr = 0.0971013
I0830 12:56:56.036463 11353 solver.cpp:228] Iteration 900, loss = 1.11098
I0830 12:56:56.036511 11353 solver.cpp:244]     Train net output #0: loss = 1.11098 (* 1 = 1.11098 loss)
I0830 12:56:56.036517 11353 sgd_solver.cpp:106] Iteration 900, lr = 0.0967526
I0830 12:57:00.284339 11353 solver.cpp:337] Iteration 1000, Testing net (#0)
I0830 12:57:03.602875 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0830 12:57:03.602927 11353 solver.cpp:404]     Test net output #1: loss = 1.10575 (* 1 = 1.10575 loss)
I0830 12:57:03.617532 11353 solver.cpp:228] Iteration 1000, loss = 1.0984
I0830 12:57:03.617596 11353 solver.cpp:244]     Train net output #0: loss = 1.0984 (* 1 = 1.0984 loss)
I0830 12:57:03.617605 11353 sgd_solver.cpp:106] Iteration 1000, lr = 0.0964069
I0830 12:57:07.914175 11353 solver.cpp:228] Iteration 1100, loss = 1.10108
I0830 12:57:07.914214 11353 solver.cpp:244]     Train net output #0: loss = 1.10108 (* 1 = 1.10108 loss)
I0830 12:57:07.914221 11353 sgd_solver.cpp:106] Iteration 1100, lr = 0.096064
I0830 12:57:12.202450 11353 solver.cpp:228] Iteration 1200, loss = 1.10058
I0830 12:57:12.202587 11353 solver.cpp:244]     Train net output #0: loss = 1.10058 (* 1 = 1.10058 loss)
I0830 12:57:12.202607 11353 sgd_solver.cpp:106] Iteration 1200, lr = 0.0957239
I0830 12:57:16.505640 11353 solver.cpp:228] Iteration 1300, loss = 1.09727
I0830 12:57:16.505704 11353 solver.cpp:244]     Train net output #0: loss = 1.09727 (* 1 = 1.09727 loss)
I0830 12:57:16.505713 11353 sgd_solver.cpp:106] Iteration 1300, lr = 0.0953867
I0830 12:57:20.799674 11353 solver.cpp:228] Iteration 1400, loss = 1.09936
I0830 12:57:20.799728 11353 solver.cpp:244]     Train net output #0: loss = 1.09936 (* 1 = 1.09936 loss)
I0830 12:57:20.799736 11353 sgd_solver.cpp:106] Iteration 1400, lr = 0.0950522
I0830 12:57:25.052953 11353 solver.cpp:337] Iteration 1500, Testing net (#0)
I0830 12:57:28.293081 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0830 12:57:28.293141 11353 solver.cpp:404]     Test net output #1: loss = 1.1285 (* 1 = 1.1285 loss)
I0830 12:57:28.309617 11353 solver.cpp:228] Iteration 1500, loss = 1.10111
I0830 12:57:28.309685 11353 solver.cpp:244]     Train net output #0: loss = 1.10111 (* 1 = 1.10111 loss)
I0830 12:57:28.309702 11353 sgd_solver.cpp:106] Iteration 1500, lr = 0.0947204
I0830 12:57:32.609455 11353 solver.cpp:228] Iteration 1600, loss = 1.09859
I0830 12:57:32.609495 11353 solver.cpp:244]     Train net output #0: loss = 1.09859 (* 1 = 1.09859 loss)
I0830 12:57:32.609500 11353 sgd_solver.cpp:106] Iteration 1600, lr = 0.0943913
I0830 12:57:36.912097 11353 solver.cpp:228] Iteration 1700, loss = 1.09878
I0830 12:57:36.912122 11353 solver.cpp:244]     Train net output #0: loss = 1.09878 (* 1 = 1.09878 loss)
I0830 12:57:36.912127 11353 sgd_solver.cpp:106] Iteration 1700, lr = 0.0940649
I0830 12:57:41.209496 11353 solver.cpp:228] Iteration 1800, loss = 1.1014
I0830 12:57:41.209522 11353 solver.cpp:244]     Train net output #0: loss = 1.1014 (* 1 = 1.1014 loss)
I0830 12:57:41.209527 11353 sgd_solver.cpp:106] Iteration 1800, lr = 0.0937411
I0830 12:57:45.504902 11353 solver.cpp:228] Iteration 1900, loss = 1.10055
I0830 12:57:45.504926 11353 solver.cpp:244]     Train net output #0: loss = 1.10055 (* 1 = 1.10055 loss)
I0830 12:57:45.504931 11353 sgd_solver.cpp:106] Iteration 1900, lr = 0.0934199
I0830 12:57:49.771497 11353 solver.cpp:337] Iteration 2000, Testing net (#0)
I0830 12:57:53.084872 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0830 12:57:53.084959 11353 solver.cpp:404]     Test net output #1: loss = 1.12472 (* 1 = 1.12472 loss)
I0830 12:57:53.099808 11353 solver.cpp:228] Iteration 2000, loss = 1.09841
I0830 12:57:53.099854 11353 solver.cpp:244]     Train net output #0: loss = 1.09841 (* 1 = 1.09841 loss)
I0830 12:57:53.099866 11353 sgd_solver.cpp:106] Iteration 2000, lr = 0.0931012
I0830 12:57:57.409255 11353 solver.cpp:228] Iteration 2100, loss = 1.0943
I0830 12:57:57.409299 11353 solver.cpp:244]     Train net output #0: loss = 1.0943 (* 1 = 1.0943 loss)
I0830 12:57:57.409306 11353 sgd_solver.cpp:106] Iteration 2100, lr = 0.0927851
I0830 12:58:01.724647 11353 solver.cpp:228] Iteration 2200, loss = 1.10205
I0830 12:58:01.724723 11353 solver.cpp:244]     Train net output #0: loss = 1.10205 (* 1 = 1.10205 loss)
I0830 12:58:01.724730 11353 sgd_solver.cpp:106] Iteration 2200, lr = 0.0924715
I0830 12:58:06.030645 11353 solver.cpp:228] Iteration 2300, loss = 1.10341
I0830 12:58:06.030699 11353 solver.cpp:244]     Train net output #0: loss = 1.10341 (* 1 = 1.10341 loss)
I0830 12:58:06.030704 11353 sgd_solver.cpp:106] Iteration 2300, lr = 0.0921603
I0830 12:58:10.337638 11353 solver.cpp:228] Iteration 2400, loss = 1.09932
I0830 12:58:10.337658 11353 solver.cpp:244]     Train net output #0: loss = 1.09932 (* 1 = 1.09932 loss)
I0830 12:58:10.337664 11353 sgd_solver.cpp:106] Iteration 2400, lr = 0.0918515
I0830 12:58:14.604054 11353 solver.cpp:337] Iteration 2500, Testing net (#0)
I0830 12:58:18.125360 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152667
I0830 12:58:18.125421 11353 solver.cpp:404]     Test net output #1: loss = 1.11538 (* 1 = 1.11538 loss)
I0830 12:58:18.141113 11353 solver.cpp:228] Iteration 2500, loss = 1.09846
I0830 12:58:18.141155 11353 solver.cpp:244]     Train net output #0: loss = 1.09846 (* 1 = 1.09846 loss)
I0830 12:58:18.141172 11353 sgd_solver.cpp:106] Iteration 2500, lr = 0.0915452
I0830 12:58:22.451521 11353 solver.cpp:228] Iteration 2600, loss = 1.10648
I0830 12:58:22.451582 11353 solver.cpp:244]     Train net output #0: loss = 1.10648 (* 1 = 1.10648 loss)
I0830 12:58:22.451588 11353 sgd_solver.cpp:106] Iteration 2600, lr = 0.0912412
I0830 12:58:26.759737 11353 solver.cpp:228] Iteration 2700, loss = 1.08785
I0830 12:58:26.759790 11353 solver.cpp:244]     Train net output #0: loss = 1.08785 (* 1 = 1.08785 loss)
I0830 12:58:26.759799 11353 sgd_solver.cpp:106] Iteration 2700, lr = 0.0909396
I0830 12:58:31.037374 11353 solver.cpp:228] Iteration 2800, loss = 1.10041
I0830 12:58:31.037425 11353 solver.cpp:244]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0830 12:58:31.037431 11353 sgd_solver.cpp:106] Iteration 2800, lr = 0.0906403
I0830 12:58:35.342684 11353 solver.cpp:228] Iteration 2900, loss = 1.09624
I0830 12:58:35.342728 11353 solver.cpp:244]     Train net output #0: loss = 1.09624 (* 1 = 1.09624 loss)
I0830 12:58:35.342735 11353 sgd_solver.cpp:106] Iteration 2900, lr = 0.0903433
I0830 12:58:39.598798 11353 solver.cpp:337] Iteration 3000, Testing net (#0)
I0830 12:58:40.420307 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 12:58:42.722976 11353 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0830 12:58:42.723022 11353 solver.cpp:404]     Test net output #1: loss = 1.09069 (* 1 = 1.09069 loss)
I0830 12:58:42.737884 11353 solver.cpp:228] Iteration 3000, loss = 1.09996
I0830 12:58:42.737934 11353 solver.cpp:244]     Train net output #0: loss = 1.09996 (* 1 = 1.09996 loss)
I0830 12:58:42.737944 11353 sgd_solver.cpp:106] Iteration 3000, lr = 0.0900485
I0830 12:58:47.053187 11353 solver.cpp:228] Iteration 3100, loss = 1.09917
I0830 12:58:47.053243 11353 solver.cpp:244]     Train net output #0: loss = 1.09917 (* 1 = 1.09917 loss)
I0830 12:58:47.053251 11353 sgd_solver.cpp:106] Iteration 3100, lr = 0.089756
I0830 12:58:51.348565 11353 solver.cpp:228] Iteration 3200, loss = 1.10169
I0830 12:58:51.348595 11353 solver.cpp:244]     Train net output #0: loss = 1.10169 (* 1 = 1.10169 loss)
I0830 12:58:51.348600 11353 sgd_solver.cpp:106] Iteration 3200, lr = 0.0894657
I0830 12:58:55.642067 11353 solver.cpp:228] Iteration 3300, loss = 1.09738
I0830 12:58:55.642087 11353 solver.cpp:244]     Train net output #0: loss = 1.09738 (* 1 = 1.09738 loss)
I0830 12:58:55.642091 11353 sgd_solver.cpp:106] Iteration 3300, lr = 0.0891776
I0830 12:58:59.948941 11353 solver.cpp:228] Iteration 3400, loss = 1.10535
I0830 12:58:59.949008 11353 solver.cpp:244]     Train net output #0: loss = 1.10535 (* 1 = 1.10535 loss)
I0830 12:58:59.949028 11353 sgd_solver.cpp:106] Iteration 3400, lr = 0.0888916
I0830 12:59:04.226330 11353 solver.cpp:337] Iteration 3500, Testing net (#0)
I0830 12:59:07.498113 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578291
I0830 12:59:07.498157 11353 solver.cpp:404]     Test net output #1: loss = 1.08515 (* 1 = 1.08515 loss)
I0830 12:59:07.513847 11353 solver.cpp:228] Iteration 3500, loss = 1.10532
I0830 12:59:07.513885 11353 solver.cpp:244]     Train net output #0: loss = 1.10532 (* 1 = 1.10532 loss)
I0830 12:59:07.513898 11353 sgd_solver.cpp:106] Iteration 3500, lr = 0.0886077
I0830 12:59:11.820123 11353 solver.cpp:228] Iteration 3600, loss = 1.09185
I0830 12:59:11.820173 11353 solver.cpp:244]     Train net output #0: loss = 1.09185 (* 1 = 1.09185 loss)
I0830 12:59:11.820179 11353 sgd_solver.cpp:106] Iteration 3600, lr = 0.088326
I0830 12:59:16.126444 11353 solver.cpp:228] Iteration 3700, loss = 1.09762
I0830 12:59:16.126490 11353 solver.cpp:244]     Train net output #0: loss = 1.09762 (* 1 = 1.09762 loss)
I0830 12:59:16.126495 11353 sgd_solver.cpp:106] Iteration 3700, lr = 0.0880463
I0830 12:59:20.431089 11353 solver.cpp:228] Iteration 3800, loss = 1.0989
I0830 12:59:20.431145 11353 solver.cpp:244]     Train net output #0: loss = 1.0989 (* 1 = 1.0989 loss)
I0830 12:59:20.431151 11353 sgd_solver.cpp:106] Iteration 3800, lr = 0.0877687
I0830 12:59:24.746726 11353 solver.cpp:228] Iteration 3900, loss = 1.10447
I0830 12:59:24.746767 11353 solver.cpp:244]     Train net output #0: loss = 1.10447 (* 1 = 1.10447 loss)
I0830 12:59:24.746772 11353 sgd_solver.cpp:106] Iteration 3900, lr = 0.0874932
I0830 12:59:29.017741 11353 solver.cpp:337] Iteration 4000, Testing net (#0)
I0830 12:59:32.157552 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0830 12:59:32.157603 11353 solver.cpp:404]     Test net output #1: loss = 1.10293 (* 1 = 1.10293 loss)
I0830 12:59:32.172457 11353 solver.cpp:228] Iteration 4000, loss = 1.0991
I0830 12:59:32.172477 11353 solver.cpp:244]     Train net output #0: loss = 1.0991 (* 1 = 1.0991 loss)
I0830 12:59:32.172488 11353 sgd_solver.cpp:106] Iteration 4000, lr = 0.0872196
I0830 12:59:36.475080 11353 solver.cpp:228] Iteration 4100, loss = 1.08862
I0830 12:59:36.475121 11353 solver.cpp:244]     Train net output #0: loss = 1.08862 (* 1 = 1.08862 loss)
I0830 12:59:36.475126 11353 sgd_solver.cpp:106] Iteration 4100, lr = 0.086948
I0830 12:59:40.783336 11353 solver.cpp:228] Iteration 4200, loss = 1.09926
I0830 12:59:40.783383 11353 solver.cpp:244]     Train net output #0: loss = 1.09926 (* 1 = 1.09926 loss)
I0830 12:59:40.783390 11353 sgd_solver.cpp:106] Iteration 4200, lr = 0.0866784
I0830 12:59:45.075105 11353 solver.cpp:228] Iteration 4300, loss = 1.09677
I0830 12:59:45.075145 11353 solver.cpp:244]     Train net output #0: loss = 1.09677 (* 1 = 1.09677 loss)
I0830 12:59:45.075150 11353 sgd_solver.cpp:106] Iteration 4300, lr = 0.0864108
I0830 12:59:49.380511 11353 solver.cpp:228] Iteration 4400, loss = 1.09771
I0830 12:59:49.380549 11353 solver.cpp:244]     Train net output #0: loss = 1.09771 (* 1 = 1.09771 loss)
I0830 12:59:49.380554 11353 sgd_solver.cpp:106] Iteration 4400, lr = 0.086145
I0830 12:59:53.641041 11353 solver.cpp:337] Iteration 4500, Testing net (#0)
I0830 12:59:56.763656 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 12:59:56.763711 11353 solver.cpp:404]     Test net output #1: loss = 1.13353 (* 1 = 1.13353 loss)
I0830 12:59:56.777856 11353 solver.cpp:228] Iteration 4500, loss = 1.10263
I0830 12:59:56.777902 11353 solver.cpp:244]     Train net output #0: loss = 1.10263 (* 1 = 1.10263 loss)
I0830 12:59:56.777915 11353 sgd_solver.cpp:106] Iteration 4500, lr = 0.0858812
I0830 13:00:01.078131 11353 solver.cpp:228] Iteration 4600, loss = 1.11048
I0830 13:00:01.078168 11353 solver.cpp:244]     Train net output #0: loss = 1.11048 (* 1 = 1.11048 loss)
I0830 13:00:01.078173 11353 sgd_solver.cpp:106] Iteration 4600, lr = 0.0856192
I0830 13:00:05.382344 11353 solver.cpp:228] Iteration 4700, loss = 1.10143
I0830 13:00:05.382382 11353 solver.cpp:244]     Train net output #0: loss = 1.10143 (* 1 = 1.10143 loss)
I0830 13:00:05.382387 11353 sgd_solver.cpp:106] Iteration 4700, lr = 0.0853591
I0830 13:00:09.688330 11353 solver.cpp:228] Iteration 4800, loss = 1.09487
I0830 13:00:09.688369 11353 solver.cpp:244]     Train net output #0: loss = 1.09487 (* 1 = 1.09487 loss)
I0830 13:00:09.688374 11353 sgd_solver.cpp:106] Iteration 4800, lr = 0.0851008
I0830 13:00:14.005622 11353 solver.cpp:228] Iteration 4900, loss = 1.09961
I0830 13:00:14.005661 11353 solver.cpp:244]     Train net output #0: loss = 1.09961 (* 1 = 1.09961 loss)
I0830 13:00:14.005667 11353 sgd_solver.cpp:106] Iteration 4900, lr = 0.0848444
I0830 13:00:18.284687 11353 solver.cpp:337] Iteration 5000, Testing net (#0)
I0830 13:00:21.577603 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269458
I0830 13:00:21.577682 11353 solver.cpp:404]     Test net output #1: loss = 1.1272 (* 1 = 1.1272 loss)
I0830 13:00:21.592614 11353 solver.cpp:228] Iteration 5000, loss = 1.08943
I0830 13:00:21.592650 11353 solver.cpp:244]     Train net output #0: loss = 1.08943 (* 1 = 1.08943 loss)
I0830 13:00:21.592660 11353 sgd_solver.cpp:106] Iteration 5000, lr = 0.0845897
I0830 13:00:25.900797 11353 solver.cpp:228] Iteration 5100, loss = 1.10141
I0830 13:00:25.900835 11353 solver.cpp:244]     Train net output #0: loss = 1.10141 (* 1 = 1.10141 loss)
I0830 13:00:25.900840 11353 sgd_solver.cpp:106] Iteration 5100, lr = 0.0843368
I0830 13:00:30.221544 11353 solver.cpp:228] Iteration 5200, loss = 1.09826
I0830 13:00:30.221676 11353 solver.cpp:244]     Train net output #0: loss = 1.09826 (* 1 = 1.09826 loss)
I0830 13:00:30.221707 11353 sgd_solver.cpp:106] Iteration 5200, lr = 0.0840857
I0830 13:00:34.539244 11353 solver.cpp:228] Iteration 5300, loss = 1.09983
I0830 13:00:34.539314 11353 solver.cpp:244]     Train net output #0: loss = 1.09983 (* 1 = 1.09983 loss)
I0830 13:00:34.539325 11353 sgd_solver.cpp:106] Iteration 5300, lr = 0.0838363
I0830 13:00:38.862112 11353 solver.cpp:228] Iteration 5400, loss = 1.09967
I0830 13:00:38.862151 11353 solver.cpp:244]     Train net output #0: loss = 1.09967 (* 1 = 1.09967 loss)
I0830 13:00:38.862156 11353 sgd_solver.cpp:106] Iteration 5400, lr = 0.0835886
I0830 13:00:43.132323 11353 solver.cpp:337] Iteration 5500, Testing net (#0)
I0830 13:00:46.673465 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0830 13:00:46.673526 11353 solver.cpp:404]     Test net output #1: loss = 1.12584 (* 1 = 1.12584 loss)
I0830 13:00:46.688412 11353 solver.cpp:228] Iteration 5500, loss = 1.10153
I0830 13:00:46.688462 11353 solver.cpp:244]     Train net output #0: loss = 1.10153 (* 1 = 1.10153 loss)
I0830 13:00:46.688475 11353 sgd_solver.cpp:106] Iteration 5500, lr = 0.0833427
I0830 13:00:50.999152 11353 solver.cpp:228] Iteration 5600, loss = 1.09681
I0830 13:00:50.999197 11353 solver.cpp:244]     Train net output #0: loss = 1.09681 (* 1 = 1.09681 loss)
I0830 13:00:50.999202 11353 sgd_solver.cpp:106] Iteration 5600, lr = 0.0830984
I0830 13:00:55.303429 11353 solver.cpp:228] Iteration 5700, loss = 1.09852
I0830 13:00:55.303491 11353 solver.cpp:244]     Train net output #0: loss = 1.09852 (* 1 = 1.09852 loss)
I0830 13:00:55.303505 11353 sgd_solver.cpp:106] Iteration 5700, lr = 0.0828558
I0830 13:00:59.609273 11353 solver.cpp:228] Iteration 5800, loss = 1.09958
I0830 13:00:59.609325 11353 solver.cpp:244]     Train net output #0: loss = 1.09958 (* 1 = 1.09958 loss)
I0830 13:00:59.609336 11353 sgd_solver.cpp:106] Iteration 5800, lr = 0.0826148
I0830 13:01:03.913879 11353 solver.cpp:228] Iteration 5900, loss = 1.09803
I0830 13:01:03.913920 11353 solver.cpp:244]     Train net output #0: loss = 1.09803 (* 1 = 1.09803 loss)
I0830 13:01:03.913925 11353 sgd_solver.cpp:106] Iteration 5900, lr = 0.0823754
I0830 13:01:08.183027 11353 solver.cpp:337] Iteration 6000, Testing net (#0)
I0830 13:01:11.630745 11353 solver.cpp:404]     Test net output #0: accuracy = 0.26925
I0830 13:01:11.630822 11353 solver.cpp:404]     Test net output #1: loss = 1.10458 (* 1 = 1.10458 loss)
I0830 13:01:11.649957 11353 solver.cpp:228] Iteration 6000, loss = 1.10025
I0830 13:01:11.650014 11353 solver.cpp:244]     Train net output #0: loss = 1.10025 (* 1 = 1.10025 loss)
I0830 13:01:11.650034 11353 sgd_solver.cpp:106] Iteration 6000, lr = 0.0821377
I0830 13:01:15.951555 11353 solver.cpp:228] Iteration 6100, loss = 1.09826
I0830 13:01:15.951624 11353 solver.cpp:244]     Train net output #0: loss = 1.09826 (* 1 = 1.09826 loss)
I0830 13:01:15.951630 11353 sgd_solver.cpp:106] Iteration 6100, lr = 0.0819016
I0830 13:01:20.261978 11353 solver.cpp:228] Iteration 6200, loss = 1.10274
I0830 13:01:20.262063 11353 solver.cpp:244]     Train net output #0: loss = 1.10274 (* 1 = 1.10274 loss)
I0830 13:01:20.262068 11353 sgd_solver.cpp:106] Iteration 6200, lr = 0.081667
I0830 13:01:24.566699 11353 solver.cpp:228] Iteration 6300, loss = 1.09836
I0830 13:01:24.566802 11353 solver.cpp:244]     Train net output #0: loss = 1.09836 (* 1 = 1.09836 loss)
I0830 13:01:24.566810 11353 sgd_solver.cpp:106] Iteration 6300, lr = 0.081434
I0830 13:01:28.446898 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:01:28.876428 11353 solver.cpp:228] Iteration 6400, loss = 1.09735
I0830 13:01:28.876508 11353 solver.cpp:244]     Train net output #0: loss = 1.09735 (* 1 = 1.09735 loss)
I0830 13:01:28.876514 11353 sgd_solver.cpp:106] Iteration 6400, lr = 0.0812025
I0830 13:01:33.126796 11353 solver.cpp:337] Iteration 6500, Testing net (#0)
I0830 13:01:36.518200 11353 solver.cpp:404]     Test net output #0: accuracy = 0.5785
I0830 13:01:36.518259 11353 solver.cpp:404]     Test net output #1: loss = 1.0692 (* 1 = 1.0692 loss)
I0830 13:01:36.532977 11353 solver.cpp:228] Iteration 6500, loss = 1.10199
I0830 13:01:36.533015 11353 solver.cpp:244]     Train net output #0: loss = 1.10199 (* 1 = 1.10199 loss)
I0830 13:01:36.533025 11353 sgd_solver.cpp:106] Iteration 6500, lr = 0.0809726
I0830 13:01:40.822985 11353 solver.cpp:228] Iteration 6600, loss = 1.10232
I0830 13:01:40.823051 11353 solver.cpp:244]     Train net output #0: loss = 1.10232 (* 1 = 1.10232 loss)
I0830 13:01:40.823057 11353 sgd_solver.cpp:106] Iteration 6600, lr = 0.0807442
I0830 13:01:45.123044 11353 solver.cpp:228] Iteration 6700, loss = 1.09535
I0830 13:01:45.123092 11353 solver.cpp:244]     Train net output #0: loss = 1.09535 (* 1 = 1.09535 loss)
I0830 13:01:45.123098 11353 sgd_solver.cpp:106] Iteration 6700, lr = 0.0805173
I0830 13:01:49.424816 11353 solver.cpp:228] Iteration 6800, loss = 1.0997
I0830 13:01:49.424860 11353 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0830 13:01:49.424866 11353 sgd_solver.cpp:106] Iteration 6800, lr = 0.0802918
I0830 13:01:53.733316 11353 solver.cpp:228] Iteration 6900, loss = 1.11779
I0830 13:01:53.733371 11353 solver.cpp:244]     Train net output #0: loss = 1.11779 (* 1 = 1.11779 loss)
I0830 13:01:53.733377 11353 sgd_solver.cpp:106] Iteration 6900, lr = 0.0800679
I0830 13:01:57.990949 11353 solver.cpp:337] Iteration 7000, Testing net (#0)
I0830 13:02:01.513603 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0830 13:02:01.513658 11353 solver.cpp:404]     Test net output #1: loss = 1.06917 (* 1 = 1.06917 loss)
I0830 13:02:01.528509 11353 solver.cpp:228] Iteration 7000, loss = 1.08558
I0830 13:02:01.528555 11353 solver.cpp:244]     Train net output #0: loss = 1.08558 (* 1 = 1.08558 loss)
I0830 13:02:01.528569 11353 sgd_solver.cpp:106] Iteration 7000, lr = 0.0798454
I0830 13:02:05.835443 11353 solver.cpp:228] Iteration 7100, loss = 1.10127
I0830 13:02:05.835484 11353 solver.cpp:244]     Train net output #0: loss = 1.10127 (* 1 = 1.10127 loss)
I0830 13:02:05.835490 11353 sgd_solver.cpp:106] Iteration 7100, lr = 0.0796243
I0830 13:02:10.157771 11353 solver.cpp:228] Iteration 7200, loss = 1.09438
I0830 13:02:10.157819 11353 solver.cpp:244]     Train net output #0: loss = 1.09438 (* 1 = 1.09438 loss)
I0830 13:02:10.157853 11353 sgd_solver.cpp:106] Iteration 7200, lr = 0.0794046
I0830 13:02:14.482241 11353 solver.cpp:228] Iteration 7300, loss = 1.08638
I0830 13:02:14.482290 11353 solver.cpp:244]     Train net output #0: loss = 1.08638 (* 1 = 1.08638 loss)
I0830 13:02:14.482297 11353 sgd_solver.cpp:106] Iteration 7300, lr = 0.0791864
I0830 13:02:18.789780 11353 solver.cpp:228] Iteration 7400, loss = 1.09967
I0830 13:02:18.789824 11353 solver.cpp:244]     Train net output #0: loss = 1.09967 (* 1 = 1.09967 loss)
I0830 13:02:18.789829 11353 sgd_solver.cpp:106] Iteration 7400, lr = 0.0789695
I0830 13:02:23.059815 11353 solver.cpp:337] Iteration 7500, Testing net (#0)
I0830 13:02:26.518404 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578583
I0830 13:02:26.518453 11353 solver.cpp:404]     Test net output #1: loss = 1.07061 (* 1 = 1.07061 loss)
I0830 13:02:26.533332 11353 solver.cpp:228] Iteration 7500, loss = 1.10458
I0830 13:02:26.533375 11353 solver.cpp:244]     Train net output #0: loss = 1.10458 (* 1 = 1.10458 loss)
I0830 13:02:26.533385 11353 sgd_solver.cpp:106] Iteration 7500, lr = 0.0787541
I0830 13:02:30.840890 11353 solver.cpp:228] Iteration 7600, loss = 1.09884
I0830 13:02:30.840934 11353 solver.cpp:244]     Train net output #0: loss = 1.09884 (* 1 = 1.09884 loss)
I0830 13:02:30.840939 11353 sgd_solver.cpp:106] Iteration 7600, lr = 0.07854
I0830 13:02:35.135274 11353 solver.cpp:228] Iteration 7700, loss = 1.12028
I0830 13:02:35.135313 11353 solver.cpp:244]     Train net output #0: loss = 1.12028 (* 1 = 1.12028 loss)
I0830 13:02:35.135318 11353 sgd_solver.cpp:106] Iteration 7700, lr = 0.0783272
I0830 13:02:39.432806 11353 solver.cpp:228] Iteration 7800, loss = 1.10648
I0830 13:02:39.432859 11353 solver.cpp:244]     Train net output #0: loss = 1.10648 (* 1 = 1.10648 loss)
I0830 13:02:39.432868 11353 sgd_solver.cpp:106] Iteration 7800, lr = 0.0781158
I0830 13:02:43.726666 11353 solver.cpp:228] Iteration 7900, loss = 1.0945
I0830 13:02:43.726687 11353 solver.cpp:244]     Train net output #0: loss = 1.0945 (* 1 = 1.0945 loss)
I0830 13:02:43.726692 11353 sgd_solver.cpp:106] Iteration 7900, lr = 0.0779057
I0830 13:02:47.983348 11353 solver.cpp:337] Iteration 8000, Testing net (#0)
I0830 13:02:51.585111 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:02:51.648331 11353 solver.cpp:404]     Test net output #0: accuracy = 0.151833
I0830 13:02:51.648421 11353 solver.cpp:404]     Test net output #1: loss = 1.10155 (* 1 = 1.10155 loss)
I0830 13:02:51.663575 11353 solver.cpp:228] Iteration 8000, loss = 1.09671
I0830 13:02:51.663619 11353 solver.cpp:244]     Train net output #0: loss = 1.09671 (* 1 = 1.09671 loss)
I0830 13:02:51.663638 11353 sgd_solver.cpp:106] Iteration 8000, lr = 0.0776969
I0830 13:02:55.956086 11353 solver.cpp:228] Iteration 8100, loss = 1.09678
I0830 13:02:55.956130 11353 solver.cpp:244]     Train net output #0: loss = 1.09678 (* 1 = 1.09678 loss)
I0830 13:02:55.956135 11353 sgd_solver.cpp:106] Iteration 8100, lr = 0.0774895
I0830 13:03:00.247244 11353 solver.cpp:228] Iteration 8200, loss = 1.10155
I0830 13:03:00.247288 11353 solver.cpp:244]     Train net output #0: loss = 1.10155 (* 1 = 1.10155 loss)
I0830 13:03:00.247293 11353 sgd_solver.cpp:106] Iteration 8200, lr = 0.0772833
I0830 13:03:04.535955 11353 solver.cpp:228] Iteration 8300, loss = 1.10117
I0830 13:03:04.535998 11353 solver.cpp:244]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0830 13:03:04.536005 11353 sgd_solver.cpp:106] Iteration 8300, lr = 0.0770784
I0830 13:03:08.821934 11353 solver.cpp:228] Iteration 8400, loss = 1.11431
I0830 13:03:08.821976 11353 solver.cpp:244]     Train net output #0: loss = 1.11431 (* 1 = 1.11431 loss)
I0830 13:03:08.821981 11353 sgd_solver.cpp:106] Iteration 8400, lr = 0.0768748
I0830 13:03:13.078301 11353 solver.cpp:337] Iteration 8500, Testing net (#0)
I0830 13:03:16.376147 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0830 13:03:16.376212 11353 solver.cpp:404]     Test net output #1: loss = 1.13456 (* 1 = 1.13456 loss)
I0830 13:03:16.391517 11353 solver.cpp:228] Iteration 8500, loss = 1.10335
I0830 13:03:16.391573 11353 solver.cpp:244]     Train net output #0: loss = 1.10335 (* 1 = 1.10335 loss)
I0830 13:03:16.391589 11353 sgd_solver.cpp:106] Iteration 8500, lr = 0.0766724
I0830 13:03:20.693755 11353 solver.cpp:228] Iteration 8600, loss = 1.09373
I0830 13:03:20.693815 11353 solver.cpp:244]     Train net output #0: loss = 1.09373 (* 1 = 1.09373 loss)
I0830 13:03:20.693822 11353 sgd_solver.cpp:106] Iteration 8600, lr = 0.0764712
I0830 13:03:24.992822 11353 solver.cpp:228] Iteration 8700, loss = 1.09634
I0830 13:03:24.992843 11353 solver.cpp:244]     Train net output #0: loss = 1.09634 (* 1 = 1.09634 loss)
I0830 13:03:24.992848 11353 sgd_solver.cpp:106] Iteration 8700, lr = 0.0762713
I0830 13:03:29.288763 11353 solver.cpp:228] Iteration 8800, loss = 1.09559
I0830 13:03:29.288782 11353 solver.cpp:244]     Train net output #0: loss = 1.09559 (* 1 = 1.09559 loss)
I0830 13:03:29.288787 11353 sgd_solver.cpp:106] Iteration 8800, lr = 0.0760726
I0830 13:03:33.593060 11353 solver.cpp:228] Iteration 8900, loss = 1.10041
I0830 13:03:33.593109 11353 solver.cpp:244]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0830 13:03:33.593116 11353 sgd_solver.cpp:106] Iteration 8900, lr = 0.0758751
I0830 13:03:37.855063 11353 solver.cpp:337] Iteration 9000, Testing net (#0)
I0830 13:03:41.236835 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0830 13:03:41.236894 11353 solver.cpp:404]     Test net output #1: loss = 1.13604 (* 1 = 1.13604 loss)
I0830 13:03:41.253228 11353 solver.cpp:228] Iteration 9000, loss = 1.0971
I0830 13:03:41.253293 11353 solver.cpp:244]     Train net output #0: loss = 1.0971 (* 1 = 1.0971 loss)
I0830 13:03:41.253306 11353 sgd_solver.cpp:106] Iteration 9000, lr = 0.0756788
I0830 13:03:45.560230 11353 solver.cpp:228] Iteration 9100, loss = 1.09842
I0830 13:03:45.560287 11353 solver.cpp:244]     Train net output #0: loss = 1.09842 (* 1 = 1.09842 loss)
I0830 13:03:45.560293 11353 sgd_solver.cpp:106] Iteration 9100, lr = 0.0754836
I0830 13:03:49.865604 11353 solver.cpp:228] Iteration 9200, loss = 1.09576
I0830 13:03:49.865744 11353 solver.cpp:244]     Train net output #0: loss = 1.09576 (* 1 = 1.09576 loss)
I0830 13:03:49.865762 11353 sgd_solver.cpp:106] Iteration 9200, lr = 0.0752897
I0830 13:03:54.168897 11353 solver.cpp:228] Iteration 9300, loss = 1.09933
I0830 13:03:54.168941 11353 solver.cpp:244]     Train net output #0: loss = 1.09933 (* 1 = 1.09933 loss)
I0830 13:03:54.168947 11353 sgd_solver.cpp:106] Iteration 9300, lr = 0.0750969
I0830 13:03:58.476119 11353 solver.cpp:228] Iteration 9400, loss = 1.09827
I0830 13:03:58.476161 11353 solver.cpp:244]     Train net output #0: loss = 1.09827 (* 1 = 1.09827 loss)
I0830 13:03:58.476166 11353 sgd_solver.cpp:106] Iteration 9400, lr = 0.0749052
I0830 13:04:02.739284 11353 solver.cpp:337] Iteration 9500, Testing net (#0)
I0830 13:04:06.177559 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0830 13:04:06.177630 11353 solver.cpp:404]     Test net output #1: loss = 1.1273 (* 1 = 1.1273 loss)
I0830 13:04:06.191622 11353 solver.cpp:228] Iteration 9500, loss = 1.09537
I0830 13:04:06.191681 11353 solver.cpp:244]     Train net output #0: loss = 1.09537 (* 1 = 1.09537 loss)
I0830 13:04:06.191705 11353 sgd_solver.cpp:106] Iteration 9500, lr = 0.0747147
I0830 13:04:10.486354 11353 solver.cpp:228] Iteration 9600, loss = 1.09951
I0830 13:04:10.486397 11353 solver.cpp:244]     Train net output #0: loss = 1.09951 (* 1 = 1.09951 loss)
I0830 13:04:10.486402 11353 sgd_solver.cpp:106] Iteration 9600, lr = 0.0745253
I0830 13:04:14.797452 11353 solver.cpp:228] Iteration 9700, loss = 1.10188
I0830 13:04:14.797503 11353 solver.cpp:244]     Train net output #0: loss = 1.10188 (* 1 = 1.10188 loss)
I0830 13:04:14.797509 11353 sgd_solver.cpp:106] Iteration 9700, lr = 0.074337
I0830 13:04:19.104001 11353 solver.cpp:228] Iteration 9800, loss = 1.09975
I0830 13:04:19.104053 11353 solver.cpp:244]     Train net output #0: loss = 1.09975 (* 1 = 1.09975 loss)
I0830 13:04:19.104060 11353 sgd_solver.cpp:106] Iteration 9800, lr = 0.0741499
I0830 13:04:23.405448 11353 solver.cpp:228] Iteration 9900, loss = 1.10101
I0830 13:04:23.405493 11353 solver.cpp:244]     Train net output #0: loss = 1.10101 (* 1 = 1.10101 loss)
I0830 13:04:23.405498 11353 sgd_solver.cpp:106] Iteration 9900, lr = 0.0739638
I0830 13:04:27.658975 11353 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_10000.caffemodel
I0830 13:04:28.305467 11353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_10000.solverstate
I0830 13:04:28.611906 11353 solver.cpp:337] Iteration 10000, Testing net (#0)
I0830 13:04:31.061686 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:04:32.115403 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:04:32.115440 11353 solver.cpp:404]     Test net output #1: loss = 1.10903 (* 1 = 1.10903 loss)
I0830 13:04:32.130270 11353 solver.cpp:228] Iteration 10000, loss = 1.10022
I0830 13:04:32.130295 11353 solver.cpp:244]     Train net output #0: loss = 1.10022 (* 1 = 1.10022 loss)
I0830 13:04:32.130307 11353 sgd_solver.cpp:106] Iteration 10000, lr = 0.0737788
I0830 13:04:36.428091 11353 solver.cpp:228] Iteration 10100, loss = 1.1021
I0830 13:04:36.428140 11353 solver.cpp:244]     Train net output #0: loss = 1.1021 (* 1 = 1.1021 loss)
I0830 13:04:36.428148 11353 sgd_solver.cpp:106] Iteration 10100, lr = 0.0735949
I0830 13:04:40.729352 11353 solver.cpp:228] Iteration 10200, loss = 1.09686
I0830 13:04:40.729406 11353 solver.cpp:244]     Train net output #0: loss = 1.09686 (* 1 = 1.09686 loss)
I0830 13:04:40.729413 11353 sgd_solver.cpp:106] Iteration 10200, lr = 0.073412
I0830 13:04:45.046916 11353 solver.cpp:228] Iteration 10300, loss = 1.10211
I0830 13:04:45.046959 11353 solver.cpp:244]     Train net output #0: loss = 1.10211 (* 1 = 1.10211 loss)
I0830 13:04:45.046964 11353 sgd_solver.cpp:106] Iteration 10300, lr = 0.0732303
I0830 13:04:49.359881 11353 solver.cpp:228] Iteration 10400, loss = 1.09793
I0830 13:04:49.359944 11353 solver.cpp:244]     Train net output #0: loss = 1.09793 (* 1 = 1.09793 loss)
I0830 13:04:49.359951 11353 sgd_solver.cpp:106] Iteration 10400, lr = 0.0730495
I0830 13:04:53.618353 11353 solver.cpp:337] Iteration 10500, Testing net (#0)
I0830 13:04:56.908478 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0830 13:04:56.908526 11353 solver.cpp:404]     Test net output #1: loss = 1.09495 (* 1 = 1.09495 loss)
I0830 13:04:56.922751 11353 solver.cpp:228] Iteration 10500, loss = 1.10117
I0830 13:04:56.922791 11353 solver.cpp:244]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0830 13:04:56.922801 11353 sgd_solver.cpp:106] Iteration 10500, lr = 0.0728698
I0830 13:05:01.229358 11353 solver.cpp:228] Iteration 10600, loss = 1.09669
I0830 13:05:01.229403 11353 solver.cpp:244]     Train net output #0: loss = 1.09669 (* 1 = 1.09669 loss)
I0830 13:05:01.229409 11353 sgd_solver.cpp:106] Iteration 10600, lr = 0.0726911
I0830 13:05:05.527685 11353 solver.cpp:228] Iteration 10700, loss = 1.10034
I0830 13:05:05.527706 11353 solver.cpp:244]     Train net output #0: loss = 1.10034 (* 1 = 1.10034 loss)
I0830 13:05:05.527711 11353 sgd_solver.cpp:106] Iteration 10700, lr = 0.0725135
I0830 13:05:09.831446 11353 solver.cpp:228] Iteration 10800, loss = 1.10686
I0830 13:05:09.831492 11353 solver.cpp:244]     Train net output #0: loss = 1.10686 (* 1 = 1.10686 loss)
I0830 13:05:09.831498 11353 sgd_solver.cpp:106] Iteration 10800, lr = 0.0723368
I0830 13:05:14.146040 11353 solver.cpp:228] Iteration 10900, loss = 1.10105
I0830 13:05:14.146080 11353 solver.cpp:244]     Train net output #0: loss = 1.10105 (* 1 = 1.10105 loss)
I0830 13:05:14.146085 11353 sgd_solver.cpp:106] Iteration 10900, lr = 0.0721612
I0830 13:05:18.413301 11353 solver.cpp:337] Iteration 11000, Testing net (#0)
I0830 13:05:22.033200 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0830 13:05:22.033267 11353 solver.cpp:404]     Test net output #1: loss = 1.09317 (* 1 = 1.09317 loss)
I0830 13:05:22.048573 11353 solver.cpp:228] Iteration 11000, loss = 1.09795
I0830 13:05:22.048638 11353 solver.cpp:244]     Train net output #0: loss = 1.09795 (* 1 = 1.09795 loss)
I0830 13:05:22.048657 11353 sgd_solver.cpp:106] Iteration 11000, lr = 0.0719865
I0830 13:05:26.357147 11353 solver.cpp:228] Iteration 11100, loss = 1.11098
I0830 13:05:26.357194 11353 solver.cpp:244]     Train net output #0: loss = 1.11098 (* 1 = 1.11098 loss)
I0830 13:05:26.357200 11353 sgd_solver.cpp:106] Iteration 11100, lr = 0.0718129
I0830 13:05:30.657352 11353 solver.cpp:228] Iteration 11200, loss = 1.10878
I0830 13:05:30.657398 11353 solver.cpp:244]     Train net output #0: loss = 1.10878 (* 1 = 1.10878 loss)
I0830 13:05:30.657403 11353 sgd_solver.cpp:106] Iteration 11200, lr = 0.0716402
I0830 13:05:34.963846 11353 solver.cpp:228] Iteration 11300, loss = 1.0945
I0830 13:05:34.963922 11353 solver.cpp:244]     Train net output #0: loss = 1.0945 (* 1 = 1.0945 loss)
I0830 13:05:34.963927 11353 sgd_solver.cpp:106] Iteration 11300, lr = 0.0714684
I0830 13:05:39.264430 11353 solver.cpp:228] Iteration 11400, loss = 1.09989
I0830 13:05:39.264473 11353 solver.cpp:244]     Train net output #0: loss = 1.09989 (* 1 = 1.09989 loss)
I0830 13:05:39.264479 11353 sgd_solver.cpp:106] Iteration 11400, lr = 0.0712977
I0830 13:05:43.515864 11353 solver.cpp:337] Iteration 11500, Testing net (#0)
I0830 13:05:46.950538 11353 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0830 13:05:46.950608 11353 solver.cpp:404]     Test net output #1: loss = 1.08246 (* 1 = 1.08246 loss)
I0830 13:05:46.965837 11353 solver.cpp:228] Iteration 11500, loss = 1.09624
I0830 13:05:46.965909 11353 solver.cpp:244]     Train net output #0: loss = 1.09624 (* 1 = 1.09624 loss)
I0830 13:05:46.965925 11353 sgd_solver.cpp:106] Iteration 11500, lr = 0.0711278
I0830 13:05:51.263566 11353 solver.cpp:228] Iteration 11600, loss = 1.09155
I0830 13:05:51.263640 11353 solver.cpp:244]     Train net output #0: loss = 1.09155 (* 1 = 1.09155 loss)
I0830 13:05:51.263654 11353 sgd_solver.cpp:106] Iteration 11600, lr = 0.070959
I0830 13:05:55.555984 11353 solver.cpp:228] Iteration 11700, loss = 1.09671
I0830 13:05:55.556026 11353 solver.cpp:244]     Train net output #0: loss = 1.09671 (* 1 = 1.09671 loss)
I0830 13:05:55.556032 11353 sgd_solver.cpp:106] Iteration 11700, lr = 0.070791
I0830 13:05:59.849493 11353 solver.cpp:228] Iteration 11800, loss = 1.09226
I0830 13:05:59.849570 11353 solver.cpp:244]     Train net output #0: loss = 1.09226 (* 1 = 1.09226 loss)
I0830 13:05:59.849578 11353 sgd_solver.cpp:106] Iteration 11800, lr = 0.070624
I0830 13:06:04.163271 11353 solver.cpp:228] Iteration 11900, loss = 1.09862
I0830 13:06:04.163328 11353 solver.cpp:244]     Train net output #0: loss = 1.09862 (* 1 = 1.09862 loss)
I0830 13:06:04.163334 11353 sgd_solver.cpp:106] Iteration 11900, lr = 0.0704579
I0830 13:06:08.421929 11353 solver.cpp:337] Iteration 12000, Testing net (#0)
I0830 13:06:09.030063 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:06:11.803756 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0830 13:06:11.803813 11353 solver.cpp:404]     Test net output #1: loss = 1.06631 (* 1 = 1.06631 loss)
I0830 13:06:11.817770 11353 solver.cpp:228] Iteration 12000, loss = 1.10913
I0830 13:06:11.817786 11353 solver.cpp:244]     Train net output #0: loss = 1.10913 (* 1 = 1.10913 loss)
I0830 13:06:11.817793 11353 sgd_solver.cpp:106] Iteration 12000, lr = 0.0702927
I0830 13:06:16.112560 11353 solver.cpp:228] Iteration 12100, loss = 1.1075
I0830 13:06:16.112579 11353 solver.cpp:244]     Train net output #0: loss = 1.1075 (* 1 = 1.1075 loss)
I0830 13:06:16.112584 11353 sgd_solver.cpp:106] Iteration 12100, lr = 0.0701284
I0830 13:06:20.419011 11353 solver.cpp:228] Iteration 12200, loss = 1.09242
I0830 13:06:20.419031 11353 solver.cpp:244]     Train net output #0: loss = 1.09242 (* 1 = 1.09242 loss)
I0830 13:06:20.419036 11353 sgd_solver.cpp:106] Iteration 12200, lr = 0.069965
I0830 13:06:24.721137 11353 solver.cpp:228] Iteration 12300, loss = 1.09819
I0830 13:06:24.721180 11353 solver.cpp:244]     Train net output #0: loss = 1.09819 (* 1 = 1.09819 loss)
I0830 13:06:24.721185 11353 sgd_solver.cpp:106] Iteration 12300, lr = 0.0698024
I0830 13:06:29.019742 11353 solver.cpp:228] Iteration 12400, loss = 1.09746
I0830 13:06:29.019781 11353 solver.cpp:244]     Train net output #0: loss = 1.09746 (* 1 = 1.09746 loss)
I0830 13:06:29.019788 11353 sgd_solver.cpp:106] Iteration 12400, lr = 0.0696408
I0830 13:06:33.268524 11353 solver.cpp:337] Iteration 12500, Testing net (#0)
I0830 13:06:36.765492 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578333
I0830 13:06:36.765558 11353 solver.cpp:404]     Test net output #1: loss = 1.07387 (* 1 = 1.07387 loss)
I0830 13:06:36.780436 11353 solver.cpp:228] Iteration 12500, loss = 1.09707
I0830 13:06:36.780478 11353 solver.cpp:244]     Train net output #0: loss = 1.09707 (* 1 = 1.09707 loss)
I0830 13:06:36.780493 11353 sgd_solver.cpp:106] Iteration 12500, lr = 0.06948
I0830 13:06:41.089196 11353 solver.cpp:228] Iteration 12600, loss = 1.09787
I0830 13:06:41.089239 11353 solver.cpp:244]     Train net output #0: loss = 1.09787 (* 1 = 1.09787 loss)
I0830 13:06:41.089246 11353 sgd_solver.cpp:106] Iteration 12600, lr = 0.0693201
I0830 13:06:45.410449 11353 solver.cpp:228] Iteration 12700, loss = 1.11054
I0830 13:06:45.410470 11353 solver.cpp:244]     Train net output #0: loss = 1.11054 (* 1 = 1.11054 loss)
I0830 13:06:45.410475 11353 sgd_solver.cpp:106] Iteration 12700, lr = 0.0691611
I0830 13:06:49.722965 11353 solver.cpp:228] Iteration 12800, loss = 1.09338
I0830 13:06:49.723009 11353 solver.cpp:244]     Train net output #0: loss = 1.09338 (* 1 = 1.09338 loss)
I0830 13:06:49.723016 11353 sgd_solver.cpp:106] Iteration 12800, lr = 0.0690029
I0830 13:06:54.035393 11353 solver.cpp:228] Iteration 12900, loss = 1.0963
I0830 13:06:54.035460 11353 solver.cpp:244]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0830 13:06:54.035467 11353 sgd_solver.cpp:106] Iteration 12900, lr = 0.0688455
I0830 13:06:58.314857 11353 solver.cpp:337] Iteration 13000, Testing net (#0)
I0830 13:07:01.828550 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0830 13:07:01.828613 11353 solver.cpp:404]     Test net output #1: loss = 1.0878 (* 1 = 1.0878 loss)
I0830 13:07:01.843493 11353 solver.cpp:228] Iteration 13000, loss = 1.09735
I0830 13:07:01.843544 11353 solver.cpp:244]     Train net output #0: loss = 1.09735 (* 1 = 1.09735 loss)
I0830 13:07:01.843559 11353 sgd_solver.cpp:106] Iteration 13000, lr = 0.068689
I0830 13:07:06.149508 11353 solver.cpp:228] Iteration 13100, loss = 1.10102
I0830 13:07:06.149528 11353 solver.cpp:244]     Train net output #0: loss = 1.10102 (* 1 = 1.10102 loss)
I0830 13:07:06.149533 11353 sgd_solver.cpp:106] Iteration 13100, lr = 0.0685333
I0830 13:07:10.449039 11353 solver.cpp:228] Iteration 13200, loss = 1.09577
I0830 13:07:10.449060 11353 solver.cpp:244]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0830 13:07:10.449066 11353 sgd_solver.cpp:106] Iteration 13200, lr = 0.0683784
I0830 13:07:14.749943 11353 solver.cpp:228] Iteration 13300, loss = 1.09833
I0830 13:07:14.750001 11353 solver.cpp:244]     Train net output #0: loss = 1.09833 (* 1 = 1.09833 loss)
I0830 13:07:14.750011 11353 sgd_solver.cpp:106] Iteration 13300, lr = 0.0682243
I0830 13:07:19.058166 11353 solver.cpp:228] Iteration 13400, loss = 1.0981
I0830 13:07:19.058209 11353 solver.cpp:244]     Train net output #0: loss = 1.0981 (* 1 = 1.0981 loss)
I0830 13:07:19.058214 11353 sgd_solver.cpp:106] Iteration 13400, lr = 0.0680711
I0830 13:07:23.330893 11353 solver.cpp:337] Iteration 13500, Testing net (#0)
I0830 13:07:26.719722 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0830 13:07:26.719792 11353 solver.cpp:404]     Test net output #1: loss = 1.10052 (* 1 = 1.10052 loss)
I0830 13:07:26.734334 11353 solver.cpp:228] Iteration 13500, loss = 1.09427
I0830 13:07:26.734378 11353 solver.cpp:244]     Train net output #0: loss = 1.09427 (* 1 = 1.09427 loss)
I0830 13:07:26.734390 11353 sgd_solver.cpp:106] Iteration 13500, lr = 0.0679186
I0830 13:07:31.033546 11353 solver.cpp:228] Iteration 13600, loss = 1.10908
I0830 13:07:31.033614 11353 solver.cpp:244]     Train net output #0: loss = 1.10908 (* 1 = 1.10908 loss)
I0830 13:07:31.033620 11353 sgd_solver.cpp:106] Iteration 13600, lr = 0.067767
I0830 13:07:35.337220 11353 solver.cpp:228] Iteration 13700, loss = 1.09435
I0830 13:07:35.337291 11353 solver.cpp:244]     Train net output #0: loss = 1.09435 (* 1 = 1.09435 loss)
I0830 13:07:35.337297 11353 sgd_solver.cpp:106] Iteration 13700, lr = 0.0676161
I0830 13:07:39.635851 11353 solver.cpp:228] Iteration 13800, loss = 1.10348
I0830 13:07:39.635902 11353 solver.cpp:244]     Train net output #0: loss = 1.10348 (* 1 = 1.10348 loss)
I0830 13:07:39.635912 11353 sgd_solver.cpp:106] Iteration 13800, lr = 0.067466
I0830 13:07:43.942136 11353 solver.cpp:228] Iteration 13900, loss = 1.09766
I0830 13:07:43.942179 11353 solver.cpp:244]     Train net output #0: loss = 1.09766 (* 1 = 1.09766 loss)
I0830 13:07:43.942185 11353 sgd_solver.cpp:106] Iteration 13900, lr = 0.0673167
I0830 13:07:48.208287 11353 solver.cpp:337] Iteration 14000, Testing net (#0)
I0830 13:07:48.912571 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:07:51.544164 11353 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0830 13:07:51.544235 11353 solver.cpp:404]     Test net output #1: loss = 1.12233 (* 1 = 1.12233 loss)
I0830 13:07:51.559525 11353 solver.cpp:228] Iteration 14000, loss = 1.10007
I0830 13:07:51.559587 11353 solver.cpp:244]     Train net output #0: loss = 1.10007 (* 1 = 1.10007 loss)
I0830 13:07:51.559605 11353 sgd_solver.cpp:106] Iteration 14000, lr = 0.0671681
I0830 13:07:55.861066 11353 solver.cpp:228] Iteration 14100, loss = 1.10286
I0830 13:07:55.861105 11353 solver.cpp:244]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0830 13:07:55.861110 11353 sgd_solver.cpp:106] Iteration 14100, lr = 0.0670204
I0830 13:08:00.166715 11353 solver.cpp:228] Iteration 14200, loss = 1.10486
I0830 13:08:00.166767 11353 solver.cpp:244]     Train net output #0: loss = 1.10486 (* 1 = 1.10486 loss)
I0830 13:08:00.166774 11353 sgd_solver.cpp:106] Iteration 14200, lr = 0.0668733
I0830 13:08:04.467103 11353 solver.cpp:228] Iteration 14300, loss = 1.09982
I0830 13:08:04.467123 11353 solver.cpp:244]     Train net output #0: loss = 1.09982 (* 1 = 1.09982 loss)
I0830 13:08:04.467128 11353 sgd_solver.cpp:106] Iteration 14300, lr = 0.066727
I0830 13:08:08.762887 11353 solver.cpp:228] Iteration 14400, loss = 1.10023
I0830 13:08:08.762905 11353 solver.cpp:244]     Train net output #0: loss = 1.10023 (* 1 = 1.10023 loss)
I0830 13:08:08.762912 11353 sgd_solver.cpp:106] Iteration 14400, lr = 0.0665815
I0830 13:08:13.027240 11353 solver.cpp:337] Iteration 14500, Testing net (#0)
I0830 13:08:16.538143 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0830 13:08:16.538188 11353 solver.cpp:404]     Test net output #1: loss = 1.11593 (* 1 = 1.11593 loss)
I0830 13:08:16.554678 11353 solver.cpp:228] Iteration 14500, loss = 1.10087
I0830 13:08:16.554738 11353 solver.cpp:244]     Train net output #0: loss = 1.10087 (* 1 = 1.10087 loss)
I0830 13:08:16.554754 11353 sgd_solver.cpp:106] Iteration 14500, lr = 0.0664367
I0830 13:08:20.858211 11353 solver.cpp:228] Iteration 14600, loss = 1.10122
I0830 13:08:20.858256 11353 solver.cpp:244]     Train net output #0: loss = 1.10122 (* 1 = 1.10122 loss)
I0830 13:08:20.858261 11353 sgd_solver.cpp:106] Iteration 14600, lr = 0.0662927
I0830 13:08:25.167073 11353 solver.cpp:228] Iteration 14700, loss = 1.09614
I0830 13:08:25.167116 11353 solver.cpp:244]     Train net output #0: loss = 1.09614 (* 1 = 1.09614 loss)
I0830 13:08:25.167121 11353 sgd_solver.cpp:106] Iteration 14700, lr = 0.0661493
I0830 13:08:29.470170 11353 solver.cpp:228] Iteration 14800, loss = 1.09752
I0830 13:08:29.470190 11353 solver.cpp:244]     Train net output #0: loss = 1.09752 (* 1 = 1.09752 loss)
I0830 13:08:29.470194 11353 sgd_solver.cpp:106] Iteration 14800, lr = 0.0660067
I0830 13:08:33.773054 11353 solver.cpp:228] Iteration 14900, loss = 1.09055
I0830 13:08:33.773098 11353 solver.cpp:244]     Train net output #0: loss = 1.09055 (* 1 = 1.09055 loss)
I0830 13:08:33.773104 11353 sgd_solver.cpp:106] Iteration 14900, lr = 0.0658648
I0830 13:08:38.026726 11353 solver.cpp:337] Iteration 15000, Testing net (#0)
I0830 13:08:41.371129 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0830 13:08:41.371225 11353 solver.cpp:404]     Test net output #1: loss = 1.09535 (* 1 = 1.09535 loss)
I0830 13:08:41.386234 11353 solver.cpp:228] Iteration 15000, loss = 1.10191
I0830 13:08:41.386286 11353 solver.cpp:244]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0830 13:08:41.386298 11353 sgd_solver.cpp:106] Iteration 15000, lr = 0.0657236
I0830 13:08:45.686468 11353 solver.cpp:228] Iteration 15100, loss = 1.10544
I0830 13:08:45.686511 11353 solver.cpp:244]     Train net output #0: loss = 1.10544 (* 1 = 1.10544 loss)
I0830 13:08:45.686517 11353 sgd_solver.cpp:106] Iteration 15100, lr = 0.0655831
I0830 13:08:49.980635 11353 solver.cpp:228] Iteration 15200, loss = 1.09582
I0830 13:08:49.980656 11353 solver.cpp:244]     Train net output #0: loss = 1.09582 (* 1 = 1.09582 loss)
I0830 13:08:49.980661 11353 sgd_solver.cpp:106] Iteration 15200, lr = 0.0654433
I0830 13:08:54.293514 11353 solver.cpp:228] Iteration 15300, loss = 1.10136
I0830 13:08:54.293565 11353 solver.cpp:244]     Train net output #0: loss = 1.10136 (* 1 = 1.10136 loss)
I0830 13:08:54.293570 11353 sgd_solver.cpp:106] Iteration 15300, lr = 0.0653043
I0830 13:08:58.602951 11353 solver.cpp:228] Iteration 15400, loss = 1.09712
I0830 13:08:58.603021 11353 solver.cpp:244]     Train net output #0: loss = 1.09712 (* 1 = 1.09712 loss)
I0830 13:08:58.603027 11353 sgd_solver.cpp:106] Iteration 15400, lr = 0.0651658
I0830 13:09:02.853582 11353 solver.cpp:337] Iteration 15500, Testing net (#0)
I0830 13:09:06.372364 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0830 13:09:06.372429 11353 solver.cpp:404]     Test net output #1: loss = 1.07968 (* 1 = 1.07968 loss)
I0830 13:09:06.387971 11353 solver.cpp:228] Iteration 15500, loss = 1.10361
I0830 13:09:06.388034 11353 solver.cpp:244]     Train net output #0: loss = 1.10361 (* 1 = 1.10361 loss)
I0830 13:09:06.388052 11353 sgd_solver.cpp:106] Iteration 15500, lr = 0.0650281
I0830 13:09:10.688971 11353 solver.cpp:228] Iteration 15600, loss = 1.10475
I0830 13:09:10.689026 11353 solver.cpp:244]     Train net output #0: loss = 1.10475 (* 1 = 1.10475 loss)
I0830 13:09:10.689034 11353 sgd_solver.cpp:106] Iteration 15600, lr = 0.0648911
I0830 13:09:15.001305 11353 solver.cpp:228] Iteration 15700, loss = 1.09347
I0830 13:09:15.001345 11353 solver.cpp:244]     Train net output #0: loss = 1.09347 (* 1 = 1.09347 loss)
I0830 13:09:15.001351 11353 sgd_solver.cpp:106] Iteration 15700, lr = 0.0647547
I0830 13:09:19.323340 11353 solver.cpp:228] Iteration 15800, loss = 1.0967
I0830 13:09:19.323412 11353 solver.cpp:244]     Train net output #0: loss = 1.0967 (* 1 = 1.0967 loss)
I0830 13:09:19.323420 11353 sgd_solver.cpp:106] Iteration 15800, lr = 0.064619
I0830 13:09:23.635473 11353 solver.cpp:228] Iteration 15900, loss = 1.10405
I0830 13:09:23.635516 11353 solver.cpp:244]     Train net output #0: loss = 1.10405 (* 1 = 1.10405 loss)
I0830 13:09:23.635522 11353 sgd_solver.cpp:106] Iteration 15900, lr = 0.064484
I0830 13:09:27.910238 11353 solver.cpp:337] Iteration 16000, Testing net (#0)
I0830 13:09:29.238840 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:09:31.446794 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0830 13:09:31.446864 11353 solver.cpp:404]     Test net output #1: loss = 1.08516 (* 1 = 1.08516 loss)
I0830 13:09:31.463161 11353 solver.cpp:228] Iteration 16000, loss = 1.09718
I0830 13:09:31.463237 11353 solver.cpp:244]     Train net output #0: loss = 1.09718 (* 1 = 1.09718 loss)
I0830 13:09:31.463249 11353 sgd_solver.cpp:106] Iteration 16000, lr = 0.0643496
I0830 13:09:35.758221 11353 solver.cpp:228] Iteration 16100, loss = 1.09562
I0830 13:09:35.758261 11353 solver.cpp:244]     Train net output #0: loss = 1.09562 (* 1 = 1.09562 loss)
I0830 13:09:35.758267 11353 sgd_solver.cpp:106] Iteration 16100, lr = 0.0642158
I0830 13:09:40.063367 11353 solver.cpp:228] Iteration 16200, loss = 1.09951
I0830 13:09:40.063429 11353 solver.cpp:244]     Train net output #0: loss = 1.09951 (* 1 = 1.09951 loss)
I0830 13:09:40.063437 11353 sgd_solver.cpp:106] Iteration 16200, lr = 0.0640827
I0830 13:09:44.369129 11353 solver.cpp:228] Iteration 16300, loss = 1.0902
I0830 13:09:44.369168 11353 solver.cpp:244]     Train net output #0: loss = 1.0902 (* 1 = 1.0902 loss)
I0830 13:09:44.369174 11353 sgd_solver.cpp:106] Iteration 16300, lr = 0.0639503
I0830 13:09:48.688566 11353 solver.cpp:228] Iteration 16400, loss = 1.09644
I0830 13:09:48.688621 11353 solver.cpp:244]     Train net output #0: loss = 1.09644 (* 1 = 1.09644 loss)
I0830 13:09:48.688629 11353 sgd_solver.cpp:106] Iteration 16400, lr = 0.0638185
I0830 13:09:52.943763 11353 solver.cpp:337] Iteration 16500, Testing net (#0)
I0830 13:09:56.468987 11353 solver.cpp:404]     Test net output #0: accuracy = 0.268917
I0830 13:09:56.469061 11353 solver.cpp:404]     Test net output #1: loss = 1.08695 (* 1 = 1.08695 loss)
I0830 13:09:56.483675 11353 solver.cpp:228] Iteration 16500, loss = 1.09571
I0830 13:09:56.483707 11353 solver.cpp:244]     Train net output #0: loss = 1.09571 (* 1 = 1.09571 loss)
I0830 13:09:56.483718 11353 sgd_solver.cpp:106] Iteration 16500, lr = 0.0636873
I0830 13:10:00.779338 11353 solver.cpp:228] Iteration 16600, loss = 1.09884
I0830 13:10:00.779381 11353 solver.cpp:244]     Train net output #0: loss = 1.09884 (* 1 = 1.09884 loss)
I0830 13:10:00.779386 11353 sgd_solver.cpp:106] Iteration 16600, lr = 0.0635568
I0830 13:10:05.078555 11353 solver.cpp:228] Iteration 16700, loss = 1.09694
I0830 13:10:05.078615 11353 solver.cpp:244]     Train net output #0: loss = 1.09694 (* 1 = 1.09694 loss)
I0830 13:10:05.078622 11353 sgd_solver.cpp:106] Iteration 16700, lr = 0.0634268
I0830 13:10:09.369782 11353 solver.cpp:228] Iteration 16800, loss = 1.09846
I0830 13:10:09.369822 11353 solver.cpp:244]     Train net output #0: loss = 1.09846 (* 1 = 1.09846 loss)
I0830 13:10:09.369827 11353 sgd_solver.cpp:106] Iteration 16800, lr = 0.0632975
I0830 13:10:13.685967 11353 solver.cpp:228] Iteration 16900, loss = 1.09623
I0830 13:10:13.686018 11353 solver.cpp:244]     Train net output #0: loss = 1.09623 (* 1 = 1.09623 loss)
I0830 13:10:13.686027 11353 sgd_solver.cpp:106] Iteration 16900, lr = 0.0631688
I0830 13:10:17.940901 11353 solver.cpp:337] Iteration 17000, Testing net (#0)
I0830 13:10:21.160336 11353 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0830 13:10:21.160439 11353 solver.cpp:404]     Test net output #1: loss = 1.0992 (* 1 = 1.0992 loss)
I0830 13:10:21.178859 11353 solver.cpp:228] Iteration 17000, loss = 1.104
I0830 13:10:21.178920 11353 solver.cpp:244]     Train net output #0: loss = 1.104 (* 1 = 1.104 loss)
I0830 13:10:21.178933 11353 sgd_solver.cpp:106] Iteration 17000, lr = 0.0630407
I0830 13:10:25.488947 11353 solver.cpp:228] Iteration 17100, loss = 1.09715
I0830 13:10:25.488994 11353 solver.cpp:244]     Train net output #0: loss = 1.09715 (* 1 = 1.09715 loss)
I0830 13:10:25.488999 11353 sgd_solver.cpp:106] Iteration 17100, lr = 0.0629132
I0830 13:10:29.790069 11353 solver.cpp:228] Iteration 17200, loss = 1.10597
I0830 13:10:29.790114 11353 solver.cpp:244]     Train net output #0: loss = 1.10597 (* 1 = 1.10597 loss)
I0830 13:10:29.790120 11353 sgd_solver.cpp:106] Iteration 17200, lr = 0.0627864
I0830 13:10:34.096019 11353 solver.cpp:228] Iteration 17300, loss = 1.09935
I0830 13:10:34.096062 11353 solver.cpp:244]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0830 13:10:34.096067 11353 sgd_solver.cpp:106] Iteration 17300, lr = 0.0626601
I0830 13:10:38.419127 11353 solver.cpp:228] Iteration 17400, loss = 1.10126
I0830 13:10:38.419190 11353 solver.cpp:244]     Train net output #0: loss = 1.10126 (* 1 = 1.10126 loss)
I0830 13:10:38.419196 11353 sgd_solver.cpp:106] Iteration 17400, lr = 0.0625344
I0830 13:10:42.697165 11353 solver.cpp:337] Iteration 17500, Testing net (#0)
I0830 13:10:46.268018 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269708
I0830 13:10:46.268129 11353 solver.cpp:404]     Test net output #1: loss = 1.09346 (* 1 = 1.09346 loss)
I0830 13:10:46.283632 11353 solver.cpp:228] Iteration 17500, loss = 1.09316
I0830 13:10:46.283673 11353 solver.cpp:244]     Train net output #0: loss = 1.09316 (* 1 = 1.09316 loss)
I0830 13:10:46.283680 11353 sgd_solver.cpp:106] Iteration 17500, lr = 0.0624093
I0830 13:10:50.595285 11353 solver.cpp:228] Iteration 17600, loss = 1.1046
I0830 13:10:50.595335 11353 solver.cpp:244]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0830 13:10:50.595340 11353 sgd_solver.cpp:106] Iteration 17600, lr = 0.0622847
I0830 13:10:54.903705 11353 solver.cpp:228] Iteration 17700, loss = 1.10006
I0830 13:10:54.903728 11353 solver.cpp:244]     Train net output #0: loss = 1.10006 (* 1 = 1.10006 loss)
I0830 13:10:54.903733 11353 sgd_solver.cpp:106] Iteration 17700, lr = 0.0621608
I0830 13:10:59.214468 11353 solver.cpp:228] Iteration 17800, loss = 1.0966
I0830 13:10:59.214512 11353 solver.cpp:244]     Train net output #0: loss = 1.0966 (* 1 = 1.0966 loss)
I0830 13:10:59.214519 11353 sgd_solver.cpp:106] Iteration 17800, lr = 0.0620374
I0830 13:11:00.336107 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:11:03.536005 11353 solver.cpp:228] Iteration 17900, loss = 1.10394
I0830 13:11:03.536064 11353 solver.cpp:244]     Train net output #0: loss = 1.10394 (* 1 = 1.10394 loss)
I0830 13:11:03.536072 11353 sgd_solver.cpp:106] Iteration 17900, lr = 0.0619146
I0830 13:11:07.808188 11353 solver.cpp:337] Iteration 18000, Testing net (#0)
I0830 13:11:11.107638 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269792
I0830 13:11:11.107707 11353 solver.cpp:404]     Test net output #1: loss = 1.09098 (* 1 = 1.09098 loss)
I0830 13:11:11.122390 11353 solver.cpp:228] Iteration 18000, loss = 1.09285
I0830 13:11:11.122429 11353 solver.cpp:244]     Train net output #0: loss = 1.09285 (* 1 = 1.09285 loss)
I0830 13:11:11.122442 11353 sgd_solver.cpp:106] Iteration 18000, lr = 0.0617924
I0830 13:11:15.426157 11353 solver.cpp:228] Iteration 18100, loss = 1.10311
I0830 13:11:15.426204 11353 solver.cpp:244]     Train net output #0: loss = 1.10311 (* 1 = 1.10311 loss)
I0830 13:11:15.426210 11353 sgd_solver.cpp:106] Iteration 18100, lr = 0.0616707
I0830 13:11:19.729393 11353 solver.cpp:228] Iteration 18200, loss = 1.09759
I0830 13:11:19.729413 11353 solver.cpp:244]     Train net output #0: loss = 1.09759 (* 1 = 1.09759 loss)
I0830 13:11:19.729416 11353 sgd_solver.cpp:106] Iteration 18200, lr = 0.0615496
I0830 13:11:24.034240 11353 solver.cpp:228] Iteration 18300, loss = 1.09889
I0830 13:11:24.034307 11353 solver.cpp:244]     Train net output #0: loss = 1.09889 (* 1 = 1.09889 loss)
I0830 13:11:24.034313 11353 sgd_solver.cpp:106] Iteration 18300, lr = 0.061429
I0830 13:11:28.356547 11353 solver.cpp:228] Iteration 18400, loss = 1.1019
I0830 13:11:28.356596 11353 solver.cpp:244]     Train net output #0: loss = 1.1019 (* 1 = 1.1019 loss)
I0830 13:11:28.356601 11353 sgd_solver.cpp:106] Iteration 18400, lr = 0.061309
I0830 13:11:32.626696 11353 solver.cpp:337] Iteration 18500, Testing net (#0)
I0830 13:11:35.883560 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0830 13:11:35.883600 11353 solver.cpp:404]     Test net output #1: loss = 1.09757 (* 1 = 1.09757 loss)
I0830 13:11:35.899305 11353 solver.cpp:228] Iteration 18500, loss = 1.10286
I0830 13:11:35.899344 11353 solver.cpp:244]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0830 13:11:35.899354 11353 sgd_solver.cpp:106] Iteration 18500, lr = 0.0611895
I0830 13:11:40.215427 11353 solver.cpp:228] Iteration 18600, loss = 1.10055
I0830 13:11:40.215495 11353 solver.cpp:244]     Train net output #0: loss = 1.10055 (* 1 = 1.10055 loss)
I0830 13:11:40.215505 11353 sgd_solver.cpp:106] Iteration 18600, lr = 0.0610706
I0830 13:11:44.526602 11353 solver.cpp:228] Iteration 18700, loss = 1.09869
I0830 13:11:44.526669 11353 solver.cpp:244]     Train net output #0: loss = 1.09869 (* 1 = 1.09869 loss)
I0830 13:11:44.526674 11353 sgd_solver.cpp:106] Iteration 18700, lr = 0.0609522
I0830 13:11:48.838887 11353 solver.cpp:228] Iteration 18800, loss = 1.1002
I0830 13:11:48.838943 11353 solver.cpp:244]     Train net output #0: loss = 1.1002 (* 1 = 1.1002 loss)
I0830 13:11:48.838950 11353 sgd_solver.cpp:106] Iteration 18800, lr = 0.0608343
I0830 13:11:53.150924 11353 solver.cpp:228] Iteration 18900, loss = 1.10238
I0830 13:11:53.150988 11353 solver.cpp:244]     Train net output #0: loss = 1.10238 (* 1 = 1.10238 loss)
I0830 13:11:53.150995 11353 sgd_solver.cpp:106] Iteration 18900, lr = 0.060717
I0830 13:11:57.416977 11353 solver.cpp:337] Iteration 19000, Testing net (#0)
I0830 13:12:00.608764 11353 solver.cpp:404]     Test net output #0: accuracy = 0.268917
I0830 13:12:00.608810 11353 solver.cpp:404]     Test net output #1: loss = 1.11303 (* 1 = 1.11303 loss)
I0830 13:12:00.624630 11353 solver.cpp:228] Iteration 19000, loss = 1.0988
I0830 13:12:00.624671 11353 solver.cpp:244]     Train net output #0: loss = 1.0988 (* 1 = 1.0988 loss)
I0830 13:12:00.624680 11353 sgd_solver.cpp:106] Iteration 19000, lr = 0.0606002
I0830 13:12:04.934993 11353 solver.cpp:228] Iteration 19100, loss = 1.10081
I0830 13:12:04.935063 11353 solver.cpp:244]     Train net output #0: loss = 1.10081 (* 1 = 1.10081 loss)
I0830 13:12:04.935070 11353 sgd_solver.cpp:106] Iteration 19100, lr = 0.0604839
I0830 13:12:09.244381 11353 solver.cpp:228] Iteration 19200, loss = 1.09737
I0830 13:12:09.244427 11353 solver.cpp:244]     Train net output #0: loss = 1.09737 (* 1 = 1.09737 loss)
I0830 13:12:09.244433 11353 sgd_solver.cpp:106] Iteration 19200, lr = 0.0603682
I0830 13:12:13.552019 11353 solver.cpp:228] Iteration 19300, loss = 1.09894
I0830 13:12:13.552059 11353 solver.cpp:244]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0830 13:12:13.552065 11353 sgd_solver.cpp:106] Iteration 19300, lr = 0.0602529
I0830 13:12:17.865190 11353 solver.cpp:228] Iteration 19400, loss = 1.10579
I0830 13:12:17.865237 11353 solver.cpp:244]     Train net output #0: loss = 1.10579 (* 1 = 1.10579 loss)
I0830 13:12:17.865243 11353 sgd_solver.cpp:106] Iteration 19400, lr = 0.0601382
I0830 13:12:22.133049 11353 solver.cpp:337] Iteration 19500, Testing net (#0)
I0830 13:12:25.594146 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:12:25.594198 11353 solver.cpp:404]     Test net output #1: loss = 1.12246 (* 1 = 1.12246 loss)
I0830 13:12:25.609007 11353 solver.cpp:228] Iteration 19500, loss = 1.09801
I0830 13:12:25.609035 11353 solver.cpp:244]     Train net output #0: loss = 1.09801 (* 1 = 1.09801 loss)
I0830 13:12:25.609046 11353 sgd_solver.cpp:106] Iteration 19500, lr = 0.060024
I0830 13:12:29.920593 11353 solver.cpp:228] Iteration 19600, loss = 1.10134
I0830 13:12:29.920655 11353 solver.cpp:244]     Train net output #0: loss = 1.10134 (* 1 = 1.10134 loss)
I0830 13:12:29.920661 11353 sgd_solver.cpp:106] Iteration 19600, lr = 0.0599102
I0830 13:12:34.232061 11353 solver.cpp:228] Iteration 19700, loss = 1.09125
I0830 13:12:34.232118 11353 solver.cpp:244]     Train net output #0: loss = 1.09125 (* 1 = 1.09125 loss)
I0830 13:12:34.232125 11353 sgd_solver.cpp:106] Iteration 19700, lr = 0.059797
I0830 13:12:38.541028 11353 solver.cpp:228] Iteration 19800, loss = 1.09793
I0830 13:12:38.541092 11353 solver.cpp:244]     Train net output #0: loss = 1.09793 (* 1 = 1.09793 loss)
I0830 13:12:38.541098 11353 sgd_solver.cpp:106] Iteration 19800, lr = 0.0596843
I0830 13:12:42.857094 11353 solver.cpp:228] Iteration 19900, loss = 1.10794
I0830 13:12:42.857161 11353 solver.cpp:244]     Train net output #0: loss = 1.10794 (* 1 = 1.10794 loss)
I0830 13:12:42.857168 11353 sgd_solver.cpp:106] Iteration 19900, lr = 0.0595721
I0830 13:12:45.703799 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:12:47.124706 11353 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_20000.caffemodel
I0830 13:12:47.707034 11353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_20000.solverstate
I0830 13:12:47.954087 11353 solver.cpp:337] Iteration 20000, Testing net (#0)
I0830 13:12:51.155042 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0830 13:12:51.155112 11353 solver.cpp:404]     Test net output #1: loss = 1.11459 (* 1 = 1.11459 loss)
I0830 13:12:51.169174 11353 solver.cpp:228] Iteration 20000, loss = 1.09473
I0830 13:12:51.169205 11353 solver.cpp:244]     Train net output #0: loss = 1.09473 (* 1 = 1.09473 loss)
I0830 13:12:51.169216 11353 sgd_solver.cpp:106] Iteration 20000, lr = 0.0594604
I0830 13:12:55.486347 11353 solver.cpp:228] Iteration 20100, loss = 1.09621
I0830 13:12:55.486404 11353 solver.cpp:244]     Train net output #0: loss = 1.09621 (* 1 = 1.09621 loss)
I0830 13:12:55.486410 11353 sgd_solver.cpp:106] Iteration 20100, lr = 0.0593491
I0830 13:12:59.797075 11353 solver.cpp:228] Iteration 20200, loss = 1.10005
I0830 13:12:59.797127 11353 solver.cpp:244]     Train net output #0: loss = 1.10005 (* 1 = 1.10005 loss)
I0830 13:12:59.797137 11353 sgd_solver.cpp:106] Iteration 20200, lr = 0.0592384
I0830 13:13:04.110409 11353 solver.cpp:228] Iteration 20300, loss = 1.09979
I0830 13:13:04.110455 11353 solver.cpp:244]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0830 13:13:04.110463 11353 sgd_solver.cpp:106] Iteration 20300, lr = 0.0591281
I0830 13:13:08.418136 11353 solver.cpp:228] Iteration 20400, loss = 1.10453
I0830 13:13:08.418156 11353 solver.cpp:244]     Train net output #0: loss = 1.10453 (* 1 = 1.10453 loss)
I0830 13:13:08.418161 11353 sgd_solver.cpp:106] Iteration 20400, lr = 0.0590183
I0830 13:13:12.703658 11353 solver.cpp:337] Iteration 20500, Testing net (#0)
I0830 13:13:16.275434 11353 solver.cpp:404]     Test net output #0: accuracy = 0.1525
I0830 13:13:16.275485 11353 solver.cpp:404]     Test net output #1: loss = 1.10109 (* 1 = 1.10109 loss)
I0830 13:13:16.290859 11353 solver.cpp:228] Iteration 20500, loss = 1.09792
I0830 13:13:16.290911 11353 solver.cpp:244]     Train net output #0: loss = 1.09792 (* 1 = 1.09792 loss)
I0830 13:13:16.290925 11353 sgd_solver.cpp:106] Iteration 20500, lr = 0.0589089
I0830 13:13:20.599957 11353 solver.cpp:228] Iteration 20600, loss = 1.09695
I0830 13:13:20.599998 11353 solver.cpp:244]     Train net output #0: loss = 1.09695 (* 1 = 1.09695 loss)
I0830 13:13:20.600003 11353 sgd_solver.cpp:106] Iteration 20600, lr = 0.0588001
I0830 13:13:24.910066 11353 solver.cpp:228] Iteration 20700, loss = 1.10252
I0830 13:13:24.910109 11353 solver.cpp:244]     Train net output #0: loss = 1.10252 (* 1 = 1.10252 loss)
I0830 13:13:24.910114 11353 sgd_solver.cpp:106] Iteration 20700, lr = 0.0586917
I0830 13:13:29.226640 11353 solver.cpp:228] Iteration 20800, loss = 1.09572
I0830 13:13:29.226686 11353 solver.cpp:244]     Train net output #0: loss = 1.09572 (* 1 = 1.09572 loss)
I0830 13:13:29.226691 11353 sgd_solver.cpp:106] Iteration 20800, lr = 0.0585838
I0830 13:13:33.541750 11353 solver.cpp:228] Iteration 20900, loss = 1.09851
I0830 13:13:33.541807 11353 solver.cpp:244]     Train net output #0: loss = 1.09851 (* 1 = 1.09851 loss)
I0830 13:13:33.541813 11353 sgd_solver.cpp:106] Iteration 20900, lr = 0.0584763
I0830 13:13:37.804234 11353 solver.cpp:337] Iteration 21000, Testing net (#0)
I0830 13:13:41.350615 11353 solver.cpp:404]     Test net output #0: accuracy = 0.5785
I0830 13:13:41.350661 11353 solver.cpp:404]     Test net output #1: loss = 1.09495 (* 1 = 1.09495 loss)
I0830 13:13:41.364578 11353 solver.cpp:228] Iteration 21000, loss = 1.09807
I0830 13:13:41.364614 11353 solver.cpp:244]     Train net output #0: loss = 1.09807 (* 1 = 1.09807 loss)
I0830 13:13:41.364624 11353 sgd_solver.cpp:106] Iteration 21000, lr = 0.0583693
I0830 13:13:45.668018 11353 solver.cpp:228] Iteration 21100, loss = 1.0957
I0830 13:13:45.668083 11353 solver.cpp:244]     Train net output #0: loss = 1.0957 (* 1 = 1.0957 loss)
I0830 13:13:45.668089 11353 sgd_solver.cpp:106] Iteration 21100, lr = 0.0582628
I0830 13:13:49.987810 11353 solver.cpp:228] Iteration 21200, loss = 1.0961
I0830 13:13:49.987869 11353 solver.cpp:244]     Train net output #0: loss = 1.0961 (* 1 = 1.0961 loss)
I0830 13:13:49.987879 11353 sgd_solver.cpp:106] Iteration 21200, lr = 0.0581567
I0830 13:13:54.296519 11353 solver.cpp:228] Iteration 21300, loss = 1.10026
I0830 13:13:54.296557 11353 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0830 13:13:54.296562 11353 sgd_solver.cpp:106] Iteration 21300, lr = 0.058051
I0830 13:13:58.595329 11353 solver.cpp:228] Iteration 21400, loss = 1.10089
I0830 13:13:58.595373 11353 solver.cpp:244]     Train net output #0: loss = 1.10089 (* 1 = 1.10089 loss)
I0830 13:13:58.595378 11353 sgd_solver.cpp:106] Iteration 21400, lr = 0.0579458
I0830 13:14:02.869102 11353 solver.cpp:337] Iteration 21500, Testing net (#0)
I0830 13:14:06.349617 11353 solver.cpp:404]     Test net output #0: accuracy = 0.57875
I0830 13:14:06.349694 11353 solver.cpp:404]     Test net output #1: loss = 1.08136 (* 1 = 1.08136 loss)
I0830 13:14:06.363978 11353 solver.cpp:228] Iteration 21500, loss = 1.1087
I0830 13:14:06.364020 11353 solver.cpp:244]     Train net output #0: loss = 1.1087 (* 1 = 1.1087 loss)
I0830 13:14:06.364032 11353 sgd_solver.cpp:106] Iteration 21500, lr = 0.0578411
I0830 13:14:10.683024 11353 solver.cpp:228] Iteration 21600, loss = 1.09975
I0830 13:14:10.683087 11353 solver.cpp:244]     Train net output #0: loss = 1.09975 (* 1 = 1.09975 loss)
I0830 13:14:10.683099 11353 sgd_solver.cpp:106] Iteration 21600, lr = 0.0577368
I0830 13:14:14.999766 11353 solver.cpp:228] Iteration 21700, loss = 1.10144
I0830 13:14:14.999819 11353 solver.cpp:244]     Train net output #0: loss = 1.10144 (* 1 = 1.10144 loss)
I0830 13:14:14.999830 11353 sgd_solver.cpp:106] Iteration 21700, lr = 0.0576329
I0830 13:14:19.309204 11353 solver.cpp:228] Iteration 21800, loss = 1.08833
I0830 13:14:19.309262 11353 solver.cpp:244]     Train net output #0: loss = 1.08833 (* 1 = 1.08833 loss)
I0830 13:14:19.309268 11353 sgd_solver.cpp:106] Iteration 21800, lr = 0.0575295
I0830 13:14:23.616081 11353 solver.cpp:228] Iteration 21900, loss = 1.09681
I0830 13:14:23.616127 11353 solver.cpp:244]     Train net output #0: loss = 1.09681 (* 1 = 1.09681 loss)
I0830 13:14:23.616132 11353 sgd_solver.cpp:106] Iteration 21900, lr = 0.0574265
I0830 13:14:27.883469 11353 solver.cpp:337] Iteration 22000, Testing net (#0)
I0830 13:14:28.421392 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:14:31.169159 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578542
I0830 13:14:31.169219 11353 solver.cpp:404]     Test net output #1: loss = 1.08062 (* 1 = 1.08062 loss)
I0830 13:14:31.184101 11353 solver.cpp:228] Iteration 22000, loss = 1.10295
I0830 13:14:31.184154 11353 solver.cpp:244]     Train net output #0: loss = 1.10295 (* 1 = 1.10295 loss)
I0830 13:14:31.184167 11353 sgd_solver.cpp:106] Iteration 22000, lr = 0.0573239
I0830 13:14:35.493068 11353 solver.cpp:228] Iteration 22100, loss = 1.1004
I0830 13:14:35.493129 11353 solver.cpp:244]     Train net output #0: loss = 1.1004 (* 1 = 1.1004 loss)
I0830 13:14:35.493136 11353 sgd_solver.cpp:106] Iteration 22100, lr = 0.0572217
I0830 13:14:39.802666 11353 solver.cpp:228] Iteration 22200, loss = 1.10443
I0830 13:14:39.802719 11353 solver.cpp:244]     Train net output #0: loss = 1.10443 (* 1 = 1.10443 loss)
I0830 13:14:39.802729 11353 sgd_solver.cpp:106] Iteration 22200, lr = 0.05712
I0830 13:14:44.110409 11353 solver.cpp:228] Iteration 22300, loss = 1.09482
I0830 13:14:44.110460 11353 solver.cpp:244]     Train net output #0: loss = 1.09482 (* 1 = 1.09482 loss)
I0830 13:14:44.110468 11353 sgd_solver.cpp:106] Iteration 22300, lr = 0.0570187
I0830 13:14:48.453862 11353 solver.cpp:228] Iteration 22400, loss = 1.10232
I0830 13:14:48.453917 11353 solver.cpp:244]     Train net output #0: loss = 1.10232 (* 1 = 1.10232 loss)
I0830 13:14:48.453924 11353 sgd_solver.cpp:106] Iteration 22400, lr = 0.0569178
I0830 13:14:52.735288 11353 solver.cpp:337] Iteration 22500, Testing net (#0)
I0830 13:14:56.320479 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0830 13:14:56.320530 11353 solver.cpp:404]     Test net output #1: loss = 1.09995 (* 1 = 1.09995 loss)
I0830 13:14:56.334524 11353 solver.cpp:228] Iteration 22500, loss = 1.09881
I0830 13:14:56.334583 11353 solver.cpp:244]     Train net output #0: loss = 1.09881 (* 1 = 1.09881 loss)
I0830 13:14:56.334596 11353 sgd_solver.cpp:106] Iteration 22500, lr = 0.0568173
I0830 13:15:00.651692 11353 solver.cpp:228] Iteration 22600, loss = 1.09988
I0830 13:15:00.651756 11353 solver.cpp:244]     Train net output #0: loss = 1.09988 (* 1 = 1.09988 loss)
I0830 13:15:00.651768 11353 sgd_solver.cpp:106] Iteration 22600, lr = 0.0567173
I0830 13:15:04.961738 11353 solver.cpp:228] Iteration 22700, loss = 1.10221
I0830 13:15:04.961791 11353 solver.cpp:244]     Train net output #0: loss = 1.10221 (* 1 = 1.10221 loss)
I0830 13:15:04.961796 11353 sgd_solver.cpp:106] Iteration 22700, lr = 0.0566176
I0830 13:15:09.280040 11353 solver.cpp:228] Iteration 22800, loss = 1.10302
I0830 13:15:09.280098 11353 solver.cpp:244]     Train net output #0: loss = 1.10302 (* 1 = 1.10302 loss)
I0830 13:15:09.280105 11353 sgd_solver.cpp:106] Iteration 22800, lr = 0.0565184
I0830 13:15:13.602695 11353 solver.cpp:228] Iteration 22900, loss = 1.10013
I0830 13:15:13.602751 11353 solver.cpp:244]     Train net output #0: loss = 1.10013 (* 1 = 1.10013 loss)
I0830 13:15:13.602758 11353 sgd_solver.cpp:106] Iteration 22900, lr = 0.0564195
I0830 13:15:17.871520 11353 solver.cpp:337] Iteration 23000, Testing net (#0)
I0830 13:15:21.334192 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0830 13:15:21.334262 11353 solver.cpp:404]     Test net output #1: loss = 1.11454 (* 1 = 1.11454 loss)
I0830 13:15:21.348465 11353 solver.cpp:228] Iteration 23000, loss = 1.09829
I0830 13:15:21.348533 11353 solver.cpp:244]     Train net output #0: loss = 1.09829 (* 1 = 1.09829 loss)
I0830 13:15:21.348543 11353 sgd_solver.cpp:106] Iteration 23000, lr = 0.0563211
I0830 13:15:25.665762 11353 solver.cpp:228] Iteration 23100, loss = 1.10072
I0830 13:15:25.665818 11353 solver.cpp:244]     Train net output #0: loss = 1.10072 (* 1 = 1.10072 loss)
I0830 13:15:25.665827 11353 sgd_solver.cpp:106] Iteration 23100, lr = 0.0562231
I0830 13:15:29.979589 11353 solver.cpp:228] Iteration 23200, loss = 1.10151
I0830 13:15:29.979660 11353 solver.cpp:244]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0830 13:15:29.979672 11353 sgd_solver.cpp:106] Iteration 23200, lr = 0.0561254
I0830 13:15:34.301931 11353 solver.cpp:228] Iteration 23300, loss = 1.09979
I0830 13:15:34.301970 11353 solver.cpp:244]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0830 13:15:34.301976 11353 sgd_solver.cpp:106] Iteration 23300, lr = 0.0560282
I0830 13:15:38.617445 11353 solver.cpp:228] Iteration 23400, loss = 1.10101
I0830 13:15:38.617466 11353 solver.cpp:244]     Train net output #0: loss = 1.10101 (* 1 = 1.10101 loss)
I0830 13:15:38.617470 11353 sgd_solver.cpp:106] Iteration 23400, lr = 0.0559313
I0830 13:15:42.891443 11353 solver.cpp:337] Iteration 23500, Testing net (#0)
I0830 13:15:46.027798 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0830 13:15:46.027904 11353 solver.cpp:404]     Test net output #1: loss = 1.11822 (* 1 = 1.11822 loss)
I0830 13:15:46.042640 11353 solver.cpp:228] Iteration 23500, loss = 1.10423
I0830 13:15:46.042681 11353 solver.cpp:244]     Train net output #0: loss = 1.10423 (* 1 = 1.10423 loss)
I0830 13:15:46.042690 11353 sgd_solver.cpp:106] Iteration 23500, lr = 0.0558349
I0830 13:15:50.357343 11353 solver.cpp:228] Iteration 23600, loss = 1.09942
I0830 13:15:50.357414 11353 solver.cpp:244]     Train net output #0: loss = 1.09942 (* 1 = 1.09942 loss)
I0830 13:15:50.357420 11353 sgd_solver.cpp:106] Iteration 23600, lr = 0.0557388
I0830 13:15:54.678561 11353 solver.cpp:228] Iteration 23700, loss = 1.09842
I0830 13:15:54.678607 11353 solver.cpp:244]     Train net output #0: loss = 1.09842 (* 1 = 1.09842 loss)
I0830 13:15:54.678613 11353 sgd_solver.cpp:106] Iteration 23700, lr = 0.0556431
I0830 13:15:58.987464 11353 solver.cpp:228] Iteration 23800, loss = 1.1026
I0830 13:15:58.987486 11353 solver.cpp:244]     Train net output #0: loss = 1.1026 (* 1 = 1.1026 loss)
I0830 13:15:58.987491 11353 sgd_solver.cpp:106] Iteration 23800, lr = 0.0555478
I0830 13:16:03.306972 11353 solver.cpp:228] Iteration 23900, loss = 1.0984
I0830 13:16:03.307041 11353 solver.cpp:244]     Train net output #0: loss = 1.0984 (* 1 = 1.0984 loss)
I0830 13:16:03.307047 11353 sgd_solver.cpp:106] Iteration 23900, lr = 0.0554529
I0830 13:16:07.575177 11353 solver.cpp:337] Iteration 24000, Testing net (#0)
I0830 13:16:10.855837 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0830 13:16:10.855890 11353 solver.cpp:404]     Test net output #1: loss = 1.11185 (* 1 = 1.11185 loss)
I0830 13:16:10.872463 11353 solver.cpp:228] Iteration 24000, loss = 1.09628
I0830 13:16:10.872521 11353 solver.cpp:244]     Train net output #0: loss = 1.09628 (* 1 = 1.09628 loss)
I0830 13:16:10.872536 11353 sgd_solver.cpp:106] Iteration 24000, lr = 0.0553583
I0830 13:16:15.189924 11353 solver.cpp:228] Iteration 24100, loss = 1.10253
I0830 13:16:15.189971 11353 solver.cpp:244]     Train net output #0: loss = 1.10253 (* 1 = 1.10253 loss)
I0830 13:16:15.189977 11353 sgd_solver.cpp:106] Iteration 24100, lr = 0.0552642
I0830 13:16:19.506407 11353 solver.cpp:228] Iteration 24200, loss = 1.1094
I0830 13:16:19.506475 11353 solver.cpp:244]     Train net output #0: loss = 1.1094 (* 1 = 1.1094 loss)
I0830 13:16:19.506481 11353 sgd_solver.cpp:106] Iteration 24200, lr = 0.0551704
I0830 13:16:23.826834 11353 solver.cpp:228] Iteration 24300, loss = 1.09756
I0830 13:16:23.826877 11353 solver.cpp:244]     Train net output #0: loss = 1.09756 (* 1 = 1.09756 loss)
I0830 13:16:23.826882 11353 sgd_solver.cpp:106] Iteration 24300, lr = 0.0550769
I0830 13:16:28.137573 11353 solver.cpp:228] Iteration 24400, loss = 1.09627
I0830 13:16:28.137595 11353 solver.cpp:244]     Train net output #0: loss = 1.09627 (* 1 = 1.09627 loss)
I0830 13:16:28.137600 11353 sgd_solver.cpp:106] Iteration 24400, lr = 0.0549839
I0830 13:16:32.412137 11353 solver.cpp:337] Iteration 24500, Testing net (#0)
I0830 13:16:32.517969 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:16:35.590884 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0830 13:16:35.590955 11353 solver.cpp:404]     Test net output #1: loss = 1.10379 (* 1 = 1.10379 loss)
I0830 13:16:35.605839 11353 solver.cpp:228] Iteration 24500, loss = 1.10396
I0830 13:16:35.605885 11353 solver.cpp:244]     Train net output #0: loss = 1.10396 (* 1 = 1.10396 loss)
I0830 13:16:35.605895 11353 sgd_solver.cpp:106] Iteration 24500, lr = 0.0548912
I0830 13:16:39.921167 11353 solver.cpp:228] Iteration 24600, loss = 1.10078
I0830 13:16:39.921208 11353 solver.cpp:244]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0830 13:16:39.921213 11353 sgd_solver.cpp:106] Iteration 24600, lr = 0.0547988
I0830 13:16:44.237342 11353 solver.cpp:228] Iteration 24700, loss = 1.1087
I0830 13:16:44.237382 11353 solver.cpp:244]     Train net output #0: loss = 1.1087 (* 1 = 1.1087 loss)
I0830 13:16:44.237387 11353 sgd_solver.cpp:106] Iteration 24700, lr = 0.0547069
I0830 13:16:48.551913 11353 solver.cpp:228] Iteration 24800, loss = 1.09758
I0830 13:16:48.551946 11353 solver.cpp:244]     Train net output #0: loss = 1.09758 (* 1 = 1.09758 loss)
I0830 13:16:48.551952 11353 sgd_solver.cpp:106] Iteration 24800, lr = 0.0546153
I0830 13:16:52.866283 11353 solver.cpp:228] Iteration 24900, loss = 1.10119
I0830 13:16:52.866325 11353 solver.cpp:244]     Train net output #0: loss = 1.10119 (* 1 = 1.10119 loss)
I0830 13:16:52.866331 11353 sgd_solver.cpp:106] Iteration 24900, lr = 0.054524
I0830 13:16:57.133855 11353 solver.cpp:337] Iteration 25000, Testing net (#0)
I0830 13:17:00.531625 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0830 13:17:00.531705 11353 solver.cpp:404]     Test net output #1: loss = 1.10004 (* 1 = 1.10004 loss)
I0830 13:17:00.546268 11353 solver.cpp:228] Iteration 25000, loss = 1.10461
I0830 13:17:00.546305 11353 solver.cpp:244]     Train net output #0: loss = 1.10461 (* 1 = 1.10461 loss)
I0830 13:17:00.546317 11353 sgd_solver.cpp:106] Iteration 25000, lr = 0.0544331
I0830 13:17:04.869320 11353 solver.cpp:228] Iteration 25100, loss = 1.09508
I0830 13:17:04.869365 11353 solver.cpp:244]     Train net output #0: loss = 1.09508 (* 1 = 1.09508 loss)
I0830 13:17:04.869371 11353 sgd_solver.cpp:106] Iteration 25100, lr = 0.0543426
I0830 13:17:09.181398 11353 solver.cpp:228] Iteration 25200, loss = 1.09863
I0830 13:17:09.181442 11353 solver.cpp:244]     Train net output #0: loss = 1.09863 (* 1 = 1.09863 loss)
I0830 13:17:09.181447 11353 sgd_solver.cpp:106] Iteration 25200, lr = 0.0542524
I0830 13:17:13.491082 11353 solver.cpp:228] Iteration 25300, loss = 1.10033
I0830 13:17:13.491127 11353 solver.cpp:244]     Train net output #0: loss = 1.10033 (* 1 = 1.10033 loss)
I0830 13:17:13.491133 11353 sgd_solver.cpp:106] Iteration 25300, lr = 0.0541625
I0830 13:17:17.813127 11353 solver.cpp:228] Iteration 25400, loss = 1.10363
I0830 13:17:17.813194 11353 solver.cpp:244]     Train net output #0: loss = 1.10363 (* 1 = 1.10363 loss)
I0830 13:17:17.813199 11353 sgd_solver.cpp:106] Iteration 25400, lr = 0.054073
I0830 13:17:22.089715 11353 solver.cpp:337] Iteration 25500, Testing net (#0)
I0830 13:17:25.296632 11353 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0830 13:17:25.296675 11353 solver.cpp:404]     Test net output #1: loss = 1.10512 (* 1 = 1.10512 loss)
I0830 13:17:25.311295 11353 solver.cpp:228] Iteration 25500, loss = 1.1018
I0830 13:17:25.311329 11353 solver.cpp:244]     Train net output #0: loss = 1.1018 (* 1 = 1.1018 loss)
I0830 13:17:25.311339 11353 sgd_solver.cpp:106] Iteration 25500, lr = 0.0539839
I0830 13:17:29.618161 11353 solver.cpp:228] Iteration 25600, loss = 1.10969
I0830 13:17:29.618224 11353 solver.cpp:244]     Train net output #0: loss = 1.10969 (* 1 = 1.10969 loss)
I0830 13:17:29.618230 11353 sgd_solver.cpp:106] Iteration 25600, lr = 0.053895
I0830 13:17:33.932102 11353 solver.cpp:228] Iteration 25700, loss = 1.10224
I0830 13:17:33.932166 11353 solver.cpp:244]     Train net output #0: loss = 1.10224 (* 1 = 1.10224 loss)
I0830 13:17:33.932173 11353 sgd_solver.cpp:106] Iteration 25700, lr = 0.0538066
I0830 13:17:38.245235 11353 solver.cpp:228] Iteration 25800, loss = 1.10814
I0830 13:17:38.245301 11353 solver.cpp:244]     Train net output #0: loss = 1.10814 (* 1 = 1.10814 loss)
I0830 13:17:38.245306 11353 sgd_solver.cpp:106] Iteration 25800, lr = 0.0537184
I0830 13:17:42.569203 11353 solver.cpp:228] Iteration 25900, loss = 1.099
I0830 13:17:42.569247 11353 solver.cpp:244]     Train net output #0: loss = 1.099 (* 1 = 1.099 loss)
I0830 13:17:42.569253 11353 sgd_solver.cpp:106] Iteration 25900, lr = 0.0536306
I0830 13:17:46.839861 11353 solver.cpp:337] Iteration 26000, Testing net (#0)
I0830 13:17:50.335014 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0830 13:17:50.335078 11353 solver.cpp:404]     Test net output #1: loss = 1.11685 (* 1 = 1.11685 loss)
I0830 13:17:50.350399 11353 solver.cpp:228] Iteration 26000, loss = 1.09954
I0830 13:17:50.350460 11353 solver.cpp:244]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0830 13:17:50.350481 11353 sgd_solver.cpp:106] Iteration 26000, lr = 0.0535432
I0830 13:17:54.674280 11353 solver.cpp:228] Iteration 26100, loss = 1.094
I0830 13:17:54.674330 11353 solver.cpp:244]     Train net output #0: loss = 1.094 (* 1 = 1.094 loss)
I0830 13:17:54.674336 11353 sgd_solver.cpp:106] Iteration 26100, lr = 0.053456
I0830 13:17:58.987927 11353 solver.cpp:228] Iteration 26200, loss = 1.09039
I0830 13:17:58.987968 11353 solver.cpp:244]     Train net output #0: loss = 1.09039 (* 1 = 1.09039 loss)
I0830 13:17:58.987973 11353 sgd_solver.cpp:106] Iteration 26200, lr = 0.0533692
I0830 13:18:03.302598 11353 solver.cpp:228] Iteration 26300, loss = 1.10204
I0830 13:18:03.302655 11353 solver.cpp:244]     Train net output #0: loss = 1.10204 (* 1 = 1.10204 loss)
I0830 13:18:03.302665 11353 sgd_solver.cpp:106] Iteration 26300, lr = 0.0532828
I0830 13:18:07.612663 11353 solver.cpp:228] Iteration 26400, loss = 1.09934
I0830 13:18:07.612720 11353 solver.cpp:244]     Train net output #0: loss = 1.09934 (* 1 = 1.09934 loss)
I0830 13:18:07.612726 11353 sgd_solver.cpp:106] Iteration 26400, lr = 0.0531966
I0830 13:18:11.879537 11353 solver.cpp:337] Iteration 26500, Testing net (#0)
I0830 13:18:14.785349 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:18:15.432700 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0830 13:18:15.432762 11353 solver.cpp:404]     Test net output #1: loss = 1.11786 (* 1 = 1.11786 loss)
I0830 13:18:15.447844 11353 solver.cpp:228] Iteration 26500, loss = 1.11062
I0830 13:18:15.447890 11353 solver.cpp:244]     Train net output #0: loss = 1.11062 (* 1 = 1.11062 loss)
I0830 13:18:15.447901 11353 sgd_solver.cpp:106] Iteration 26500, lr = 0.0531108
I0830 13:18:19.766299 11353 solver.cpp:228] Iteration 26600, loss = 1.10195
I0830 13:18:19.766350 11353 solver.cpp:244]     Train net output #0: loss = 1.10195 (* 1 = 1.10195 loss)
I0830 13:18:19.766360 11353 sgd_solver.cpp:106] Iteration 26600, lr = 0.0530253
I0830 13:18:24.084599 11353 solver.cpp:228] Iteration 26700, loss = 1.10288
I0830 13:18:24.084673 11353 solver.cpp:244]     Train net output #0: loss = 1.10288 (* 1 = 1.10288 loss)
I0830 13:18:24.084679 11353 sgd_solver.cpp:106] Iteration 26700, lr = 0.0529401
I0830 13:18:28.400133 11353 solver.cpp:228] Iteration 26800, loss = 1.10101
I0830 13:18:28.400192 11353 solver.cpp:244]     Train net output #0: loss = 1.10101 (* 1 = 1.10101 loss)
I0830 13:18:28.400203 11353 sgd_solver.cpp:106] Iteration 26800, lr = 0.0528552
I0830 13:18:32.718075 11353 solver.cpp:228] Iteration 26900, loss = 1.0988
I0830 13:18:32.718116 11353 solver.cpp:244]     Train net output #0: loss = 1.0988 (* 1 = 1.0988 loss)
I0830 13:18:32.718122 11353 sgd_solver.cpp:106] Iteration 26900, lr = 0.0527707
I0830 13:18:36.986902 11353 solver.cpp:337] Iteration 27000, Testing net (#0)
I0830 13:18:40.362085 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0830 13:18:40.362174 11353 solver.cpp:404]     Test net output #1: loss = 1.12042 (* 1 = 1.12042 loss)
I0830 13:18:40.377874 11353 solver.cpp:228] Iteration 27000, loss = 1.10124
I0830 13:18:40.377939 11353 solver.cpp:244]     Train net output #0: loss = 1.10124 (* 1 = 1.10124 loss)
I0830 13:18:40.377959 11353 sgd_solver.cpp:106] Iteration 27000, lr = 0.0526865
I0830 13:18:44.689924 11353 solver.cpp:228] Iteration 27100, loss = 1.10406
I0830 13:18:44.689965 11353 solver.cpp:244]     Train net output #0: loss = 1.10406 (* 1 = 1.10406 loss)
I0830 13:18:44.689970 11353 sgd_solver.cpp:106] Iteration 27100, lr = 0.0526026
I0830 13:18:48.997969 11353 solver.cpp:228] Iteration 27200, loss = 1.09749
I0830 13:18:48.997989 11353 solver.cpp:244]     Train net output #0: loss = 1.09749 (* 1 = 1.09749 loss)
I0830 13:18:48.997994 11353 sgd_solver.cpp:106] Iteration 27200, lr = 0.0525189
I0830 13:18:53.305610 11353 solver.cpp:228] Iteration 27300, loss = 1.09792
I0830 13:18:53.305629 11353 solver.cpp:244]     Train net output #0: loss = 1.09792 (* 1 = 1.09792 loss)
I0830 13:18:53.305634 11353 sgd_solver.cpp:106] Iteration 27300, lr = 0.0524356
I0830 13:18:57.612236 11353 solver.cpp:228] Iteration 27400, loss = 1.10096
I0830 13:18:57.612257 11353 solver.cpp:244]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0830 13:18:57.612262 11353 sgd_solver.cpp:106] Iteration 27400, lr = 0.0523527
I0830 13:19:01.886997 11353 solver.cpp:337] Iteration 27500, Testing net (#0)
I0830 13:19:05.113922 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0830 13:19:05.113993 11353 solver.cpp:404]     Test net output #1: loss = 1.09619 (* 1 = 1.09619 loss)
I0830 13:19:05.128837 11353 solver.cpp:228] Iteration 27500, loss = 1.09895
I0830 13:19:05.128895 11353 solver.cpp:244]     Train net output #0: loss = 1.09895 (* 1 = 1.09895 loss)
I0830 13:19:05.128914 11353 sgd_solver.cpp:106] Iteration 27500, lr = 0.05227
I0830 13:19:09.437361 11353 solver.cpp:228] Iteration 27600, loss = 1.09804
I0830 13:19:09.437413 11353 solver.cpp:244]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0830 13:19:09.437418 11353 sgd_solver.cpp:106] Iteration 27600, lr = 0.0521876
I0830 13:19:13.751476 11353 solver.cpp:228] Iteration 27700, loss = 1.0933
I0830 13:19:13.751526 11353 solver.cpp:244]     Train net output #0: loss = 1.0933 (* 1 = 1.0933 loss)
I0830 13:19:13.751533 11353 sgd_solver.cpp:106] Iteration 27700, lr = 0.0521055
I0830 13:19:18.070166 11353 solver.cpp:228] Iteration 27800, loss = 1.10189
I0830 13:19:18.070217 11353 solver.cpp:244]     Train net output #0: loss = 1.10189 (* 1 = 1.10189 loss)
I0830 13:19:18.070227 11353 sgd_solver.cpp:106] Iteration 27800, lr = 0.0520237
I0830 13:19:22.383577 11353 solver.cpp:228] Iteration 27900, loss = 1.09903
I0830 13:19:22.383620 11353 solver.cpp:244]     Train net output #0: loss = 1.09903 (* 1 = 1.09903 loss)
I0830 13:19:22.383625 11353 sgd_solver.cpp:106] Iteration 27900, lr = 0.0519423
I0830 13:19:26.658176 11353 solver.cpp:337] Iteration 28000, Testing net (#0)
I0830 13:19:29.831635 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0830 13:19:29.831750 11353 solver.cpp:404]     Test net output #1: loss = 1.08486 (* 1 = 1.08486 loss)
I0830 13:19:29.847262 11353 solver.cpp:228] Iteration 28000, loss = 1.09662
I0830 13:19:29.847347 11353 solver.cpp:244]     Train net output #0: loss = 1.09662 (* 1 = 1.09662 loss)
I0830 13:19:29.847359 11353 sgd_solver.cpp:106] Iteration 28000, lr = 0.0518611
I0830 13:19:34.156069 11353 solver.cpp:228] Iteration 28100, loss = 1.10489
I0830 13:19:34.156136 11353 solver.cpp:244]     Train net output #0: loss = 1.10489 (* 1 = 1.10489 loss)
I0830 13:19:34.156141 11353 sgd_solver.cpp:106] Iteration 28100, lr = 0.0517802
I0830 13:19:38.462976 11353 solver.cpp:228] Iteration 28200, loss = 1.09489
I0830 13:19:38.463040 11353 solver.cpp:244]     Train net output #0: loss = 1.09489 (* 1 = 1.09489 loss)
I0830 13:19:38.463048 11353 sgd_solver.cpp:106] Iteration 28200, lr = 0.0516996
I0830 13:19:42.787411 11353 solver.cpp:228] Iteration 28300, loss = 1.10295
I0830 13:19:42.787479 11353 solver.cpp:244]     Train net output #0: loss = 1.10295 (* 1 = 1.10295 loss)
I0830 13:19:42.787485 11353 sgd_solver.cpp:106] Iteration 28300, lr = 0.0516193
I0830 13:19:47.097137 11353 solver.cpp:228] Iteration 28400, loss = 1.1007
I0830 13:19:47.097209 11353 solver.cpp:244]     Train net output #0: loss = 1.1007 (* 1 = 1.1007 loss)
I0830 13:19:47.097216 11353 sgd_solver.cpp:106] Iteration 28400, lr = 0.0515393
I0830 13:19:51.363121 11353 solver.cpp:337] Iteration 28500, Testing net (#0)
I0830 13:19:54.714519 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0830 13:19:54.714594 11353 solver.cpp:404]     Test net output #1: loss = 1.07295 (* 1 = 1.07295 loss)
I0830 13:19:54.729006 11353 solver.cpp:228] Iteration 28500, loss = 1.10267
I0830 13:19:54.729043 11353 solver.cpp:244]     Train net output #0: loss = 1.10267 (* 1 = 1.10267 loss)
I0830 13:19:54.729053 11353 sgd_solver.cpp:106] Iteration 28500, lr = 0.0514596
I0830 13:19:59.044126 11353 solver.cpp:228] Iteration 28600, loss = 1.10319
I0830 13:19:59.044173 11353 solver.cpp:244]     Train net output #0: loss = 1.10319 (* 1 = 1.10319 loss)
I0830 13:19:59.044178 11353 sgd_solver.cpp:106] Iteration 28600, lr = 0.0513801
I0830 13:20:03.355402 11353 solver.cpp:228] Iteration 28700, loss = 1.09563
I0830 13:20:03.355424 11353 solver.cpp:244]     Train net output #0: loss = 1.09563 (* 1 = 1.09563 loss)
I0830 13:20:03.355429 11353 sgd_solver.cpp:106] Iteration 28700, lr = 0.051301
I0830 13:20:07.663166 11353 solver.cpp:228] Iteration 28800, loss = 1.09645
I0830 13:20:07.663208 11353 solver.cpp:244]     Train net output #0: loss = 1.09645 (* 1 = 1.09645 loss)
I0830 13:20:07.663213 11353 sgd_solver.cpp:106] Iteration 28800, lr = 0.0512221
I0830 13:20:11.980564 11353 solver.cpp:228] Iteration 28900, loss = 1.09892
I0830 13:20:11.980638 11353 solver.cpp:244]     Train net output #0: loss = 1.09892 (* 1 = 1.09892 loss)
I0830 13:20:11.980644 11353 sgd_solver.cpp:106] Iteration 28900, lr = 0.0511435
I0830 13:20:16.255794 11353 solver.cpp:337] Iteration 29000, Testing net (#0)
I0830 13:20:17.842706 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:20:19.658599 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0830 13:20:19.658704 11353 solver.cpp:404]     Test net output #1: loss = 1.07433 (* 1 = 1.07433 loss)
I0830 13:20:19.673827 11353 solver.cpp:228] Iteration 29000, loss = 1.10951
I0830 13:20:19.673877 11353 solver.cpp:244]     Train net output #0: loss = 1.10951 (* 1 = 1.10951 loss)
I0830 13:20:19.673887 11353 sgd_solver.cpp:106] Iteration 29000, lr = 0.0510653
I0830 13:20:23.995527 11353 solver.cpp:228] Iteration 29100, loss = 1.09836
I0830 13:20:23.995582 11353 solver.cpp:244]     Train net output #0: loss = 1.09836 (* 1 = 1.09836 loss)
I0830 13:20:23.995589 11353 sgd_solver.cpp:106] Iteration 29100, lr = 0.0509872
I0830 13:20:28.323781 11353 solver.cpp:228] Iteration 29200, loss = 1.09715
I0830 13:20:28.323803 11353 solver.cpp:244]     Train net output #0: loss = 1.09715 (* 1 = 1.09715 loss)
I0830 13:20:28.323809 11353 sgd_solver.cpp:106] Iteration 29200, lr = 0.0509095
I0830 13:20:32.641209 11353 solver.cpp:228] Iteration 29300, loss = 1.10725
I0830 13:20:32.641264 11353 solver.cpp:244]     Train net output #0: loss = 1.10725 (* 1 = 1.10725 loss)
I0830 13:20:32.641270 11353 sgd_solver.cpp:106] Iteration 29300, lr = 0.050832
I0830 13:20:36.948786 11353 solver.cpp:228] Iteration 29400, loss = 1.10834
I0830 13:20:36.948832 11353 solver.cpp:244]     Train net output #0: loss = 1.10834 (* 1 = 1.10834 loss)
I0830 13:20:36.948837 11353 sgd_solver.cpp:106] Iteration 29400, lr = 0.0507548
I0830 13:20:41.215687 11353 solver.cpp:337] Iteration 29500, Testing net (#0)
I0830 13:20:44.597422 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0830 13:20:44.597545 11353 solver.cpp:404]     Test net output #1: loss = 1.09891 (* 1 = 1.09891 loss)
I0830 13:20:44.613361 11353 solver.cpp:228] Iteration 29500, loss = 1.09648
I0830 13:20:44.613418 11353 solver.cpp:244]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0830 13:20:44.613428 11353 sgd_solver.cpp:106] Iteration 29500, lr = 0.0506779
I0830 13:20:48.924989 11353 solver.cpp:228] Iteration 29600, loss = 1.09823
I0830 13:20:48.925055 11353 solver.cpp:244]     Train net output #0: loss = 1.09823 (* 1 = 1.09823 loss)
I0830 13:20:48.925061 11353 sgd_solver.cpp:106] Iteration 29600, lr = 0.0506013
I0830 13:20:53.240173 11353 solver.cpp:228] Iteration 29700, loss = 1.10689
I0830 13:20:53.240257 11353 solver.cpp:244]     Train net output #0: loss = 1.10689 (* 1 = 1.10689 loss)
I0830 13:20:53.240263 11353 sgd_solver.cpp:106] Iteration 29700, lr = 0.0505249
I0830 13:20:57.571449 11353 solver.cpp:228] Iteration 29800, loss = 1.10429
I0830 13:20:57.571504 11353 solver.cpp:244]     Train net output #0: loss = 1.10429 (* 1 = 1.10429 loss)
I0830 13:20:57.571511 11353 sgd_solver.cpp:106] Iteration 29800, lr = 0.0504488
I0830 13:21:01.897408 11353 solver.cpp:228] Iteration 29900, loss = 1.10168
I0830 13:21:01.897456 11353 solver.cpp:244]     Train net output #0: loss = 1.10168 (* 1 = 1.10168 loss)
I0830 13:21:01.897462 11353 sgd_solver.cpp:106] Iteration 29900, lr = 0.0503729
I0830 13:21:06.164160 11353 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_30000.caffemodel
I0830 13:21:06.811566 11353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_30000.solverstate
I0830 13:21:06.988517 11353 solver.cpp:337] Iteration 30000, Testing net (#0)
I0830 13:21:10.195374 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0830 13:21:10.195415 11353 solver.cpp:404]     Test net output #1: loss = 1.1143 (* 1 = 1.1143 loss)
I0830 13:21:10.213171 11353 solver.cpp:228] Iteration 30000, loss = 1.09469
I0830 13:21:10.213232 11353 solver.cpp:244]     Train net output #0: loss = 1.09469 (* 1 = 1.09469 loss)
I0830 13:21:10.213258 11353 sgd_solver.cpp:106] Iteration 30000, lr = 0.0502973
I0830 13:21:14.532065 11353 solver.cpp:228] Iteration 30100, loss = 1.10436
I0830 13:21:14.532109 11353 solver.cpp:244]     Train net output #0: loss = 1.10436 (* 1 = 1.10436 loss)
I0830 13:21:14.532115 11353 sgd_solver.cpp:106] Iteration 30100, lr = 0.050222
I0830 13:21:18.857298 11353 solver.cpp:228] Iteration 30200, loss = 1.09632
I0830 13:21:18.857357 11353 solver.cpp:244]     Train net output #0: loss = 1.09632 (* 1 = 1.09632 loss)
I0830 13:21:18.857363 11353 sgd_solver.cpp:106] Iteration 30200, lr = 0.050147
I0830 13:21:23.171819 11353 solver.cpp:228] Iteration 30300, loss = 1.09849
I0830 13:21:23.171864 11353 solver.cpp:244]     Train net output #0: loss = 1.09849 (* 1 = 1.09849 loss)
I0830 13:21:23.171869 11353 sgd_solver.cpp:106] Iteration 30300, lr = 0.0500722
I0830 13:21:27.486958 11353 solver.cpp:228] Iteration 30400, loss = 1.09213
I0830 13:21:27.487009 11353 solver.cpp:244]     Train net output #0: loss = 1.09213 (* 1 = 1.09213 loss)
I0830 13:21:27.487013 11353 sgd_solver.cpp:106] Iteration 30400, lr = 0.0499977
I0830 13:21:31.757717 11353 solver.cpp:337] Iteration 30500, Testing net (#0)
I0830 13:21:35.218133 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0830 13:21:35.218274 11353 solver.cpp:404]     Test net output #1: loss = 1.12796 (* 1 = 1.12796 loss)
I0830 13:21:35.233806 11353 solver.cpp:228] Iteration 30500, loss = 1.09391
I0830 13:21:35.233868 11353 solver.cpp:244]     Train net output #0: loss = 1.09391 (* 1 = 1.09391 loss)
I0830 13:21:35.233883 11353 sgd_solver.cpp:106] Iteration 30500, lr = 0.0499234
I0830 13:21:39.553604 11353 solver.cpp:228] Iteration 30600, loss = 1.10354
I0830 13:21:39.553663 11353 solver.cpp:244]     Train net output #0: loss = 1.10354 (* 1 = 1.10354 loss)
I0830 13:21:39.553674 11353 sgd_solver.cpp:106] Iteration 30600, lr = 0.0498494
I0830 13:21:43.868870 11353 solver.cpp:228] Iteration 30700, loss = 1.09905
I0830 13:21:43.868912 11353 solver.cpp:244]     Train net output #0: loss = 1.09905 (* 1 = 1.09905 loss)
I0830 13:21:43.868917 11353 sgd_solver.cpp:106] Iteration 30700, lr = 0.0497756
I0830 13:21:48.176971 11353 solver.cpp:228] Iteration 30800, loss = 1.10222
I0830 13:21:48.176991 11353 solver.cpp:244]     Train net output #0: loss = 1.10222 (* 1 = 1.10222 loss)
I0830 13:21:48.176996 11353 sgd_solver.cpp:106] Iteration 30800, lr = 0.0497021
I0830 13:21:52.477761 11353 solver.cpp:228] Iteration 30900, loss = 1.09068
I0830 13:21:52.477783 11353 solver.cpp:244]     Train net output #0: loss = 1.09068 (* 1 = 1.09068 loss)
I0830 13:21:52.477789 11353 sgd_solver.cpp:106] Iteration 30900, lr = 0.0496288
I0830 13:21:56.736624 11353 solver.cpp:337] Iteration 31000, Testing net (#0)
I0830 13:21:59.000650 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:22:00.077237 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152083
I0830 13:22:00.077291 11353 solver.cpp:404]     Test net output #1: loss = 1.12742 (* 1 = 1.12742 loss)
I0830 13:22:00.092314 11353 solver.cpp:228] Iteration 31000, loss = 1.10153
I0830 13:22:00.092342 11353 solver.cpp:244]     Train net output #0: loss = 1.10153 (* 1 = 1.10153 loss)
I0830 13:22:00.092356 11353 sgd_solver.cpp:106] Iteration 31000, lr = 0.0495558
I0830 13:22:04.398980 11353 solver.cpp:228] Iteration 31100, loss = 1.0997
I0830 13:22:04.399031 11353 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0830 13:22:04.399036 11353 sgd_solver.cpp:106] Iteration 31100, lr = 0.0494831
I0830 13:22:08.718890 11353 solver.cpp:228] Iteration 31200, loss = 1.09716
I0830 13:22:08.718955 11353 solver.cpp:244]     Train net output #0: loss = 1.09716 (* 1 = 1.09716 loss)
I0830 13:22:08.718967 11353 sgd_solver.cpp:106] Iteration 31200, lr = 0.0494106
I0830 13:22:13.029878 11353 solver.cpp:228] Iteration 31300, loss = 1.09841
I0830 13:22:13.029933 11353 solver.cpp:244]     Train net output #0: loss = 1.09841 (* 1 = 1.09841 loss)
I0830 13:22:13.029939 11353 sgd_solver.cpp:106] Iteration 31300, lr = 0.0493383
I0830 13:22:17.351574 11353 solver.cpp:228] Iteration 31400, loss = 1.10126
I0830 13:22:17.351619 11353 solver.cpp:244]     Train net output #0: loss = 1.10126 (* 1 = 1.10126 loss)
I0830 13:22:17.351624 11353 sgd_solver.cpp:106] Iteration 31400, lr = 0.0492663
I0830 13:22:21.623256 11353 solver.cpp:337] Iteration 31500, Testing net (#0)
I0830 13:22:25.142693 11353 solver.cpp:404]     Test net output #0: accuracy = 0.151958
I0830 13:22:25.142745 11353 solver.cpp:404]     Test net output #1: loss = 1.116 (* 1 = 1.116 loss)
I0830 13:22:25.157053 11353 solver.cpp:228] Iteration 31500, loss = 1.09892
I0830 13:22:25.157085 11353 solver.cpp:244]     Train net output #0: loss = 1.09892 (* 1 = 1.09892 loss)
I0830 13:22:25.157097 11353 sgd_solver.cpp:106] Iteration 31500, lr = 0.0491946
I0830 13:22:29.461604 11353 solver.cpp:228] Iteration 31600, loss = 1.1009
I0830 13:22:29.461650 11353 solver.cpp:244]     Train net output #0: loss = 1.1009 (* 1 = 1.1009 loss)
I0830 13:22:29.461657 11353 sgd_solver.cpp:106] Iteration 31600, lr = 0.049123
I0830 13:22:33.772967 11353 solver.cpp:228] Iteration 31700, loss = 1.09761
I0830 13:22:33.773005 11353 solver.cpp:244]     Train net output #0: loss = 1.09761 (* 1 = 1.09761 loss)
I0830 13:22:33.773010 11353 sgd_solver.cpp:106] Iteration 31700, lr = 0.0490518
I0830 13:22:38.083151 11353 solver.cpp:228] Iteration 31800, loss = 1.1013
I0830 13:22:38.083195 11353 solver.cpp:244]     Train net output #0: loss = 1.1013 (* 1 = 1.1013 loss)
I0830 13:22:38.083200 11353 sgd_solver.cpp:106] Iteration 31800, lr = 0.0489807
I0830 13:22:42.388010 11353 solver.cpp:228] Iteration 31900, loss = 1.09785
I0830 13:22:42.388033 11353 solver.cpp:244]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0830 13:22:42.388038 11353 sgd_solver.cpp:106] Iteration 31900, lr = 0.0489099
I0830 13:22:46.654772 11353 solver.cpp:337] Iteration 32000, Testing net (#0)
I0830 13:22:49.726785 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0830 13:22:49.726881 11353 solver.cpp:404]     Test net output #1: loss = 1.10191 (* 1 = 1.10191 loss)
I0830 13:22:49.741619 11353 solver.cpp:228] Iteration 32000, loss = 1.10026
I0830 13:22:49.741638 11353 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0830 13:22:49.741647 11353 sgd_solver.cpp:106] Iteration 32000, lr = 0.0488394
I0830 13:22:54.047046 11353 solver.cpp:228] Iteration 32100, loss = 1.09329
I0830 13:22:54.047091 11353 solver.cpp:244]     Train net output #0: loss = 1.09329 (* 1 = 1.09329 loss)
I0830 13:22:54.047097 11353 sgd_solver.cpp:106] Iteration 32100, lr = 0.048769
I0830 13:22:58.356600 11353 solver.cpp:228] Iteration 32200, loss = 1.09584
I0830 13:22:58.356657 11353 solver.cpp:244]     Train net output #0: loss = 1.09584 (* 1 = 1.09584 loss)
I0830 13:22:58.356662 11353 sgd_solver.cpp:106] Iteration 32200, lr = 0.048699
I0830 13:23:02.675966 11353 solver.cpp:228] Iteration 32300, loss = 1.09797
I0830 13:23:02.676025 11353 solver.cpp:244]     Train net output #0: loss = 1.09797 (* 1 = 1.09797 loss)
I0830 13:23:02.676030 11353 sgd_solver.cpp:106] Iteration 32300, lr = 0.0486291
I0830 13:23:06.994897 11353 solver.cpp:228] Iteration 32400, loss = 1.10209
I0830 13:23:06.994946 11353 solver.cpp:244]     Train net output #0: loss = 1.10209 (* 1 = 1.10209 loss)
I0830 13:23:06.994951 11353 sgd_solver.cpp:106] Iteration 32400, lr = 0.0485595
I0830 13:23:11.275171 11353 solver.cpp:337] Iteration 32500, Testing net (#0)
I0830 13:23:14.705927 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0830 13:23:14.705972 11353 solver.cpp:404]     Test net output #1: loss = 1.09654 (* 1 = 1.09654 loss)
I0830 13:23:14.721710 11353 solver.cpp:228] Iteration 32500, loss = 1.09131
I0830 13:23:14.721741 11353 solver.cpp:244]     Train net output #0: loss = 1.09131 (* 1 = 1.09131 loss)
I0830 13:23:14.721751 11353 sgd_solver.cpp:106] Iteration 32500, lr = 0.0484901
I0830 13:23:19.029817 11353 solver.cpp:228] Iteration 32600, loss = 1.10435
I0830 13:23:19.029887 11353 solver.cpp:244]     Train net output #0: loss = 1.10435 (* 1 = 1.10435 loss)
I0830 13:23:19.029893 11353 sgd_solver.cpp:106] Iteration 32600, lr = 0.0484209
I0830 13:23:23.355412 11353 solver.cpp:228] Iteration 32700, loss = 1.09903
I0830 13:23:23.355454 11353 solver.cpp:244]     Train net output #0: loss = 1.09903 (* 1 = 1.09903 loss)
I0830 13:23:23.355460 11353 sgd_solver.cpp:106] Iteration 32700, lr = 0.048352
I0830 13:23:27.679877 11353 solver.cpp:228] Iteration 32800, loss = 1.09984
I0830 13:23:27.679922 11353 solver.cpp:244]     Train net output #0: loss = 1.09984 (* 1 = 1.09984 loss)
I0830 13:23:27.679927 11353 sgd_solver.cpp:106] Iteration 32800, lr = 0.0482833
I0830 13:23:31.999184 11353 solver.cpp:228] Iteration 32900, loss = 1.10338
I0830 13:23:31.999239 11353 solver.cpp:244]     Train net output #0: loss = 1.10338 (* 1 = 1.10338 loss)
I0830 13:23:31.999245 11353 sgd_solver.cpp:106] Iteration 32900, lr = 0.0482148
I0830 13:23:36.268448 11353 solver.cpp:337] Iteration 33000, Testing net (#0)
I0830 13:23:39.665729 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0830 13:23:39.665778 11353 solver.cpp:404]     Test net output #1: loss = 1.07683 (* 1 = 1.07683 loss)
I0830 13:23:39.680287 11353 solver.cpp:228] Iteration 33000, loss = 1.09358
I0830 13:23:39.680330 11353 solver.cpp:244]     Train net output #0: loss = 1.09358 (* 1 = 1.09358 loss)
I0830 13:23:39.680341 11353 sgd_solver.cpp:106] Iteration 33000, lr = 0.0481466
I0830 13:23:43.994882 11353 solver.cpp:228] Iteration 33100, loss = 1.08836
I0830 13:23:43.994947 11353 solver.cpp:244]     Train net output #0: loss = 1.08836 (* 1 = 1.08836 loss)
I0830 13:23:43.994953 11353 sgd_solver.cpp:106] Iteration 33100, lr = 0.0480786
I0830 13:23:48.312940 11353 solver.cpp:228] Iteration 33200, loss = 1.09726
I0830 13:23:48.312994 11353 solver.cpp:244]     Train net output #0: loss = 1.09726 (* 1 = 1.09726 loss)
I0830 13:23:48.313001 11353 sgd_solver.cpp:106] Iteration 33200, lr = 0.0480108
I0830 13:23:52.634855 11353 solver.cpp:228] Iteration 33300, loss = 1.09916
I0830 13:23:52.634924 11353 solver.cpp:244]     Train net output #0: loss = 1.09916 (* 1 = 1.09916 loss)
I0830 13:23:52.634930 11353 sgd_solver.cpp:106] Iteration 33300, lr = 0.0479432
I0830 13:23:53.022995 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:23:56.952700 11353 solver.cpp:228] Iteration 33400, loss = 1.09923
I0830 13:23:56.952749 11353 solver.cpp:244]     Train net output #0: loss = 1.09923 (* 1 = 1.09923 loss)
I0830 13:23:56.952755 11353 sgd_solver.cpp:106] Iteration 33400, lr = 0.0478759
I0830 13:24:01.227555 11353 solver.cpp:337] Iteration 33500, Testing net (#0)
I0830 13:24:04.530612 11353 solver.cpp:404]     Test net output #0: accuracy = 0.57825
I0830 13:24:04.530660 11353 solver.cpp:404]     Test net output #1: loss = 1.06538 (* 1 = 1.06538 loss)
I0830 13:24:04.545351 11353 solver.cpp:228] Iteration 33500, loss = 1.09868
I0830 13:24:04.545400 11353 solver.cpp:244]     Train net output #0: loss = 1.09868 (* 1 = 1.09868 loss)
I0830 13:24:04.545413 11353 sgd_solver.cpp:106] Iteration 33500, lr = 0.0478087
I0830 13:24:08.860014 11353 solver.cpp:228] Iteration 33600, loss = 1.09788
I0830 13:24:08.860086 11353 solver.cpp:244]     Train net output #0: loss = 1.09788 (* 1 = 1.09788 loss)
I0830 13:24:08.860093 11353 sgd_solver.cpp:106] Iteration 33600, lr = 0.0477418
I0830 13:24:13.173635 11353 solver.cpp:228] Iteration 33700, loss = 1.09871
I0830 13:24:13.173676 11353 solver.cpp:244]     Train net output #0: loss = 1.09871 (* 1 = 1.09871 loss)
I0830 13:24:13.173682 11353 sgd_solver.cpp:106] Iteration 33700, lr = 0.0476751
I0830 13:24:17.488710 11353 solver.cpp:228] Iteration 33800, loss = 1.09768
I0830 13:24:17.488755 11353 solver.cpp:244]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0830 13:24:17.488762 11353 sgd_solver.cpp:106] Iteration 33800, lr = 0.0476086
I0830 13:24:21.808364 11353 solver.cpp:228] Iteration 33900, loss = 1.09812
I0830 13:24:21.808409 11353 solver.cpp:244]     Train net output #0: loss = 1.09812 (* 1 = 1.09812 loss)
I0830 13:24:21.808414 11353 sgd_solver.cpp:106] Iteration 33900, lr = 0.0475424
I0830 13:24:26.093225 11353 solver.cpp:337] Iteration 34000, Testing net (#0)
I0830 13:24:29.703553 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578292
I0830 13:24:29.703613 11353 solver.cpp:404]     Test net output #1: loss = 1.06977 (* 1 = 1.06977 loss)
I0830 13:24:29.718335 11353 solver.cpp:228] Iteration 34000, loss = 1.10284
I0830 13:24:29.718381 11353 solver.cpp:244]     Train net output #0: loss = 1.10284 (* 1 = 1.10284 loss)
I0830 13:24:29.718403 11353 sgd_solver.cpp:106] Iteration 34000, lr = 0.0474763
I0830 13:24:34.043534 11353 solver.cpp:228] Iteration 34100, loss = 1.09797
I0830 13:24:34.043592 11353 solver.cpp:244]     Train net output #0: loss = 1.09797 (* 1 = 1.09797 loss)
I0830 13:24:34.043599 11353 sgd_solver.cpp:106] Iteration 34100, lr = 0.0474105
I0830 13:24:38.358000 11353 solver.cpp:228] Iteration 34200, loss = 1.10984
I0830 13:24:38.358038 11353 solver.cpp:244]     Train net output #0: loss = 1.10984 (* 1 = 1.10984 loss)
I0830 13:24:38.358044 11353 sgd_solver.cpp:106] Iteration 34200, lr = 0.0473449
I0830 13:24:42.675205 11353 solver.cpp:228] Iteration 34300, loss = 1.09574
I0830 13:24:42.675271 11353 solver.cpp:244]     Train net output #0: loss = 1.09574 (* 1 = 1.09574 loss)
I0830 13:24:42.675277 11353 sgd_solver.cpp:106] Iteration 34300, lr = 0.0472795
I0830 13:24:46.996295 11353 solver.cpp:228] Iteration 34400, loss = 1.09789
I0830 13:24:46.996357 11353 solver.cpp:244]     Train net output #0: loss = 1.09789 (* 1 = 1.09789 loss)
I0830 13:24:46.996363 11353 sgd_solver.cpp:106] Iteration 34400, lr = 0.0472143
I0830 13:24:51.265542 11353 solver.cpp:337] Iteration 34500, Testing net (#0)
I0830 13:24:54.809137 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0830 13:24:54.809207 11353 solver.cpp:404]     Test net output #1: loss = 1.08162 (* 1 = 1.08162 loss)
I0830 13:24:54.825481 11353 solver.cpp:228] Iteration 34500, loss = 1.0976
I0830 13:24:54.825551 11353 solver.cpp:244]     Train net output #0: loss = 1.0976 (* 1 = 1.0976 loss)
I0830 13:24:54.825564 11353 sgd_solver.cpp:106] Iteration 34500, lr = 0.0471493
I0830 13:24:59.137152 11353 solver.cpp:228] Iteration 34600, loss = 1.09985
I0830 13:24:59.137193 11353 solver.cpp:244]     Train net output #0: loss = 1.09985 (* 1 = 1.09985 loss)
I0830 13:24:59.137199 11353 sgd_solver.cpp:106] Iteration 34600, lr = 0.0470845
I0830 13:25:03.445047 11353 solver.cpp:228] Iteration 34700, loss = 1.09234
I0830 13:25:03.445091 11353 solver.cpp:244]     Train net output #0: loss = 1.09234 (* 1 = 1.09234 loss)
I0830 13:25:03.445097 11353 sgd_solver.cpp:106] Iteration 34700, lr = 0.0470199
I0830 13:25:07.756497 11353 solver.cpp:228] Iteration 34800, loss = 1.10804
I0830 13:25:07.756516 11353 solver.cpp:244]     Train net output #0: loss = 1.10804 (* 1 = 1.10804 loss)
I0830 13:25:07.756520 11353 sgd_solver.cpp:106] Iteration 34800, lr = 0.0469556
I0830 13:25:12.068253 11353 solver.cpp:228] Iteration 34900, loss = 1.10015
I0830 13:25:12.068317 11353 solver.cpp:244]     Train net output #0: loss = 1.10015 (* 1 = 1.10015 loss)
I0830 13:25:12.068323 11353 sgd_solver.cpp:106] Iteration 34900, lr = 0.0468914
I0830 13:25:16.336647 11353 solver.cpp:337] Iteration 35000, Testing net (#0)
I0830 13:25:19.461160 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0830 13:25:19.461264 11353 solver.cpp:404]     Test net output #1: loss = 1.1016 (* 1 = 1.1016 loss)
I0830 13:25:19.477247 11353 solver.cpp:228] Iteration 35000, loss = 1.10184
I0830 13:25:19.477293 11353 solver.cpp:244]     Train net output #0: loss = 1.10184 (* 1 = 1.10184 loss)
I0830 13:25:19.477301 11353 sgd_solver.cpp:106] Iteration 35000, lr = 0.0468274
I0830 13:25:23.788962 11353 solver.cpp:228] Iteration 35100, loss = 1.09648
I0830 13:25:23.789027 11353 solver.cpp:244]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0830 13:25:23.789033 11353 sgd_solver.cpp:106] Iteration 35100, lr = 0.0467637
I0830 13:25:28.095552 11353 solver.cpp:228] Iteration 35200, loss = 1.08826
I0830 13:25:28.095597 11353 solver.cpp:244]     Train net output #0: loss = 1.08826 (* 1 = 1.08826 loss)
I0830 13:25:28.095602 11353 sgd_solver.cpp:106] Iteration 35200, lr = 0.0467001
I0830 13:25:32.400667 11353 solver.cpp:228] Iteration 35300, loss = 1.09606
I0830 13:25:32.400687 11353 solver.cpp:244]     Train net output #0: loss = 1.09606 (* 1 = 1.09606 loss)
I0830 13:25:32.400692 11353 sgd_solver.cpp:106] Iteration 35300, lr = 0.0466368
I0830 13:25:35.370214 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:25:36.702639 11353 solver.cpp:228] Iteration 35400, loss = 1.10267
I0830 13:25:36.702689 11353 solver.cpp:244]     Train net output #0: loss = 1.10267 (* 1 = 1.10267 loss)
I0830 13:25:36.702694 11353 sgd_solver.cpp:106] Iteration 35400, lr = 0.0465736
I0830 13:25:40.972415 11353 solver.cpp:337] Iteration 35500, Testing net (#0)
I0830 13:25:44.322891 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:25:44.323002 11353 solver.cpp:404]     Test net output #1: loss = 1.11167 (* 1 = 1.11167 loss)
I0830 13:25:44.339625 11353 solver.cpp:228] Iteration 35500, loss = 1.09718
I0830 13:25:44.339690 11353 solver.cpp:244]     Train net output #0: loss = 1.09718 (* 1 = 1.09718 loss)
I0830 13:25:44.339706 11353 sgd_solver.cpp:106] Iteration 35500, lr = 0.0465107
I0830 13:25:48.655678 11353 solver.cpp:228] Iteration 35600, loss = 1.09883
I0830 13:25:48.655736 11353 solver.cpp:244]     Train net output #0: loss = 1.09883 (* 1 = 1.09883 loss)
I0830 13:25:48.655745 11353 sgd_solver.cpp:106] Iteration 35600, lr = 0.0464479
I0830 13:25:52.976991 11353 solver.cpp:228] Iteration 35700, loss = 1.09986
I0830 13:25:52.977046 11353 solver.cpp:244]     Train net output #0: loss = 1.09986 (* 1 = 1.09986 loss)
I0830 13:25:52.977052 11353 sgd_solver.cpp:106] Iteration 35700, lr = 0.0463854
I0830 13:25:57.291645 11353 solver.cpp:228] Iteration 35800, loss = 1.10167
I0830 13:25:57.291707 11353 solver.cpp:244]     Train net output #0: loss = 1.10167 (* 1 = 1.10167 loss)
I0830 13:25:57.291718 11353 sgd_solver.cpp:106] Iteration 35800, lr = 0.046323
I0830 13:26:01.601212 11353 solver.cpp:228] Iteration 35900, loss = 1.10199
I0830 13:26:01.601259 11353 solver.cpp:244]     Train net output #0: loss = 1.10199 (* 1 = 1.10199 loss)
I0830 13:26:01.601264 11353 sgd_solver.cpp:106] Iteration 35900, lr = 0.0462609
I0830 13:26:05.854903 11353 solver.cpp:337] Iteration 36000, Testing net (#0)
I0830 13:26:09.276017 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152625
I0830 13:26:09.276063 11353 solver.cpp:404]     Test net output #1: loss = 1.11265 (* 1 = 1.11265 loss)
I0830 13:26:09.291630 11353 solver.cpp:228] Iteration 36000, loss = 1.09811
I0830 13:26:09.291687 11353 solver.cpp:244]     Train net output #0: loss = 1.09811 (* 1 = 1.09811 loss)
I0830 13:26:09.291717 11353 sgd_solver.cpp:106] Iteration 36000, lr = 0.0461989
I0830 13:26:13.601996 11353 solver.cpp:228] Iteration 36100, loss = 1.10018
I0830 13:26:13.602046 11353 solver.cpp:244]     Train net output #0: loss = 1.10018 (* 1 = 1.10018 loss)
I0830 13:26:13.602051 11353 sgd_solver.cpp:106] Iteration 36100, lr = 0.0461371
I0830 13:26:17.910681 11353 solver.cpp:228] Iteration 36200, loss = 1.10073
I0830 13:26:17.910702 11353 solver.cpp:244]     Train net output #0: loss = 1.10073 (* 1 = 1.10073 loss)
I0830 13:26:17.910707 11353 sgd_solver.cpp:106] Iteration 36200, lr = 0.0460755
I0830 13:26:22.224056 11353 solver.cpp:228] Iteration 36300, loss = 1.10461
I0830 13:26:22.224100 11353 solver.cpp:244]     Train net output #0: loss = 1.10461 (* 1 = 1.10461 loss)
I0830 13:26:22.224107 11353 sgd_solver.cpp:106] Iteration 36300, lr = 0.0460141
I0830 13:26:26.540395 11353 solver.cpp:228] Iteration 36400, loss = 1.09449
I0830 13:26:26.540457 11353 solver.cpp:244]     Train net output #0: loss = 1.09449 (* 1 = 1.09449 loss)
I0830 13:26:26.540463 11353 sgd_solver.cpp:106] Iteration 36400, lr = 0.0459529
I0830 13:26:30.810101 11353 solver.cpp:337] Iteration 36500, Testing net (#0)
I0830 13:26:34.206434 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152042
I0830 13:26:34.206512 11353 solver.cpp:404]     Test net output #1: loss = 1.09877 (* 1 = 1.09877 loss)
I0830 13:26:34.221473 11353 solver.cpp:228] Iteration 36500, loss = 1.0989
I0830 13:26:34.221530 11353 solver.cpp:244]     Train net output #0: loss = 1.0989 (* 1 = 1.0989 loss)
I0830 13:26:34.221567 11353 sgd_solver.cpp:106] Iteration 36500, lr = 0.0458919
I0830 13:26:38.527029 11353 solver.cpp:228] Iteration 36600, loss = 1.09511
I0830 13:26:38.527060 11353 solver.cpp:244]     Train net output #0: loss = 1.09511 (* 1 = 1.09511 loss)
I0830 13:26:38.527065 11353 sgd_solver.cpp:106] Iteration 36600, lr = 0.0458311
I0830 13:26:42.843669 11353 solver.cpp:228] Iteration 36700, loss = 1.09856
I0830 13:26:42.843735 11353 solver.cpp:244]     Train net output #0: loss = 1.09856 (* 1 = 1.09856 loss)
I0830 13:26:42.843741 11353 sgd_solver.cpp:106] Iteration 36700, lr = 0.0457705
I0830 13:26:47.157578 11353 solver.cpp:228] Iteration 36800, loss = 1.09398
I0830 13:26:47.157621 11353 solver.cpp:244]     Train net output #0: loss = 1.09398 (* 1 = 1.09398 loss)
I0830 13:26:47.157626 11353 sgd_solver.cpp:106] Iteration 36800, lr = 0.04571
I0830 13:26:51.467684 11353 solver.cpp:228] Iteration 36900, loss = 1.0986
I0830 13:26:51.467731 11353 solver.cpp:244]     Train net output #0: loss = 1.0986 (* 1 = 1.0986 loss)
I0830 13:26:51.467736 11353 sgd_solver.cpp:106] Iteration 36900, lr = 0.0456497
I0830 13:26:55.739727 11353 solver.cpp:337] Iteration 37000, Testing net (#0)
I0830 13:26:59.281342 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578709
I0830 13:26:59.281394 11353 solver.cpp:404]     Test net output #1: loss = 1.09446 (* 1 = 1.09446 loss)
I0830 13:26:59.296206 11353 solver.cpp:228] Iteration 37000, loss = 1.0988
I0830 13:26:59.296243 11353 solver.cpp:244]     Train net output #0: loss = 1.0988 (* 1 = 1.0988 loss)
I0830 13:26:59.296257 11353 sgd_solver.cpp:106] Iteration 37000, lr = 0.0455897
I0830 13:27:03.608949 11353 solver.cpp:228] Iteration 37100, loss = 1.0979
I0830 13:27:03.609005 11353 solver.cpp:244]     Train net output #0: loss = 1.0979 (* 1 = 1.0979 loss)
I0830 13:27:03.609014 11353 sgd_solver.cpp:106] Iteration 37100, lr = 0.0455298
I0830 13:27:07.926477 11353 solver.cpp:228] Iteration 37200, loss = 1.10639
I0830 13:27:07.926548 11353 solver.cpp:244]     Train net output #0: loss = 1.10639 (* 1 = 1.10639 loss)
I0830 13:27:07.926555 11353 sgd_solver.cpp:106] Iteration 37200, lr = 0.0454701
I0830 13:27:12.236559 11353 solver.cpp:228] Iteration 37300, loss = 1.10095
I0830 13:27:12.236634 11353 solver.cpp:244]     Train net output #0: loss = 1.10095 (* 1 = 1.10095 loss)
I0830 13:27:12.236640 11353 sgd_solver.cpp:106] Iteration 37300, lr = 0.0454105
I0830 13:27:16.559960 11353 solver.cpp:228] Iteration 37400, loss = 1.09978
I0830 13:27:16.560008 11353 solver.cpp:244]     Train net output #0: loss = 1.09978 (* 1 = 1.09978 loss)
I0830 13:27:16.560012 11353 sgd_solver.cpp:106] Iteration 37400, lr = 0.0453512
I0830 13:27:20.831143 11353 solver.cpp:337] Iteration 37500, Testing net (#0)
I0830 13:27:22.504062 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:27:24.266499 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578209
I0830 13:27:24.266573 11353 solver.cpp:404]     Test net output #1: loss = 1.09007 (* 1 = 1.09007 loss)
I0830 13:27:24.281564 11353 solver.cpp:228] Iteration 37500, loss = 1.09753
I0830 13:27:24.281627 11353 solver.cpp:244]     Train net output #0: loss = 1.09753 (* 1 = 1.09753 loss)
I0830 13:27:24.281638 11353 sgd_solver.cpp:106] Iteration 37500, lr = 0.045292
I0830 13:27:28.591801 11353 solver.cpp:228] Iteration 37600, loss = 1.09896
I0830 13:27:28.591845 11353 solver.cpp:244]     Train net output #0: loss = 1.09896 (* 1 = 1.09896 loss)
I0830 13:27:28.591850 11353 sgd_solver.cpp:106] Iteration 37600, lr = 0.045233
I0830 13:27:32.909940 11353 solver.cpp:228] Iteration 37700, loss = 1.0981
I0830 13:27:32.909983 11353 solver.cpp:244]     Train net output #0: loss = 1.0981 (* 1 = 1.0981 loss)
I0830 13:27:32.909988 11353 sgd_solver.cpp:106] Iteration 37700, lr = 0.0451742
I0830 13:27:37.234097 11353 solver.cpp:228] Iteration 37800, loss = 1.1021
I0830 13:27:37.234153 11353 solver.cpp:244]     Train net output #0: loss = 1.1021 (* 1 = 1.1021 loss)
I0830 13:27:37.234160 11353 sgd_solver.cpp:106] Iteration 37800, lr = 0.0451156
I0830 13:27:41.553303 11353 solver.cpp:228] Iteration 37900, loss = 1.09678
I0830 13:27:41.553339 11353 solver.cpp:244]     Train net output #0: loss = 1.09678 (* 1 = 1.09678 loss)
I0830 13:27:41.553344 11353 sgd_solver.cpp:106] Iteration 37900, lr = 0.0450571
I0830 13:27:45.822589 11353 solver.cpp:337] Iteration 38000, Testing net (#0)
I0830 13:27:49.047397 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0830 13:27:49.047480 11353 solver.cpp:404]     Test net output #1: loss = 1.09021 (* 1 = 1.09021 loss)
I0830 13:27:49.064139 11353 solver.cpp:228] Iteration 38000, loss = 1.09315
I0830 13:27:49.064211 11353 solver.cpp:244]     Train net output #0: loss = 1.09315 (* 1 = 1.09315 loss)
I0830 13:27:49.064227 11353 sgd_solver.cpp:106] Iteration 38000, lr = 0.0449989
I0830 13:27:53.379886 11353 solver.cpp:228] Iteration 38100, loss = 1.09969
I0830 13:27:53.379932 11353 solver.cpp:244]     Train net output #0: loss = 1.09969 (* 1 = 1.09969 loss)
I0830 13:27:53.379938 11353 sgd_solver.cpp:106] Iteration 38100, lr = 0.0449408
I0830 13:27:57.691907 11353 solver.cpp:228] Iteration 38200, loss = 1.09905
I0830 13:27:57.691952 11353 solver.cpp:244]     Train net output #0: loss = 1.09905 (* 1 = 1.09905 loss)
I0830 13:27:57.691957 11353 sgd_solver.cpp:106] Iteration 38200, lr = 0.0448828
I0830 13:28:01.996577 11353 solver.cpp:228] Iteration 38300, loss = 1.09941
I0830 13:28:01.996620 11353 solver.cpp:244]     Train net output #0: loss = 1.09941 (* 1 = 1.09941 loss)
I0830 13:28:01.996626 11353 sgd_solver.cpp:106] Iteration 38300, lr = 0.0448251
I0830 13:28:06.303932 11353 solver.cpp:228] Iteration 38400, loss = 1.0911
I0830 13:28:06.303980 11353 solver.cpp:244]     Train net output #0: loss = 1.0911 (* 1 = 1.0911 loss)
I0830 13:28:06.303987 11353 sgd_solver.cpp:106] Iteration 38400, lr = 0.0447675
I0830 13:28:10.575652 11353 solver.cpp:337] Iteration 38500, Testing net (#0)
I0830 13:28:14.141455 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0830 13:28:14.141525 11353 solver.cpp:404]     Test net output #1: loss = 1.0897 (* 1 = 1.0897 loss)
I0830 13:28:14.157196 11353 solver.cpp:228] Iteration 38500, loss = 1.11567
I0830 13:28:14.157238 11353 solver.cpp:244]     Train net output #0: loss = 1.11567 (* 1 = 1.11567 loss)
I0830 13:28:14.157250 11353 sgd_solver.cpp:106] Iteration 38500, lr = 0.0447101
I0830 13:28:18.468557 11353 solver.cpp:228] Iteration 38600, loss = 1.10259
I0830 13:28:18.468633 11353 solver.cpp:244]     Train net output #0: loss = 1.10259 (* 1 = 1.10259 loss)
I0830 13:28:18.468642 11353 sgd_solver.cpp:106] Iteration 38600, lr = 0.0446529
I0830 13:28:22.774912 11353 solver.cpp:228] Iteration 38700, loss = 1.09524
I0830 13:28:22.774977 11353 solver.cpp:244]     Train net output #0: loss = 1.09524 (* 1 = 1.09524 loss)
I0830 13:28:22.774982 11353 sgd_solver.cpp:106] Iteration 38700, lr = 0.0445958
I0830 13:28:27.091415 11353 solver.cpp:228] Iteration 38800, loss = 1.1025
I0830 13:28:27.091469 11353 solver.cpp:244]     Train net output #0: loss = 1.1025 (* 1 = 1.1025 loss)
I0830 13:28:27.091473 11353 sgd_solver.cpp:106] Iteration 38800, lr = 0.0445389
I0830 13:28:31.403209 11353 solver.cpp:228] Iteration 38900, loss = 1.0994
I0830 13:28:31.403262 11353 solver.cpp:244]     Train net output #0: loss = 1.0994 (* 1 = 1.0994 loss)
I0830 13:28:31.403269 11353 sgd_solver.cpp:106] Iteration 38900, lr = 0.0444822
I0830 13:28:35.665421 11353 solver.cpp:337] Iteration 39000, Testing net (#0)
I0830 13:28:39.064505 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269083
I0830 13:28:39.064553 11353 solver.cpp:404]     Test net output #1: loss = 1.08453 (* 1 = 1.08453 loss)
I0830 13:28:39.080090 11353 solver.cpp:228] Iteration 39000, loss = 1.09556
I0830 13:28:39.080153 11353 solver.cpp:244]     Train net output #0: loss = 1.09556 (* 1 = 1.09556 loss)
I0830 13:28:39.080175 11353 sgd_solver.cpp:106] Iteration 39000, lr = 0.0444256
I0830 13:28:43.405747 11353 solver.cpp:228] Iteration 39100, loss = 1.10239
I0830 13:28:43.405804 11353 solver.cpp:244]     Train net output #0: loss = 1.10239 (* 1 = 1.10239 loss)
I0830 13:28:43.405812 11353 sgd_solver.cpp:106] Iteration 39100, lr = 0.0443692
I0830 13:28:47.713974 11353 solver.cpp:228] Iteration 39200, loss = 1.0962
I0830 13:28:47.714020 11353 solver.cpp:244]     Train net output #0: loss = 1.0962 (* 1 = 1.0962 loss)
I0830 13:28:47.714025 11353 sgd_solver.cpp:106] Iteration 39200, lr = 0.044313
I0830 13:28:52.025923 11353 solver.cpp:228] Iteration 39300, loss = 1.09757
I0830 13:28:52.025961 11353 solver.cpp:244]     Train net output #0: loss = 1.09757 (* 1 = 1.09757 loss)
I0830 13:28:52.025969 11353 sgd_solver.cpp:106] Iteration 39300, lr = 0.044257
I0830 13:28:56.340847 11353 solver.cpp:228] Iteration 39400, loss = 1.0989
I0830 13:28:56.340894 11353 solver.cpp:244]     Train net output #0: loss = 1.0989 (* 1 = 1.0989 loss)
I0830 13:28:56.340900 11353 sgd_solver.cpp:106] Iteration 39400, lr = 0.0442011
I0830 13:29:00.606675 11353 solver.cpp:337] Iteration 39500, Testing net (#0)
I0830 13:29:03.821614 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0830 13:29:03.821660 11353 solver.cpp:404]     Test net output #1: loss = 1.09161 (* 1 = 1.09161 loss)
I0830 13:29:03.836318 11353 solver.cpp:228] Iteration 39500, loss = 1.0949
I0830 13:29:03.836355 11353 solver.cpp:244]     Train net output #0: loss = 1.0949 (* 1 = 1.0949 loss)
I0830 13:29:03.836365 11353 sgd_solver.cpp:106] Iteration 39500, lr = 0.0441453
I0830 13:29:08.155802 11353 solver.cpp:228] Iteration 39600, loss = 1.0926
I0830 13:29:08.155845 11353 solver.cpp:244]     Train net output #0: loss = 1.0926 (* 1 = 1.0926 loss)
I0830 13:29:08.155851 11353 sgd_solver.cpp:106] Iteration 39600, lr = 0.0440898
I0830 13:29:12.468679 11353 solver.cpp:228] Iteration 39700, loss = 1.10224
I0830 13:29:12.468724 11353 solver.cpp:244]     Train net output #0: loss = 1.10224 (* 1 = 1.10224 loss)
I0830 13:29:12.468730 11353 sgd_solver.cpp:106] Iteration 39700, lr = 0.0440344
I0830 13:29:16.774338 11353 solver.cpp:228] Iteration 39800, loss = 1.09859
I0830 13:29:16.774392 11353 solver.cpp:244]     Train net output #0: loss = 1.09859 (* 1 = 1.09859 loss)
I0830 13:29:16.774399 11353 sgd_solver.cpp:106] Iteration 39800, lr = 0.0439791
I0830 13:29:21.089361 11353 solver.cpp:228] Iteration 39900, loss = 1.10756
I0830 13:29:21.089435 11353 solver.cpp:244]     Train net output #0: loss = 1.10756 (* 1 = 1.10756 loss)
I0830 13:29:21.089442 11353 sgd_solver.cpp:106] Iteration 39900, lr = 0.0439241
I0830 13:29:25.365874 11353 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_40000.caffemodel
I0830 13:29:25.984453 11353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_40000.solverstate
I0830 13:29:26.320338 11353 solver.cpp:337] Iteration 40000, Testing net (#0)
I0830 13:29:26.855085 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:29:29.567566 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269792
I0830 13:29:29.567631 11353 solver.cpp:404]     Test net output #1: loss = 1.10184 (* 1 = 1.10184 loss)
I0830 13:29:29.583410 11353 solver.cpp:228] Iteration 40000, loss = 1.10471
I0830 13:29:29.583461 11353 solver.cpp:244]     Train net output #0: loss = 1.10471 (* 1 = 1.10471 loss)
I0830 13:29:29.583472 11353 sgd_solver.cpp:106] Iteration 40000, lr = 0.0438691
I0830 13:29:33.904358 11353 solver.cpp:228] Iteration 40100, loss = 1.10302
I0830 13:29:33.904415 11353 solver.cpp:244]     Train net output #0: loss = 1.10302 (* 1 = 1.10302 loss)
I0830 13:29:33.904424 11353 sgd_solver.cpp:106] Iteration 40100, lr = 0.0438144
I0830 13:29:38.217087 11353 solver.cpp:228] Iteration 40200, loss = 1.09825
I0830 13:29:38.217145 11353 solver.cpp:244]     Train net output #0: loss = 1.09825 (* 1 = 1.09825 loss)
I0830 13:29:38.217154 11353 sgd_solver.cpp:106] Iteration 40200, lr = 0.0437598
I0830 13:29:42.528776 11353 solver.cpp:228] Iteration 40300, loss = 1.09648
I0830 13:29:42.528830 11353 solver.cpp:244]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0830 13:29:42.528836 11353 sgd_solver.cpp:106] Iteration 40300, lr = 0.0437053
I0830 13:29:46.847767 11353 solver.cpp:228] Iteration 40400, loss = 1.09893
I0830 13:29:46.847810 11353 solver.cpp:244]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I0830 13:29:46.847816 11353 sgd_solver.cpp:106] Iteration 40400, lr = 0.0436511
I0830 13:29:51.127126 11353 solver.cpp:337] Iteration 40500, Testing net (#0)
I0830 13:29:54.349670 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0830 13:29:54.349742 11353 solver.cpp:404]     Test net output #1: loss = 1.11392 (* 1 = 1.11392 loss)
I0830 13:29:54.364012 11353 solver.cpp:228] Iteration 40500, loss = 1.09987
I0830 13:29:54.364059 11353 solver.cpp:244]     Train net output #0: loss = 1.09987 (* 1 = 1.09987 loss)
I0830 13:29:54.364071 11353 sgd_solver.cpp:106] Iteration 40500, lr = 0.0435969
I0830 13:29:58.681259 11353 solver.cpp:228] Iteration 40600, loss = 1.09565
I0830 13:29:58.681303 11353 solver.cpp:244]     Train net output #0: loss = 1.09565 (* 1 = 1.09565 loss)
I0830 13:29:58.681310 11353 sgd_solver.cpp:106] Iteration 40600, lr = 0.043543
I0830 13:30:02.993839 11353 solver.cpp:228] Iteration 40700, loss = 1.09627
I0830 13:30:02.993857 11353 solver.cpp:244]     Train net output #0: loss = 1.09627 (* 1 = 1.09627 loss)
I0830 13:30:02.993862 11353 sgd_solver.cpp:106] Iteration 40700, lr = 0.0434892
I0830 13:30:07.313067 11353 solver.cpp:228] Iteration 40800, loss = 1.099
I0830 13:30:07.313108 11353 solver.cpp:244]     Train net output #0: loss = 1.099 (* 1 = 1.099 loss)
I0830 13:30:07.313113 11353 sgd_solver.cpp:106] Iteration 40800, lr = 0.0434355
I0830 13:30:11.633700 11353 solver.cpp:228] Iteration 40900, loss = 1.0914
I0830 13:30:11.633744 11353 solver.cpp:244]     Train net output #0: loss = 1.0914 (* 1 = 1.0914 loss)
I0830 13:30:11.633749 11353 sgd_solver.cpp:106] Iteration 40900, lr = 0.043382
I0830 13:30:15.897778 11353 solver.cpp:337] Iteration 41000, Testing net (#0)
I0830 13:30:19.344421 11353 solver.cpp:404]     Test net output #0: accuracy = 0.1525
I0830 13:30:19.344480 11353 solver.cpp:404]     Test net output #1: loss = 1.11555 (* 1 = 1.11555 loss)
I0830 13:30:19.360247 11353 solver.cpp:228] Iteration 41000, loss = 1.0997
I0830 13:30:19.360306 11353 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0830 13:30:19.360318 11353 sgd_solver.cpp:106] Iteration 41000, lr = 0.0433286
I0830 13:30:23.675009 11353 solver.cpp:228] Iteration 41100, loss = 1.09698
I0830 13:30:23.675076 11353 solver.cpp:244]     Train net output #0: loss = 1.09698 (* 1 = 1.09698 loss)
I0830 13:30:23.675082 11353 sgd_solver.cpp:106] Iteration 41100, lr = 0.0432754
I0830 13:30:27.985483 11353 solver.cpp:228] Iteration 41200, loss = 1.09374
I0830 13:30:27.985553 11353 solver.cpp:244]     Train net output #0: loss = 1.09374 (* 1 = 1.09374 loss)
I0830 13:30:27.985561 11353 sgd_solver.cpp:106] Iteration 41200, lr = 0.0432224
I0830 13:30:32.294529 11353 solver.cpp:228] Iteration 41300, loss = 1.10066
I0830 13:30:32.294595 11353 solver.cpp:244]     Train net output #0: loss = 1.10066 (* 1 = 1.10066 loss)
I0830 13:30:32.294600 11353 sgd_solver.cpp:106] Iteration 41300, lr = 0.0431695
I0830 13:30:36.607939 11353 solver.cpp:228] Iteration 41400, loss = 1.10163
I0830 13:30:36.608009 11353 solver.cpp:244]     Train net output #0: loss = 1.10163 (* 1 = 1.10163 loss)
I0830 13:30:36.608016 11353 sgd_solver.cpp:106] Iteration 41400, lr = 0.0431168
I0830 13:30:40.879205 11353 solver.cpp:337] Iteration 41500, Testing net (#0)
I0830 13:30:44.426013 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0830 13:30:44.426084 11353 solver.cpp:404]     Test net output #1: loss = 1.11112 (* 1 = 1.11112 loss)
I0830 13:30:44.441001 11353 solver.cpp:228] Iteration 41500, loss = 1.10199
I0830 13:30:44.441037 11353 solver.cpp:244]     Train net output #0: loss = 1.10199 (* 1 = 1.10199 loss)
I0830 13:30:44.441053 11353 sgd_solver.cpp:106] Iteration 41500, lr = 0.0430642
I0830 13:30:48.753883 11353 solver.cpp:228] Iteration 41600, loss = 1.10757
I0830 13:30:48.753924 11353 solver.cpp:244]     Train net output #0: loss = 1.10757 (* 1 = 1.10757 loss)
I0830 13:30:48.753929 11353 sgd_solver.cpp:106] Iteration 41600, lr = 0.0430117
I0830 13:30:53.066926 11353 solver.cpp:228] Iteration 41700, loss = 1.10583
I0830 13:30:53.066983 11353 solver.cpp:244]     Train net output #0: loss = 1.10583 (* 1 = 1.10583 loss)
I0830 13:30:53.066992 11353 sgd_solver.cpp:106] Iteration 41700, lr = 0.0429594
I0830 13:30:57.386381 11353 solver.cpp:228] Iteration 41800, loss = 1.09847
I0830 13:30:57.386425 11353 solver.cpp:244]     Train net output #0: loss = 1.09847 (* 1 = 1.09847 loss)
I0830 13:30:57.386430 11353 sgd_solver.cpp:106] Iteration 41800, lr = 0.0429073
I0830 13:31:01.713013 11353 solver.cpp:228] Iteration 41900, loss = 1.09768
I0830 13:31:01.713068 11353 solver.cpp:244]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0830 13:31:01.713073 11353 sgd_solver.cpp:106] Iteration 41900, lr = 0.0428553
I0830 13:31:05.983497 11353 solver.cpp:337] Iteration 42000, Testing net (#0)
I0830 13:31:07.918735 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:31:09.475064 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152625
I0830 13:31:09.475144 11353 solver.cpp:404]     Test net output #1: loss = 1.10412 (* 1 = 1.10412 loss)
I0830 13:31:09.490056 11353 solver.cpp:228] Iteration 42000, loss = 1.09757
I0830 13:31:09.490110 11353 solver.cpp:244]     Train net output #0: loss = 1.09757 (* 1 = 1.09757 loss)
I0830 13:31:09.490125 11353 sgd_solver.cpp:106] Iteration 42000, lr = 0.0428034
I0830 13:31:13.798848 11353 solver.cpp:228] Iteration 42100, loss = 1.10187
I0830 13:31:13.798890 11353 solver.cpp:244]     Train net output #0: loss = 1.10187 (* 1 = 1.10187 loss)
I0830 13:31:13.798895 11353 sgd_solver.cpp:106] Iteration 42100, lr = 0.0427517
I0830 13:31:18.113467 11353 solver.cpp:228] Iteration 42200, loss = 1.10677
I0830 13:31:18.113543 11353 solver.cpp:244]     Train net output #0: loss = 1.10677 (* 1 = 1.10677 loss)
I0830 13:31:18.113549 11353 sgd_solver.cpp:106] Iteration 42200, lr = 0.0427002
I0830 13:31:22.424559 11353 solver.cpp:228] Iteration 42300, loss = 1.09448
I0830 13:31:22.424628 11353 solver.cpp:244]     Train net output #0: loss = 1.09448 (* 1 = 1.09448 loss)
I0830 13:31:22.424633 11353 sgd_solver.cpp:106] Iteration 42300, lr = 0.0426488
I0830 13:31:26.748056 11353 solver.cpp:228] Iteration 42400, loss = 1.09447
I0830 13:31:26.748100 11353 solver.cpp:244]     Train net output #0: loss = 1.09447 (* 1 = 1.09447 loss)
I0830 13:31:26.748105 11353 sgd_solver.cpp:106] Iteration 42400, lr = 0.0425975
I0830 13:31:31.014473 11353 solver.cpp:337] Iteration 42500, Testing net (#0)
I0830 13:31:34.556177 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0830 13:31:34.556227 11353 solver.cpp:404]     Test net output #1: loss = 1.09659 (* 1 = 1.09659 loss)
I0830 13:31:34.571429 11353 solver.cpp:228] Iteration 42500, loss = 1.09804
I0830 13:31:34.571467 11353 solver.cpp:244]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0830 13:31:34.571478 11353 sgd_solver.cpp:106] Iteration 42500, lr = 0.0425464
I0830 13:31:38.893465 11353 solver.cpp:228] Iteration 42600, loss = 1.09455
I0830 13:31:38.893515 11353 solver.cpp:244]     Train net output #0: loss = 1.09455 (* 1 = 1.09455 loss)
I0830 13:31:38.893524 11353 sgd_solver.cpp:106] Iteration 42600, lr = 0.0424954
I0830 13:31:43.208899 11353 solver.cpp:228] Iteration 42700, loss = 1.09443
I0830 13:31:43.208943 11353 solver.cpp:244]     Train net output #0: loss = 1.09443 (* 1 = 1.09443 loss)
I0830 13:31:43.208948 11353 sgd_solver.cpp:106] Iteration 42700, lr = 0.0424445
I0830 13:31:47.524185 11353 solver.cpp:228] Iteration 42800, loss = 1.10416
I0830 13:31:47.524227 11353 solver.cpp:244]     Train net output #0: loss = 1.10416 (* 1 = 1.10416 loss)
I0830 13:31:47.524232 11353 sgd_solver.cpp:106] Iteration 42800, lr = 0.0423938
I0830 13:31:51.833314 11353 solver.cpp:228] Iteration 42900, loss = 1.09794
I0830 13:31:51.833365 11353 solver.cpp:244]     Train net output #0: loss = 1.09794 (* 1 = 1.09794 loss)
I0830 13:31:51.833374 11353 sgd_solver.cpp:106] Iteration 42900, lr = 0.0423433
I0830 13:31:56.101797 11353 solver.cpp:337] Iteration 43000, Testing net (#0)
I0830 13:31:59.477721 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0830 13:31:59.477782 11353 solver.cpp:404]     Test net output #1: loss = 1.0871 (* 1 = 1.0871 loss)
I0830 13:31:59.492586 11353 solver.cpp:228] Iteration 43000, loss = 1.09767
I0830 13:31:59.492624 11353 solver.cpp:244]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0830 13:31:59.492633 11353 sgd_solver.cpp:106] Iteration 43000, lr = 0.0422929
I0830 13:32:03.802495 11353 solver.cpp:228] Iteration 43100, loss = 1.10279
I0830 13:32:03.802533 11353 solver.cpp:244]     Train net output #0: loss = 1.10279 (* 1 = 1.10279 loss)
I0830 13:32:03.802538 11353 sgd_solver.cpp:106] Iteration 43100, lr = 0.0422426
I0830 13:32:08.113581 11353 solver.cpp:228] Iteration 43200, loss = 1.09699
I0830 13:32:08.113626 11353 solver.cpp:244]     Train net output #0: loss = 1.09699 (* 1 = 1.09699 loss)
I0830 13:32:08.113631 11353 sgd_solver.cpp:106] Iteration 43200, lr = 0.0421924
I0830 13:32:12.427355 11353 solver.cpp:228] Iteration 43300, loss = 1.09926
I0830 13:32:12.427398 11353 solver.cpp:244]     Train net output #0: loss = 1.09926 (* 1 = 1.09926 loss)
I0830 13:32:12.427403 11353 sgd_solver.cpp:106] Iteration 43300, lr = 0.0421424
I0830 13:32:16.738720 11353 solver.cpp:228] Iteration 43400, loss = 1.09749
I0830 13:32:16.738741 11353 solver.cpp:244]     Train net output #0: loss = 1.09749 (* 1 = 1.09749 loss)
I0830 13:32:16.738746 11353 sgd_solver.cpp:106] Iteration 43400, lr = 0.0420926
I0830 13:32:21.008095 11353 solver.cpp:337] Iteration 43500, Testing net (#0)
I0830 13:32:24.624013 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578708
I0830 13:32:24.624074 11353 solver.cpp:404]     Test net output #1: loss = 1.08879 (* 1 = 1.08879 loss)
I0830 13:32:24.639083 11353 solver.cpp:228] Iteration 43500, loss = 1.09778
I0830 13:32:24.639125 11353 solver.cpp:244]     Train net output #0: loss = 1.09778 (* 1 = 1.09778 loss)
I0830 13:32:24.639145 11353 sgd_solver.cpp:106] Iteration 43500, lr = 0.0420429
I0830 13:32:28.964681 11353 solver.cpp:228] Iteration 43600, loss = 1.1
I0830 13:32:28.964732 11353 solver.cpp:244]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0830 13:32:28.964741 11353 sgd_solver.cpp:106] Iteration 43600, lr = 0.0419933
I0830 13:32:33.279067 11353 solver.cpp:228] Iteration 43700, loss = 1.09815
I0830 13:32:33.279114 11353 solver.cpp:244]     Train net output #0: loss = 1.09815 (* 1 = 1.09815 loss)
I0830 13:32:33.279120 11353 sgd_solver.cpp:106] Iteration 43700, lr = 0.0419438
I0830 13:32:37.604403 11353 solver.cpp:228] Iteration 43800, loss = 1.10412
I0830 13:32:37.604454 11353 solver.cpp:244]     Train net output #0: loss = 1.10412 (* 1 = 1.10412 loss)
I0830 13:32:37.604460 11353 sgd_solver.cpp:106] Iteration 43800, lr = 0.0418945
I0830 13:32:41.919817 11353 solver.cpp:228] Iteration 43900, loss = 1.10312
I0830 13:32:41.919889 11353 solver.cpp:244]     Train net output #0: loss = 1.10312 (* 1 = 1.10312 loss)
I0830 13:32:41.919895 11353 sgd_solver.cpp:106] Iteration 43900, lr = 0.0418453
I0830 13:32:46.198796 11353 solver.cpp:337] Iteration 44000, Testing net (#0)
I0830 13:32:48.838994 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:32:49.790860 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0830 13:32:49.790915 11353 solver.cpp:404]     Test net output #1: loss = 1.10033 (* 1 = 1.10033 loss)
I0830 13:32:49.806430 11353 solver.cpp:228] Iteration 44000, loss = 1.10005
I0830 13:32:49.806493 11353 solver.cpp:244]     Train net output #0: loss = 1.10005 (* 1 = 1.10005 loss)
I0830 13:32:49.806511 11353 sgd_solver.cpp:106] Iteration 44000, lr = 0.0417963
I0830 13:32:54.127037 11353 solver.cpp:228] Iteration 44100, loss = 1.09586
I0830 13:32:54.127086 11353 solver.cpp:244]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0830 13:32:54.127092 11353 sgd_solver.cpp:106] Iteration 44100, lr = 0.0417474
I0830 13:32:58.438485 11353 solver.cpp:228] Iteration 44200, loss = 1.10282
I0830 13:32:58.438536 11353 solver.cpp:244]     Train net output #0: loss = 1.10282 (* 1 = 1.10282 loss)
I0830 13:32:58.438544 11353 sgd_solver.cpp:106] Iteration 44200, lr = 0.0416986
I0830 13:33:02.747799 11353 solver.cpp:228] Iteration 44300, loss = 1.09995
I0830 13:33:02.747851 11353 solver.cpp:244]     Train net output #0: loss = 1.09995 (* 1 = 1.09995 loss)
I0830 13:33:02.747856 11353 sgd_solver.cpp:106] Iteration 44300, lr = 0.0416499
I0830 13:33:07.069787 11353 solver.cpp:228] Iteration 44400, loss = 1.09938
I0830 13:33:07.069857 11353 solver.cpp:244]     Train net output #0: loss = 1.09938 (* 1 = 1.09938 loss)
I0830 13:33:07.069869 11353 sgd_solver.cpp:106] Iteration 44400, lr = 0.0416014
I0830 13:33:11.340728 11353 solver.cpp:337] Iteration 44500, Testing net (#0)
I0830 13:33:14.470425 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0830 13:33:14.470468 11353 solver.cpp:404]     Test net output #1: loss = 1.10878 (* 1 = 1.10878 loss)
I0830 13:33:14.485939 11353 solver.cpp:228] Iteration 44500, loss = 1.09671
I0830 13:33:14.486017 11353 solver.cpp:244]     Train net output #0: loss = 1.09671 (* 1 = 1.09671 loss)
I0830 13:33:14.486032 11353 sgd_solver.cpp:106] Iteration 44500, lr = 0.041553
I0830 13:33:18.806833 11353 solver.cpp:228] Iteration 44600, loss = 1.10031
I0830 13:33:18.806905 11353 solver.cpp:244]     Train net output #0: loss = 1.10031 (* 1 = 1.10031 loss)
I0830 13:33:18.806910 11353 sgd_solver.cpp:106] Iteration 44600, lr = 0.0415048
I0830 13:33:23.126494 11353 solver.cpp:228] Iteration 44700, loss = 1.09892
I0830 13:33:23.126567 11353 solver.cpp:244]     Train net output #0: loss = 1.09892 (* 1 = 1.09892 loss)
I0830 13:33:23.126572 11353 sgd_solver.cpp:106] Iteration 44700, lr = 0.0414567
I0830 13:33:27.440840 11353 solver.cpp:228] Iteration 44800, loss = 1.10054
I0830 13:33:27.440898 11353 solver.cpp:244]     Train net output #0: loss = 1.10054 (* 1 = 1.10054 loss)
I0830 13:33:27.440906 11353 sgd_solver.cpp:106] Iteration 44800, lr = 0.0414087
I0830 13:33:31.752116 11353 solver.cpp:228] Iteration 44900, loss = 1.09623
I0830 13:33:31.752184 11353 solver.cpp:244]     Train net output #0: loss = 1.09623 (* 1 = 1.09623 loss)
I0830 13:33:31.752190 11353 sgd_solver.cpp:106] Iteration 44900, lr = 0.0413608
I0830 13:33:36.029697 11353 solver.cpp:337] Iteration 45000, Testing net (#0)
I0830 13:33:39.333160 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152083
I0830 13:33:39.333253 11353 solver.cpp:404]     Test net output #1: loss = 1.11416 (* 1 = 1.11416 loss)
I0830 13:33:39.348628 11353 solver.cpp:228] Iteration 45000, loss = 1.10366
I0830 13:33:39.348685 11353 solver.cpp:244]     Train net output #0: loss = 1.10366 (* 1 = 1.10366 loss)
I0830 13:33:39.348700 11353 sgd_solver.cpp:106] Iteration 45000, lr = 0.0413131
I0830 13:33:43.667887 11353 solver.cpp:228] Iteration 45100, loss = 1.10004
I0830 13:33:43.667934 11353 solver.cpp:244]     Train net output #0: loss = 1.10004 (* 1 = 1.10004 loss)
I0830 13:33:43.667942 11353 sgd_solver.cpp:106] Iteration 45100, lr = 0.0412655
I0830 13:33:47.985986 11353 solver.cpp:228] Iteration 45200, loss = 1.09551
I0830 13:33:47.986057 11353 solver.cpp:244]     Train net output #0: loss = 1.09551 (* 1 = 1.09551 loss)
I0830 13:33:47.986063 11353 sgd_solver.cpp:106] Iteration 45200, lr = 0.041218
I0830 13:33:52.312160 11353 solver.cpp:228] Iteration 45300, loss = 1.09961
I0830 13:33:52.312228 11353 solver.cpp:244]     Train net output #0: loss = 1.09961 (* 1 = 1.09961 loss)
I0830 13:33:52.312235 11353 sgd_solver.cpp:106] Iteration 45300, lr = 0.0411706
I0830 13:33:56.623674 11353 solver.cpp:228] Iteration 45400, loss = 1.09564
I0830 13:33:56.623751 11353 solver.cpp:244]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0830 13:33:56.623757 11353 sgd_solver.cpp:106] Iteration 45400, lr = 0.0411234
I0830 13:34:00.892029 11353 solver.cpp:337] Iteration 45500, Testing net (#0)
I0830 13:34:04.217644 11353 solver.cpp:404]     Test net output #0: accuracy = 0.151833
I0830 13:34:04.217775 11353 solver.cpp:404]     Test net output #1: loss = 1.10995 (* 1 = 1.10995 loss)
I0830 13:34:04.233397 11353 solver.cpp:228] Iteration 45500, loss = 1.09317
I0830 13:34:04.233480 11353 solver.cpp:244]     Train net output #0: loss = 1.09317 (* 1 = 1.09317 loss)
I0830 13:34:04.233495 11353 sgd_solver.cpp:106] Iteration 45500, lr = 0.0410763
I0830 13:34:08.545132 11353 solver.cpp:228] Iteration 45600, loss = 1.1035
I0830 13:34:08.545176 11353 solver.cpp:244]     Train net output #0: loss = 1.1035 (* 1 = 1.1035 loss)
I0830 13:34:08.545181 11353 sgd_solver.cpp:106] Iteration 45600, lr = 0.0410293
I0830 13:34:12.856801 11353 solver.cpp:228] Iteration 45700, loss = 1.0949
I0830 13:34:12.856855 11353 solver.cpp:244]     Train net output #0: loss = 1.0949 (* 1 = 1.0949 loss)
I0830 13:34:12.856860 11353 sgd_solver.cpp:106] Iteration 45700, lr = 0.0409825
I0830 13:34:17.166527 11353 solver.cpp:228] Iteration 45800, loss = 1.09567
I0830 13:34:17.166571 11353 solver.cpp:244]     Train net output #0: loss = 1.09567 (* 1 = 1.09567 loss)
I0830 13:34:17.166576 11353 sgd_solver.cpp:106] Iteration 45800, lr = 0.0409358
I0830 13:34:21.477383 11353 solver.cpp:228] Iteration 45900, loss = 1.116
I0830 13:34:21.477453 11353 solver.cpp:244]     Train net output #0: loss = 1.116 (* 1 = 1.116 loss)
I0830 13:34:21.477460 11353 sgd_solver.cpp:106] Iteration 45900, lr = 0.0408892
I0830 13:34:25.753235 11353 solver.cpp:337] Iteration 46000, Testing net (#0)
I0830 13:34:29.167743 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:34:29.167798 11353 solver.cpp:404]     Test net output #1: loss = 1.10841 (* 1 = 1.10841 loss)
I0830 13:34:29.182740 11353 solver.cpp:228] Iteration 46000, loss = 1.10276
I0830 13:34:29.182772 11353 solver.cpp:244]     Train net output #0: loss = 1.10276 (* 1 = 1.10276 loss)
I0830 13:34:29.182781 11353 sgd_solver.cpp:106] Iteration 46000, lr = 0.0408427
I0830 13:34:33.494851 11353 solver.cpp:228] Iteration 46100, loss = 1.0963
I0830 13:34:33.494910 11353 solver.cpp:244]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0830 13:34:33.494916 11353 sgd_solver.cpp:106] Iteration 46100, lr = 0.0407964
I0830 13:34:37.814340 11353 solver.cpp:228] Iteration 46200, loss = 1.09702
I0830 13:34:37.814385 11353 solver.cpp:244]     Train net output #0: loss = 1.09702 (* 1 = 1.09702 loss)
I0830 13:34:37.814391 11353 sgd_solver.cpp:106] Iteration 46200, lr = 0.0407501
I0830 13:34:42.122421 11353 solver.cpp:228] Iteration 46300, loss = 1.10107
I0830 13:34:42.122464 11353 solver.cpp:244]     Train net output #0: loss = 1.10107 (* 1 = 1.10107 loss)
I0830 13:34:42.122469 11353 sgd_solver.cpp:106] Iteration 46300, lr = 0.040704
I0830 13:34:46.439383 11353 solver.cpp:228] Iteration 46400, loss = 1.10041
I0830 13:34:46.439431 11353 solver.cpp:244]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0830 13:34:46.439437 11353 sgd_solver.cpp:106] Iteration 46400, lr = 0.040658
I0830 13:34:50.707082 11353 solver.cpp:337] Iteration 46500, Testing net (#0)
I0830 13:34:53.594471 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:34:54.050004 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0830 13:34:54.050041 11353 solver.cpp:404]     Test net output #1: loss = 1.10785 (* 1 = 1.10785 loss)
I0830 13:34:54.065407 11353 solver.cpp:228] Iteration 46500, loss = 1.10421
I0830 13:34:54.065466 11353 solver.cpp:244]     Train net output #0: loss = 1.10421 (* 1 = 1.10421 loss)
I0830 13:34:54.065482 11353 sgd_solver.cpp:106] Iteration 46500, lr = 0.0406122
I0830 13:34:58.382761 11353 solver.cpp:228] Iteration 46600, loss = 1.10168
I0830 13:34:58.382808 11353 solver.cpp:244]     Train net output #0: loss = 1.10168 (* 1 = 1.10168 loss)
I0830 13:34:58.382814 11353 sgd_solver.cpp:106] Iteration 46600, lr = 0.0405664
I0830 13:35:02.697379 11353 solver.cpp:228] Iteration 46700, loss = 1.09378
I0830 13:35:02.697424 11353 solver.cpp:244]     Train net output #0: loss = 1.09378 (* 1 = 1.09378 loss)
I0830 13:35:02.697429 11353 sgd_solver.cpp:106] Iteration 46700, lr = 0.0405208
I0830 13:35:07.011283 11353 solver.cpp:228] Iteration 46800, loss = 1.09665
I0830 13:35:07.011327 11353 solver.cpp:244]     Train net output #0: loss = 1.09665 (* 1 = 1.09665 loss)
I0830 13:35:07.011332 11353 sgd_solver.cpp:106] Iteration 46800, lr = 0.0404753
I0830 13:35:11.322589 11353 solver.cpp:228] Iteration 46900, loss = 1.09525
I0830 13:35:11.322639 11353 solver.cpp:244]     Train net output #0: loss = 1.09525 (* 1 = 1.09525 loss)
I0830 13:35:11.322645 11353 sgd_solver.cpp:106] Iteration 46900, lr = 0.0404299
I0830 13:35:15.595983 11353 solver.cpp:337] Iteration 47000, Testing net (#0)
I0830 13:35:19.133887 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:35:19.134011 11353 solver.cpp:404]     Test net output #1: loss = 1.11385 (* 1 = 1.11385 loss)
I0830 13:35:19.149181 11353 solver.cpp:228] Iteration 47000, loss = 1.09937
I0830 13:35:19.149242 11353 solver.cpp:244]     Train net output #0: loss = 1.09937 (* 1 = 1.09937 loss)
I0830 13:35:19.149256 11353 sgd_solver.cpp:106] Iteration 47000, lr = 0.0403847
I0830 13:35:23.468801 11353 solver.cpp:228] Iteration 47100, loss = 1.09661
I0830 13:35:23.468874 11353 solver.cpp:244]     Train net output #0: loss = 1.09661 (* 1 = 1.09661 loss)
I0830 13:35:23.468880 11353 sgd_solver.cpp:106] Iteration 47100, lr = 0.0403395
I0830 13:35:27.792451 11353 solver.cpp:228] Iteration 47200, loss = 1.09826
I0830 13:35:27.792511 11353 solver.cpp:244]     Train net output #0: loss = 1.09826 (* 1 = 1.09826 loss)
I0830 13:35:27.792517 11353 sgd_solver.cpp:106] Iteration 47200, lr = 0.0402945
I0830 13:35:32.107971 11353 solver.cpp:228] Iteration 47300, loss = 1.10076
I0830 13:35:32.108016 11353 solver.cpp:244]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0830 13:35:32.108021 11353 sgd_solver.cpp:106] Iteration 47300, lr = 0.0402496
I0830 13:35:36.421447 11353 solver.cpp:228] Iteration 47400, loss = 1.10263
I0830 13:35:36.421494 11353 solver.cpp:244]     Train net output #0: loss = 1.10263 (* 1 = 1.10263 loss)
I0830 13:35:36.421499 11353 sgd_solver.cpp:106] Iteration 47400, lr = 0.0402048
I0830 13:35:40.701509 11353 solver.cpp:337] Iteration 47500, Testing net (#0)
I0830 13:35:44.148363 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0830 13:35:44.148437 11353 solver.cpp:404]     Test net output #1: loss = 1.11717 (* 1 = 1.11717 loss)
I0830 13:35:44.163832 11353 solver.cpp:228] Iteration 47500, loss = 1.09834
I0830 13:35:44.163866 11353 solver.cpp:244]     Train net output #0: loss = 1.09834 (* 1 = 1.09834 loss)
I0830 13:35:44.163877 11353 sgd_solver.cpp:106] Iteration 47500, lr = 0.0401601
I0830 13:35:48.473697 11353 solver.cpp:228] Iteration 47600, loss = 1.0989
I0830 13:35:48.473739 11353 solver.cpp:244]     Train net output #0: loss = 1.0989 (* 1 = 1.0989 loss)
I0830 13:35:48.473745 11353 sgd_solver.cpp:106] Iteration 47600, lr = 0.0401155
I0830 13:35:52.789407 11353 solver.cpp:228] Iteration 47700, loss = 1.09815
I0830 13:35:52.789427 11353 solver.cpp:244]     Train net output #0: loss = 1.09815 (* 1 = 1.09815 loss)
I0830 13:35:52.789430 11353 sgd_solver.cpp:106] Iteration 47700, lr = 0.0400711
I0830 13:35:57.112674 11353 solver.cpp:228] Iteration 47800, loss = 1.09934
I0830 13:35:57.112745 11353 solver.cpp:244]     Train net output #0: loss = 1.09934 (* 1 = 1.09934 loss)
I0830 13:35:57.112751 11353 sgd_solver.cpp:106] Iteration 47800, lr = 0.0400267
I0830 13:36:01.437875 11353 solver.cpp:228] Iteration 47900, loss = 1.10026
I0830 13:36:01.437919 11353 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0830 13:36:01.437925 11353 sgd_solver.cpp:106] Iteration 47900, lr = 0.0399825
I0830 13:36:05.710263 11353 solver.cpp:337] Iteration 48000, Testing net (#0)
I0830 13:36:09.039896 11353 solver.cpp:404]     Test net output #0: accuracy = 0.26925
I0830 13:36:09.039958 11353 solver.cpp:404]     Test net output #1: loss = 1.1202 (* 1 = 1.1202 loss)
I0830 13:36:09.054728 11353 solver.cpp:228] Iteration 48000, loss = 1.10054
I0830 13:36:09.054765 11353 solver.cpp:244]     Train net output #0: loss = 1.10054 (* 1 = 1.10054 loss)
I0830 13:36:09.054775 11353 sgd_solver.cpp:106] Iteration 48000, lr = 0.0399384
I0830 13:36:13.367547 11353 solver.cpp:228] Iteration 48100, loss = 1.11055
I0830 13:36:13.367568 11353 solver.cpp:244]     Train net output #0: loss = 1.11055 (* 1 = 1.11055 loss)
I0830 13:36:13.367573 11353 sgd_solver.cpp:106] Iteration 48100, lr = 0.0398944
I0830 13:36:17.681730 11353 solver.cpp:228] Iteration 48200, loss = 1.10166
I0830 13:36:17.681749 11353 solver.cpp:244]     Train net output #0: loss = 1.10166 (* 1 = 1.10166 loss)
I0830 13:36:17.681754 11353 sgd_solver.cpp:106] Iteration 48200, lr = 0.0398505
I0830 13:36:21.996100 11353 solver.cpp:228] Iteration 48300, loss = 1.09809
I0830 13:36:21.996120 11353 solver.cpp:244]     Train net output #0: loss = 1.09809 (* 1 = 1.09809 loss)
I0830 13:36:21.996125 11353 sgd_solver.cpp:106] Iteration 48300, lr = 0.0398068
I0830 13:36:26.307770 11353 solver.cpp:228] Iteration 48400, loss = 1.09839
I0830 13:36:26.307790 11353 solver.cpp:244]     Train net output #0: loss = 1.09839 (* 1 = 1.09839 loss)
I0830 13:36:26.307796 11353 sgd_solver.cpp:106] Iteration 48400, lr = 0.0397631
I0830 13:36:30.577605 11353 solver.cpp:337] Iteration 48500, Testing net (#0)
I0830 13:36:33.867100 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0830 13:36:33.867146 11353 solver.cpp:404]     Test net output #1: loss = 1.11089 (* 1 = 1.11089 loss)
I0830 13:36:33.881361 11353 solver.cpp:228] Iteration 48500, loss = 1.10238
I0830 13:36:33.881408 11353 solver.cpp:244]     Train net output #0: loss = 1.10238 (* 1 = 1.10238 loss)
I0830 13:36:33.881420 11353 sgd_solver.cpp:106] Iteration 48500, lr = 0.0397196
I0830 13:36:38.199318 11353 solver.cpp:228] Iteration 48600, loss = 1.09954
I0830 13:36:38.199385 11353 solver.cpp:244]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0830 13:36:38.199398 11353 sgd_solver.cpp:106] Iteration 48600, lr = 0.0396761
I0830 13:36:42.514406 11353 solver.cpp:228] Iteration 48700, loss = 1.10062
I0830 13:36:42.514463 11353 solver.cpp:244]     Train net output #0: loss = 1.10062 (* 1 = 1.10062 loss)
I0830 13:36:42.514472 11353 sgd_solver.cpp:106] Iteration 48700, lr = 0.0396328
I0830 13:36:46.825923 11353 solver.cpp:228] Iteration 48800, loss = 1.09776
I0830 13:36:46.825948 11353 solver.cpp:244]     Train net output #0: loss = 1.09776 (* 1 = 1.09776 loss)
I0830 13:36:46.825953 11353 sgd_solver.cpp:106] Iteration 48800, lr = 0.0395896
I0830 13:36:51.135880 11353 solver.cpp:228] Iteration 48900, loss = 1.10286
I0830 13:36:51.135900 11353 solver.cpp:244]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0830 13:36:51.135905 11353 sgd_solver.cpp:106] Iteration 48900, lr = 0.0395465
I0830 13:36:55.408738 11353 solver.cpp:337] Iteration 49000, Testing net (#0)
I0830 13:36:58.777101 11353 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0830 13:36:58.777173 11353 solver.cpp:404]     Test net output #1: loss = 1.09301 (* 1 = 1.09301 loss)
I0830 13:36:58.792189 11353 solver.cpp:228] Iteration 49000, loss = 1.09851
I0830 13:36:58.792243 11353 solver.cpp:244]     Train net output #0: loss = 1.09851 (* 1 = 1.09851 loss)
I0830 13:36:58.792256 11353 sgd_solver.cpp:106] Iteration 49000, lr = 0.0395035
I0830 13:37:03.104845 11353 solver.cpp:228] Iteration 49100, loss = 1.09922
I0830 13:37:03.104887 11353 solver.cpp:244]     Train net output #0: loss = 1.09922 (* 1 = 1.09922 loss)
I0830 13:37:03.104893 11353 sgd_solver.cpp:106] Iteration 49100, lr = 0.0394606
I0830 13:37:07.414504 11353 solver.cpp:228] Iteration 49200, loss = 1.0993
I0830 13:37:07.414525 11353 solver.cpp:244]     Train net output #0: loss = 1.0993 (* 1 = 1.0993 loss)
I0830 13:37:07.414530 11353 sgd_solver.cpp:106] Iteration 49200, lr = 0.0394178
I0830 13:37:11.727737 11353 solver.cpp:228] Iteration 49300, loss = 1.10266
I0830 13:37:11.727794 11353 solver.cpp:244]     Train net output #0: loss = 1.10266 (* 1 = 1.10266 loss)
I0830 13:37:11.727799 11353 sgd_solver.cpp:106] Iteration 49300, lr = 0.0393752
I0830 13:37:16.037467 11353 solver.cpp:228] Iteration 49400, loss = 1.0986
I0830 13:37:16.037546 11353 solver.cpp:244]     Train net output #0: loss = 1.0986 (* 1 = 1.0986 loss)
I0830 13:37:16.037555 11353 sgd_solver.cpp:106] Iteration 49400, lr = 0.0393326
I0830 13:37:17.637400 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:37:20.308091 11353 solver.cpp:337] Iteration 49500, Testing net (#0)
I0830 13:37:23.649179 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0830 13:37:23.649289 11353 solver.cpp:404]     Test net output #1: loss = 1.08345 (* 1 = 1.08345 loss)
I0830 13:37:23.664984 11353 solver.cpp:228] Iteration 49500, loss = 1.09693
I0830 13:37:23.665030 11353 solver.cpp:244]     Train net output #0: loss = 1.09693 (* 1 = 1.09693 loss)
I0830 13:37:23.665038 11353 sgd_solver.cpp:106] Iteration 49500, lr = 0.0392902
I0830 13:37:27.983669 11353 solver.cpp:228] Iteration 49600, loss = 1.09816
I0830 13:37:27.983747 11353 solver.cpp:244]     Train net output #0: loss = 1.09816 (* 1 = 1.09816 loss)
I0830 13:37:27.983753 11353 sgd_solver.cpp:106] Iteration 49600, lr = 0.0392478
I0830 13:37:32.294545 11353 solver.cpp:228] Iteration 49700, loss = 1.10182
I0830 13:37:32.294610 11353 solver.cpp:244]     Train net output #0: loss = 1.10182 (* 1 = 1.10182 loss)
I0830 13:37:32.294616 11353 sgd_solver.cpp:106] Iteration 49700, lr = 0.0392056
I0830 13:37:36.603629 11353 solver.cpp:228] Iteration 49800, loss = 1.09198
I0830 13:37:36.603649 11353 solver.cpp:244]     Train net output #0: loss = 1.09198 (* 1 = 1.09198 loss)
I0830 13:37:36.603655 11353 sgd_solver.cpp:106] Iteration 49800, lr = 0.0391634
I0830 13:37:40.913195 11353 solver.cpp:228] Iteration 49900, loss = 1.09952
I0830 13:37:40.913239 11353 solver.cpp:244]     Train net output #0: loss = 1.09952 (* 1 = 1.09952 loss)
I0830 13:37:40.913244 11353 sgd_solver.cpp:106] Iteration 49900, lr = 0.0391214
I0830 13:37:45.181113 11353 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_50000.caffemodel
I0830 13:37:45.817844 11353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1_iter_50000.solverstate
I0830 13:37:45.992676 11353 solver.cpp:337] Iteration 50000, Testing net (#0)
I0830 13:37:49.412317 11353 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0830 13:37:49.412431 11353 solver.cpp:404]     Test net output #1: loss = 1.07784 (* 1 = 1.07784 loss)
I0830 13:37:49.428069 11353 solver.cpp:228] Iteration 50000, loss = 1.09373
I0830 13:37:49.428112 11353 solver.cpp:244]     Train net output #0: loss = 1.09373 (* 1 = 1.09373 loss)
I0830 13:37:49.428122 11353 sgd_solver.cpp:106] Iteration 50000, lr = 0.0390795
I0830 13:37:53.741480 11353 solver.cpp:228] Iteration 50100, loss = 1.09458
I0830 13:37:53.741531 11353 solver.cpp:244]     Train net output #0: loss = 1.09458 (* 1 = 1.09458 loss)
I0830 13:37:53.741544 11353 sgd_solver.cpp:106] Iteration 50100, lr = 0.0390377
I0830 13:37:58.051823 11353 solver.cpp:228] Iteration 50200, loss = 1.10217
I0830 13:37:58.051844 11353 solver.cpp:244]     Train net output #0: loss = 1.10217 (* 1 = 1.10217 loss)
I0830 13:37:58.051851 11353 sgd_solver.cpp:106] Iteration 50200, lr = 0.038996
I0830 13:38:02.363409 11353 solver.cpp:228] Iteration 50300, loss = 1.10456
I0830 13:38:02.363452 11353 solver.cpp:244]     Train net output #0: loss = 1.10456 (* 1 = 1.10456 loss)
I0830 13:38:02.363457 11353 sgd_solver.cpp:106] Iteration 50300, lr = 0.0389544
I0830 13:38:06.672911 11353 solver.cpp:228] Iteration 50400, loss = 1.09575
I0830 13:38:06.672956 11353 solver.cpp:244]     Train net output #0: loss = 1.09575 (* 1 = 1.09575 loss)
I0830 13:38:06.672961 11353 sgd_solver.cpp:106] Iteration 50400, lr = 0.0389128
I0830 13:38:10.949882 11353 solver.cpp:337] Iteration 50500, Testing net (#0)
I0830 13:38:14.305369 11353 solver.cpp:404]     Test net output #0: accuracy = 0.577958
I0830 13:38:14.305482 11353 solver.cpp:404]     Test net output #1: loss = 1.08621 (* 1 = 1.08621 loss)
I0830 13:38:14.320245 11353 solver.cpp:228] Iteration 50500, loss = 1.09576
I0830 13:38:14.320289 11353 solver.cpp:244]     Train net output #0: loss = 1.09576 (* 1 = 1.09576 loss)
I0830 13:38:14.320298 11353 sgd_solver.cpp:106] Iteration 50500, lr = 0.0388714
I0830 13:38:18.634845 11353 solver.cpp:228] Iteration 50600, loss = 1.10209
I0830 13:38:18.634892 11353 solver.cpp:244]     Train net output #0: loss = 1.10209 (* 1 = 1.10209 loss)
I0830 13:38:18.634898 11353 sgd_solver.cpp:106] Iteration 50600, lr = 0.0388301
I0830 13:38:22.950153 11353 solver.cpp:228] Iteration 50700, loss = 1.09648
I0830 13:38:22.950197 11353 solver.cpp:244]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0830 13:38:22.950202 11353 sgd_solver.cpp:106] Iteration 50700, lr = 0.0387889
I0830 13:38:27.266052 11353 solver.cpp:228] Iteration 50800, loss = 1.09562
I0830 13:38:27.266096 11353 solver.cpp:244]     Train net output #0: loss = 1.09562 (* 1 = 1.09562 loss)
I0830 13:38:27.266103 11353 sgd_solver.cpp:106] Iteration 50800, lr = 0.0387478
I0830 13:38:31.587874 11353 solver.cpp:228] Iteration 50900, loss = 1.10485
I0830 13:38:31.587919 11353 solver.cpp:244]     Train net output #0: loss = 1.10485 (* 1 = 1.10485 loss)
I0830 13:38:31.587924 11353 sgd_solver.cpp:106] Iteration 50900, lr = 0.0387069
I0830 13:38:35.866660 11353 solver.cpp:337] Iteration 51000, Testing net (#0)
I0830 13:38:38.945686 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0830 13:38:38.945758 11353 solver.cpp:404]     Test net output #1: loss = 1.09853 (* 1 = 1.09853 loss)
I0830 13:38:38.962260 11353 solver.cpp:228] Iteration 51000, loss = 1.09576
I0830 13:38:38.962303 11353 solver.cpp:244]     Train net output #0: loss = 1.09576 (* 1 = 1.09576 loss)
I0830 13:38:38.962314 11353 sgd_solver.cpp:106] Iteration 51000, lr = 0.038666
I0830 13:38:43.281805 11353 solver.cpp:228] Iteration 51100, loss = 1.09807
I0830 13:38:43.281867 11353 solver.cpp:244]     Train net output #0: loss = 1.09807 (* 1 = 1.09807 loss)
I0830 13:38:43.281873 11353 sgd_solver.cpp:106] Iteration 51100, lr = 0.0386252
I0830 13:38:47.593219 11353 solver.cpp:228] Iteration 51200, loss = 1.10047
I0830 13:38:47.593240 11353 solver.cpp:244]     Train net output #0: loss = 1.10047 (* 1 = 1.10047 loss)
I0830 13:38:47.593245 11353 sgd_solver.cpp:106] Iteration 51200, lr = 0.0385845
I0830 13:38:51.902482 11353 solver.cpp:228] Iteration 51300, loss = 1.10587
I0830 13:38:51.902503 11353 solver.cpp:244]     Train net output #0: loss = 1.10587 (* 1 = 1.10587 loss)
I0830 13:38:51.902508 11353 sgd_solver.cpp:106] Iteration 51300, lr = 0.0385439
I0830 13:38:56.213052 11353 solver.cpp:228] Iteration 51400, loss = 1.09461
I0830 13:38:56.213071 11353 solver.cpp:244]     Train net output #0: loss = 1.09461 (* 1 = 1.09461 loss)
I0830 13:38:56.213075 11353 sgd_solver.cpp:106] Iteration 51400, lr = 0.0385034
I0830 13:39:00.484122 11353 solver.cpp:337] Iteration 51500, Testing net (#0)
I0830 13:39:04.121433 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0830 13:39:04.121506 11353 solver.cpp:404]     Test net output #1: loss = 1.11282 (* 1 = 1.11282 loss)
I0830 13:39:04.136416 11353 solver.cpp:228] Iteration 51500, loss = 1.09783
I0830 13:39:04.136467 11353 solver.cpp:244]     Train net output #0: loss = 1.09783 (* 1 = 1.09783 loss)
I0830 13:39:04.136479 11353 sgd_solver.cpp:106] Iteration 51500, lr = 0.038463
I0830 13:39:08.449201 11353 solver.cpp:228] Iteration 51600, loss = 1.09981
I0830 13:39:08.449270 11353 solver.cpp:244]     Train net output #0: loss = 1.09981 (* 1 = 1.09981 loss)
I0830 13:39:08.449275 11353 sgd_solver.cpp:106] Iteration 51600, lr = 0.0384227
I0830 13:39:12.761497 11353 solver.cpp:228] Iteration 51700, loss = 1.10299
I0830 13:39:12.761548 11353 solver.cpp:244]     Train net output #0: loss = 1.10299 (* 1 = 1.10299 loss)
I0830 13:39:12.761554 11353 sgd_solver.cpp:106] Iteration 51700, lr = 0.0383825
I0830 13:39:16.950259 11353 blocking_queue.cpp:50] Data layer prefetch queue empty
I0830 13:39:17.080090 11353 solver.cpp:228] Iteration 51800, loss = 1.09838
I0830 13:39:17.080157 11353 solver.cpp:244]     Train net output #0: loss = 1.09838 (* 1 = 1.09838 loss)
I0830 13:39:17.080163 11353 sgd_solver.cpp:106] Iteration 51800, lr = 0.0383424
I0830 13:39:21.396224 11353 solver.cpp:228] Iteration 51900, loss = 1.09813
I0830 13:39:21.396287 11353 solver.cpp:244]     Train net output #0: loss = 1.09813 (* 1 = 1.09813 loss)
I0830 13:39:21.396293 11353 sgd_solver.cpp:106] Iteration 51900, lr = 0.0383024
I0830 13:39:25.671628 11353 solver.cpp:337] Iteration 52000, Testing net (#0)
I0830 13:39:28.974187 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0830 13:39:28.974232 11353 solver.cpp:404]     Test net output #1: loss = 1.12158 (* 1 = 1.12158 loss)
I0830 13:39:28.989437 11353 solver.cpp:228] Iteration 52000, loss = 1.10296
I0830 13:39:28.989476 11353 solver.cpp:244]     Train net output #0: loss = 1.10296 (* 1 = 1.10296 loss)
I0830 13:39:28.989488 11353 sgd_solver.cpp:106] Iteration 52000, lr = 0.0382625
I0830 13:39:33.315457 11353 solver.cpp:228] Iteration 52100, loss = 1.09801
I0830 13:39:33.315505 11353 solver.cpp:244]     Train net output #0: loss = 1.09801 (* 1 = 1.09801 loss)
I0830 13:39:33.315511 11353 sgd_solver.cpp:106] Iteration 52100, lr = 0.0382227
I0830 13:39:37.629776 11353 solver.cpp:228] Iteration 52200, loss = 1.09822
I0830 13:39:37.629796 11353 solver.cpp:244]     Train net output #0: loss = 1.09822 (* 1 = 1.09822 loss)
I0830 13:39:37.629801 11353 sgd_solver.cpp:106] Iteration 52200, lr = 0.038183
I0830 13:39:41.957120 11353 solver.cpp:228] Iteration 52300, loss = 1.10052
I0830 13:39:41.957172 11353 solver.cpp:244]     Train net output #0: loss = 1.10052 (* 1 = 1.10052 loss)
I0830 13:39:41.957180 11353 sgd_solver.cpp:106] Iteration 52300, lr = 0.0381433
I0830 13:39:46.277115 11353 solver.cpp:228] Iteration 52400, loss = 1.10938
I0830 13:39:46.277159 11353 solver.cpp:244]     Train net output #0: loss = 1.10938 (* 1 = 1.10938 loss)
I0830 13:39:46.277164 11353 sgd_solver.cpp:106] Iteration 52400, lr = 0.0381038
I0830 13:39:50.544791 11353 solver.cpp:337] Iteration 52500, Testing net (#0)
I0830 13:39:54.036783 11353 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0830 13:39:54.036831 11353 solver.cpp:404]     Test net output #1: loss = 1.12169 (* 1 = 1.12169 loss)
I0830 13:39:54.051558 11353 solver.cpp:228] Iteration 52500, loss = 1.10413
I0830 13:39:54.051597 11353 solver.cpp:244]     Train net output #0: loss = 1.10413 (* 1 = 1.10413 loss)
I0830 13:39:54.051607 11353 sgd_solver.cpp:106] Iteration 52500, lr = 0.0380644
I0830 13:39:58.367431 11353 solver.cpp:228] Iteration 52600, loss = 1.09784
I0830 13:39:58.367494 11353 solver.cpp:244]     Train net output #0: loss = 1.09784 (* 1 = 1.09784 loss)
I0830 13:39:58.367501 11353 sgd_solver.cpp:106] Iteration 52600, lr = 0.0380251
I0830 13:40:02.690433 11353 solver.cpp:228] Iteration 52700, loss = 1.09792
I0830 13:40:02.690477 11353 solver.cpp:244]     Train net output #0: loss = 1.09792 (* 1 = 1.09792 loss)
I0830 13:40:02.690484 11353 sgd_solver.cpp:106] Iteration 52700, lr = 0.0379858
I0830 13:40:07.006866 11353 solver.cpp:228] Iteration 52800, loss = 1.107
I0830 13:40:07.006947 11353 solver.cpp:244]     Train net output #0: loss = 1.107 (* 1 = 1.107 loss)
I0830 13:40:07.006956 11353 sgd_solver.cpp:106] Iteration 52800, lr = 0.0379467
I0830 13:40:11.318779 11353 solver.cpp:228] Iteration 52900, loss = 1.1011
I0830 13:40:11.318819 11353 solver.cpp:244]     Train net output #0: loss = 1.1011 (* 1 = 1.1011 loss)
I0830 13:40:11.318823 11353 sgd_solver.cpp:106] Iteration 52900, lr = 0.0379076
I0830 13:40:15.591065 11353 solver.cpp:337] Iteration 53000, Testing net (#0)
I0830 13:40:18.922673 11353 solver.cpp:404]     Test net output #0: accuracy = 0.26925
I0830 13:40:18.922732 11353 solver.cpp:404]     Test net output #1: loss = 1.11169 (* 1 = 1.11169 loss)
I0830 13:40:18.937309 11353 solver.cpp:228] Iteration 53000, loss = 1.09651
I0830 13:40:18.937347 11353 solver.cpp:244]     Train net output #0: loss = 1.09651 (* 1 = 1.09651 loss)
I0830 13:40:18.937361 11353 sgd_solver.cpp:106] Iteration 53000, lr = 0.0378687
I0830 13:40:23.252343 11353 solver.cpp:228] Iteration 53100, loss = 1.09855
I0830 13:40:23.252393 11353 solver.cpp:244]     Train net output #0: loss = 1.09855 (* 1 = 1.09855 loss)
I0830 13:40:23.252399 11353 sgd_solver.cpp:106] Iteration 53100, lr = 0.0378298
I0830 13:40:27.563004 11353 solver.cpp:228] Iteration 53200, loss = 1.10291
I0830 13:40:27.563060 11353 solver.cpp:244]     Train net output #0: loss = 1.10291 (* 1 = 1.10291 loss)
I0830 13:40:27.563071 11353 sgd_solver.cpp:106] Iteration 53200, lr = 0.0377911
I0830 13:40:31.871204 11353 solver.cpp:228] Iteration 53300, loss = 1.09951
I0830 13:40:31.871279 11353 solver.cpp:244]     Train net output #0: loss = 1.09951 (* 1 = 1.09951 loss)
I0830 13:40:31.871285 11353 sgd_solver.cpp:106] Iteration 53300, lr = 0.0377524
I0830 13:40:36.185118 11353 solver.cpp:228] Iteration 53400, loss = 1.09817
I0830 13:40:36.185184 11353 solver.cpp:244]     Train net output #0: loss = 1.09817 (* 1 = 1.09817 loss)
I0830 13:40:36.185191 11353 sgd_solver.cpp:106] Iteration 53400, lr = 0.0377138
I0830 13:40:40.469519 11353 solver.cpp:337] Iteration 53500, Testing net (#0)
