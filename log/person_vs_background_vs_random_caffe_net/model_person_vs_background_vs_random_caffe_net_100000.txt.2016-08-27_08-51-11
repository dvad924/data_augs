WARNING: Logging before InitGoogleLogging() is written to STDERR
I0827 08:51:15.921659 10163 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 10000
snapshot_prefix: "models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001"
solver_mode: GPU
net: "nets/person_vs_background_vs_random_caffe_net/trainval.prototxt"
I0827 08:51:15.921975 10163 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0827 08:51:15.922827 10163 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0827 08:51:15.922859 10163 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0827 08:51:15.923099 10163 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0827 08:51:15.923226 10163 layer_factory.hpp:77] Creating layer data
I0827 08:51:15.924289 10163 net.cpp:100] Creating Layer data
I0827 08:51:15.924311 10163 net.cpp:408] data -> data
I0827 08:51:15.924330 10163 net.cpp:408] data -> label
I0827 08:51:15.924345 10163 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0827 08:51:15.926486 10285 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0827 08:51:16.003720 10163 data_layer.cpp:41] output data size: 128,3,128,128
I0827 08:51:16.066998 10163 net.cpp:150] Setting up data
I0827 08:51:16.067036 10163 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0827 08:51:16.067042 10163 net.cpp:157] Top shape: 128 (128)
I0827 08:51:16.067045 10163 net.cpp:165] Memory required for data: 25166336
I0827 08:51:16.067054 10163 layer_factory.hpp:77] Creating layer conv1
I0827 08:51:16.067077 10163 net.cpp:100] Creating Layer conv1
I0827 08:51:16.067082 10163 net.cpp:434] conv1 <- data
I0827 08:51:16.067091 10163 net.cpp:408] conv1 -> conv1
I0827 08:51:16.569103 10163 net.cpp:150] Setting up conv1
I0827 08:51:16.569149 10163 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0827 08:51:16.569154 10163 net.cpp:165] Memory required for data: 69403136
I0827 08:51:16.569177 10163 layer_factory.hpp:77] Creating layer relu1
I0827 08:51:16.569195 10163 net.cpp:100] Creating Layer relu1
I0827 08:51:16.569201 10163 net.cpp:434] relu1 <- conv1
I0827 08:51:16.569210 10163 net.cpp:395] relu1 -> conv1 (in-place)
I0827 08:51:16.569476 10163 net.cpp:150] Setting up relu1
I0827 08:51:16.569494 10163 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0827 08:51:16.569499 10163 net.cpp:165] Memory required for data: 113639936
I0827 08:51:16.569502 10163 layer_factory.hpp:77] Creating layer pool1
I0827 08:51:16.569512 10163 net.cpp:100] Creating Layer pool1
I0827 08:51:16.569519 10163 net.cpp:434] pool1 <- conv1
I0827 08:51:16.569525 10163 net.cpp:408] pool1 -> pool1
I0827 08:51:16.569584 10163 net.cpp:150] Setting up pool1
I0827 08:51:16.569594 10163 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0827 08:51:16.569598 10163 net.cpp:165] Memory required for data: 124699136
I0827 08:51:16.569602 10163 layer_factory.hpp:77] Creating layer norm1
I0827 08:51:16.569614 10163 net.cpp:100] Creating Layer norm1
I0827 08:51:16.569618 10163 net.cpp:434] norm1 <- pool1
I0827 08:51:16.569623 10163 net.cpp:408] norm1 -> norm1
I0827 08:51:16.570263 10163 net.cpp:150] Setting up norm1
I0827 08:51:16.570283 10163 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0827 08:51:16.570287 10163 net.cpp:165] Memory required for data: 135758336
I0827 08:51:16.570292 10163 layer_factory.hpp:77] Creating layer conv2
I0827 08:51:16.570312 10163 net.cpp:100] Creating Layer conv2
I0827 08:51:16.570315 10163 net.cpp:434] conv2 <- norm1
I0827 08:51:16.570323 10163 net.cpp:408] conv2 -> conv2
I0827 08:51:16.578805 10163 net.cpp:150] Setting up conv2
I0827 08:51:16.578827 10163 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0827 08:51:16.578832 10163 net.cpp:165] Memory required for data: 165249536
I0827 08:51:16.578847 10163 layer_factory.hpp:77] Creating layer relu2
I0827 08:51:16.578856 10163 net.cpp:100] Creating Layer relu2
I0827 08:51:16.578860 10163 net.cpp:434] relu2 <- conv2
I0827 08:51:16.578867 10163 net.cpp:395] relu2 -> conv2 (in-place)
I0827 08:51:16.579494 10163 net.cpp:150] Setting up relu2
I0827 08:51:16.579514 10163 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0827 08:51:16.579519 10163 net.cpp:165] Memory required for data: 194740736
I0827 08:51:16.579524 10163 layer_factory.hpp:77] Creating layer pool2
I0827 08:51:16.579533 10163 net.cpp:100] Creating Layer pool2
I0827 08:51:16.579537 10163 net.cpp:434] pool2 <- conv2
I0827 08:51:16.579546 10163 net.cpp:408] pool2 -> pool2
I0827 08:51:16.579612 10163 net.cpp:150] Setting up pool2
I0827 08:51:16.579622 10163 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0827 08:51:16.579627 10163 net.cpp:165] Memory required for data: 201163264
I0827 08:51:16.579632 10163 layer_factory.hpp:77] Creating layer norm2
I0827 08:51:16.579648 10163 net.cpp:100] Creating Layer norm2
I0827 08:51:16.579653 10163 net.cpp:434] norm2 <- pool2
I0827 08:51:16.579660 10163 net.cpp:408] norm2 -> norm2
I0827 08:51:16.579939 10163 net.cpp:150] Setting up norm2
I0827 08:51:16.579953 10163 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0827 08:51:16.579957 10163 net.cpp:165] Memory required for data: 207585792
I0827 08:51:16.579962 10163 layer_factory.hpp:77] Creating layer conv3
I0827 08:51:16.579977 10163 net.cpp:100] Creating Layer conv3
I0827 08:51:16.579983 10163 net.cpp:434] conv3 <- norm2
I0827 08:51:16.579991 10163 net.cpp:408] conv3 -> conv3
I0827 08:51:16.596684 10163 net.cpp:150] Setting up conv3
I0827 08:51:16.596704 10163 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0827 08:51:16.596709 10163 net.cpp:165] Memory required for data: 217219584
I0827 08:51:16.596720 10163 layer_factory.hpp:77] Creating layer relu3
I0827 08:51:16.596731 10163 net.cpp:100] Creating Layer relu3
I0827 08:51:16.596735 10163 net.cpp:434] relu3 <- conv3
I0827 08:51:16.596741 10163 net.cpp:395] relu3 -> conv3 (in-place)
I0827 08:51:16.596979 10163 net.cpp:150] Setting up relu3
I0827 08:51:16.596993 10163 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0827 08:51:16.596997 10163 net.cpp:165] Memory required for data: 226853376
I0827 08:51:16.597002 10163 layer_factory.hpp:77] Creating layer conv4
I0827 08:51:16.597015 10163 net.cpp:100] Creating Layer conv4
I0827 08:51:16.597020 10163 net.cpp:434] conv4 <- conv3
I0827 08:51:16.597030 10163 net.cpp:408] conv4 -> conv4
I0827 08:51:16.610311 10163 net.cpp:150] Setting up conv4
I0827 08:51:16.610330 10163 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0827 08:51:16.610334 10163 net.cpp:165] Memory required for data: 236487168
I0827 08:51:16.610342 10163 layer_factory.hpp:77] Creating layer relu4
I0827 08:51:16.610352 10163 net.cpp:100] Creating Layer relu4
I0827 08:51:16.610357 10163 net.cpp:434] relu4 <- conv4
I0827 08:51:16.610361 10163 net.cpp:395] relu4 -> conv4 (in-place)
I0827 08:51:16.610594 10163 net.cpp:150] Setting up relu4
I0827 08:51:16.610606 10163 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0827 08:51:16.610610 10163 net.cpp:165] Memory required for data: 246120960
I0827 08:51:16.610615 10163 layer_factory.hpp:77] Creating layer conv5
I0827 08:51:16.610628 10163 net.cpp:100] Creating Layer conv5
I0827 08:51:16.610632 10163 net.cpp:434] conv5 <- conv4
I0827 08:51:16.610640 10163 net.cpp:408] conv5 -> conv5
I0827 08:51:16.620198 10163 net.cpp:150] Setting up conv5
I0827 08:51:16.620216 10163 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0827 08:51:16.620220 10163 net.cpp:165] Memory required for data: 252543488
I0827 08:51:16.620234 10163 layer_factory.hpp:77] Creating layer relu5
I0827 08:51:16.620242 10163 net.cpp:100] Creating Layer relu5
I0827 08:51:16.620245 10163 net.cpp:434] relu5 <- conv5
I0827 08:51:16.620251 10163 net.cpp:395] relu5 -> conv5 (in-place)
I0827 08:51:16.620476 10163 net.cpp:150] Setting up relu5
I0827 08:51:16.620488 10163 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0827 08:51:16.620492 10163 net.cpp:165] Memory required for data: 258966016
I0827 08:51:16.620496 10163 layer_factory.hpp:77] Creating layer pool5
I0827 08:51:16.620502 10163 net.cpp:100] Creating Layer pool5
I0827 08:51:16.620506 10163 net.cpp:434] pool5 <- conv5
I0827 08:51:16.620513 10163 net.cpp:408] pool5 -> pool5
I0827 08:51:16.620565 10163 net.cpp:150] Setting up pool5
I0827 08:51:16.620575 10163 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0827 08:51:16.620579 10163 net.cpp:165] Memory required for data: 260145664
I0827 08:51:16.620584 10163 layer_factory.hpp:77] Creating layer fc6n
I0827 08:51:16.620596 10163 net.cpp:100] Creating Layer fc6n
I0827 08:51:16.620604 10163 net.cpp:434] fc6n <- pool5
I0827 08:51:16.620609 10163 net.cpp:408] fc6n -> fc6
I0827 08:51:16.753095 10163 net.cpp:150] Setting up fc6n
I0827 08:51:16.753132 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.753135 10163 net.cpp:165] Memory required for data: 262242816
I0827 08:51:16.753149 10163 layer_factory.hpp:77] Creating layer relu6
I0827 08:51:16.753161 10163 net.cpp:100] Creating Layer relu6
I0827 08:51:16.753165 10163 net.cpp:434] relu6 <- fc6
I0827 08:51:16.753173 10163 net.cpp:395] relu6 -> fc6 (in-place)
I0827 08:51:16.753777 10163 net.cpp:150] Setting up relu6
I0827 08:51:16.753793 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.753795 10163 net.cpp:165] Memory required for data: 264339968
I0827 08:51:16.753798 10163 layer_factory.hpp:77] Creating layer drop6
I0827 08:51:16.753808 10163 net.cpp:100] Creating Layer drop6
I0827 08:51:16.753810 10163 net.cpp:434] drop6 <- fc6
I0827 08:51:16.753818 10163 net.cpp:395] drop6 -> fc6 (in-place)
I0827 08:51:16.753844 10163 net.cpp:150] Setting up drop6
I0827 08:51:16.753850 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.753854 10163 net.cpp:165] Memory required for data: 266437120
I0827 08:51:16.753855 10163 layer_factory.hpp:77] Creating layer fc7n
I0827 08:51:16.753867 10163 net.cpp:100] Creating Layer fc7n
I0827 08:51:16.753875 10163 net.cpp:434] fc7n <- fc6
I0827 08:51:16.753880 10163 net.cpp:408] fc7n -> fc7
I0827 08:51:16.984123 10163 net.cpp:150] Setting up fc7n
I0827 08:51:16.984165 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.984169 10163 net.cpp:165] Memory required for data: 268534272
I0827 08:51:16.984181 10163 layer_factory.hpp:77] Creating layer relu7
I0827 08:51:16.984194 10163 net.cpp:100] Creating Layer relu7
I0827 08:51:16.984199 10163 net.cpp:434] relu7 <- fc7
I0827 08:51:16.984208 10163 net.cpp:395] relu7 -> fc7 (in-place)
I0827 08:51:16.984480 10163 net.cpp:150] Setting up relu7
I0827 08:51:16.984493 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.984495 10163 net.cpp:165] Memory required for data: 270631424
I0827 08:51:16.984498 10163 layer_factory.hpp:77] Creating layer drop7
I0827 08:51:16.984508 10163 net.cpp:100] Creating Layer drop7
I0827 08:51:16.984510 10163 net.cpp:434] drop7 <- fc7
I0827 08:51:16.984515 10163 net.cpp:395] drop7 -> fc7 (in-place)
I0827 08:51:16.984540 10163 net.cpp:150] Setting up drop7
I0827 08:51:16.984545 10163 net.cpp:157] Top shape: 128 4096 (524288)
I0827 08:51:16.984549 10163 net.cpp:165] Memory required for data: 272728576
I0827 08:51:16.984551 10163 layer_factory.hpp:77] Creating layer fc8n
I0827 08:51:16.984563 10163 net.cpp:100] Creating Layer fc8n
I0827 08:51:16.984566 10163 net.cpp:434] fc8n <- fc7
I0827 08:51:16.984573 10163 net.cpp:408] fc8n -> fc8
I0827 08:51:16.986187 10163 net.cpp:150] Setting up fc8n
I0827 08:51:16.986202 10163 net.cpp:157] Top shape: 128 3 (384)
I0827 08:51:16.986205 10163 net.cpp:165] Memory required for data: 272730112
I0827 08:51:16.986212 10163 layer_factory.hpp:77] Creating layer loss
I0827 08:51:16.986220 10163 net.cpp:100] Creating Layer loss
I0827 08:51:16.986224 10163 net.cpp:434] loss <- fc8
I0827 08:51:16.986229 10163 net.cpp:434] loss <- label
I0827 08:51:16.986234 10163 net.cpp:408] loss -> loss
I0827 08:51:16.986248 10163 layer_factory.hpp:77] Creating layer loss
I0827 08:51:16.986549 10163 net.cpp:150] Setting up loss
I0827 08:51:16.986562 10163 net.cpp:157] Top shape: (1)
I0827 08:51:16.986564 10163 net.cpp:160]     with loss weight 1
I0827 08:51:16.986583 10163 net.cpp:165] Memory required for data: 272730116
I0827 08:51:16.986588 10163 net.cpp:226] loss needs backward computation.
I0827 08:51:16.986591 10163 net.cpp:226] fc8n needs backward computation.
I0827 08:51:16.986594 10163 net.cpp:226] drop7 needs backward computation.
I0827 08:51:16.986596 10163 net.cpp:226] relu7 needs backward computation.
I0827 08:51:16.986598 10163 net.cpp:226] fc7n needs backward computation.
I0827 08:51:16.986601 10163 net.cpp:226] drop6 needs backward computation.
I0827 08:51:16.986604 10163 net.cpp:226] relu6 needs backward computation.
I0827 08:51:16.986608 10163 net.cpp:226] fc6n needs backward computation.
I0827 08:51:16.986610 10163 net.cpp:226] pool5 needs backward computation.
I0827 08:51:16.986613 10163 net.cpp:226] relu5 needs backward computation.
I0827 08:51:16.986616 10163 net.cpp:226] conv5 needs backward computation.
I0827 08:51:16.986619 10163 net.cpp:226] relu4 needs backward computation.
I0827 08:51:16.986623 10163 net.cpp:226] conv4 needs backward computation.
I0827 08:51:16.986625 10163 net.cpp:226] relu3 needs backward computation.
I0827 08:51:16.986629 10163 net.cpp:226] conv3 needs backward computation.
I0827 08:51:16.986631 10163 net.cpp:226] norm2 needs backward computation.
I0827 08:51:16.986634 10163 net.cpp:226] pool2 needs backward computation.
I0827 08:51:16.986639 10163 net.cpp:226] relu2 needs backward computation.
I0827 08:51:16.986642 10163 net.cpp:226] conv2 needs backward computation.
I0827 08:51:16.986645 10163 net.cpp:226] norm1 needs backward computation.
I0827 08:51:16.986649 10163 net.cpp:226] pool1 needs backward computation.
I0827 08:51:16.986651 10163 net.cpp:226] relu1 needs backward computation.
I0827 08:51:16.986654 10163 net.cpp:226] conv1 needs backward computation.
I0827 08:51:16.986657 10163 net.cpp:228] data does not need backward computation.
I0827 08:51:16.986660 10163 net.cpp:270] This network produces output loss
I0827 08:51:16.986676 10163 net.cpp:283] Network initialization done.
I0827 08:51:16.987045 10163 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0827 08:51:16.987084 10163 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0827 08:51:16.987257 10163 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0827 08:51:16.987368 10163 layer_factory.hpp:77] Creating layer data
I0827 08:51:16.987512 10163 net.cpp:100] Creating Layer data
I0827 08:51:16.987520 10163 net.cpp:408] data -> data
I0827 08:51:16.987529 10163 net.cpp:408] data -> label
I0827 08:51:16.987540 10163 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0827 08:51:16.991461 10288 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0827 08:51:16.992957 10163 data_layer.cpp:41] output data size: 100,3,128,128
I0827 08:51:17.048506 10163 net.cpp:150] Setting up data
I0827 08:51:17.048548 10163 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0827 08:51:17.048557 10163 net.cpp:157] Top shape: 100 (100)
I0827 08:51:17.048562 10163 net.cpp:165] Memory required for data: 19661200
I0827 08:51:17.048569 10163 layer_factory.hpp:77] Creating layer label_data_1_split
I0827 08:51:17.048589 10163 net.cpp:100] Creating Layer label_data_1_split
I0827 08:51:17.048595 10163 net.cpp:434] label_data_1_split <- label
I0827 08:51:17.048607 10163 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0827 08:51:17.048627 10163 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0827 08:51:17.048734 10163 net.cpp:150] Setting up label_data_1_split
I0827 08:51:17.048745 10163 net.cpp:157] Top shape: 100 (100)
I0827 08:51:17.048751 10163 net.cpp:157] Top shape: 100 (100)
I0827 08:51:17.048755 10163 net.cpp:165] Memory required for data: 19662000
I0827 08:51:17.048761 10163 layer_factory.hpp:77] Creating layer conv1
I0827 08:51:17.048784 10163 net.cpp:100] Creating Layer conv1
I0827 08:51:17.048790 10163 net.cpp:434] conv1 <- data
I0827 08:51:17.048802 10163 net.cpp:408] conv1 -> conv1
I0827 08:51:17.053238 10163 net.cpp:150] Setting up conv1
I0827 08:51:17.053266 10163 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0827 08:51:17.053272 10163 net.cpp:165] Memory required for data: 54222000
I0827 08:51:17.053303 10163 layer_factory.hpp:77] Creating layer relu1
I0827 08:51:17.053316 10163 net.cpp:100] Creating Layer relu1
I0827 08:51:17.053321 10163 net.cpp:434] relu1 <- conv1
I0827 08:51:17.053328 10163 net.cpp:395] relu1 -> conv1 (in-place)
I0827 08:51:17.053618 10163 net.cpp:150] Setting up relu1
I0827 08:51:17.053633 10163 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0827 08:51:17.053637 10163 net.cpp:165] Memory required for data: 88782000
I0827 08:51:17.053642 10163 layer_factory.hpp:77] Creating layer pool1
I0827 08:51:17.053653 10163 net.cpp:100] Creating Layer pool1
I0827 08:51:17.053658 10163 net.cpp:434] pool1 <- conv1
I0827 08:51:17.053666 10163 net.cpp:408] pool1 -> pool1
I0827 08:51:17.053735 10163 net.cpp:150] Setting up pool1
I0827 08:51:17.053746 10163 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0827 08:51:17.053750 10163 net.cpp:165] Memory required for data: 97422000
I0827 08:51:17.053755 10163 layer_factory.hpp:77] Creating layer norm1
I0827 08:51:17.053764 10163 net.cpp:100] Creating Layer norm1
I0827 08:51:17.053771 10163 net.cpp:434] norm1 <- pool1
I0827 08:51:17.053779 10163 net.cpp:408] norm1 -> norm1
I0827 08:51:17.054574 10163 net.cpp:150] Setting up norm1
I0827 08:51:17.054594 10163 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0827 08:51:17.054600 10163 net.cpp:165] Memory required for data: 106062000
I0827 08:51:17.054605 10163 layer_factory.hpp:77] Creating layer conv2
I0827 08:51:17.054620 10163 net.cpp:100] Creating Layer conv2
I0827 08:51:17.054625 10163 net.cpp:434] conv2 <- norm1
I0827 08:51:17.054635 10163 net.cpp:408] conv2 -> conv2
I0827 08:51:17.063812 10163 net.cpp:150] Setting up conv2
I0827 08:51:17.063837 10163 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0827 08:51:17.063843 10163 net.cpp:165] Memory required for data: 129102000
I0827 08:51:17.063855 10163 layer_factory.hpp:77] Creating layer relu2
I0827 08:51:17.063868 10163 net.cpp:100] Creating Layer relu2
I0827 08:51:17.063872 10163 net.cpp:434] relu2 <- conv2
I0827 08:51:17.063880 10163 net.cpp:395] relu2 -> conv2 (in-place)
I0827 08:51:17.064563 10163 net.cpp:150] Setting up relu2
I0827 08:51:17.064584 10163 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0827 08:51:17.064589 10163 net.cpp:165] Memory required for data: 152142000
I0827 08:51:17.064594 10163 layer_factory.hpp:77] Creating layer pool2
I0827 08:51:17.064607 10163 net.cpp:100] Creating Layer pool2
I0827 08:51:17.064612 10163 net.cpp:434] pool2 <- conv2
I0827 08:51:17.064620 10163 net.cpp:408] pool2 -> pool2
I0827 08:51:17.064697 10163 net.cpp:150] Setting up pool2
I0827 08:51:17.064708 10163 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0827 08:51:17.064713 10163 net.cpp:165] Memory required for data: 157159600
I0827 08:51:17.064716 10163 layer_factory.hpp:77] Creating layer norm2
I0827 08:51:17.064724 10163 net.cpp:100] Creating Layer norm2
I0827 08:51:17.064728 10163 net.cpp:434] norm2 <- pool2
I0827 08:51:17.064736 10163 net.cpp:408] norm2 -> norm2
I0827 08:51:17.065066 10163 net.cpp:150] Setting up norm2
I0827 08:51:17.065083 10163 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0827 08:51:17.065086 10163 net.cpp:165] Memory required for data: 162177200
I0827 08:51:17.065090 10163 layer_factory.hpp:77] Creating layer conv3
I0827 08:51:17.065110 10163 net.cpp:100] Creating Layer conv3
I0827 08:51:17.065115 10163 net.cpp:434] conv3 <- norm2
I0827 08:51:17.065124 10163 net.cpp:408] conv3 -> conv3
I0827 08:51:17.083277 10163 net.cpp:150] Setting up conv3
I0827 08:51:17.083299 10163 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0827 08:51:17.083304 10163 net.cpp:165] Memory required for data: 169703600
I0827 08:51:17.083318 10163 layer_factory.hpp:77] Creating layer relu3
I0827 08:51:17.083331 10163 net.cpp:100] Creating Layer relu3
I0827 08:51:17.083335 10163 net.cpp:434] relu3 <- conv3
I0827 08:51:17.083343 10163 net.cpp:395] relu3 -> conv3 (in-place)
I0827 08:51:17.083622 10163 net.cpp:150] Setting up relu3
I0827 08:51:17.083636 10163 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0827 08:51:17.083641 10163 net.cpp:165] Memory required for data: 177230000
I0827 08:51:17.083644 10163 layer_factory.hpp:77] Creating layer conv4
I0827 08:51:17.083660 10163 net.cpp:100] Creating Layer conv4
I0827 08:51:17.083664 10163 net.cpp:434] conv4 <- conv3
I0827 08:51:17.083673 10163 net.cpp:408] conv4 -> conv4
I0827 08:51:17.097934 10163 net.cpp:150] Setting up conv4
I0827 08:51:17.097954 10163 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0827 08:51:17.097957 10163 net.cpp:165] Memory required for data: 184756400
I0827 08:51:17.097966 10163 layer_factory.hpp:77] Creating layer relu4
I0827 08:51:17.097975 10163 net.cpp:100] Creating Layer relu4
I0827 08:51:17.097980 10163 net.cpp:434] relu4 <- conv4
I0827 08:51:17.097985 10163 net.cpp:395] relu4 -> conv4 (in-place)
I0827 08:51:17.098598 10163 net.cpp:150] Setting up relu4
I0827 08:51:17.098615 10163 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0827 08:51:17.098619 10163 net.cpp:165] Memory required for data: 192282800
I0827 08:51:17.098623 10163 layer_factory.hpp:77] Creating layer conv5
I0827 08:51:17.098637 10163 net.cpp:100] Creating Layer conv5
I0827 08:51:17.098641 10163 net.cpp:434] conv5 <- conv4
I0827 08:51:17.098651 10163 net.cpp:408] conv5 -> conv5
I0827 08:51:17.108927 10163 net.cpp:150] Setting up conv5
I0827 08:51:17.108947 10163 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0827 08:51:17.108952 10163 net.cpp:165] Memory required for data: 197300400
I0827 08:51:17.108965 10163 layer_factory.hpp:77] Creating layer relu5
I0827 08:51:17.108973 10163 net.cpp:100] Creating Layer relu5
I0827 08:51:17.108978 10163 net.cpp:434] relu5 <- conv5
I0827 08:51:17.108983 10163 net.cpp:395] relu5 -> conv5 (in-place)
I0827 08:51:17.109233 10163 net.cpp:150] Setting up relu5
I0827 08:51:17.109247 10163 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0827 08:51:17.109251 10163 net.cpp:165] Memory required for data: 202318000
I0827 08:51:17.109254 10163 layer_factory.hpp:77] Creating layer pool5
I0827 08:51:17.109266 10163 net.cpp:100] Creating Layer pool5
I0827 08:51:17.109269 10163 net.cpp:434] pool5 <- conv5
I0827 08:51:17.109290 10163 net.cpp:408] pool5 -> pool5
I0827 08:51:17.109356 10163 net.cpp:150] Setting up pool5
I0827 08:51:17.109366 10163 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0827 08:51:17.109369 10163 net.cpp:165] Memory required for data: 203239600
I0827 08:51:17.109372 10163 layer_factory.hpp:77] Creating layer fc6n
I0827 08:51:17.109382 10163 net.cpp:100] Creating Layer fc6n
I0827 08:51:17.109385 10163 net.cpp:434] fc6n <- pool5
I0827 08:51:17.109393 10163 net.cpp:408] fc6n -> fc6
I0827 08:51:17.241811 10163 net.cpp:150] Setting up fc6n
I0827 08:51:17.241854 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.241858 10163 net.cpp:165] Memory required for data: 204878000
I0827 08:51:17.241871 10163 layer_factory.hpp:77] Creating layer relu6
I0827 08:51:17.241883 10163 net.cpp:100] Creating Layer relu6
I0827 08:51:17.241888 10163 net.cpp:434] relu6 <- fc6
I0827 08:51:17.241896 10163 net.cpp:395] relu6 -> fc6 (in-place)
I0827 08:51:17.242192 10163 net.cpp:150] Setting up relu6
I0827 08:51:17.242202 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.242205 10163 net.cpp:165] Memory required for data: 206516400
I0827 08:51:17.242208 10163 layer_factory.hpp:77] Creating layer drop6
I0827 08:51:17.242216 10163 net.cpp:100] Creating Layer drop6
I0827 08:51:17.242219 10163 net.cpp:434] drop6 <- fc6
I0827 08:51:17.242225 10163 net.cpp:395] drop6 -> fc6 (in-place)
I0827 08:51:17.242262 10163 net.cpp:150] Setting up drop6
I0827 08:51:17.242270 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.242272 10163 net.cpp:165] Memory required for data: 208154800
I0827 08:51:17.242275 10163 layer_factory.hpp:77] Creating layer fc7n
I0827 08:51:17.242286 10163 net.cpp:100] Creating Layer fc7n
I0827 08:51:17.242291 10163 net.cpp:434] fc7n <- fc6
I0827 08:51:17.242300 10163 net.cpp:408] fc7n -> fc7
I0827 08:51:17.473191 10163 net.cpp:150] Setting up fc7n
I0827 08:51:17.473235 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.473239 10163 net.cpp:165] Memory required for data: 209793200
I0827 08:51:17.473251 10163 layer_factory.hpp:77] Creating layer relu7
I0827 08:51:17.473263 10163 net.cpp:100] Creating Layer relu7
I0827 08:51:17.473268 10163 net.cpp:434] relu7 <- fc7
I0827 08:51:17.473284 10163 net.cpp:395] relu7 -> fc7 (in-place)
I0827 08:51:17.474058 10163 net.cpp:150] Setting up relu7
I0827 08:51:17.474073 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.474076 10163 net.cpp:165] Memory required for data: 211431600
I0827 08:51:17.474079 10163 layer_factory.hpp:77] Creating layer drop7
I0827 08:51:17.474092 10163 net.cpp:100] Creating Layer drop7
I0827 08:51:17.474095 10163 net.cpp:434] drop7 <- fc7
I0827 08:51:17.474102 10163 net.cpp:395] drop7 -> fc7 (in-place)
I0827 08:51:17.474143 10163 net.cpp:150] Setting up drop7
I0827 08:51:17.474151 10163 net.cpp:157] Top shape: 100 4096 (409600)
I0827 08:51:17.474154 10163 net.cpp:165] Memory required for data: 213070000
I0827 08:51:17.474158 10163 layer_factory.hpp:77] Creating layer fc8n
I0827 08:51:17.474166 10163 net.cpp:100] Creating Layer fc8n
I0827 08:51:17.474169 10163 net.cpp:434] fc8n <- fc7
I0827 08:51:17.474176 10163 net.cpp:408] fc8n -> fc8
I0827 08:51:17.474470 10163 net.cpp:150] Setting up fc8n
I0827 08:51:17.474479 10163 net.cpp:157] Top shape: 100 3 (300)
I0827 08:51:17.474481 10163 net.cpp:165] Memory required for data: 213071200
I0827 08:51:17.474488 10163 layer_factory.hpp:77] Creating layer fc8_fc8n_0_split
I0827 08:51:17.474496 10163 net.cpp:100] Creating Layer fc8_fc8n_0_split
I0827 08:51:17.474499 10163 net.cpp:434] fc8_fc8n_0_split <- fc8
I0827 08:51:17.474505 10163 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_0
I0827 08:51:17.474511 10163 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_1
I0827 08:51:17.474555 10163 net.cpp:150] Setting up fc8_fc8n_0_split
I0827 08:51:17.474562 10163 net.cpp:157] Top shape: 100 3 (300)
I0827 08:51:17.474565 10163 net.cpp:157] Top shape: 100 3 (300)
I0827 08:51:17.474567 10163 net.cpp:165] Memory required for data: 213073600
I0827 08:51:17.474570 10163 layer_factory.hpp:77] Creating layer accuracy
I0827 08:51:17.474578 10163 net.cpp:100] Creating Layer accuracy
I0827 08:51:17.474581 10163 net.cpp:434] accuracy <- fc8_fc8n_0_split_0
I0827 08:51:17.474586 10163 net.cpp:434] accuracy <- label_data_1_split_0
I0827 08:51:17.474591 10163 net.cpp:408] accuracy -> accuracy
I0827 08:51:17.474601 10163 net.cpp:150] Setting up accuracy
I0827 08:51:17.474604 10163 net.cpp:157] Top shape: (1)
I0827 08:51:17.474606 10163 net.cpp:165] Memory required for data: 213073604
I0827 08:51:17.474609 10163 layer_factory.hpp:77] Creating layer loss
I0827 08:51:17.474614 10163 net.cpp:100] Creating Layer loss
I0827 08:51:17.474617 10163 net.cpp:434] loss <- fc8_fc8n_0_split_1
I0827 08:51:17.474622 10163 net.cpp:434] loss <- label_data_1_split_1
I0827 08:51:17.474625 10163 net.cpp:408] loss -> loss
I0827 08:51:17.474634 10163 layer_factory.hpp:77] Creating layer loss
I0827 08:51:17.474944 10163 net.cpp:150] Setting up loss
I0827 08:51:17.474956 10163 net.cpp:157] Top shape: (1)
I0827 08:51:17.474958 10163 net.cpp:160]     with loss weight 1
I0827 08:51:17.474972 10163 net.cpp:165] Memory required for data: 213073608
I0827 08:51:17.474977 10163 net.cpp:226] loss needs backward computation.
I0827 08:51:17.474980 10163 net.cpp:228] accuracy does not need backward computation.
I0827 08:51:17.474984 10163 net.cpp:226] fc8_fc8n_0_split needs backward computation.
I0827 08:51:17.474987 10163 net.cpp:226] fc8n needs backward computation.
I0827 08:51:17.474990 10163 net.cpp:226] drop7 needs backward computation.
I0827 08:51:17.474992 10163 net.cpp:226] relu7 needs backward computation.
I0827 08:51:17.474995 10163 net.cpp:226] fc7n needs backward computation.
I0827 08:51:17.474997 10163 net.cpp:226] drop6 needs backward computation.
I0827 08:51:17.475000 10163 net.cpp:226] relu6 needs backward computation.
I0827 08:51:17.475003 10163 net.cpp:226] fc6n needs backward computation.
I0827 08:51:17.475006 10163 net.cpp:226] pool5 needs backward computation.
I0827 08:51:17.475009 10163 net.cpp:226] relu5 needs backward computation.
I0827 08:51:17.475013 10163 net.cpp:226] conv5 needs backward computation.
I0827 08:51:17.475015 10163 net.cpp:226] relu4 needs backward computation.
I0827 08:51:17.475018 10163 net.cpp:226] conv4 needs backward computation.
I0827 08:51:17.475021 10163 net.cpp:226] relu3 needs backward computation.
I0827 08:51:17.475024 10163 net.cpp:226] conv3 needs backward computation.
I0827 08:51:17.475028 10163 net.cpp:226] norm2 needs backward computation.
I0827 08:51:17.475030 10163 net.cpp:226] pool2 needs backward computation.
I0827 08:51:17.475033 10163 net.cpp:226] relu2 needs backward computation.
I0827 08:51:17.475036 10163 net.cpp:226] conv2 needs backward computation.
I0827 08:51:17.475039 10163 net.cpp:226] norm1 needs backward computation.
I0827 08:51:17.475044 10163 net.cpp:226] pool1 needs backward computation.
I0827 08:51:17.475047 10163 net.cpp:226] relu1 needs backward computation.
I0827 08:51:17.475050 10163 net.cpp:226] conv1 needs backward computation.
I0827 08:51:17.475054 10163 net.cpp:228] label_data_1_split does not need backward computation.
I0827 08:51:17.475057 10163 net.cpp:228] data does not need backward computation.
I0827 08:51:17.475060 10163 net.cpp:270] This network produces output accuracy
I0827 08:51:17.475064 10163 net.cpp:270] This network produces output loss
I0827 08:51:17.475083 10163 net.cpp:283] Network initialization done.
I0827 08:51:17.475178 10163 solver.cpp:60] Solver scaffolding done.
I0827 08:51:17.478734 10163 solver.cpp:337] Iteration 0, Testing net (#0)
I0827 08:51:17.598114 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 08:51:20.663856 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0827 08:51:20.663913 10163 solver.cpp:404]     Test net output #1: loss = 0.99714 (* 1 = 0.99714 loss)
I0827 08:51:20.697208 10163 solver.cpp:228] Iteration 0, loss = 1.58077
I0827 08:51:20.697295 10163 solver.cpp:244]     Train net output #0: loss = 1.58077 (* 1 = 1.58077 loss)
I0827 08:51:20.697329 10163 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0827 08:51:24.932858 10163 solver.cpp:228] Iteration 100, loss = 1.23735
I0827 08:51:24.932904 10163 solver.cpp:244]     Train net output #0: loss = 1.23735 (* 1 = 1.23735 loss)
I0827 08:51:24.932910 10163 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-05
I0827 08:51:29.196933 10163 solver.cpp:228] Iteration 200, loss = 1.27791
I0827 08:51:29.196992 10163 solver.cpp:244]     Train net output #0: loss = 1.27791 (* 1 = 1.27791 loss)
I0827 08:51:29.197003 10163 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-05
I0827 08:51:33.457486 10163 solver.cpp:228] Iteration 300, loss = 1.19985
I0827 08:51:33.457527 10163 solver.cpp:244]     Train net output #0: loss = 1.19985 (* 1 = 1.19985 loss)
I0827 08:51:33.457533 10163 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-05
I0827 08:51:37.717226 10163 solver.cpp:228] Iteration 400, loss = 1.18426
I0827 08:51:37.717247 10163 solver.cpp:244]     Train net output #0: loss = 1.18426 (* 1 = 1.18426 loss)
I0827 08:51:37.717252 10163 sgd_solver.cpp:106] Iteration 400, lr = 9.85258e-05
I0827 08:51:41.952183 10163 solver.cpp:337] Iteration 500, Testing net (#0)
I0827 08:51:45.094996 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 08:51:45.095042 10163 solver.cpp:404]     Test net output #1: loss = 1.09783 (* 1 = 1.09783 loss)
I0827 08:51:45.109578 10163 solver.cpp:228] Iteration 500, loss = 1.10316
I0827 08:51:45.109632 10163 solver.cpp:244]     Train net output #0: loss = 1.10316 (* 1 = 1.10316 loss)
I0827 08:51:45.109642 10163 sgd_solver.cpp:106] Iteration 500, lr = 9.81651e-05
I0827 08:51:49.386250 10163 solver.cpp:228] Iteration 600, loss = 1.15774
I0827 08:51:49.386319 10163 solver.cpp:244]     Train net output #0: loss = 1.15774 (* 1 = 1.15774 loss)
I0827 08:51:49.386325 10163 sgd_solver.cpp:106] Iteration 600, lr = 9.78075e-05
I0827 08:51:53.664680 10163 solver.cpp:228] Iteration 700, loss = 1.16848
I0827 08:51:53.664767 10163 solver.cpp:244]     Train net output #0: loss = 1.16848 (* 1 = 1.16848 loss)
I0827 08:51:53.664774 10163 sgd_solver.cpp:106] Iteration 700, lr = 9.74529e-05
I0827 08:51:57.950197 10163 solver.cpp:228] Iteration 800, loss = 1.16009
I0827 08:51:57.950224 10163 solver.cpp:244]     Train net output #0: loss = 1.16009 (* 1 = 1.16009 loss)
I0827 08:51:57.950229 10163 sgd_solver.cpp:106] Iteration 800, lr = 9.71013e-05
I0827 08:52:02.249683 10163 solver.cpp:228] Iteration 900, loss = 1.15942
I0827 08:52:02.249728 10163 solver.cpp:244]     Train net output #0: loss = 1.15942 (* 1 = 1.15942 loss)
I0827 08:52:02.249734 10163 sgd_solver.cpp:106] Iteration 900, lr = 9.67526e-05
I0827 08:52:06.501996 10163 solver.cpp:337] Iteration 1000, Testing net (#0)
I0827 08:52:09.642905 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578167
I0827 08:52:09.642945 10163 solver.cpp:404]     Test net output #1: loss = 1.08818 (* 1 = 1.08818 loss)
I0827 08:52:09.658648 10163 solver.cpp:228] Iteration 1000, loss = 1.14304
I0827 08:52:09.658686 10163 solver.cpp:244]     Train net output #0: loss = 1.14304 (* 1 = 1.14304 loss)
I0827 08:52:09.658695 10163 sgd_solver.cpp:106] Iteration 1000, lr = 9.64069e-05
I0827 08:52:13.950597 10163 solver.cpp:228] Iteration 1100, loss = 1.12855
I0827 08:52:13.950639 10163 solver.cpp:244]     Train net output #0: loss = 1.12855 (* 1 = 1.12855 loss)
I0827 08:52:13.950645 10163 sgd_solver.cpp:106] Iteration 1100, lr = 9.6064e-05
I0827 08:52:18.259443 10163 solver.cpp:228] Iteration 1200, loss = 1.16778
I0827 08:52:18.259495 10163 solver.cpp:244]     Train net output #0: loss = 1.16778 (* 1 = 1.16778 loss)
I0827 08:52:18.259515 10163 sgd_solver.cpp:106] Iteration 1200, lr = 9.57239e-05
I0827 08:52:22.576491 10163 solver.cpp:228] Iteration 1300, loss = 1.17707
I0827 08:52:22.576545 10163 solver.cpp:244]     Train net output #0: loss = 1.17707 (* 1 = 1.17707 loss)
I0827 08:52:22.576550 10163 sgd_solver.cpp:106] Iteration 1300, lr = 9.53867e-05
I0827 08:52:26.886656 10163 solver.cpp:228] Iteration 1400, loss = 1.15917
I0827 08:52:26.886705 10163 solver.cpp:244]     Train net output #0: loss = 1.15917 (* 1 = 1.15917 loss)
I0827 08:52:26.886711 10163 sgd_solver.cpp:106] Iteration 1400, lr = 9.50522e-05
I0827 08:52:31.158393 10163 solver.cpp:337] Iteration 1500, Testing net (#0)
I0827 08:52:34.275763 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 08:52:34.275797 10163 solver.cpp:404]     Test net output #1: loss = 1.13262 (* 1 = 1.13262 loss)
I0827 08:52:34.291079 10163 solver.cpp:228] Iteration 1500, loss = 1.13347
I0827 08:52:34.291137 10163 solver.cpp:244]     Train net output #0: loss = 1.13347 (* 1 = 1.13347 loss)
I0827 08:52:34.291153 10163 sgd_solver.cpp:106] Iteration 1500, lr = 9.47204e-05
I0827 08:52:38.605396 10163 solver.cpp:228] Iteration 1600, loss = 1.14872
I0827 08:52:38.605434 10163 solver.cpp:244]     Train net output #0: loss = 1.14872 (* 1 = 1.14872 loss)
I0827 08:52:38.605440 10163 sgd_solver.cpp:106] Iteration 1600, lr = 9.43913e-05
I0827 08:52:42.915758 10163 solver.cpp:228] Iteration 1700, loss = 1.15162
I0827 08:52:42.915801 10163 solver.cpp:244]     Train net output #0: loss = 1.15162 (* 1 = 1.15162 loss)
I0827 08:52:42.915807 10163 sgd_solver.cpp:106] Iteration 1700, lr = 9.40649e-05
I0827 08:52:47.226353 10163 solver.cpp:228] Iteration 1800, loss = 1.17502
I0827 08:52:47.226415 10163 solver.cpp:244]     Train net output #0: loss = 1.17502 (* 1 = 1.17502 loss)
I0827 08:52:47.226421 10163 sgd_solver.cpp:106] Iteration 1800, lr = 9.37411e-05
I0827 08:52:51.549005 10163 solver.cpp:228] Iteration 1900, loss = 1.13899
I0827 08:52:51.549063 10163 solver.cpp:244]     Train net output #0: loss = 1.13899 (* 1 = 1.13899 loss)
I0827 08:52:51.549070 10163 sgd_solver.cpp:106] Iteration 1900, lr = 9.34199e-05
I0827 08:52:55.829154 10163 solver.cpp:337] Iteration 2000, Testing net (#0)
I0827 08:52:58.948894 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0827 08:52:58.948945 10163 solver.cpp:404]     Test net output #1: loss = 1.12103 (* 1 = 1.12103 loss)
I0827 08:52:58.963732 10163 solver.cpp:228] Iteration 2000, loss = 1.08755
I0827 08:52:58.963778 10163 solver.cpp:244]     Train net output #0: loss = 1.08755 (* 1 = 1.08755 loss)
I0827 08:52:58.963788 10163 sgd_solver.cpp:106] Iteration 2000, lr = 9.31012e-05
I0827 08:53:03.283880 10163 solver.cpp:228] Iteration 2100, loss = 1.09301
I0827 08:53:03.283923 10163 solver.cpp:244]     Train net output #0: loss = 1.09301 (* 1 = 1.09301 loss)
I0827 08:53:03.283928 10163 sgd_solver.cpp:106] Iteration 2100, lr = 9.27851e-05
I0827 08:53:07.603123 10163 solver.cpp:228] Iteration 2200, loss = 1.1581
I0827 08:53:07.603160 10163 solver.cpp:244]     Train net output #0: loss = 1.1581 (* 1 = 1.1581 loss)
I0827 08:53:07.603166 10163 sgd_solver.cpp:106] Iteration 2200, lr = 9.24715e-05
I0827 08:53:11.921811 10163 solver.cpp:228] Iteration 2300, loss = 1.14327
I0827 08:53:11.921831 10163 solver.cpp:244]     Train net output #0: loss = 1.14327 (* 1 = 1.14327 loss)
I0827 08:53:11.921838 10163 sgd_solver.cpp:106] Iteration 2300, lr = 9.21603e-05
I0827 08:53:16.242352 10163 solver.cpp:228] Iteration 2400, loss = 1.13367
I0827 08:53:16.242410 10163 solver.cpp:244]     Train net output #0: loss = 1.13367 (* 1 = 1.13367 loss)
I0827 08:53:16.242416 10163 sgd_solver.cpp:106] Iteration 2400, lr = 9.18515e-05
I0827 08:53:20.523296 10163 solver.cpp:337] Iteration 2500, Testing net (#0)
I0827 08:53:23.663991 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152667
I0827 08:53:23.664057 10163 solver.cpp:404]     Test net output #1: loss = 1.09821 (* 1 = 1.09821 loss)
I0827 08:53:23.679401 10163 solver.cpp:228] Iteration 2500, loss = 1.13384
I0827 08:53:23.679450 10163 solver.cpp:244]     Train net output #0: loss = 1.13384 (* 1 = 1.13384 loss)
I0827 08:53:23.679464 10163 sgd_solver.cpp:106] Iteration 2500, lr = 9.15452e-05
I0827 08:53:28.001698 10163 solver.cpp:228] Iteration 2600, loss = 1.17319
I0827 08:53:28.001744 10163 solver.cpp:244]     Train net output #0: loss = 1.17319 (* 1 = 1.17319 loss)
I0827 08:53:28.001749 10163 sgd_solver.cpp:106] Iteration 2600, lr = 9.12412e-05
I0827 08:53:32.318632 10163 solver.cpp:228] Iteration 2700, loss = 1.12737
I0827 08:53:32.318653 10163 solver.cpp:244]     Train net output #0: loss = 1.12737 (* 1 = 1.12737 loss)
I0827 08:53:32.318658 10163 sgd_solver.cpp:106] Iteration 2700, lr = 9.09396e-05
I0827 08:53:36.641058 10163 solver.cpp:228] Iteration 2800, loss = 1.11925
I0827 08:53:36.641120 10163 solver.cpp:244]     Train net output #0: loss = 1.11925 (* 1 = 1.11925 loss)
I0827 08:53:36.641127 10163 sgd_solver.cpp:106] Iteration 2800, lr = 9.06403e-05
I0827 08:53:40.966768 10163 solver.cpp:228] Iteration 2900, loss = 1.14554
I0827 08:53:40.966820 10163 solver.cpp:244]     Train net output #0: loss = 1.14554 (* 1 = 1.14554 loss)
I0827 08:53:40.966827 10163 sgd_solver.cpp:106] Iteration 2900, lr = 9.03433e-05
I0827 08:53:45.242947 10163 solver.cpp:337] Iteration 3000, Testing net (#0)
I0827 08:53:48.440225 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 08:53:48.440268 10163 solver.cpp:404]     Test net output #1: loss = 1.09202 (* 1 = 1.09202 loss)
I0827 08:53:48.455787 10163 solver.cpp:228] Iteration 3000, loss = 1.11402
I0827 08:53:48.455850 10163 solver.cpp:244]     Train net output #0: loss = 1.11402 (* 1 = 1.11402 loss)
I0827 08:53:48.455868 10163 sgd_solver.cpp:106] Iteration 3000, lr = 9.00485e-05
I0827 08:53:52.786731 10163 solver.cpp:228] Iteration 3100, loss = 1.10902
I0827 08:53:52.786775 10163 solver.cpp:244]     Train net output #0: loss = 1.10902 (* 1 = 1.10902 loss)
I0827 08:53:52.786782 10163 sgd_solver.cpp:106] Iteration 3100, lr = 8.9756e-05
I0827 08:53:57.111706 10163 solver.cpp:228] Iteration 3200, loss = 1.12311
I0827 08:53:57.111747 10163 solver.cpp:244]     Train net output #0: loss = 1.12311 (* 1 = 1.12311 loss)
I0827 08:53:57.111752 10163 sgd_solver.cpp:106] Iteration 3200, lr = 8.94657e-05
I0827 08:54:01.435442 10163 solver.cpp:228] Iteration 3300, loss = 1.0898
I0827 08:54:01.435483 10163 solver.cpp:244]     Train net output #0: loss = 1.0898 (* 1 = 1.0898 loss)
I0827 08:54:01.435489 10163 sgd_solver.cpp:106] Iteration 3300, lr = 8.91776e-05
I0827 08:54:05.769561 10163 solver.cpp:228] Iteration 3400, loss = 1.10899
I0827 08:54:05.769613 10163 solver.cpp:244]     Train net output #0: loss = 1.10899 (* 1 = 1.10899 loss)
I0827 08:54:05.769623 10163 sgd_solver.cpp:106] Iteration 3400, lr = 8.88916e-05
I0827 08:54:10.053581 10163 solver.cpp:337] Iteration 3500, Testing net (#0)
I0827 08:54:13.267511 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 08:54:13.267551 10163 solver.cpp:404]     Test net output #1: loss = 1.0991 (* 1 = 1.0991 loss)
I0827 08:54:13.282316 10163 solver.cpp:228] Iteration 3500, loss = 1.1268
I0827 08:54:13.282356 10163 solver.cpp:244]     Train net output #0: loss = 1.1268 (* 1 = 1.1268 loss)
I0827 08:54:13.282364 10163 sgd_solver.cpp:106] Iteration 3500, lr = 8.86077e-05
I0827 08:54:17.610127 10163 solver.cpp:228] Iteration 3600, loss = 1.09568
I0827 08:54:17.610174 10163 solver.cpp:244]     Train net output #0: loss = 1.09568 (* 1 = 1.09568 loss)
I0827 08:54:17.610180 10163 sgd_solver.cpp:106] Iteration 3600, lr = 8.8326e-05
I0827 08:54:18.084489 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 08:54:21.930555 10163 solver.cpp:228] Iteration 3700, loss = 1.09651
I0827 08:54:21.930594 10163 solver.cpp:244]     Train net output #0: loss = 1.09651 (* 1 = 1.09651 loss)
I0827 08:54:21.930601 10163 sgd_solver.cpp:106] Iteration 3700, lr = 8.80463e-05
I0827 08:54:26.248478 10163 solver.cpp:228] Iteration 3800, loss = 1.10851
I0827 08:54:26.248522 10163 solver.cpp:244]     Train net output #0: loss = 1.10851 (* 1 = 1.10851 loss)
I0827 08:54:26.248528 10163 sgd_solver.cpp:106] Iteration 3800, lr = 8.77687e-05
I0827 08:54:30.566929 10163 solver.cpp:228] Iteration 3900, loss = 1.09337
I0827 08:54:30.566988 10163 solver.cpp:244]     Train net output #0: loss = 1.09337 (* 1 = 1.09337 loss)
I0827 08:54:30.566995 10163 sgd_solver.cpp:106] Iteration 3900, lr = 8.74932e-05
I0827 08:54:34.848639 10163 solver.cpp:337] Iteration 4000, Testing net (#0)
I0827 08:54:37.955127 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 08:54:37.955169 10163 solver.cpp:404]     Test net output #1: loss = 1.12602 (* 1 = 1.12602 loss)
I0827 08:54:37.970089 10163 solver.cpp:228] Iteration 4000, loss = 1.10374
I0827 08:54:37.970106 10163 solver.cpp:244]     Train net output #0: loss = 1.10374 (* 1 = 1.10374 loss)
I0827 08:54:37.970118 10163 sgd_solver.cpp:106] Iteration 4000, lr = 8.72196e-05
I0827 08:54:42.290217 10163 solver.cpp:228] Iteration 4100, loss = 1.10112
I0827 08:54:42.290280 10163 solver.cpp:244]     Train net output #0: loss = 1.10112 (* 1 = 1.10112 loss)
I0827 08:54:42.290288 10163 sgd_solver.cpp:106] Iteration 4100, lr = 8.6948e-05
I0827 08:54:46.612570 10163 solver.cpp:228] Iteration 4200, loss = 1.11492
I0827 08:54:46.612629 10163 solver.cpp:244]     Train net output #0: loss = 1.11492 (* 1 = 1.11492 loss)
I0827 08:54:46.612643 10163 sgd_solver.cpp:106] Iteration 4200, lr = 8.66784e-05
I0827 08:54:50.929983 10163 solver.cpp:228] Iteration 4300, loss = 1.11242
I0827 08:54:50.930006 10163 solver.cpp:244]     Train net output #0: loss = 1.11242 (* 1 = 1.11242 loss)
I0827 08:54:50.930011 10163 sgd_solver.cpp:106] Iteration 4300, lr = 8.64107e-05
I0827 08:54:55.251346 10163 solver.cpp:228] Iteration 4400, loss = 1.11648
I0827 08:54:55.251368 10163 solver.cpp:244]     Train net output #0: loss = 1.11648 (* 1 = 1.11648 loss)
I0827 08:54:55.251374 10163 sgd_solver.cpp:106] Iteration 4400, lr = 8.6145e-05
I0827 08:54:59.532130 10163 solver.cpp:337] Iteration 4500, Testing net (#0)
I0827 08:55:02.656838 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 08:55:02.656888 10163 solver.cpp:404]     Test net output #1: loss = 1.16122 (* 1 = 1.16122 loss)
I0827 08:55:02.674212 10163 solver.cpp:228] Iteration 4500, loss = 1.10549
I0827 08:55:02.674279 10163 solver.cpp:244]     Train net output #0: loss = 1.10549 (* 1 = 1.10549 loss)
I0827 08:55:02.674293 10163 sgd_solver.cpp:106] Iteration 4500, lr = 8.58812e-05
I0827 08:55:07.014091 10163 solver.cpp:228] Iteration 4600, loss = 1.12565
I0827 08:55:07.014140 10163 solver.cpp:244]     Train net output #0: loss = 1.12565 (* 1 = 1.12565 loss)
I0827 08:55:07.014149 10163 sgd_solver.cpp:106] Iteration 4600, lr = 8.56192e-05
I0827 08:55:11.340209 10163 solver.cpp:228] Iteration 4700, loss = 1.12178
I0827 08:55:11.340267 10163 solver.cpp:244]     Train net output #0: loss = 1.12178 (* 1 = 1.12178 loss)
I0827 08:55:11.340276 10163 sgd_solver.cpp:106] Iteration 4700, lr = 8.53591e-05
I0827 08:55:15.661056 10163 solver.cpp:228] Iteration 4800, loss = 1.10944
I0827 08:55:15.661104 10163 solver.cpp:244]     Train net output #0: loss = 1.10944 (* 1 = 1.10944 loss)
I0827 08:55:15.661110 10163 sgd_solver.cpp:106] Iteration 4800, lr = 8.51008e-05
I0827 08:55:20.000174 10163 solver.cpp:228] Iteration 4900, loss = 1.10871
I0827 08:55:20.000237 10163 solver.cpp:244]     Train net output #0: loss = 1.10871 (* 1 = 1.10871 loss)
I0827 08:55:20.000246 10163 sgd_solver.cpp:106] Iteration 4900, lr = 8.48444e-05
I0827 08:55:24.277304 10163 solver.cpp:337] Iteration 5000, Testing net (#0)
I0827 08:55:27.872750 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269458
I0827 08:55:27.872803 10163 solver.cpp:404]     Test net output #1: loss = 1.13814 (* 1 = 1.13814 loss)
I0827 08:55:27.887791 10163 solver.cpp:228] Iteration 5000, loss = 1.10547
I0827 08:55:27.887820 10163 solver.cpp:244]     Train net output #0: loss = 1.10547 (* 1 = 1.10547 loss)
I0827 08:55:27.887835 10163 sgd_solver.cpp:106] Iteration 5000, lr = 8.45897e-05
I0827 08:55:32.219079 10163 solver.cpp:228] Iteration 5100, loss = 1.09237
I0827 08:55:32.219120 10163 solver.cpp:244]     Train net output #0: loss = 1.09237 (* 1 = 1.09237 loss)
I0827 08:55:32.219125 10163 sgd_solver.cpp:106] Iteration 5100, lr = 8.43368e-05
I0827 08:55:36.556026 10163 solver.cpp:228] Iteration 5200, loss = 1.10915
I0827 08:55:36.556071 10163 solver.cpp:244]     Train net output #0: loss = 1.10915 (* 1 = 1.10915 loss)
I0827 08:55:36.556077 10163 sgd_solver.cpp:106] Iteration 5200, lr = 8.40857e-05
I0827 08:55:40.878420 10163 solver.cpp:228] Iteration 5300, loss = 1.11232
I0827 08:55:40.878438 10163 solver.cpp:244]     Train net output #0: loss = 1.11232 (* 1 = 1.11232 loss)
I0827 08:55:40.878443 10163 sgd_solver.cpp:106] Iteration 5300, lr = 8.38363e-05
I0827 08:55:45.201527 10163 solver.cpp:228] Iteration 5400, loss = 1.10779
I0827 08:55:45.201567 10163 solver.cpp:244]     Train net output #0: loss = 1.10779 (* 1 = 1.10779 loss)
I0827 08:55:45.201573 10163 sgd_solver.cpp:106] Iteration 5400, lr = 8.35886e-05
I0827 08:55:49.485687 10163 solver.cpp:337] Iteration 5500, Testing net (#0)
I0827 08:55:53.171855 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0827 08:55:53.171916 10163 solver.cpp:404]     Test net output #1: loss = 1.12828 (* 1 = 1.12828 loss)
I0827 08:55:53.186714 10163 solver.cpp:228] Iteration 5500, loss = 1.11438
I0827 08:55:53.186745 10163 solver.cpp:244]     Train net output #0: loss = 1.11438 (* 1 = 1.11438 loss)
I0827 08:55:53.186758 10163 sgd_solver.cpp:106] Iteration 5500, lr = 8.33427e-05
I0827 08:55:57.515646 10163 solver.cpp:228] Iteration 5600, loss = 1.11015
I0827 08:55:57.515703 10163 solver.cpp:244]     Train net output #0: loss = 1.11015 (* 1 = 1.11015 loss)
I0827 08:55:57.515709 10163 sgd_solver.cpp:106] Iteration 5600, lr = 8.30984e-05
I0827 08:56:01.851752 10163 solver.cpp:228] Iteration 5700, loss = 1.08826
I0827 08:56:01.851794 10163 solver.cpp:244]     Train net output #0: loss = 1.08826 (* 1 = 1.08826 loss)
I0827 08:56:01.851801 10163 sgd_solver.cpp:106] Iteration 5700, lr = 8.28558e-05
I0827 08:56:06.180065 10163 solver.cpp:228] Iteration 5800, loss = 1.12355
I0827 08:56:06.180105 10163 solver.cpp:244]     Train net output #0: loss = 1.12355 (* 1 = 1.12355 loss)
I0827 08:56:06.180111 10163 sgd_solver.cpp:106] Iteration 5800, lr = 8.26148e-05
I0827 08:56:10.514219 10163 solver.cpp:228] Iteration 5900, loss = 1.10704
I0827 08:56:10.514268 10163 solver.cpp:244]     Train net output #0: loss = 1.10704 (* 1 = 1.10704 loss)
I0827 08:56:10.514276 10163 sgd_solver.cpp:106] Iteration 5900, lr = 8.23754e-05
I0827 08:56:14.807328 10163 solver.cpp:337] Iteration 6000, Testing net (#0)
I0827 08:56:15.931603 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 08:56:18.551408 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 08:56:18.551461 10163 solver.cpp:404]     Test net output #1: loss = 1.10353 (* 1 = 1.10353 loss)
I0827 08:56:18.565738 10163 solver.cpp:228] Iteration 6000, loss = 1.08443
I0827 08:56:18.565768 10163 solver.cpp:244]     Train net output #0: loss = 1.08443 (* 1 = 1.08443 loss)
I0827 08:56:18.565778 10163 sgd_solver.cpp:106] Iteration 6000, lr = 8.21377e-05
I0827 08:56:22.894528 10163 solver.cpp:228] Iteration 6100, loss = 1.12051
I0827 08:56:22.894572 10163 solver.cpp:244]     Train net output #0: loss = 1.12051 (* 1 = 1.12051 loss)
I0827 08:56:22.894578 10163 sgd_solver.cpp:106] Iteration 6100, lr = 8.19015e-05
I0827 08:56:27.227360 10163 solver.cpp:228] Iteration 6200, loss = 1.11957
I0827 08:56:27.227407 10163 solver.cpp:244]     Train net output #0: loss = 1.11957 (* 1 = 1.11957 loss)
I0827 08:56:27.227416 10163 sgd_solver.cpp:106] Iteration 6200, lr = 8.1667e-05
I0827 08:56:31.558121 10163 solver.cpp:228] Iteration 6300, loss = 1.09992
I0827 08:56:31.558138 10163 solver.cpp:244]     Train net output #0: loss = 1.09992 (* 1 = 1.09992 loss)
I0827 08:56:31.558145 10163 sgd_solver.cpp:106] Iteration 6300, lr = 8.1434e-05
I0827 08:56:35.890136 10163 solver.cpp:228] Iteration 6400, loss = 1.10798
I0827 08:56:35.890178 10163 solver.cpp:244]     Train net output #0: loss = 1.10798 (* 1 = 1.10798 loss)
I0827 08:56:35.890183 10163 sgd_solver.cpp:106] Iteration 6400, lr = 8.12025e-05
I0827 08:56:40.178851 10163 solver.cpp:337] Iteration 6500, Testing net (#0)
I0827 08:56:43.366284 10163 solver.cpp:404]     Test net output #0: accuracy = 0.5785
I0827 08:56:43.366329 10163 solver.cpp:404]     Test net output #1: loss = 1.07076 (* 1 = 1.07076 loss)
I0827 08:56:43.382091 10163 solver.cpp:228] Iteration 6500, loss = 1.11675
I0827 08:56:43.382164 10163 solver.cpp:244]     Train net output #0: loss = 1.11675 (* 1 = 1.11675 loss)
I0827 08:56:43.382184 10163 sgd_solver.cpp:106] Iteration 6500, lr = 8.09726e-05
I0827 08:56:47.718006 10163 solver.cpp:228] Iteration 6600, loss = 1.10591
I0827 08:56:47.718055 10163 solver.cpp:244]     Train net output #0: loss = 1.10591 (* 1 = 1.10591 loss)
I0827 08:56:47.718062 10163 sgd_solver.cpp:106] Iteration 6600, lr = 8.07442e-05
I0827 08:56:52.048848 10163 solver.cpp:228] Iteration 6700, loss = 1.09679
I0827 08:56:52.048887 10163 solver.cpp:244]     Train net output #0: loss = 1.09679 (* 1 = 1.09679 loss)
I0827 08:56:52.048893 10163 sgd_solver.cpp:106] Iteration 6700, lr = 8.05173e-05
I0827 08:56:56.374727 10163 solver.cpp:228] Iteration 6800, loss = 1.10373
I0827 08:56:56.374771 10163 solver.cpp:244]     Train net output #0: loss = 1.10373 (* 1 = 1.10373 loss)
I0827 08:56:56.374778 10163 sgd_solver.cpp:106] Iteration 6800, lr = 8.02918e-05
I0827 08:57:00.701694 10163 solver.cpp:228] Iteration 6900, loss = 1.1303
I0827 08:57:00.701735 10163 solver.cpp:244]     Train net output #0: loss = 1.1303 (* 1 = 1.1303 loss)
I0827 08:57:00.701740 10163 sgd_solver.cpp:106] Iteration 6900, lr = 8.00679e-05
I0827 08:57:04.991724 10163 solver.cpp:337] Iteration 7000, Testing net (#0)
I0827 08:57:08.305961 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578208
I0827 08:57:08.306002 10163 solver.cpp:404]     Test net output #1: loss = 1.07433 (* 1 = 1.07433 loss)
I0827 08:57:08.321519 10163 solver.cpp:228] Iteration 7000, loss = 1.10063
I0827 08:57:08.321557 10163 solver.cpp:244]     Train net output #0: loss = 1.10063 (* 1 = 1.10063 loss)
I0827 08:57:08.321569 10163 sgd_solver.cpp:106] Iteration 7000, lr = 7.98454e-05
I0827 08:57:12.644225 10163 solver.cpp:228] Iteration 7100, loss = 1.10083
I0827 08:57:12.644284 10163 solver.cpp:244]     Train net output #0: loss = 1.10083 (* 1 = 1.10083 loss)
I0827 08:57:12.644290 10163 sgd_solver.cpp:106] Iteration 7100, lr = 7.96243e-05
I0827 08:57:16.970239 10163 solver.cpp:228] Iteration 7200, loss = 1.10477
I0827 08:57:16.970296 10163 solver.cpp:244]     Train net output #0: loss = 1.10477 (* 1 = 1.10477 loss)
I0827 08:57:16.970302 10163 sgd_solver.cpp:106] Iteration 7200, lr = 7.94046e-05
I0827 08:57:21.295406 10163 solver.cpp:228] Iteration 7300, loss = 1.08488
I0827 08:57:21.295465 10163 solver.cpp:244]     Train net output #0: loss = 1.08488 (* 1 = 1.08488 loss)
I0827 08:57:21.295471 10163 sgd_solver.cpp:106] Iteration 7300, lr = 7.91864e-05
I0827 08:57:25.616863 10163 solver.cpp:228] Iteration 7400, loss = 1.09874
I0827 08:57:25.616917 10163 solver.cpp:244]     Train net output #0: loss = 1.09874 (* 1 = 1.09874 loss)
I0827 08:57:25.616924 10163 sgd_solver.cpp:106] Iteration 7400, lr = 7.89695e-05
I0827 08:57:29.897372 10163 solver.cpp:337] Iteration 7500, Testing net (#0)
I0827 08:57:33.040457 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578583
I0827 08:57:33.040506 10163 solver.cpp:404]     Test net output #1: loss = 1.07654 (* 1 = 1.07654 loss)
I0827 08:57:33.055486 10163 solver.cpp:228] Iteration 7500, loss = 1.11034
I0827 08:57:33.055541 10163 solver.cpp:244]     Train net output #0: loss = 1.11034 (* 1 = 1.11034 loss)
I0827 08:57:33.055552 10163 sgd_solver.cpp:106] Iteration 7500, lr = 7.87541e-05
I0827 08:57:37.394404 10163 solver.cpp:228] Iteration 7600, loss = 1.09712
I0827 08:57:37.394441 10163 solver.cpp:244]     Train net output #0: loss = 1.09712 (* 1 = 1.09712 loss)
I0827 08:57:37.394446 10163 sgd_solver.cpp:106] Iteration 7600, lr = 7.854e-05
I0827 08:57:41.712512 10163 solver.cpp:228] Iteration 7700, loss = 1.10397
I0827 08:57:41.712529 10163 solver.cpp:244]     Train net output #0: loss = 1.10397 (* 1 = 1.10397 loss)
I0827 08:57:41.712534 10163 sgd_solver.cpp:106] Iteration 7700, lr = 7.83272e-05
I0827 08:57:46.035708 10163 solver.cpp:228] Iteration 7800, loss = 1.10148
I0827 08:57:46.035729 10163 solver.cpp:244]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0827 08:57:46.035734 10163 sgd_solver.cpp:106] Iteration 7800, lr = 7.81158e-05
I0827 08:57:50.358288 10163 solver.cpp:228] Iteration 7900, loss = 1.1191
I0827 08:57:50.358330 10163 solver.cpp:244]     Train net output #0: loss = 1.1191 (* 1 = 1.1191 loss)
I0827 08:57:50.358335 10163 sgd_solver.cpp:106] Iteration 7900, lr = 7.79057e-05
I0827 08:57:54.633451 10163 solver.cpp:337] Iteration 8000, Testing net (#0)
I0827 08:57:57.878872 10163 solver.cpp:404]     Test net output #0: accuracy = 0.151833
I0827 08:57:57.878914 10163 solver.cpp:404]     Test net output #1: loss = 1.11502 (* 1 = 1.11502 loss)
I0827 08:57:57.894327 10163 solver.cpp:228] Iteration 8000, loss = 1.10903
I0827 08:57:57.894364 10163 solver.cpp:244]     Train net output #0: loss = 1.10903 (* 1 = 1.10903 loss)
I0827 08:57:57.894373 10163 sgd_solver.cpp:106] Iteration 8000, lr = 7.76969e-05
I0827 08:58:02.221211 10163 solver.cpp:228] Iteration 8100, loss = 1.11119
I0827 08:58:02.221269 10163 solver.cpp:244]     Train net output #0: loss = 1.11119 (* 1 = 1.11119 loss)
I0827 08:58:02.221289 10163 sgd_solver.cpp:106] Iteration 8100, lr = 7.74895e-05
I0827 08:58:06.551728 10163 solver.cpp:228] Iteration 8200, loss = 1.09705
I0827 08:58:06.551767 10163 solver.cpp:244]     Train net output #0: loss = 1.09705 (* 1 = 1.09705 loss)
I0827 08:58:06.551772 10163 sgd_solver.cpp:106] Iteration 8200, lr = 7.72833e-05
I0827 08:58:10.880514 10163 solver.cpp:228] Iteration 8300, loss = 1.10217
I0827 08:58:10.880556 10163 solver.cpp:244]     Train net output #0: loss = 1.10217 (* 1 = 1.10217 loss)
I0827 08:58:10.880561 10163 sgd_solver.cpp:106] Iteration 8300, lr = 7.70784e-05
I0827 08:58:15.210022 10163 solver.cpp:228] Iteration 8400, loss = 1.13218
I0827 08:58:15.210069 10163 solver.cpp:244]     Train net output #0: loss = 1.13218 (* 1 = 1.13218 loss)
I0827 08:58:15.210078 10163 sgd_solver.cpp:106] Iteration 8400, lr = 7.68748e-05
I0827 08:58:19.499712 10163 solver.cpp:337] Iteration 8500, Testing net (#0)
I0827 08:58:19.932225 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 08:58:22.749225 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0827 08:58:22.749307 10163 solver.cpp:404]     Test net output #1: loss = 1.14354 (* 1 = 1.14354 loss)
I0827 08:58:22.764065 10163 solver.cpp:228] Iteration 8500, loss = 1.10823
I0827 08:58:22.764111 10163 solver.cpp:244]     Train net output #0: loss = 1.10823 (* 1 = 1.10823 loss)
I0827 08:58:22.764122 10163 sgd_solver.cpp:106] Iteration 8500, lr = 7.66724e-05
I0827 08:58:27.086374 10163 solver.cpp:228] Iteration 8600, loss = 1.07894
I0827 08:58:27.086416 10163 solver.cpp:244]     Train net output #0: loss = 1.07894 (* 1 = 1.07894 loss)
I0827 08:58:27.086421 10163 sgd_solver.cpp:106] Iteration 8600, lr = 7.64712e-05
I0827 08:58:31.413624 10163 solver.cpp:228] Iteration 8700, loss = 1.11743
I0827 08:58:31.413677 10163 solver.cpp:244]     Train net output #0: loss = 1.11743 (* 1 = 1.11743 loss)
I0827 08:58:31.413684 10163 sgd_solver.cpp:106] Iteration 8700, lr = 7.62713e-05
I0827 08:58:35.740221 10163 solver.cpp:228] Iteration 8800, loss = 1.0946
I0827 08:58:35.740277 10163 solver.cpp:244]     Train net output #0: loss = 1.0946 (* 1 = 1.0946 loss)
I0827 08:58:35.740285 10163 sgd_solver.cpp:106] Iteration 8800, lr = 7.60726e-05
I0827 08:58:40.066500 10163 solver.cpp:228] Iteration 8900, loss = 1.11343
I0827 08:58:40.066548 10163 solver.cpp:244]     Train net output #0: loss = 1.11343 (* 1 = 1.11343 loss)
I0827 08:58:40.066556 10163 sgd_solver.cpp:106] Iteration 8900, lr = 7.58751e-05
I0827 08:58:44.350487 10163 solver.cpp:337] Iteration 9000, Testing net (#0)
I0827 08:58:47.440394 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0827 08:58:47.440457 10163 solver.cpp:404]     Test net output #1: loss = 1.1415 (* 1 = 1.1415 loss)
I0827 08:58:47.455217 10163 solver.cpp:228] Iteration 9000, loss = 1.10396
I0827 08:58:47.455267 10163 solver.cpp:244]     Train net output #0: loss = 1.10396 (* 1 = 1.10396 loss)
I0827 08:58:47.455279 10163 sgd_solver.cpp:106] Iteration 9000, lr = 7.56788e-05
I0827 08:58:51.772024 10163 solver.cpp:228] Iteration 9100, loss = 1.1
I0827 08:58:51.772058 10163 solver.cpp:244]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0827 08:58:51.772063 10163 sgd_solver.cpp:106] Iteration 9100, lr = 7.54836e-05
I0827 08:58:56.090185 10163 solver.cpp:228] Iteration 9200, loss = 1.11181
I0827 08:58:56.090225 10163 solver.cpp:244]     Train net output #0: loss = 1.11181 (* 1 = 1.11181 loss)
I0827 08:58:56.090231 10163 sgd_solver.cpp:106] Iteration 9200, lr = 7.52897e-05
I0827 08:59:00.409596 10163 solver.cpp:228] Iteration 9300, loss = 1.11035
I0827 08:59:00.409616 10163 solver.cpp:244]     Train net output #0: loss = 1.11035 (* 1 = 1.11035 loss)
I0827 08:59:00.409621 10163 sgd_solver.cpp:106] Iteration 9300, lr = 7.50969e-05
I0827 08:59:04.728360 10163 solver.cpp:228] Iteration 9400, loss = 1.10042
I0827 08:59:04.728379 10163 solver.cpp:244]     Train net output #0: loss = 1.10042 (* 1 = 1.10042 loss)
I0827 08:59:04.728384 10163 sgd_solver.cpp:106] Iteration 9400, lr = 7.49052e-05
I0827 08:59:09.006799 10163 solver.cpp:337] Iteration 9500, Testing net (#0)
I0827 08:59:12.204320 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 08:59:12.204381 10163 solver.cpp:404]     Test net output #1: loss = 1.13204 (* 1 = 1.13204 loss)
I0827 08:59:12.220130 10163 solver.cpp:228] Iteration 9500, loss = 1.11333
I0827 08:59:12.220170 10163 solver.cpp:244]     Train net output #0: loss = 1.11333 (* 1 = 1.11333 loss)
I0827 08:59:12.220177 10163 sgd_solver.cpp:106] Iteration 9500, lr = 7.47147e-05
I0827 08:59:16.538914 10163 solver.cpp:228] Iteration 9600, loss = 1.10777
I0827 08:59:16.538949 10163 solver.cpp:244]     Train net output #0: loss = 1.10777 (* 1 = 1.10777 loss)
I0827 08:59:16.538954 10163 sgd_solver.cpp:106] Iteration 9600, lr = 7.45253e-05
I0827 08:59:20.863306 10163 solver.cpp:228] Iteration 9700, loss = 1.10688
I0827 08:59:20.863370 10163 solver.cpp:244]     Train net output #0: loss = 1.10688 (* 1 = 1.10688 loss)
I0827 08:59:20.863376 10163 sgd_solver.cpp:106] Iteration 9700, lr = 7.4337e-05
I0827 08:59:25.181948 10163 solver.cpp:228] Iteration 9800, loss = 1.0998
I0827 08:59:25.182010 10163 solver.cpp:244]     Train net output #0: loss = 1.0998 (* 1 = 1.0998 loss)
I0827 08:59:25.182016 10163 sgd_solver.cpp:106] Iteration 9800, lr = 7.41499e-05
I0827 08:59:29.517869 10163 solver.cpp:228] Iteration 9900, loss = 1.09866
I0827 08:59:29.517912 10163 solver.cpp:244]     Train net output #0: loss = 1.09866 (* 1 = 1.09866 loss)
I0827 08:59:29.517920 10163 sgd_solver.cpp:106] Iteration 9900, lr = 7.39638e-05
I0827 08:59:33.796419 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_10000.caffemodel
I0827 08:59:34.315469 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_10000.solverstate
I0827 08:59:34.470489 10163 solver.cpp:337] Iteration 10000, Testing net (#0)
I0827 08:59:37.866789 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 08:59:37.866835 10163 solver.cpp:404]     Test net output #1: loss = 1.11156 (* 1 = 1.11156 loss)
I0827 08:59:37.882421 10163 solver.cpp:228] Iteration 10000, loss = 1.09999
I0827 08:59:37.882490 10163 solver.cpp:244]     Train net output #0: loss = 1.09999 (* 1 = 1.09999 loss)
I0827 08:59:37.882506 10163 sgd_solver.cpp:106] Iteration 10000, lr = 7.37788e-05
I0827 08:59:42.204732 10163 solver.cpp:228] Iteration 10100, loss = 1.10184
I0827 08:59:42.204777 10163 solver.cpp:244]     Train net output #0: loss = 1.10184 (* 1 = 1.10184 loss)
I0827 08:59:42.204782 10163 sgd_solver.cpp:106] Iteration 10100, lr = 7.35949e-05
I0827 08:59:46.525493 10163 solver.cpp:228] Iteration 10200, loss = 1.09186
I0827 08:59:46.525521 10163 solver.cpp:244]     Train net output #0: loss = 1.09186 (* 1 = 1.09186 loss)
I0827 08:59:46.525527 10163 sgd_solver.cpp:106] Iteration 10200, lr = 7.3412e-05
I0827 08:59:50.848140 10163 solver.cpp:228] Iteration 10300, loss = 1.09816
I0827 08:59:50.848181 10163 solver.cpp:244]     Train net output #0: loss = 1.09816 (* 1 = 1.09816 loss)
I0827 08:59:50.848186 10163 sgd_solver.cpp:106] Iteration 10300, lr = 7.32303e-05
I0827 08:59:55.166306 10163 solver.cpp:228] Iteration 10400, loss = 1.1003
I0827 08:59:55.166342 10163 solver.cpp:244]     Train net output #0: loss = 1.1003 (* 1 = 1.1003 loss)
I0827 08:59:55.166347 10163 sgd_solver.cpp:106] Iteration 10400, lr = 7.30495e-05
I0827 08:59:59.451349 10163 solver.cpp:337] Iteration 10500, Testing net (#0)
I0827 09:00:02.656990 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 09:00:02.657034 10163 solver.cpp:404]     Test net output #1: loss = 1.10008 (* 1 = 1.10008 loss)
I0827 09:00:02.672559 10163 solver.cpp:228] Iteration 10500, loss = 1.09566
I0827 09:00:02.672624 10163 solver.cpp:244]     Train net output #0: loss = 1.09566 (* 1 = 1.09566 loss)
I0827 09:00:02.672641 10163 sgd_solver.cpp:106] Iteration 10500, lr = 7.28698e-05
I0827 09:00:06.996409 10163 solver.cpp:228] Iteration 10600, loss = 1.0842
I0827 09:00:06.996474 10163 solver.cpp:244]     Train net output #0: loss = 1.0842 (* 1 = 1.0842 loss)
I0827 09:00:06.996479 10163 sgd_solver.cpp:106] Iteration 10600, lr = 7.26911e-05
I0827 09:00:11.313788 10163 solver.cpp:228] Iteration 10700, loss = 1.1
I0827 09:00:11.313843 10163 solver.cpp:244]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0827 09:00:11.313849 10163 sgd_solver.cpp:106] Iteration 10700, lr = 7.25135e-05
I0827 09:00:15.634989 10163 solver.cpp:228] Iteration 10800, loss = 1.10491
I0827 09:00:15.635010 10163 solver.cpp:244]     Train net output #0: loss = 1.10491 (* 1 = 1.10491 loss)
I0827 09:00:15.635015 10163 sgd_solver.cpp:106] Iteration 10800, lr = 7.23368e-05
I0827 09:00:19.955399 10163 solver.cpp:228] Iteration 10900, loss = 1.0941
I0827 09:00:19.955440 10163 solver.cpp:244]     Train net output #0: loss = 1.0941 (* 1 = 1.0941 loss)
I0827 09:00:19.955446 10163 sgd_solver.cpp:106] Iteration 10900, lr = 7.21612e-05
I0827 09:00:24.228147 10163 solver.cpp:337] Iteration 11000, Testing net (#0)
I0827 09:00:27.795068 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 09:00:27.795126 10163 solver.cpp:404]     Test net output #1: loss = 1.09505 (* 1 = 1.09505 loss)
I0827 09:00:27.809430 10163 solver.cpp:228] Iteration 11000, loss = 1.1095
I0827 09:00:27.809471 10163 solver.cpp:244]     Train net output #0: loss = 1.1095 (* 1 = 1.1095 loss)
I0827 09:00:27.809484 10163 sgd_solver.cpp:106] Iteration 11000, lr = 7.19865e-05
I0827 09:00:32.137545 10163 solver.cpp:228] Iteration 11100, loss = 1.1103
I0827 09:00:32.137604 10163 solver.cpp:244]     Train net output #0: loss = 1.1103 (* 1 = 1.1103 loss)
I0827 09:00:32.137611 10163 sgd_solver.cpp:106] Iteration 11100, lr = 7.18129e-05
I0827 09:00:36.459856 10163 solver.cpp:228] Iteration 11200, loss = 1.1031
I0827 09:00:36.459913 10163 solver.cpp:244]     Train net output #0: loss = 1.1031 (* 1 = 1.1031 loss)
I0827 09:00:36.459918 10163 sgd_solver.cpp:106] Iteration 11200, lr = 7.16402e-05
I0827 09:00:40.778476 10163 solver.cpp:228] Iteration 11300, loss = 1.09084
I0827 09:00:40.778535 10163 solver.cpp:244]     Train net output #0: loss = 1.09084 (* 1 = 1.09084 loss)
I0827 09:00:40.778542 10163 sgd_solver.cpp:106] Iteration 11300, lr = 7.14684e-05
I0827 09:00:45.097668 10163 solver.cpp:228] Iteration 11400, loss = 1.09617
I0827 09:00:45.097728 10163 solver.cpp:244]     Train net output #0: loss = 1.09617 (* 1 = 1.09617 loss)
I0827 09:00:45.097734 10163 sgd_solver.cpp:106] Iteration 11400, lr = 7.12977e-05
I0827 09:00:48.380086 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:00:49.374111 10163 solver.cpp:337] Iteration 11500, Testing net (#0)
I0827 09:00:52.894608 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 09:00:52.894670 10163 solver.cpp:404]     Test net output #1: loss = 1.08195 (* 1 = 1.08195 loss)
I0827 09:00:52.910138 10163 solver.cpp:228] Iteration 11500, loss = 1.09935
I0827 09:00:52.910212 10163 solver.cpp:244]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0827 09:00:52.910228 10163 sgd_solver.cpp:106] Iteration 11500, lr = 7.11278e-05
I0827 09:00:57.241047 10163 solver.cpp:228] Iteration 11600, loss = 1.09552
I0827 09:00:57.241093 10163 solver.cpp:244]     Train net output #0: loss = 1.09552 (* 1 = 1.09552 loss)
I0827 09:00:57.241111 10163 sgd_solver.cpp:106] Iteration 11600, lr = 7.0959e-05
I0827 09:01:01.573171 10163 solver.cpp:228] Iteration 11700, loss = 1.09432
I0827 09:01:01.573210 10163 solver.cpp:244]     Train net output #0: loss = 1.09432 (* 1 = 1.09432 loss)
I0827 09:01:01.573217 10163 sgd_solver.cpp:106] Iteration 11700, lr = 7.0791e-05
I0827 09:01:05.897533 10163 solver.cpp:228] Iteration 11800, loss = 1.09784
I0827 09:01:05.897596 10163 solver.cpp:244]     Train net output #0: loss = 1.09784 (* 1 = 1.09784 loss)
I0827 09:01:05.897603 10163 sgd_solver.cpp:106] Iteration 11800, lr = 7.0624e-05
I0827 09:01:10.227113 10163 solver.cpp:228] Iteration 11900, loss = 1.10018
I0827 09:01:10.227154 10163 solver.cpp:244]     Train net output #0: loss = 1.10018 (* 1 = 1.10018 loss)
I0827 09:01:10.227160 10163 sgd_solver.cpp:106] Iteration 11900, lr = 7.04579e-05
I0827 09:01:14.503010 10163 solver.cpp:337] Iteration 12000, Testing net (#0)
I0827 09:01:17.883919 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0827 09:01:17.883965 10163 solver.cpp:404]     Test net output #1: loss = 1.06737 (* 1 = 1.06737 loss)
I0827 09:01:17.898768 10163 solver.cpp:228] Iteration 12000, loss = 1.11006
I0827 09:01:17.898808 10163 solver.cpp:244]     Train net output #0: loss = 1.11006 (* 1 = 1.11006 loss)
I0827 09:01:17.898834 10163 sgd_solver.cpp:106] Iteration 12000, lr = 7.02927e-05
I0827 09:01:22.219040 10163 solver.cpp:228] Iteration 12100, loss = 1.11812
I0827 09:01:22.219100 10163 solver.cpp:244]     Train net output #0: loss = 1.11812 (* 1 = 1.11812 loss)
I0827 09:01:22.219108 10163 sgd_solver.cpp:106] Iteration 12100, lr = 7.01284e-05
I0827 09:01:26.537813 10163 solver.cpp:228] Iteration 12200, loss = 1.10364
I0827 09:01:26.537873 10163 solver.cpp:244]     Train net output #0: loss = 1.10364 (* 1 = 1.10364 loss)
I0827 09:01:26.537879 10163 sgd_solver.cpp:106] Iteration 12200, lr = 6.9965e-05
I0827 09:01:30.859958 10163 solver.cpp:228] Iteration 12300, loss = 1.09304
I0827 09:01:30.860002 10163 solver.cpp:244]     Train net output #0: loss = 1.09304 (* 1 = 1.09304 loss)
I0827 09:01:30.860008 10163 sgd_solver.cpp:106] Iteration 12300, lr = 6.98024e-05
I0827 09:01:35.183650 10163 solver.cpp:228] Iteration 12400, loss = 1.10252
I0827 09:01:35.183691 10163 solver.cpp:244]     Train net output #0: loss = 1.10252 (* 1 = 1.10252 loss)
I0827 09:01:35.183696 10163 sgd_solver.cpp:106] Iteration 12400, lr = 6.96408e-05
I0827 09:01:39.460453 10163 solver.cpp:337] Iteration 12500, Testing net (#0)
I0827 09:01:42.900202 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578333
I0827 09:01:42.900254 10163 solver.cpp:404]     Test net output #1: loss = 1.07515 (* 1 = 1.07515 loss)
I0827 09:01:42.915094 10163 solver.cpp:228] Iteration 12500, loss = 1.09424
I0827 09:01:42.915133 10163 solver.cpp:244]     Train net output #0: loss = 1.09424 (* 1 = 1.09424 loss)
I0827 09:01:42.915145 10163 sgd_solver.cpp:106] Iteration 12500, lr = 6.948e-05
I0827 09:01:47.245487 10163 solver.cpp:228] Iteration 12600, loss = 1.0989
I0827 09:01:47.245540 10163 solver.cpp:244]     Train net output #0: loss = 1.0989 (* 1 = 1.0989 loss)
I0827 09:01:47.245550 10163 sgd_solver.cpp:106] Iteration 12600, lr = 6.93201e-05
I0827 09:01:51.568625 10163 solver.cpp:228] Iteration 12700, loss = 1.1212
I0827 09:01:51.568676 10163 solver.cpp:244]     Train net output #0: loss = 1.1212 (* 1 = 1.1212 loss)
I0827 09:01:51.568683 10163 sgd_solver.cpp:106] Iteration 12700, lr = 6.91611e-05
I0827 09:01:55.888562 10163 solver.cpp:228] Iteration 12800, loss = 1.10228
I0827 09:01:55.888619 10163 solver.cpp:244]     Train net output #0: loss = 1.10228 (* 1 = 1.10228 loss)
I0827 09:01:55.888625 10163 sgd_solver.cpp:106] Iteration 12800, lr = 6.90029e-05
I0827 09:02:00.212653 10163 solver.cpp:228] Iteration 12900, loss = 1.10036
I0827 09:02:00.212705 10163 solver.cpp:244]     Train net output #0: loss = 1.10036 (* 1 = 1.10036 loss)
I0827 09:02:00.212712 10163 sgd_solver.cpp:106] Iteration 12900, lr = 6.88455e-05
I0827 09:02:04.493403 10163 solver.cpp:337] Iteration 13000, Testing net (#0)
I0827 09:02:07.776154 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0827 09:02:07.776209 10163 solver.cpp:404]     Test net output #1: loss = 1.08835 (* 1 = 1.08835 loss)
I0827 09:02:07.791587 10163 solver.cpp:228] Iteration 13000, loss = 1.09113
I0827 09:02:07.791658 10163 solver.cpp:244]     Train net output #0: loss = 1.09113 (* 1 = 1.09113 loss)
I0827 09:02:07.791676 10163 sgd_solver.cpp:106] Iteration 13000, lr = 6.8689e-05
I0827 09:02:12.119272 10163 solver.cpp:228] Iteration 13100, loss = 1.09616
I0827 09:02:12.119326 10163 solver.cpp:244]     Train net output #0: loss = 1.09616 (* 1 = 1.09616 loss)
I0827 09:02:12.119334 10163 sgd_solver.cpp:106] Iteration 13100, lr = 6.85333e-05
I0827 09:02:16.443581 10163 solver.cpp:228] Iteration 13200, loss = 1.08793
I0827 09:02:16.443631 10163 solver.cpp:244]     Train net output #0: loss = 1.08793 (* 1 = 1.08793 loss)
I0827 09:02:16.443639 10163 sgd_solver.cpp:106] Iteration 13200, lr = 6.83784e-05
I0827 09:02:20.768319 10163 solver.cpp:228] Iteration 13300, loss = 1.11437
I0827 09:02:20.768365 10163 solver.cpp:244]     Train net output #0: loss = 1.11437 (* 1 = 1.11437 loss)
I0827 09:02:20.768371 10163 sgd_solver.cpp:106] Iteration 13300, lr = 6.82243e-05
I0827 09:02:25.097578 10163 solver.cpp:228] Iteration 13400, loss = 1.10099
I0827 09:02:25.097635 10163 solver.cpp:244]     Train net output #0: loss = 1.10099 (* 1 = 1.10099 loss)
I0827 09:02:25.097642 10163 sgd_solver.cpp:106] Iteration 13400, lr = 6.80711e-05
I0827 09:02:29.374477 10163 solver.cpp:337] Iteration 13500, Testing net (#0)
I0827 09:02:32.720818 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:02:32.839139 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:02:32.839206 10163 solver.cpp:404]     Test net output #1: loss = 1.09629 (* 1 = 1.09629 loss)
I0827 09:02:32.853216 10163 solver.cpp:228] Iteration 13500, loss = 1.10119
I0827 09:02:32.853262 10163 solver.cpp:244]     Train net output #0: loss = 1.10119 (* 1 = 1.10119 loss)
I0827 09:02:32.853271 10163 sgd_solver.cpp:106] Iteration 13500, lr = 6.79186e-05
I0827 09:02:37.178547 10163 solver.cpp:228] Iteration 13600, loss = 1.11304
I0827 09:02:37.178606 10163 solver.cpp:244]     Train net output #0: loss = 1.11304 (* 1 = 1.11304 loss)
I0827 09:02:37.178613 10163 sgd_solver.cpp:106] Iteration 13600, lr = 6.7767e-05
I0827 09:02:41.503445 10163 solver.cpp:228] Iteration 13700, loss = 1.10147
I0827 09:02:41.503504 10163 solver.cpp:244]     Train net output #0: loss = 1.10147 (* 1 = 1.10147 loss)
I0827 09:02:41.503510 10163 sgd_solver.cpp:106] Iteration 13700, lr = 6.76161e-05
I0827 09:02:45.825418 10163 solver.cpp:228] Iteration 13800, loss = 1.11608
I0827 09:02:45.825479 10163 solver.cpp:244]     Train net output #0: loss = 1.11608 (* 1 = 1.11608 loss)
I0827 09:02:45.825485 10163 sgd_solver.cpp:106] Iteration 13800, lr = 6.7466e-05
I0827 09:02:50.147524 10163 solver.cpp:228] Iteration 13900, loss = 1.10561
I0827 09:02:50.147585 10163 solver.cpp:244]     Train net output #0: loss = 1.10561 (* 1 = 1.10561 loss)
I0827 09:02:50.147593 10163 sgd_solver.cpp:106] Iteration 13900, lr = 6.73167e-05
I0827 09:02:54.428594 10163 solver.cpp:337] Iteration 14000, Testing net (#0)
I0827 09:02:57.743242 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 09:02:57.743296 10163 solver.cpp:404]     Test net output #1: loss = 1.11897 (* 1 = 1.11897 loss)
I0827 09:02:57.759687 10163 solver.cpp:228] Iteration 14000, loss = 1.11203
I0827 09:02:57.759752 10163 solver.cpp:244]     Train net output #0: loss = 1.11203 (* 1 = 1.11203 loss)
I0827 09:02:57.759773 10163 sgd_solver.cpp:106] Iteration 14000, lr = 6.71681e-05
I0827 09:03:02.079421 10163 solver.cpp:228] Iteration 14100, loss = 1.11493
I0827 09:03:02.079462 10163 solver.cpp:244]     Train net output #0: loss = 1.11493 (* 1 = 1.11493 loss)
I0827 09:03:02.079468 10163 sgd_solver.cpp:106] Iteration 14100, lr = 6.70204e-05
I0827 09:03:06.396349 10163 solver.cpp:228] Iteration 14200, loss = 1.09875
I0827 09:03:06.396389 10163 solver.cpp:244]     Train net output #0: loss = 1.09875 (* 1 = 1.09875 loss)
I0827 09:03:06.396394 10163 sgd_solver.cpp:106] Iteration 14200, lr = 6.68733e-05
I0827 09:03:10.716315 10163 solver.cpp:228] Iteration 14300, loss = 1.1043
I0827 09:03:10.716356 10163 solver.cpp:244]     Train net output #0: loss = 1.1043 (* 1 = 1.1043 loss)
I0827 09:03:10.716362 10163 sgd_solver.cpp:106] Iteration 14300, lr = 6.67271e-05
I0827 09:03:15.035171 10163 solver.cpp:228] Iteration 14400, loss = 1.10807
I0827 09:03:15.035190 10163 solver.cpp:244]     Train net output #0: loss = 1.10807 (* 1 = 1.10807 loss)
I0827 09:03:15.035195 10163 sgd_solver.cpp:106] Iteration 14400, lr = 6.65815e-05
I0827 09:03:19.312335 10163 solver.cpp:337] Iteration 14500, Testing net (#0)
I0827 09:03:22.647438 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 09:03:22.647542 10163 solver.cpp:404]     Test net output #1: loss = 1.11984 (* 1 = 1.11984 loss)
I0827 09:03:22.663854 10163 solver.cpp:228] Iteration 14500, loss = 1.0977
I0827 09:03:22.663918 10163 solver.cpp:244]     Train net output #0: loss = 1.0977 (* 1 = 1.0977 loss)
I0827 09:03:22.663934 10163 sgd_solver.cpp:106] Iteration 14500, lr = 6.64367e-05
I0827 09:03:26.987475 10163 solver.cpp:228] Iteration 14600, loss = 1.10577
I0827 09:03:26.987517 10163 solver.cpp:244]     Train net output #0: loss = 1.10577 (* 1 = 1.10577 loss)
I0827 09:03:26.987524 10163 sgd_solver.cpp:106] Iteration 14600, lr = 6.62927e-05
I0827 09:03:31.305300 10163 solver.cpp:228] Iteration 14700, loss = 1.0925
I0827 09:03:31.305340 10163 solver.cpp:244]     Train net output #0: loss = 1.0925 (* 1 = 1.0925 loss)
I0827 09:03:31.305346 10163 sgd_solver.cpp:106] Iteration 14700, lr = 6.61493e-05
I0827 09:03:35.624362 10163 solver.cpp:228] Iteration 14800, loss = 1.08676
I0827 09:03:35.624382 10163 solver.cpp:244]     Train net output #0: loss = 1.08676 (* 1 = 1.08676 loss)
I0827 09:03:35.624387 10163 sgd_solver.cpp:106] Iteration 14800, lr = 6.60067e-05
I0827 09:03:39.942360 10163 solver.cpp:228] Iteration 14900, loss = 1.09328
I0827 09:03:39.942378 10163 solver.cpp:244]     Train net output #0: loss = 1.09328 (* 1 = 1.09328 loss)
I0827 09:03:39.942383 10163 sgd_solver.cpp:106] Iteration 14900, lr = 6.58648e-05
I0827 09:03:44.218477 10163 solver.cpp:337] Iteration 15000, Testing net (#0)
I0827 09:03:47.752835 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:03:47.752892 10163 solver.cpp:404]     Test net output #1: loss = 1.10359 (* 1 = 1.10359 loss)
I0827 09:03:47.767802 10163 solver.cpp:228] Iteration 15000, loss = 1.10663
I0827 09:03:47.767848 10163 solver.cpp:244]     Train net output #0: loss = 1.10663 (* 1 = 1.10663 loss)
I0827 09:03:47.767863 10163 sgd_solver.cpp:106] Iteration 15000, lr = 6.57236e-05
I0827 09:03:52.092330 10163 solver.cpp:228] Iteration 15100, loss = 1.10627
I0827 09:03:52.092370 10163 solver.cpp:244]     Train net output #0: loss = 1.10627 (* 1 = 1.10627 loss)
I0827 09:03:52.092375 10163 sgd_solver.cpp:106] Iteration 15100, lr = 6.55831e-05
I0827 09:03:56.416652 10163 solver.cpp:228] Iteration 15200, loss = 1.104
I0827 09:03:56.416693 10163 solver.cpp:244]     Train net output #0: loss = 1.104 (* 1 = 1.104 loss)
I0827 09:03:56.416699 10163 sgd_solver.cpp:106] Iteration 15200, lr = 6.54433e-05
I0827 09:04:00.735808 10163 solver.cpp:228] Iteration 15300, loss = 1.09595
I0827 09:04:00.735826 10163 solver.cpp:244]     Train net output #0: loss = 1.09595 (* 1 = 1.09595 loss)
I0827 09:04:00.735831 10163 sgd_solver.cpp:106] Iteration 15300, lr = 6.53043e-05
I0827 09:04:05.060451 10163 solver.cpp:228] Iteration 15400, loss = 1.11087
I0827 09:04:05.060492 10163 solver.cpp:244]     Train net output #0: loss = 1.11087 (* 1 = 1.11087 loss)
I0827 09:04:05.060498 10163 sgd_solver.cpp:106] Iteration 15400, lr = 6.51658e-05
I0827 09:04:09.335326 10163 solver.cpp:337] Iteration 15500, Testing net (#0)
I0827 09:04:12.849359 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0827 09:04:12.849418 10163 solver.cpp:404]     Test net output #1: loss = 1.09063 (* 1 = 1.09063 loss)
I0827 09:04:12.863760 10163 solver.cpp:228] Iteration 15500, loss = 1.11318
I0827 09:04:12.863813 10163 solver.cpp:244]     Train net output #0: loss = 1.11318 (* 1 = 1.11318 loss)
I0827 09:04:12.863834 10163 sgd_solver.cpp:106] Iteration 15500, lr = 6.50281e-05
I0827 09:04:17.193395 10163 solver.cpp:228] Iteration 15600, loss = 1.12358
I0827 09:04:17.193446 10163 solver.cpp:244]     Train net output #0: loss = 1.12358 (* 1 = 1.12358 loss)
I0827 09:04:17.193454 10163 sgd_solver.cpp:106] Iteration 15600, lr = 6.48911e-05
I0827 09:04:21.520735 10163 solver.cpp:228] Iteration 15700, loss = 1.10393
I0827 09:04:21.520793 10163 solver.cpp:244]     Train net output #0: loss = 1.10393 (* 1 = 1.10393 loss)
I0827 09:04:21.520800 10163 sgd_solver.cpp:106] Iteration 15700, lr = 6.47547e-05
I0827 09:04:25.850312 10163 solver.cpp:228] Iteration 15800, loss = 1.09793
I0827 09:04:25.850358 10163 solver.cpp:244]     Train net output #0: loss = 1.09793 (* 1 = 1.09793 loss)
I0827 09:04:25.850363 10163 sgd_solver.cpp:106] Iteration 15800, lr = 6.4619e-05
I0827 09:04:30.184905 10163 solver.cpp:228] Iteration 15900, loss = 1.1205
I0827 09:04:30.184967 10163 solver.cpp:244]     Train net output #0: loss = 1.1205 (* 1 = 1.1205 loss)
I0827 09:04:30.184978 10163 sgd_solver.cpp:106] Iteration 15900, lr = 6.4484e-05
I0827 09:04:34.460832 10163 solver.cpp:337] Iteration 16000, Testing net (#0)
I0827 09:04:36.715733 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:04:38.066697 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0827 09:04:38.066759 10163 solver.cpp:404]     Test net output #1: loss = 1.09281 (* 1 = 1.09281 loss)
I0827 09:04:38.082236 10163 solver.cpp:228] Iteration 16000, loss = 1.10424
I0827 09:04:38.082300 10163 solver.cpp:244]     Train net output #0: loss = 1.10424 (* 1 = 1.10424 loss)
I0827 09:04:38.082321 10163 sgd_solver.cpp:106] Iteration 16000, lr = 6.43496e-05
I0827 09:04:42.407455 10163 solver.cpp:228] Iteration 16100, loss = 1.09147
I0827 09:04:42.407495 10163 solver.cpp:244]     Train net output #0: loss = 1.09147 (* 1 = 1.09147 loss)
I0827 09:04:42.407500 10163 sgd_solver.cpp:106] Iteration 16100, lr = 6.42158e-05
I0827 09:04:46.729892 10163 solver.cpp:228] Iteration 16200, loss = 1.10166
I0827 09:04:46.729912 10163 solver.cpp:244]     Train net output #0: loss = 1.10166 (* 1 = 1.10166 loss)
I0827 09:04:46.729918 10163 sgd_solver.cpp:106] Iteration 16200, lr = 6.40827e-05
I0827 09:04:51.053830 10163 solver.cpp:228] Iteration 16300, loss = 1.08674
I0827 09:04:51.053871 10163 solver.cpp:244]     Train net output #0: loss = 1.08674 (* 1 = 1.08674 loss)
I0827 09:04:51.053877 10163 sgd_solver.cpp:106] Iteration 16300, lr = 6.39503e-05
I0827 09:04:55.373844 10163 solver.cpp:228] Iteration 16400, loss = 1.09872
I0827 09:04:55.373885 10163 solver.cpp:244]     Train net output #0: loss = 1.09872 (* 1 = 1.09872 loss)
I0827 09:04:55.373891 10163 sgd_solver.cpp:106] Iteration 16400, lr = 6.38185e-05
I0827 09:04:59.652056 10163 solver.cpp:337] Iteration 16500, Testing net (#0)
I0827 09:05:03.227605 10163 solver.cpp:404]     Test net output #0: accuracy = 0.268917
I0827 09:05:03.227658 10163 solver.cpp:404]     Test net output #1: loss = 1.08933 (* 1 = 1.08933 loss)
I0827 09:05:03.243023 10163 solver.cpp:228] Iteration 16500, loss = 1.10281
I0827 09:05:03.243090 10163 solver.cpp:244]     Train net output #0: loss = 1.10281 (* 1 = 1.10281 loss)
I0827 09:05:03.243108 10163 sgd_solver.cpp:106] Iteration 16500, lr = 6.36873e-05
I0827 09:05:07.568413 10163 solver.cpp:228] Iteration 16600, loss = 1.10766
I0827 09:05:07.568466 10163 solver.cpp:244]     Train net output #0: loss = 1.10766 (* 1 = 1.10766 loss)
I0827 09:05:07.568475 10163 sgd_solver.cpp:106] Iteration 16600, lr = 6.35567e-05
I0827 09:05:11.891932 10163 solver.cpp:228] Iteration 16700, loss = 1.09528
I0827 09:05:11.891986 10163 solver.cpp:244]     Train net output #0: loss = 1.09528 (* 1 = 1.09528 loss)
I0827 09:05:11.891993 10163 sgd_solver.cpp:106] Iteration 16700, lr = 6.34268e-05
I0827 09:05:16.216274 10163 solver.cpp:228] Iteration 16800, loss = 1.09794
I0827 09:05:16.216341 10163 solver.cpp:244]     Train net output #0: loss = 1.09794 (* 1 = 1.09794 loss)
I0827 09:05:16.216356 10163 sgd_solver.cpp:106] Iteration 16800, lr = 6.32975e-05
I0827 09:05:20.542448 10163 solver.cpp:228] Iteration 16900, loss = 1.09472
I0827 09:05:20.542502 10163 solver.cpp:244]     Train net output #0: loss = 1.09472 (* 1 = 1.09472 loss)
I0827 09:05:20.542511 10163 sgd_solver.cpp:106] Iteration 16900, lr = 6.31688e-05
I0827 09:05:24.828004 10163 solver.cpp:337] Iteration 17000, Testing net (#0)
I0827 09:05:28.031827 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 09:05:28.031870 10163 solver.cpp:404]     Test net output #1: loss = 1.09827 (* 1 = 1.09827 loss)
I0827 09:05:28.046547 10163 solver.cpp:228] Iteration 17000, loss = 1.10559
I0827 09:05:28.046566 10163 solver.cpp:244]     Train net output #0: loss = 1.10559 (* 1 = 1.10559 loss)
I0827 09:05:28.046572 10163 sgd_solver.cpp:106] Iteration 17000, lr = 6.30407e-05
I0827 09:05:32.377777 10163 solver.cpp:228] Iteration 17100, loss = 1.10821
I0827 09:05:32.377826 10163 solver.cpp:244]     Train net output #0: loss = 1.10821 (* 1 = 1.10821 loss)
I0827 09:05:32.377833 10163 sgd_solver.cpp:106] Iteration 17100, lr = 6.29132e-05
I0827 09:05:36.704120 10163 solver.cpp:228] Iteration 17200, loss = 1.10636
I0827 09:05:36.704165 10163 solver.cpp:244]     Train net output #0: loss = 1.10636 (* 1 = 1.10636 loss)
I0827 09:05:36.704171 10163 sgd_solver.cpp:106] Iteration 17200, lr = 6.27864e-05
I0827 09:05:41.024442 10163 solver.cpp:228] Iteration 17300, loss = 1.10641
I0827 09:05:41.024489 10163 solver.cpp:244]     Train net output #0: loss = 1.10641 (* 1 = 1.10641 loss)
I0827 09:05:41.024498 10163 sgd_solver.cpp:106] Iteration 17300, lr = 6.26601e-05
I0827 09:05:45.351498 10163 solver.cpp:228] Iteration 17400, loss = 1.11497
I0827 09:05:45.351541 10163 solver.cpp:244]     Train net output #0: loss = 1.11497 (* 1 = 1.11497 loss)
I0827 09:05:45.351546 10163 sgd_solver.cpp:106] Iteration 17400, lr = 6.25344e-05
I0827 09:05:49.632004 10163 solver.cpp:337] Iteration 17500, Testing net (#0)
I0827 09:05:53.043829 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269708
I0827 09:05:53.043926 10163 solver.cpp:404]     Test net output #1: loss = 1.09549 (* 1 = 1.09549 loss)
I0827 09:05:53.058076 10163 solver.cpp:228] Iteration 17500, loss = 1.09488
I0827 09:05:53.058145 10163 solver.cpp:244]     Train net output #0: loss = 1.09488 (* 1 = 1.09488 loss)
I0827 09:05:53.058153 10163 sgd_solver.cpp:106] Iteration 17500, lr = 6.24093e-05
I0827 09:05:57.389996 10163 solver.cpp:228] Iteration 17600, loss = 1.10785
I0827 09:05:57.390049 10163 solver.cpp:244]     Train net output #0: loss = 1.10785 (* 1 = 1.10785 loss)
I0827 09:05:57.390056 10163 sgd_solver.cpp:106] Iteration 17600, lr = 6.22847e-05
I0827 09:06:01.712448 10163 solver.cpp:228] Iteration 17700, loss = 1.10451
I0827 09:06:01.712508 10163 solver.cpp:244]     Train net output #0: loss = 1.10451 (* 1 = 1.10451 loss)
I0827 09:06:01.712515 10163 sgd_solver.cpp:106] Iteration 17700, lr = 6.21608e-05
I0827 09:06:06.037657 10163 solver.cpp:228] Iteration 17800, loss = 1.09806
I0827 09:06:06.037703 10163 solver.cpp:244]     Train net output #0: loss = 1.09806 (* 1 = 1.09806 loss)
I0827 09:06:06.037708 10163 sgd_solver.cpp:106] Iteration 17800, lr = 6.20374e-05
I0827 09:06:10.359557 10163 solver.cpp:228] Iteration 17900, loss = 1.09214
I0827 09:06:10.359598 10163 solver.cpp:244]     Train net output #0: loss = 1.09214 (* 1 = 1.09214 loss)
I0827 09:06:10.359604 10163 sgd_solver.cpp:106] Iteration 17900, lr = 6.19146e-05
I0827 09:06:14.649704 10163 solver.cpp:337] Iteration 18000, Testing net (#0)
I0827 09:06:18.063498 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269792
I0827 09:06:18.063566 10163 solver.cpp:404]     Test net output #1: loss = 1.09247 (* 1 = 1.09247 loss)
I0827 09:06:18.079155 10163 solver.cpp:228] Iteration 18000, loss = 1.09047
I0827 09:06:18.079234 10163 solver.cpp:244]     Train net output #0: loss = 1.09047 (* 1 = 1.09047 loss)
I0827 09:06:18.079251 10163 sgd_solver.cpp:106] Iteration 18000, lr = 6.17924e-05
I0827 09:06:22.399844 10163 solver.cpp:228] Iteration 18100, loss = 1.10672
I0827 09:06:22.399884 10163 solver.cpp:244]     Train net output #0: loss = 1.10672 (* 1 = 1.10672 loss)
I0827 09:06:22.399890 10163 sgd_solver.cpp:106] Iteration 18100, lr = 6.16707e-05
I0827 09:06:26.720623 10163 solver.cpp:228] Iteration 18200, loss = 1.10011
I0827 09:06:26.720662 10163 solver.cpp:244]     Train net output #0: loss = 1.10011 (* 1 = 1.10011 loss)
I0827 09:06:26.720669 10163 sgd_solver.cpp:106] Iteration 18200, lr = 6.15496e-05
I0827 09:06:31.044806 10163 solver.cpp:228] Iteration 18300, loss = 1.10029
I0827 09:06:31.044857 10163 solver.cpp:244]     Train net output #0: loss = 1.10029 (* 1 = 1.10029 loss)
I0827 09:06:31.044862 10163 sgd_solver.cpp:106] Iteration 18300, lr = 6.1429e-05
I0827 09:06:35.382333 10163 solver.cpp:228] Iteration 18400, loss = 1.1046
I0827 09:06:35.382383 10163 solver.cpp:244]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0827 09:06:35.382391 10163 sgd_solver.cpp:106] Iteration 18400, lr = 6.1309e-05
I0827 09:06:39.659965 10163 solver.cpp:337] Iteration 18500, Testing net (#0)
I0827 09:06:41.292879 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:06:42.992874 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 09:06:42.992943 10163 solver.cpp:404]     Test net output #1: loss = 1.1002 (* 1 = 1.1002 loss)
I0827 09:06:43.008422 10163 solver.cpp:228] Iteration 18500, loss = 1.10424
I0827 09:06:43.008497 10163 solver.cpp:244]     Train net output #0: loss = 1.10424 (* 1 = 1.10424 loss)
I0827 09:06:43.008514 10163 sgd_solver.cpp:106] Iteration 18500, lr = 6.11895e-05
I0827 09:06:47.330449 10163 solver.cpp:228] Iteration 18600, loss = 1.10168
I0827 09:06:47.330492 10163 solver.cpp:244]     Train net output #0: loss = 1.10168 (* 1 = 1.10168 loss)
I0827 09:06:47.330497 10163 sgd_solver.cpp:106] Iteration 18600, lr = 6.10706e-05
I0827 09:06:51.649559 10163 solver.cpp:228] Iteration 18700, loss = 1.09421
I0827 09:06:51.649579 10163 solver.cpp:244]     Train net output #0: loss = 1.09421 (* 1 = 1.09421 loss)
I0827 09:06:51.649583 10163 sgd_solver.cpp:106] Iteration 18700, lr = 6.09522e-05
I0827 09:06:55.973505 10163 solver.cpp:228] Iteration 18800, loss = 1.09536
I0827 09:06:55.973546 10163 solver.cpp:244]     Train net output #0: loss = 1.09536 (* 1 = 1.09536 loss)
I0827 09:06:55.973552 10163 sgd_solver.cpp:106] Iteration 18800, lr = 6.08343e-05
I0827 09:07:00.296478 10163 solver.cpp:228] Iteration 18900, loss = 1.11378
I0827 09:07:00.296517 10163 solver.cpp:244]     Train net output #0: loss = 1.11378 (* 1 = 1.11378 loss)
I0827 09:07:00.296522 10163 sgd_solver.cpp:106] Iteration 18900, lr = 6.0717e-05
I0827 09:07:04.578353 10163 solver.cpp:337] Iteration 19000, Testing net (#0)
I0827 09:07:07.944284 10163 solver.cpp:404]     Test net output #0: accuracy = 0.268917
I0827 09:07:07.944356 10163 solver.cpp:404]     Test net output #1: loss = 1.10965 (* 1 = 1.10965 loss)
I0827 09:07:07.958935 10163 solver.cpp:228] Iteration 19000, loss = 1.09225
I0827 09:07:07.958998 10163 solver.cpp:244]     Train net output #0: loss = 1.09225 (* 1 = 1.09225 loss)
I0827 09:07:07.959013 10163 sgd_solver.cpp:106] Iteration 19000, lr = 6.06002e-05
I0827 09:07:12.289301 10163 solver.cpp:228] Iteration 19100, loss = 1.10196
I0827 09:07:12.289347 10163 solver.cpp:244]     Train net output #0: loss = 1.10196 (* 1 = 1.10196 loss)
I0827 09:07:12.289353 10163 sgd_solver.cpp:106] Iteration 19100, lr = 6.04839e-05
I0827 09:07:16.613606 10163 solver.cpp:228] Iteration 19200, loss = 1.10599
I0827 09:07:16.613649 10163 solver.cpp:244]     Train net output #0: loss = 1.10599 (* 1 = 1.10599 loss)
I0827 09:07:16.613656 10163 sgd_solver.cpp:106] Iteration 19200, lr = 6.03682e-05
I0827 09:07:20.934742 10163 solver.cpp:228] Iteration 19300, loss = 1.09274
I0827 09:07:20.934799 10163 solver.cpp:244]     Train net output #0: loss = 1.09274 (* 1 = 1.09274 loss)
I0827 09:07:20.934806 10163 sgd_solver.cpp:106] Iteration 19300, lr = 6.02529e-05
I0827 09:07:25.263602 10163 solver.cpp:228] Iteration 19400, loss = 1.09669
I0827 09:07:25.263641 10163 solver.cpp:244]     Train net output #0: loss = 1.09669 (* 1 = 1.09669 loss)
I0827 09:07:25.263648 10163 sgd_solver.cpp:106] Iteration 19400, lr = 6.01382e-05
I0827 09:07:29.542116 10163 solver.cpp:337] Iteration 19500, Testing net (#0)
I0827 09:07:32.933293 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:07:32.933334 10163 solver.cpp:404]     Test net output #1: loss = 1.12036 (* 1 = 1.12036 loss)
I0827 09:07:32.948878 10163 solver.cpp:228] Iteration 19500, loss = 1.10195
I0827 09:07:32.948930 10163 solver.cpp:244]     Train net output #0: loss = 1.10195 (* 1 = 1.10195 loss)
I0827 09:07:32.948961 10163 sgd_solver.cpp:106] Iteration 19500, lr = 6.0024e-05
I0827 09:07:37.273324 10163 solver.cpp:228] Iteration 19600, loss = 1.1116
I0827 09:07:37.273371 10163 solver.cpp:244]     Train net output #0: loss = 1.1116 (* 1 = 1.1116 loss)
I0827 09:07:37.273378 10163 sgd_solver.cpp:106] Iteration 19600, lr = 5.99102e-05
I0827 09:07:41.594521 10163 solver.cpp:228] Iteration 19700, loss = 1.09516
I0827 09:07:41.594583 10163 solver.cpp:244]     Train net output #0: loss = 1.09516 (* 1 = 1.09516 loss)
I0827 09:07:41.594590 10163 sgd_solver.cpp:106] Iteration 19700, lr = 5.9797e-05
I0827 09:07:45.920392 10163 solver.cpp:228] Iteration 19800, loss = 1.10764
I0827 09:07:45.920455 10163 solver.cpp:244]     Train net output #0: loss = 1.10764 (* 1 = 1.10764 loss)
I0827 09:07:45.920462 10163 sgd_solver.cpp:106] Iteration 19800, lr = 5.96843e-05
I0827 09:07:50.251327 10163 solver.cpp:228] Iteration 19900, loss = 1.10439
I0827 09:07:50.251371 10163 solver.cpp:244]     Train net output #0: loss = 1.10439 (* 1 = 1.10439 loss)
I0827 09:07:50.251377 10163 sgd_solver.cpp:106] Iteration 19900, lr = 5.95721e-05
I0827 09:07:54.530103 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_20000.caffemodel
I0827 09:07:55.007294 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_20000.solverstate
I0827 09:07:55.162849 10163 solver.cpp:337] Iteration 20000, Testing net (#0)
I0827 09:07:58.668448 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 09:07:58.668496 10163 solver.cpp:404]     Test net output #1: loss = 1.11809 (* 1 = 1.11809 loss)
I0827 09:07:58.683864 10163 solver.cpp:228] Iteration 20000, loss = 1.09951
I0827 09:07:58.683931 10163 solver.cpp:244]     Train net output #0: loss = 1.09951 (* 1 = 1.09951 loss)
I0827 09:07:58.683943 10163 sgd_solver.cpp:106] Iteration 20000, lr = 5.94604e-05
I0827 09:08:03.025867 10163 solver.cpp:228] Iteration 20100, loss = 1.10577
I0827 09:08:03.025923 10163 solver.cpp:244]     Train net output #0: loss = 1.10577 (* 1 = 1.10577 loss)
I0827 09:08:03.025929 10163 sgd_solver.cpp:106] Iteration 20100, lr = 5.93491e-05
I0827 09:08:07.341886 10163 solver.cpp:228] Iteration 20200, loss = 1.10845
I0827 09:08:07.341907 10163 solver.cpp:244]     Train net output #0: loss = 1.10845 (* 1 = 1.10845 loss)
I0827 09:08:07.341912 10163 sgd_solver.cpp:106] Iteration 20200, lr = 5.92383e-05
I0827 09:08:11.666261 10163 solver.cpp:228] Iteration 20300, loss = 1.11692
I0827 09:08:11.666312 10163 solver.cpp:244]     Train net output #0: loss = 1.11692 (* 1 = 1.11692 loss)
I0827 09:08:11.666318 10163 sgd_solver.cpp:106] Iteration 20300, lr = 5.91281e-05
I0827 09:08:15.988476 10163 solver.cpp:228] Iteration 20400, loss = 1.10554
I0827 09:08:15.988497 10163 solver.cpp:244]     Train net output #0: loss = 1.10554 (* 1 = 1.10554 loss)
I0827 09:08:15.988502 10163 sgd_solver.cpp:106] Iteration 20400, lr = 5.90183e-05
I0827 09:08:20.272857 10163 solver.cpp:337] Iteration 20500, Testing net (#0)
I0827 09:08:23.872143 10163 solver.cpp:404]     Test net output #0: accuracy = 0.1525
I0827 09:08:23.872205 10163 solver.cpp:404]     Test net output #1: loss = 1.11074 (* 1 = 1.11074 loss)
I0827 09:08:23.892340 10163 solver.cpp:228] Iteration 20500, loss = 1.10507
I0827 09:08:23.892405 10163 solver.cpp:244]     Train net output #0: loss = 1.10507 (* 1 = 1.10507 loss)
I0827 09:08:23.892427 10163 sgd_solver.cpp:106] Iteration 20500, lr = 5.89089e-05
I0827 09:08:28.212155 10163 solver.cpp:228] Iteration 20600, loss = 1.09699
I0827 09:08:28.212196 10163 solver.cpp:244]     Train net output #0: loss = 1.09699 (* 1 = 1.09699 loss)
I0827 09:08:28.212203 10163 sgd_solver.cpp:106] Iteration 20600, lr = 5.88001e-05
I0827 09:08:32.532953 10163 solver.cpp:228] Iteration 20700, loss = 1.10971
I0827 09:08:32.532991 10163 solver.cpp:244]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0827 09:08:32.532996 10163 sgd_solver.cpp:106] Iteration 20700, lr = 5.86917e-05
I0827 09:08:36.854354 10163 solver.cpp:228] Iteration 20800, loss = 1.09468
I0827 09:08:36.854389 10163 solver.cpp:244]     Train net output #0: loss = 1.09468 (* 1 = 1.09468 loss)
I0827 09:08:36.854395 10163 sgd_solver.cpp:106] Iteration 20800, lr = 5.85838e-05
I0827 09:08:41.179009 10163 solver.cpp:228] Iteration 20900, loss = 1.10339
I0827 09:08:41.179056 10163 solver.cpp:244]     Train net output #0: loss = 1.10339 (* 1 = 1.10339 loss)
I0827 09:08:41.179064 10163 sgd_solver.cpp:106] Iteration 20900, lr = 5.84763e-05
I0827 09:08:44.116164 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:08:45.455328 10163 solver.cpp:337] Iteration 21000, Testing net (#0)
I0827 09:08:48.948999 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 09:08:48.949045 10163 solver.cpp:404]     Test net output #1: loss = 1.10397 (* 1 = 1.10397 loss)
I0827 09:08:48.963933 10163 solver.cpp:228] Iteration 21000, loss = 1.1065
I0827 09:08:48.963971 10163 solver.cpp:244]     Train net output #0: loss = 1.1065 (* 1 = 1.1065 loss)
I0827 09:08:48.963982 10163 sgd_solver.cpp:106] Iteration 21000, lr = 5.83693e-05
I0827 09:08:53.293498 10163 solver.cpp:228] Iteration 21100, loss = 1.09081
I0827 09:08:53.293540 10163 solver.cpp:244]     Train net output #0: loss = 1.09081 (* 1 = 1.09081 loss)
I0827 09:08:53.293546 10163 sgd_solver.cpp:106] Iteration 21100, lr = 5.82628e-05
I0827 09:08:57.609448 10163 solver.cpp:228] Iteration 21200, loss = 1.09455
I0827 09:08:57.609488 10163 solver.cpp:244]     Train net output #0: loss = 1.09455 (* 1 = 1.09455 loss)
I0827 09:08:57.609493 10163 sgd_solver.cpp:106] Iteration 21200, lr = 5.81567e-05
I0827 09:09:01.921833 10163 solver.cpp:228] Iteration 21300, loss = 1.09722
I0827 09:09:01.921852 10163 solver.cpp:244]     Train net output #0: loss = 1.09722 (* 1 = 1.09722 loss)
I0827 09:09:01.921857 10163 sgd_solver.cpp:106] Iteration 21300, lr = 5.8051e-05
I0827 09:09:06.238842 10163 solver.cpp:228] Iteration 21400, loss = 1.10176
I0827 09:09:06.238883 10163 solver.cpp:244]     Train net output #0: loss = 1.10176 (* 1 = 1.10176 loss)
I0827 09:09:06.238888 10163 sgd_solver.cpp:106] Iteration 21400, lr = 5.79458e-05
I0827 09:09:10.512065 10163 solver.cpp:337] Iteration 21500, Testing net (#0)
I0827 09:09:13.763048 10163 solver.cpp:404]     Test net output #0: accuracy = 0.57875
I0827 09:09:13.763141 10163 solver.cpp:404]     Test net output #1: loss = 1.09141 (* 1 = 1.09141 loss)
I0827 09:09:13.779608 10163 solver.cpp:228] Iteration 21500, loss = 1.10346
I0827 09:09:13.779680 10163 solver.cpp:244]     Train net output #0: loss = 1.10346 (* 1 = 1.10346 loss)
I0827 09:09:13.779696 10163 sgd_solver.cpp:106] Iteration 21500, lr = 5.78411e-05
I0827 09:09:18.106500 10163 solver.cpp:228] Iteration 21600, loss = 1.09274
I0827 09:09:18.106551 10163 solver.cpp:244]     Train net output #0: loss = 1.09274 (* 1 = 1.09274 loss)
I0827 09:09:18.106562 10163 sgd_solver.cpp:106] Iteration 21600, lr = 5.77368e-05
I0827 09:09:22.428421 10163 solver.cpp:228] Iteration 21700, loss = 1.10278
I0827 09:09:22.428459 10163 solver.cpp:244]     Train net output #0: loss = 1.10278 (* 1 = 1.10278 loss)
I0827 09:09:22.428465 10163 sgd_solver.cpp:106] Iteration 21700, lr = 5.76329e-05
I0827 09:09:26.748811 10163 solver.cpp:228] Iteration 21800, loss = 1.08864
I0827 09:09:26.748829 10163 solver.cpp:244]     Train net output #0: loss = 1.08864 (* 1 = 1.08864 loss)
I0827 09:09:26.748836 10163 sgd_solver.cpp:106] Iteration 21800, lr = 5.75295e-05
I0827 09:09:31.069244 10163 solver.cpp:228] Iteration 21900, loss = 1.08932
I0827 09:09:31.069301 10163 solver.cpp:244]     Train net output #0: loss = 1.08932 (* 1 = 1.08932 loss)
I0827 09:09:31.069308 10163 sgd_solver.cpp:106] Iteration 21900, lr = 5.74264e-05
I0827 09:09:35.355553 10163 solver.cpp:337] Iteration 22000, Testing net (#0)
I0827 09:09:38.856556 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578542
I0827 09:09:38.856619 10163 solver.cpp:404]     Test net output #1: loss = 1.08699 (* 1 = 1.08699 loss)
I0827 09:09:38.871417 10163 solver.cpp:228] Iteration 22000, loss = 1.11606
I0827 09:09:38.871481 10163 solver.cpp:244]     Train net output #0: loss = 1.11606 (* 1 = 1.11606 loss)
I0827 09:09:38.871498 10163 sgd_solver.cpp:106] Iteration 22000, lr = 5.73239e-05
I0827 09:09:43.199403 10163 solver.cpp:228] Iteration 22100, loss = 1.10565
I0827 09:09:43.199451 10163 solver.cpp:244]     Train net output #0: loss = 1.10565 (* 1 = 1.10565 loss)
I0827 09:09:43.199460 10163 sgd_solver.cpp:106] Iteration 22100, lr = 5.72217e-05
I0827 09:09:47.523973 10163 solver.cpp:228] Iteration 22200, loss = 1.10612
I0827 09:09:47.523993 10163 solver.cpp:244]     Train net output #0: loss = 1.10612 (* 1 = 1.10612 loss)
I0827 09:09:47.523999 10163 sgd_solver.cpp:106] Iteration 22200, lr = 5.712e-05
I0827 09:09:51.852728 10163 solver.cpp:228] Iteration 22300, loss = 1.09079
I0827 09:09:51.852771 10163 solver.cpp:244]     Train net output #0: loss = 1.09079 (* 1 = 1.09079 loss)
I0827 09:09:51.852777 10163 sgd_solver.cpp:106] Iteration 22300, lr = 5.70187e-05
I0827 09:09:56.174793 10163 solver.cpp:228] Iteration 22400, loss = 1.10795
I0827 09:09:56.174836 10163 solver.cpp:244]     Train net output #0: loss = 1.10795 (* 1 = 1.10795 loss)
I0827 09:09:56.174842 10163 sgd_solver.cpp:106] Iteration 22400, lr = 5.69178e-05
I0827 09:10:00.459945 10163 solver.cpp:337] Iteration 22500, Testing net (#0)
I0827 09:10:03.724112 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0827 09:10:03.724155 10163 solver.cpp:404]     Test net output #1: loss = 1.09839 (* 1 = 1.09839 loss)
I0827 09:10:03.739413 10163 solver.cpp:228] Iteration 22500, loss = 1.09707
I0827 09:10:03.739478 10163 solver.cpp:244]     Train net output #0: loss = 1.09707 (* 1 = 1.09707 loss)
I0827 09:10:03.739495 10163 sgd_solver.cpp:106] Iteration 22500, lr = 5.68173e-05
I0827 09:10:08.070206 10163 solver.cpp:228] Iteration 22600, loss = 1.09718
I0827 09:10:08.070264 10163 solver.cpp:244]     Train net output #0: loss = 1.09718 (* 1 = 1.09718 loss)
I0827 09:10:08.070271 10163 sgd_solver.cpp:106] Iteration 22600, lr = 5.67173e-05
I0827 09:10:12.389266 10163 solver.cpp:228] Iteration 22700, loss = 1.10074
I0827 09:10:12.389291 10163 solver.cpp:244]     Train net output #0: loss = 1.10074 (* 1 = 1.10074 loss)
I0827 09:10:12.389297 10163 sgd_solver.cpp:106] Iteration 22700, lr = 5.66176e-05
I0827 09:10:16.710218 10163 solver.cpp:228] Iteration 22800, loss = 1.10279
I0827 09:10:16.710258 10163 solver.cpp:244]     Train net output #0: loss = 1.10279 (* 1 = 1.10279 loss)
I0827 09:10:16.710264 10163 sgd_solver.cpp:106] Iteration 22800, lr = 5.65184e-05
I0827 09:10:21.032289 10163 solver.cpp:228] Iteration 22900, loss = 1.10847
I0827 09:10:21.032330 10163 solver.cpp:244]     Train net output #0: loss = 1.10847 (* 1 = 1.10847 loss)
I0827 09:10:21.032336 10163 sgd_solver.cpp:106] Iteration 22900, lr = 5.64195e-05
I0827 09:10:25.315398 10163 solver.cpp:337] Iteration 23000, Testing net (#0)
I0827 09:10:28.603711 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269375
I0827 09:10:28.603772 10163 solver.cpp:404]     Test net output #1: loss = 1.10685 (* 1 = 1.10685 loss)
I0827 09:10:28.618016 10163 solver.cpp:228] Iteration 23000, loss = 1.11193
I0827 09:10:28.618064 10163 solver.cpp:244]     Train net output #0: loss = 1.11193 (* 1 = 1.11193 loss)
I0827 09:10:28.618077 10163 sgd_solver.cpp:106] Iteration 23000, lr = 5.63211e-05
I0827 09:10:32.935617 10163 solver.cpp:228] Iteration 23100, loss = 1.0997
I0827 09:10:32.935638 10163 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0827 09:10:32.935643 10163 sgd_solver.cpp:106] Iteration 23100, lr = 5.62231e-05
I0827 09:10:37.256208 10163 solver.cpp:228] Iteration 23200, loss = 1.10322
I0827 09:10:37.256247 10163 solver.cpp:244]     Train net output #0: loss = 1.10322 (* 1 = 1.10322 loss)
I0827 09:10:37.256253 10163 sgd_solver.cpp:106] Iteration 23200, lr = 5.61254e-05
I0827 09:10:41.575228 10163 solver.cpp:228] Iteration 23300, loss = 1.09796
I0827 09:10:41.575271 10163 solver.cpp:244]     Train net output #0: loss = 1.09796 (* 1 = 1.09796 loss)
I0827 09:10:41.575278 10163 sgd_solver.cpp:106] Iteration 23300, lr = 5.60282e-05
I0827 09:10:45.895673 10163 solver.cpp:228] Iteration 23400, loss = 1.09685
I0827 09:10:45.895725 10163 solver.cpp:244]     Train net output #0: loss = 1.09685 (* 1 = 1.09685 loss)
I0827 09:10:45.895733 10163 sgd_solver.cpp:106] Iteration 23400, lr = 5.59313e-05
I0827 09:10:50.170368 10163 solver.cpp:337] Iteration 23500, Testing net (#0)
I0827 09:10:51.048540 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:10:53.658023 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:10:53.658078 10163 solver.cpp:404]     Test net output #1: loss = 1.11228 (* 1 = 1.11228 loss)
I0827 09:10:53.674031 10163 solver.cpp:228] Iteration 23500, loss = 1.10488
I0827 09:10:53.674054 10163 solver.cpp:244]     Train net output #0: loss = 1.10488 (* 1 = 1.10488 loss)
I0827 09:10:53.674067 10163 sgd_solver.cpp:106] Iteration 23500, lr = 5.58349e-05
I0827 09:10:57.992918 10163 solver.cpp:228] Iteration 23600, loss = 1.09951
I0827 09:10:57.992965 10163 solver.cpp:244]     Train net output #0: loss = 1.09951 (* 1 = 1.09951 loss)
I0827 09:10:57.992970 10163 sgd_solver.cpp:106] Iteration 23600, lr = 5.57388e-05
I0827 09:11:02.311550 10163 solver.cpp:228] Iteration 23700, loss = 1.10223
I0827 09:11:02.311595 10163 solver.cpp:244]     Train net output #0: loss = 1.10223 (* 1 = 1.10223 loss)
I0827 09:11:02.311601 10163 sgd_solver.cpp:106] Iteration 23700, lr = 5.56431e-05
I0827 09:11:06.633317 10163 solver.cpp:228] Iteration 23800, loss = 1.10459
I0827 09:11:06.633359 10163 solver.cpp:244]     Train net output #0: loss = 1.10459 (* 1 = 1.10459 loss)
I0827 09:11:06.633364 10163 sgd_solver.cpp:106] Iteration 23800, lr = 5.55478e-05
I0827 09:11:10.951652 10163 solver.cpp:228] Iteration 23900, loss = 1.11694
I0827 09:11:10.951699 10163 solver.cpp:244]     Train net output #0: loss = 1.11694 (* 1 = 1.11694 loss)
I0827 09:11:10.951707 10163 sgd_solver.cpp:106] Iteration 23900, lr = 5.54529e-05
I0827 09:11:15.230619 10163 solver.cpp:337] Iteration 24000, Testing net (#0)
I0827 09:11:18.422794 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:11:18.422854 10163 solver.cpp:404]     Test net output #1: loss = 1.11206 (* 1 = 1.11206 loss)
I0827 09:11:18.438499 10163 solver.cpp:228] Iteration 24000, loss = 1.10066
I0827 09:11:18.438529 10163 solver.cpp:244]     Train net output #0: loss = 1.10066 (* 1 = 1.10066 loss)
I0827 09:11:18.438540 10163 sgd_solver.cpp:106] Iteration 24000, lr = 5.53583e-05
I0827 09:11:22.760107 10163 solver.cpp:228] Iteration 24100, loss = 1.1084
I0827 09:11:22.760145 10163 solver.cpp:244]     Train net output #0: loss = 1.1084 (* 1 = 1.1084 loss)
I0827 09:11:22.760151 10163 sgd_solver.cpp:106] Iteration 24100, lr = 5.52642e-05
I0827 09:11:27.076586 10163 solver.cpp:228] Iteration 24200, loss = 1.10894
I0827 09:11:27.076643 10163 solver.cpp:244]     Train net output #0: loss = 1.10894 (* 1 = 1.10894 loss)
I0827 09:11:27.076649 10163 sgd_solver.cpp:106] Iteration 24200, lr = 5.51704e-05
I0827 09:11:31.402235 10163 solver.cpp:228] Iteration 24300, loss = 1.09589
I0827 09:11:31.402298 10163 solver.cpp:244]     Train net output #0: loss = 1.09589 (* 1 = 1.09589 loss)
I0827 09:11:31.402305 10163 sgd_solver.cpp:106] Iteration 24300, lr = 5.50769e-05
I0827 09:11:35.723227 10163 solver.cpp:228] Iteration 24400, loss = 1.09776
I0827 09:11:35.723265 10163 solver.cpp:244]     Train net output #0: loss = 1.09776 (* 1 = 1.09776 loss)
I0827 09:11:35.723271 10163 sgd_solver.cpp:106] Iteration 24400, lr = 5.49839e-05
I0827 09:11:39.996937 10163 solver.cpp:337] Iteration 24500, Testing net (#0)
I0827 09:11:43.369418 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0827 09:11:43.369477 10163 solver.cpp:404]     Test net output #1: loss = 1.11256 (* 1 = 1.11256 loss)
I0827 09:11:43.387838 10163 solver.cpp:228] Iteration 24500, loss = 1.09526
I0827 09:11:43.387884 10163 solver.cpp:244]     Train net output #0: loss = 1.09526 (* 1 = 1.09526 loss)
I0827 09:11:43.387908 10163 sgd_solver.cpp:106] Iteration 24500, lr = 5.48912e-05
I0827 09:11:47.703153 10163 solver.cpp:228] Iteration 24600, loss = 1.11056
I0827 09:11:47.703202 10163 solver.cpp:244]     Train net output #0: loss = 1.11056 (* 1 = 1.11056 loss)
I0827 09:11:47.703208 10163 sgd_solver.cpp:106] Iteration 24600, lr = 5.47988e-05
I0827 09:11:52.025317 10163 solver.cpp:228] Iteration 24700, loss = 1.10162
I0827 09:11:52.025378 10163 solver.cpp:244]     Train net output #0: loss = 1.10162 (* 1 = 1.10162 loss)
I0827 09:11:52.025385 10163 sgd_solver.cpp:106] Iteration 24700, lr = 5.47069e-05
I0827 09:11:56.342978 10163 solver.cpp:228] Iteration 24800, loss = 1.10354
I0827 09:11:56.343039 10163 solver.cpp:244]     Train net output #0: loss = 1.10354 (* 1 = 1.10354 loss)
I0827 09:11:56.343045 10163 sgd_solver.cpp:106] Iteration 24800, lr = 5.46153e-05
I0827 09:12:00.663681 10163 solver.cpp:228] Iteration 24900, loss = 1.10644
I0827 09:12:00.663744 10163 solver.cpp:244]     Train net output #0: loss = 1.10644 (* 1 = 1.10644 loss)
I0827 09:12:00.663751 10163 sgd_solver.cpp:106] Iteration 24900, lr = 5.4524e-05
I0827 09:12:04.944310 10163 solver.cpp:337] Iteration 25000, Testing net (#0)
I0827 09:12:08.255471 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0827 09:12:08.255527 10163 solver.cpp:404]     Test net output #1: loss = 1.11133 (* 1 = 1.11133 loss)
I0827 09:12:08.271237 10163 solver.cpp:228] Iteration 25000, loss = 1.09872
I0827 09:12:08.271275 10163 solver.cpp:244]     Train net output #0: loss = 1.09872 (* 1 = 1.09872 loss)
I0827 09:12:08.271286 10163 sgd_solver.cpp:106] Iteration 25000, lr = 5.44331e-05
I0827 09:12:12.621239 10163 solver.cpp:228] Iteration 25100, loss = 1.10026
I0827 09:12:12.621263 10163 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0827 09:12:12.621268 10163 sgd_solver.cpp:106] Iteration 25100, lr = 5.43426e-05
I0827 09:12:16.935997 10163 solver.cpp:228] Iteration 25200, loss = 1.09902
I0827 09:12:16.936017 10163 solver.cpp:244]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0827 09:12:16.936022 10163 sgd_solver.cpp:106] Iteration 25200, lr = 5.42524e-05
I0827 09:12:21.257344 10163 solver.cpp:228] Iteration 25300, loss = 1.10553
I0827 09:12:21.257385 10163 solver.cpp:244]     Train net output #0: loss = 1.10553 (* 1 = 1.10553 loss)
I0827 09:12:21.257390 10163 sgd_solver.cpp:106] Iteration 25300, lr = 5.41625e-05
I0827 09:12:25.569010 10163 solver.cpp:228] Iteration 25400, loss = 1.101
I0827 09:12:25.569031 10163 solver.cpp:244]     Train net output #0: loss = 1.101 (* 1 = 1.101 loss)
I0827 09:12:25.569036 10163 sgd_solver.cpp:106] Iteration 25400, lr = 5.4073e-05
I0827 09:12:29.847290 10163 solver.cpp:337] Iteration 25500, Testing net (#0)
I0827 09:12:33.161798 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 09:12:33.161842 10163 solver.cpp:404]     Test net output #1: loss = 1.11562 (* 1 = 1.11562 loss)
I0827 09:12:33.177106 10163 solver.cpp:228] Iteration 25500, loss = 1.10083
I0827 09:12:33.177124 10163 solver.cpp:244]     Train net output #0: loss = 1.10083 (* 1 = 1.10083 loss)
I0827 09:12:33.177131 10163 sgd_solver.cpp:106] Iteration 25500, lr = 5.39839e-05
I0827 09:12:37.498236 10163 solver.cpp:228] Iteration 25600, loss = 1.11298
I0827 09:12:37.498257 10163 solver.cpp:244]     Train net output #0: loss = 1.11298 (* 1 = 1.11298 loss)
I0827 09:12:37.498262 10163 sgd_solver.cpp:106] Iteration 25600, lr = 5.3895e-05
I0827 09:12:41.815920 10163 solver.cpp:228] Iteration 25700, loss = 1.10717
I0827 09:12:41.815973 10163 solver.cpp:244]     Train net output #0: loss = 1.10717 (* 1 = 1.10717 loss)
I0827 09:12:41.815981 10163 sgd_solver.cpp:106] Iteration 25700, lr = 5.38066e-05
I0827 09:12:46.143393 10163 solver.cpp:228] Iteration 25800, loss = 1.09409
I0827 09:12:46.143447 10163 solver.cpp:244]     Train net output #0: loss = 1.09409 (* 1 = 1.09409 loss)
I0827 09:12:46.143453 10163 sgd_solver.cpp:106] Iteration 25800, lr = 5.37184e-05
I0827 09:12:50.460594 10163 solver.cpp:228] Iteration 25900, loss = 1.09812
I0827 09:12:50.460614 10163 solver.cpp:244]     Train net output #0: loss = 1.09812 (* 1 = 1.09812 loss)
I0827 09:12:50.460620 10163 sgd_solver.cpp:106] Iteration 25900, lr = 5.36306e-05
I0827 09:12:54.745565 10163 solver.cpp:337] Iteration 26000, Testing net (#0)
I0827 09:12:57.070175 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:12:58.255794 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:12:58.255851 10163 solver.cpp:404]     Test net output #1: loss = 1.12016 (* 1 = 1.12016 loss)
I0827 09:12:58.271256 10163 solver.cpp:228] Iteration 26000, loss = 1.10955
I0827 09:12:58.271320 10163 solver.cpp:244]     Train net output #0: loss = 1.10955 (* 1 = 1.10955 loss)
I0827 09:12:58.271349 10163 sgd_solver.cpp:106] Iteration 26000, lr = 5.35432e-05
I0827 09:13:02.603320 10163 solver.cpp:228] Iteration 26100, loss = 1.09107
I0827 09:13:02.603363 10163 solver.cpp:244]     Train net output #0: loss = 1.09107 (* 1 = 1.09107 loss)
I0827 09:13:02.603368 10163 sgd_solver.cpp:106] Iteration 26100, lr = 5.3456e-05
I0827 09:13:06.922317 10163 solver.cpp:228] Iteration 26200, loss = 1.09707
I0827 09:13:06.922356 10163 solver.cpp:244]     Train net output #0: loss = 1.09707 (* 1 = 1.09707 loss)
I0827 09:13:06.922361 10163 sgd_solver.cpp:106] Iteration 26200, lr = 5.33692e-05
I0827 09:13:11.240097 10163 solver.cpp:228] Iteration 26300, loss = 1.09499
I0827 09:13:11.240139 10163 solver.cpp:244]     Train net output #0: loss = 1.09499 (* 1 = 1.09499 loss)
I0827 09:13:11.240144 10163 sgd_solver.cpp:106] Iteration 26300, lr = 5.32828e-05
I0827 09:13:15.567409 10163 solver.cpp:228] Iteration 26400, loss = 1.09807
I0827 09:13:15.567450 10163 solver.cpp:244]     Train net output #0: loss = 1.09807 (* 1 = 1.09807 loss)
I0827 09:13:15.567456 10163 sgd_solver.cpp:106] Iteration 26400, lr = 5.31966e-05
I0827 09:13:19.859072 10163 solver.cpp:337] Iteration 26500, Testing net (#0)
I0827 09:13:23.368551 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 09:13:23.368610 10163 solver.cpp:404]     Test net output #1: loss = 1.11684 (* 1 = 1.11684 loss)
I0827 09:13:23.384016 10163 solver.cpp:228] Iteration 26500, loss = 1.09479
I0827 09:13:23.384086 10163 solver.cpp:244]     Train net output #0: loss = 1.09479 (* 1 = 1.09479 loss)
I0827 09:13:23.384109 10163 sgd_solver.cpp:106] Iteration 26500, lr = 5.31108e-05
I0827 09:13:27.707304 10163 solver.cpp:228] Iteration 26600, loss = 1.11002
I0827 09:13:27.707346 10163 solver.cpp:244]     Train net output #0: loss = 1.11002 (* 1 = 1.11002 loss)
I0827 09:13:27.707351 10163 sgd_solver.cpp:106] Iteration 26600, lr = 5.30253e-05
I0827 09:13:32.026856 10163 solver.cpp:228] Iteration 26700, loss = 1.10945
I0827 09:13:32.026880 10163 solver.cpp:244]     Train net output #0: loss = 1.10945 (* 1 = 1.10945 loss)
I0827 09:13:32.026886 10163 sgd_solver.cpp:106] Iteration 26700, lr = 5.29401e-05
I0827 09:13:36.354575 10163 solver.cpp:228] Iteration 26800, loss = 1.10191
I0827 09:13:36.354617 10163 solver.cpp:244]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0827 09:13:36.354624 10163 sgd_solver.cpp:106] Iteration 26800, lr = 5.28552e-05
I0827 09:13:40.673552 10163 solver.cpp:228] Iteration 26900, loss = 1.09789
I0827 09:13:40.673570 10163 solver.cpp:244]     Train net output #0: loss = 1.09789 (* 1 = 1.09789 loss)
I0827 09:13:40.673576 10163 sgd_solver.cpp:106] Iteration 26900, lr = 5.27707e-05
I0827 09:13:44.955404 10163 solver.cpp:337] Iteration 27000, Testing net (#0)
I0827 09:13:48.449070 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0827 09:13:48.449123 10163 solver.cpp:404]     Test net output #1: loss = 1.11935 (* 1 = 1.11935 loss)
I0827 09:13:48.463152 10163 solver.cpp:228] Iteration 27000, loss = 1.10242
I0827 09:13:48.463183 10163 solver.cpp:244]     Train net output #0: loss = 1.10242 (* 1 = 1.10242 loss)
I0827 09:13:48.463191 10163 sgd_solver.cpp:106] Iteration 27000, lr = 5.26865e-05
I0827 09:13:52.786774 10163 solver.cpp:228] Iteration 27100, loss = 1.10221
I0827 09:13:52.786815 10163 solver.cpp:244]     Train net output #0: loss = 1.10221 (* 1 = 1.10221 loss)
I0827 09:13:52.786821 10163 sgd_solver.cpp:106] Iteration 27100, lr = 5.26026e-05
I0827 09:13:57.107897 10163 solver.cpp:228] Iteration 27200, loss = 1.09546
I0827 09:13:57.107916 10163 solver.cpp:244]     Train net output #0: loss = 1.09546 (* 1 = 1.09546 loss)
I0827 09:13:57.107921 10163 sgd_solver.cpp:106] Iteration 27200, lr = 5.25189e-05
I0827 09:14:01.435575 10163 solver.cpp:228] Iteration 27300, loss = 1.09419
I0827 09:14:01.435619 10163 solver.cpp:244]     Train net output #0: loss = 1.09419 (* 1 = 1.09419 loss)
I0827 09:14:01.435626 10163 sgd_solver.cpp:106] Iteration 27300, lr = 5.24356e-05
I0827 09:14:05.753139 10163 solver.cpp:228] Iteration 27400, loss = 1.09894
I0827 09:14:05.753156 10163 solver.cpp:244]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0827 09:14:05.753162 10163 sgd_solver.cpp:106] Iteration 27400, lr = 5.23527e-05
I0827 09:14:10.030150 10163 solver.cpp:337] Iteration 27500, Testing net (#0)
I0827 09:14:13.239447 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:14:13.239549 10163 solver.cpp:404]     Test net output #1: loss = 1.10469 (* 1 = 1.10469 loss)
I0827 09:14:13.255292 10163 solver.cpp:228] Iteration 27500, loss = 1.11031
I0827 09:14:13.255322 10163 solver.cpp:244]     Train net output #0: loss = 1.11031 (* 1 = 1.11031 loss)
I0827 09:14:13.255331 10163 sgd_solver.cpp:106] Iteration 27500, lr = 5.227e-05
I0827 09:14:17.576452 10163 solver.cpp:228] Iteration 27600, loss = 1.09942
I0827 09:14:17.576495 10163 solver.cpp:244]     Train net output #0: loss = 1.09942 (* 1 = 1.09942 loss)
I0827 09:14:17.576501 10163 sgd_solver.cpp:106] Iteration 27600, lr = 5.21876e-05
I0827 09:14:21.897559 10163 solver.cpp:228] Iteration 27700, loss = 1.1079
I0827 09:14:21.897580 10163 solver.cpp:244]     Train net output #0: loss = 1.1079 (* 1 = 1.1079 loss)
I0827 09:14:21.897585 10163 sgd_solver.cpp:106] Iteration 27700, lr = 5.21055e-05
I0827 09:14:26.218016 10163 solver.cpp:228] Iteration 27800, loss = 1.10497
I0827 09:14:26.218036 10163 solver.cpp:244]     Train net output #0: loss = 1.10497 (* 1 = 1.10497 loss)
I0827 09:14:26.218042 10163 sgd_solver.cpp:106] Iteration 27800, lr = 5.20237e-05
I0827 09:14:30.543468 10163 solver.cpp:228] Iteration 27900, loss = 1.10064
I0827 09:14:30.543519 10163 solver.cpp:244]     Train net output #0: loss = 1.10064 (* 1 = 1.10064 loss)
I0827 09:14:30.543532 10163 sgd_solver.cpp:106] Iteration 27900, lr = 5.19423e-05
I0827 09:14:34.821377 10163 solver.cpp:337] Iteration 28000, Testing net (#0)
I0827 09:14:38.066231 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269083
I0827 09:14:38.066299 10163 solver.cpp:404]     Test net output #1: loss = 1.09573 (* 1 = 1.09573 loss)
I0827 09:14:38.083129 10163 solver.cpp:228] Iteration 28000, loss = 1.08862
I0827 09:14:38.083199 10163 solver.cpp:244]     Train net output #0: loss = 1.08862 (* 1 = 1.08862 loss)
I0827 09:14:38.083214 10163 sgd_solver.cpp:106] Iteration 28000, lr = 5.18611e-05
I0827 09:14:42.402513 10163 solver.cpp:228] Iteration 28100, loss = 1.10393
I0827 09:14:42.402580 10163 solver.cpp:244]     Train net output #0: loss = 1.10393 (* 1 = 1.10393 loss)
I0827 09:14:42.402587 10163 sgd_solver.cpp:106] Iteration 28100, lr = 5.17802e-05
I0827 09:14:46.716987 10163 solver.cpp:228] Iteration 28200, loss = 1.09941
I0827 09:14:46.717049 10163 solver.cpp:244]     Train net output #0: loss = 1.09941 (* 1 = 1.09941 loss)
I0827 09:14:46.717056 10163 sgd_solver.cpp:106] Iteration 28200, lr = 5.16996e-05
I0827 09:14:51.038769 10163 solver.cpp:228] Iteration 28300, loss = 1.10977
I0827 09:14:51.038822 10163 solver.cpp:244]     Train net output #0: loss = 1.10977 (* 1 = 1.10977 loss)
I0827 09:14:51.038828 10163 sgd_solver.cpp:106] Iteration 28300, lr = 5.16193e-05
I0827 09:14:55.351631 10163 solver.cpp:228] Iteration 28400, loss = 1.10817
I0827 09:14:55.351651 10163 solver.cpp:244]     Train net output #0: loss = 1.10817 (* 1 = 1.10817 loss)
I0827 09:14:55.351656 10163 sgd_solver.cpp:106] Iteration 28400, lr = 5.15393e-05
I0827 09:14:59.628314 10163 solver.cpp:337] Iteration 28500, Testing net (#0)
I0827 09:15:02.223387 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:15:02.958390 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0827 09:15:02.958498 10163 solver.cpp:404]     Test net output #1: loss = 1.08484 (* 1 = 1.08484 loss)
I0827 09:15:02.973773 10163 solver.cpp:228] Iteration 28500, loss = 1.1058
I0827 09:15:02.973816 10163 solver.cpp:244]     Train net output #0: loss = 1.1058 (* 1 = 1.1058 loss)
I0827 09:15:02.973831 10163 sgd_solver.cpp:106] Iteration 28500, lr = 5.14596e-05
I0827 09:15:07.294595 10163 solver.cpp:228] Iteration 28600, loss = 1.10597
I0827 09:15:07.294647 10163 solver.cpp:244]     Train net output #0: loss = 1.10597 (* 1 = 1.10597 loss)
I0827 09:15:07.294656 10163 sgd_solver.cpp:106] Iteration 28600, lr = 5.13801e-05
I0827 09:15:11.612174 10163 solver.cpp:228] Iteration 28700, loss = 1.11281
I0827 09:15:11.612195 10163 solver.cpp:244]     Train net output #0: loss = 1.11281 (* 1 = 1.11281 loss)
I0827 09:15:11.612200 10163 sgd_solver.cpp:106] Iteration 28700, lr = 5.1301e-05
I0827 09:15:15.935379 10163 solver.cpp:228] Iteration 28800, loss = 1.08703
I0827 09:15:15.935420 10163 solver.cpp:244]     Train net output #0: loss = 1.08703 (* 1 = 1.08703 loss)
I0827 09:15:15.935425 10163 sgd_solver.cpp:106] Iteration 28800, lr = 5.12221e-05
I0827 09:15:20.250854 10163 solver.cpp:228] Iteration 28900, loss = 1.10744
I0827 09:15:20.250874 10163 solver.cpp:244]     Train net output #0: loss = 1.10744 (* 1 = 1.10744 loss)
I0827 09:15:20.250879 10163 sgd_solver.cpp:106] Iteration 28900, lr = 5.11435e-05
I0827 09:15:24.524610 10163 solver.cpp:337] Iteration 29000, Testing net (#0)
I0827 09:15:27.920703 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0827 09:15:27.920778 10163 solver.cpp:404]     Test net output #1: loss = 1.08003 (* 1 = 1.08003 loss)
I0827 09:15:27.935092 10163 solver.cpp:228] Iteration 29000, loss = 1.11838
I0827 09:15:27.935130 10163 solver.cpp:244]     Train net output #0: loss = 1.11838 (* 1 = 1.11838 loss)
I0827 09:15:27.935142 10163 sgd_solver.cpp:106] Iteration 29000, lr = 5.10652e-05
I0827 09:15:32.255456 10163 solver.cpp:228] Iteration 29100, loss = 1.10068
I0827 09:15:32.255499 10163 solver.cpp:244]     Train net output #0: loss = 1.10068 (* 1 = 1.10068 loss)
I0827 09:15:32.255506 10163 sgd_solver.cpp:106] Iteration 29100, lr = 5.09872e-05
I0827 09:15:36.574844 10163 solver.cpp:228] Iteration 29200, loss = 1.09538
I0827 09:15:36.574862 10163 solver.cpp:244]     Train net output #0: loss = 1.09538 (* 1 = 1.09538 loss)
I0827 09:15:36.574867 10163 sgd_solver.cpp:106] Iteration 29200, lr = 5.09095e-05
I0827 09:15:40.892251 10163 solver.cpp:228] Iteration 29300, loss = 1.10605
I0827 09:15:40.892273 10163 solver.cpp:244]     Train net output #0: loss = 1.10605 (* 1 = 1.10605 loss)
I0827 09:15:40.892279 10163 sgd_solver.cpp:106] Iteration 29300, lr = 5.0832e-05
I0827 09:15:45.217967 10163 solver.cpp:228] Iteration 29400, loss = 1.1002
I0827 09:15:45.218020 10163 solver.cpp:244]     Train net output #0: loss = 1.1002 (* 1 = 1.1002 loss)
I0827 09:15:45.218029 10163 sgd_solver.cpp:106] Iteration 29400, lr = 5.07548e-05
I0827 09:15:49.493943 10163 solver.cpp:337] Iteration 29500, Testing net (#0)
I0827 09:15:52.935731 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578292
I0827 09:15:52.935781 10163 solver.cpp:404]     Test net output #1: loss = 1.09 (* 1 = 1.09 loss)
I0827 09:15:52.950723 10163 solver.cpp:228] Iteration 29500, loss = 1.0915
I0827 09:15:52.950762 10163 solver.cpp:244]     Train net output #0: loss = 1.0915 (* 1 = 1.0915 loss)
I0827 09:15:52.950784 10163 sgd_solver.cpp:106] Iteration 29500, lr = 5.06779e-05
I0827 09:15:57.272950 10163 solver.cpp:228] Iteration 29600, loss = 1.10403
I0827 09:15:57.273008 10163 solver.cpp:244]     Train net output #0: loss = 1.10403 (* 1 = 1.10403 loss)
I0827 09:15:57.273017 10163 sgd_solver.cpp:106] Iteration 29600, lr = 5.06012e-05
I0827 09:16:01.596783 10163 solver.cpp:228] Iteration 29700, loss = 1.09962
I0827 09:16:01.596840 10163 solver.cpp:244]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0827 09:16:01.596848 10163 sgd_solver.cpp:106] Iteration 29700, lr = 5.05249e-05
I0827 09:16:05.921808 10163 solver.cpp:228] Iteration 29800, loss = 1.11348
I0827 09:16:05.921866 10163 solver.cpp:244]     Train net output #0: loss = 1.11348 (* 1 = 1.11348 loss)
I0827 09:16:05.921875 10163 sgd_solver.cpp:106] Iteration 29800, lr = 5.04488e-05
I0827 09:16:10.244029 10163 solver.cpp:228] Iteration 29900, loss = 1.10321
I0827 09:16:10.244053 10163 solver.cpp:244]     Train net output #0: loss = 1.10321 (* 1 = 1.10321 loss)
I0827 09:16:10.244058 10163 sgd_solver.cpp:106] Iteration 29900, lr = 5.03729e-05
I0827 09:16:14.523542 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_30000.caffemodel
I0827 09:16:14.999297 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_30000.solverstate
I0827 09:16:15.154819 10163 solver.cpp:337] Iteration 30000, Testing net (#0)
I0827 09:16:18.677012 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:16:18.677062 10163 solver.cpp:404]     Test net output #1: loss = 1.10135 (* 1 = 1.10135 loss)
I0827 09:16:18.691962 10163 solver.cpp:228] Iteration 30000, loss = 1.10076
I0827 09:16:18.692026 10163 solver.cpp:244]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0827 09:16:18.692049 10163 sgd_solver.cpp:106] Iteration 30000, lr = 5.02973e-05
I0827 09:16:23.011433 10163 solver.cpp:228] Iteration 30100, loss = 1.09196
I0827 09:16:23.011456 10163 solver.cpp:244]     Train net output #0: loss = 1.09196 (* 1 = 1.09196 loss)
I0827 09:16:23.011463 10163 sgd_solver.cpp:106] Iteration 30100, lr = 5.0222e-05
I0827 09:16:27.327540 10163 solver.cpp:228] Iteration 30200, loss = 1.09184
I0827 09:16:27.327558 10163 solver.cpp:244]     Train net output #0: loss = 1.09184 (* 1 = 1.09184 loss)
I0827 09:16:27.327564 10163 sgd_solver.cpp:106] Iteration 30200, lr = 5.0147e-05
I0827 09:16:31.648862 10163 solver.cpp:228] Iteration 30300, loss = 1.10784
I0827 09:16:31.648919 10163 solver.cpp:244]     Train net output #0: loss = 1.10784 (* 1 = 1.10784 loss)
I0827 09:16:31.648931 10163 sgd_solver.cpp:106] Iteration 30300, lr = 5.00722e-05
I0827 09:16:35.975930 10163 solver.cpp:228] Iteration 30400, loss = 1.10334
I0827 09:16:35.975970 10163 solver.cpp:244]     Train net output #0: loss = 1.10334 (* 1 = 1.10334 loss)
I0827 09:16:35.975975 10163 sgd_solver.cpp:106] Iteration 30400, lr = 4.99976e-05
I0827 09:16:40.251670 10163 solver.cpp:337] Iteration 30500, Testing net (#0)
I0827 09:16:43.752421 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0827 09:16:43.752470 10163 solver.cpp:404]     Test net output #1: loss = 1.11271 (* 1 = 1.11271 loss)
I0827 09:16:43.767230 10163 solver.cpp:228] Iteration 30500, loss = 1.09857
I0827 09:16:43.767259 10163 solver.cpp:244]     Train net output #0: loss = 1.09857 (* 1 = 1.09857 loss)
I0827 09:16:43.767282 10163 sgd_solver.cpp:106] Iteration 30500, lr = 4.99234e-05
I0827 09:16:48.085913 10163 solver.cpp:228] Iteration 30600, loss = 1.09429
I0827 09:16:48.085970 10163 solver.cpp:244]     Train net output #0: loss = 1.09429 (* 1 = 1.09429 loss)
I0827 09:16:48.085978 10163 sgd_solver.cpp:106] Iteration 30600, lr = 4.98494e-05
I0827 09:16:52.407886 10163 solver.cpp:228] Iteration 30700, loss = 1.09768
I0827 09:16:52.407944 10163 solver.cpp:244]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0827 09:16:52.407950 10163 sgd_solver.cpp:106] Iteration 30700, lr = 4.97756e-05
I0827 09:16:56.727304 10163 solver.cpp:228] Iteration 30800, loss = 1.10553
I0827 09:16:56.727363 10163 solver.cpp:244]     Train net output #0: loss = 1.10553 (* 1 = 1.10553 loss)
I0827 09:16:56.727370 10163 sgd_solver.cpp:106] Iteration 30800, lr = 4.97021e-05
I0827 09:17:01.053761 10163 solver.cpp:228] Iteration 30900, loss = 1.09291
I0827 09:17:01.053802 10163 solver.cpp:244]     Train net output #0: loss = 1.09291 (* 1 = 1.09291 loss)
I0827 09:17:01.053808 10163 sgd_solver.cpp:106] Iteration 30900, lr = 4.96288e-05
I0827 09:17:05.335875 10163 solver.cpp:337] Iteration 31000, Testing net (#0)
I0827 09:17:07.473093 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:17:08.829336 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152083
I0827 09:17:08.829391 10163 solver.cpp:404]     Test net output #1: loss = 1.11873 (* 1 = 1.11873 loss)
I0827 09:17:08.843669 10163 solver.cpp:228] Iteration 31000, loss = 1.10528
I0827 09:17:08.843730 10163 solver.cpp:244]     Train net output #0: loss = 1.10528 (* 1 = 1.10528 loss)
I0827 09:17:08.843744 10163 sgd_solver.cpp:106] Iteration 31000, lr = 4.95558e-05
I0827 09:17:13.166216 10163 solver.cpp:228] Iteration 31100, loss = 1.09238
I0827 09:17:13.166270 10163 solver.cpp:244]     Train net output #0: loss = 1.09238 (* 1 = 1.09238 loss)
I0827 09:17:13.166275 10163 sgd_solver.cpp:106] Iteration 31100, lr = 4.94831e-05
I0827 09:17:17.484792 10163 solver.cpp:228] Iteration 31200, loss = 1.1003
I0827 09:17:17.484850 10163 solver.cpp:244]     Train net output #0: loss = 1.1003 (* 1 = 1.1003 loss)
I0827 09:17:17.484856 10163 sgd_solver.cpp:106] Iteration 31200, lr = 4.94106e-05
I0827 09:17:21.804249 10163 solver.cpp:228] Iteration 31300, loss = 1.09954
I0827 09:17:21.804294 10163 solver.cpp:244]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0827 09:17:21.804301 10163 sgd_solver.cpp:106] Iteration 31300, lr = 4.93383e-05
I0827 09:17:26.130503 10163 solver.cpp:228] Iteration 31400, loss = 1.10292
I0827 09:17:26.130547 10163 solver.cpp:244]     Train net output #0: loss = 1.10292 (* 1 = 1.10292 loss)
I0827 09:17:26.130553 10163 sgd_solver.cpp:106] Iteration 31400, lr = 4.92663e-05
I0827 09:17:30.408350 10163 solver.cpp:337] Iteration 31500, Testing net (#0)
I0827 09:17:33.924149 10163 solver.cpp:404]     Test net output #0: accuracy = 0.151958
I0827 09:17:33.924216 10163 solver.cpp:404]     Test net output #1: loss = 1.11857 (* 1 = 1.11857 loss)
I0827 09:17:33.939590 10163 solver.cpp:228] Iteration 31500, loss = 1.10653
I0827 09:17:33.939621 10163 solver.cpp:244]     Train net output #0: loss = 1.10653 (* 1 = 1.10653 loss)
I0827 09:17:33.939631 10163 sgd_solver.cpp:106] Iteration 31500, lr = 4.91946e-05
I0827 09:17:38.251548 10163 solver.cpp:228] Iteration 31600, loss = 1.10008
I0827 09:17:38.251581 10163 solver.cpp:244]     Train net output #0: loss = 1.10008 (* 1 = 1.10008 loss)
I0827 09:17:38.251587 10163 sgd_solver.cpp:106] Iteration 31600, lr = 4.9123e-05
I0827 09:17:42.568528 10163 solver.cpp:228] Iteration 31700, loss = 1.09541
I0827 09:17:42.568547 10163 solver.cpp:244]     Train net output #0: loss = 1.09541 (* 1 = 1.09541 loss)
I0827 09:17:42.568552 10163 sgd_solver.cpp:106] Iteration 31700, lr = 4.90518e-05
I0827 09:17:46.884898 10163 solver.cpp:228] Iteration 31800, loss = 1.09631
I0827 09:17:46.884915 10163 solver.cpp:244]     Train net output #0: loss = 1.09631 (* 1 = 1.09631 loss)
I0827 09:17:46.884920 10163 sgd_solver.cpp:106] Iteration 31800, lr = 4.89807e-05
I0827 09:17:51.201483 10163 solver.cpp:228] Iteration 31900, loss = 1.09371
I0827 09:17:51.201514 10163 solver.cpp:244]     Train net output #0: loss = 1.09371 (* 1 = 1.09371 loss)
I0827 09:17:51.201519 10163 sgd_solver.cpp:106] Iteration 31900, lr = 4.89099e-05
I0827 09:17:55.473043 10163 solver.cpp:337] Iteration 32000, Testing net (#0)
I0827 09:17:58.827651 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 09:17:58.827714 10163 solver.cpp:404]     Test net output #1: loss = 1.11257 (* 1 = 1.11257 loss)
I0827 09:17:58.842391 10163 solver.cpp:228] Iteration 32000, loss = 1.10144
I0827 09:17:58.842413 10163 solver.cpp:244]     Train net output #0: loss = 1.10144 (* 1 = 1.10144 loss)
I0827 09:17:58.842423 10163 sgd_solver.cpp:106] Iteration 32000, lr = 4.88394e-05
I0827 09:18:03.163566 10163 solver.cpp:228] Iteration 32100, loss = 1.10224
I0827 09:18:03.163606 10163 solver.cpp:244]     Train net output #0: loss = 1.10224 (* 1 = 1.10224 loss)
I0827 09:18:03.163612 10163 sgd_solver.cpp:106] Iteration 32100, lr = 4.8769e-05
I0827 09:18:07.484079 10163 solver.cpp:228] Iteration 32200, loss = 1.09687
I0827 09:18:07.484118 10163 solver.cpp:244]     Train net output #0: loss = 1.09687 (* 1 = 1.09687 loss)
I0827 09:18:07.484124 10163 sgd_solver.cpp:106] Iteration 32200, lr = 4.86989e-05
I0827 09:18:11.805784 10163 solver.cpp:228] Iteration 32300, loss = 1.10262
I0827 09:18:11.805826 10163 solver.cpp:244]     Train net output #0: loss = 1.10262 (* 1 = 1.10262 loss)
I0827 09:18:11.805831 10163 sgd_solver.cpp:106] Iteration 32300, lr = 4.86291e-05
I0827 09:18:16.125488 10163 solver.cpp:228] Iteration 32400, loss = 1.09604
I0827 09:18:16.125550 10163 solver.cpp:244]     Train net output #0: loss = 1.09604 (* 1 = 1.09604 loss)
I0827 09:18:16.125556 10163 sgd_solver.cpp:106] Iteration 32400, lr = 4.85595e-05
I0827 09:18:20.400768 10163 solver.cpp:337] Iteration 32500, Testing net (#0)
I0827 09:18:23.694684 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0827 09:18:23.694797 10163 solver.cpp:404]     Test net output #1: loss = 1.11063 (* 1 = 1.11063 loss)
I0827 09:18:23.710686 10163 solver.cpp:228] Iteration 32500, loss = 1.10468
I0827 09:18:23.710717 10163 solver.cpp:244]     Train net output #0: loss = 1.10468 (* 1 = 1.10468 loss)
I0827 09:18:23.710727 10163 sgd_solver.cpp:106] Iteration 32500, lr = 4.84901e-05
I0827 09:18:28.035421 10163 solver.cpp:228] Iteration 32600, loss = 1.10172
I0827 09:18:28.035493 10163 solver.cpp:244]     Train net output #0: loss = 1.10172 (* 1 = 1.10172 loss)
I0827 09:18:28.035507 10163 sgd_solver.cpp:106] Iteration 32600, lr = 4.84209e-05
I0827 09:18:32.360024 10163 solver.cpp:228] Iteration 32700, loss = 1.09486
I0827 09:18:32.360064 10163 solver.cpp:244]     Train net output #0: loss = 1.09486 (* 1 = 1.09486 loss)
I0827 09:18:32.360069 10163 sgd_solver.cpp:106] Iteration 32700, lr = 4.8352e-05
I0827 09:18:36.681324 10163 solver.cpp:228] Iteration 32800, loss = 1.10122
I0827 09:18:36.681344 10163 solver.cpp:244]     Train net output #0: loss = 1.10122 (* 1 = 1.10122 loss)
I0827 09:18:36.681349 10163 sgd_solver.cpp:106] Iteration 32800, lr = 4.82833e-05
I0827 09:18:41.005298 10163 solver.cpp:228] Iteration 32900, loss = 1.10914
I0827 09:18:41.005340 10163 solver.cpp:244]     Train net output #0: loss = 1.10914 (* 1 = 1.10914 loss)
I0827 09:18:41.005347 10163 sgd_solver.cpp:106] Iteration 32900, lr = 4.82148e-05
I0827 09:18:45.284060 10163 solver.cpp:337] Iteration 33000, Testing net (#0)
I0827 09:18:48.596863 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0827 09:18:48.596915 10163 solver.cpp:404]     Test net output #1: loss = 1.09589 (* 1 = 1.09589 loss)
I0827 09:18:48.616137 10163 solver.cpp:228] Iteration 33000, loss = 1.09876
I0827 09:18:48.616199 10163 solver.cpp:244]     Train net output #0: loss = 1.09876 (* 1 = 1.09876 loss)
I0827 09:18:48.616215 10163 sgd_solver.cpp:106] Iteration 33000, lr = 4.81466e-05
I0827 09:18:52.936700 10163 solver.cpp:228] Iteration 33100, loss = 1.08761
I0827 09:18:52.936758 10163 solver.cpp:244]     Train net output #0: loss = 1.08761 (* 1 = 1.08761 loss)
I0827 09:18:52.936767 10163 sgd_solver.cpp:106] Iteration 33100, lr = 4.80786e-05
I0827 09:18:57.259969 10163 solver.cpp:228] Iteration 33200, loss = 1.09419
I0827 09:18:57.260010 10163 solver.cpp:244]     Train net output #0: loss = 1.09419 (* 1 = 1.09419 loss)
I0827 09:18:57.260016 10163 sgd_solver.cpp:106] Iteration 33200, lr = 4.80108e-05
I0827 09:19:01.577016 10163 solver.cpp:228] Iteration 33300, loss = 1.10276
I0827 09:19:01.577081 10163 solver.cpp:244]     Train net output #0: loss = 1.10276 (* 1 = 1.10276 loss)
I0827 09:19:01.577088 10163 sgd_solver.cpp:106] Iteration 33300, lr = 4.79432e-05
I0827 09:19:05.898252 10163 solver.cpp:228] Iteration 33400, loss = 1.09734
I0827 09:19:05.898318 10163 solver.cpp:244]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0827 09:19:05.898324 10163 sgd_solver.cpp:106] Iteration 33400, lr = 4.78759e-05
I0827 09:19:10.174093 10163 solver.cpp:337] Iteration 33500, Testing net (#0)
I0827 09:19:13.242127 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:19:13.509425 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 09:19:13.509492 10163 solver.cpp:404]     Test net output #1: loss = 1.0836 (* 1 = 1.0836 loss)
I0827 09:19:13.524299 10163 solver.cpp:228] Iteration 33500, loss = 1.10176
I0827 09:19:13.524349 10163 solver.cpp:244]     Train net output #0: loss = 1.10176 (* 1 = 1.10176 loss)
I0827 09:19:13.524358 10163 sgd_solver.cpp:106] Iteration 33500, lr = 4.78087e-05
I0827 09:19:17.844619 10163 solver.cpp:228] Iteration 33600, loss = 1.09222
I0827 09:19:17.844660 10163 solver.cpp:244]     Train net output #0: loss = 1.09222 (* 1 = 1.09222 loss)
I0827 09:19:17.844666 10163 sgd_solver.cpp:106] Iteration 33600, lr = 4.77418e-05
I0827 09:19:22.167227 10163 solver.cpp:228] Iteration 33700, loss = 1.10156
I0827 09:19:22.167268 10163 solver.cpp:244]     Train net output #0: loss = 1.10156 (* 1 = 1.10156 loss)
I0827 09:19:22.167273 10163 sgd_solver.cpp:106] Iteration 33700, lr = 4.76751e-05
I0827 09:19:26.489902 10163 solver.cpp:228] Iteration 33800, loss = 1.10368
I0827 09:19:26.489919 10163 solver.cpp:244]     Train net output #0: loss = 1.10368 (* 1 = 1.10368 loss)
I0827 09:19:26.489924 10163 sgd_solver.cpp:106] Iteration 33800, lr = 4.76086e-05
I0827 09:19:30.808404 10163 solver.cpp:228] Iteration 33900, loss = 1.10702
I0827 09:19:30.808446 10163 solver.cpp:244]     Train net output #0: loss = 1.10702 (* 1 = 1.10702 loss)
I0827 09:19:30.808456 10163 sgd_solver.cpp:106] Iteration 33900, lr = 4.75424e-05
I0827 09:19:35.091156 10163 solver.cpp:337] Iteration 34000, Testing net (#0)
I0827 09:19:38.283069 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269542
I0827 09:19:38.283130 10163 solver.cpp:404]     Test net output #1: loss = 1.08021 (* 1 = 1.08021 loss)
I0827 09:19:38.297930 10163 solver.cpp:228] Iteration 34000, loss = 1.11165
I0827 09:19:38.297958 10163 solver.cpp:244]     Train net output #0: loss = 1.11165 (* 1 = 1.11165 loss)
I0827 09:19:38.297971 10163 sgd_solver.cpp:106] Iteration 34000, lr = 4.74763e-05
I0827 09:19:42.622113 10163 solver.cpp:228] Iteration 34100, loss = 1.09332
I0827 09:19:42.622175 10163 solver.cpp:244]     Train net output #0: loss = 1.09332 (* 1 = 1.09332 loss)
I0827 09:19:42.622189 10163 sgd_solver.cpp:106] Iteration 34100, lr = 4.74105e-05
I0827 09:19:46.947695 10163 solver.cpp:228] Iteration 34200, loss = 1.10984
I0827 09:19:46.947733 10163 solver.cpp:244]     Train net output #0: loss = 1.10984 (* 1 = 1.10984 loss)
I0827 09:19:46.947739 10163 sgd_solver.cpp:106] Iteration 34200, lr = 4.73449e-05
I0827 09:19:51.273452 10163 solver.cpp:228] Iteration 34300, loss = 1.10015
I0827 09:19:51.273504 10163 solver.cpp:244]     Train net output #0: loss = 1.10015 (* 1 = 1.10015 loss)
I0827 09:19:51.273511 10163 sgd_solver.cpp:106] Iteration 34300, lr = 4.72795e-05
I0827 09:19:55.613466 10163 solver.cpp:228] Iteration 34400, loss = 1.09716
I0827 09:19:55.613523 10163 solver.cpp:244]     Train net output #0: loss = 1.09716 (* 1 = 1.09716 loss)
I0827 09:19:55.613534 10163 sgd_solver.cpp:106] Iteration 34400, lr = 4.72143e-05
I0827 09:19:59.893074 10163 solver.cpp:337] Iteration 34500, Testing net (#0)
I0827 09:20:03.058956 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0827 09:20:03.059018 10163 solver.cpp:404]     Test net output #1: loss = 1.08037 (* 1 = 1.08037 loss)
I0827 09:20:03.073843 10163 solver.cpp:228] Iteration 34500, loss = 1.09801
I0827 09:20:03.073873 10163 solver.cpp:244]     Train net output #0: loss = 1.09801 (* 1 = 1.09801 loss)
I0827 09:20:03.073884 10163 sgd_solver.cpp:106] Iteration 34500, lr = 4.71493e-05
I0827 09:20:07.395349 10163 solver.cpp:228] Iteration 34600, loss = 1.10421
I0827 09:20:07.395370 10163 solver.cpp:244]     Train net output #0: loss = 1.10421 (* 1 = 1.10421 loss)
I0827 09:20:07.395375 10163 sgd_solver.cpp:106] Iteration 34600, lr = 4.70845e-05
I0827 09:20:11.717214 10163 solver.cpp:228] Iteration 34700, loss = 1.08994
I0827 09:20:11.717264 10163 solver.cpp:244]     Train net output #0: loss = 1.08994 (* 1 = 1.08994 loss)
I0827 09:20:11.717289 10163 sgd_solver.cpp:106] Iteration 34700, lr = 4.70199e-05
I0827 09:20:16.044147 10163 solver.cpp:228] Iteration 34800, loss = 1.10915
I0827 09:20:16.044190 10163 solver.cpp:244]     Train net output #0: loss = 1.10915 (* 1 = 1.10915 loss)
I0827 09:20:16.044196 10163 sgd_solver.cpp:106] Iteration 34800, lr = 4.69556e-05
I0827 09:20:20.365324 10163 solver.cpp:228] Iteration 34900, loss = 1.10463
I0827 09:20:20.365345 10163 solver.cpp:244]     Train net output #0: loss = 1.10463 (* 1 = 1.10463 loss)
I0827 09:20:20.365350 10163 sgd_solver.cpp:106] Iteration 34900, lr = 4.68914e-05
I0827 09:20:24.640455 10163 solver.cpp:337] Iteration 35000, Testing net (#0)
I0827 09:20:27.839673 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578084
I0827 09:20:27.839715 10163 solver.cpp:404]     Test net output #1: loss = 1.08808 (* 1 = 1.08808 loss)
I0827 09:20:27.854514 10163 solver.cpp:228] Iteration 35000, loss = 1.10501
I0827 09:20:27.854539 10163 solver.cpp:244]     Train net output #0: loss = 1.10501 (* 1 = 1.10501 loss)
I0827 09:20:27.854549 10163 sgd_solver.cpp:106] Iteration 35000, lr = 4.68274e-05
I0827 09:20:32.174729 10163 solver.cpp:228] Iteration 35100, loss = 1.09571
I0827 09:20:32.174788 10163 solver.cpp:244]     Train net output #0: loss = 1.09571 (* 1 = 1.09571 loss)
I0827 09:20:32.174795 10163 sgd_solver.cpp:106] Iteration 35100, lr = 4.67637e-05
I0827 09:20:36.500035 10163 solver.cpp:228] Iteration 35200, loss = 1.09193
I0827 09:20:36.500088 10163 solver.cpp:244]     Train net output #0: loss = 1.09193 (* 1 = 1.09193 loss)
I0827 09:20:36.500095 10163 sgd_solver.cpp:106] Iteration 35200, lr = 4.67001e-05
I0827 09:20:40.826999 10163 solver.cpp:228] Iteration 35300, loss = 1.10502
I0827 09:20:40.827040 10163 solver.cpp:244]     Train net output #0: loss = 1.10502 (* 1 = 1.10502 loss)
I0827 09:20:40.827046 10163 sgd_solver.cpp:106] Iteration 35300, lr = 4.66368e-05
I0827 09:20:45.143223 10163 solver.cpp:228] Iteration 35400, loss = 1.09539
I0827 09:20:45.143270 10163 solver.cpp:244]     Train net output #0: loss = 1.09539 (* 1 = 1.09539 loss)
I0827 09:20:45.143276 10163 sgd_solver.cpp:106] Iteration 35400, lr = 4.65736e-05
I0827 09:20:49.418316 10163 solver.cpp:337] Iteration 35500, Testing net (#0)
I0827 09:20:52.642632 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578666
I0827 09:20:52.642680 10163 solver.cpp:404]     Test net output #1: loss = 1.09436 (* 1 = 1.09436 loss)
I0827 09:20:52.657588 10163 solver.cpp:228] Iteration 35500, loss = 1.10408
I0827 09:20:52.657629 10163 solver.cpp:244]     Train net output #0: loss = 1.10408 (* 1 = 1.10408 loss)
I0827 09:20:52.657652 10163 sgd_solver.cpp:106] Iteration 35500, lr = 4.65107e-05
I0827 09:20:56.979990 10163 solver.cpp:228] Iteration 35600, loss = 1.0949
I0827 09:20:56.980036 10163 solver.cpp:244]     Train net output #0: loss = 1.0949 (* 1 = 1.0949 loss)
I0827 09:20:56.980042 10163 sgd_solver.cpp:106] Iteration 35600, lr = 4.64479e-05
I0827 09:21:01.306988 10163 solver.cpp:228] Iteration 35700, loss = 1.10244
I0827 09:21:01.307032 10163 solver.cpp:244]     Train net output #0: loss = 1.10244 (* 1 = 1.10244 loss)
I0827 09:21:01.307039 10163 sgd_solver.cpp:106] Iteration 35700, lr = 4.63854e-05
I0827 09:21:05.629812 10163 solver.cpp:228] Iteration 35800, loss = 1.09772
I0827 09:21:05.629868 10163 solver.cpp:244]     Train net output #0: loss = 1.09772 (* 1 = 1.09772 loss)
I0827 09:21:05.629876 10163 sgd_solver.cpp:106] Iteration 35800, lr = 4.6323e-05
I0827 09:21:09.951215 10163 solver.cpp:228] Iteration 35900, loss = 1.09924
I0827 09:21:09.951272 10163 solver.cpp:244]     Train net output #0: loss = 1.09924 (* 1 = 1.09924 loss)
I0827 09:21:09.951279 10163 sgd_solver.cpp:106] Iteration 35900, lr = 4.62609e-05
I0827 09:21:14.260807 10163 solver.cpp:337] Iteration 36000, Testing net (#0)
I0827 09:21:17.620789 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152625
I0827 09:21:17.620836 10163 solver.cpp:404]     Test net output #1: loss = 1.09955 (* 1 = 1.09955 loss)
I0827 09:21:17.635723 10163 solver.cpp:228] Iteration 36000, loss = 1.09162
I0827 09:21:17.635752 10163 solver.cpp:244]     Train net output #0: loss = 1.09162 (* 1 = 1.09162 loss)
I0827 09:21:17.635781 10163 sgd_solver.cpp:106] Iteration 36000, lr = 4.61989e-05
I0827 09:21:21.954063 10163 solver.cpp:228] Iteration 36100, loss = 1.10385
I0827 09:21:21.954116 10163 solver.cpp:244]     Train net output #0: loss = 1.10385 (* 1 = 1.10385 loss)
I0827 09:21:21.954128 10163 sgd_solver.cpp:106] Iteration 36100, lr = 4.61371e-05
I0827 09:21:26.271169 10163 solver.cpp:228] Iteration 36200, loss = 1.09885
I0827 09:21:26.271209 10163 solver.cpp:244]     Train net output #0: loss = 1.09885 (* 1 = 1.09885 loss)
I0827 09:21:26.271215 10163 sgd_solver.cpp:106] Iteration 36200, lr = 4.60755e-05
I0827 09:21:30.591487 10163 solver.cpp:228] Iteration 36300, loss = 1.0981
I0827 09:21:30.591506 10163 solver.cpp:244]     Train net output #0: loss = 1.0981 (* 1 = 1.0981 loss)
I0827 09:21:30.591511 10163 sgd_solver.cpp:106] Iteration 36300, lr = 4.60141e-05
I0827 09:21:34.911641 10163 solver.cpp:228] Iteration 36400, loss = 1.10075
I0827 09:21:34.911660 10163 solver.cpp:244]     Train net output #0: loss = 1.10075 (* 1 = 1.10075 loss)
I0827 09:21:34.911665 10163 sgd_solver.cpp:106] Iteration 36400, lr = 4.59529e-05
I0827 09:21:39.193163 10163 solver.cpp:337] Iteration 36500, Testing net (#0)
I0827 09:21:42.475344 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152042
I0827 09:21:42.475386 10163 solver.cpp:404]     Test net output #1: loss = 1.09858 (* 1 = 1.09858 loss)
I0827 09:21:42.490208 10163 solver.cpp:228] Iteration 36500, loss = 1.10187
I0827 09:21:42.490226 10163 solver.cpp:244]     Train net output #0: loss = 1.10187 (* 1 = 1.10187 loss)
I0827 09:21:42.490236 10163 sgd_solver.cpp:106] Iteration 36500, lr = 4.58919e-05
I0827 09:21:46.817565 10163 solver.cpp:228] Iteration 36600, loss = 1.09518
I0827 09:21:46.817621 10163 solver.cpp:244]     Train net output #0: loss = 1.09518 (* 1 = 1.09518 loss)
I0827 09:21:46.817631 10163 sgd_solver.cpp:106] Iteration 36600, lr = 4.58311e-05
I0827 09:21:51.139632 10163 solver.cpp:228] Iteration 36700, loss = 1.10012
I0827 09:21:51.139673 10163 solver.cpp:244]     Train net output #0: loss = 1.10012 (* 1 = 1.10012 loss)
I0827 09:21:51.139679 10163 sgd_solver.cpp:106] Iteration 36700, lr = 4.57705e-05
I0827 09:21:55.466603 10163 solver.cpp:228] Iteration 36800, loss = 1.09674
I0827 09:21:55.466645 10163 solver.cpp:244]     Train net output #0: loss = 1.09674 (* 1 = 1.09674 loss)
I0827 09:21:55.466651 10163 sgd_solver.cpp:106] Iteration 36800, lr = 4.571e-05
I0827 09:21:59.786897 10163 solver.cpp:228] Iteration 36900, loss = 1.10287
I0827 09:21:59.786919 10163 solver.cpp:244]     Train net output #0: loss = 1.10287 (* 1 = 1.10287 loss)
I0827 09:21:59.786926 10163 sgd_solver.cpp:106] Iteration 36900, lr = 4.56497e-05
I0827 09:22:04.071822 10163 solver.cpp:337] Iteration 37000, Testing net (#0)
I0827 09:22:04.582712 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:22:07.514973 10163 solver.cpp:404]     Test net output #0: accuracy = 0.151958
I0827 09:22:07.515015 10163 solver.cpp:404]     Test net output #1: loss = 1.10078 (* 1 = 1.10078 loss)
I0827 09:22:07.529212 10163 solver.cpp:228] Iteration 37000, loss = 1.10334
I0827 09:22:07.529266 10163 solver.cpp:244]     Train net output #0: loss = 1.10334 (* 1 = 1.10334 loss)
I0827 09:22:07.529286 10163 sgd_solver.cpp:106] Iteration 37000, lr = 4.55897e-05
I0827 09:22:11.857609 10163 solver.cpp:228] Iteration 37100, loss = 1.0998
I0827 09:22:11.857650 10163 solver.cpp:244]     Train net output #0: loss = 1.0998 (* 1 = 1.0998 loss)
I0827 09:22:11.857658 10163 sgd_solver.cpp:106] Iteration 37100, lr = 4.55298e-05
I0827 09:22:16.180107 10163 solver.cpp:228] Iteration 37200, loss = 1.09804
I0827 09:22:16.180124 10163 solver.cpp:244]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0827 09:22:16.180130 10163 sgd_solver.cpp:106] Iteration 37200, lr = 4.54701e-05
I0827 09:22:20.508199 10163 solver.cpp:228] Iteration 37300, loss = 1.09938
I0827 09:22:20.508255 10163 solver.cpp:244]     Train net output #0: loss = 1.09938 (* 1 = 1.09938 loss)
I0827 09:22:20.508261 10163 sgd_solver.cpp:106] Iteration 37300, lr = 4.54105e-05
I0827 09:22:24.828698 10163 solver.cpp:228] Iteration 37400, loss = 1.10417
I0827 09:22:24.828719 10163 solver.cpp:244]     Train net output #0: loss = 1.10417 (* 1 = 1.10417 loss)
I0827 09:22:24.828725 10163 sgd_solver.cpp:106] Iteration 37400, lr = 4.53512e-05
I0827 09:22:29.114612 10163 solver.cpp:337] Iteration 37500, Testing net (#0)
I0827 09:22:32.584677 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:22:32.584729 10163 solver.cpp:404]     Test net output #1: loss = 1.10141 (* 1 = 1.10141 loss)
I0827 09:22:32.599252 10163 solver.cpp:228] Iteration 37500, loss = 1.10711
I0827 09:22:32.599282 10163 solver.cpp:244]     Train net output #0: loss = 1.10711 (* 1 = 1.10711 loss)
I0827 09:22:32.599294 10163 sgd_solver.cpp:106] Iteration 37500, lr = 4.5292e-05
I0827 09:22:36.920639 10163 solver.cpp:228] Iteration 37600, loss = 1.10264
I0827 09:22:36.920675 10163 solver.cpp:244]     Train net output #0: loss = 1.10264 (* 1 = 1.10264 loss)
I0827 09:22:36.920681 10163 sgd_solver.cpp:106] Iteration 37600, lr = 4.5233e-05
I0827 09:22:41.240211 10163 solver.cpp:228] Iteration 37700, loss = 1.10412
I0827 09:22:41.240253 10163 solver.cpp:244]     Train net output #0: loss = 1.10412 (* 1 = 1.10412 loss)
I0827 09:22:41.240258 10163 sgd_solver.cpp:106] Iteration 37700, lr = 4.51742e-05
I0827 09:22:45.563993 10163 solver.cpp:228] Iteration 37800, loss = 1.10175
I0827 09:22:45.564034 10163 solver.cpp:244]     Train net output #0: loss = 1.10175 (* 1 = 1.10175 loss)
I0827 09:22:45.564039 10163 sgd_solver.cpp:106] Iteration 37800, lr = 4.51156e-05
I0827 09:22:49.891525 10163 solver.cpp:228] Iteration 37900, loss = 1.09869
I0827 09:22:49.891571 10163 solver.cpp:244]     Train net output #0: loss = 1.09869 (* 1 = 1.09869 loss)
I0827 09:22:49.891576 10163 sgd_solver.cpp:106] Iteration 37900, lr = 4.50571e-05
I0827 09:22:54.168283 10163 solver.cpp:337] Iteration 38000, Testing net (#0)
I0827 09:22:57.537732 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:22:57.537791 10163 solver.cpp:404]     Test net output #1: loss = 1.09847 (* 1 = 1.09847 loss)
I0827 09:22:57.552722 10163 solver.cpp:228] Iteration 38000, loss = 1.10005
I0827 09:22:57.552770 10163 solver.cpp:244]     Train net output #0: loss = 1.10005 (* 1 = 1.10005 loss)
I0827 09:22:57.552785 10163 sgd_solver.cpp:106] Iteration 38000, lr = 4.49989e-05
I0827 09:23:01.877640 10163 solver.cpp:228] Iteration 38100, loss = 1.10409
I0827 09:23:01.877699 10163 solver.cpp:244]     Train net output #0: loss = 1.10409 (* 1 = 1.10409 loss)
I0827 09:23:01.877707 10163 sgd_solver.cpp:106] Iteration 38100, lr = 4.49408e-05
I0827 09:23:06.204918 10163 solver.cpp:228] Iteration 38200, loss = 1.10005
I0827 09:23:06.204959 10163 solver.cpp:244]     Train net output #0: loss = 1.10005 (* 1 = 1.10005 loss)
I0827 09:23:06.204965 10163 sgd_solver.cpp:106] Iteration 38200, lr = 4.48828e-05
I0827 09:23:10.536283 10163 solver.cpp:228] Iteration 38300, loss = 1.09882
I0827 09:23:10.536344 10163 solver.cpp:244]     Train net output #0: loss = 1.09882 (* 1 = 1.09882 loss)
I0827 09:23:10.536351 10163 sgd_solver.cpp:106] Iteration 38300, lr = 4.48251e-05
I0827 09:23:14.863006 10163 solver.cpp:228] Iteration 38400, loss = 1.09425
I0827 09:23:14.863075 10163 solver.cpp:244]     Train net output #0: loss = 1.09425 (* 1 = 1.09425 loss)
I0827 09:23:14.863087 10163 sgd_solver.cpp:106] Iteration 38400, lr = 4.47675e-05
I0827 09:23:19.148115 10163 solver.cpp:337] Iteration 38500, Testing net (#0)
I0827 09:23:22.541776 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:23:22.541847 10163 solver.cpp:404]     Test net output #1: loss = 1.09786 (* 1 = 1.09786 loss)
I0827 09:23:22.557077 10163 solver.cpp:228] Iteration 38500, loss = 1.10559
I0827 09:23:22.557143 10163 solver.cpp:244]     Train net output #0: loss = 1.10559 (* 1 = 1.10559 loss)
I0827 09:23:22.557160 10163 sgd_solver.cpp:106] Iteration 38500, lr = 4.47101e-05
I0827 09:23:26.875665 10163 solver.cpp:228] Iteration 38600, loss = 1.10529
I0827 09:23:26.875707 10163 solver.cpp:244]     Train net output #0: loss = 1.10529 (* 1 = 1.10529 loss)
I0827 09:23:26.875713 10163 sgd_solver.cpp:106] Iteration 38600, lr = 4.46529e-05
I0827 09:23:31.196256 10163 solver.cpp:228] Iteration 38700, loss = 1.10487
I0827 09:23:31.196301 10163 solver.cpp:244]     Train net output #0: loss = 1.10487 (* 1 = 1.10487 loss)
I0827 09:23:31.196310 10163 sgd_solver.cpp:106] Iteration 38700, lr = 4.45958e-05
I0827 09:23:35.510799 10163 solver.cpp:228] Iteration 38800, loss = 1.11128
I0827 09:23:35.510818 10163 solver.cpp:244]     Train net output #0: loss = 1.11128 (* 1 = 1.11128 loss)
I0827 09:23:35.510823 10163 sgd_solver.cpp:106] Iteration 38800, lr = 4.45389e-05
I0827 09:23:39.829807 10163 solver.cpp:228] Iteration 38900, loss = 1.09915
I0827 09:23:39.829866 10163 solver.cpp:244]     Train net output #0: loss = 1.09915 (* 1 = 1.09915 loss)
I0827 09:23:39.829872 10163 sgd_solver.cpp:106] Iteration 38900, lr = 4.44822e-05
I0827 09:23:44.104846 10163 solver.cpp:337] Iteration 39000, Testing net (#0)
I0827 09:23:47.367676 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269083
I0827 09:23:47.367739 10163 solver.cpp:404]     Test net output #1: loss = 1.0933 (* 1 = 1.0933 loss)
I0827 09:23:47.382488 10163 solver.cpp:228] Iteration 39000, loss = 1.09992
I0827 09:23:47.382532 10163 solver.cpp:244]     Train net output #0: loss = 1.09992 (* 1 = 1.09992 loss)
I0827 09:23:47.382540 10163 sgd_solver.cpp:106] Iteration 39000, lr = 4.44256e-05
I0827 09:23:49.804291 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:23:51.702206 10163 solver.cpp:228] Iteration 39100, loss = 1.09531
I0827 09:23:51.702268 10163 solver.cpp:244]     Train net output #0: loss = 1.09531 (* 1 = 1.09531 loss)
I0827 09:23:51.702275 10163 sgd_solver.cpp:106] Iteration 39100, lr = 4.43692e-05
I0827 09:23:56.026106 10163 solver.cpp:228] Iteration 39200, loss = 1.10557
I0827 09:23:56.026165 10163 solver.cpp:244]     Train net output #0: loss = 1.10557 (* 1 = 1.10557 loss)
I0827 09:23:56.026171 10163 sgd_solver.cpp:106] Iteration 39200, lr = 4.4313e-05
I0827 09:24:00.348539 10163 solver.cpp:228] Iteration 39300, loss = 1.10185
I0827 09:24:00.348579 10163 solver.cpp:244]     Train net output #0: loss = 1.10185 (* 1 = 1.10185 loss)
I0827 09:24:00.348585 10163 sgd_solver.cpp:106] Iteration 39300, lr = 4.4257e-05
I0827 09:24:04.666790 10163 solver.cpp:228] Iteration 39400, loss = 1.09629
I0827 09:24:04.666831 10163 solver.cpp:244]     Train net output #0: loss = 1.09629 (* 1 = 1.09629 loss)
I0827 09:24:04.666836 10163 sgd_solver.cpp:106] Iteration 39400, lr = 4.42011e-05
I0827 09:24:08.946164 10163 solver.cpp:337] Iteration 39500, Testing net (#0)
I0827 09:24:12.486946 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0827 09:24:12.487004 10163 solver.cpp:404]     Test net output #1: loss = 1.09544 (* 1 = 1.09544 loss)
I0827 09:24:12.501719 10163 solver.cpp:228] Iteration 39500, loss = 1.09058
I0827 09:24:12.501754 10163 solver.cpp:244]     Train net output #0: loss = 1.09058 (* 1 = 1.09058 loss)
I0827 09:24:12.501776 10163 sgd_solver.cpp:106] Iteration 39500, lr = 4.41453e-05
I0827 09:24:16.822600 10163 solver.cpp:228] Iteration 39600, loss = 1.09855
I0827 09:24:16.822659 10163 solver.cpp:244]     Train net output #0: loss = 1.09855 (* 1 = 1.09855 loss)
I0827 09:24:16.822665 10163 sgd_solver.cpp:106] Iteration 39600, lr = 4.40898e-05
I0827 09:24:21.146065 10163 solver.cpp:228] Iteration 39700, loss = 1.10296
I0827 09:24:21.146126 10163 solver.cpp:244]     Train net output #0: loss = 1.10296 (* 1 = 1.10296 loss)
I0827 09:24:21.146132 10163 sgd_solver.cpp:106] Iteration 39700, lr = 4.40344e-05
I0827 09:24:25.468451 10163 solver.cpp:228] Iteration 39800, loss = 1.10061
I0827 09:24:25.468490 10163 solver.cpp:244]     Train net output #0: loss = 1.10061 (* 1 = 1.10061 loss)
I0827 09:24:25.468497 10163 sgd_solver.cpp:106] Iteration 39800, lr = 4.39791e-05
I0827 09:24:29.790657 10163 solver.cpp:228] Iteration 39900, loss = 1.10241
I0827 09:24:29.790716 10163 solver.cpp:244]     Train net output #0: loss = 1.10241 (* 1 = 1.10241 loss)
I0827 09:24:29.790724 10163 sgd_solver.cpp:106] Iteration 39900, lr = 4.39241e-05
I0827 09:24:34.077463 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_40000.caffemodel
I0827 09:24:34.646502 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_40000.solverstate
I0827 09:24:34.837046 10163 solver.cpp:337] Iteration 40000, Testing net (#0)
I0827 09:24:38.096842 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269792
I0827 09:24:38.096884 10163 solver.cpp:404]     Test net output #1: loss = 1.10053 (* 1 = 1.10053 loss)
I0827 09:24:38.114398 10163 solver.cpp:228] Iteration 40000, loss = 1.1083
I0827 09:24:38.114455 10163 solver.cpp:244]     Train net output #0: loss = 1.1083 (* 1 = 1.1083 loss)
I0827 09:24:38.114475 10163 sgd_solver.cpp:106] Iteration 40000, lr = 4.38691e-05
I0827 09:24:42.449640 10163 solver.cpp:228] Iteration 40100, loss = 1.09785
I0827 09:24:42.449676 10163 solver.cpp:244]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0827 09:24:42.449681 10163 sgd_solver.cpp:106] Iteration 40100, lr = 4.38144e-05
I0827 09:24:46.778777 10163 solver.cpp:228] Iteration 40200, loss = 1.09398
I0827 09:24:46.778842 10163 solver.cpp:244]     Train net output #0: loss = 1.09398 (* 1 = 1.09398 loss)
I0827 09:24:46.778861 10163 sgd_solver.cpp:106] Iteration 40200, lr = 4.37598e-05
I0827 09:24:51.103577 10163 solver.cpp:228] Iteration 40300, loss = 1.09617
I0827 09:24:51.103596 10163 solver.cpp:244]     Train net output #0: loss = 1.09617 (* 1 = 1.09617 loss)
I0827 09:24:51.103601 10163 sgd_solver.cpp:106] Iteration 40300, lr = 4.37053e-05
I0827 09:24:55.424684 10163 solver.cpp:228] Iteration 40400, loss = 1.09492
I0827 09:24:55.424717 10163 solver.cpp:244]     Train net output #0: loss = 1.09492 (* 1 = 1.09492 loss)
I0827 09:24:55.424723 10163 sgd_solver.cpp:106] Iteration 40400, lr = 4.36511e-05
I0827 09:24:59.717201 10163 solver.cpp:337] Iteration 40500, Testing net (#0)
I0827 09:25:02.845609 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 09:25:02.845649 10163 solver.cpp:404]     Test net output #1: loss = 1.10483 (* 1 = 1.10483 loss)
I0827 09:25:02.861356 10163 solver.cpp:228] Iteration 40500, loss = 1.09901
I0827 09:25:02.861426 10163 solver.cpp:244]     Train net output #0: loss = 1.09901 (* 1 = 1.09901 loss)
I0827 09:25:02.861459 10163 sgd_solver.cpp:106] Iteration 40500, lr = 4.35969e-05
I0827 09:25:07.184639 10163 solver.cpp:228] Iteration 40600, loss = 1.10231
I0827 09:25:07.184681 10163 solver.cpp:244]     Train net output #0: loss = 1.10231 (* 1 = 1.10231 loss)
I0827 09:25:07.184687 10163 sgd_solver.cpp:106] Iteration 40600, lr = 4.3543e-05
I0827 09:25:11.509891 10163 solver.cpp:228] Iteration 40700, loss = 1.11155
I0827 09:25:11.509932 10163 solver.cpp:244]     Train net output #0: loss = 1.11155 (* 1 = 1.11155 loss)
I0827 09:25:11.509938 10163 sgd_solver.cpp:106] Iteration 40700, lr = 4.34892e-05
I0827 09:25:15.834859 10163 solver.cpp:228] Iteration 40800, loss = 1.10027
I0827 09:25:15.834906 10163 solver.cpp:244]     Train net output #0: loss = 1.10027 (* 1 = 1.10027 loss)
I0827 09:25:15.834913 10163 sgd_solver.cpp:106] Iteration 40800, lr = 4.34355e-05
I0827 09:25:20.168656 10163 solver.cpp:228] Iteration 40900, loss = 1.1039
I0827 09:25:20.168721 10163 solver.cpp:244]     Train net output #0: loss = 1.1039 (* 1 = 1.1039 loss)
I0827 09:25:20.168730 10163 sgd_solver.cpp:106] Iteration 40900, lr = 4.3382e-05
I0827 09:25:24.450995 10163 solver.cpp:337] Iteration 41000, Testing net (#0)
I0827 09:25:27.903779 10163 solver.cpp:404]     Test net output #0: accuracy = 0.26925
I0827 09:25:27.903839 10163 solver.cpp:404]     Test net output #1: loss = 1.10802 (* 1 = 1.10802 loss)
I0827 09:25:27.918778 10163 solver.cpp:228] Iteration 41000, loss = 1.09714
I0827 09:25:27.918812 10163 solver.cpp:244]     Train net output #0: loss = 1.09714 (* 1 = 1.09714 loss)
I0827 09:25:27.918823 10163 sgd_solver.cpp:106] Iteration 41000, lr = 4.33286e-05
I0827 09:25:32.242606 10163 solver.cpp:228] Iteration 41100, loss = 1.10162
I0827 09:25:32.242646 10163 solver.cpp:244]     Train net output #0: loss = 1.10162 (* 1 = 1.10162 loss)
I0827 09:25:32.242653 10163 sgd_solver.cpp:106] Iteration 41100, lr = 4.32754e-05
I0827 09:25:36.565946 10163 solver.cpp:228] Iteration 41200, loss = 1.10238
I0827 09:25:36.565965 10163 solver.cpp:244]     Train net output #0: loss = 1.10238 (* 1 = 1.10238 loss)
I0827 09:25:36.565971 10163 sgd_solver.cpp:106] Iteration 41200, lr = 4.32224e-05
I0827 09:25:40.890723 10163 solver.cpp:228] Iteration 41300, loss = 1.09253
I0827 09:25:40.890764 10163 solver.cpp:244]     Train net output #0: loss = 1.09253 (* 1 = 1.09253 loss)
I0827 09:25:40.890770 10163 sgd_solver.cpp:106] Iteration 41300, lr = 4.31695e-05
I0827 09:25:45.215119 10163 solver.cpp:228] Iteration 41400, loss = 1.09353
I0827 09:25:45.215164 10163 solver.cpp:244]     Train net output #0: loss = 1.09353 (* 1 = 1.09353 loss)
I0827 09:25:45.215185 10163 sgd_solver.cpp:106] Iteration 41400, lr = 4.31168e-05
I0827 09:25:49.498121 10163 solver.cpp:337] Iteration 41500, Testing net (#0)
I0827 09:25:52.800228 10163 solver.cpp:404]     Test net output #0: accuracy = 0.26925
I0827 09:25:52.800328 10163 solver.cpp:404]     Test net output #1: loss = 1.10708 (* 1 = 1.10708 loss)
I0827 09:25:52.816901 10163 solver.cpp:228] Iteration 41500, loss = 1.10196
I0827 09:25:52.816964 10163 solver.cpp:244]     Train net output #0: loss = 1.10196 (* 1 = 1.10196 loss)
I0827 09:25:52.816982 10163 sgd_solver.cpp:106] Iteration 41500, lr = 4.30642e-05
I0827 09:25:57.139575 10163 solver.cpp:228] Iteration 41600, loss = 1.11059
I0827 09:25:57.139617 10163 solver.cpp:244]     Train net output #0: loss = 1.11059 (* 1 = 1.11059 loss)
I0827 09:25:57.139623 10163 sgd_solver.cpp:106] Iteration 41600, lr = 4.30117e-05
I0827 09:25:59.390410 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:26:01.463490 10163 solver.cpp:228] Iteration 41700, loss = 1.10164
I0827 09:26:01.463508 10163 solver.cpp:244]     Train net output #0: loss = 1.10164 (* 1 = 1.10164 loss)
I0827 09:26:01.463513 10163 sgd_solver.cpp:106] Iteration 41700, lr = 4.29594e-05
I0827 09:26:05.784008 10163 solver.cpp:228] Iteration 41800, loss = 1.10069
I0827 09:26:05.784049 10163 solver.cpp:244]     Train net output #0: loss = 1.10069 (* 1 = 1.10069 loss)
I0827 09:26:05.784055 10163 sgd_solver.cpp:106] Iteration 41800, lr = 4.29073e-05
I0827 09:26:10.104661 10163 solver.cpp:228] Iteration 41900, loss = 1.10211
I0827 09:26:10.104704 10163 solver.cpp:244]     Train net output #0: loss = 1.10211 (* 1 = 1.10211 loss)
I0827 09:26:10.104710 10163 sgd_solver.cpp:106] Iteration 41900, lr = 4.28553e-05
I0827 09:26:14.385996 10163 solver.cpp:337] Iteration 42000, Testing net (#0)
I0827 09:26:17.934671 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 09:26:17.934739 10163 solver.cpp:404]     Test net output #1: loss = 1.10676 (* 1 = 1.10676 loss)
I0827 09:26:17.957792 10163 solver.cpp:228] Iteration 42000, loss = 1.10124
I0827 09:26:17.957854 10163 solver.cpp:244]     Train net output #0: loss = 1.10124 (* 1 = 1.10124 loss)
I0827 09:26:17.957870 10163 sgd_solver.cpp:106] Iteration 42000, lr = 4.28034e-05
I0827 09:26:22.279865 10163 solver.cpp:228] Iteration 42100, loss = 1.09981
I0827 09:26:22.279907 10163 solver.cpp:244]     Train net output #0: loss = 1.09981 (* 1 = 1.09981 loss)
I0827 09:26:22.279913 10163 sgd_solver.cpp:106] Iteration 42100, lr = 4.27517e-05
I0827 09:26:26.596563 10163 solver.cpp:228] Iteration 42200, loss = 1.1096
I0827 09:26:26.596614 10163 solver.cpp:244]     Train net output #0: loss = 1.1096 (* 1 = 1.1096 loss)
I0827 09:26:26.596622 10163 sgd_solver.cpp:106] Iteration 42200, lr = 4.27002e-05
I0827 09:26:30.914331 10163 solver.cpp:228] Iteration 42300, loss = 1.10596
I0827 09:26:30.914352 10163 solver.cpp:244]     Train net output #0: loss = 1.10596 (* 1 = 1.10596 loss)
I0827 09:26:30.914357 10163 sgd_solver.cpp:106] Iteration 42300, lr = 4.26488e-05
I0827 09:26:35.231973 10163 solver.cpp:228] Iteration 42400, loss = 1.09942
I0827 09:26:35.231993 10163 solver.cpp:244]     Train net output #0: loss = 1.09942 (* 1 = 1.09942 loss)
I0827 09:26:35.231999 10163 sgd_solver.cpp:106] Iteration 42400, lr = 4.25975e-05
I0827 09:26:39.508894 10163 solver.cpp:337] Iteration 42500, Testing net (#0)
I0827 09:26:42.996191 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 09:26:42.996250 10163 solver.cpp:404]     Test net output #1: loss = 1.10464 (* 1 = 1.10464 loss)
I0827 09:26:43.010974 10163 solver.cpp:228] Iteration 42500, loss = 1.09876
I0827 09:26:43.011011 10163 solver.cpp:244]     Train net output #0: loss = 1.09876 (* 1 = 1.09876 loss)
I0827 09:26:43.011023 10163 sgd_solver.cpp:106] Iteration 42500, lr = 4.25464e-05
I0827 09:26:47.328088 10163 solver.cpp:228] Iteration 42600, loss = 1.09236
I0827 09:26:47.328136 10163 solver.cpp:244]     Train net output #0: loss = 1.09236 (* 1 = 1.09236 loss)
I0827 09:26:47.328141 10163 sgd_solver.cpp:106] Iteration 42600, lr = 4.24954e-05
I0827 09:26:51.650774 10163 solver.cpp:228] Iteration 42700, loss = 1.08753
I0827 09:26:51.650820 10163 solver.cpp:244]     Train net output #0: loss = 1.08753 (* 1 = 1.08753 loss)
I0827 09:26:51.650826 10163 sgd_solver.cpp:106] Iteration 42700, lr = 4.24445e-05
I0827 09:26:55.970969 10163 solver.cpp:228] Iteration 42800, loss = 1.11329
I0827 09:26:55.971043 10163 solver.cpp:244]     Train net output #0: loss = 1.11329 (* 1 = 1.11329 loss)
I0827 09:26:55.971052 10163 sgd_solver.cpp:106] Iteration 42800, lr = 4.23938e-05
I0827 09:27:00.292564 10163 solver.cpp:228] Iteration 42900, loss = 1.09038
I0827 09:27:00.292614 10163 solver.cpp:244]     Train net output #0: loss = 1.09038 (* 1 = 1.09038 loss)
I0827 09:27:00.292620 10163 sgd_solver.cpp:106] Iteration 42900, lr = 4.23433e-05
I0827 09:27:04.571691 10163 solver.cpp:337] Iteration 43000, Testing net (#0)
I0827 09:27:07.958470 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 09:27:07.958529 10163 solver.cpp:404]     Test net output #1: loss = 1.10014 (* 1 = 1.10014 loss)
I0827 09:27:07.973404 10163 solver.cpp:228] Iteration 43000, loss = 1.10068
I0827 09:27:07.973445 10163 solver.cpp:244]     Train net output #0: loss = 1.10068 (* 1 = 1.10068 loss)
I0827 09:27:07.973464 10163 sgd_solver.cpp:106] Iteration 43000, lr = 4.22929e-05
I0827 09:27:12.291579 10163 solver.cpp:228] Iteration 43100, loss = 1.09679
I0827 09:27:12.291643 10163 solver.cpp:244]     Train net output #0: loss = 1.09679 (* 1 = 1.09679 loss)
I0827 09:27:12.291656 10163 sgd_solver.cpp:106] Iteration 43100, lr = 4.22426e-05
I0827 09:27:16.620203 10163 solver.cpp:228] Iteration 43200, loss = 1.10414
I0827 09:27:16.620244 10163 solver.cpp:244]     Train net output #0: loss = 1.10414 (* 1 = 1.10414 loss)
I0827 09:27:16.620250 10163 sgd_solver.cpp:106] Iteration 43200, lr = 4.21924e-05
I0827 09:27:20.942560 10163 solver.cpp:228] Iteration 43300, loss = 1.09663
I0827 09:27:20.942600 10163 solver.cpp:244]     Train net output #0: loss = 1.09663 (* 1 = 1.09663 loss)
I0827 09:27:20.942605 10163 sgd_solver.cpp:106] Iteration 43300, lr = 4.21424e-05
I0827 09:27:25.265010 10163 solver.cpp:228] Iteration 43400, loss = 1.09734
I0827 09:27:25.265071 10163 solver.cpp:244]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0827 09:27:25.265079 10163 sgd_solver.cpp:106] Iteration 43400, lr = 4.20926e-05
I0827 09:27:29.545266 10163 solver.cpp:337] Iteration 43500, Testing net (#0)
I0827 09:27:33.071036 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152083
I0827 09:27:33.071100 10163 solver.cpp:404]     Test net output #1: loss = 1.09893 (* 1 = 1.09893 loss)
I0827 09:27:33.085839 10163 solver.cpp:228] Iteration 43500, loss = 1.11041
I0827 09:27:33.085886 10163 solver.cpp:244]     Train net output #0: loss = 1.11041 (* 1 = 1.11041 loss)
I0827 09:27:33.085897 10163 sgd_solver.cpp:106] Iteration 43500, lr = 4.20429e-05
I0827 09:27:37.407974 10163 solver.cpp:228] Iteration 43600, loss = 1.10378
I0827 09:27:37.408015 10163 solver.cpp:244]     Train net output #0: loss = 1.10378 (* 1 = 1.10378 loss)
I0827 09:27:37.408021 10163 sgd_solver.cpp:106] Iteration 43600, lr = 4.19933e-05
I0827 09:27:41.729490 10163 solver.cpp:228] Iteration 43700, loss = 1.09407
I0827 09:27:41.729528 10163 solver.cpp:244]     Train net output #0: loss = 1.09407 (* 1 = 1.09407 loss)
I0827 09:27:41.729538 10163 sgd_solver.cpp:106] Iteration 43700, lr = 4.19438e-05
I0827 09:27:46.051223 10163 solver.cpp:228] Iteration 43800, loss = 1.09891
I0827 09:27:46.051241 10163 solver.cpp:244]     Train net output #0: loss = 1.09891 (* 1 = 1.09891 loss)
I0827 09:27:46.051259 10163 sgd_solver.cpp:106] Iteration 43800, lr = 4.18945e-05
I0827 09:27:50.369699 10163 solver.cpp:228] Iteration 43900, loss = 1.09623
I0827 09:27:50.369751 10163 solver.cpp:244]     Train net output #0: loss = 1.09623 (* 1 = 1.09623 loss)
I0827 09:27:50.369758 10163 sgd_solver.cpp:106] Iteration 43900, lr = 4.18453e-05
I0827 09:27:54.645849 10163 solver.cpp:337] Iteration 44000, Testing net (#0)
I0827 09:27:56.643602 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:27:57.897460 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:27:57.897507 10163 solver.cpp:404]     Test net output #1: loss = 1.10103 (* 1 = 1.10103 loss)
I0827 09:27:57.914926 10163 solver.cpp:228] Iteration 44000, loss = 1.10401
I0827 09:27:57.914983 10163 solver.cpp:244]     Train net output #0: loss = 1.10401 (* 1 = 1.10401 loss)
I0827 09:27:57.915002 10163 sgd_solver.cpp:106] Iteration 44000, lr = 4.17963e-05
I0827 09:28:02.235450 10163 solver.cpp:228] Iteration 44100, loss = 1.10407
I0827 09:28:02.235501 10163 solver.cpp:244]     Train net output #0: loss = 1.10407 (* 1 = 1.10407 loss)
I0827 09:28:02.235505 10163 sgd_solver.cpp:106] Iteration 44100, lr = 4.17474e-05
I0827 09:28:06.558794 10163 solver.cpp:228] Iteration 44200, loss = 1.09962
I0827 09:28:06.558837 10163 solver.cpp:244]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0827 09:28:06.558843 10163 sgd_solver.cpp:106] Iteration 44200, lr = 4.16986e-05
I0827 09:28:10.875957 10163 solver.cpp:228] Iteration 44300, loss = 1.10175
I0827 09:28:10.875999 10163 solver.cpp:244]     Train net output #0: loss = 1.10175 (* 1 = 1.10175 loss)
I0827 09:28:10.876005 10163 sgd_solver.cpp:106] Iteration 44300, lr = 4.16499e-05
I0827 09:28:15.212095 10163 solver.cpp:228] Iteration 44400, loss = 1.10009
I0827 09:28:15.212146 10163 solver.cpp:244]     Train net output #0: loss = 1.10009 (* 1 = 1.10009 loss)
I0827 09:28:15.212152 10163 sgd_solver.cpp:106] Iteration 44400, lr = 4.16014e-05
I0827 09:28:19.498534 10163 solver.cpp:337] Iteration 44500, Testing net (#0)
I0827 09:28:22.746052 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:28:22.746119 10163 solver.cpp:404]     Test net output #1: loss = 1.10315 (* 1 = 1.10315 loss)
I0827 09:28:22.761607 10163 solver.cpp:228] Iteration 44500, loss = 1.09961
I0827 09:28:22.761675 10163 solver.cpp:244]     Train net output #0: loss = 1.09961 (* 1 = 1.09961 loss)
I0827 09:28:22.761693 10163 sgd_solver.cpp:106] Iteration 44500, lr = 4.1553e-05
I0827 09:28:27.084453 10163 solver.cpp:228] Iteration 44600, loss = 1.09729
I0827 09:28:27.084520 10163 solver.cpp:244]     Train net output #0: loss = 1.09729 (* 1 = 1.09729 loss)
I0827 09:28:27.084528 10163 sgd_solver.cpp:106] Iteration 44600, lr = 4.15048e-05
I0827 09:28:31.406777 10163 solver.cpp:228] Iteration 44700, loss = 1.08811
I0827 09:28:31.406816 10163 solver.cpp:244]     Train net output #0: loss = 1.08811 (* 1 = 1.08811 loss)
I0827 09:28:31.406822 10163 sgd_solver.cpp:106] Iteration 44700, lr = 4.14567e-05
I0827 09:28:35.726197 10163 solver.cpp:228] Iteration 44800, loss = 1.10468
I0827 09:28:35.726217 10163 solver.cpp:244]     Train net output #0: loss = 1.10468 (* 1 = 1.10468 loss)
I0827 09:28:35.726223 10163 sgd_solver.cpp:106] Iteration 44800, lr = 4.14087e-05
I0827 09:28:40.047899 10163 solver.cpp:228] Iteration 44900, loss = 1.10627
I0827 09:28:40.047941 10163 solver.cpp:244]     Train net output #0: loss = 1.10627 (* 1 = 1.10627 loss)
I0827 09:28:40.047947 10163 sgd_solver.cpp:106] Iteration 44900, lr = 4.13608e-05
I0827 09:28:44.323392 10163 solver.cpp:337] Iteration 45000, Testing net (#0)
I0827 09:28:47.562428 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152083
I0827 09:28:47.562538 10163 solver.cpp:404]     Test net output #1: loss = 1.10701 (* 1 = 1.10701 loss)
I0827 09:28:47.579798 10163 solver.cpp:228] Iteration 45000, loss = 1.10384
I0827 09:28:47.579860 10163 solver.cpp:244]     Train net output #0: loss = 1.10384 (* 1 = 1.10384 loss)
I0827 09:28:47.579884 10163 sgd_solver.cpp:106] Iteration 45000, lr = 4.13131e-05
I0827 09:28:51.907665 10163 solver.cpp:228] Iteration 45100, loss = 1.10337
I0827 09:28:51.907711 10163 solver.cpp:244]     Train net output #0: loss = 1.10337 (* 1 = 1.10337 loss)
I0827 09:28:51.907717 10163 sgd_solver.cpp:106] Iteration 45100, lr = 4.12655e-05
I0827 09:28:56.229573 10163 solver.cpp:228] Iteration 45200, loss = 1.09666
I0827 09:28:56.229594 10163 solver.cpp:244]     Train net output #0: loss = 1.09666 (* 1 = 1.09666 loss)
I0827 09:28:56.229600 10163 sgd_solver.cpp:106] Iteration 45200, lr = 4.1218e-05
I0827 09:29:00.552268 10163 solver.cpp:228] Iteration 45300, loss = 1.09962
I0827 09:29:00.552309 10163 solver.cpp:244]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0827 09:29:00.552314 10163 sgd_solver.cpp:106] Iteration 45300, lr = 4.11706e-05
I0827 09:29:04.874670 10163 solver.cpp:228] Iteration 45400, loss = 1.10028
I0827 09:29:04.874723 10163 solver.cpp:244]     Train net output #0: loss = 1.10028 (* 1 = 1.10028 loss)
I0827 09:29:04.874732 10163 sgd_solver.cpp:106] Iteration 45400, lr = 4.11234e-05
I0827 09:29:09.153481 10163 solver.cpp:337] Iteration 45500, Testing net (#0)
I0827 09:29:12.370728 10163 solver.cpp:404]     Test net output #0: accuracy = 0.151833
I0827 09:29:12.370790 10163 solver.cpp:404]     Test net output #1: loss = 1.10565 (* 1 = 1.10565 loss)
I0827 09:29:12.386520 10163 solver.cpp:228] Iteration 45500, loss = 1.09404
I0827 09:29:12.386564 10163 solver.cpp:244]     Train net output #0: loss = 1.09404 (* 1 = 1.09404 loss)
I0827 09:29:12.386577 10163 sgd_solver.cpp:106] Iteration 45500, lr = 4.10763e-05
I0827 09:29:16.704497 10163 solver.cpp:228] Iteration 45600, loss = 1.11041
I0827 09:29:16.704536 10163 solver.cpp:244]     Train net output #0: loss = 1.11041 (* 1 = 1.11041 loss)
I0827 09:29:16.704541 10163 sgd_solver.cpp:106] Iteration 45600, lr = 4.10293e-05
I0827 09:29:21.021409 10163 solver.cpp:228] Iteration 45700, loss = 1.10773
I0827 09:29:21.021447 10163 solver.cpp:244]     Train net output #0: loss = 1.10773 (* 1 = 1.10773 loss)
I0827 09:29:21.021453 10163 sgd_solver.cpp:106] Iteration 45700, lr = 4.09825e-05
I0827 09:29:25.339895 10163 solver.cpp:228] Iteration 45800, loss = 1.09873
I0827 09:29:25.339937 10163 solver.cpp:244]     Train net output #0: loss = 1.09873 (* 1 = 1.09873 loss)
I0827 09:29:25.339942 10163 sgd_solver.cpp:106] Iteration 45800, lr = 4.09358e-05
I0827 09:29:29.655187 10163 solver.cpp:228] Iteration 45900, loss = 1.09979
I0827 09:29:29.655205 10163 solver.cpp:244]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0827 09:29:29.655210 10163 sgd_solver.cpp:106] Iteration 45900, lr = 4.08892e-05
I0827 09:29:33.927914 10163 solver.cpp:337] Iteration 46000, Testing net (#0)
I0827 09:29:37.311517 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:29:37.311583 10163 solver.cpp:404]     Test net output #1: loss = 1.1063 (* 1 = 1.1063 loss)
I0827 09:29:37.326814 10163 solver.cpp:228] Iteration 46000, loss = 1.09351
I0827 09:29:37.326881 10163 solver.cpp:244]     Train net output #0: loss = 1.09351 (* 1 = 1.09351 loss)
I0827 09:29:37.326902 10163 sgd_solver.cpp:106] Iteration 46000, lr = 4.08427e-05
I0827 09:29:41.652123 10163 solver.cpp:228] Iteration 46100, loss = 1.10359
I0827 09:29:41.652180 10163 solver.cpp:244]     Train net output #0: loss = 1.10359 (* 1 = 1.10359 loss)
I0827 09:29:41.652187 10163 sgd_solver.cpp:106] Iteration 46100, lr = 4.07964e-05
I0827 09:29:45.970731 10163 solver.cpp:228] Iteration 46200, loss = 1.09528
I0827 09:29:45.970790 10163 solver.cpp:244]     Train net output #0: loss = 1.09528 (* 1 = 1.09528 loss)
I0827 09:29:45.970798 10163 sgd_solver.cpp:106] Iteration 46200, lr = 4.07501e-05
I0827 09:29:50.288100 10163 solver.cpp:228] Iteration 46300, loss = 1.10351
I0827 09:29:50.288154 10163 solver.cpp:244]     Train net output #0: loss = 1.10351 (* 1 = 1.10351 loss)
I0827 09:29:50.288161 10163 sgd_solver.cpp:106] Iteration 46300, lr = 4.0704e-05
I0827 09:29:54.613481 10163 solver.cpp:228] Iteration 46400, loss = 1.10295
I0827 09:29:54.613544 10163 solver.cpp:244]     Train net output #0: loss = 1.10295 (* 1 = 1.10295 loss)
I0827 09:29:54.613551 10163 sgd_solver.cpp:106] Iteration 46400, lr = 4.0658e-05
I0827 09:29:58.906996 10163 solver.cpp:337] Iteration 46500, Testing net (#0)
I0827 09:30:02.142065 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0827 09:30:02.142110 10163 solver.cpp:404]     Test net output #1: loss = 1.1082 (* 1 = 1.1082 loss)
I0827 09:30:02.158684 10163 solver.cpp:228] Iteration 46500, loss = 1.10685
I0827 09:30:02.158758 10163 solver.cpp:244]     Train net output #0: loss = 1.10685 (* 1 = 1.10685 loss)
I0827 09:30:02.158774 10163 sgd_solver.cpp:106] Iteration 46500, lr = 4.06122e-05
I0827 09:30:06.486518 10163 solver.cpp:228] Iteration 46600, loss = 1.10141
I0827 09:30:06.486568 10163 solver.cpp:244]     Train net output #0: loss = 1.10141 (* 1 = 1.10141 loss)
I0827 09:30:06.486577 10163 sgd_solver.cpp:106] Iteration 46600, lr = 4.05664e-05
I0827 09:30:10.809345 10163 solver.cpp:228] Iteration 46700, loss = 1.0927
I0827 09:30:10.809377 10163 solver.cpp:244]     Train net output #0: loss = 1.0927 (* 1 = 1.0927 loss)
I0827 09:30:10.809383 10163 sgd_solver.cpp:106] Iteration 46700, lr = 4.05208e-05
I0827 09:30:15.133708 10163 solver.cpp:228] Iteration 46800, loss = 1.09762
I0827 09:30:15.133764 10163 solver.cpp:244]     Train net output #0: loss = 1.09762 (* 1 = 1.09762 loss)
I0827 09:30:15.133771 10163 sgd_solver.cpp:106] Iteration 46800, lr = 4.04753e-05
I0827 09:30:19.453011 10163 solver.cpp:228] Iteration 46900, loss = 1.09608
I0827 09:30:19.453064 10163 solver.cpp:244]     Train net output #0: loss = 1.09608 (* 1 = 1.09608 loss)
I0827 09:30:19.453073 10163 sgd_solver.cpp:106] Iteration 46900, lr = 4.04299e-05
I0827 09:30:23.741214 10163 solver.cpp:337] Iteration 47000, Testing net (#0)
I0827 09:30:24.439936 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:30:27.059903 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:30:27.059962 10163 solver.cpp:404]     Test net output #1: loss = 1.11111 (* 1 = 1.11111 loss)
I0827 09:30:27.074381 10163 solver.cpp:228] Iteration 47000, loss = 1.10496
I0827 09:30:27.074414 10163 solver.cpp:244]     Train net output #0: loss = 1.10496 (* 1 = 1.10496 loss)
I0827 09:30:27.074421 10163 sgd_solver.cpp:106] Iteration 47000, lr = 4.03847e-05
I0827 09:30:31.395064 10163 solver.cpp:228] Iteration 47100, loss = 1.09119
I0827 09:30:31.395104 10163 solver.cpp:244]     Train net output #0: loss = 1.09119 (* 1 = 1.09119 loss)
I0827 09:30:31.395110 10163 sgd_solver.cpp:106] Iteration 47100, lr = 4.03395e-05
I0827 09:30:35.717546 10163 solver.cpp:228] Iteration 47200, loss = 1.09906
I0827 09:30:35.717566 10163 solver.cpp:244]     Train net output #0: loss = 1.09906 (* 1 = 1.09906 loss)
I0827 09:30:35.717571 10163 sgd_solver.cpp:106] Iteration 47200, lr = 4.02945e-05
I0827 09:30:40.039849 10163 solver.cpp:228] Iteration 47300, loss = 1.10917
I0827 09:30:40.039904 10163 solver.cpp:244]     Train net output #0: loss = 1.10917 (* 1 = 1.10917 loss)
I0827 09:30:40.039916 10163 sgd_solver.cpp:106] Iteration 47300, lr = 4.02496e-05
I0827 09:30:44.368783 10163 solver.cpp:228] Iteration 47400, loss = 1.10453
I0827 09:30:44.368836 10163 solver.cpp:244]     Train net output #0: loss = 1.10453 (* 1 = 1.10453 loss)
I0827 09:30:44.368842 10163 sgd_solver.cpp:106] Iteration 47400, lr = 4.02048e-05
I0827 09:30:48.647730 10163 solver.cpp:337] Iteration 47500, Testing net (#0)
I0827 09:30:51.965668 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:30:51.965724 10163 solver.cpp:404]     Test net output #1: loss = 1.11373 (* 1 = 1.11373 loss)
I0827 09:30:51.981057 10163 solver.cpp:228] Iteration 47500, loss = 1.09328
I0827 09:30:51.981132 10163 solver.cpp:244]     Train net output #0: loss = 1.09328 (* 1 = 1.09328 loss)
I0827 09:30:51.981150 10163 sgd_solver.cpp:106] Iteration 47500, lr = 4.01601e-05
I0827 09:30:56.299811 10163 solver.cpp:228] Iteration 47600, loss = 1.09791
I0827 09:30:56.299875 10163 solver.cpp:244]     Train net output #0: loss = 1.09791 (* 1 = 1.09791 loss)
I0827 09:30:56.299881 10163 sgd_solver.cpp:106] Iteration 47600, lr = 4.01155e-05
I0827 09:31:00.621616 10163 solver.cpp:228] Iteration 47700, loss = 1.09519
I0827 09:31:00.621678 10163 solver.cpp:244]     Train net output #0: loss = 1.09519 (* 1 = 1.09519 loss)
I0827 09:31:00.621685 10163 sgd_solver.cpp:106] Iteration 47700, lr = 4.00711e-05
I0827 09:31:04.947022 10163 solver.cpp:228] Iteration 47800, loss = 1.09664
I0827 09:31:04.947085 10163 solver.cpp:244]     Train net output #0: loss = 1.09664 (* 1 = 1.09664 loss)
I0827 09:31:04.947093 10163 sgd_solver.cpp:106] Iteration 47800, lr = 4.00267e-05
I0827 09:31:09.272881 10163 solver.cpp:228] Iteration 47900, loss = 1.10431
I0827 09:31:09.272944 10163 solver.cpp:244]     Train net output #0: loss = 1.10431 (* 1 = 1.10431 loss)
I0827 09:31:09.272951 10163 sgd_solver.cpp:106] Iteration 47900, lr = 3.99825e-05
I0827 09:31:13.557281 10163 solver.cpp:337] Iteration 48000, Testing net (#0)
I0827 09:31:16.851068 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0827 09:31:16.851171 10163 solver.cpp:404]     Test net output #1: loss = 1.11542 (* 1 = 1.11542 loss)
I0827 09:31:16.866521 10163 solver.cpp:228] Iteration 48000, loss = 1.10888
I0827 09:31:16.866590 10163 solver.cpp:244]     Train net output #0: loss = 1.10888 (* 1 = 1.10888 loss)
I0827 09:31:16.866605 10163 sgd_solver.cpp:106] Iteration 48000, lr = 3.99384e-05
I0827 09:31:21.192975 10163 solver.cpp:228] Iteration 48100, loss = 1.11167
I0827 09:31:21.193019 10163 solver.cpp:244]     Train net output #0: loss = 1.11167 (* 1 = 1.11167 loss)
I0827 09:31:21.193027 10163 sgd_solver.cpp:106] Iteration 48100, lr = 3.98944e-05
I0827 09:31:25.514008 10163 solver.cpp:228] Iteration 48200, loss = 1.10627
I0827 09:31:25.514027 10163 solver.cpp:244]     Train net output #0: loss = 1.10627 (* 1 = 1.10627 loss)
I0827 09:31:25.514034 10163 sgd_solver.cpp:106] Iteration 48200, lr = 3.98505e-05
I0827 09:31:29.836199 10163 solver.cpp:228] Iteration 48300, loss = 1.10695
I0827 09:31:29.836239 10163 solver.cpp:244]     Train net output #0: loss = 1.10695 (* 1 = 1.10695 loss)
I0827 09:31:29.836246 10163 sgd_solver.cpp:106] Iteration 48300, lr = 3.98068e-05
I0827 09:31:34.159018 10163 solver.cpp:228] Iteration 48400, loss = 1.09962
I0827 09:31:34.159057 10163 solver.cpp:244]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0827 09:31:34.159063 10163 sgd_solver.cpp:106] Iteration 48400, lr = 3.97631e-05
I0827 09:31:38.439414 10163 solver.cpp:337] Iteration 48500, Testing net (#0)
I0827 09:31:41.860586 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:31:41.860689 10163 solver.cpp:404]     Test net output #1: loss = 1.11258 (* 1 = 1.11258 loss)
I0827 09:31:41.876116 10163 solver.cpp:228] Iteration 48500, loss = 1.10198
I0827 09:31:41.876183 10163 solver.cpp:244]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0827 09:31:41.876199 10163 sgd_solver.cpp:106] Iteration 48500, lr = 3.97196e-05
I0827 09:31:46.201877 10163 solver.cpp:228] Iteration 48600, loss = 1.10126
I0827 09:31:46.201941 10163 solver.cpp:244]     Train net output #0: loss = 1.10126 (* 1 = 1.10126 loss)
I0827 09:31:46.201947 10163 sgd_solver.cpp:106] Iteration 48600, lr = 3.96761e-05
I0827 09:31:50.522804 10163 solver.cpp:228] Iteration 48700, loss = 1.09819
I0827 09:31:50.522847 10163 solver.cpp:244]     Train net output #0: loss = 1.09819 (* 1 = 1.09819 loss)
I0827 09:31:50.522853 10163 sgd_solver.cpp:106] Iteration 48700, lr = 3.96328e-05
I0827 09:31:54.845765 10163 solver.cpp:228] Iteration 48800, loss = 1.09663
I0827 09:31:54.845785 10163 solver.cpp:244]     Train net output #0: loss = 1.09663 (* 1 = 1.09663 loss)
I0827 09:31:54.845790 10163 sgd_solver.cpp:106] Iteration 48800, lr = 3.95896e-05
I0827 09:31:59.165802 10163 solver.cpp:228] Iteration 48900, loss = 1.09736
I0827 09:31:59.165843 10163 solver.cpp:244]     Train net output #0: loss = 1.09736 (* 1 = 1.09736 loss)
I0827 09:31:59.165848 10163 sgd_solver.cpp:106] Iteration 48900, lr = 3.95465e-05
I0827 09:32:03.453001 10163 solver.cpp:337] Iteration 49000, Testing net (#0)
I0827 09:32:06.874039 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0827 09:32:06.874146 10163 solver.cpp:404]     Test net output #1: loss = 1.10331 (* 1 = 1.10331 loss)
I0827 09:32:06.889736 10163 solver.cpp:228] Iteration 49000, loss = 1.10817
I0827 09:32:06.889766 10163 solver.cpp:244]     Train net output #0: loss = 1.10817 (* 1 = 1.10817 loss)
I0827 09:32:06.889780 10163 sgd_solver.cpp:106] Iteration 49000, lr = 3.95035e-05
I0827 09:32:11.214117 10163 solver.cpp:228] Iteration 49100, loss = 1.10391
I0827 09:32:11.214166 10163 solver.cpp:244]     Train net output #0: loss = 1.10391 (* 1 = 1.10391 loss)
I0827 09:32:11.214174 10163 sgd_solver.cpp:106] Iteration 49100, lr = 3.94606e-05
I0827 09:32:15.531802 10163 solver.cpp:228] Iteration 49200, loss = 1.10191
I0827 09:32:15.531823 10163 solver.cpp:244]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0827 09:32:15.531829 10163 sgd_solver.cpp:106] Iteration 49200, lr = 3.94178e-05
I0827 09:32:19.855470 10163 solver.cpp:228] Iteration 49300, loss = 1.09483
I0827 09:32:19.855541 10163 solver.cpp:244]     Train net output #0: loss = 1.09483 (* 1 = 1.09483 loss)
I0827 09:32:19.855548 10163 sgd_solver.cpp:106] Iteration 49300, lr = 3.93752e-05
I0827 09:32:24.178057 10163 solver.cpp:228] Iteration 49400, loss = 1.09543
I0827 09:32:24.178122 10163 solver.cpp:244]     Train net output #0: loss = 1.09543 (* 1 = 1.09543 loss)
I0827 09:32:24.178129 10163 sgd_solver.cpp:106] Iteration 49400, lr = 3.93326e-05
I0827 09:32:28.456395 10163 solver.cpp:337] Iteration 49500, Testing net (#0)
I0827 09:32:30.517513 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:32:31.919771 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0827 09:32:31.919826 10163 solver.cpp:404]     Test net output #1: loss = 1.09703 (* 1 = 1.09703 loss)
I0827 09:32:31.934662 10163 solver.cpp:228] Iteration 49500, loss = 1.09894
I0827 09:32:31.934701 10163 solver.cpp:244]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0827 09:32:31.934711 10163 sgd_solver.cpp:106] Iteration 49500, lr = 3.92902e-05
I0827 09:32:36.259241 10163 solver.cpp:228] Iteration 49600, loss = 1.09124
I0827 09:32:36.259287 10163 solver.cpp:244]     Train net output #0: loss = 1.09124 (* 1 = 1.09124 loss)
I0827 09:32:36.259294 10163 sgd_solver.cpp:106] Iteration 49600, lr = 3.92478e-05
I0827 09:32:40.575978 10163 solver.cpp:228] Iteration 49700, loss = 1.1051
I0827 09:32:40.576017 10163 solver.cpp:244]     Train net output #0: loss = 1.1051 (* 1 = 1.1051 loss)
I0827 09:32:40.576023 10163 sgd_solver.cpp:106] Iteration 49700, lr = 3.92056e-05
I0827 09:32:44.895629 10163 solver.cpp:228] Iteration 49800, loss = 1.1034
I0827 09:32:44.895676 10163 solver.cpp:244]     Train net output #0: loss = 1.1034 (* 1 = 1.1034 loss)
I0827 09:32:44.895684 10163 sgd_solver.cpp:106] Iteration 49800, lr = 3.91634e-05
I0827 09:32:49.216187 10163 solver.cpp:228] Iteration 49900, loss = 1.09628
I0827 09:32:49.216238 10163 solver.cpp:244]     Train net output #0: loss = 1.09628 (* 1 = 1.09628 loss)
I0827 09:32:49.216243 10163 sgd_solver.cpp:106] Iteration 49900, lr = 3.91214e-05
I0827 09:32:53.490689 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_50000.caffemodel
I0827 09:32:53.965261 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_50000.solverstate
I0827 09:32:54.120728 10163 solver.cpp:337] Iteration 50000, Testing net (#0)
I0827 09:32:57.730926 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0827 09:32:57.730988 10163 solver.cpp:404]     Test net output #1: loss = 1.09111 (* 1 = 1.09111 loss)
I0827 09:32:57.745517 10163 solver.cpp:228] Iteration 50000, loss = 1.09226
I0827 09:32:57.745556 10163 solver.cpp:244]     Train net output #0: loss = 1.09226 (* 1 = 1.09226 loss)
I0827 09:32:57.745568 10163 sgd_solver.cpp:106] Iteration 50000, lr = 3.90795e-05
I0827 09:33:02.067289 10163 solver.cpp:228] Iteration 50100, loss = 1.09971
I0827 09:33:02.067330 10163 solver.cpp:244]     Train net output #0: loss = 1.09971 (* 1 = 1.09971 loss)
I0827 09:33:02.067337 10163 sgd_solver.cpp:106] Iteration 50100, lr = 3.90377e-05
I0827 09:33:06.390067 10163 solver.cpp:228] Iteration 50200, loss = 1.09374
I0827 09:33:06.390084 10163 solver.cpp:244]     Train net output #0: loss = 1.09374 (* 1 = 1.09374 loss)
I0827 09:33:06.390089 10163 sgd_solver.cpp:106] Iteration 50200, lr = 3.8996e-05
I0827 09:33:10.707576 10163 solver.cpp:228] Iteration 50300, loss = 1.10654
I0827 09:33:10.707595 10163 solver.cpp:244]     Train net output #0: loss = 1.10654 (* 1 = 1.10654 loss)
I0827 09:33:10.707600 10163 sgd_solver.cpp:106] Iteration 50300, lr = 3.89544e-05
I0827 09:33:15.022958 10163 solver.cpp:228] Iteration 50400, loss = 1.10511
I0827 09:33:15.022995 10163 solver.cpp:244]     Train net output #0: loss = 1.10511 (* 1 = 1.10511 loss)
I0827 09:33:15.023001 10163 sgd_solver.cpp:106] Iteration 50400, lr = 3.89128e-05
I0827 09:33:19.297444 10163 solver.cpp:337] Iteration 50500, Testing net (#0)
I0827 09:33:22.642616 10163 solver.cpp:404]     Test net output #0: accuracy = 0.577958
I0827 09:33:22.642678 10163 solver.cpp:404]     Test net output #1: loss = 1.0909 (* 1 = 1.0909 loss)
I0827 09:33:22.657460 10163 solver.cpp:228] Iteration 50500, loss = 1.10262
I0827 09:33:22.657495 10163 solver.cpp:244]     Train net output #0: loss = 1.10262 (* 1 = 1.10262 loss)
I0827 09:33:22.657507 10163 sgd_solver.cpp:106] Iteration 50500, lr = 3.88714e-05
I0827 09:33:26.979611 10163 solver.cpp:228] Iteration 50600, loss = 1.10328
I0827 09:33:26.979660 10163 solver.cpp:244]     Train net output #0: loss = 1.10328 (* 1 = 1.10328 loss)
I0827 09:33:26.979666 10163 sgd_solver.cpp:106] Iteration 50600, lr = 3.88301e-05
I0827 09:33:31.299787 10163 solver.cpp:228] Iteration 50700, loss = 1.10079
I0827 09:33:31.299803 10163 solver.cpp:244]     Train net output #0: loss = 1.10079 (* 1 = 1.10079 loss)
I0827 09:33:31.299809 10163 sgd_solver.cpp:106] Iteration 50700, lr = 3.87889e-05
I0827 09:33:35.616535 10163 solver.cpp:228] Iteration 50800, loss = 1.09713
I0827 09:33:35.616576 10163 solver.cpp:244]     Train net output #0: loss = 1.09713 (* 1 = 1.09713 loss)
I0827 09:33:35.616582 10163 sgd_solver.cpp:106] Iteration 50800, lr = 3.87478e-05
I0827 09:33:39.937734 10163 solver.cpp:228] Iteration 50900, loss = 1.09873
I0827 09:33:39.937774 10163 solver.cpp:244]     Train net output #0: loss = 1.09873 (* 1 = 1.09873 loss)
I0827 09:33:39.937780 10163 sgd_solver.cpp:106] Iteration 50900, lr = 3.87069e-05
I0827 09:33:44.215668 10163 solver.cpp:337] Iteration 51000, Testing net (#0)
I0827 09:33:47.397984 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578625
I0827 09:33:47.398093 10163 solver.cpp:404]     Test net output #1: loss = 1.09478 (* 1 = 1.09478 loss)
I0827 09:33:47.413470 10163 solver.cpp:228] Iteration 51000, loss = 1.10158
I0827 09:33:47.413537 10163 solver.cpp:244]     Train net output #0: loss = 1.10158 (* 1 = 1.10158 loss)
I0827 09:33:47.413548 10163 sgd_solver.cpp:106] Iteration 51000, lr = 3.8666e-05
I0827 09:33:51.735520 10163 solver.cpp:228] Iteration 51100, loss = 1.10048
I0827 09:33:51.735563 10163 solver.cpp:244]     Train net output #0: loss = 1.10048 (* 1 = 1.10048 loss)
I0827 09:33:51.735568 10163 sgd_solver.cpp:106] Iteration 51100, lr = 3.86252e-05
I0827 09:33:56.054724 10163 solver.cpp:228] Iteration 51200, loss = 1.09808
I0827 09:33:56.054743 10163 solver.cpp:244]     Train net output #0: loss = 1.09808 (* 1 = 1.09808 loss)
I0827 09:33:56.054747 10163 sgd_solver.cpp:106] Iteration 51200, lr = 3.85845e-05
I0827 09:34:00.374541 10163 solver.cpp:228] Iteration 51300, loss = 1.10407
I0827 09:34:00.374599 10163 solver.cpp:244]     Train net output #0: loss = 1.10407 (* 1 = 1.10407 loss)
I0827 09:34:00.374608 10163 sgd_solver.cpp:106] Iteration 51300, lr = 3.85439e-05
I0827 09:34:04.698724 10163 solver.cpp:228] Iteration 51400, loss = 1.09743
I0827 09:34:04.698778 10163 solver.cpp:244]     Train net output #0: loss = 1.09743 (* 1 = 1.09743 loss)
I0827 09:34:04.698786 10163 sgd_solver.cpp:106] Iteration 51400, lr = 3.85034e-05
I0827 09:34:08.984068 10163 solver.cpp:337] Iteration 51500, Testing net (#0)
I0827 09:34:12.551410 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 09:34:12.551477 10163 solver.cpp:404]     Test net output #1: loss = 1.09927 (* 1 = 1.09927 loss)
I0827 09:34:12.566196 10163 solver.cpp:228] Iteration 51500, loss = 1.10253
I0827 09:34:12.566236 10163 solver.cpp:244]     Train net output #0: loss = 1.10253 (* 1 = 1.10253 loss)
I0827 09:34:12.566246 10163 sgd_solver.cpp:106] Iteration 51500, lr = 3.8463e-05
I0827 09:34:16.891399 10163 solver.cpp:228] Iteration 51600, loss = 1.10452
I0827 09:34:16.891435 10163 solver.cpp:244]     Train net output #0: loss = 1.10452 (* 1 = 1.10452 loss)
I0827 09:34:16.891441 10163 sgd_solver.cpp:106] Iteration 51600, lr = 3.84227e-05
I0827 09:34:21.212760 10163 solver.cpp:228] Iteration 51700, loss = 1.11042
I0827 09:34:21.212780 10163 solver.cpp:244]     Train net output #0: loss = 1.11042 (* 1 = 1.11042 loss)
I0827 09:34:21.212785 10163 sgd_solver.cpp:106] Iteration 51700, lr = 3.83825e-05
I0827 09:34:25.531994 10163 solver.cpp:228] Iteration 51800, loss = 1.10151
I0827 09:34:25.532054 10163 solver.cpp:244]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0827 09:34:25.532061 10163 sgd_solver.cpp:106] Iteration 51800, lr = 3.83424e-05
I0827 09:34:29.852237 10163 solver.cpp:228] Iteration 51900, loss = 1.11135
I0827 09:34:29.852301 10163 solver.cpp:244]     Train net output #0: loss = 1.11135 (* 1 = 1.11135 loss)
I0827 09:34:29.852308 10163 sgd_solver.cpp:106] Iteration 51900, lr = 3.83024e-05
I0827 09:34:34.131114 10163 solver.cpp:337] Iteration 52000, Testing net (#0)
I0827 09:34:34.720479 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:34:37.216022 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0827 09:34:37.216094 10163 solver.cpp:404]     Test net output #1: loss = 1.10501 (* 1 = 1.10501 loss)
I0827 09:34:37.230850 10163 solver.cpp:228] Iteration 52000, loss = 1.10129
I0827 09:34:37.230918 10163 solver.cpp:244]     Train net output #0: loss = 1.10129 (* 1 = 1.10129 loss)
I0827 09:34:37.230928 10163 sgd_solver.cpp:106] Iteration 52000, lr = 3.82625e-05
I0827 09:34:41.556241 10163 solver.cpp:228] Iteration 52100, loss = 1.09789
I0827 09:34:41.556304 10163 solver.cpp:244]     Train net output #0: loss = 1.09789 (* 1 = 1.09789 loss)
I0827 09:34:41.556311 10163 sgd_solver.cpp:106] Iteration 52100, lr = 3.82227e-05
I0827 09:34:45.877092 10163 solver.cpp:228] Iteration 52200, loss = 1.09893
I0827 09:34:45.877151 10163 solver.cpp:244]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I0827 09:34:45.877157 10163 sgd_solver.cpp:106] Iteration 52200, lr = 3.8183e-05
I0827 09:34:50.194787 10163 solver.cpp:228] Iteration 52300, loss = 1.1032
I0827 09:34:50.194844 10163 solver.cpp:244]     Train net output #0: loss = 1.1032 (* 1 = 1.1032 loss)
I0827 09:34:50.194850 10163 sgd_solver.cpp:106] Iteration 52300, lr = 3.81433e-05
I0827 09:34:54.514981 10163 solver.cpp:228] Iteration 52400, loss = 1.10675
I0827 09:34:54.515041 10163 solver.cpp:244]     Train net output #0: loss = 1.10675 (* 1 = 1.10675 loss)
I0827 09:34:54.515048 10163 sgd_solver.cpp:106] Iteration 52400, lr = 3.81038e-05
I0827 09:34:58.792073 10163 solver.cpp:337] Iteration 52500, Testing net (#0)
I0827 09:35:02.062052 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0827 09:35:02.062117 10163 solver.cpp:404]     Test net output #1: loss = 1.11066 (* 1 = 1.11066 loss)
I0827 09:35:02.076694 10163 solver.cpp:228] Iteration 52500, loss = 1.09748
I0827 09:35:02.076722 10163 solver.cpp:244]     Train net output #0: loss = 1.09748 (* 1 = 1.09748 loss)
I0827 09:35:02.076730 10163 sgd_solver.cpp:106] Iteration 52500, lr = 3.80644e-05
I0827 09:35:06.393586 10163 solver.cpp:228] Iteration 52600, loss = 1.09872
I0827 09:35:06.393605 10163 solver.cpp:244]     Train net output #0: loss = 1.09872 (* 1 = 1.09872 loss)
I0827 09:35:06.393611 10163 sgd_solver.cpp:106] Iteration 52600, lr = 3.80251e-05
I0827 09:35:10.711632 10163 solver.cpp:228] Iteration 52700, loss = 1.10151
I0827 09:35:10.711688 10163 solver.cpp:244]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0827 09:35:10.711694 10163 sgd_solver.cpp:106] Iteration 52700, lr = 3.79858e-05
I0827 09:35:15.032794 10163 solver.cpp:228] Iteration 52800, loss = 1.10493
I0827 09:35:15.032855 10163 solver.cpp:244]     Train net output #0: loss = 1.10493 (* 1 = 1.10493 loss)
I0827 09:35:15.032860 10163 sgd_solver.cpp:106] Iteration 52800, lr = 3.79467e-05
I0827 09:35:19.354656 10163 solver.cpp:228] Iteration 52900, loss = 1.10126
I0827 09:35:19.354717 10163 solver.cpp:244]     Train net output #0: loss = 1.10126 (* 1 = 1.10126 loss)
I0827 09:35:19.354724 10163 sgd_solver.cpp:106] Iteration 52900, lr = 3.79076e-05
I0827 09:35:23.630939 10163 solver.cpp:337] Iteration 53000, Testing net (#0)
I0827 09:35:26.970649 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0827 09:35:26.970701 10163 solver.cpp:404]     Test net output #1: loss = 1.109 (* 1 = 1.109 loss)
I0827 09:35:26.986033 10163 solver.cpp:228] Iteration 53000, loss = 1.10325
I0827 09:35:26.986104 10163 solver.cpp:244]     Train net output #0: loss = 1.10325 (* 1 = 1.10325 loss)
I0827 09:35:26.986126 10163 sgd_solver.cpp:106] Iteration 53000, lr = 3.78687e-05
I0827 09:35:31.309602 10163 solver.cpp:228] Iteration 53100, loss = 1.09989
I0827 09:35:31.309644 10163 solver.cpp:244]     Train net output #0: loss = 1.09989 (* 1 = 1.09989 loss)
I0827 09:35:31.309650 10163 sgd_solver.cpp:106] Iteration 53100, lr = 3.78298e-05
I0827 09:35:35.630748 10163 solver.cpp:228] Iteration 53200, loss = 1.1001
I0827 09:35:35.630789 10163 solver.cpp:244]     Train net output #0: loss = 1.1001 (* 1 = 1.1001 loss)
I0827 09:35:35.630795 10163 sgd_solver.cpp:106] Iteration 53200, lr = 3.77911e-05
I0827 09:35:39.948447 10163 solver.cpp:228] Iteration 53300, loss = 1.09815
I0827 09:35:39.948468 10163 solver.cpp:244]     Train net output #0: loss = 1.09815 (* 1 = 1.09815 loss)
I0827 09:35:39.948474 10163 sgd_solver.cpp:106] Iteration 53300, lr = 3.77524e-05
I0827 09:35:44.271181 10163 solver.cpp:228] Iteration 53400, loss = 1.10522
I0827 09:35:44.271224 10163 solver.cpp:244]     Train net output #0: loss = 1.10522 (* 1 = 1.10522 loss)
I0827 09:35:44.271230 10163 sgd_solver.cpp:106] Iteration 53400, lr = 3.77138e-05
I0827 09:35:48.546876 10163 solver.cpp:337] Iteration 53500, Testing net (#0)
I0827 09:35:51.816741 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 09:35:51.816783 10163 solver.cpp:404]     Test net output #1: loss = 1.10881 (* 1 = 1.10881 loss)
I0827 09:35:51.831464 10163 solver.cpp:228] Iteration 53500, loss = 1.0995
I0827 09:35:51.831485 10163 solver.cpp:244]     Train net output #0: loss = 1.0995 (* 1 = 1.0995 loss)
I0827 09:35:51.831516 10163 sgd_solver.cpp:106] Iteration 53500, lr = 3.76753e-05
I0827 09:35:56.154243 10163 solver.cpp:228] Iteration 53600, loss = 1.09405
I0827 09:35:56.154285 10163 solver.cpp:244]     Train net output #0: loss = 1.09405 (* 1 = 1.09405 loss)
I0827 09:35:56.154291 10163 sgd_solver.cpp:106] Iteration 53600, lr = 3.76369e-05
I0827 09:36:00.476177 10163 solver.cpp:228] Iteration 53700, loss = 1.10317
I0827 09:36:00.476220 10163 solver.cpp:244]     Train net output #0: loss = 1.10317 (* 1 = 1.10317 loss)
I0827 09:36:00.476227 10163 sgd_solver.cpp:106] Iteration 53700, lr = 3.75986e-05
I0827 09:36:04.803510 10163 solver.cpp:228] Iteration 53800, loss = 1.09283
I0827 09:36:04.803565 10163 solver.cpp:244]     Train net output #0: loss = 1.09283 (* 1 = 1.09283 loss)
I0827 09:36:04.803572 10163 sgd_solver.cpp:106] Iteration 53800, lr = 3.75604e-05
I0827 09:36:09.121917 10163 solver.cpp:228] Iteration 53900, loss = 1.10437
I0827 09:36:09.121937 10163 solver.cpp:244]     Train net output #0: loss = 1.10437 (* 1 = 1.10437 loss)
I0827 09:36:09.121942 10163 sgd_solver.cpp:106] Iteration 53900, lr = 3.75223e-05
I0827 09:36:13.399518 10163 solver.cpp:337] Iteration 54000, Testing net (#0)
I0827 09:36:17.059108 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0827 09:36:17.059166 10163 solver.cpp:404]     Test net output #1: loss = 1.10465 (* 1 = 1.10465 loss)
I0827 09:36:17.074353 10163 solver.cpp:228] Iteration 54000, loss = 1.09821
I0827 09:36:17.074414 10163 solver.cpp:244]     Train net output #0: loss = 1.09821 (* 1 = 1.09821 loss)
I0827 09:36:17.074434 10163 sgd_solver.cpp:106] Iteration 54000, lr = 3.74842e-05
I0827 09:36:21.399132 10163 solver.cpp:228] Iteration 54100, loss = 1.10508
I0827 09:36:21.399171 10163 solver.cpp:244]     Train net output #0: loss = 1.10508 (* 1 = 1.10508 loss)
I0827 09:36:21.399176 10163 sgd_solver.cpp:106] Iteration 54100, lr = 3.74463e-05
I0827 09:36:25.732012 10163 solver.cpp:228] Iteration 54200, loss = 1.09478
I0827 09:36:25.732066 10163 solver.cpp:244]     Train net output #0: loss = 1.09478 (* 1 = 1.09478 loss)
I0827 09:36:25.732074 10163 sgd_solver.cpp:106] Iteration 54200, lr = 3.74084e-05
I0827 09:36:30.050014 10163 solver.cpp:228] Iteration 54300, loss = 1.09946
I0827 09:36:30.050035 10163 solver.cpp:244]     Train net output #0: loss = 1.09946 (* 1 = 1.09946 loss)
I0827 09:36:30.050041 10163 sgd_solver.cpp:106] Iteration 54300, lr = 3.73707e-05
I0827 09:36:34.380409 10163 solver.cpp:228] Iteration 54400, loss = 1.0971
I0827 09:36:34.380450 10163 solver.cpp:244]     Train net output #0: loss = 1.0971 (* 1 = 1.0971 loss)
I0827 09:36:34.380455 10163 sgd_solver.cpp:106] Iteration 54400, lr = 3.7333e-05
I0827 09:36:38.658620 10163 solver.cpp:337] Iteration 54500, Testing net (#0)
I0827 09:36:41.932212 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 09:36:41.932276 10163 solver.cpp:404]     Test net output #1: loss = 1.09652 (* 1 = 1.09652 loss)
I0827 09:36:41.946893 10163 solver.cpp:228] Iteration 54500, loss = 1.10453
I0827 09:36:41.946940 10163 solver.cpp:244]     Train net output #0: loss = 1.10453 (* 1 = 1.10453 loss)
I0827 09:36:41.946952 10163 sgd_solver.cpp:106] Iteration 54500, lr = 3.72954e-05
I0827 09:36:46.270555 10163 solver.cpp:228] Iteration 54600, loss = 1.09349
I0827 09:36:46.270596 10163 solver.cpp:244]     Train net output #0: loss = 1.09349 (* 1 = 1.09349 loss)
I0827 09:36:46.270602 10163 sgd_solver.cpp:106] Iteration 54600, lr = 3.72579e-05
I0827 09:36:50.605160 10163 solver.cpp:228] Iteration 54700, loss = 1.09725
I0827 09:36:50.605201 10163 solver.cpp:244]     Train net output #0: loss = 1.09725 (* 1 = 1.09725 loss)
I0827 09:36:50.605207 10163 sgd_solver.cpp:106] Iteration 54700, lr = 3.72205e-05
I0827 09:36:54.923864 10163 solver.cpp:228] Iteration 54800, loss = 1.10121
I0827 09:36:54.923910 10163 solver.cpp:244]     Train net output #0: loss = 1.10121 (* 1 = 1.10121 loss)
I0827 09:36:54.923916 10163 sgd_solver.cpp:106] Iteration 54800, lr = 3.71832e-05
I0827 09:36:59.243162 10163 solver.cpp:228] Iteration 54900, loss = 1.10435
I0827 09:36:59.243213 10163 solver.cpp:244]     Train net output #0: loss = 1.10435 (* 1 = 1.10435 loss)
I0827 09:36:59.243219 10163 sgd_solver.cpp:106] Iteration 54900, lr = 3.71459e-05
I0827 09:37:03.520413 10163 solver.cpp:337] Iteration 55000, Testing net (#0)
I0827 09:37:03.615309 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:37:07.043987 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:37:07.044049 10163 solver.cpp:404]     Test net output #1: loss = 1.09012 (* 1 = 1.09012 loss)
I0827 09:37:07.061440 10163 solver.cpp:228] Iteration 55000, loss = 1.09666
I0827 09:37:07.061503 10163 solver.cpp:244]     Train net output #0: loss = 1.09666 (* 1 = 1.09666 loss)
I0827 09:37:07.061524 10163 sgd_solver.cpp:106] Iteration 55000, lr = 3.71088e-05
I0827 09:37:11.391625 10163 solver.cpp:228] Iteration 55100, loss = 1.09617
I0827 09:37:11.391682 10163 solver.cpp:244]     Train net output #0: loss = 1.09617 (* 1 = 1.09617 loss)
I0827 09:37:11.391691 10163 sgd_solver.cpp:106] Iteration 55100, lr = 3.70717e-05
I0827 09:37:15.717032 10163 solver.cpp:228] Iteration 55200, loss = 1.10687
I0827 09:37:15.717074 10163 solver.cpp:244]     Train net output #0: loss = 1.10687 (* 1 = 1.10687 loss)
I0827 09:37:15.717080 10163 sgd_solver.cpp:106] Iteration 55200, lr = 3.70347e-05
I0827 09:37:20.036887 10163 solver.cpp:228] Iteration 55300, loss = 1.10296
I0827 09:37:20.036907 10163 solver.cpp:244]     Train net output #0: loss = 1.10296 (* 1 = 1.10296 loss)
I0827 09:37:20.036912 10163 sgd_solver.cpp:106] Iteration 55300, lr = 3.69978e-05
I0827 09:37:24.359748 10163 solver.cpp:228] Iteration 55400, loss = 1.10426
I0827 09:37:24.359768 10163 solver.cpp:244]     Train net output #0: loss = 1.10426 (* 1 = 1.10426 loss)
I0827 09:37:24.359773 10163 sgd_solver.cpp:106] Iteration 55400, lr = 3.6961e-05
I0827 09:37:28.638180 10163 solver.cpp:337] Iteration 55500, Testing net (#0)
I0827 09:37:32.034963 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 09:37:32.035037 10163 solver.cpp:404]     Test net output #1: loss = 1.08641 (* 1 = 1.08641 loss)
I0827 09:37:32.050248 10163 solver.cpp:228] Iteration 55500, loss = 1.10112
I0827 09:37:32.050309 10163 solver.cpp:244]     Train net output #0: loss = 1.10112 (* 1 = 1.10112 loss)
I0827 09:37:32.050325 10163 sgd_solver.cpp:106] Iteration 55500, lr = 3.69243e-05
I0827 09:37:36.378711 10163 solver.cpp:228] Iteration 55600, loss = 1.10148
I0827 09:37:36.378774 10163 solver.cpp:244]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0827 09:37:36.378783 10163 sgd_solver.cpp:106] Iteration 55600, lr = 3.68877e-05
I0827 09:37:40.702520 10163 solver.cpp:228] Iteration 55700, loss = 1.09483
I0827 09:37:40.702571 10163 solver.cpp:244]     Train net output #0: loss = 1.09483 (* 1 = 1.09483 loss)
I0827 09:37:40.702579 10163 sgd_solver.cpp:106] Iteration 55700, lr = 3.68511e-05
I0827 09:37:45.024031 10163 solver.cpp:228] Iteration 55800, loss = 1.09608
I0827 09:37:45.024051 10163 solver.cpp:244]     Train net output #0: loss = 1.09608 (* 1 = 1.09608 loss)
I0827 09:37:45.024056 10163 sgd_solver.cpp:106] Iteration 55800, lr = 3.68146e-05
I0827 09:37:49.348037 10163 solver.cpp:228] Iteration 55900, loss = 1.10234
I0827 09:37:49.348067 10163 solver.cpp:244]     Train net output #0: loss = 1.10234 (* 1 = 1.10234 loss)
I0827 09:37:49.348072 10163 sgd_solver.cpp:106] Iteration 55900, lr = 3.67783e-05
I0827 09:37:53.628813 10163 solver.cpp:337] Iteration 56000, Testing net (#0)
I0827 09:37:57.238412 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578542
I0827 09:37:57.238462 10163 solver.cpp:404]     Test net output #1: loss = 1.08711 (* 1 = 1.08711 loss)
I0827 09:37:57.253242 10163 solver.cpp:228] Iteration 56000, loss = 1.10366
I0827 09:37:57.253279 10163 solver.cpp:244]     Train net output #0: loss = 1.10366 (* 1 = 1.10366 loss)
I0827 09:37:57.253289 10163 sgd_solver.cpp:106] Iteration 56000, lr = 3.6742e-05
I0827 09:38:01.570466 10163 solver.cpp:228] Iteration 56100, loss = 1.09929
I0827 09:38:01.570530 10163 solver.cpp:244]     Train net output #0: loss = 1.09929 (* 1 = 1.09929 loss)
I0827 09:38:01.570536 10163 sgd_solver.cpp:106] Iteration 56100, lr = 3.67057e-05
I0827 09:38:05.891541 10163 solver.cpp:228] Iteration 56200, loss = 1.0935
I0827 09:38:05.891582 10163 solver.cpp:244]     Train net output #0: loss = 1.0935 (* 1 = 1.0935 loss)
I0827 09:38:05.891587 10163 sgd_solver.cpp:106] Iteration 56200, lr = 3.66696e-05
I0827 09:38:10.206315 10163 solver.cpp:228] Iteration 56300, loss = 1.10143
I0827 09:38:10.206357 10163 solver.cpp:244]     Train net output #0: loss = 1.10143 (* 1 = 1.10143 loss)
I0827 09:38:10.206362 10163 sgd_solver.cpp:106] Iteration 56300, lr = 3.66336e-05
I0827 09:38:14.523746 10163 solver.cpp:228] Iteration 56400, loss = 1.09099
I0827 09:38:14.523799 10163 solver.cpp:244]     Train net output #0: loss = 1.09099 (* 1 = 1.09099 loss)
I0827 09:38:14.523807 10163 sgd_solver.cpp:106] Iteration 56400, lr = 3.65976e-05
I0827 09:38:18.832870 10163 solver.cpp:337] Iteration 56500, Testing net (#0)
I0827 09:38:22.124783 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578125
I0827 09:38:22.124824 10163 solver.cpp:404]     Test net output #1: loss = 1.09089 (* 1 = 1.09089 loss)
I0827 09:38:22.141496 10163 solver.cpp:228] Iteration 56500, loss = 1.10771
I0827 09:38:22.141563 10163 solver.cpp:244]     Train net output #0: loss = 1.10771 (* 1 = 1.10771 loss)
I0827 09:38:22.141579 10163 sgd_solver.cpp:106] Iteration 56500, lr = 3.65617e-05
I0827 09:38:26.461545 10163 solver.cpp:228] Iteration 56600, loss = 1.10531
I0827 09:38:26.461606 10163 solver.cpp:244]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0827 09:38:26.461612 10163 sgd_solver.cpp:106] Iteration 56600, lr = 3.65259e-05
I0827 09:38:30.788215 10163 solver.cpp:228] Iteration 56700, loss = 1.09955
I0827 09:38:30.788276 10163 solver.cpp:244]     Train net output #0: loss = 1.09955 (* 1 = 1.09955 loss)
I0827 09:38:30.788283 10163 sgd_solver.cpp:106] Iteration 56700, lr = 3.64902e-05
I0827 09:38:35.110307 10163 solver.cpp:228] Iteration 56800, loss = 1.10126
I0827 09:38:35.110369 10163 solver.cpp:244]     Train net output #0: loss = 1.10126 (* 1 = 1.10126 loss)
I0827 09:38:35.110376 10163 sgd_solver.cpp:106] Iteration 56800, lr = 3.64545e-05
I0827 09:38:39.439548 10163 solver.cpp:228] Iteration 56900, loss = 1.10186
I0827 09:38:39.439589 10163 solver.cpp:244]     Train net output #0: loss = 1.10186 (* 1 = 1.10186 loss)
I0827 09:38:39.439595 10163 sgd_solver.cpp:106] Iteration 56900, lr = 3.6419e-05
I0827 09:38:43.725718 10163 solver.cpp:337] Iteration 57000, Testing net (#0)
I0827 09:38:46.771035 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578458
I0827 09:38:46.771098 10163 solver.cpp:404]     Test net output #1: loss = 1.09223 (* 1 = 1.09223 loss)
I0827 09:38:46.786383 10163 solver.cpp:228] Iteration 57000, loss = 1.10534
I0827 09:38:46.786445 10163 solver.cpp:244]     Train net output #0: loss = 1.10534 (* 1 = 1.10534 loss)
I0827 09:38:46.786459 10163 sgd_solver.cpp:106] Iteration 57000, lr = 3.63835e-05
I0827 09:38:51.115939 10163 solver.cpp:228] Iteration 57100, loss = 1.0987
I0827 09:38:51.116001 10163 solver.cpp:244]     Train net output #0: loss = 1.0987 (* 1 = 1.0987 loss)
I0827 09:38:51.116008 10163 sgd_solver.cpp:106] Iteration 57100, lr = 3.63481e-05
I0827 09:38:55.227726 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:38:55.443778 10163 solver.cpp:228] Iteration 57200, loss = 1.10098
I0827 09:38:55.443833 10163 solver.cpp:244]     Train net output #0: loss = 1.10098 (* 1 = 1.10098 loss)
I0827 09:38:55.443840 10163 sgd_solver.cpp:106] Iteration 57200, lr = 3.63128e-05
I0827 09:38:59.774664 10163 solver.cpp:228] Iteration 57300, loss = 1.0915
I0827 09:38:59.774721 10163 solver.cpp:244]     Train net output #0: loss = 1.0915 (* 1 = 1.0915 loss)
I0827 09:38:59.774727 10163 sgd_solver.cpp:106] Iteration 57300, lr = 3.62775e-05
I0827 09:39:04.103797 10163 solver.cpp:228] Iteration 57400, loss = 1.101
I0827 09:39:04.103852 10163 solver.cpp:244]     Train net output #0: loss = 1.101 (* 1 = 1.101 loss)
I0827 09:39:04.103859 10163 sgd_solver.cpp:106] Iteration 57400, lr = 3.62424e-05
I0827 09:39:08.388377 10163 solver.cpp:337] Iteration 57500, Testing net (#0)
I0827 09:39:12.492241 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578667
I0827 09:39:12.492293 10163 solver.cpp:404]     Test net output #1: loss = 1.09337 (* 1 = 1.09337 loss)
I0827 09:39:12.507030 10163 solver.cpp:228] Iteration 57500, loss = 1.10026
I0827 09:39:12.507067 10163 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0827 09:39:12.507077 10163 sgd_solver.cpp:106] Iteration 57500, lr = 3.62073e-05
I0827 09:39:16.830968 10163 solver.cpp:228] Iteration 57600, loss = 1.09908
I0827 09:39:16.831007 10163 solver.cpp:244]     Train net output #0: loss = 1.09908 (* 1 = 1.09908 loss)
I0827 09:39:16.831012 10163 sgd_solver.cpp:106] Iteration 57600, lr = 3.61723e-05
I0827 09:39:21.152680 10163 solver.cpp:228] Iteration 57700, loss = 1.09972
I0827 09:39:21.152721 10163 solver.cpp:244]     Train net output #0: loss = 1.09972 (* 1 = 1.09972 loss)
I0827 09:39:21.152727 10163 sgd_solver.cpp:106] Iteration 57700, lr = 3.61374e-05
I0827 09:39:25.470898 10163 solver.cpp:228] Iteration 57800, loss = 1.10051
I0827 09:39:25.470919 10163 solver.cpp:244]     Train net output #0: loss = 1.10051 (* 1 = 1.10051 loss)
I0827 09:39:25.470924 10163 sgd_solver.cpp:106] Iteration 57800, lr = 3.61025e-05
I0827 09:39:29.793642 10163 solver.cpp:228] Iteration 57900, loss = 1.09046
I0827 09:39:29.793683 10163 solver.cpp:244]     Train net output #0: loss = 1.09046 (* 1 = 1.09046 loss)
I0827 09:39:29.793689 10163 sgd_solver.cpp:106] Iteration 57900, lr = 3.60678e-05
I0827 09:39:34.068135 10163 solver.cpp:337] Iteration 58000, Testing net (#0)
I0827 09:39:37.223284 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0827 09:39:37.223345 10163 solver.cpp:404]     Test net output #1: loss = 1.09507 (* 1 = 1.09507 loss)
I0827 09:39:37.238037 10163 solver.cpp:228] Iteration 58000, loss = 1.09984
I0827 09:39:37.238055 10163 solver.cpp:244]     Train net output #0: loss = 1.09984 (* 1 = 1.09984 loss)
I0827 09:39:37.238066 10163 sgd_solver.cpp:106] Iteration 58000, lr = 3.60331e-05
I0827 09:39:41.572490 10163 solver.cpp:228] Iteration 58100, loss = 1.10165
I0827 09:39:41.572551 10163 solver.cpp:244]     Train net output #0: loss = 1.10165 (* 1 = 1.10165 loss)
I0827 09:39:41.572558 10163 sgd_solver.cpp:106] Iteration 58100, lr = 3.59985e-05
I0827 09:39:45.893846 10163 solver.cpp:228] Iteration 58200, loss = 1.10287
I0827 09:39:45.893901 10163 solver.cpp:244]     Train net output #0: loss = 1.10287 (* 1 = 1.10287 loss)
I0827 09:39:45.893910 10163 sgd_solver.cpp:106] Iteration 58200, lr = 3.5964e-05
I0827 09:39:50.213044 10163 solver.cpp:228] Iteration 58300, loss = 1.10104
I0827 09:39:50.213102 10163 solver.cpp:244]     Train net output #0: loss = 1.10104 (* 1 = 1.10104 loss)
I0827 09:39:50.213109 10163 sgd_solver.cpp:106] Iteration 58300, lr = 3.59295e-05
I0827 09:39:54.541478 10163 solver.cpp:228] Iteration 58400, loss = 1.10342
I0827 09:39:54.541519 10163 solver.cpp:244]     Train net output #0: loss = 1.10342 (* 1 = 1.10342 loss)
I0827 09:39:54.541525 10163 sgd_solver.cpp:106] Iteration 58400, lr = 3.58951e-05
I0827 09:39:58.818485 10163 solver.cpp:337] Iteration 58500, Testing net (#0)
I0827 09:40:02.213392 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:40:02.213459 10163 solver.cpp:404]     Test net output #1: loss = 1.09704 (* 1 = 1.09704 loss)
I0827 09:40:02.228857 10163 solver.cpp:228] Iteration 58500, loss = 1.10666
I0827 09:40:02.228931 10163 solver.cpp:244]     Train net output #0: loss = 1.10666 (* 1 = 1.10666 loss)
I0827 09:40:02.228948 10163 sgd_solver.cpp:106] Iteration 58500, lr = 3.58608e-05
I0827 09:40:06.556655 10163 solver.cpp:228] Iteration 58600, loss = 1.10438
I0827 09:40:06.556716 10163 solver.cpp:244]     Train net output #0: loss = 1.10438 (* 1 = 1.10438 loss)
I0827 09:40:06.556722 10163 sgd_solver.cpp:106] Iteration 58600, lr = 3.58266e-05
I0827 09:40:10.886564 10163 solver.cpp:228] Iteration 58700, loss = 1.10058
I0827 09:40:10.886605 10163 solver.cpp:244]     Train net output #0: loss = 1.10058 (* 1 = 1.10058 loss)
I0827 09:40:10.886610 10163 sgd_solver.cpp:106] Iteration 58700, lr = 3.57925e-05
I0827 09:40:15.205061 10163 solver.cpp:228] Iteration 58800, loss = 1.10117
I0827 09:40:15.205122 10163 solver.cpp:244]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0827 09:40:15.205128 10163 sgd_solver.cpp:106] Iteration 58800, lr = 3.57584e-05
I0827 09:40:19.525459 10163 solver.cpp:228] Iteration 58900, loss = 1.09729
I0827 09:40:19.525499 10163 solver.cpp:244]     Train net output #0: loss = 1.09729 (* 1 = 1.09729 loss)
I0827 09:40:19.525506 10163 sgd_solver.cpp:106] Iteration 58900, lr = 3.57244e-05
I0827 09:40:23.804093 10163 solver.cpp:337] Iteration 59000, Testing net (#0)
I0827 09:40:26.898977 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578542
I0827 09:40:26.899078 10163 solver.cpp:404]     Test net output #1: loss = 1.096 (* 1 = 1.096 loss)
I0827 09:40:26.916532 10163 solver.cpp:228] Iteration 59000, loss = 1.10399
I0827 09:40:26.916601 10163 solver.cpp:244]     Train net output #0: loss = 1.10399 (* 1 = 1.10399 loss)
I0827 09:40:26.916616 10163 sgd_solver.cpp:106] Iteration 59000, lr = 3.56905e-05
I0827 09:40:31.237079 10163 solver.cpp:228] Iteration 59100, loss = 1.10042
I0827 09:40:31.237143 10163 solver.cpp:244]     Train net output #0: loss = 1.10042 (* 1 = 1.10042 loss)
I0827 09:40:31.237150 10163 sgd_solver.cpp:106] Iteration 59100, lr = 3.56566e-05
I0827 09:40:35.557198 10163 solver.cpp:228] Iteration 59200, loss = 1.09585
I0827 09:40:35.557260 10163 solver.cpp:244]     Train net output #0: loss = 1.09585 (* 1 = 1.09585 loss)
I0827 09:40:35.557265 10163 sgd_solver.cpp:106] Iteration 59200, lr = 3.56228e-05
I0827 09:40:39.881012 10163 solver.cpp:228] Iteration 59300, loss = 1.09982
I0827 09:40:39.881073 10163 solver.cpp:244]     Train net output #0: loss = 1.09982 (* 1 = 1.09982 loss)
I0827 09:40:39.881079 10163 sgd_solver.cpp:106] Iteration 59300, lr = 3.55891e-05
I0827 09:40:44.201436 10163 solver.cpp:228] Iteration 59400, loss = 1.10343
I0827 09:40:44.201496 10163 solver.cpp:244]     Train net output #0: loss = 1.10343 (* 1 = 1.10343 loss)
I0827 09:40:44.201503 10163 sgd_solver.cpp:106] Iteration 59400, lr = 3.55555e-05
I0827 09:40:48.477444 10163 solver.cpp:337] Iteration 59500, Testing net (#0)
I0827 09:40:51.666219 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:40:51.666277 10163 solver.cpp:404]     Test net output #1: loss = 1.09678 (* 1 = 1.09678 loss)
I0827 09:40:51.680619 10163 solver.cpp:228] Iteration 59500, loss = 1.09654
I0827 09:40:51.680666 10163 solver.cpp:244]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0827 09:40:51.680677 10163 sgd_solver.cpp:106] Iteration 59500, lr = 3.5522e-05
I0827 09:40:56.004642 10163 solver.cpp:228] Iteration 59600, loss = 1.10561
I0827 09:40:56.004688 10163 solver.cpp:244]     Train net output #0: loss = 1.10561 (* 1 = 1.10561 loss)
I0827 09:40:56.004693 10163 sgd_solver.cpp:106] Iteration 59600, lr = 3.54885e-05
I0827 09:41:00.324705 10163 solver.cpp:228] Iteration 59700, loss = 1.0948
I0827 09:41:00.324755 10163 solver.cpp:244]     Train net output #0: loss = 1.0948 (* 1 = 1.0948 loss)
I0827 09:41:00.324762 10163 sgd_solver.cpp:106] Iteration 59700, lr = 3.54551e-05
I0827 09:41:04.645853 10163 solver.cpp:228] Iteration 59800, loss = 1.10234
I0827 09:41:04.645903 10163 solver.cpp:244]     Train net output #0: loss = 1.10234 (* 1 = 1.10234 loss)
I0827 09:41:04.645910 10163 sgd_solver.cpp:106] Iteration 59800, lr = 3.54218e-05
I0827 09:41:08.973038 10163 solver.cpp:228] Iteration 59900, loss = 1.10519
I0827 09:41:08.973088 10163 solver.cpp:244]     Train net output #0: loss = 1.10519 (* 1 = 1.10519 loss)
I0827 09:41:08.973095 10163 sgd_solver.cpp:106] Iteration 59900, lr = 3.53885e-05
I0827 09:41:13.246619 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_60000.caffemodel
I0827 09:41:13.724388 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_60000.solverstate
I0827 09:41:13.879986 10163 solver.cpp:337] Iteration 60000, Testing net (#0)
I0827 09:41:14.120610 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:41:17.250773 10163 solver.cpp:404]     Test net output #0: accuracy = 0.268792
I0827 09:41:17.250828 10163 solver.cpp:404]     Test net output #1: loss = 1.09343 (* 1 = 1.09343 loss)
I0827 09:41:17.266414 10163 solver.cpp:228] Iteration 60000, loss = 1.09963
I0827 09:41:17.266446 10163 solver.cpp:244]     Train net output #0: loss = 1.09963 (* 1 = 1.09963 loss)
I0827 09:41:17.266458 10163 sgd_solver.cpp:106] Iteration 60000, lr = 3.53553e-05
I0827 09:41:21.593123 10163 solver.cpp:228] Iteration 60100, loss = 1.09568
I0827 09:41:21.593180 10163 solver.cpp:244]     Train net output #0: loss = 1.09568 (* 1 = 1.09568 loss)
I0827 09:41:21.593192 10163 sgd_solver.cpp:106] Iteration 60100, lr = 3.53222e-05
I0827 09:41:25.914965 10163 solver.cpp:228] Iteration 60200, loss = 1.10108
I0827 09:41:25.915012 10163 solver.cpp:244]     Train net output #0: loss = 1.10108 (* 1 = 1.10108 loss)
I0827 09:41:25.915019 10163 sgd_solver.cpp:106] Iteration 60200, lr = 3.52892e-05
I0827 09:41:30.247057 10163 solver.cpp:228] Iteration 60300, loss = 1.09958
I0827 09:41:30.247102 10163 solver.cpp:244]     Train net output #0: loss = 1.09958 (* 1 = 1.09958 loss)
I0827 09:41:30.247107 10163 sgd_solver.cpp:106] Iteration 60300, lr = 3.52562e-05
I0827 09:41:34.566701 10163 solver.cpp:228] Iteration 60400, loss = 1.09492
I0827 09:41:34.566743 10163 solver.cpp:244]     Train net output #0: loss = 1.09492 (* 1 = 1.09492 loss)
I0827 09:41:34.566750 10163 sgd_solver.cpp:106] Iteration 60400, lr = 3.52233e-05
I0827 09:41:38.842713 10163 solver.cpp:337] Iteration 60500, Testing net (#0)
I0827 09:41:41.971554 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269375
I0827 09:41:41.971604 10163 solver.cpp:404]     Test net output #1: loss = 1.09421 (* 1 = 1.09421 loss)
I0827 09:41:41.989089 10163 solver.cpp:228] Iteration 60500, loss = 1.09718
I0827 09:41:41.989148 10163 solver.cpp:244]     Train net output #0: loss = 1.09718 (* 1 = 1.09718 loss)
I0827 09:41:41.989164 10163 sgd_solver.cpp:106] Iteration 60500, lr = 3.51905e-05
I0827 09:41:46.310632 10163 solver.cpp:228] Iteration 60600, loss = 1.10407
I0827 09:41:46.310679 10163 solver.cpp:244]     Train net output #0: loss = 1.10407 (* 1 = 1.10407 loss)
I0827 09:41:46.310684 10163 sgd_solver.cpp:106] Iteration 60600, lr = 3.51578e-05
I0827 09:41:50.634898 10163 solver.cpp:228] Iteration 60700, loss = 1.10587
I0827 09:41:50.634951 10163 solver.cpp:244]     Train net output #0: loss = 1.10587 (* 1 = 1.10587 loss)
I0827 09:41:50.634959 10163 sgd_solver.cpp:106] Iteration 60700, lr = 3.51251e-05
I0827 09:41:54.955756 10163 solver.cpp:228] Iteration 60800, loss = 1.09866
I0827 09:41:54.955776 10163 solver.cpp:244]     Train net output #0: loss = 1.09866 (* 1 = 1.09866 loss)
I0827 09:41:54.955782 10163 sgd_solver.cpp:106] Iteration 60800, lr = 3.50925e-05
I0827 09:41:59.281080 10163 solver.cpp:228] Iteration 60900, loss = 1.10661
I0827 09:41:59.281122 10163 solver.cpp:244]     Train net output #0: loss = 1.10661 (* 1 = 1.10661 loss)
I0827 09:41:59.281128 10163 sgd_solver.cpp:106] Iteration 60900, lr = 3.50599e-05
I0827 09:42:03.559855 10163 solver.cpp:337] Iteration 61000, Testing net (#0)
I0827 09:42:06.726450 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 09:42:06.726573 10163 solver.cpp:404]     Test net output #1: loss = 1.09578 (* 1 = 1.09578 loss)
I0827 09:42:06.741780 10163 solver.cpp:228] Iteration 61000, loss = 1.11343
I0827 09:42:06.741839 10163 solver.cpp:244]     Train net output #0: loss = 1.11343 (* 1 = 1.11343 loss)
I0827 09:42:06.741852 10163 sgd_solver.cpp:106] Iteration 61000, lr = 3.50275e-05
I0827 09:42:11.068742 10163 solver.cpp:228] Iteration 61100, loss = 1.10017
I0827 09:42:11.068827 10163 solver.cpp:244]     Train net output #0: loss = 1.10017 (* 1 = 1.10017 loss)
I0827 09:42:11.068840 10163 sgd_solver.cpp:106] Iteration 61100, lr = 3.49951e-05
I0827 09:42:15.389297 10163 solver.cpp:228] Iteration 61200, loss = 1.0962
I0827 09:42:15.389335 10163 solver.cpp:244]     Train net output #0: loss = 1.0962 (* 1 = 1.0962 loss)
I0827 09:42:15.389341 10163 sgd_solver.cpp:106] Iteration 61200, lr = 3.49627e-05
I0827 09:42:19.708050 10163 solver.cpp:228] Iteration 61300, loss = 1.10376
I0827 09:42:19.708092 10163 solver.cpp:244]     Train net output #0: loss = 1.10376 (* 1 = 1.10376 loss)
I0827 09:42:19.708098 10163 sgd_solver.cpp:106] Iteration 61300, lr = 3.49305e-05
I0827 09:42:24.029665 10163 solver.cpp:228] Iteration 61400, loss = 1.09939
I0827 09:42:24.029707 10163 solver.cpp:244]     Train net output #0: loss = 1.09939 (* 1 = 1.09939 loss)
I0827 09:42:24.029714 10163 sgd_solver.cpp:106] Iteration 61400, lr = 3.48983e-05
I0827 09:42:28.305836 10163 solver.cpp:337] Iteration 61500, Testing net (#0)
I0827 09:42:31.450017 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 09:42:31.450083 10163 solver.cpp:404]     Test net output #1: loss = 1.09994 (* 1 = 1.09994 loss)
I0827 09:42:31.465034 10163 solver.cpp:228] Iteration 61500, loss = 1.09196
I0827 09:42:31.465080 10163 solver.cpp:244]     Train net output #0: loss = 1.09196 (* 1 = 1.09196 loss)
I0827 09:42:31.465091 10163 sgd_solver.cpp:106] Iteration 61500, lr = 3.48662e-05
I0827 09:42:35.784556 10163 solver.cpp:228] Iteration 61600, loss = 1.09731
I0827 09:42:35.784600 10163 solver.cpp:244]     Train net output #0: loss = 1.09731 (* 1 = 1.09731 loss)
I0827 09:42:35.784605 10163 sgd_solver.cpp:106] Iteration 61600, lr = 3.48341e-05
I0827 09:42:40.102427 10163 solver.cpp:228] Iteration 61700, loss = 1.09871
I0827 09:42:40.102468 10163 solver.cpp:244]     Train net output #0: loss = 1.09871 (* 1 = 1.09871 loss)
I0827 09:42:40.102474 10163 sgd_solver.cpp:106] Iteration 61700, lr = 3.48021e-05
I0827 09:42:44.422060 10163 solver.cpp:228] Iteration 61800, loss = 1.10141
I0827 09:42:44.422099 10163 solver.cpp:244]     Train net output #0: loss = 1.10141 (* 1 = 1.10141 loss)
I0827 09:42:44.422106 10163 sgd_solver.cpp:106] Iteration 61800, lr = 3.47702e-05
I0827 09:42:48.742246 10163 solver.cpp:228] Iteration 61900, loss = 1.10358
I0827 09:42:48.742296 10163 solver.cpp:244]     Train net output #0: loss = 1.10358 (* 1 = 1.10358 loss)
I0827 09:42:48.742301 10163 sgd_solver.cpp:106] Iteration 61900, lr = 3.47384e-05
I0827 09:42:53.020982 10163 solver.cpp:337] Iteration 62000, Testing net (#0)
I0827 09:42:56.463433 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269
I0827 09:42:56.463490 10163 solver.cpp:404]     Test net output #1: loss = 1.10399 (* 1 = 1.10399 loss)
I0827 09:42:56.478484 10163 solver.cpp:228] Iteration 62000, loss = 1.10298
I0827 09:42:56.478521 10163 solver.cpp:244]     Train net output #0: loss = 1.10298 (* 1 = 1.10298 loss)
I0827 09:42:56.478531 10163 sgd_solver.cpp:106] Iteration 62000, lr = 3.47066e-05
I0827 09:43:00.802796 10163 solver.cpp:228] Iteration 62100, loss = 1.10237
I0827 09:43:00.802837 10163 solver.cpp:244]     Train net output #0: loss = 1.10237 (* 1 = 1.10237 loss)
I0827 09:43:00.802844 10163 sgd_solver.cpp:106] Iteration 62100, lr = 3.46749e-05
I0827 09:43:05.127583 10163 solver.cpp:228] Iteration 62200, loss = 1.09871
I0827 09:43:05.127624 10163 solver.cpp:244]     Train net output #0: loss = 1.09871 (* 1 = 1.09871 loss)
I0827 09:43:05.127629 10163 sgd_solver.cpp:106] Iteration 62200, lr = 3.46433e-05
I0827 09:43:09.447322 10163 solver.cpp:228] Iteration 62300, loss = 1.10369
I0827 09:43:09.447365 10163 solver.cpp:244]     Train net output #0: loss = 1.10369 (* 1 = 1.10369 loss)
I0827 09:43:09.447371 10163 sgd_solver.cpp:106] Iteration 62300, lr = 3.46117e-05
I0827 09:43:13.769048 10163 solver.cpp:228] Iteration 62400, loss = 1.10251
I0827 09:43:13.769068 10163 solver.cpp:244]     Train net output #0: loss = 1.10251 (* 1 = 1.10251 loss)
I0827 09:43:13.769073 10163 sgd_solver.cpp:106] Iteration 62400, lr = 3.45802e-05
I0827 09:43:18.044358 10163 solver.cpp:337] Iteration 62500, Testing net (#0)
I0827 09:43:21.198853 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 09:43:21.198914 10163 solver.cpp:404]     Test net output #1: loss = 1.10621 (* 1 = 1.10621 loss)
I0827 09:43:21.214334 10163 solver.cpp:228] Iteration 62500, loss = 1.10207
I0827 09:43:21.214408 10163 solver.cpp:244]     Train net output #0: loss = 1.10207 (* 1 = 1.10207 loss)
I0827 09:43:21.214424 10163 sgd_solver.cpp:106] Iteration 62500, lr = 3.45487e-05
I0827 09:43:25.537081 10163 solver.cpp:228] Iteration 62600, loss = 1.09824
I0827 09:43:25.537127 10163 solver.cpp:244]     Train net output #0: loss = 1.09824 (* 1 = 1.09824 loss)
I0827 09:43:25.537132 10163 sgd_solver.cpp:106] Iteration 62600, lr = 3.45174e-05
I0827 09:43:29.855919 10163 solver.cpp:228] Iteration 62700, loss = 1.10086
I0827 09:43:29.855983 10163 solver.cpp:244]     Train net output #0: loss = 1.10086 (* 1 = 1.10086 loss)
I0827 09:43:29.855988 10163 sgd_solver.cpp:106] Iteration 62700, lr = 3.4486e-05
I0827 09:43:34.185380 10163 solver.cpp:228] Iteration 62800, loss = 1.10432
I0827 09:43:34.185441 10163 solver.cpp:244]     Train net output #0: loss = 1.10432 (* 1 = 1.10432 loss)
I0827 09:43:34.185452 10163 sgd_solver.cpp:106] Iteration 62800, lr = 3.44548e-05
I0827 09:43:38.509438 10163 solver.cpp:228] Iteration 62900, loss = 1.10477
I0827 09:43:38.509495 10163 solver.cpp:244]     Train net output #0: loss = 1.10477 (* 1 = 1.10477 loss)
I0827 09:43:38.509501 10163 sgd_solver.cpp:106] Iteration 62900, lr = 3.44236e-05
I0827 09:43:42.788691 10163 solver.cpp:337] Iteration 63000, Testing net (#0)
I0827 09:43:46.218857 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 09:43:46.218909 10163 solver.cpp:404]     Test net output #1: loss = 1.10554 (* 1 = 1.10554 loss)
I0827 09:43:46.234184 10163 solver.cpp:228] Iteration 63000, loss = 1.10702
I0827 09:43:46.234246 10163 solver.cpp:244]     Train net output #0: loss = 1.10702 (* 1 = 1.10702 loss)
I0827 09:43:46.234262 10163 sgd_solver.cpp:106] Iteration 63000, lr = 3.43925e-05
I0827 09:43:50.558639 10163 solver.cpp:228] Iteration 63100, loss = 1.10209
I0827 09:43:50.558702 10163 solver.cpp:244]     Train net output #0: loss = 1.10209 (* 1 = 1.10209 loss)
I0827 09:43:50.558709 10163 sgd_solver.cpp:106] Iteration 63100, lr = 3.43615e-05
I0827 09:43:54.879495 10163 solver.cpp:228] Iteration 63200, loss = 1.107
I0827 09:43:54.879556 10163 solver.cpp:244]     Train net output #0: loss = 1.107 (* 1 = 1.107 loss)
I0827 09:43:54.879562 10163 sgd_solver.cpp:106] Iteration 63200, lr = 3.43305e-05
I0827 09:43:56.260035 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:43:59.196210 10163 solver.cpp:228] Iteration 63300, loss = 1.09844
I0827 09:43:59.196256 10163 solver.cpp:244]     Train net output #0: loss = 1.09844 (* 1 = 1.09844 loss)
I0827 09:43:59.196262 10163 sgd_solver.cpp:106] Iteration 63300, lr = 3.42996e-05
I0827 09:44:03.511533 10163 solver.cpp:228] Iteration 63400, loss = 1.10207
I0827 09:44:03.511597 10163 solver.cpp:244]     Train net output #0: loss = 1.10207 (* 1 = 1.10207 loss)
I0827 09:44:03.511603 10163 sgd_solver.cpp:106] Iteration 63400, lr = 3.42687e-05
I0827 09:44:07.789666 10163 solver.cpp:337] Iteration 63500, Testing net (#0)
I0827 09:44:11.196743 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269083
I0827 09:44:11.196801 10163 solver.cpp:404]     Test net output #1: loss = 1.10397 (* 1 = 1.10397 loss)
I0827 09:44:11.212239 10163 solver.cpp:228] Iteration 63500, loss = 1.08935
I0827 09:44:11.212296 10163 solver.cpp:244]     Train net output #0: loss = 1.08935 (* 1 = 1.08935 loss)
I0827 09:44:11.212307 10163 sgd_solver.cpp:106] Iteration 63500, lr = 3.42379e-05
I0827 09:44:15.539026 10163 solver.cpp:228] Iteration 63600, loss = 1.10215
I0827 09:44:15.539075 10163 solver.cpp:244]     Train net output #0: loss = 1.10215 (* 1 = 1.10215 loss)
I0827 09:44:15.539083 10163 sgd_solver.cpp:106] Iteration 63600, lr = 3.42072e-05
I0827 09:44:19.861443 10163 solver.cpp:228] Iteration 63700, loss = 1.09975
I0827 09:44:19.861470 10163 solver.cpp:244]     Train net output #0: loss = 1.09975 (* 1 = 1.09975 loss)
I0827 09:44:19.861479 10163 sgd_solver.cpp:106] Iteration 63700, lr = 3.41766e-05
I0827 09:44:24.196043 10163 solver.cpp:228] Iteration 63800, loss = 1.09833
I0827 09:44:24.196104 10163 solver.cpp:244]     Train net output #0: loss = 1.09833 (* 1 = 1.09833 loss)
I0827 09:44:24.196111 10163 sgd_solver.cpp:106] Iteration 63800, lr = 3.4146e-05
I0827 09:44:28.518497 10163 solver.cpp:228] Iteration 63900, loss = 1.10403
I0827 09:44:28.518548 10163 solver.cpp:244]     Train net output #0: loss = 1.10403 (* 1 = 1.10403 loss)
I0827 09:44:28.518556 10163 sgd_solver.cpp:106] Iteration 63900, lr = 3.41154e-05
I0827 09:44:32.793537 10163 solver.cpp:337] Iteration 64000, Testing net (#0)
I0827 09:44:36.115627 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 09:44:36.115682 10163 solver.cpp:404]     Test net output #1: loss = 1.10116 (* 1 = 1.10116 loss)
I0827 09:44:36.131614 10163 solver.cpp:228] Iteration 64000, loss = 1.10239
I0827 09:44:36.131659 10163 solver.cpp:244]     Train net output #0: loss = 1.10239 (* 1 = 1.10239 loss)
I0827 09:44:36.131670 10163 sgd_solver.cpp:106] Iteration 64000, lr = 3.4085e-05
I0827 09:44:40.459592 10163 solver.cpp:228] Iteration 64100, loss = 1.09842
I0827 09:44:40.459641 10163 solver.cpp:244]     Train net output #0: loss = 1.09842 (* 1 = 1.09842 loss)
I0827 09:44:40.459651 10163 sgd_solver.cpp:106] Iteration 64100, lr = 3.40546e-05
I0827 09:44:44.787933 10163 solver.cpp:228] Iteration 64200, loss = 1.10568
I0827 09:44:44.787976 10163 solver.cpp:244]     Train net output #0: loss = 1.10568 (* 1 = 1.10568 loss)
I0827 09:44:44.787983 10163 sgd_solver.cpp:106] Iteration 64200, lr = 3.40242e-05
I0827 09:44:49.107314 10163 solver.cpp:228] Iteration 64300, loss = 1.09283
I0827 09:44:49.107355 10163 solver.cpp:244]     Train net output #0: loss = 1.09283 (* 1 = 1.09283 loss)
I0827 09:44:49.107362 10163 sgd_solver.cpp:106] Iteration 64300, lr = 3.3994e-05
I0827 09:44:53.435293 10163 solver.cpp:228] Iteration 64400, loss = 1.09904
I0827 09:44:53.435364 10163 solver.cpp:244]     Train net output #0: loss = 1.09904 (* 1 = 1.09904 loss)
I0827 09:44:53.435394 10163 sgd_solver.cpp:106] Iteration 64400, lr = 3.39637e-05
I0827 09:44:57.719301 10163 solver.cpp:337] Iteration 64500, Testing net (#0)
I0827 09:45:01.071763 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 09:45:01.071830 10163 solver.cpp:404]     Test net output #1: loss = 1.10028 (* 1 = 1.10028 loss)
I0827 09:45:01.087218 10163 solver.cpp:228] Iteration 64500, loss = 1.09753
I0827 09:45:01.087294 10163 solver.cpp:244]     Train net output #0: loss = 1.09753 (* 1 = 1.09753 loss)
I0827 09:45:01.087314 10163 sgd_solver.cpp:106] Iteration 64500, lr = 3.39336e-05
I0827 09:45:05.409091 10163 solver.cpp:228] Iteration 64600, loss = 1.10098
I0827 09:45:05.409132 10163 solver.cpp:244]     Train net output #0: loss = 1.10098 (* 1 = 1.10098 loss)
I0827 09:45:05.409137 10163 sgd_solver.cpp:106] Iteration 64600, lr = 3.39035e-05
I0827 09:45:09.730551 10163 solver.cpp:228] Iteration 64700, loss = 1.09566
I0827 09:45:09.730568 10163 solver.cpp:244]     Train net output #0: loss = 1.09566 (* 1 = 1.09566 loss)
I0827 09:45:09.730573 10163 sgd_solver.cpp:106] Iteration 64700, lr = 3.38735e-05
I0827 09:45:14.050068 10163 solver.cpp:228] Iteration 64800, loss = 1.10046
I0827 09:45:14.050120 10163 solver.cpp:244]     Train net output #0: loss = 1.10046 (* 1 = 1.10046 loss)
I0827 09:45:14.050127 10163 sgd_solver.cpp:106] Iteration 64800, lr = 3.38435e-05
I0827 09:45:18.369418 10163 solver.cpp:228] Iteration 64900, loss = 1.0981
I0827 09:45:18.369482 10163 solver.cpp:244]     Train net output #0: loss = 1.0981 (* 1 = 1.0981 loss)
I0827 09:45:18.369488 10163 sgd_solver.cpp:106] Iteration 64900, lr = 3.38136e-05
I0827 09:45:22.649791 10163 solver.cpp:337] Iteration 65000, Testing net (#0)
I0827 09:45:25.865532 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269667
I0827 09:45:25.865591 10163 solver.cpp:404]     Test net output #1: loss = 1.10262 (* 1 = 1.10262 loss)
I0827 09:45:25.881305 10163 solver.cpp:228] Iteration 65000, loss = 1.10128
I0827 09:45:25.881376 10163 solver.cpp:244]     Train net output #0: loss = 1.10128 (* 1 = 1.10128 loss)
I0827 09:45:25.881395 10163 sgd_solver.cpp:106] Iteration 65000, lr = 3.37838e-05
I0827 09:45:30.211894 10163 solver.cpp:228] Iteration 65100, loss = 1.09912
I0827 09:45:30.211952 10163 solver.cpp:244]     Train net output #0: loss = 1.09912 (* 1 = 1.09912 loss)
I0827 09:45:30.211959 10163 sgd_solver.cpp:106] Iteration 65100, lr = 3.3754e-05
I0827 09:45:34.531263 10163 solver.cpp:228] Iteration 65200, loss = 1.1051
I0827 09:45:34.531323 10163 solver.cpp:244]     Train net output #0: loss = 1.1051 (* 1 = 1.1051 loss)
I0827 09:45:34.531329 10163 sgd_solver.cpp:106] Iteration 65200, lr = 3.37243e-05
I0827 09:45:38.855664 10163 solver.cpp:228] Iteration 65300, loss = 1.09513
I0827 09:45:38.855712 10163 solver.cpp:244]     Train net output #0: loss = 1.09513 (* 1 = 1.09513 loss)
I0827 09:45:38.855718 10163 sgd_solver.cpp:106] Iteration 65300, lr = 3.36946e-05
I0827 09:45:43.176690 10163 solver.cpp:228] Iteration 65400, loss = 1.1053
I0827 09:45:43.176731 10163 solver.cpp:244]     Train net output #0: loss = 1.1053 (* 1 = 1.1053 loss)
I0827 09:45:43.176736 10163 sgd_solver.cpp:106] Iteration 65400, lr = 3.3665e-05
I0827 09:45:47.456637 10163 solver.cpp:337] Iteration 65500, Testing net (#0)
I0827 09:45:50.132980 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:45:50.917444 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2695
I0827 09:45:50.917485 10163 solver.cpp:404]     Test net output #1: loss = 1.1038 (* 1 = 1.1038 loss)
I0827 09:45:50.932981 10163 solver.cpp:228] Iteration 65500, loss = 1.10472
I0827 09:45:50.933023 10163 solver.cpp:244]     Train net output #0: loss = 1.10472 (* 1 = 1.10472 loss)
I0827 09:45:50.933033 10163 sgd_solver.cpp:106] Iteration 65500, lr = 3.36355e-05
I0827 09:45:55.259168 10163 solver.cpp:228] Iteration 65600, loss = 1.10098
I0827 09:45:55.259208 10163 solver.cpp:244]     Train net output #0: loss = 1.10098 (* 1 = 1.10098 loss)
I0827 09:45:55.259214 10163 sgd_solver.cpp:106] Iteration 65600, lr = 3.3606e-05
I0827 09:45:59.579365 10163 solver.cpp:228] Iteration 65700, loss = 1.10197
I0827 09:45:59.579411 10163 solver.cpp:244]     Train net output #0: loss = 1.10197 (* 1 = 1.10197 loss)
I0827 09:45:59.579416 10163 sgd_solver.cpp:106] Iteration 65700, lr = 3.35766e-05
I0827 09:46:03.900346 10163 solver.cpp:228] Iteration 65800, loss = 1.10078
I0827 09:46:03.900395 10163 solver.cpp:244]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0827 09:46:03.900401 10163 sgd_solver.cpp:106] Iteration 65800, lr = 3.35473e-05
I0827 09:46:08.224442 10163 solver.cpp:228] Iteration 65900, loss = 1.10013
I0827 09:46:08.224511 10163 solver.cpp:244]     Train net output #0: loss = 1.10013 (* 1 = 1.10013 loss)
I0827 09:46:08.224525 10163 sgd_solver.cpp:106] Iteration 65900, lr = 3.3518e-05
I0827 09:46:12.513164 10163 solver.cpp:337] Iteration 66000, Testing net (#0)
I0827 09:46:15.960219 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0827 09:46:15.960285 10163 solver.cpp:404]     Test net output #1: loss = 1.10409 (* 1 = 1.10409 loss)
I0827 09:46:15.975162 10163 solver.cpp:228] Iteration 66000, loss = 1.09454
I0827 09:46:15.975210 10163 solver.cpp:244]     Train net output #0: loss = 1.09454 (* 1 = 1.09454 loss)
I0827 09:46:15.975221 10163 sgd_solver.cpp:106] Iteration 66000, lr = 3.34887e-05
I0827 09:46:20.304072 10163 solver.cpp:228] Iteration 66100, loss = 1.09506
I0827 09:46:20.304122 10163 solver.cpp:244]     Train net output #0: loss = 1.09506 (* 1 = 1.09506 loss)
I0827 09:46:20.304128 10163 sgd_solver.cpp:106] Iteration 66100, lr = 3.34596e-05
I0827 09:46:24.631676 10163 solver.cpp:228] Iteration 66200, loss = 1.09865
I0827 09:46:24.631731 10163 solver.cpp:244]     Train net output #0: loss = 1.09865 (* 1 = 1.09865 loss)
I0827 09:46:24.631737 10163 sgd_solver.cpp:106] Iteration 66200, lr = 3.34304e-05
I0827 09:46:28.958766 10163 solver.cpp:228] Iteration 66300, loss = 1.10617
I0827 09:46:28.958809 10163 solver.cpp:244]     Train net output #0: loss = 1.10617 (* 1 = 1.10617 loss)
I0827 09:46:28.958816 10163 sgd_solver.cpp:106] Iteration 66300, lr = 3.34014e-05
I0827 09:46:33.292534 10163 solver.cpp:228] Iteration 66400, loss = 1.10403
I0827 09:46:33.292600 10163 solver.cpp:244]     Train net output #0: loss = 1.10403 (* 1 = 1.10403 loss)
I0827 09:46:33.292608 10163 sgd_solver.cpp:106] Iteration 66400, lr = 3.33724e-05
I0827 09:46:37.576742 10163 solver.cpp:337] Iteration 66500, Testing net (#0)
I0827 09:46:40.887648 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 09:46:40.887696 10163 solver.cpp:404]     Test net output #1: loss = 1.10447 (* 1 = 1.10447 loss)
I0827 09:46:40.903569 10163 solver.cpp:228] Iteration 66500, loss = 1.09998
I0827 09:46:40.903604 10163 solver.cpp:244]     Train net output #0: loss = 1.09998 (* 1 = 1.09998 loss)
I0827 09:46:40.903616 10163 sgd_solver.cpp:106] Iteration 66500, lr = 3.33434e-05
I0827 09:46:45.228778 10163 solver.cpp:228] Iteration 66600, loss = 1.10861
I0827 09:46:45.228835 10163 solver.cpp:244]     Train net output #0: loss = 1.10861 (* 1 = 1.10861 loss)
I0827 09:46:45.228844 10163 sgd_solver.cpp:106] Iteration 66600, lr = 3.33146e-05
I0827 09:46:49.547049 10163 solver.cpp:228] Iteration 66700, loss = 1.10338
I0827 09:46:49.547108 10163 solver.cpp:244]     Train net output #0: loss = 1.10338 (* 1 = 1.10338 loss)
I0827 09:46:49.547114 10163 sgd_solver.cpp:106] Iteration 66700, lr = 3.32857e-05
I0827 09:46:53.864738 10163 solver.cpp:228] Iteration 66800, loss = 1.10246
I0827 09:46:53.864797 10163 solver.cpp:244]     Train net output #0: loss = 1.10246 (* 1 = 1.10246 loss)
I0827 09:46:53.864804 10163 sgd_solver.cpp:106] Iteration 66800, lr = 3.3257e-05
I0827 09:46:58.194557 10163 solver.cpp:228] Iteration 66900, loss = 1.10066
I0827 09:46:58.194617 10163 solver.cpp:244]     Train net output #0: loss = 1.10066 (* 1 = 1.10066 loss)
I0827 09:46:58.194625 10163 sgd_solver.cpp:106] Iteration 66900, lr = 3.32283e-05
I0827 09:47:02.477630 10163 solver.cpp:337] Iteration 67000, Testing net (#0)
I0827 09:47:05.893625 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152292
I0827 09:47:05.893688 10163 solver.cpp:404]     Test net output #1: loss = 1.10541 (* 1 = 1.10541 loss)
I0827 09:47:05.908387 10163 solver.cpp:228] Iteration 67000, loss = 1.09894
I0827 09:47:05.908409 10163 solver.cpp:244]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0827 09:47:05.908422 10163 sgd_solver.cpp:106] Iteration 67000, lr = 3.31996e-05
I0827 09:47:10.231979 10163 solver.cpp:228] Iteration 67100, loss = 1.09883
I0827 09:47:10.232025 10163 solver.cpp:244]     Train net output #0: loss = 1.09883 (* 1 = 1.09883 loss)
I0827 09:47:10.232033 10163 sgd_solver.cpp:106] Iteration 67100, lr = 3.3171e-05
I0827 09:47:14.559865 10163 solver.cpp:228] Iteration 67200, loss = 1.09779
I0827 09:47:14.559914 10163 solver.cpp:244]     Train net output #0: loss = 1.09779 (* 1 = 1.09779 loss)
I0827 09:47:14.559931 10163 sgd_solver.cpp:106] Iteration 67200, lr = 3.31425e-05
I0827 09:47:18.877842 10163 solver.cpp:228] Iteration 67300, loss = 1.10664
I0827 09:47:18.877900 10163 solver.cpp:244]     Train net output #0: loss = 1.10664 (* 1 = 1.10664 loss)
I0827 09:47:18.877907 10163 sgd_solver.cpp:106] Iteration 67300, lr = 3.3114e-05
I0827 09:47:23.196907 10163 solver.cpp:228] Iteration 67400, loss = 1.103
I0827 09:47:23.196959 10163 solver.cpp:244]     Train net output #0: loss = 1.103 (* 1 = 1.103 loss)
I0827 09:47:23.196964 10163 sgd_solver.cpp:106] Iteration 67400, lr = 3.30856e-05
I0827 09:47:27.476790 10163 solver.cpp:337] Iteration 67500, Testing net (#0)
I0827 09:47:30.969177 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:47:30.969233 10163 solver.cpp:404]     Test net output #1: loss = 1.10644 (* 1 = 1.10644 loss)
I0827 09:47:30.983693 10163 solver.cpp:228] Iteration 67500, loss = 1.09077
I0827 09:47:30.983726 10163 solver.cpp:244]     Train net output #0: loss = 1.09077 (* 1 = 1.09077 loss)
I0827 09:47:30.983738 10163 sgd_solver.cpp:106] Iteration 67500, lr = 3.30572e-05
I0827 09:47:35.308748 10163 solver.cpp:228] Iteration 67600, loss = 1.10424
I0827 09:47:35.308794 10163 solver.cpp:244]     Train net output #0: loss = 1.10424 (* 1 = 1.10424 loss)
I0827 09:47:35.308799 10163 sgd_solver.cpp:106] Iteration 67600, lr = 3.30289e-05
I0827 09:47:39.631692 10163 solver.cpp:228] Iteration 67700, loss = 1.0969
I0827 09:47:39.631737 10163 solver.cpp:244]     Train net output #0: loss = 1.0969 (* 1 = 1.0969 loss)
I0827 09:47:39.631743 10163 sgd_solver.cpp:106] Iteration 67700, lr = 3.30007e-05
I0827 09:47:40.281010 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:47:43.954138 10163 solver.cpp:228] Iteration 67800, loss = 1.10194
I0827 09:47:43.954201 10163 solver.cpp:244]     Train net output #0: loss = 1.10194 (* 1 = 1.10194 loss)
I0827 09:47:43.954208 10163 sgd_solver.cpp:106] Iteration 67800, lr = 3.29725e-05
I0827 09:47:48.282739 10163 solver.cpp:228] Iteration 67900, loss = 1.10498
I0827 09:47:48.282793 10163 solver.cpp:244]     Train net output #0: loss = 1.10498 (* 1 = 1.10498 loss)
I0827 09:47:48.282800 10163 sgd_solver.cpp:106] Iteration 67900, lr = 3.29443e-05
I0827 09:47:52.557694 10163 solver.cpp:337] Iteration 68000, Testing net (#0)
I0827 09:47:55.758344 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 09:47:55.758441 10163 solver.cpp:404]     Test net output #1: loss = 1.10976 (* 1 = 1.10976 loss)
I0827 09:47:55.773125 10163 solver.cpp:228] Iteration 68000, loss = 1.10489
I0827 09:47:55.773154 10163 solver.cpp:244]     Train net output #0: loss = 1.10489 (* 1 = 1.10489 loss)
I0827 09:47:55.773162 10163 sgd_solver.cpp:106] Iteration 68000, lr = 3.29163e-05
I0827 09:48:00.093668 10163 solver.cpp:228] Iteration 68100, loss = 1.09737
I0827 09:48:00.093722 10163 solver.cpp:244]     Train net output #0: loss = 1.09737 (* 1 = 1.09737 loss)
I0827 09:48:00.093730 10163 sgd_solver.cpp:106] Iteration 68100, lr = 3.28882e-05
I0827 09:48:04.415959 10163 solver.cpp:228] Iteration 68200, loss = 1.09708
I0827 09:48:04.415978 10163 solver.cpp:244]     Train net output #0: loss = 1.09708 (* 1 = 1.09708 loss)
I0827 09:48:04.415984 10163 sgd_solver.cpp:106] Iteration 68200, lr = 3.28603e-05
I0827 09:48:08.740566 10163 solver.cpp:228] Iteration 68300, loss = 1.10274
I0827 09:48:08.740630 10163 solver.cpp:244]     Train net output #0: loss = 1.10274 (* 1 = 1.10274 loss)
I0827 09:48:08.740638 10163 sgd_solver.cpp:106] Iteration 68300, lr = 3.28323e-05
I0827 09:48:13.066049 10163 solver.cpp:228] Iteration 68400, loss = 1.0946
I0827 09:48:13.066103 10163 solver.cpp:244]     Train net output #0: loss = 1.0946 (* 1 = 1.0946 loss)
I0827 09:48:13.066112 10163 sgd_solver.cpp:106] Iteration 68400, lr = 3.28045e-05
I0827 09:48:17.355245 10163 solver.cpp:337] Iteration 68500, Testing net (#0)
I0827 09:48:20.639641 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0827 09:48:20.639696 10163 solver.cpp:404]     Test net output #1: loss = 1.11186 (* 1 = 1.11186 loss)
I0827 09:48:20.654294 10163 solver.cpp:228] Iteration 68500, loss = 1.09774
I0827 09:48:20.654325 10163 solver.cpp:244]     Train net output #0: loss = 1.09774 (* 1 = 1.09774 loss)
I0827 09:48:20.654336 10163 sgd_solver.cpp:106] Iteration 68500, lr = 3.27767e-05
I0827 09:48:24.978869 10163 solver.cpp:228] Iteration 68600, loss = 1.09799
I0827 09:48:24.978929 10163 solver.cpp:244]     Train net output #0: loss = 1.09799 (* 1 = 1.09799 loss)
I0827 09:48:24.978935 10163 sgd_solver.cpp:106] Iteration 68600, lr = 3.27489e-05
I0827 09:48:29.308142 10163 solver.cpp:228] Iteration 68700, loss = 1.10754
I0827 09:48:29.308205 10163 solver.cpp:244]     Train net output #0: loss = 1.10754 (* 1 = 1.10754 loss)
I0827 09:48:29.308212 10163 sgd_solver.cpp:106] Iteration 68700, lr = 3.27212e-05
I0827 09:48:33.629652 10163 solver.cpp:228] Iteration 68800, loss = 1.09719
I0827 09:48:33.629714 10163 solver.cpp:244]     Train net output #0: loss = 1.09719 (* 1 = 1.09719 loss)
I0827 09:48:33.629721 10163 sgd_solver.cpp:106] Iteration 68800, lr = 3.26936e-05
I0827 09:48:37.958102 10163 solver.cpp:228] Iteration 68900, loss = 1.09382
I0827 09:48:37.958140 10163 solver.cpp:244]     Train net output #0: loss = 1.09382 (* 1 = 1.09382 loss)
I0827 09:48:37.958147 10163 sgd_solver.cpp:106] Iteration 68900, lr = 3.2666e-05
I0827 09:48:42.234627 10163 solver.cpp:337] Iteration 69000, Testing net (#0)
I0827 09:48:45.565903 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152
I0827 09:48:45.565944 10163 solver.cpp:404]     Test net output #1: loss = 1.11259 (* 1 = 1.11259 loss)
I0827 09:48:45.582226 10163 solver.cpp:228] Iteration 69000, loss = 1.10288
I0827 09:48:45.582269 10163 solver.cpp:244]     Train net output #0: loss = 1.10288 (* 1 = 1.10288 loss)
I0827 09:48:45.582304 10163 sgd_solver.cpp:106] Iteration 69000, lr = 3.26385e-05
I0827 09:48:49.901752 10163 solver.cpp:228] Iteration 69100, loss = 1.09564
I0827 09:48:49.901811 10163 solver.cpp:244]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0827 09:48:49.901818 10163 sgd_solver.cpp:106] Iteration 69100, lr = 3.2611e-05
I0827 09:48:54.227984 10163 solver.cpp:228] Iteration 69200, loss = 1.10159
I0827 09:48:54.228025 10163 solver.cpp:244]     Train net output #0: loss = 1.10159 (* 1 = 1.10159 loss)
I0827 09:48:54.228031 10163 sgd_solver.cpp:106] Iteration 69200, lr = 3.25836e-05
I0827 09:48:58.552963 10163 solver.cpp:228] Iteration 69300, loss = 1.09976
I0827 09:48:58.553000 10163 solver.cpp:244]     Train net output #0: loss = 1.09976 (* 1 = 1.09976 loss)
I0827 09:48:58.553006 10163 sgd_solver.cpp:106] Iteration 69300, lr = 3.25562e-05
I0827 09:49:02.877202 10163 solver.cpp:228] Iteration 69400, loss = 1.10096
I0827 09:49:02.877231 10163 solver.cpp:244]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0827 09:49:02.877238 10163 sgd_solver.cpp:106] Iteration 69400, lr = 3.25289e-05
I0827 09:49:07.158258 10163 solver.cpp:337] Iteration 69500, Testing net (#0)
I0827 09:49:10.716557 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152042
I0827 09:49:10.716610 10163 solver.cpp:404]     Test net output #1: loss = 1.11334 (* 1 = 1.11334 loss)
I0827 09:49:10.732103 10163 solver.cpp:228] Iteration 69500, loss = 1.09703
I0827 09:49:10.732143 10163 solver.cpp:244]     Train net output #0: loss = 1.09703 (* 1 = 1.09703 loss)
I0827 09:49:10.732156 10163 sgd_solver.cpp:106] Iteration 69500, lr = 3.25016e-05
I0827 09:49:15.056815 10163 solver.cpp:228] Iteration 69600, loss = 1.09903
I0827 09:49:15.056862 10163 solver.cpp:244]     Train net output #0: loss = 1.09903 (* 1 = 1.09903 loss)
I0827 09:49:15.056869 10163 sgd_solver.cpp:106] Iteration 69600, lr = 3.24744e-05
I0827 09:49:19.377293 10163 solver.cpp:228] Iteration 69700, loss = 1.1029
I0827 09:49:19.377333 10163 solver.cpp:244]     Train net output #0: loss = 1.1029 (* 1 = 1.1029 loss)
I0827 09:49:19.377339 10163 sgd_solver.cpp:106] Iteration 69700, lr = 3.24473e-05
I0827 09:49:23.704802 10163 solver.cpp:228] Iteration 69800, loss = 1.09726
I0827 09:49:23.704843 10163 solver.cpp:244]     Train net output #0: loss = 1.09726 (* 1 = 1.09726 loss)
I0827 09:49:23.704849 10163 sgd_solver.cpp:106] Iteration 69800, lr = 3.24202e-05
I0827 09:49:28.032410 10163 solver.cpp:228] Iteration 69900, loss = 1.10696
I0827 09:49:28.032454 10163 solver.cpp:244]     Train net output #0: loss = 1.10696 (* 1 = 1.10696 loss)
I0827 09:49:28.032459 10163 sgd_solver.cpp:106] Iteration 69900, lr = 3.23931e-05
I0827 09:49:32.311993 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_70000.caffemodel
I0827 09:49:32.789994 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_70000.solverstate
I0827 09:49:32.945454 10163 solver.cpp:337] Iteration 70000, Testing net (#0)
I0827 09:49:36.474925 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152333
I0827 09:49:36.474982 10163 solver.cpp:404]     Test net output #1: loss = 1.10893 (* 1 = 1.10893 loss)
I0827 09:49:36.490260 10163 solver.cpp:228] Iteration 70000, loss = 1.09729
I0827 09:49:36.490303 10163 solver.cpp:244]     Train net output #0: loss = 1.09729 (* 1 = 1.09729 loss)
I0827 09:49:36.490314 10163 sgd_solver.cpp:106] Iteration 70000, lr = 3.23661e-05
I0827 09:49:40.812861 10163 solver.cpp:228] Iteration 70100, loss = 1.09105
I0827 09:49:40.812897 10163 solver.cpp:244]     Train net output #0: loss = 1.09105 (* 1 = 1.09105 loss)
I0827 09:49:40.812903 10163 sgd_solver.cpp:106] Iteration 70100, lr = 3.23392e-05
I0827 09:49:45.134420 10163 solver.cpp:228] Iteration 70200, loss = 1.10476
I0827 09:49:45.134451 10163 solver.cpp:244]     Train net output #0: loss = 1.10476 (* 1 = 1.10476 loss)
I0827 09:49:45.134457 10163 sgd_solver.cpp:106] Iteration 70200, lr = 3.23123e-05
I0827 09:49:48.816969 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:49:49.467052 10163 solver.cpp:228] Iteration 70300, loss = 1.10343
I0827 09:49:49.467079 10163 solver.cpp:244]     Train net output #0: loss = 1.10343 (* 1 = 1.10343 loss)
I0827 09:49:49.467085 10163 sgd_solver.cpp:106] Iteration 70300, lr = 3.22854e-05
I0827 09:49:53.786526 10163 solver.cpp:228] Iteration 70400, loss = 1.09369
I0827 09:49:53.786566 10163 solver.cpp:244]     Train net output #0: loss = 1.09369 (* 1 = 1.09369 loss)
I0827 09:49:53.786571 10163 sgd_solver.cpp:106] Iteration 70400, lr = 3.22586e-05
I0827 09:49:58.062412 10163 solver.cpp:337] Iteration 70500, Testing net (#0)
I0827 09:50:01.303319 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 09:50:01.303424 10163 solver.cpp:404]     Test net output #1: loss = 1.10478 (* 1 = 1.10478 loss)
I0827 09:50:01.318899 10163 solver.cpp:228] Iteration 70500, loss = 1.10216
I0827 09:50:01.318928 10163 solver.cpp:244]     Train net output #0: loss = 1.10216 (* 1 = 1.10216 loss)
I0827 09:50:01.318936 10163 sgd_solver.cpp:106] Iteration 70500, lr = 3.22319e-05
I0827 09:50:05.637627 10163 solver.cpp:228] Iteration 70600, loss = 1.0954
I0827 09:50:05.637670 10163 solver.cpp:244]     Train net output #0: loss = 1.0954 (* 1 = 1.0954 loss)
I0827 09:50:05.637676 10163 sgd_solver.cpp:106] Iteration 70600, lr = 3.22052e-05
I0827 09:50:09.954870 10163 solver.cpp:228] Iteration 70700, loss = 1.10256
I0827 09:50:09.954890 10163 solver.cpp:244]     Train net output #0: loss = 1.10256 (* 1 = 1.10256 loss)
I0827 09:50:09.954895 10163 sgd_solver.cpp:106] Iteration 70700, lr = 3.21786e-05
I0827 09:50:14.274781 10163 solver.cpp:228] Iteration 70800, loss = 1.10679
I0827 09:50:14.274819 10163 solver.cpp:244]     Train net output #0: loss = 1.10679 (* 1 = 1.10679 loss)
I0827 09:50:14.274826 10163 sgd_solver.cpp:106] Iteration 70800, lr = 3.2152e-05
I0827 09:50:18.597502 10163 solver.cpp:228] Iteration 70900, loss = 1.09597
I0827 09:50:18.597560 10163 solver.cpp:244]     Train net output #0: loss = 1.09597 (* 1 = 1.09597 loss)
I0827 09:50:18.597568 10163 sgd_solver.cpp:106] Iteration 70900, lr = 3.21255e-05
I0827 09:50:22.881842 10163 solver.cpp:337] Iteration 71000, Testing net (#0)
I0827 09:50:26.286376 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578875
I0827 09:50:26.286423 10163 solver.cpp:404]     Test net output #1: loss = 1.09812 (* 1 = 1.09812 loss)
I0827 09:50:26.301760 10163 solver.cpp:228] Iteration 71000, loss = 1.09905
I0827 09:50:26.301820 10163 solver.cpp:244]     Train net output #0: loss = 1.09905 (* 1 = 1.09905 loss)
I0827 09:50:26.301836 10163 sgd_solver.cpp:106] Iteration 71000, lr = 3.2099e-05
I0827 09:50:30.636983 10163 solver.cpp:228] Iteration 71100, loss = 1.09954
I0827 09:50:30.637040 10163 solver.cpp:244]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0827 09:50:30.637048 10163 sgd_solver.cpp:106] Iteration 71100, lr = 3.20726e-05
I0827 09:50:34.968225 10163 solver.cpp:228] Iteration 71200, loss = 1.10681
I0827 09:50:34.968282 10163 solver.cpp:244]     Train net output #0: loss = 1.10681 (* 1 = 1.10681 loss)
I0827 09:50:34.968291 10163 sgd_solver.cpp:106] Iteration 71200, lr = 3.20462e-05
I0827 09:50:39.288251 10163 solver.cpp:228] Iteration 71300, loss = 1.09344
I0827 09:50:39.288311 10163 solver.cpp:244]     Train net output #0: loss = 1.09344 (* 1 = 1.09344 loss)
I0827 09:50:39.288317 10163 sgd_solver.cpp:106] Iteration 71300, lr = 3.20199e-05
I0827 09:50:43.605968 10163 solver.cpp:228] Iteration 71400, loss = 1.09781
I0827 09:50:43.606029 10163 solver.cpp:244]     Train net output #0: loss = 1.09781 (* 1 = 1.09781 loss)
I0827 09:50:43.606034 10163 sgd_solver.cpp:106] Iteration 71400, lr = 3.19936e-05
I0827 09:50:47.891314 10163 solver.cpp:337] Iteration 71500, Testing net (#0)
I0827 09:50:51.337834 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578
I0827 09:50:51.337903 10163 solver.cpp:404]     Test net output #1: loss = 1.0948 (* 1 = 1.0948 loss)
I0827 09:50:51.353724 10163 solver.cpp:228] Iteration 71500, loss = 1.10249
I0827 09:50:51.353781 10163 solver.cpp:244]     Train net output #0: loss = 1.10249 (* 1 = 1.10249 loss)
I0827 09:50:51.353793 10163 sgd_solver.cpp:106] Iteration 71500, lr = 3.19674e-05
I0827 09:50:55.683079 10163 solver.cpp:228] Iteration 71600, loss = 1.09739
I0827 09:50:55.683135 10163 solver.cpp:244]     Train net output #0: loss = 1.09739 (* 1 = 1.09739 loss)
I0827 09:50:55.683154 10163 sgd_solver.cpp:106] Iteration 71600, lr = 3.19412e-05
I0827 09:51:00.013335 10163 solver.cpp:228] Iteration 71700, loss = 1.09804
I0827 09:51:00.013377 10163 solver.cpp:244]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0827 09:51:00.013383 10163 sgd_solver.cpp:106] Iteration 71700, lr = 3.1915e-05
I0827 09:51:04.339352 10163 solver.cpp:228] Iteration 71800, loss = 1.09589
I0827 09:51:04.339402 10163 solver.cpp:244]     Train net output #0: loss = 1.09589 (* 1 = 1.09589 loss)
I0827 09:51:04.339409 10163 sgd_solver.cpp:106] Iteration 71800, lr = 3.1889e-05
I0827 09:51:08.668897 10163 solver.cpp:228] Iteration 71900, loss = 1.1033
I0827 09:51:08.668949 10163 solver.cpp:244]     Train net output #0: loss = 1.1033 (* 1 = 1.1033 loss)
I0827 09:51:08.668956 10163 sgd_solver.cpp:106] Iteration 71900, lr = 3.18629e-05
I0827 09:51:12.959244 10163 solver.cpp:337] Iteration 72000, Testing net (#0)
I0827 09:51:16.280069 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578125
I0827 09:51:16.280117 10163 solver.cpp:404]     Test net output #1: loss = 1.09706 (* 1 = 1.09706 loss)
I0827 09:51:16.294437 10163 solver.cpp:228] Iteration 72000, loss = 1.0972
I0827 09:51:16.294473 10163 solver.cpp:244]     Train net output #0: loss = 1.0972 (* 1 = 1.0972 loss)
I0827 09:51:16.294487 10163 sgd_solver.cpp:106] Iteration 72000, lr = 3.1837e-05
I0827 09:51:20.616108 10163 solver.cpp:228] Iteration 72100, loss = 1.09665
I0827 09:51:20.616147 10163 solver.cpp:244]     Train net output #0: loss = 1.09665 (* 1 = 1.09665 loss)
I0827 09:51:20.616153 10163 sgd_solver.cpp:106] Iteration 72100, lr = 3.1811e-05
I0827 09:51:24.948182 10163 solver.cpp:228] Iteration 72200, loss = 1.10046
I0827 09:51:24.948232 10163 solver.cpp:244]     Train net output #0: loss = 1.10046 (* 1 = 1.10046 loss)
I0827 09:51:24.948240 10163 sgd_solver.cpp:106] Iteration 72200, lr = 3.17852e-05
I0827 09:51:29.271183 10163 solver.cpp:228] Iteration 72300, loss = 1.09079
I0827 09:51:29.271224 10163 solver.cpp:244]     Train net output #0: loss = 1.09079 (* 1 = 1.09079 loss)
I0827 09:51:29.271230 10163 sgd_solver.cpp:106] Iteration 72300, lr = 3.17593e-05
I0827 09:51:33.593703 10163 solver.cpp:228] Iteration 72400, loss = 1.11036
I0827 09:51:33.593746 10163 solver.cpp:244]     Train net output #0: loss = 1.11036 (* 1 = 1.11036 loss)
I0827 09:51:33.593752 10163 sgd_solver.cpp:106] Iteration 72400, lr = 3.17335e-05
I0827 09:51:37.831532 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:51:37.874699 10163 solver.cpp:337] Iteration 72500, Testing net (#0)
I0827 09:51:41.118113 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:51:41.118170 10163 solver.cpp:404]     Test net output #1: loss = 1.09808 (* 1 = 1.09808 loss)
I0827 09:51:41.133833 10163 solver.cpp:228] Iteration 72500, loss = 1.102
I0827 09:51:41.133872 10163 solver.cpp:244]     Train net output #0: loss = 1.102 (* 1 = 1.102 loss)
I0827 09:51:41.133883 10163 sgd_solver.cpp:106] Iteration 72500, lr = 3.17078e-05
I0827 09:51:45.469785 10163 solver.cpp:228] Iteration 72600, loss = 1.0955
I0827 09:51:45.469852 10163 solver.cpp:244]     Train net output #0: loss = 1.0955 (* 1 = 1.0955 loss)
I0827 09:51:45.469871 10163 sgd_solver.cpp:106] Iteration 72600, lr = 3.16821e-05
I0827 09:51:49.798202 10163 solver.cpp:228] Iteration 72700, loss = 1.09673
I0827 09:51:49.798244 10163 solver.cpp:244]     Train net output #0: loss = 1.09673 (* 1 = 1.09673 loss)
I0827 09:51:49.798250 10163 sgd_solver.cpp:106] Iteration 72700, lr = 3.16565e-05
I0827 09:51:54.124318 10163 solver.cpp:228] Iteration 72800, loss = 1.10943
I0827 09:51:54.124374 10163 solver.cpp:244]     Train net output #0: loss = 1.10943 (* 1 = 1.10943 loss)
I0827 09:51:54.124383 10163 sgd_solver.cpp:106] Iteration 72800, lr = 3.16309e-05
I0827 09:51:58.447479 10163 solver.cpp:228] Iteration 72900, loss = 1.09862
I0827 09:51:58.447536 10163 solver.cpp:244]     Train net output #0: loss = 1.09862 (* 1 = 1.09862 loss)
I0827 09:51:58.447546 10163 sgd_solver.cpp:106] Iteration 72900, lr = 3.16054e-05
I0827 09:52:02.733419 10163 solver.cpp:337] Iteration 73000, Testing net (#0)
I0827 09:52:06.299412 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:52:06.299471 10163 solver.cpp:404]     Test net output #1: loss = 1.10118 (* 1 = 1.10118 loss)
I0827 09:52:06.314316 10163 solver.cpp:228] Iteration 73000, loss = 1.10557
I0827 09:52:06.314352 10163 solver.cpp:244]     Train net output #0: loss = 1.10557 (* 1 = 1.10557 loss)
I0827 09:52:06.314363 10163 sgd_solver.cpp:106] Iteration 73000, lr = 3.15799e-05
I0827 09:52:10.634021 10163 solver.cpp:228] Iteration 73100, loss = 1.10068
I0827 09:52:10.634086 10163 solver.cpp:244]     Train net output #0: loss = 1.10068 (* 1 = 1.10068 loss)
I0827 09:52:10.634093 10163 sgd_solver.cpp:106] Iteration 73100, lr = 3.15544e-05
I0827 09:52:14.959944 10163 solver.cpp:228] Iteration 73200, loss = 1.09927
I0827 09:52:14.960005 10163 solver.cpp:244]     Train net output #0: loss = 1.09927 (* 1 = 1.09927 loss)
I0827 09:52:14.960011 10163 sgd_solver.cpp:106] Iteration 73200, lr = 3.1529e-05
I0827 09:52:19.286603 10163 solver.cpp:228] Iteration 73300, loss = 1.10026
I0827 09:52:19.286649 10163 solver.cpp:244]     Train net output #0: loss = 1.10026 (* 1 = 1.10026 loss)
I0827 09:52:19.286656 10163 sgd_solver.cpp:106] Iteration 73300, lr = 3.15037e-05
I0827 09:52:23.616595 10163 solver.cpp:228] Iteration 73400, loss = 1.09691
I0827 09:52:23.616652 10163 solver.cpp:244]     Train net output #0: loss = 1.09691 (* 1 = 1.09691 loss)
I0827 09:52:23.616659 10163 sgd_solver.cpp:106] Iteration 73400, lr = 3.14784e-05
I0827 09:52:27.894107 10163 solver.cpp:337] Iteration 73500, Testing net (#0)
I0827 09:52:31.231531 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 09:52:31.231583 10163 solver.cpp:404]     Test net output #1: loss = 1.10387 (* 1 = 1.10387 loss)
I0827 09:52:31.246932 10163 solver.cpp:228] Iteration 73500, loss = 1.089
I0827 09:52:31.246997 10163 solver.cpp:244]     Train net output #0: loss = 1.089 (* 1 = 1.089 loss)
I0827 09:52:31.247017 10163 sgd_solver.cpp:106] Iteration 73500, lr = 3.14531e-05
I0827 09:52:35.565465 10163 solver.cpp:228] Iteration 73600, loss = 1.09594
I0827 09:52:35.565490 10163 solver.cpp:244]     Train net output #0: loss = 1.09594 (* 1 = 1.09594 loss)
I0827 09:52:35.565496 10163 sgd_solver.cpp:106] Iteration 73600, lr = 3.14279e-05
I0827 09:52:39.885186 10163 solver.cpp:228] Iteration 73700, loss = 1.09402
I0827 09:52:39.885254 10163 solver.cpp:244]     Train net output #0: loss = 1.09402 (* 1 = 1.09402 loss)
I0827 09:52:39.885260 10163 sgd_solver.cpp:106] Iteration 73700, lr = 3.14028e-05
I0827 09:52:44.203110 10163 solver.cpp:228] Iteration 73800, loss = 1.09952
I0827 09:52:44.203178 10163 solver.cpp:244]     Train net output #0: loss = 1.09952 (* 1 = 1.09952 loss)
I0827 09:52:44.203186 10163 sgd_solver.cpp:106] Iteration 73800, lr = 3.13776e-05
I0827 09:52:48.526093 10163 solver.cpp:228] Iteration 73900, loss = 1.0921
I0827 09:52:48.526137 10163 solver.cpp:244]     Train net output #0: loss = 1.0921 (* 1 = 1.0921 loss)
I0827 09:52:48.526142 10163 sgd_solver.cpp:106] Iteration 73900, lr = 3.13526e-05
I0827 09:52:52.801936 10163 solver.cpp:337] Iteration 74000, Testing net (#0)
I0827 09:52:56.273917 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 09:52:56.273970 10163 solver.cpp:404]     Test net output #1: loss = 1.10577 (* 1 = 1.10577 loss)
I0827 09:52:56.288756 10163 solver.cpp:228] Iteration 74000, loss = 1.10426
I0827 09:52:56.288792 10163 solver.cpp:244]     Train net output #0: loss = 1.10426 (* 1 = 1.10426 loss)
I0827 09:52:56.288803 10163 sgd_solver.cpp:106] Iteration 74000, lr = 3.13276e-05
I0827 09:53:00.607733 10163 solver.cpp:228] Iteration 74100, loss = 1.0956
I0827 09:53:00.607758 10163 solver.cpp:244]     Train net output #0: loss = 1.0956 (* 1 = 1.0956 loss)
I0827 09:53:00.607764 10163 sgd_solver.cpp:106] Iteration 74100, lr = 3.13026e-05
I0827 09:53:04.928776 10163 solver.cpp:228] Iteration 74200, loss = 1.09968
I0827 09:53:04.928817 10163 solver.cpp:244]     Train net output #0: loss = 1.09968 (* 1 = 1.09968 loss)
I0827 09:53:04.928822 10163 sgd_solver.cpp:106] Iteration 74200, lr = 3.12777e-05
I0827 09:53:09.253731 10163 solver.cpp:228] Iteration 74300, loss = 1.0997
I0827 09:53:09.253794 10163 solver.cpp:244]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0827 09:53:09.253801 10163 sgd_solver.cpp:106] Iteration 74300, lr = 3.12528e-05
I0827 09:53:13.575742 10163 solver.cpp:228] Iteration 74400, loss = 1.09561
I0827 09:53:13.575786 10163 solver.cpp:244]     Train net output #0: loss = 1.09561 (* 1 = 1.09561 loss)
I0827 09:53:13.575793 10163 sgd_solver.cpp:106] Iteration 74400, lr = 3.1228e-05
I0827 09:53:17.853710 10163 solver.cpp:337] Iteration 74500, Testing net (#0)
I0827 09:53:21.219823 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 09:53:21.219871 10163 solver.cpp:404]     Test net output #1: loss = 1.10572 (* 1 = 1.10572 loss)
I0827 09:53:21.234719 10163 solver.cpp:228] Iteration 74500, loss = 1.09741
I0827 09:53:21.234758 10163 solver.cpp:244]     Train net output #0: loss = 1.09741 (* 1 = 1.09741 loss)
I0827 09:53:21.234771 10163 sgd_solver.cpp:106] Iteration 74500, lr = 3.12032e-05
I0827 09:53:25.565155 10163 solver.cpp:228] Iteration 74600, loss = 1.09831
I0827 09:53:25.565204 10163 solver.cpp:244]     Train net output #0: loss = 1.09831 (* 1 = 1.09831 loss)
I0827 09:53:25.565210 10163 sgd_solver.cpp:106] Iteration 74600, lr = 3.11784e-05
I0827 09:53:29.897677 10163 solver.cpp:228] Iteration 74700, loss = 1.10038
I0827 09:53:29.897717 10163 solver.cpp:244]     Train net output #0: loss = 1.10038 (* 1 = 1.10038 loss)
I0827 09:53:29.897723 10163 sgd_solver.cpp:106] Iteration 74700, lr = 3.11537e-05
I0827 09:53:34.226346 10163 solver.cpp:228] Iteration 74800, loss = 1.10938
I0827 09:53:34.226411 10163 solver.cpp:244]     Train net output #0: loss = 1.10938 (* 1 = 1.10938 loss)
I0827 09:53:34.226418 10163 sgd_solver.cpp:106] Iteration 74800, lr = 3.11291e-05
I0827 09:53:38.567580 10163 solver.cpp:228] Iteration 74900, loss = 1.10433
I0827 09:53:38.567637 10163 solver.cpp:244]     Train net output #0: loss = 1.10433 (* 1 = 1.10433 loss)
I0827 09:53:38.567644 10163 sgd_solver.cpp:106] Iteration 74900, lr = 3.11045e-05
I0827 09:53:39.907245 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:53:42.844399 10163 solver.cpp:337] Iteration 75000, Testing net (#0)
I0827 09:53:46.460484 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 09:53:46.460537 10163 solver.cpp:404]     Test net output #1: loss = 1.10572 (* 1 = 1.10572 loss)
I0827 09:53:46.475358 10163 solver.cpp:228] Iteration 75000, loss = 1.09527
I0827 09:53:46.475385 10163 solver.cpp:244]     Train net output #0: loss = 1.09527 (* 1 = 1.09527 loss)
I0827 09:53:46.475399 10163 sgd_solver.cpp:106] Iteration 75000, lr = 3.10799e-05
I0827 09:53:50.800544 10163 solver.cpp:228] Iteration 75100, loss = 1.10303
I0827 09:53:50.800585 10163 solver.cpp:244]     Train net output #0: loss = 1.10303 (* 1 = 1.10303 loss)
I0827 09:53:50.800591 10163 sgd_solver.cpp:106] Iteration 75100, lr = 3.10554e-05
I0827 09:53:55.124217 10163 solver.cpp:228] Iteration 75200, loss = 1.09788
I0827 09:53:55.124238 10163 solver.cpp:244]     Train net output #0: loss = 1.09788 (* 1 = 1.09788 loss)
I0827 09:53:55.124243 10163 sgd_solver.cpp:106] Iteration 75200, lr = 3.10309e-05
I0827 09:53:59.446188 10163 solver.cpp:228] Iteration 75300, loss = 1.10349
I0827 09:53:59.446207 10163 solver.cpp:244]     Train net output #0: loss = 1.10349 (* 1 = 1.10349 loss)
I0827 09:53:59.446213 10163 sgd_solver.cpp:106] Iteration 75300, lr = 3.10065e-05
I0827 09:54:03.768368 10163 solver.cpp:228] Iteration 75400, loss = 1.09406
I0827 09:54:03.768410 10163 solver.cpp:244]     Train net output #0: loss = 1.09406 (* 1 = 1.09406 loss)
I0827 09:54:03.768416 10163 sgd_solver.cpp:106] Iteration 75400, lr = 3.09821e-05
I0827 09:54:08.045655 10163 solver.cpp:337] Iteration 75500, Testing net (#0)
I0827 09:54:11.587529 10163 solver.cpp:404]     Test net output #0: accuracy = 0.2685
I0827 09:54:11.587587 10163 solver.cpp:404]     Test net output #1: loss = 1.09967 (* 1 = 1.09967 loss)
I0827 09:54:11.602725 10163 solver.cpp:228] Iteration 75500, loss = 1.10206
I0827 09:54:11.602778 10163 solver.cpp:244]     Train net output #0: loss = 1.10206 (* 1 = 1.10206 loss)
I0827 09:54:11.602802 10163 sgd_solver.cpp:106] Iteration 75500, lr = 3.09578e-05
I0827 09:54:15.922535 10163 solver.cpp:228] Iteration 75600, loss = 1.09339
I0827 09:54:15.922574 10163 solver.cpp:244]     Train net output #0: loss = 1.09339 (* 1 = 1.09339 loss)
I0827 09:54:15.922580 10163 sgd_solver.cpp:106] Iteration 75600, lr = 3.09335e-05
I0827 09:54:20.241089 10163 solver.cpp:228] Iteration 75700, loss = 1.09785
I0827 09:54:20.241119 10163 solver.cpp:244]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0827 09:54:20.241124 10163 sgd_solver.cpp:106] Iteration 75700, lr = 3.09093e-05
I0827 09:54:24.564198 10163 solver.cpp:228] Iteration 75800, loss = 1.09765
I0827 09:54:24.564259 10163 solver.cpp:244]     Train net output #0: loss = 1.09765 (* 1 = 1.09765 loss)
I0827 09:54:24.564263 10163 sgd_solver.cpp:106] Iteration 75800, lr = 3.08851e-05
I0827 09:54:28.886580 10163 solver.cpp:228] Iteration 75900, loss = 1.1044
I0827 09:54:28.886618 10163 solver.cpp:244]     Train net output #0: loss = 1.1044 (* 1 = 1.1044 loss)
I0827 09:54:28.886623 10163 sgd_solver.cpp:106] Iteration 75900, lr = 3.08609e-05
I0827 09:54:33.169472 10163 solver.cpp:337] Iteration 76000, Testing net (#0)
I0827 09:54:36.684999 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269542
I0827 09:54:36.685055 10163 solver.cpp:404]     Test net output #1: loss = 1.09489 (* 1 = 1.09489 loss)
I0827 09:54:36.699143 10163 solver.cpp:228] Iteration 76000, loss = 1.09416
I0827 09:54:36.699187 10163 solver.cpp:244]     Train net output #0: loss = 1.09416 (* 1 = 1.09416 loss)
I0827 09:54:36.699198 10163 sgd_solver.cpp:106] Iteration 76000, lr = 3.08368e-05
I0827 09:54:41.025970 10163 solver.cpp:228] Iteration 76100, loss = 1.09001
I0827 09:54:41.026021 10163 solver.cpp:244]     Train net output #0: loss = 1.09001 (* 1 = 1.09001 loss)
I0827 09:54:41.026031 10163 sgd_solver.cpp:106] Iteration 76100, lr = 3.08127e-05
I0827 09:54:45.349197 10163 solver.cpp:228] Iteration 76200, loss = 1.10017
I0827 09:54:45.349256 10163 solver.cpp:244]     Train net output #0: loss = 1.10017 (* 1 = 1.10017 loss)
I0827 09:54:45.349261 10163 sgd_solver.cpp:106] Iteration 76200, lr = 3.07887e-05
I0827 09:54:49.677139 10163 solver.cpp:228] Iteration 76300, loss = 1.09626
I0827 09:54:49.677199 10163 solver.cpp:244]     Train net output #0: loss = 1.09626 (* 1 = 1.09626 loss)
I0827 09:54:49.677206 10163 sgd_solver.cpp:106] Iteration 76300, lr = 3.07647e-05
I0827 09:54:54.009681 10163 solver.cpp:228] Iteration 76400, loss = 1.09986
I0827 09:54:54.009729 10163 solver.cpp:244]     Train net output #0: loss = 1.09986 (* 1 = 1.09986 loss)
I0827 09:54:54.009737 10163 sgd_solver.cpp:106] Iteration 76400, lr = 3.07408e-05
I0827 09:54:58.295289 10163 solver.cpp:337] Iteration 76500, Testing net (#0)
I0827 09:55:01.541208 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 09:55:01.541416 10163 solver.cpp:404]     Test net output #1: loss = 1.09189 (* 1 = 1.09189 loss)
I0827 09:55:01.555665 10163 solver.cpp:228] Iteration 76500, loss = 1.09848
I0827 09:55:01.555726 10163 solver.cpp:244]     Train net output #0: loss = 1.09848 (* 1 = 1.09848 loss)
I0827 09:55:01.555735 10163 sgd_solver.cpp:106] Iteration 76500, lr = 3.07169e-05
I0827 09:55:05.886299 10163 solver.cpp:228] Iteration 76600, loss = 1.09767
I0827 09:55:05.886359 10163 solver.cpp:244]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0827 09:55:05.886366 10163 sgd_solver.cpp:106] Iteration 76600, lr = 3.0693e-05
I0827 09:55:10.209345 10163 solver.cpp:228] Iteration 76700, loss = 1.10246
I0827 09:55:10.209406 10163 solver.cpp:244]     Train net output #0: loss = 1.10246 (* 1 = 1.10246 loss)
I0827 09:55:10.209413 10163 sgd_solver.cpp:106] Iteration 76700, lr = 3.06692e-05
I0827 09:55:10.726902 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:55:14.532449 10163 solver.cpp:228] Iteration 76800, loss = 1.09603
I0827 09:55:14.532510 10163 solver.cpp:244]     Train net output #0: loss = 1.09603 (* 1 = 1.09603 loss)
I0827 09:55:14.532516 10163 sgd_solver.cpp:106] Iteration 76800, lr = 3.06454e-05
I0827 09:55:18.853013 10163 solver.cpp:228] Iteration 76900, loss = 1.09249
I0827 09:55:18.853056 10163 solver.cpp:244]     Train net output #0: loss = 1.09249 (* 1 = 1.09249 loss)
I0827 09:55:18.853062 10163 sgd_solver.cpp:106] Iteration 76900, lr = 3.06217e-05
I0827 09:55:23.145946 10163 solver.cpp:337] Iteration 77000, Testing net (#0)
I0827 09:55:26.379325 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269
I0827 09:55:26.379380 10163 solver.cpp:404]     Test net output #1: loss = 1.08916 (* 1 = 1.08916 loss)
I0827 09:55:26.393642 10163 solver.cpp:228] Iteration 77000, loss = 1.09682
I0827 09:55:26.393667 10163 solver.cpp:244]     Train net output #0: loss = 1.09682 (* 1 = 1.09682 loss)
I0827 09:55:26.393677 10163 sgd_solver.cpp:106] Iteration 77000, lr = 3.0598e-05
I0827 09:55:30.714905 10163 solver.cpp:228] Iteration 77100, loss = 1.10748
I0827 09:55:30.714968 10163 solver.cpp:244]     Train net output #0: loss = 1.10748 (* 1 = 1.10748 loss)
I0827 09:55:30.714978 10163 sgd_solver.cpp:106] Iteration 77100, lr = 3.05744e-05
I0827 09:55:35.040673 10163 solver.cpp:228] Iteration 77200, loss = 1.10637
I0827 09:55:35.040727 10163 solver.cpp:244]     Train net output #0: loss = 1.10637 (* 1 = 1.10637 loss)
I0827 09:55:35.040737 10163 sgd_solver.cpp:106] Iteration 77200, lr = 3.05508e-05
I0827 09:55:39.360374 10163 solver.cpp:228] Iteration 77300, loss = 1.1018
I0827 09:55:39.360411 10163 solver.cpp:244]     Train net output #0: loss = 1.1018 (* 1 = 1.1018 loss)
I0827 09:55:39.360417 10163 sgd_solver.cpp:106] Iteration 77300, lr = 3.05273e-05
I0827 09:55:43.692538 10163 solver.cpp:228] Iteration 77400, loss = 1.10232
I0827 09:55:43.692595 10163 solver.cpp:244]     Train net output #0: loss = 1.10232 (* 1 = 1.10232 loss)
I0827 09:55:43.692601 10163 sgd_solver.cpp:106] Iteration 77400, lr = 3.05038e-05
I0827 09:55:47.969590 10163 solver.cpp:337] Iteration 77500, Testing net (#0)
I0827 09:55:51.245136 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269208
I0827 09:55:51.245201 10163 solver.cpp:404]     Test net output #1: loss = 1.09116 (* 1 = 1.09116 loss)
I0827 09:55:51.259521 10163 solver.cpp:228] Iteration 77500, loss = 1.09734
I0827 09:55:51.259580 10163 solver.cpp:244]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0827 09:55:51.259590 10163 sgd_solver.cpp:106] Iteration 77500, lr = 3.04803e-05
I0827 09:55:55.585466 10163 solver.cpp:228] Iteration 77600, loss = 1.09436
I0827 09:55:55.585510 10163 solver.cpp:244]     Train net output #0: loss = 1.09436 (* 1 = 1.09436 loss)
I0827 09:55:55.585515 10163 sgd_solver.cpp:106] Iteration 77600, lr = 3.04569e-05
I0827 09:55:59.916070 10163 solver.cpp:228] Iteration 77700, loss = 1.09404
I0827 09:55:59.916108 10163 solver.cpp:244]     Train net output #0: loss = 1.09404 (* 1 = 1.09404 loss)
I0827 09:55:59.916113 10163 sgd_solver.cpp:106] Iteration 77700, lr = 3.04335e-05
I0827 09:56:04.235998 10163 solver.cpp:228] Iteration 77800, loss = 1.09852
I0827 09:56:04.236047 10163 solver.cpp:244]     Train net output #0: loss = 1.09852 (* 1 = 1.09852 loss)
I0827 09:56:04.236052 10163 sgd_solver.cpp:106] Iteration 77800, lr = 3.04101e-05
I0827 09:56:08.555528 10163 solver.cpp:228] Iteration 77900, loss = 1.10078
I0827 09:56:08.555575 10163 solver.cpp:244]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0827 09:56:08.555582 10163 sgd_solver.cpp:106] Iteration 77900, lr = 3.03868e-05
I0827 09:56:12.842449 10163 solver.cpp:337] Iteration 78000, Testing net (#0)
I0827 09:56:16.066344 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578375
I0827 09:56:16.066382 10163 solver.cpp:404]     Test net output #1: loss = 1.09317 (* 1 = 1.09317 loss)
I0827 09:56:16.080410 10163 solver.cpp:228] Iteration 78000, loss = 1.10231
I0827 09:56:16.080456 10163 solver.cpp:244]     Train net output #0: loss = 1.10231 (* 1 = 1.10231 loss)
I0827 09:56:16.080468 10163 sgd_solver.cpp:106] Iteration 78000, lr = 3.03636e-05
I0827 09:56:20.398803 10163 solver.cpp:228] Iteration 78100, loss = 1.10777
I0827 09:56:20.398841 10163 solver.cpp:244]     Train net output #0: loss = 1.10777 (* 1 = 1.10777 loss)
I0827 09:56:20.398847 10163 sgd_solver.cpp:106] Iteration 78100, lr = 3.03404e-05
I0827 09:56:24.716094 10163 solver.cpp:228] Iteration 78200, loss = 1.10712
I0827 09:56:24.716132 10163 solver.cpp:244]     Train net output #0: loss = 1.10712 (* 1 = 1.10712 loss)
I0827 09:56:24.716138 10163 sgd_solver.cpp:106] Iteration 78200, lr = 3.03172e-05
I0827 09:56:29.035462 10163 solver.cpp:228] Iteration 78300, loss = 1.09885
I0827 09:56:29.035482 10163 solver.cpp:244]     Train net output #0: loss = 1.09885 (* 1 = 1.09885 loss)
I0827 09:56:29.035486 10163 sgd_solver.cpp:106] Iteration 78300, lr = 3.02941e-05
I0827 09:56:33.353935 10163 solver.cpp:228] Iteration 78400, loss = 1.09461
I0827 09:56:33.353953 10163 solver.cpp:244]     Train net output #0: loss = 1.09461 (* 1 = 1.09461 loss)
I0827 09:56:33.353958 10163 sgd_solver.cpp:106] Iteration 78400, lr = 3.0271e-05
I0827 09:56:37.633103 10163 solver.cpp:337] Iteration 78500, Testing net (#0)
I0827 09:56:41.084573 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578333
I0827 09:56:41.084630 10163 solver.cpp:404]     Test net output #1: loss = 1.09364 (* 1 = 1.09364 loss)
I0827 09:56:41.100407 10163 solver.cpp:228] Iteration 78500, loss = 1.09499
I0827 09:56:41.100450 10163 solver.cpp:244]     Train net output #0: loss = 1.09499 (* 1 = 1.09499 loss)
I0827 09:56:41.100462 10163 sgd_solver.cpp:106] Iteration 78500, lr = 3.02479e-05
I0827 09:56:45.421665 10163 solver.cpp:228] Iteration 78600, loss = 1.10492
I0827 09:56:45.421705 10163 solver.cpp:244]     Train net output #0: loss = 1.10492 (* 1 = 1.10492 loss)
I0827 09:56:45.421710 10163 sgd_solver.cpp:106] Iteration 78600, lr = 3.02249e-05
I0827 09:56:49.746237 10163 solver.cpp:228] Iteration 78700, loss = 1.09089
I0827 09:56:49.746279 10163 solver.cpp:244]     Train net output #0: loss = 1.09089 (* 1 = 1.09089 loss)
I0827 09:56:49.746284 10163 sgd_solver.cpp:106] Iteration 78700, lr = 3.02019e-05
I0827 09:56:54.083003 10163 solver.cpp:228] Iteration 78800, loss = 1.09722
I0827 09:56:54.083045 10163 solver.cpp:244]     Train net output #0: loss = 1.09722 (* 1 = 1.09722 loss)
I0827 09:56:54.083052 10163 sgd_solver.cpp:106] Iteration 78800, lr = 3.0179e-05
I0827 09:56:58.405030 10163 solver.cpp:228] Iteration 78900, loss = 1.10193
I0827 09:56:58.405048 10163 solver.cpp:244]     Train net output #0: loss = 1.10193 (* 1 = 1.10193 loss)
I0827 09:56:58.405055 10163 sgd_solver.cpp:106] Iteration 78900, lr = 3.01561e-05
I0827 09:57:02.682783 10163 solver.cpp:337] Iteration 79000, Testing net (#0)
I0827 09:57:06.092552 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578667
I0827 09:57:06.092602 10163 solver.cpp:404]     Test net output #1: loss = 1.09127 (* 1 = 1.09127 loss)
I0827 09:57:06.108047 10163 solver.cpp:228] Iteration 79000, loss = 1.10319
I0827 09:57:06.108077 10163 solver.cpp:244]     Train net output #0: loss = 1.10319 (* 1 = 1.10319 loss)
I0827 09:57:06.108088 10163 sgd_solver.cpp:106] Iteration 79000, lr = 3.01333e-05
I0827 09:57:10.431442 10163 solver.cpp:228] Iteration 79100, loss = 1.10711
I0827 09:57:10.431480 10163 solver.cpp:244]     Train net output #0: loss = 1.10711 (* 1 = 1.10711 loss)
I0827 09:57:10.431486 10163 sgd_solver.cpp:106] Iteration 79100, lr = 3.01105e-05
I0827 09:57:14.755327 10163 solver.cpp:228] Iteration 79200, loss = 1.09952
I0827 09:57:14.755345 10163 solver.cpp:244]     Train net output #0: loss = 1.09952 (* 1 = 1.09952 loss)
I0827 09:57:14.755350 10163 sgd_solver.cpp:106] Iteration 79200, lr = 3.00877e-05
I0827 09:57:18.047122 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:57:19.082578 10163 solver.cpp:228] Iteration 79300, loss = 1.0992
I0827 09:57:19.082638 10163 solver.cpp:244]     Train net output #0: loss = 1.0992 (* 1 = 1.0992 loss)
I0827 09:57:19.082650 10163 sgd_solver.cpp:106] Iteration 79300, lr = 3.0065e-05
I0827 09:57:23.404285 10163 solver.cpp:228] Iteration 79400, loss = 1.09071
I0827 09:57:23.404325 10163 solver.cpp:244]     Train net output #0: loss = 1.09071 (* 1 = 1.09071 loss)
I0827 09:57:23.404330 10163 sgd_solver.cpp:106] Iteration 79400, lr = 3.00423e-05
I0827 09:57:27.685823 10163 solver.cpp:337] Iteration 79500, Testing net (#0)
I0827 09:57:31.136091 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578542
I0827 09:57:31.136134 10163 solver.cpp:404]     Test net output #1: loss = 1.09452 (* 1 = 1.09452 loss)
I0827 09:57:31.151343 10163 solver.cpp:228] Iteration 79500, loss = 1.09747
I0827 09:57:31.151382 10163 solver.cpp:244]     Train net output #0: loss = 1.09747 (* 1 = 1.09747 loss)
I0827 09:57:31.151394 10163 sgd_solver.cpp:106] Iteration 79500, lr = 3.00196e-05
I0827 09:57:35.473407 10163 solver.cpp:228] Iteration 79600, loss = 1.10241
I0827 09:57:35.473448 10163 solver.cpp:244]     Train net output #0: loss = 1.10241 (* 1 = 1.10241 loss)
I0827 09:57:35.473453 10163 sgd_solver.cpp:106] Iteration 79600, lr = 2.9997e-05
I0827 09:57:39.791744 10163 solver.cpp:228] Iteration 79700, loss = 1.09618
I0827 09:57:39.791764 10163 solver.cpp:244]     Train net output #0: loss = 1.09618 (* 1 = 1.09618 loss)
I0827 09:57:39.791769 10163 sgd_solver.cpp:106] Iteration 79700, lr = 2.99744e-05
I0827 09:57:44.116309 10163 solver.cpp:228] Iteration 79800, loss = 1.09694
I0827 09:57:44.116349 10163 solver.cpp:244]     Train net output #0: loss = 1.09694 (* 1 = 1.09694 loss)
I0827 09:57:44.116355 10163 sgd_solver.cpp:106] Iteration 79800, lr = 2.99519e-05
I0827 09:57:48.438107 10163 solver.cpp:228] Iteration 79900, loss = 1.10041
I0827 09:57:48.438127 10163 solver.cpp:244]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0827 09:57:48.438133 10163 sgd_solver.cpp:106] Iteration 79900, lr = 2.99294e-05
I0827 09:57:52.721460 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_80000.caffemodel
I0827 09:57:53.198704 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_80000.solverstate
I0827 09:57:53.354714 10163 solver.cpp:337] Iteration 80000, Testing net (#0)
I0827 09:57:56.971179 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578125
I0827 09:57:56.971242 10163 solver.cpp:404]     Test net output #1: loss = 1.0941 (* 1 = 1.0941 loss)
I0827 09:57:56.985852 10163 solver.cpp:228] Iteration 80000, loss = 1.09839
I0827 09:57:56.985870 10163 solver.cpp:244]     Train net output #0: loss = 1.09839 (* 1 = 1.09839 loss)
I0827 09:57:56.985893 10163 sgd_solver.cpp:106] Iteration 80000, lr = 2.9907e-05
I0827 09:58:01.301651 10163 solver.cpp:228] Iteration 80100, loss = 1.10356
I0827 09:58:01.301693 10163 solver.cpp:244]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0827 09:58:01.301700 10163 sgd_solver.cpp:106] Iteration 80100, lr = 2.98846e-05
I0827 09:58:05.628492 10163 solver.cpp:228] Iteration 80200, loss = 1.10198
I0827 09:58:05.628532 10163 solver.cpp:244]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0827 09:58:05.628538 10163 sgd_solver.cpp:106] Iteration 80200, lr = 2.98622e-05
I0827 09:58:09.950762 10163 solver.cpp:228] Iteration 80300, loss = 1.09998
I0827 09:58:09.950814 10163 solver.cpp:244]     Train net output #0: loss = 1.09998 (* 1 = 1.09998 loss)
I0827 09:58:09.950824 10163 sgd_solver.cpp:106] Iteration 80300, lr = 2.98399e-05
I0827 09:58:14.280422 10163 solver.cpp:228] Iteration 80400, loss = 1.10326
I0827 09:58:14.280462 10163 solver.cpp:244]     Train net output #0: loss = 1.10326 (* 1 = 1.10326 loss)
I0827 09:58:14.280468 10163 sgd_solver.cpp:106] Iteration 80400, lr = 2.98176e-05
I0827 09:58:18.564013 10163 solver.cpp:337] Iteration 80500, Testing net (#0)
I0827 09:58:21.947414 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269375
I0827 09:58:21.947479 10163 solver.cpp:404]     Test net output #1: loss = 1.09567 (* 1 = 1.09567 loss)
I0827 09:58:21.962288 10163 solver.cpp:228] Iteration 80500, loss = 1.10247
I0827 09:58:21.962318 10163 solver.cpp:244]     Train net output #0: loss = 1.10247 (* 1 = 1.10247 loss)
I0827 09:58:21.962328 10163 sgd_solver.cpp:106] Iteration 80500, lr = 2.97953e-05
I0827 09:58:26.284308 10163 solver.cpp:228] Iteration 80600, loss = 1.09423
I0827 09:58:26.284359 10163 solver.cpp:244]     Train net output #0: loss = 1.09423 (* 1 = 1.09423 loss)
I0827 09:58:26.284368 10163 sgd_solver.cpp:106] Iteration 80600, lr = 2.97731e-05
I0827 09:58:30.605878 10163 solver.cpp:228] Iteration 80700, loss = 1.09696
I0827 09:58:30.605916 10163 solver.cpp:244]     Train net output #0: loss = 1.09696 (* 1 = 1.09696 loss)
I0827 09:58:30.605922 10163 sgd_solver.cpp:106] Iteration 80700, lr = 2.97509e-05
I0827 09:58:34.928565 10163 solver.cpp:228] Iteration 80800, loss = 1.0978
I0827 09:58:34.928632 10163 solver.cpp:244]     Train net output #0: loss = 1.0978 (* 1 = 1.0978 loss)
I0827 09:58:34.928639 10163 sgd_solver.cpp:106] Iteration 80800, lr = 2.97288e-05
I0827 09:58:39.247445 10163 solver.cpp:228] Iteration 80900, loss = 1.10138
I0827 09:58:39.247512 10163 solver.cpp:244]     Train net output #0: loss = 1.10138 (* 1 = 1.10138 loss)
I0827 09:58:39.247519 10163 sgd_solver.cpp:106] Iteration 80900, lr = 2.97067e-05
I0827 09:58:43.524201 10163 solver.cpp:337] Iteration 81000, Testing net (#0)
I0827 09:58:46.765897 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269375
I0827 09:58:46.765960 10163 solver.cpp:404]     Test net output #1: loss = 1.0936 (* 1 = 1.0936 loss)
I0827 09:58:46.782290 10163 solver.cpp:228] Iteration 81000, loss = 1.09722
I0827 09:58:46.782359 10163 solver.cpp:244]     Train net output #0: loss = 1.09722 (* 1 = 1.09722 loss)
I0827 09:58:46.782376 10163 sgd_solver.cpp:106] Iteration 81000, lr = 2.96846e-05
I0827 09:58:51.105916 10163 solver.cpp:228] Iteration 81100, loss = 1.09566
I0827 09:58:51.105964 10163 solver.cpp:244]     Train net output #0: loss = 1.09566 (* 1 = 1.09566 loss)
I0827 09:58:51.105970 10163 sgd_solver.cpp:106] Iteration 81100, lr = 2.96626e-05
I0827 09:58:55.426733 10163 solver.cpp:228] Iteration 81200, loss = 1.09686
I0827 09:58:55.426785 10163 solver.cpp:244]     Train net output #0: loss = 1.09686 (* 1 = 1.09686 loss)
I0827 09:58:55.426794 10163 sgd_solver.cpp:106] Iteration 81200, lr = 2.96406e-05
I0827 09:58:59.745223 10163 solver.cpp:228] Iteration 81300, loss = 1.10313
I0827 09:58:59.745242 10163 solver.cpp:244]     Train net output #0: loss = 1.10313 (* 1 = 1.10313 loss)
I0827 09:58:59.745247 10163 sgd_solver.cpp:106] Iteration 81300, lr = 2.96187e-05
I0827 09:59:04.068265 10163 solver.cpp:228] Iteration 81400, loss = 1.09527
I0827 09:59:04.068322 10163 solver.cpp:244]     Train net output #0: loss = 1.09527 (* 1 = 1.09527 loss)
I0827 09:59:04.068332 10163 sgd_solver.cpp:106] Iteration 81400, lr = 2.95968e-05
I0827 09:59:08.343878 10163 solver.cpp:337] Iteration 81500, Testing net (#0)
I0827 09:59:11.489032 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 09:59:11.489078 10163 solver.cpp:404]     Test net output #1: loss = 1.09213 (* 1 = 1.09213 loss)
I0827 09:59:11.504429 10163 solver.cpp:228] Iteration 81500, loss = 1.09279
I0827 09:59:11.504494 10163 solver.cpp:244]     Train net output #0: loss = 1.09279 (* 1 = 1.09279 loss)
I0827 09:59:11.504511 10163 sgd_solver.cpp:106] Iteration 81500, lr = 2.95749e-05
I0827 09:59:15.829452 10163 solver.cpp:228] Iteration 81600, loss = 1.09021
I0827 09:59:15.829515 10163 solver.cpp:244]     Train net output #0: loss = 1.09021 (* 1 = 1.09021 loss)
I0827 09:59:15.829522 10163 sgd_solver.cpp:106] Iteration 81600, lr = 2.9553e-05
I0827 09:59:20.155369 10163 solver.cpp:228] Iteration 81700, loss = 1.09372
I0827 09:59:20.155408 10163 solver.cpp:244]     Train net output #0: loss = 1.09372 (* 1 = 1.09372 loss)
I0827 09:59:20.155414 10163 sgd_solver.cpp:106] Iteration 81700, lr = 2.95312e-05
I0827 09:59:24.482802 10163 solver.cpp:228] Iteration 81800, loss = 1.09621
I0827 09:59:24.482856 10163 solver.cpp:244]     Train net output #0: loss = 1.09621 (* 1 = 1.09621 loss)
I0827 09:59:24.482862 10163 sgd_solver.cpp:106] Iteration 81800, lr = 2.95095e-05
I0827 09:59:28.808378 10163 solver.cpp:228] Iteration 81900, loss = 1.10573
I0827 09:59:28.808428 10163 solver.cpp:244]     Train net output #0: loss = 1.10573 (* 1 = 1.10573 loss)
I0827 09:59:28.808434 10163 sgd_solver.cpp:106] Iteration 81900, lr = 2.94878e-05
I0827 09:59:32.390411 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 09:59:33.081802 10163 solver.cpp:337] Iteration 82000, Testing net (#0)
I0827 09:59:36.558742 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269458
I0827 09:59:36.558789 10163 solver.cpp:404]     Test net output #1: loss = 1.09232 (* 1 = 1.09232 loss)
I0827 09:59:36.574360 10163 solver.cpp:228] Iteration 82000, loss = 1.10098
I0827 09:59:36.574386 10163 solver.cpp:244]     Train net output #0: loss = 1.10098 (* 1 = 1.10098 loss)
I0827 09:59:36.574398 10163 sgd_solver.cpp:106] Iteration 82000, lr = 2.94661e-05
I0827 09:59:40.896996 10163 solver.cpp:228] Iteration 82100, loss = 1.10439
I0827 09:59:40.897059 10163 solver.cpp:244]     Train net output #0: loss = 1.10439 (* 1 = 1.10439 loss)
I0827 09:59:40.897065 10163 sgd_solver.cpp:106] Iteration 82100, lr = 2.94444e-05
I0827 09:59:45.228746 10163 solver.cpp:228] Iteration 82200, loss = 1.0996
I0827 09:59:45.228785 10163 solver.cpp:244]     Train net output #0: loss = 1.0996 (* 1 = 1.0996 loss)
I0827 09:59:45.228790 10163 sgd_solver.cpp:106] Iteration 82200, lr = 2.94228e-05
I0827 09:59:49.551981 10163 solver.cpp:228] Iteration 82300, loss = 1.09926
I0827 09:59:49.552022 10163 solver.cpp:244]     Train net output #0: loss = 1.09926 (* 1 = 1.09926 loss)
I0827 09:59:49.552028 10163 sgd_solver.cpp:106] Iteration 82300, lr = 2.94012e-05
I0827 09:59:53.870313 10163 solver.cpp:228] Iteration 82400, loss = 1.10813
I0827 09:59:53.870337 10163 solver.cpp:244]     Train net output #0: loss = 1.10813 (* 1 = 1.10813 loss)
I0827 09:59:53.870342 10163 sgd_solver.cpp:106] Iteration 82400, lr = 2.93797e-05
I0827 09:59:58.148145 10163 solver.cpp:337] Iteration 82500, Testing net (#0)
I0827 10:00:01.445438 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0827 10:00:01.445499 10163 solver.cpp:404]     Test net output #1: loss = 1.09567 (* 1 = 1.09567 loss)
I0827 10:00:01.459792 10163 solver.cpp:228] Iteration 82500, loss = 1.10413
I0827 10:00:01.459825 10163 solver.cpp:244]     Train net output #0: loss = 1.10413 (* 1 = 1.10413 loss)
I0827 10:00:01.459837 10163 sgd_solver.cpp:106] Iteration 82500, lr = 2.93582e-05
I0827 10:00:05.779242 10163 solver.cpp:228] Iteration 82600, loss = 1.09925
I0827 10:00:05.779281 10163 solver.cpp:244]     Train net output #0: loss = 1.09925 (* 1 = 1.09925 loss)
I0827 10:00:05.779287 10163 sgd_solver.cpp:106] Iteration 82600, lr = 2.93367e-05
I0827 10:00:10.127344 10163 solver.cpp:228] Iteration 82700, loss = 1.09825
I0827 10:00:10.127388 10163 solver.cpp:244]     Train net output #0: loss = 1.09825 (* 1 = 1.09825 loss)
I0827 10:00:10.127393 10163 sgd_solver.cpp:106] Iteration 82700, lr = 2.93153e-05
I0827 10:00:14.464128 10163 solver.cpp:228] Iteration 82800, loss = 1.09651
I0827 10:00:14.464175 10163 solver.cpp:244]     Train net output #0: loss = 1.09651 (* 1 = 1.09651 loss)
I0827 10:00:14.464181 10163 sgd_solver.cpp:106] Iteration 82800, lr = 2.92939e-05
I0827 10:00:18.786118 10163 solver.cpp:228] Iteration 82900, loss = 1.10027
I0827 10:00:18.786161 10163 solver.cpp:244]     Train net output #0: loss = 1.10027 (* 1 = 1.10027 loss)
I0827 10:00:18.786167 10163 sgd_solver.cpp:106] Iteration 82900, lr = 2.92726e-05
I0827 10:00:23.061089 10163 solver.cpp:337] Iteration 83000, Testing net (#0)
I0827 10:00:26.605303 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269708
I0827 10:00:26.605361 10163 solver.cpp:404]     Test net output #1: loss = 1.09952 (* 1 = 1.09952 loss)
I0827 10:00:26.620245 10163 solver.cpp:228] Iteration 83000, loss = 1.10491
I0827 10:00:26.620290 10163 solver.cpp:244]     Train net output #0: loss = 1.10491 (* 1 = 1.10491 loss)
I0827 10:00:26.620306 10163 sgd_solver.cpp:106] Iteration 83000, lr = 2.92513e-05
I0827 10:00:30.940968 10163 solver.cpp:228] Iteration 83100, loss = 1.1015
I0827 10:00:30.941027 10163 solver.cpp:244]     Train net output #0: loss = 1.1015 (* 1 = 1.1015 loss)
I0827 10:00:30.941033 10163 sgd_solver.cpp:106] Iteration 83100, lr = 2.923e-05
I0827 10:00:35.259834 10163 solver.cpp:228] Iteration 83200, loss = 1.09637
I0827 10:00:35.259896 10163 solver.cpp:244]     Train net output #0: loss = 1.09637 (* 1 = 1.09637 loss)
I0827 10:00:35.259902 10163 sgd_solver.cpp:106] Iteration 83200, lr = 2.92087e-05
I0827 10:00:39.583793 10163 solver.cpp:228] Iteration 83300, loss = 1.10178
I0827 10:00:39.583856 10163 solver.cpp:244]     Train net output #0: loss = 1.10178 (* 1 = 1.10178 loss)
I0827 10:00:39.583863 10163 sgd_solver.cpp:106] Iteration 83300, lr = 2.91875e-05
I0827 10:00:43.909947 10163 solver.cpp:228] Iteration 83400, loss = 1.09243
I0827 10:00:43.909999 10163 solver.cpp:244]     Train net output #0: loss = 1.09243 (* 1 = 1.09243 loss)
I0827 10:00:43.910006 10163 sgd_solver.cpp:106] Iteration 83400, lr = 2.91663e-05
I0827 10:00:48.206535 10163 solver.cpp:337] Iteration 83500, Testing net (#0)
I0827 10:00:51.494748 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269292
I0827 10:00:51.494807 10163 solver.cpp:404]     Test net output #1: loss = 1.10136 (* 1 = 1.10136 loss)
I0827 10:00:51.509744 10163 solver.cpp:228] Iteration 83500, loss = 1.10091
I0827 10:00:51.509790 10163 solver.cpp:244]     Train net output #0: loss = 1.10091 (* 1 = 1.10091 loss)
I0827 10:00:51.509802 10163 sgd_solver.cpp:106] Iteration 83500, lr = 2.91452e-05
I0827 10:00:55.831639 10163 solver.cpp:228] Iteration 83600, loss = 1.09228
I0827 10:00:55.831660 10163 solver.cpp:244]     Train net output #0: loss = 1.09228 (* 1 = 1.09228 loss)
I0827 10:00:55.831665 10163 sgd_solver.cpp:106] Iteration 83600, lr = 2.91241e-05
I0827 10:01:00.155298 10163 solver.cpp:228] Iteration 83700, loss = 1.09921
I0827 10:01:00.155342 10163 solver.cpp:244]     Train net output #0: loss = 1.09921 (* 1 = 1.09921 loss)
I0827 10:01:00.155349 10163 sgd_solver.cpp:106] Iteration 83700, lr = 2.9103e-05
I0827 10:01:04.478772 10163 solver.cpp:228] Iteration 83800, loss = 1.09935
I0827 10:01:04.478812 10163 solver.cpp:244]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0827 10:01:04.478818 10163 sgd_solver.cpp:106] Iteration 83800, lr = 2.9082e-05
I0827 10:01:08.796005 10163 solver.cpp:228] Iteration 83900, loss = 1.10031
I0827 10:01:08.796048 10163 solver.cpp:244]     Train net output #0: loss = 1.10031 (* 1 = 1.10031 loss)
I0827 10:01:08.796054 10163 sgd_solver.cpp:106] Iteration 83900, lr = 2.9061e-05
I0827 10:01:13.077246 10163 solver.cpp:337] Iteration 84000, Testing net (#0)
I0827 10:01:16.319667 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269
I0827 10:01:16.319705 10163 solver.cpp:404]     Test net output #1: loss = 1.10195 (* 1 = 1.10195 loss)
I0827 10:01:16.334336 10163 solver.cpp:228] Iteration 84000, loss = 1.09749
I0827 10:01:16.334354 10163 solver.cpp:244]     Train net output #0: loss = 1.09749 (* 1 = 1.09749 loss)
I0827 10:01:16.334364 10163 sgd_solver.cpp:106] Iteration 84000, lr = 2.90401e-05
I0827 10:01:20.652757 10163 solver.cpp:228] Iteration 84100, loss = 1.10232
I0827 10:01:20.652796 10163 solver.cpp:244]     Train net output #0: loss = 1.10232 (* 1 = 1.10232 loss)
I0827 10:01:20.652802 10163 sgd_solver.cpp:106] Iteration 84100, lr = 2.90191e-05
I0827 10:01:24.969573 10163 solver.cpp:228] Iteration 84200, loss = 1.09735
I0827 10:01:24.969629 10163 solver.cpp:244]     Train net output #0: loss = 1.09735 (* 1 = 1.09735 loss)
I0827 10:01:24.969635 10163 sgd_solver.cpp:106] Iteration 84200, lr = 2.89982e-05
I0827 10:01:29.291606 10163 solver.cpp:228] Iteration 84300, loss = 1.09312
I0827 10:01:29.291657 10163 solver.cpp:244]     Train net output #0: loss = 1.09312 (* 1 = 1.09312 loss)
I0827 10:01:29.291668 10163 sgd_solver.cpp:106] Iteration 84300, lr = 2.89774e-05
I0827 10:01:33.616387 10163 solver.cpp:228] Iteration 84400, loss = 1.09685
I0827 10:01:33.616430 10163 solver.cpp:244]     Train net output #0: loss = 1.09685 (* 1 = 1.09685 loss)
I0827 10:01:33.616436 10163 sgd_solver.cpp:106] Iteration 84400, lr = 2.89566e-05
I0827 10:01:37.893993 10163 solver.cpp:337] Iteration 84500, Testing net (#0)
I0827 10:01:40.519995 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:01:41.296778 10163 solver.cpp:404]     Test net output #0: accuracy = 0.268833
I0827 10:01:41.296841 10163 solver.cpp:404]     Test net output #1: loss = 1.10229 (* 1 = 1.10229 loss)
I0827 10:01:41.312178 10163 solver.cpp:228] Iteration 84500, loss = 1.10103
I0827 10:01:41.312242 10163 solver.cpp:244]     Train net output #0: loss = 1.10103 (* 1 = 1.10103 loss)
I0827 10:01:41.312266 10163 sgd_solver.cpp:106] Iteration 84500, lr = 2.89358e-05
I0827 10:01:45.634313 10163 solver.cpp:228] Iteration 84600, loss = 1.1041
I0827 10:01:45.634353 10163 solver.cpp:244]     Train net output #0: loss = 1.1041 (* 1 = 1.1041 loss)
I0827 10:01:45.634361 10163 sgd_solver.cpp:106] Iteration 84600, lr = 2.8915e-05
I0827 10:01:49.954602 10163 solver.cpp:228] Iteration 84700, loss = 1.09226
I0827 10:01:49.954638 10163 solver.cpp:244]     Train net output #0: loss = 1.09226 (* 1 = 1.09226 loss)
I0827 10:01:49.954643 10163 sgd_solver.cpp:106] Iteration 84700, lr = 2.88943e-05
I0827 10:01:54.276216 10163 solver.cpp:228] Iteration 84800, loss = 1.09956
I0827 10:01:54.276257 10163 solver.cpp:244]     Train net output #0: loss = 1.09956 (* 1 = 1.09956 loss)
I0827 10:01:54.276262 10163 sgd_solver.cpp:106] Iteration 84800, lr = 2.88736e-05
I0827 10:01:58.596907 10163 solver.cpp:228] Iteration 84900, loss = 1.10351
I0827 10:01:58.596949 10163 solver.cpp:244]     Train net output #0: loss = 1.10351 (* 1 = 1.10351 loss)
I0827 10:01:58.596956 10163 sgd_solver.cpp:106] Iteration 84900, lr = 2.8853e-05
I0827 10:02:02.876101 10163 solver.cpp:337] Iteration 85000, Testing net (#0)
I0827 10:02:06.080498 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269042
I0827 10:02:06.080559 10163 solver.cpp:404]     Test net output #1: loss = 1.101 (* 1 = 1.101 loss)
I0827 10:02:06.095404 10163 solver.cpp:228] Iteration 85000, loss = 1.10277
I0827 10:02:06.095455 10163 solver.cpp:244]     Train net output #0: loss = 1.10277 (* 1 = 1.10277 loss)
I0827 10:02:06.095468 10163 sgd_solver.cpp:106] Iteration 85000, lr = 2.88324e-05
I0827 10:02:10.419062 10163 solver.cpp:228] Iteration 85100, loss = 1.09606
I0827 10:02:10.419112 10163 solver.cpp:244]     Train net output #0: loss = 1.09606 (* 1 = 1.09606 loss)
I0827 10:02:10.419121 10163 sgd_solver.cpp:106] Iteration 85100, lr = 2.88118e-05
I0827 10:02:14.746611 10163 solver.cpp:228] Iteration 85200, loss = 1.09648
I0827 10:02:14.746682 10163 solver.cpp:244]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0827 10:02:14.746698 10163 sgd_solver.cpp:106] Iteration 85200, lr = 2.87913e-05
I0827 10:02:19.077864 10163 solver.cpp:228] Iteration 85300, loss = 1.09311
I0827 10:02:19.077915 10163 solver.cpp:244]     Train net output #0: loss = 1.09311 (* 1 = 1.09311 loss)
I0827 10:02:19.077924 10163 sgd_solver.cpp:106] Iteration 85300, lr = 2.87708e-05
I0827 10:02:23.400795 10163 solver.cpp:228] Iteration 85400, loss = 1.10086
I0827 10:02:23.400858 10163 solver.cpp:244]     Train net output #0: loss = 1.10086 (* 1 = 1.10086 loss)
I0827 10:02:23.400864 10163 sgd_solver.cpp:106] Iteration 85400, lr = 2.87503e-05
I0827 10:02:27.678445 10163 solver.cpp:337] Iteration 85500, Testing net (#0)
I0827 10:02:31.144876 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 10:02:31.144918 10163 solver.cpp:404]     Test net output #1: loss = 1.09841 (* 1 = 1.09841 loss)
I0827 10:02:31.161350 10163 solver.cpp:228] Iteration 85500, loss = 1.09696
I0827 10:02:31.161399 10163 solver.cpp:244]     Train net output #0: loss = 1.09696 (* 1 = 1.09696 loss)
I0827 10:02:31.161419 10163 sgd_solver.cpp:106] Iteration 85500, lr = 2.87298e-05
I0827 10:02:35.487643 10163 solver.cpp:228] Iteration 85600, loss = 1.1031
I0827 10:02:35.487686 10163 solver.cpp:244]     Train net output #0: loss = 1.1031 (* 1 = 1.1031 loss)
I0827 10:02:35.487692 10163 sgd_solver.cpp:106] Iteration 85600, lr = 2.87094e-05
I0827 10:02:39.810950 10163 solver.cpp:228] Iteration 85700, loss = 1.09618
I0827 10:02:39.811002 10163 solver.cpp:244]     Train net output #0: loss = 1.09618 (* 1 = 1.09618 loss)
I0827 10:02:39.811009 10163 sgd_solver.cpp:106] Iteration 85700, lr = 2.86891e-05
I0827 10:02:44.136481 10163 solver.cpp:228] Iteration 85800, loss = 1.09802
I0827 10:02:44.136540 10163 solver.cpp:244]     Train net output #0: loss = 1.09802 (* 1 = 1.09802 loss)
I0827 10:02:44.136546 10163 sgd_solver.cpp:106] Iteration 85800, lr = 2.86687e-05
I0827 10:02:48.468453 10163 solver.cpp:228] Iteration 85900, loss = 1.09657
I0827 10:02:48.468497 10163 solver.cpp:244]     Train net output #0: loss = 1.09657 (* 1 = 1.09657 loss)
I0827 10:02:48.468502 10163 sgd_solver.cpp:106] Iteration 85900, lr = 2.86484e-05
I0827 10:02:52.745326 10163 solver.cpp:337] Iteration 86000, Testing net (#0)
I0827 10:02:56.349130 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 10:02:56.349187 10163 solver.cpp:404]     Test net output #1: loss = 1.09847 (* 1 = 1.09847 loss)
I0827 10:02:56.363816 10163 solver.cpp:228] Iteration 86000, loss = 1.10484
I0827 10:02:56.363870 10163 solver.cpp:244]     Train net output #0: loss = 1.10484 (* 1 = 1.10484 loss)
I0827 10:02:56.363883 10163 sgd_solver.cpp:106] Iteration 86000, lr = 2.86281e-05
I0827 10:03:00.683818 10163 solver.cpp:228] Iteration 86100, loss = 1.09673
I0827 10:03:00.683864 10163 solver.cpp:244]     Train net output #0: loss = 1.09673 (* 1 = 1.09673 loss)
I0827 10:03:00.683872 10163 sgd_solver.cpp:106] Iteration 86100, lr = 2.86079e-05
I0827 10:03:05.007673 10163 solver.cpp:228] Iteration 86200, loss = 1.10191
I0827 10:03:05.007694 10163 solver.cpp:244]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0827 10:03:05.007699 10163 sgd_solver.cpp:106] Iteration 86200, lr = 2.85877e-05
I0827 10:03:09.328891 10163 solver.cpp:228] Iteration 86300, loss = 1.10165
I0827 10:03:09.328933 10163 solver.cpp:244]     Train net output #0: loss = 1.10165 (* 1 = 1.10165 loss)
I0827 10:03:09.328938 10163 sgd_solver.cpp:106] Iteration 86300, lr = 2.85675e-05
I0827 10:03:13.654100 10163 solver.cpp:228] Iteration 86400, loss = 1.10074
I0827 10:03:13.654129 10163 solver.cpp:244]     Train net output #0: loss = 1.10074 (* 1 = 1.10074 loss)
I0827 10:03:13.654136 10163 sgd_solver.cpp:106] Iteration 86400, lr = 2.85474e-05
I0827 10:03:17.931450 10163 solver.cpp:337] Iteration 86500, Testing net (#0)
I0827 10:03:21.158953 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269417
I0827 10:03:21.158994 10163 solver.cpp:404]     Test net output #1: loss = 1.10015 (* 1 = 1.10015 loss)
I0827 10:03:21.173071 10163 solver.cpp:228] Iteration 86500, loss = 1.10843
I0827 10:03:21.173110 10163 solver.cpp:244]     Train net output #0: loss = 1.10843 (* 1 = 1.10843 loss)
I0827 10:03:21.173123 10163 sgd_solver.cpp:106] Iteration 86500, lr = 2.85273e-05
I0827 10:03:25.490346 10163 solver.cpp:228] Iteration 86600, loss = 1.09742
I0827 10:03:25.490386 10163 solver.cpp:244]     Train net output #0: loss = 1.09742 (* 1 = 1.09742 loss)
I0827 10:03:25.490391 10163 sgd_solver.cpp:106] Iteration 86600, lr = 2.85072e-05
I0827 10:03:29.813982 10163 solver.cpp:228] Iteration 86700, loss = 1.09448
I0827 10:03:29.814018 10163 solver.cpp:244]     Train net output #0: loss = 1.09448 (* 1 = 1.09448 loss)
I0827 10:03:29.814024 10163 sgd_solver.cpp:106] Iteration 86700, lr = 2.84872e-05
I0827 10:03:34.133033 10163 solver.cpp:228] Iteration 86800, loss = 1.09978
I0827 10:03:34.133093 10163 solver.cpp:244]     Train net output #0: loss = 1.09978 (* 1 = 1.09978 loss)
I0827 10:03:34.133100 10163 sgd_solver.cpp:106] Iteration 86800, lr = 2.84672e-05
I0827 10:03:38.460068 10163 solver.cpp:228] Iteration 86900, loss = 1.10035
I0827 10:03:38.460108 10163 solver.cpp:244]     Train net output #0: loss = 1.10035 (* 1 = 1.10035 loss)
I0827 10:03:38.460114 10163 sgd_solver.cpp:106] Iteration 86900, lr = 2.84472e-05
I0827 10:03:42.744011 10163 solver.cpp:337] Iteration 87000, Testing net (#0)
I0827 10:03:46.188511 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 10:03:46.188571 10163 solver.cpp:404]     Test net output #1: loss = 1.10165 (* 1 = 1.10165 loss)
I0827 10:03:46.203085 10163 solver.cpp:228] Iteration 87000, loss = 1.09661
I0827 10:03:46.203156 10163 solver.cpp:244]     Train net output #0: loss = 1.09661 (* 1 = 1.09661 loss)
I0827 10:03:46.203171 10163 sgd_solver.cpp:106] Iteration 87000, lr = 2.84272e-05
I0827 10:03:50.523090 10163 solver.cpp:228] Iteration 87100, loss = 1.10416
I0827 10:03:50.523130 10163 solver.cpp:244]     Train net output #0: loss = 1.10416 (* 1 = 1.10416 loss)
I0827 10:03:50.523136 10163 sgd_solver.cpp:106] Iteration 87100, lr = 2.84073e-05
I0827 10:03:54.844393 10163 solver.cpp:228] Iteration 87200, loss = 1.10179
I0827 10:03:54.844411 10163 solver.cpp:244]     Train net output #0: loss = 1.10179 (* 1 = 1.10179 loss)
I0827 10:03:54.844418 10163 sgd_solver.cpp:106] Iteration 87200, lr = 2.83875e-05
I0827 10:03:59.167034 10163 solver.cpp:228] Iteration 87300, loss = 1.10436
I0827 10:03:59.167074 10163 solver.cpp:244]     Train net output #0: loss = 1.10436 (* 1 = 1.10436 loss)
I0827 10:03:59.167080 10163 sgd_solver.cpp:106] Iteration 87300, lr = 2.83676e-05
I0827 10:04:03.489156 10163 solver.cpp:228] Iteration 87400, loss = 1.10072
I0827 10:04:03.489218 10163 solver.cpp:244]     Train net output #0: loss = 1.10072 (* 1 = 1.10072 loss)
I0827 10:04:03.489234 10163 sgd_solver.cpp:106] Iteration 87400, lr = 2.83478e-05
I0827 10:04:07.770041 10163 solver.cpp:337] Iteration 87500, Testing net (#0)
I0827 10:04:10.720702 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:04:11.028450 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 10:04:11.028496 10163 solver.cpp:404]     Test net output #1: loss = 1.10224 (* 1 = 1.10224 loss)
I0827 10:04:11.043359 10163 solver.cpp:228] Iteration 87500, loss = 1.10467
I0827 10:04:11.043380 10163 solver.cpp:244]     Train net output #0: loss = 1.10467 (* 1 = 1.10467 loss)
I0827 10:04:11.043395 10163 sgd_solver.cpp:106] Iteration 87500, lr = 2.8328e-05
I0827 10:04:15.369637 10163 solver.cpp:228] Iteration 87600, loss = 1.10185
I0827 10:04:15.369676 10163 solver.cpp:244]     Train net output #0: loss = 1.10185 (* 1 = 1.10185 loss)
I0827 10:04:15.369681 10163 sgd_solver.cpp:106] Iteration 87600, lr = 2.83083e-05
I0827 10:04:19.693783 10163 solver.cpp:228] Iteration 87700, loss = 1.1035
I0827 10:04:19.693836 10163 solver.cpp:244]     Train net output #0: loss = 1.1035 (* 1 = 1.1035 loss)
I0827 10:04:19.693846 10163 sgd_solver.cpp:106] Iteration 87700, lr = 2.82886e-05
I0827 10:04:24.012749 10163 solver.cpp:228] Iteration 87800, loss = 1.09945
I0827 10:04:24.012789 10163 solver.cpp:244]     Train net output #0: loss = 1.09945 (* 1 = 1.09945 loss)
I0827 10:04:24.012795 10163 sgd_solver.cpp:106] Iteration 87800, lr = 2.82689e-05
I0827 10:04:28.341426 10163 solver.cpp:228] Iteration 87900, loss = 1.09888
I0827 10:04:28.341488 10163 solver.cpp:244]     Train net output #0: loss = 1.09888 (* 1 = 1.09888 loss)
I0827 10:04:28.341495 10163 sgd_solver.cpp:106] Iteration 87900, lr = 2.82492e-05
I0827 10:04:32.621476 10163 solver.cpp:337] Iteration 88000, Testing net (#0)
I0827 10:04:35.842362 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 10:04:35.842478 10163 solver.cpp:404]     Test net output #1: loss = 1.10237 (* 1 = 1.10237 loss)
I0827 10:04:35.857720 10163 solver.cpp:228] Iteration 88000, loss = 1.09537
I0827 10:04:35.857784 10163 solver.cpp:244]     Train net output #0: loss = 1.09537 (* 1 = 1.09537 loss)
I0827 10:04:35.857798 10163 sgd_solver.cpp:106] Iteration 88000, lr = 2.82296e-05
I0827 10:04:40.181826 10163 solver.cpp:228] Iteration 88100, loss = 1.09461
I0827 10:04:40.181885 10163 solver.cpp:244]     Train net output #0: loss = 1.09461 (* 1 = 1.09461 loss)
I0827 10:04:40.181891 10163 sgd_solver.cpp:106] Iteration 88100, lr = 2.821e-05
I0827 10:04:44.510999 10163 solver.cpp:228] Iteration 88200, loss = 1.09762
I0827 10:04:44.511039 10163 solver.cpp:244]     Train net output #0: loss = 1.09762 (* 1 = 1.09762 loss)
I0827 10:04:44.511044 10163 sgd_solver.cpp:106] Iteration 88200, lr = 2.81905e-05
I0827 10:04:48.835995 10163 solver.cpp:228] Iteration 88300, loss = 1.09762
I0827 10:04:48.836040 10163 solver.cpp:244]     Train net output #0: loss = 1.09762 (* 1 = 1.09762 loss)
I0827 10:04:48.836045 10163 sgd_solver.cpp:106] Iteration 88300, lr = 2.81709e-05
I0827 10:04:53.159972 10163 solver.cpp:228] Iteration 88400, loss = 1.09294
I0827 10:04:53.160015 10163 solver.cpp:244]     Train net output #0: loss = 1.09294 (* 1 = 1.09294 loss)
I0827 10:04:53.160022 10163 sgd_solver.cpp:106] Iteration 88400, lr = 2.81514e-05
I0827 10:04:57.438549 10163 solver.cpp:337] Iteration 88500, Testing net (#0)
I0827 10:05:00.694399 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 10:05:00.694500 10163 solver.cpp:404]     Test net output #1: loss = 1.10272 (* 1 = 1.10272 loss)
I0827 10:05:00.708853 10163 solver.cpp:228] Iteration 88500, loss = 1.09621
I0827 10:05:00.708912 10163 solver.cpp:244]     Train net output #0: loss = 1.09621 (* 1 = 1.09621 loss)
I0827 10:05:00.708923 10163 sgd_solver.cpp:106] Iteration 88500, lr = 2.8132e-05
I0827 10:05:05.039304 10163 solver.cpp:228] Iteration 88600, loss = 1.09767
I0827 10:05:05.039362 10163 solver.cpp:244]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0827 10:05:05.039369 10163 sgd_solver.cpp:106] Iteration 88600, lr = 2.81125e-05
I0827 10:05:09.365772 10163 solver.cpp:228] Iteration 88700, loss = 1.09981
I0827 10:05:09.365815 10163 solver.cpp:244]     Train net output #0: loss = 1.09981 (* 1 = 1.09981 loss)
I0827 10:05:09.365821 10163 sgd_solver.cpp:106] Iteration 88700, lr = 2.80931e-05
I0827 10:05:13.689705 10163 solver.cpp:228] Iteration 88800, loss = 1.09195
I0827 10:05:13.689728 10163 solver.cpp:244]     Train net output #0: loss = 1.09195 (* 1 = 1.09195 loss)
I0827 10:05:13.689733 10163 sgd_solver.cpp:106] Iteration 88800, lr = 2.80738e-05
I0827 10:05:18.017947 10163 solver.cpp:228] Iteration 88900, loss = 1.10176
I0827 10:05:18.018005 10163 solver.cpp:244]     Train net output #0: loss = 1.10176 (* 1 = 1.10176 loss)
I0827 10:05:18.018012 10163 sgd_solver.cpp:106] Iteration 88900, lr = 2.80544e-05
I0827 10:05:22.301064 10163 solver.cpp:337] Iteration 89000, Testing net (#0)
I0827 10:05:25.874037 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 10:05:25.874142 10163 solver.cpp:404]     Test net output #1: loss = 1.10462 (* 1 = 1.10462 loss)
I0827 10:05:25.889787 10163 solver.cpp:228] Iteration 89000, loss = 1.09597
I0827 10:05:25.889837 10163 solver.cpp:244]     Train net output #0: loss = 1.09597 (* 1 = 1.09597 loss)
I0827 10:05:25.889847 10163 sgd_solver.cpp:106] Iteration 89000, lr = 2.80351e-05
I0827 10:05:30.221721 10163 solver.cpp:228] Iteration 89100, loss = 1.09794
I0827 10:05:30.221774 10163 solver.cpp:244]     Train net output #0: loss = 1.09794 (* 1 = 1.09794 loss)
I0827 10:05:30.221781 10163 sgd_solver.cpp:106] Iteration 89100, lr = 2.80159e-05
I0827 10:05:34.543790 10163 solver.cpp:228] Iteration 89200, loss = 1.10049
I0827 10:05:34.543829 10163 solver.cpp:244]     Train net output #0: loss = 1.10049 (* 1 = 1.10049 loss)
I0827 10:05:34.543836 10163 sgd_solver.cpp:106] Iteration 89200, lr = 2.79966e-05
I0827 10:05:38.863085 10163 solver.cpp:228] Iteration 89300, loss = 1.10308
I0827 10:05:38.863104 10163 solver.cpp:244]     Train net output #0: loss = 1.10308 (* 1 = 1.10308 loss)
I0827 10:05:38.863109 10163 sgd_solver.cpp:106] Iteration 89300, lr = 2.79774e-05
I0827 10:05:43.188290 10163 solver.cpp:228] Iteration 89400, loss = 1.1026
I0827 10:05:43.188343 10163 solver.cpp:244]     Train net output #0: loss = 1.1026 (* 1 = 1.1026 loss)
I0827 10:05:43.188349 10163 sgd_solver.cpp:106] Iteration 89400, lr = 2.79582e-05
I0827 10:05:47.471464 10163 solver.cpp:337] Iteration 89500, Testing net (#0)
I0827 10:05:50.726194 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152458
I0827 10:05:50.726260 10163 solver.cpp:404]     Test net output #1: loss = 1.10758 (* 1 = 1.10758 loss)
I0827 10:05:50.740872 10163 solver.cpp:228] Iteration 89500, loss = 1.0965
I0827 10:05:50.740902 10163 solver.cpp:244]     Train net output #0: loss = 1.0965 (* 1 = 1.0965 loss)
I0827 10:05:50.740911 10163 sgd_solver.cpp:106] Iteration 89500, lr = 2.79391e-05
I0827 10:05:55.062295 10163 solver.cpp:228] Iteration 89600, loss = 1.09799
I0827 10:05:55.062348 10163 solver.cpp:244]     Train net output #0: loss = 1.09799 (* 1 = 1.09799 loss)
I0827 10:05:55.062356 10163 sgd_solver.cpp:106] Iteration 89600, lr = 2.79199e-05
I0827 10:05:59.383950 10163 solver.cpp:228] Iteration 89700, loss = 1.09547
I0827 10:05:59.383968 10163 solver.cpp:244]     Train net output #0: loss = 1.09547 (* 1 = 1.09547 loss)
I0827 10:05:59.383973 10163 sgd_solver.cpp:106] Iteration 89700, lr = 2.79009e-05
I0827 10:06:03.704596 10163 solver.cpp:228] Iteration 89800, loss = 1.09935
I0827 10:06:03.704650 10163 solver.cpp:244]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0827 10:06:03.704656 10163 sgd_solver.cpp:106] Iteration 89800, lr = 2.78818e-05
I0827 10:06:08.035007 10163 solver.cpp:228] Iteration 89900, loss = 1.10374
I0827 10:06:08.035073 10163 solver.cpp:244]     Train net output #0: loss = 1.10374 (* 1 = 1.10374 loss)
I0827 10:06:08.035080 10163 sgd_solver.cpp:106] Iteration 89900, lr = 2.78628e-05
I0827 10:06:12.316761 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_90000.caffemodel
I0827 10:06:12.933744 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_90000.solverstate
I0827 10:06:13.127971 10163 solver.cpp:337] Iteration 90000, Testing net (#0)
I0827 10:06:15.327404 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:06:16.346248 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 10:06:16.346285 10163 solver.cpp:404]     Test net output #1: loss = 1.10872 (* 1 = 1.10872 loss)
I0827 10:06:16.361287 10163 solver.cpp:228] Iteration 90000, loss = 1.09505
I0827 10:06:16.361336 10163 solver.cpp:244]     Train net output #0: loss = 1.09505 (* 1 = 1.09505 loss)
I0827 10:06:16.361348 10163 sgd_solver.cpp:106] Iteration 90000, lr = 2.78438e-05
I0827 10:06:20.681813 10163 solver.cpp:228] Iteration 90100, loss = 1.09985
I0827 10:06:20.681869 10163 solver.cpp:244]     Train net output #0: loss = 1.09985 (* 1 = 1.09985 loss)
I0827 10:06:20.681875 10163 sgd_solver.cpp:106] Iteration 90100, lr = 2.78248e-05
I0827 10:06:25.004442 10163 solver.cpp:228] Iteration 90200, loss = 1.09921
I0827 10:06:25.004500 10163 solver.cpp:244]     Train net output #0: loss = 1.09921 (* 1 = 1.09921 loss)
I0827 10:06:25.004506 10163 sgd_solver.cpp:106] Iteration 90200, lr = 2.78059e-05
I0827 10:06:29.333498 10163 solver.cpp:228] Iteration 90300, loss = 1.09852
I0827 10:06:29.333560 10163 solver.cpp:244]     Train net output #0: loss = 1.09852 (* 1 = 1.09852 loss)
I0827 10:06:29.333566 10163 sgd_solver.cpp:106] Iteration 90300, lr = 2.77869e-05
I0827 10:06:33.656389 10163 solver.cpp:228] Iteration 90400, loss = 1.10003
I0827 10:06:33.656429 10163 solver.cpp:244]     Train net output #0: loss = 1.10003 (* 1 = 1.10003 loss)
I0827 10:06:33.656433 10163 sgd_solver.cpp:106] Iteration 90400, lr = 2.77681e-05
I0827 10:06:37.936058 10163 solver.cpp:337] Iteration 90500, Testing net (#0)
I0827 10:06:41.117820 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 10:06:41.117861 10163 solver.cpp:404]     Test net output #1: loss = 1.11171 (* 1 = 1.11171 loss)
I0827 10:06:41.131872 10163 solver.cpp:228] Iteration 90500, loss = 1.10148
I0827 10:06:41.131901 10163 solver.cpp:244]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0827 10:06:41.131911 10163 sgd_solver.cpp:106] Iteration 90500, lr = 2.77492e-05
I0827 10:06:45.461328 10163 solver.cpp:228] Iteration 90600, loss = 1.10838
I0827 10:06:45.461365 10163 solver.cpp:244]     Train net output #0: loss = 1.10838 (* 1 = 1.10838 loss)
I0827 10:06:45.461371 10163 sgd_solver.cpp:106] Iteration 90600, lr = 2.77304e-05
I0827 10:06:49.781186 10163 solver.cpp:228] Iteration 90700, loss = 1.09972
I0827 10:06:49.781204 10163 solver.cpp:244]     Train net output #0: loss = 1.09972 (* 1 = 1.09972 loss)
I0827 10:06:49.781209 10163 sgd_solver.cpp:106] Iteration 90700, lr = 2.77116e-05
I0827 10:06:54.109443 10163 solver.cpp:228] Iteration 90800, loss = 1.10268
I0827 10:06:54.109488 10163 solver.cpp:244]     Train net output #0: loss = 1.10268 (* 1 = 1.10268 loss)
I0827 10:06:54.109496 10163 sgd_solver.cpp:106] Iteration 90800, lr = 2.76929e-05
I0827 10:06:58.436523 10163 solver.cpp:228] Iteration 90900, loss = 1.09534
I0827 10:06:58.436564 10163 solver.cpp:244]     Train net output #0: loss = 1.09534 (* 1 = 1.09534 loss)
I0827 10:06:58.436570 10163 sgd_solver.cpp:106] Iteration 90900, lr = 2.76741e-05
I0827 10:07:02.720525 10163 solver.cpp:337] Iteration 91000, Testing net (#0)
I0827 10:07:06.079355 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 10:07:06.079413 10163 solver.cpp:404]     Test net output #1: loss = 1.11007 (* 1 = 1.11007 loss)
I0827 10:07:06.093503 10163 solver.cpp:228] Iteration 91000, loss = 1.09869
I0827 10:07:06.093545 10163 solver.cpp:244]     Train net output #0: loss = 1.09869 (* 1 = 1.09869 loss)
I0827 10:07:06.093559 10163 sgd_solver.cpp:106] Iteration 91000, lr = 2.76554e-05
I0827 10:07:10.419021 10163 solver.cpp:228] Iteration 91100, loss = 1.10097
I0827 10:07:10.419059 10163 solver.cpp:244]     Train net output #0: loss = 1.10097 (* 1 = 1.10097 loss)
I0827 10:07:10.419066 10163 sgd_solver.cpp:106] Iteration 91100, lr = 2.76367e-05
I0827 10:07:14.740420 10163 solver.cpp:228] Iteration 91200, loss = 1.09717
I0827 10:07:14.740478 10163 solver.cpp:244]     Train net output #0: loss = 1.09717 (* 1 = 1.09717 loss)
I0827 10:07:14.740483 10163 sgd_solver.cpp:106] Iteration 91200, lr = 2.76181e-05
I0827 10:07:19.073776 10163 solver.cpp:228] Iteration 91300, loss = 1.09855
I0827 10:07:19.073846 10163 solver.cpp:244]     Train net output #0: loss = 1.09855 (* 1 = 1.09855 loss)
I0827 10:07:19.073853 10163 sgd_solver.cpp:106] Iteration 91300, lr = 2.75995e-05
I0827 10:07:23.396492 10163 solver.cpp:228] Iteration 91400, loss = 1.09985
I0827 10:07:23.396530 10163 solver.cpp:244]     Train net output #0: loss = 1.09985 (* 1 = 1.09985 loss)
I0827 10:07:23.396535 10163 sgd_solver.cpp:106] Iteration 91400, lr = 2.75809e-05
I0827 10:07:27.672216 10163 solver.cpp:337] Iteration 91500, Testing net (#0)
I0827 10:07:30.857923 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 10:07:30.858029 10163 solver.cpp:404]     Test net output #1: loss = 1.10581 (* 1 = 1.10581 loss)
I0827 10:07:30.873261 10163 solver.cpp:228] Iteration 91500, loss = 1.09653
I0827 10:07:30.873337 10163 solver.cpp:244]     Train net output #0: loss = 1.09653 (* 1 = 1.09653 loss)
I0827 10:07:30.873359 10163 sgd_solver.cpp:106] Iteration 91500, lr = 2.75624e-05
I0827 10:07:35.197157 10163 solver.cpp:228] Iteration 91600, loss = 1.09917
I0827 10:07:35.197201 10163 solver.cpp:244]     Train net output #0: loss = 1.09917 (* 1 = 1.09917 loss)
I0827 10:07:35.197206 10163 sgd_solver.cpp:106] Iteration 91600, lr = 2.75438e-05
I0827 10:07:39.524180 10163 solver.cpp:228] Iteration 91700, loss = 1.09849
I0827 10:07:39.524224 10163 solver.cpp:244]     Train net output #0: loss = 1.09849 (* 1 = 1.09849 loss)
I0827 10:07:39.524230 10163 sgd_solver.cpp:106] Iteration 91700, lr = 2.75253e-05
I0827 10:07:43.855680 10163 solver.cpp:228] Iteration 91800, loss = 1.10132
I0827 10:07:43.855744 10163 solver.cpp:244]     Train net output #0: loss = 1.10132 (* 1 = 1.10132 loss)
I0827 10:07:43.855751 10163 sgd_solver.cpp:106] Iteration 91800, lr = 2.75069e-05
I0827 10:07:48.186632 10163 solver.cpp:228] Iteration 91900, loss = 1.09893
I0827 10:07:48.186681 10163 solver.cpp:244]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I0827 10:07:48.186689 10163 sgd_solver.cpp:106] Iteration 91900, lr = 2.74884e-05
I0827 10:07:52.467916 10163 solver.cpp:337] Iteration 92000, Testing net (#0)
I0827 10:07:56.090659 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152583
I0827 10:07:56.090725 10163 solver.cpp:404]     Test net output #1: loss = 1.10145 (* 1 = 1.10145 loss)
I0827 10:07:56.105541 10163 solver.cpp:228] Iteration 92000, loss = 1.09357
I0827 10:07:56.105584 10163 solver.cpp:244]     Train net output #0: loss = 1.09357 (* 1 = 1.09357 loss)
I0827 10:07:56.105602 10163 sgd_solver.cpp:106] Iteration 92000, lr = 2.747e-05
I0827 10:08:00.435660 10163 solver.cpp:228] Iteration 92100, loss = 1.0976
I0827 10:08:00.435725 10163 solver.cpp:244]     Train net output #0: loss = 1.0976 (* 1 = 1.0976 loss)
I0827 10:08:00.435732 10163 sgd_solver.cpp:106] Iteration 92100, lr = 2.74516e-05
I0827 10:08:04.756171 10163 solver.cpp:228] Iteration 92200, loss = 1.0969
I0827 10:08:04.756230 10163 solver.cpp:244]     Train net output #0: loss = 1.0969 (* 1 = 1.0969 loss)
I0827 10:08:04.756244 10163 sgd_solver.cpp:106] Iteration 92200, lr = 2.74333e-05
I0827 10:08:09.076994 10163 solver.cpp:228] Iteration 92300, loss = 1.10019
I0827 10:08:09.077054 10163 solver.cpp:244]     Train net output #0: loss = 1.10019 (* 1 = 1.10019 loss)
I0827 10:08:09.077061 10163 sgd_solver.cpp:106] Iteration 92300, lr = 2.7415e-05
I0827 10:08:13.406846 10163 solver.cpp:228] Iteration 92400, loss = 1.0992
I0827 10:08:13.406886 10163 solver.cpp:244]     Train net output #0: loss = 1.0992 (* 1 = 1.0992 loss)
I0827 10:08:13.406893 10163 sgd_solver.cpp:106] Iteration 92400, lr = 2.73967e-05
I0827 10:08:17.687867 10163 solver.cpp:337] Iteration 92500, Testing net (#0)
I0827 10:08:18.198796 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:08:21.202603 10163 solver.cpp:404]     Test net output #0: accuracy = 0.151958
I0827 10:08:21.202657 10163 solver.cpp:404]     Test net output #1: loss = 1.09826 (* 1 = 1.09826 loss)
I0827 10:08:21.218075 10163 solver.cpp:228] Iteration 92500, loss = 1.09973
I0827 10:08:21.218144 10163 solver.cpp:244]     Train net output #0: loss = 1.09973 (* 1 = 1.09973 loss)
I0827 10:08:21.218160 10163 sgd_solver.cpp:106] Iteration 92500, lr = 2.73784e-05
I0827 10:08:25.546705 10163 solver.cpp:228] Iteration 92600, loss = 1.10138
I0827 10:08:25.546752 10163 solver.cpp:244]     Train net output #0: loss = 1.10138 (* 1 = 1.10138 loss)
I0827 10:08:25.546758 10163 sgd_solver.cpp:106] Iteration 92600, lr = 2.73602e-05
I0827 10:08:29.876915 10163 solver.cpp:228] Iteration 92700, loss = 1.10224
I0827 10:08:29.876957 10163 solver.cpp:244]     Train net output #0: loss = 1.10224 (* 1 = 1.10224 loss)
I0827 10:08:29.876963 10163 sgd_solver.cpp:106] Iteration 92700, lr = 2.7342e-05
I0827 10:08:34.207078 10163 solver.cpp:228] Iteration 92800, loss = 1.09302
I0827 10:08:34.207124 10163 solver.cpp:244]     Train net output #0: loss = 1.09302 (* 1 = 1.09302 loss)
I0827 10:08:34.207142 10163 sgd_solver.cpp:106] Iteration 92800, lr = 2.73238e-05
I0827 10:08:38.536736 10163 solver.cpp:228] Iteration 92900, loss = 1.09857
I0827 10:08:38.536772 10163 solver.cpp:244]     Train net output #0: loss = 1.09857 (* 1 = 1.09857 loss)
I0827 10:08:38.536778 10163 sgd_solver.cpp:106] Iteration 92900, lr = 2.73056e-05
I0827 10:08:42.814790 10163 solver.cpp:337] Iteration 93000, Testing net (#0)
I0827 10:08:46.033622 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152417
I0827 10:08:46.033682 10163 solver.cpp:404]     Test net output #1: loss = 1.09854 (* 1 = 1.09854 loss)
I0827 10:08:46.053375 10163 solver.cpp:228] Iteration 93000, loss = 1.09661
I0827 10:08:46.053447 10163 solver.cpp:244]     Train net output #0: loss = 1.09661 (* 1 = 1.09661 loss)
I0827 10:08:46.053464 10163 sgd_solver.cpp:106] Iteration 93000, lr = 2.72875e-05
I0827 10:08:50.381748 10163 solver.cpp:228] Iteration 93100, loss = 1.09414
I0827 10:08:50.381798 10163 solver.cpp:244]     Train net output #0: loss = 1.09414 (* 1 = 1.09414 loss)
I0827 10:08:50.381805 10163 sgd_solver.cpp:106] Iteration 93100, lr = 2.72694e-05
I0827 10:08:54.703346 10163 solver.cpp:228] Iteration 93200, loss = 1.09687
I0827 10:08:54.703364 10163 solver.cpp:244]     Train net output #0: loss = 1.09687 (* 1 = 1.09687 loss)
I0827 10:08:54.703371 10163 sgd_solver.cpp:106] Iteration 93200, lr = 2.72513e-05
I0827 10:08:59.027884 10163 solver.cpp:228] Iteration 93300, loss = 1.09868
I0827 10:08:59.027926 10163 solver.cpp:244]     Train net output #0: loss = 1.09868 (* 1 = 1.09868 loss)
I0827 10:08:59.027931 10163 sgd_solver.cpp:106] Iteration 93300, lr = 2.72333e-05
I0827 10:09:03.352089 10163 solver.cpp:228] Iteration 93400, loss = 1.09722
I0827 10:09:03.352150 10163 solver.cpp:244]     Train net output #0: loss = 1.09722 (* 1 = 1.09722 loss)
I0827 10:09:03.352157 10163 sgd_solver.cpp:106] Iteration 93400, lr = 2.72153e-05
I0827 10:09:07.637748 10163 solver.cpp:337] Iteration 93500, Testing net (#0)
I0827 10:09:11.027235 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152125
I0827 10:09:11.027302 10163 solver.cpp:404]     Test net output #1: loss = 1.09854 (* 1 = 1.09854 loss)
I0827 10:09:11.041334 10163 solver.cpp:228] Iteration 93500, loss = 1.10198
I0827 10:09:11.041383 10163 solver.cpp:244]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0827 10:09:11.041391 10163 sgd_solver.cpp:106] Iteration 93500, lr = 2.71973e-05
I0827 10:09:15.370574 10163 solver.cpp:228] Iteration 93600, loss = 1.09932
I0827 10:09:15.370623 10163 solver.cpp:244]     Train net output #0: loss = 1.09932 (* 1 = 1.09932 loss)
I0827 10:09:15.370630 10163 sgd_solver.cpp:106] Iteration 93600, lr = 2.71793e-05
I0827 10:09:19.695484 10163 solver.cpp:228] Iteration 93700, loss = 1.1007
I0827 10:09:19.695544 10163 solver.cpp:244]     Train net output #0: loss = 1.1007 (* 1 = 1.1007 loss)
I0827 10:09:19.695551 10163 sgd_solver.cpp:106] Iteration 93700, lr = 2.71614e-05
I0827 10:09:24.014246 10163 solver.cpp:228] Iteration 93800, loss = 1.10067
I0827 10:09:24.014307 10163 solver.cpp:244]     Train net output #0: loss = 1.10067 (* 1 = 1.10067 loss)
I0827 10:09:24.014312 10163 sgd_solver.cpp:106] Iteration 93800, lr = 2.71435e-05
I0827 10:09:28.335997 10163 solver.cpp:228] Iteration 93900, loss = 1.09311
I0827 10:09:28.336045 10163 solver.cpp:244]     Train net output #0: loss = 1.09311 (* 1 = 1.09311 loss)
I0827 10:09:28.336051 10163 sgd_solver.cpp:106] Iteration 93900, lr = 2.71256e-05
I0827 10:09:32.618654 10163 solver.cpp:337] Iteration 94000, Testing net (#0)
I0827 10:09:35.691938 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15275
I0827 10:09:35.692000 10163 solver.cpp:404]     Test net output #1: loss = 1.09997 (* 1 = 1.09997 loss)
I0827 10:09:35.706851 10163 solver.cpp:228] Iteration 94000, loss = 1.10135
I0827 10:09:35.706909 10163 solver.cpp:244]     Train net output #0: loss = 1.10135 (* 1 = 1.10135 loss)
I0827 10:09:35.706923 10163 sgd_solver.cpp:106] Iteration 94000, lr = 2.71078e-05
I0827 10:09:40.034828 10163 solver.cpp:228] Iteration 94100, loss = 1.09634
I0827 10:09:40.034873 10163 solver.cpp:244]     Train net output #0: loss = 1.09634 (* 1 = 1.09634 loss)
I0827 10:09:40.034878 10163 sgd_solver.cpp:106] Iteration 94100, lr = 2.709e-05
I0827 10:09:44.360994 10163 solver.cpp:228] Iteration 94200, loss = 1.10055
I0827 10:09:44.361034 10163 solver.cpp:244]     Train net output #0: loss = 1.10055 (* 1 = 1.10055 loss)
I0827 10:09:44.361040 10163 sgd_solver.cpp:106] Iteration 94200, lr = 2.70722e-05
I0827 10:09:48.683184 10163 solver.cpp:228] Iteration 94300, loss = 1.09237
I0827 10:09:48.683235 10163 solver.cpp:244]     Train net output #0: loss = 1.09237 (* 1 = 1.09237 loss)
I0827 10:09:48.683248 10163 sgd_solver.cpp:106] Iteration 94300, lr = 2.70544e-05
I0827 10:09:53.010349 10163 solver.cpp:228] Iteration 94400, loss = 1.09476
I0827 10:09:53.010390 10163 solver.cpp:244]     Train net output #0: loss = 1.09476 (* 1 = 1.09476 loss)
I0827 10:09:53.010396 10163 sgd_solver.cpp:106] Iteration 94400, lr = 2.70367e-05
I0827 10:09:57.287623 10163 solver.cpp:337] Iteration 94500, Testing net (#0)
I0827 10:10:00.604856 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152167
I0827 10:10:00.604925 10163 solver.cpp:404]     Test net output #1: loss = 1.1022 (* 1 = 1.1022 loss)
I0827 10:10:00.619325 10163 solver.cpp:228] Iteration 94500, loss = 1.10644
I0827 10:10:00.619356 10163 solver.cpp:244]     Train net output #0: loss = 1.10644 (* 1 = 1.10644 loss)
I0827 10:10:00.619364 10163 sgd_solver.cpp:106] Iteration 94500, lr = 2.70189e-05
I0827 10:10:04.945857 10163 solver.cpp:228] Iteration 94600, loss = 1.09768
I0827 10:10:04.945904 10163 solver.cpp:244]     Train net output #0: loss = 1.09768 (* 1 = 1.09768 loss)
I0827 10:10:04.945911 10163 sgd_solver.cpp:106] Iteration 94600, lr = 2.70013e-05
I0827 10:10:09.267158 10163 solver.cpp:228] Iteration 94700, loss = 1.10079
I0827 10:10:09.267197 10163 solver.cpp:244]     Train net output #0: loss = 1.10079 (* 1 = 1.10079 loss)
I0827 10:10:09.267204 10163 sgd_solver.cpp:106] Iteration 94700, lr = 2.69836e-05
I0827 10:10:13.585325 10163 solver.cpp:228] Iteration 94800, loss = 1.1077
I0827 10:10:13.585366 10163 solver.cpp:244]     Train net output #0: loss = 1.1077 (* 1 = 1.1077 loss)
I0827 10:10:13.585372 10163 sgd_solver.cpp:106] Iteration 94800, lr = 2.6966e-05
I0827 10:10:17.900920 10163 solver.cpp:228] Iteration 94900, loss = 1.10372
I0827 10:10:17.900980 10163 solver.cpp:244]     Train net output #0: loss = 1.10372 (* 1 = 1.10372 loss)
I0827 10:10:17.900990 10163 sgd_solver.cpp:106] Iteration 94900, lr = 2.69484e-05
I0827 10:10:22.178593 10163 solver.cpp:337] Iteration 95000, Testing net (#0)
I0827 10:10:22.256714 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:10:25.421090 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152208
I0827 10:10:25.421139 10163 solver.cpp:404]     Test net output #1: loss = 1.10358 (* 1 = 1.10358 loss)
I0827 10:10:25.436264 10163 solver.cpp:228] Iteration 95000, loss = 1.09891
I0827 10:10:25.436326 10163 solver.cpp:244]     Train net output #0: loss = 1.09891 (* 1 = 1.09891 loss)
I0827 10:10:25.436342 10163 sgd_solver.cpp:106] Iteration 95000, lr = 2.69308e-05
I0827 10:10:29.760995 10163 solver.cpp:228] Iteration 95100, loss = 1.10254
I0827 10:10:29.761059 10163 solver.cpp:244]     Train net output #0: loss = 1.10254 (* 1 = 1.10254 loss)
I0827 10:10:29.761066 10163 sgd_solver.cpp:106] Iteration 95100, lr = 2.69132e-05
I0827 10:10:34.078452 10163 solver.cpp:228] Iteration 95200, loss = 1.09699
I0827 10:10:34.078512 10163 solver.cpp:244]     Train net output #0: loss = 1.09699 (* 1 = 1.09699 loss)
I0827 10:10:34.078519 10163 sgd_solver.cpp:106] Iteration 95200, lr = 2.68957e-05
I0827 10:10:38.399199 10163 solver.cpp:228] Iteration 95300, loss = 1.09981
I0827 10:10:38.399260 10163 solver.cpp:244]     Train net output #0: loss = 1.09981 (* 1 = 1.09981 loss)
I0827 10:10:38.399267 10163 sgd_solver.cpp:106] Iteration 95300, lr = 2.68782e-05
I0827 10:10:42.723345 10163 solver.cpp:228] Iteration 95400, loss = 1.09706
I0827 10:10:42.723402 10163 solver.cpp:244]     Train net output #0: loss = 1.09706 (* 1 = 1.09706 loss)
I0827 10:10:42.723408 10163 sgd_solver.cpp:106] Iteration 95400, lr = 2.68607e-05
I0827 10:10:46.999147 10163 solver.cpp:337] Iteration 95500, Testing net (#0)
I0827 10:10:50.519629 10163 solver.cpp:404]     Test net output #0: accuracy = 0.152375
I0827 10:10:50.519678 10163 solver.cpp:404]     Test net output #1: loss = 1.10364 (* 1 = 1.10364 loss)
I0827 10:10:50.533718 10163 solver.cpp:228] Iteration 95500, loss = 1.10426
I0827 10:10:50.533756 10163 solver.cpp:244]     Train net output #0: loss = 1.10426 (* 1 = 1.10426 loss)
I0827 10:10:50.533766 10163 sgd_solver.cpp:106] Iteration 95500, lr = 2.68433e-05
I0827 10:10:54.862293 10163 solver.cpp:228] Iteration 95600, loss = 1.10044
I0827 10:10:54.862337 10163 solver.cpp:244]     Train net output #0: loss = 1.10044 (* 1 = 1.10044 loss)
I0827 10:10:54.862344 10163 sgd_solver.cpp:106] Iteration 95600, lr = 2.68259e-05
I0827 10:10:59.183001 10163 solver.cpp:228] Iteration 95700, loss = 1.10287
I0827 10:10:59.183022 10163 solver.cpp:244]     Train net output #0: loss = 1.10287 (* 1 = 1.10287 loss)
I0827 10:10:59.183027 10163 sgd_solver.cpp:106] Iteration 95700, lr = 2.68085e-05
I0827 10:11:03.501593 10163 solver.cpp:228] Iteration 95800, loss = 1.10353
I0827 10:11:03.501615 10163 solver.cpp:244]     Train net output #0: loss = 1.10353 (* 1 = 1.10353 loss)
I0827 10:11:03.501619 10163 sgd_solver.cpp:106] Iteration 95800, lr = 2.67911e-05
I0827 10:11:07.821077 10163 solver.cpp:228] Iteration 95900, loss = 1.09408
I0827 10:11:07.821117 10163 solver.cpp:244]     Train net output #0: loss = 1.09408 (* 1 = 1.09408 loss)
I0827 10:11:07.821123 10163 sgd_solver.cpp:106] Iteration 95900, lr = 2.67738e-05
I0827 10:11:12.107652 10163 solver.cpp:337] Iteration 96000, Testing net (#0)
I0827 10:11:15.392006 10163 solver.cpp:404]     Test net output #0: accuracy = 0.15225
I0827 10:11:15.392067 10163 solver.cpp:404]     Test net output #1: loss = 1.10474 (* 1 = 1.10474 loss)
I0827 10:11:15.406939 10163 solver.cpp:228] Iteration 96000, loss = 1.09819
I0827 10:11:15.407001 10163 solver.cpp:244]     Train net output #0: loss = 1.09819 (* 1 = 1.09819 loss)
I0827 10:11:15.407013 10163 sgd_solver.cpp:106] Iteration 96000, lr = 2.67565e-05
I0827 10:11:19.733857 10163 solver.cpp:228] Iteration 96100, loss = 1.10039
I0827 10:11:19.733896 10163 solver.cpp:244]     Train net output #0: loss = 1.10039 (* 1 = 1.10039 loss)
I0827 10:11:19.733902 10163 sgd_solver.cpp:106] Iteration 96100, lr = 2.67392e-05
I0827 10:11:24.064469 10163 solver.cpp:228] Iteration 96200, loss = 1.10096
I0827 10:11:24.064530 10163 solver.cpp:244]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0827 10:11:24.064539 10163 sgd_solver.cpp:106] Iteration 96200, lr = 2.67219e-05
I0827 10:11:28.388753 10163 solver.cpp:228] Iteration 96300, loss = 1.09463
I0827 10:11:28.388810 10163 solver.cpp:244]     Train net output #0: loss = 1.09463 (* 1 = 1.09463 loss)
I0827 10:11:28.388818 10163 sgd_solver.cpp:106] Iteration 96300, lr = 2.67047e-05
I0827 10:11:32.720739 10163 solver.cpp:228] Iteration 96400, loss = 1.10413
I0827 10:11:32.720794 10163 solver.cpp:244]     Train net output #0: loss = 1.10413 (* 1 = 1.10413 loss)
I0827 10:11:32.720803 10163 sgd_solver.cpp:106] Iteration 96400, lr = 2.66875e-05
I0827 10:11:37.000717 10163 solver.cpp:337] Iteration 96500, Testing net (#0)
I0827 10:11:40.603878 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269167
I0827 10:11:40.603930 10163 solver.cpp:404]     Test net output #1: loss = 1.10169 (* 1 = 1.10169 loss)
I0827 10:11:40.618733 10163 solver.cpp:228] Iteration 96500, loss = 1.10325
I0827 10:11:40.618778 10163 solver.cpp:244]     Train net output #0: loss = 1.10325 (* 1 = 1.10325 loss)
I0827 10:11:40.618793 10163 sgd_solver.cpp:106] Iteration 96500, lr = 2.66703e-05
I0827 10:11:44.944015 10163 solver.cpp:228] Iteration 96600, loss = 1.10336
I0827 10:11:44.944047 10163 solver.cpp:244]     Train net output #0: loss = 1.10336 (* 1 = 1.10336 loss)
I0827 10:11:44.944053 10163 sgd_solver.cpp:106] Iteration 96600, lr = 2.66532e-05
I0827 10:11:49.269007 10163 solver.cpp:228] Iteration 96700, loss = 1.10206
I0827 10:11:49.269047 10163 solver.cpp:244]     Train net output #0: loss = 1.10206 (* 1 = 1.10206 loss)
I0827 10:11:49.269053 10163 sgd_solver.cpp:106] Iteration 96700, lr = 2.6636e-05
I0827 10:11:53.590100 10163 solver.cpp:228] Iteration 96800, loss = 1.09946
I0827 10:11:53.590153 10163 solver.cpp:244]     Train net output #0: loss = 1.09946 (* 1 = 1.09946 loss)
I0827 10:11:53.590160 10163 sgd_solver.cpp:106] Iteration 96800, lr = 2.66189e-05
I0827 10:11:57.913270 10163 solver.cpp:228] Iteration 96900, loss = 1.10095
I0827 10:11:57.913336 10163 solver.cpp:244]     Train net output #0: loss = 1.10095 (* 1 = 1.10095 loss)
I0827 10:11:57.913343 10163 sgd_solver.cpp:106] Iteration 96900, lr = 2.66018e-05
I0827 10:12:02.193636 10163 solver.cpp:337] Iteration 97000, Testing net (#0)
I0827 10:12:05.366374 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269333
I0827 10:12:05.366417 10163 solver.cpp:404]     Test net output #1: loss = 1.09667 (* 1 = 1.09667 loss)
I0827 10:12:05.380563 10163 solver.cpp:228] Iteration 97000, loss = 1.09654
I0827 10:12:05.380606 10163 solver.cpp:244]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0827 10:12:05.380616 10163 sgd_solver.cpp:106] Iteration 97000, lr = 2.65848e-05
I0827 10:12:09.706140 10163 solver.cpp:228] Iteration 97100, loss = 1.09675
I0827 10:12:09.706179 10163 solver.cpp:244]     Train net output #0: loss = 1.09675 (* 1 = 1.09675 loss)
I0827 10:12:09.706185 10163 sgd_solver.cpp:106] Iteration 97100, lr = 2.65678e-05
I0827 10:12:14.035230 10163 solver.cpp:228] Iteration 97200, loss = 1.10284
I0827 10:12:14.035280 10163 solver.cpp:244]     Train net output #0: loss = 1.10284 (* 1 = 1.10284 loss)
I0827 10:12:14.035290 10163 sgd_solver.cpp:106] Iteration 97200, lr = 2.65507e-05
I0827 10:12:18.360815 10163 solver.cpp:228] Iteration 97300, loss = 1.1013
I0827 10:12:18.360837 10163 solver.cpp:244]     Train net output #0: loss = 1.1013 (* 1 = 1.1013 loss)
I0827 10:12:18.360843 10163 sgd_solver.cpp:106] Iteration 97300, lr = 2.65338e-05
I0827 10:12:22.684545 10163 solver.cpp:228] Iteration 97400, loss = 1.09245
I0827 10:12:22.684590 10163 solver.cpp:244]     Train net output #0: loss = 1.09245 (* 1 = 1.09245 loss)
I0827 10:12:22.684597 10163 sgd_solver.cpp:106] Iteration 97400, lr = 2.65168e-05
I0827 10:12:26.969770 10163 solver.cpp:337] Iteration 97500, Testing net (#0)
I0827 10:12:30.266166 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269125
I0827 10:12:30.266207 10163 solver.cpp:404]     Test net output #1: loss = 1.09368 (* 1 = 1.09368 loss)
I0827 10:12:30.280380 10163 solver.cpp:228] Iteration 97500, loss = 1.10407
I0827 10:12:30.280419 10163 solver.cpp:244]     Train net output #0: loss = 1.10407 (* 1 = 1.10407 loss)
I0827 10:12:30.280427 10163 sgd_solver.cpp:106] Iteration 97500, lr = 2.64999e-05
I0827 10:12:34.607048 10163 solver.cpp:228] Iteration 97600, loss = 1.10153
I0827 10:12:34.607108 10163 solver.cpp:244]     Train net output #0: loss = 1.10153 (* 1 = 1.10153 loss)
I0827 10:12:34.607115 10163 sgd_solver.cpp:106] Iteration 97600, lr = 2.6483e-05
I0827 10:12:38.931797 10163 solver.cpp:228] Iteration 97700, loss = 1.09375
I0827 10:12:38.931854 10163 solver.cpp:244]     Train net output #0: loss = 1.09375 (* 1 = 1.09375 loss)
I0827 10:12:38.931860 10163 sgd_solver.cpp:106] Iteration 97700, lr = 2.64661e-05
I0827 10:12:43.256062 10163 solver.cpp:228] Iteration 97800, loss = 1.10169
I0827 10:12:43.256121 10163 solver.cpp:244]     Train net output #0: loss = 1.10169 (* 1 = 1.10169 loss)
I0827 10:12:43.256129 10163 sgd_solver.cpp:106] Iteration 97800, lr = 2.64493e-05
I0827 10:12:44.898502 10163 blocking_queue.cpp:50] Data layer prefetch queue empty
I0827 10:12:47.583173 10163 solver.cpp:228] Iteration 97900, loss = 1.10343
I0827 10:12:47.583214 10163 solver.cpp:244]     Train net output #0: loss = 1.10343 (* 1 = 1.10343 loss)
I0827 10:12:47.583220 10163 sgd_solver.cpp:106] Iteration 97900, lr = 2.64324e-05
I0827 10:12:51.859411 10163 solver.cpp:337] Iteration 98000, Testing net (#0)
I0827 10:12:55.290995 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269583
I0827 10:12:55.291056 10163 solver.cpp:404]     Test net output #1: loss = 1.09219 (* 1 = 1.09219 loss)
I0827 10:12:55.307657 10163 solver.cpp:228] Iteration 98000, loss = 1.09342
I0827 10:12:55.307723 10163 solver.cpp:244]     Train net output #0: loss = 1.09342 (* 1 = 1.09342 loss)
I0827 10:12:55.307739 10163 sgd_solver.cpp:106] Iteration 98000, lr = 2.64156e-05
I0827 10:12:59.631702 10163 solver.cpp:228] Iteration 98100, loss = 1.10076
I0827 10:12:59.631755 10163 solver.cpp:244]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0827 10:12:59.631763 10163 sgd_solver.cpp:106] Iteration 98100, lr = 2.63989e-05
I0827 10:13:03.954278 10163 solver.cpp:228] Iteration 98200, loss = 1.09662
I0827 10:13:03.954320 10163 solver.cpp:244]     Train net output #0: loss = 1.09662 (* 1 = 1.09662 loss)
I0827 10:13:03.954326 10163 sgd_solver.cpp:106] Iteration 98200, lr = 2.63821e-05
I0827 10:13:08.269075 10163 solver.cpp:228] Iteration 98300, loss = 1.09399
I0827 10:13:08.269095 10163 solver.cpp:244]     Train net output #0: loss = 1.09399 (* 1 = 1.09399 loss)
I0827 10:13:08.269100 10163 sgd_solver.cpp:106] Iteration 98300, lr = 2.63654e-05
I0827 10:13:12.585202 10163 solver.cpp:228] Iteration 98400, loss = 1.10275
I0827 10:13:12.585222 10163 solver.cpp:244]     Train net output #0: loss = 1.10275 (* 1 = 1.10275 loss)
I0827 10:13:12.585228 10163 sgd_solver.cpp:106] Iteration 98400, lr = 2.63487e-05
I0827 10:13:16.859758 10163 solver.cpp:337] Iteration 98500, Testing net (#0)
I0827 10:13:20.105339 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269042
I0827 10:13:20.105396 10163 solver.cpp:404]     Test net output #1: loss = 1.09246 (* 1 = 1.09246 loss)
I0827 10:13:20.120743 10163 solver.cpp:228] Iteration 98500, loss = 1.10276
I0827 10:13:20.120815 10163 solver.cpp:244]     Train net output #0: loss = 1.10276 (* 1 = 1.10276 loss)
I0827 10:13:20.120836 10163 sgd_solver.cpp:106] Iteration 98500, lr = 2.6332e-05
I0827 10:13:24.446518 10163 solver.cpp:228] Iteration 98600, loss = 1.09404
I0827 10:13:24.446596 10163 solver.cpp:244]     Train net output #0: loss = 1.09404 (* 1 = 1.09404 loss)
I0827 10:13:24.446609 10163 sgd_solver.cpp:106] Iteration 98600, lr = 2.63153e-05
I0827 10:13:28.768345 10163 solver.cpp:228] Iteration 98700, loss = 1.09265
I0827 10:13:28.768389 10163 solver.cpp:244]     Train net output #0: loss = 1.09265 (* 1 = 1.09265 loss)
I0827 10:13:28.768395 10163 sgd_solver.cpp:106] Iteration 98700, lr = 2.62987e-05
I0827 10:13:33.086164 10163 solver.cpp:228] Iteration 98800, loss = 1.10672
I0827 10:13:33.086185 10163 solver.cpp:244]     Train net output #0: loss = 1.10672 (* 1 = 1.10672 loss)
I0827 10:13:33.086190 10163 sgd_solver.cpp:106] Iteration 98800, lr = 2.62821e-05
I0827 10:13:37.406601 10163 solver.cpp:228] Iteration 98900, loss = 1.09996
I0827 10:13:37.406638 10163 solver.cpp:244]     Train net output #0: loss = 1.09996 (* 1 = 1.09996 loss)
I0827 10:13:37.406643 10163 sgd_solver.cpp:106] Iteration 98900, lr = 2.62655e-05
I0827 10:13:41.687897 10163 solver.cpp:337] Iteration 99000, Testing net (#0)
I0827 10:13:44.937008 10163 solver.cpp:404]     Test net output #0: accuracy = 0.269542
I0827 10:13:44.937065 10163 solver.cpp:404]     Test net output #1: loss = 1.09279 (* 1 = 1.09279 loss)
I0827 10:13:44.951256 10163 solver.cpp:228] Iteration 99000, loss = 1.10019
I0827 10:13:44.951318 10163 solver.cpp:244]     Train net output #0: loss = 1.10019 (* 1 = 1.10019 loss)
I0827 10:13:44.951340 10163 sgd_solver.cpp:106] Iteration 99000, lr = 2.6249e-05
I0827 10:13:49.282481 10163 solver.cpp:228] Iteration 99100, loss = 1.10374
I0827 10:13:49.282538 10163 solver.cpp:244]     Train net output #0: loss = 1.10374 (* 1 = 1.10374 loss)
I0827 10:13:49.282548 10163 sgd_solver.cpp:106] Iteration 99100, lr = 2.62324e-05
I0827 10:13:53.605953 10163 solver.cpp:228] Iteration 99200, loss = 1.10543
I0827 10:13:53.606014 10163 solver.cpp:244]     Train net output #0: loss = 1.10543 (* 1 = 1.10543 loss)
I0827 10:13:53.606022 10163 sgd_solver.cpp:106] Iteration 99200, lr = 2.62159e-05
I0827 10:13:57.932890 10163 solver.cpp:228] Iteration 99300, loss = 1.09573
I0827 10:13:57.932951 10163 solver.cpp:244]     Train net output #0: loss = 1.09573 (* 1 = 1.09573 loss)
I0827 10:13:57.932957 10163 sgd_solver.cpp:106] Iteration 99300, lr = 2.61995e-05
I0827 10:14:02.253895 10163 solver.cpp:228] Iteration 99400, loss = 1.09192
I0827 10:14:02.253933 10163 solver.cpp:244]     Train net output #0: loss = 1.09192 (* 1 = 1.09192 loss)
I0827 10:14:02.253939 10163 sgd_solver.cpp:106] Iteration 99400, lr = 2.6183e-05
I0827 10:14:06.533257 10163 solver.cpp:337] Iteration 99500, Testing net (#0)
I0827 10:14:10.021262 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578417
I0827 10:14:10.021314 10163 solver.cpp:404]     Test net output #1: loss = 1.09288 (* 1 = 1.09288 loss)
I0827 10:14:10.035928 10163 solver.cpp:228] Iteration 99500, loss = 1.09685
I0827 10:14:10.035960 10163 solver.cpp:244]     Train net output #0: loss = 1.09685 (* 1 = 1.09685 loss)
I0827 10:14:10.035974 10163 sgd_solver.cpp:106] Iteration 99500, lr = 2.61666e-05
I0827 10:14:14.363834 10163 solver.cpp:228] Iteration 99600, loss = 1.09459
I0827 10:14:14.363870 10163 solver.cpp:244]     Train net output #0: loss = 1.09459 (* 1 = 1.09459 loss)
I0827 10:14:14.363878 10163 sgd_solver.cpp:106] Iteration 99600, lr = 2.61501e-05
I0827 10:14:18.686417 10163 solver.cpp:228] Iteration 99700, loss = 1.1013
I0827 10:14:18.686456 10163 solver.cpp:244]     Train net output #0: loss = 1.1013 (* 1 = 1.1013 loss)
I0827 10:14:18.686462 10163 sgd_solver.cpp:106] Iteration 99700, lr = 2.61338e-05
I0827 10:14:23.021661 10163 solver.cpp:228] Iteration 99800, loss = 1.10052
I0827 10:14:23.021703 10163 solver.cpp:244]     Train net output #0: loss = 1.10052 (* 1 = 1.10052 loss)
I0827 10:14:23.021709 10163 sgd_solver.cpp:106] Iteration 99800, lr = 2.61174e-05
I0827 10:14:27.345552 10163 solver.cpp:228] Iteration 99900, loss = 1.10131
I0827 10:14:27.345594 10163 solver.cpp:244]     Train net output #0: loss = 1.10131 (* 1 = 1.10131 loss)
I0827 10:14:27.345600 10163 sgd_solver.cpp:106] Iteration 99900, lr = 2.61011e-05
I0827 10:14:31.626480 10163 solver.cpp:454] Snapshotting to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_100000.caffemodel
I0827 10:14:32.101994 10163 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.0001_iter_100000.solverstate
I0827 10:14:32.257585 10163 solver.cpp:337] Iteration 100000, Testing net (#0)
I0827 10:14:35.659648 10163 solver.cpp:404]     Test net output #0: accuracy = 0.578334
I0827 10:14:35.659713 10163 solver.cpp:404]     Test net output #1: loss = 1.09195 (* 1 = 1.09195 loss)
I0827 10:14:35.674216 10163 solver.cpp:228] Iteration 100000, loss = 1.09467
I0827 10:14:35.674244 10163 solver.cpp:244]     Train net output #0: loss = 1.09467 (* 1 = 1.09467 loss)
I0827 10:14:35.674257 10163 sgd_solver.cpp:106] Iteration 100000, lr = 2.60847e-05
nets/person_vs_background_vs_random_caffe_net/solver.prototxt
