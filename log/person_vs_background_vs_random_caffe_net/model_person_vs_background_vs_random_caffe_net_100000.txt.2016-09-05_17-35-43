WARNING: Logging before InitGoogleLogging() is written to STDERR
I0905 17:35:45.886927 13268 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 40000
lr_policy: "inv"
gamma: 5e-05
power: 0.75
momentum: 0.9
weight_decay: 2e-05
stepsize: 10000
snapshot: 10000
snapshot_prefix: "models/person_vs_background_vs_random_caffe_net/person_vs_background_vs_random_alex_net_pre_trained__lr_0.1"
solver_mode: GPU
net: "nets/person_vs_background_vs_random_caffe_net/trainval.prototxt"
I0905 17:35:45.887066 13268 solver.cpp:91] Creating training net from net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0905 17:35:45.887707 13268 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0905 17:35:45.887734 13268 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0905 17:35:45.887915 13268 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0905 17:35:45.888016 13268 layer_factory.hpp:77] Creating layer data
I0905 17:35:45.889348 13268 net.cpp:100] Creating Layer data
I0905 17:35:45.889369 13268 net.cpp:408] data -> data
I0905 17:35:45.889389 13268 net.cpp:408] data -> label
I0905 17:35:45.889503 13268 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0905 17:35:45.891029 13309 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_train_lmdb
I0905 17:35:45.918858 13268 data_layer.cpp:41] output data size: 128,3,128,128
I0905 17:35:45.975394 13268 net.cpp:150] Setting up data
I0905 17:35:45.975498 13268 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0905 17:35:45.975538 13268 net.cpp:157] Top shape: 128 (128)
I0905 17:35:45.975548 13268 net.cpp:165] Memory required for data: 25166336
I0905 17:35:45.975558 13268 layer_factory.hpp:77] Creating layer conv1
I0905 17:35:45.975589 13268 net.cpp:100] Creating Layer conv1
I0905 17:35:45.975597 13268 net.cpp:434] conv1 <- data
I0905 17:35:45.975617 13268 net.cpp:408] conv1 -> conv1
I0905 17:35:46.280474 13268 net.cpp:150] Setting up conv1
I0905 17:35:46.280513 13268 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0905 17:35:46.280519 13268 net.cpp:165] Memory required for data: 69403136
I0905 17:35:46.280541 13268 layer_factory.hpp:77] Creating layer relu1
I0905 17:35:46.280555 13268 net.cpp:100] Creating Layer relu1
I0905 17:35:46.280560 13268 net.cpp:434] relu1 <- conv1
I0905 17:35:46.280566 13268 net.cpp:395] relu1 -> conv1 (in-place)
I0905 17:35:46.280776 13268 net.cpp:150] Setting up relu1
I0905 17:35:46.280796 13268 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0905 17:35:46.280802 13268 net.cpp:165] Memory required for data: 113639936
I0905 17:35:46.280807 13268 layer_factory.hpp:77] Creating layer pool1
I0905 17:35:46.280822 13268 net.cpp:100] Creating Layer pool1
I0905 17:35:46.280830 13268 net.cpp:434] pool1 <- conv1
I0905 17:35:46.280846 13268 net.cpp:408] pool1 -> pool1
I0905 17:35:46.280901 13268 net.cpp:150] Setting up pool1
I0905 17:35:46.280912 13268 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0905 17:35:46.280916 13268 net.cpp:165] Memory required for data: 124699136
I0905 17:35:46.280920 13268 layer_factory.hpp:77] Creating layer norm1
I0905 17:35:46.280931 13268 net.cpp:100] Creating Layer norm1
I0905 17:35:46.280935 13268 net.cpp:434] norm1 <- pool1
I0905 17:35:46.280941 13268 net.cpp:408] norm1 -> norm1
I0905 17:35:46.281503 13268 net.cpp:150] Setting up norm1
I0905 17:35:46.281522 13268 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0905 17:35:46.281527 13268 net.cpp:165] Memory required for data: 135758336
I0905 17:35:46.281530 13268 layer_factory.hpp:77] Creating layer conv2
I0905 17:35:46.281543 13268 net.cpp:100] Creating Layer conv2
I0905 17:35:46.281548 13268 net.cpp:434] conv2 <- norm1
I0905 17:35:46.281554 13268 net.cpp:408] conv2 -> conv2
I0905 17:35:46.295228 13268 net.cpp:150] Setting up conv2
I0905 17:35:46.295248 13268 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0905 17:35:46.295253 13268 net.cpp:165] Memory required for data: 165249536
I0905 17:35:46.295264 13268 layer_factory.hpp:77] Creating layer relu2
I0905 17:35:46.295271 13268 net.cpp:100] Creating Layer relu2
I0905 17:35:46.295275 13268 net.cpp:434] relu2 <- conv2
I0905 17:35:46.295280 13268 net.cpp:395] relu2 -> conv2 (in-place)
I0905 17:35:46.295799 13268 net.cpp:150] Setting up relu2
I0905 17:35:46.295817 13268 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0905 17:35:46.295821 13268 net.cpp:165] Memory required for data: 194740736
I0905 17:35:46.295825 13268 layer_factory.hpp:77] Creating layer pool2
I0905 17:35:46.295833 13268 net.cpp:100] Creating Layer pool2
I0905 17:35:46.295840 13268 net.cpp:434] pool2 <- conv2
I0905 17:35:46.295845 13268 net.cpp:408] pool2 -> pool2
I0905 17:35:46.295914 13268 net.cpp:150] Setting up pool2
I0905 17:35:46.295924 13268 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0905 17:35:46.295928 13268 net.cpp:165] Memory required for data: 201163264
I0905 17:35:46.295931 13268 layer_factory.hpp:77] Creating layer norm2
I0905 17:35:46.295939 13268 net.cpp:100] Creating Layer norm2
I0905 17:35:46.295943 13268 net.cpp:434] norm2 <- pool2
I0905 17:35:46.295950 13268 net.cpp:408] norm2 -> norm2
I0905 17:35:46.296171 13268 net.cpp:150] Setting up norm2
I0905 17:35:46.296185 13268 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0905 17:35:46.296190 13268 net.cpp:165] Memory required for data: 207585792
I0905 17:35:46.296192 13268 layer_factory.hpp:77] Creating layer conv3
I0905 17:35:46.296205 13268 net.cpp:100] Creating Layer conv3
I0905 17:35:46.296208 13268 net.cpp:434] conv3 <- norm2
I0905 17:35:46.296216 13268 net.cpp:408] conv3 -> conv3
I0905 17:35:46.330631 13268 net.cpp:150] Setting up conv3
I0905 17:35:46.330649 13268 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0905 17:35:46.330653 13268 net.cpp:165] Memory required for data: 217219584
I0905 17:35:46.330665 13268 layer_factory.hpp:77] Creating layer relu3
I0905 17:35:46.330674 13268 net.cpp:100] Creating Layer relu3
I0905 17:35:46.330678 13268 net.cpp:434] relu3 <- conv3
I0905 17:35:46.330684 13268 net.cpp:395] relu3 -> conv3 (in-place)
I0905 17:35:46.330901 13268 net.cpp:150] Setting up relu3
I0905 17:35:46.330921 13268 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0905 17:35:46.330929 13268 net.cpp:165] Memory required for data: 226853376
I0905 17:35:46.330935 13268 layer_factory.hpp:77] Creating layer conv4
I0905 17:35:46.330950 13268 net.cpp:100] Creating Layer conv4
I0905 17:35:46.330953 13268 net.cpp:434] conv4 <- conv3
I0905 17:35:46.330960 13268 net.cpp:408] conv4 -> conv4
I0905 17:35:46.358016 13268 net.cpp:150] Setting up conv4
I0905 17:35:46.358036 13268 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0905 17:35:46.358041 13268 net.cpp:165] Memory required for data: 236487168
I0905 17:35:46.358048 13268 layer_factory.hpp:77] Creating layer relu4
I0905 17:35:46.358057 13268 net.cpp:100] Creating Layer relu4
I0905 17:35:46.358060 13268 net.cpp:434] relu4 <- conv4
I0905 17:35:46.358067 13268 net.cpp:395] relu4 -> conv4 (in-place)
I0905 17:35:46.358274 13268 net.cpp:150] Setting up relu4
I0905 17:35:46.358289 13268 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0905 17:35:46.358292 13268 net.cpp:165] Memory required for data: 246120960
I0905 17:35:46.358295 13268 layer_factory.hpp:77] Creating layer conv5
I0905 17:35:46.358307 13268 net.cpp:100] Creating Layer conv5
I0905 17:35:46.358311 13268 net.cpp:434] conv5 <- conv4
I0905 17:35:46.358319 13268 net.cpp:408] conv5 -> conv5
I0905 17:35:46.377408 13268 net.cpp:150] Setting up conv5
I0905 17:35:46.377425 13268 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0905 17:35:46.377430 13268 net.cpp:165] Memory required for data: 252543488
I0905 17:35:46.377441 13268 layer_factory.hpp:77] Creating layer relu5
I0905 17:35:46.377451 13268 net.cpp:100] Creating Layer relu5
I0905 17:35:46.377455 13268 net.cpp:434] relu5 <- conv5
I0905 17:35:46.377460 13268 net.cpp:395] relu5 -> conv5 (in-place)
I0905 17:35:46.377670 13268 net.cpp:150] Setting up relu5
I0905 17:35:46.377691 13268 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0905 17:35:46.377699 13268 net.cpp:165] Memory required for data: 258966016
I0905 17:35:46.377706 13268 layer_factory.hpp:77] Creating layer pool5
I0905 17:35:46.377713 13268 net.cpp:100] Creating Layer pool5
I0905 17:35:46.377717 13268 net.cpp:434] pool5 <- conv5
I0905 17:35:46.377724 13268 net.cpp:408] pool5 -> pool5
I0905 17:35:46.377789 13268 net.cpp:150] Setting up pool5
I0905 17:35:46.377802 13268 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0905 17:35:46.377805 13268 net.cpp:165] Memory required for data: 260145664
I0905 17:35:46.377810 13268 layer_factory.hpp:77] Creating layer fc6n
I0905 17:35:46.377821 13268 net.cpp:100] Creating Layer fc6n
I0905 17:35:46.377825 13268 net.cpp:434] fc6n <- pool5
I0905 17:35:46.377835 13268 net.cpp:408] fc6n -> fc6
I0905 17:35:46.724380 13268 net.cpp:150] Setting up fc6n
I0905 17:35:46.724414 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:46.724417 13268 net.cpp:165] Memory required for data: 262242816
I0905 17:35:46.724427 13268 layer_factory.hpp:77] Creating layer relu6
I0905 17:35:46.724437 13268 net.cpp:100] Creating Layer relu6
I0905 17:35:46.724442 13268 net.cpp:434] relu6 <- fc6
I0905 17:35:46.724449 13268 net.cpp:395] relu6 -> fc6 (in-place)
I0905 17:35:46.725081 13268 net.cpp:150] Setting up relu6
I0905 17:35:46.725095 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:46.725097 13268 net.cpp:165] Memory required for data: 264339968
I0905 17:35:46.725100 13268 layer_factory.hpp:77] Creating layer drop6
I0905 17:35:46.725108 13268 net.cpp:100] Creating Layer drop6
I0905 17:35:46.725111 13268 net.cpp:434] drop6 <- fc6
I0905 17:35:46.725117 13268 net.cpp:395] drop6 -> fc6 (in-place)
I0905 17:35:46.725152 13268 net.cpp:150] Setting up drop6
I0905 17:35:46.725157 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:46.725159 13268 net.cpp:165] Memory required for data: 266437120
I0905 17:35:46.725162 13268 layer_factory.hpp:77] Creating layer fc7n
I0905 17:35:46.725170 13268 net.cpp:100] Creating Layer fc7n
I0905 17:35:46.725173 13268 net.cpp:434] fc7n <- fc6
I0905 17:35:46.725178 13268 net.cpp:408] fc7n -> fc7
I0905 17:35:47.312587 13268 net.cpp:150] Setting up fc7n
I0905 17:35:47.312623 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:47.312626 13268 net.cpp:165] Memory required for data: 268534272
I0905 17:35:47.312636 13268 layer_factory.hpp:77] Creating layer relu7
I0905 17:35:47.312646 13268 net.cpp:100] Creating Layer relu7
I0905 17:35:47.312650 13268 net.cpp:434] relu7 <- fc7
I0905 17:35:47.312657 13268 net.cpp:395] relu7 -> fc7 (in-place)
I0905 17:35:47.312940 13268 net.cpp:150] Setting up relu7
I0905 17:35:47.312954 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:47.312966 13268 net.cpp:165] Memory required for data: 270631424
I0905 17:35:47.312970 13268 layer_factory.hpp:77] Creating layer drop7
I0905 17:35:47.312983 13268 net.cpp:100] Creating Layer drop7
I0905 17:35:47.312988 13268 net.cpp:434] drop7 <- fc7
I0905 17:35:47.312993 13268 net.cpp:395] drop7 -> fc7 (in-place)
I0905 17:35:47.313026 13268 net.cpp:150] Setting up drop7
I0905 17:35:47.313040 13268 net.cpp:157] Top shape: 128 4096 (524288)
I0905 17:35:47.313042 13268 net.cpp:165] Memory required for data: 272728576
I0905 17:35:47.313045 13268 layer_factory.hpp:77] Creating layer fc8n
I0905 17:35:47.313055 13268 net.cpp:100] Creating Layer fc8n
I0905 17:35:47.313057 13268 net.cpp:434] fc8n <- fc7
I0905 17:35:47.313063 13268 net.cpp:408] fc8n -> fc8
I0905 17:35:47.314785 13268 net.cpp:150] Setting up fc8n
I0905 17:35:47.314798 13268 net.cpp:157] Top shape: 128 3 (384)
I0905 17:35:47.314801 13268 net.cpp:165] Memory required for data: 272730112
I0905 17:35:47.314807 13268 layer_factory.hpp:77] Creating layer loss
I0905 17:35:47.314818 13268 net.cpp:100] Creating Layer loss
I0905 17:35:47.314821 13268 net.cpp:434] loss <- fc8
I0905 17:35:47.314826 13268 net.cpp:434] loss <- label
I0905 17:35:47.314831 13268 net.cpp:408] loss -> loss
I0905 17:35:47.314842 13268 layer_factory.hpp:77] Creating layer loss
I0905 17:35:47.315124 13268 net.cpp:150] Setting up loss
I0905 17:35:47.315137 13268 net.cpp:157] Top shape: (1)
I0905 17:35:47.315140 13268 net.cpp:160]     with loss weight 1
I0905 17:35:47.315155 13268 net.cpp:165] Memory required for data: 272730116
I0905 17:35:47.315157 13268 net.cpp:226] loss needs backward computation.
I0905 17:35:47.315161 13268 net.cpp:226] fc8n needs backward computation.
I0905 17:35:47.315165 13268 net.cpp:226] drop7 needs backward computation.
I0905 17:35:47.315166 13268 net.cpp:226] relu7 needs backward computation.
I0905 17:35:47.315170 13268 net.cpp:226] fc7n needs backward computation.
I0905 17:35:47.315171 13268 net.cpp:226] drop6 needs backward computation.
I0905 17:35:47.315174 13268 net.cpp:226] relu6 needs backward computation.
I0905 17:35:47.315177 13268 net.cpp:226] fc6n needs backward computation.
I0905 17:35:47.315181 13268 net.cpp:226] pool5 needs backward computation.
I0905 17:35:47.315184 13268 net.cpp:226] relu5 needs backward computation.
I0905 17:35:47.315188 13268 net.cpp:226] conv5 needs backward computation.
I0905 17:35:47.315191 13268 net.cpp:226] relu4 needs backward computation.
I0905 17:35:47.315193 13268 net.cpp:226] conv4 needs backward computation.
I0905 17:35:47.315196 13268 net.cpp:226] relu3 needs backward computation.
I0905 17:35:47.315199 13268 net.cpp:226] conv3 needs backward computation.
I0905 17:35:47.315202 13268 net.cpp:226] norm2 needs backward computation.
I0905 17:35:47.315207 13268 net.cpp:226] pool2 needs backward computation.
I0905 17:35:47.315212 13268 net.cpp:226] relu2 needs backward computation.
I0905 17:35:47.315217 13268 net.cpp:226] conv2 needs backward computation.
I0905 17:35:47.315222 13268 net.cpp:226] norm1 needs backward computation.
I0905 17:35:47.315227 13268 net.cpp:226] pool1 needs backward computation.
I0905 17:35:47.315233 13268 net.cpp:226] relu1 needs backward computation.
I0905 17:35:47.315237 13268 net.cpp:226] conv1 needs backward computation.
I0905 17:35:47.315240 13268 net.cpp:228] data does not need backward computation.
I0905 17:35:47.315243 13268 net.cpp:270] This network produces output loss
I0905 17:35:47.315256 13268 net.cpp:283] Network initialization done.
I0905 17:35:47.315836 13268 solver.cpp:181] Creating test net (#0) specified by net file: nets/person_vs_background_vs_random_caffe_net/trainval.prototxt
I0905 17:35:47.315904 13268 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0905 17:35:47.316072 13268 net.cpp:58] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto"
  }
  data_param {
    source: "data/person_only_lmdb/person_vs_background_vs_random_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6n"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7n"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8n"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0905 17:35:47.316171 13268 layer_factory.hpp:77] Creating layer data
I0905 17:35:47.316296 13268 net.cpp:100] Creating Layer data
I0905 17:35:47.316308 13268 net.cpp:408] data -> data
I0905 17:35:47.316314 13268 net.cpp:408] data -> label
I0905 17:35:47.316321 13268 data_transformer.cpp:25] Loading mean file from: data/person_only_lmdb/person_vs_background_vs_random_color_mean.binaryproto
I0905 17:35:47.317833 13311 db_lmdb.cpp:35] Opened lmdb data/person_only_lmdb/person_vs_background_vs_random_test_lmdb
I0905 17:35:47.318112 13268 data_layer.cpp:41] output data size: 100,3,128,128
I0905 17:35:47.363637 13268 net.cpp:150] Setting up data
I0905 17:35:47.363675 13268 net.cpp:157] Top shape: 100 3 128 128 (4915200)
I0905 17:35:47.363682 13268 net.cpp:157] Top shape: 100 (100)
I0905 17:35:47.363685 13268 net.cpp:165] Memory required for data: 19661200
I0905 17:35:47.363692 13268 layer_factory.hpp:77] Creating layer label_data_1_split
I0905 17:35:47.363708 13268 net.cpp:100] Creating Layer label_data_1_split
I0905 17:35:47.363713 13268 net.cpp:434] label_data_1_split <- label
I0905 17:35:47.363723 13268 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0905 17:35:47.363734 13268 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0905 17:35:47.364042 13268 net.cpp:150] Setting up label_data_1_split
I0905 17:35:47.364078 13268 net.cpp:157] Top shape: 100 (100)
I0905 17:35:47.364089 13268 net.cpp:157] Top shape: 100 (100)
I0905 17:35:47.364095 13268 net.cpp:165] Memory required for data: 19662000
I0905 17:35:47.364104 13268 layer_factory.hpp:77] Creating layer conv1
I0905 17:35:47.364125 13268 net.cpp:100] Creating Layer conv1
I0905 17:35:47.364133 13268 net.cpp:434] conv1 <- data
I0905 17:35:47.364146 13268 net.cpp:408] conv1 -> conv1
I0905 17:35:47.370605 13268 net.cpp:150] Setting up conv1
I0905 17:35:47.370642 13268 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0905 17:35:47.370652 13268 net.cpp:165] Memory required for data: 54222000
I0905 17:35:47.370674 13268 layer_factory.hpp:77] Creating layer relu1
I0905 17:35:47.370688 13268 net.cpp:100] Creating Layer relu1
I0905 17:35:47.370695 13268 net.cpp:434] relu1 <- conv1
I0905 17:35:47.370707 13268 net.cpp:395] relu1 -> conv1 (in-place)
I0905 17:35:47.371052 13268 net.cpp:150] Setting up relu1
I0905 17:35:47.371073 13268 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I0905 17:35:47.371081 13268 net.cpp:165] Memory required for data: 88782000
I0905 17:35:47.371088 13268 layer_factory.hpp:77] Creating layer pool1
I0905 17:35:47.371103 13268 net.cpp:100] Creating Layer pool1
I0905 17:35:47.371109 13268 net.cpp:434] pool1 <- conv1
I0905 17:35:47.371119 13268 net.cpp:408] pool1 -> pool1
I0905 17:35:47.371206 13268 net.cpp:150] Setting up pool1
I0905 17:35:47.371220 13268 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0905 17:35:47.371227 13268 net.cpp:165] Memory required for data: 97422000
I0905 17:35:47.371232 13268 layer_factory.hpp:77] Creating layer norm1
I0905 17:35:47.371244 13268 net.cpp:100] Creating Layer norm1
I0905 17:35:47.371250 13268 net.cpp:434] norm1 <- pool1
I0905 17:35:47.371260 13268 net.cpp:408] norm1 -> norm1
I0905 17:35:47.372238 13268 net.cpp:150] Setting up norm1
I0905 17:35:47.372270 13268 net.cpp:157] Top shape: 100 96 15 15 (2160000)
I0905 17:35:47.372278 13268 net.cpp:165] Memory required for data: 106062000
I0905 17:35:47.372287 13268 layer_factory.hpp:77] Creating layer conv2
I0905 17:35:47.372328 13268 net.cpp:100] Creating Layer conv2
I0905 17:35:47.372335 13268 net.cpp:434] conv2 <- norm1
I0905 17:35:47.372349 13268 net.cpp:408] conv2 -> conv2
I0905 17:35:47.390467 13268 net.cpp:150] Setting up conv2
I0905 17:35:47.390493 13268 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0905 17:35:47.390497 13268 net.cpp:165] Memory required for data: 129102000
I0905 17:35:47.390511 13268 layer_factory.hpp:77] Creating layer relu2
I0905 17:35:47.390518 13268 net.cpp:100] Creating Layer relu2
I0905 17:35:47.390522 13268 net.cpp:434] relu2 <- conv2
I0905 17:35:47.390530 13268 net.cpp:395] relu2 -> conv2 (in-place)
I0905 17:35:47.391104 13268 net.cpp:150] Setting up relu2
I0905 17:35:47.391124 13268 net.cpp:157] Top shape: 100 256 15 15 (5760000)
I0905 17:35:47.391129 13268 net.cpp:165] Memory required for data: 152142000
I0905 17:35:47.391134 13268 layer_factory.hpp:77] Creating layer pool2
I0905 17:35:47.391145 13268 net.cpp:100] Creating Layer pool2
I0905 17:35:47.391149 13268 net.cpp:434] pool2 <- conv2
I0905 17:35:47.391156 13268 net.cpp:408] pool2 -> pool2
I0905 17:35:47.391216 13268 net.cpp:150] Setting up pool2
I0905 17:35:47.391224 13268 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0905 17:35:47.391227 13268 net.cpp:165] Memory required for data: 157159600
I0905 17:35:47.391232 13268 layer_factory.hpp:77] Creating layer norm2
I0905 17:35:47.391239 13268 net.cpp:100] Creating Layer norm2
I0905 17:35:47.391243 13268 net.cpp:434] norm2 <- pool2
I0905 17:35:47.391248 13268 net.cpp:408] norm2 -> norm2
I0905 17:35:47.391477 13268 net.cpp:150] Setting up norm2
I0905 17:35:47.391492 13268 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0905 17:35:47.391496 13268 net.cpp:165] Memory required for data: 162177200
I0905 17:35:47.391499 13268 layer_factory.hpp:77] Creating layer conv3
I0905 17:35:47.391512 13268 net.cpp:100] Creating Layer conv3
I0905 17:35:47.391516 13268 net.cpp:434] conv3 <- norm2
I0905 17:35:47.391522 13268 net.cpp:408] conv3 -> conv3
I0905 17:35:47.426379 13268 net.cpp:150] Setting up conv3
I0905 17:35:47.426411 13268 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0905 17:35:47.426416 13268 net.cpp:165] Memory required for data: 169703600
I0905 17:35:47.426431 13268 layer_factory.hpp:77] Creating layer relu3
I0905 17:35:47.426443 13268 net.cpp:100] Creating Layer relu3
I0905 17:35:47.426447 13268 net.cpp:434] relu3 <- conv3
I0905 17:35:47.426456 13268 net.cpp:395] relu3 -> conv3 (in-place)
I0905 17:35:47.426676 13268 net.cpp:150] Setting up relu3
I0905 17:35:47.426688 13268 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0905 17:35:47.426692 13268 net.cpp:165] Memory required for data: 177230000
I0905 17:35:47.426697 13268 layer_factory.hpp:77] Creating layer conv4
I0905 17:35:47.426712 13268 net.cpp:100] Creating Layer conv4
I0905 17:35:47.426715 13268 net.cpp:434] conv4 <- conv3
I0905 17:35:47.426722 13268 net.cpp:408] conv4 -> conv4
I0905 17:35:47.454231 13268 net.cpp:150] Setting up conv4
I0905 17:35:47.454262 13268 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0905 17:35:47.454267 13268 net.cpp:165] Memory required for data: 184756400
I0905 17:35:47.454277 13268 layer_factory.hpp:77] Creating layer relu4
I0905 17:35:47.454288 13268 net.cpp:100] Creating Layer relu4
I0905 17:35:47.454293 13268 net.cpp:434] relu4 <- conv4
I0905 17:35:47.454300 13268 net.cpp:395] relu4 -> conv4 (in-place)
I0905 17:35:47.454864 13268 net.cpp:150] Setting up relu4
I0905 17:35:47.454879 13268 net.cpp:157] Top shape: 100 384 7 7 (1881600)
I0905 17:35:47.454884 13268 net.cpp:165] Memory required for data: 192282800
I0905 17:35:47.454887 13268 layer_factory.hpp:77] Creating layer conv5
I0905 17:35:47.454902 13268 net.cpp:100] Creating Layer conv5
I0905 17:35:47.454911 13268 net.cpp:434] conv5 <- conv4
I0905 17:35:47.454918 13268 net.cpp:408] conv5 -> conv5
I0905 17:35:47.474112 13268 net.cpp:150] Setting up conv5
I0905 17:35:47.474130 13268 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0905 17:35:47.474134 13268 net.cpp:165] Memory required for data: 197300400
I0905 17:35:47.474146 13268 layer_factory.hpp:77] Creating layer relu5
I0905 17:35:47.474154 13268 net.cpp:100] Creating Layer relu5
I0905 17:35:47.474158 13268 net.cpp:434] relu5 <- conv5
I0905 17:35:47.474165 13268 net.cpp:395] relu5 -> conv5 (in-place)
I0905 17:35:47.474375 13268 net.cpp:150] Setting up relu5
I0905 17:35:47.474388 13268 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0905 17:35:47.474392 13268 net.cpp:165] Memory required for data: 202318000
I0905 17:35:47.474396 13268 layer_factory.hpp:77] Creating layer pool5
I0905 17:35:47.474407 13268 net.cpp:100] Creating Layer pool5
I0905 17:35:47.474411 13268 net.cpp:434] pool5 <- conv5
I0905 17:35:47.474416 13268 net.cpp:408] pool5 -> pool5
I0905 17:35:47.474470 13268 net.cpp:150] Setting up pool5
I0905 17:35:47.474481 13268 net.cpp:157] Top shape: 100 256 3 3 (230400)
I0905 17:35:47.474484 13268 net.cpp:165] Memory required for data: 203239600
I0905 17:35:47.474488 13268 layer_factory.hpp:77] Creating layer fc6n
I0905 17:35:47.474498 13268 net.cpp:100] Creating Layer fc6n
I0905 17:35:47.474503 13268 net.cpp:434] fc6n <- pool5
I0905 17:35:47.474509 13268 net.cpp:408] fc6n -> fc6
I0905 17:35:47.762681 13268 net.cpp:150] Setting up fc6n
I0905 17:35:47.762715 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:47.762719 13268 net.cpp:165] Memory required for data: 204878000
I0905 17:35:47.762728 13268 layer_factory.hpp:77] Creating layer relu6
I0905 17:35:47.762740 13268 net.cpp:100] Creating Layer relu6
I0905 17:35:47.762744 13268 net.cpp:434] relu6 <- fc6
I0905 17:35:47.762751 13268 net.cpp:395] relu6 -> fc6 (in-place)
I0905 17:35:47.763030 13268 net.cpp:150] Setting up relu6
I0905 17:35:47.763041 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:47.763044 13268 net.cpp:165] Memory required for data: 206516400
I0905 17:35:47.763047 13268 layer_factory.hpp:77] Creating layer drop6
I0905 17:35:47.763054 13268 net.cpp:100] Creating Layer drop6
I0905 17:35:47.763057 13268 net.cpp:434] drop6 <- fc6
I0905 17:35:47.763068 13268 net.cpp:395] drop6 -> fc6 (in-place)
I0905 17:35:47.763098 13268 net.cpp:150] Setting up drop6
I0905 17:35:47.763111 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:47.763115 13268 net.cpp:165] Memory required for data: 208154800
I0905 17:35:47.763118 13268 layer_factory.hpp:77] Creating layer fc7n
I0905 17:35:47.763126 13268 net.cpp:100] Creating Layer fc7n
I0905 17:35:47.763129 13268 net.cpp:434] fc7n <- fc6
I0905 17:35:47.763136 13268 net.cpp:408] fc7n -> fc7
I0905 17:35:48.231619 13268 net.cpp:150] Setting up fc7n
I0905 17:35:48.231653 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:48.231657 13268 net.cpp:165] Memory required for data: 209793200
I0905 17:35:48.231667 13268 layer_factory.hpp:77] Creating layer relu7
I0905 17:35:48.231676 13268 net.cpp:100] Creating Layer relu7
I0905 17:35:48.231680 13268 net.cpp:434] relu7 <- fc7
I0905 17:35:48.231685 13268 net.cpp:395] relu7 -> fc7 (in-place)
I0905 17:35:48.232447 13268 net.cpp:150] Setting up relu7
I0905 17:35:48.232460 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:48.232465 13268 net.cpp:165] Memory required for data: 211431600
I0905 17:35:48.232467 13268 layer_factory.hpp:77] Creating layer drop7
I0905 17:35:48.232475 13268 net.cpp:100] Creating Layer drop7
I0905 17:35:48.232478 13268 net.cpp:434] drop7 <- fc7
I0905 17:35:48.232484 13268 net.cpp:395] drop7 -> fc7 (in-place)
I0905 17:35:48.232524 13268 net.cpp:150] Setting up drop7
I0905 17:35:48.232529 13268 net.cpp:157] Top shape: 100 4096 (409600)
I0905 17:35:48.232532 13268 net.cpp:165] Memory required for data: 213070000
I0905 17:35:48.232534 13268 layer_factory.hpp:77] Creating layer fc8n
I0905 17:35:48.232547 13268 net.cpp:100] Creating Layer fc8n
I0905 17:35:48.232549 13268 net.cpp:434] fc8n <- fc7
I0905 17:35:48.232555 13268 net.cpp:408] fc8n -> fc8
I0905 17:35:48.233079 13268 net.cpp:150] Setting up fc8n
I0905 17:35:48.233088 13268 net.cpp:157] Top shape: 100 3 (300)
I0905 17:35:48.233090 13268 net.cpp:165] Memory required for data: 213071200
I0905 17:35:48.233095 13268 layer_factory.hpp:77] Creating layer fc8_fc8n_0_split
I0905 17:35:48.233101 13268 net.cpp:100] Creating Layer fc8_fc8n_0_split
I0905 17:35:48.233103 13268 net.cpp:434] fc8_fc8n_0_split <- fc8
I0905 17:35:48.233108 13268 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_0
I0905 17:35:48.233113 13268 net.cpp:408] fc8_fc8n_0_split -> fc8_fc8n_0_split_1
I0905 17:35:48.233147 13268 net.cpp:150] Setting up fc8_fc8n_0_split
I0905 17:35:48.233152 13268 net.cpp:157] Top shape: 100 3 (300)
I0905 17:35:48.233155 13268 net.cpp:157] Top shape: 100 3 (300)
I0905 17:35:48.233157 13268 net.cpp:165] Memory required for data: 213073600
I0905 17:35:48.233160 13268 layer_factory.hpp:77] Creating layer accuracy
I0905 17:35:48.233170 13268 net.cpp:100] Creating Layer accuracy
I0905 17:35:48.233172 13268 net.cpp:434] accuracy <- fc8_fc8n_0_split_0
I0905 17:35:48.233176 13268 net.cpp:434] accuracy <- label_data_1_split_0
I0905 17:35:48.233182 13268 net.cpp:408] accuracy -> accuracy
I0905 17:35:48.233191 13268 net.cpp:150] Setting up accuracy
I0905 17:35:48.233194 13268 net.cpp:157] Top shape: (1)
I0905 17:35:48.233196 13268 net.cpp:165] Memory required for data: 213073604
I0905 17:35:48.233199 13268 layer_factory.hpp:77] Creating layer loss
I0905 17:35:48.233204 13268 net.cpp:100] Creating Layer loss
I0905 17:35:48.233206 13268 net.cpp:434] loss <- fc8_fc8n_0_split_1
I0905 17:35:48.233211 13268 net.cpp:434] loss <- label_data_1_split_1
I0905 17:35:48.233214 13268 net.cpp:408] loss -> loss
I0905 17:35:48.233220 13268 layer_factory.hpp:77] Creating layer loss
I0905 17:35:48.233449 13268 net.cpp:150] Setting up loss
I0905 17:35:48.233458 13268 net.cpp:157] Top shape: (1)
I0905 17:35:48.233460 13268 net.cpp:160]     with loss weight 1
I0905 17:35:48.233469 13268 net.cpp:165] Memory required for data: 213073608
I0905 17:35:48.233471 13268 net.cpp:226] loss needs backward computation.
I0905 17:35:48.233476 13268 net.cpp:228] accuracy does not need backward computation.
I0905 17:35:48.233479 13268 net.cpp:226] fc8_fc8n_0_split needs backward computation.
I0905 17:35:48.233482 13268 net.cpp:226] fc8n needs backward computation.
I0905 17:35:48.233484 13268 net.cpp:226] drop7 needs backward computation.
I0905 17:35:48.233487 13268 net.cpp:226] relu7 needs backward computation.
I0905 17:35:48.233489 13268 net.cpp:226] fc7n needs backward computation.
I0905 17:35:48.233491 13268 net.cpp:226] drop6 needs backward computation.
I0905 17:35:48.233494 13268 net.cpp:226] relu6 needs backward computation.
I0905 17:35:48.233496 13268 net.cpp:226] fc6n needs backward computation.
I0905 17:35:48.233500 13268 net.cpp:226] pool5 needs backward computation.
I0905 17:35:48.233502 13268 net.cpp:226] relu5 needs backward computation.
I0905 17:35:48.233505 13268 net.cpp:226] conv5 needs backward computation.
I0905 17:35:48.233508 13268 net.cpp:226] relu4 needs backward computation.
I0905 17:35:48.233510 13268 net.cpp:226] conv4 needs backward computation.
I0905 17:35:48.233513 13268 net.cpp:226] relu3 needs backward computation.
I0905 17:35:48.233515 13268 net.cpp:226] conv3 needs backward computation.
I0905 17:35:48.233518 13268 net.cpp:226] norm2 needs backward computation.
I0905 17:35:48.233521 13268 net.cpp:226] pool2 needs backward computation.
I0905 17:35:48.233525 13268 net.cpp:226] relu2 needs backward computation.
I0905 17:35:48.233526 13268 net.cpp:226] conv2 needs backward computation.
I0905 17:35:48.233530 13268 net.cpp:226] norm1 needs backward computation.
I0905 17:35:48.233532 13268 net.cpp:226] pool1 needs backward computation.
I0905 17:35:48.233536 13268 net.cpp:226] relu1 needs backward computation.
I0905 17:35:48.233538 13268 net.cpp:226] conv1 needs backward computation.
I0905 17:35:48.233541 13268 net.cpp:228] label_data_1_split does not need backward computation.
I0905 17:35:48.233544 13268 net.cpp:228] data does not need backward computation.
I0905 17:35:48.233546 13268 net.cpp:270] This network produces output accuracy
I0905 17:35:48.233549 13268 net.cpp:270] This network produces output loss
I0905 17:35:48.233566 13268 net.cpp:283] Network initialization done.
I0905 17:35:48.233646 13268 solver.cpp:60] Solver scaffolding done.
I0905 17:35:48.236625 13268 solver.cpp:337] Iteration 0, Testing net (#0)
I0905 17:35:48.312903 13268 blocking_queue.cpp:50] Data layer prefetch queue empty
I0905 17:35:53.197727 13268 solver.cpp:404]     Test net output #0: accuracy = 0.269667
I0905 17:35:53.197779 13268 solver.cpp:404]     Test net output #1: loss = 63.7848 (* 1 = 63.7848 loss)
I0905 17:35:53.224020 13268 solver.cpp:228] Iteration 0, loss = 58.6792
I0905 17:35:53.224059 13268 solver.cpp:244]     Train net output #0: loss = 58.6792 (* 1 = 58.6792 loss)
I0905 17:35:53.224076 13268 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0905 17:35:57.487988 13268 solver.cpp:228] Iteration 100, loss = 87.3365
I0905 17:35:57.488055 13268 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0905 17:35:57.488066 13268 sgd_solver.cpp:106] Iteration 100, lr = 9.96266e-05
I0905 17:36:01.731506 13268 solver.cpp:228] Iteration 200, loss = 87.3365
I0905 17:36:01.731590 13268 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0905 17:36:01.731608 13268 sgd_solver.cpp:106] Iteration 200, lr = 9.92565e-05
I0905 17:36:05.893566 13268 solver.cpp:228] Iteration 300, loss = 87.3365
I0905 17:36:05.893612 13268 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0905 17:36:05.893620 13268 sgd_solver.cpp:106] Iteration 300, lr = 9.88896e-05
